[
    {
        "func_name": "test_rowwise_dnnlowp_fully_connected_int",
        "original": "@given(input_channels=st.sampled_from([3, 4, 5, 8, 16, 32]), output_channels=st.integers(2, 16), batch_size=st.integers(0, 16), in_quantized=st.booleans(), out_quantized=st.booleans(), prepack_weight=st.booleans(), **hu.gcs_cpu_only)\ndef test_rowwise_dnnlowp_fully_connected_int(self, input_channels, output_channels, batch_size, in_quantized, out_quantized, prepack_weight, gc, dc):\n    X_min = -77\n    X_max = X_min + 255\n    X = np.round(np.random.rand(batch_size, input_channels) * (X_max - X_min) + X_min)\n    X = X.astype(np.float32)\n    X[:, 0:2] = X_min\n    if batch_size != 0:\n        X[0, 2] = X_max\n    W = np.zeros((output_channels, input_channels))\n    W = W.astype(np.float32)\n    for i in range(output_channels):\n        W_min = -100 + i\n        W_max = W_min + 255\n        W[i, :] = np.round(np.random.rand(input_channels) * (W_max - W_min) + W_min)\n        W[i, 0] = W_min\n        W[i, 1] = W_max\n        avoid_vpmaddubsw_overflow_fc(batch_size, input_channels, 1, X, X_min, X_max, W[i:i + 1,], W_min, W_max)\n        if i % 2 == 0:\n            W[i, :] = (W[i, :] - W_min) * 2 + W_min\n    b = np.random.randn(output_channels).astype(np.float32)\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('FC', ''), ('FC', 'DNNLOWP_ROWWISE'), ('FC', 'DNNLOWP_ROWWISE_16'), ('Int8FC', 'DNNLOWP_ROWWISE')]\n    for (op_type, engine) in op_engine_list:\n        init_net = core.Net('test_init_net')\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_prepack_weight = engine == 'DNNLOWP_ROWWISE' and prepack_weight\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        X_min = 0 if X.size == 0 else X.min()\n        X_max = 0 if X.size == 0 else X.max()\n        x_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n        if do_prepack_weight:\n            inputs = ['W']\n            if do_dequantize:\n                inputs += ['b']\n            pack = core.CreateOperator('Int8FCPackWeight', inputs, ['W_packed'], in_scale=x_q_param.scale, engine=engine)\n            init_net.Proto().op.extend([pack])\n        fc = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'W_packed' if do_prepack_weight else 'W', 'b'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n        if do_prepack_weight:\n            dnnlowp_utils.add_quantization_param_args(fc, outputs[0][0])\n        net.Proto().op.extend([fc])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        run_conv_or_fc(self, init_net, net, X, W, b, op_type, engine, None, gc, outputs)\n    check_quantized_results_close(outputs)",
        "mutated": [
            "@given(input_channels=st.sampled_from([3, 4, 5, 8, 16, 32]), output_channels=st.integers(2, 16), batch_size=st.integers(0, 16), in_quantized=st.booleans(), out_quantized=st.booleans(), prepack_weight=st.booleans(), **hu.gcs_cpu_only)\ndef test_rowwise_dnnlowp_fully_connected_int(self, input_channels, output_channels, batch_size, in_quantized, out_quantized, prepack_weight, gc, dc):\n    if False:\n        i = 10\n    X_min = -77\n    X_max = X_min + 255\n    X = np.round(np.random.rand(batch_size, input_channels) * (X_max - X_min) + X_min)\n    X = X.astype(np.float32)\n    X[:, 0:2] = X_min\n    if batch_size != 0:\n        X[0, 2] = X_max\n    W = np.zeros((output_channels, input_channels))\n    W = W.astype(np.float32)\n    for i in range(output_channels):\n        W_min = -100 + i\n        W_max = W_min + 255\n        W[i, :] = np.round(np.random.rand(input_channels) * (W_max - W_min) + W_min)\n        W[i, 0] = W_min\n        W[i, 1] = W_max\n        avoid_vpmaddubsw_overflow_fc(batch_size, input_channels, 1, X, X_min, X_max, W[i:i + 1,], W_min, W_max)\n        if i % 2 == 0:\n            W[i, :] = (W[i, :] - W_min) * 2 + W_min\n    b = np.random.randn(output_channels).astype(np.float32)\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('FC', ''), ('FC', 'DNNLOWP_ROWWISE'), ('FC', 'DNNLOWP_ROWWISE_16'), ('Int8FC', 'DNNLOWP_ROWWISE')]\n    for (op_type, engine) in op_engine_list:\n        init_net = core.Net('test_init_net')\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_prepack_weight = engine == 'DNNLOWP_ROWWISE' and prepack_weight\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        X_min = 0 if X.size == 0 else X.min()\n        X_max = 0 if X.size == 0 else X.max()\n        x_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n        if do_prepack_weight:\n            inputs = ['W']\n            if do_dequantize:\n                inputs += ['b']\n            pack = core.CreateOperator('Int8FCPackWeight', inputs, ['W_packed'], in_scale=x_q_param.scale, engine=engine)\n            init_net.Proto().op.extend([pack])\n        fc = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'W_packed' if do_prepack_weight else 'W', 'b'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n        if do_prepack_weight:\n            dnnlowp_utils.add_quantization_param_args(fc, outputs[0][0])\n        net.Proto().op.extend([fc])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        run_conv_or_fc(self, init_net, net, X, W, b, op_type, engine, None, gc, outputs)\n    check_quantized_results_close(outputs)",
            "@given(input_channels=st.sampled_from([3, 4, 5, 8, 16, 32]), output_channels=st.integers(2, 16), batch_size=st.integers(0, 16), in_quantized=st.booleans(), out_quantized=st.booleans(), prepack_weight=st.booleans(), **hu.gcs_cpu_only)\ndef test_rowwise_dnnlowp_fully_connected_int(self, input_channels, output_channels, batch_size, in_quantized, out_quantized, prepack_weight, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    X_min = -77\n    X_max = X_min + 255\n    X = np.round(np.random.rand(batch_size, input_channels) * (X_max - X_min) + X_min)\n    X = X.astype(np.float32)\n    X[:, 0:2] = X_min\n    if batch_size != 0:\n        X[0, 2] = X_max\n    W = np.zeros((output_channels, input_channels))\n    W = W.astype(np.float32)\n    for i in range(output_channels):\n        W_min = -100 + i\n        W_max = W_min + 255\n        W[i, :] = np.round(np.random.rand(input_channels) * (W_max - W_min) + W_min)\n        W[i, 0] = W_min\n        W[i, 1] = W_max\n        avoid_vpmaddubsw_overflow_fc(batch_size, input_channels, 1, X, X_min, X_max, W[i:i + 1,], W_min, W_max)\n        if i % 2 == 0:\n            W[i, :] = (W[i, :] - W_min) * 2 + W_min\n    b = np.random.randn(output_channels).astype(np.float32)\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('FC', ''), ('FC', 'DNNLOWP_ROWWISE'), ('FC', 'DNNLOWP_ROWWISE_16'), ('Int8FC', 'DNNLOWP_ROWWISE')]\n    for (op_type, engine) in op_engine_list:\n        init_net = core.Net('test_init_net')\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_prepack_weight = engine == 'DNNLOWP_ROWWISE' and prepack_weight\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        X_min = 0 if X.size == 0 else X.min()\n        X_max = 0 if X.size == 0 else X.max()\n        x_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n        if do_prepack_weight:\n            inputs = ['W']\n            if do_dequantize:\n                inputs += ['b']\n            pack = core.CreateOperator('Int8FCPackWeight', inputs, ['W_packed'], in_scale=x_q_param.scale, engine=engine)\n            init_net.Proto().op.extend([pack])\n        fc = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'W_packed' if do_prepack_weight else 'W', 'b'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n        if do_prepack_weight:\n            dnnlowp_utils.add_quantization_param_args(fc, outputs[0][0])\n        net.Proto().op.extend([fc])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        run_conv_or_fc(self, init_net, net, X, W, b, op_type, engine, None, gc, outputs)\n    check_quantized_results_close(outputs)",
            "@given(input_channels=st.sampled_from([3, 4, 5, 8, 16, 32]), output_channels=st.integers(2, 16), batch_size=st.integers(0, 16), in_quantized=st.booleans(), out_quantized=st.booleans(), prepack_weight=st.booleans(), **hu.gcs_cpu_only)\ndef test_rowwise_dnnlowp_fully_connected_int(self, input_channels, output_channels, batch_size, in_quantized, out_quantized, prepack_weight, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    X_min = -77\n    X_max = X_min + 255\n    X = np.round(np.random.rand(batch_size, input_channels) * (X_max - X_min) + X_min)\n    X = X.astype(np.float32)\n    X[:, 0:2] = X_min\n    if batch_size != 0:\n        X[0, 2] = X_max\n    W = np.zeros((output_channels, input_channels))\n    W = W.astype(np.float32)\n    for i in range(output_channels):\n        W_min = -100 + i\n        W_max = W_min + 255\n        W[i, :] = np.round(np.random.rand(input_channels) * (W_max - W_min) + W_min)\n        W[i, 0] = W_min\n        W[i, 1] = W_max\n        avoid_vpmaddubsw_overflow_fc(batch_size, input_channels, 1, X, X_min, X_max, W[i:i + 1,], W_min, W_max)\n        if i % 2 == 0:\n            W[i, :] = (W[i, :] - W_min) * 2 + W_min\n    b = np.random.randn(output_channels).astype(np.float32)\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('FC', ''), ('FC', 'DNNLOWP_ROWWISE'), ('FC', 'DNNLOWP_ROWWISE_16'), ('Int8FC', 'DNNLOWP_ROWWISE')]\n    for (op_type, engine) in op_engine_list:\n        init_net = core.Net('test_init_net')\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_prepack_weight = engine == 'DNNLOWP_ROWWISE' and prepack_weight\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        X_min = 0 if X.size == 0 else X.min()\n        X_max = 0 if X.size == 0 else X.max()\n        x_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n        if do_prepack_weight:\n            inputs = ['W']\n            if do_dequantize:\n                inputs += ['b']\n            pack = core.CreateOperator('Int8FCPackWeight', inputs, ['W_packed'], in_scale=x_q_param.scale, engine=engine)\n            init_net.Proto().op.extend([pack])\n        fc = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'W_packed' if do_prepack_weight else 'W', 'b'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n        if do_prepack_weight:\n            dnnlowp_utils.add_quantization_param_args(fc, outputs[0][0])\n        net.Proto().op.extend([fc])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        run_conv_or_fc(self, init_net, net, X, W, b, op_type, engine, None, gc, outputs)\n    check_quantized_results_close(outputs)",
            "@given(input_channels=st.sampled_from([3, 4, 5, 8, 16, 32]), output_channels=st.integers(2, 16), batch_size=st.integers(0, 16), in_quantized=st.booleans(), out_quantized=st.booleans(), prepack_weight=st.booleans(), **hu.gcs_cpu_only)\ndef test_rowwise_dnnlowp_fully_connected_int(self, input_channels, output_channels, batch_size, in_quantized, out_quantized, prepack_weight, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    X_min = -77\n    X_max = X_min + 255\n    X = np.round(np.random.rand(batch_size, input_channels) * (X_max - X_min) + X_min)\n    X = X.astype(np.float32)\n    X[:, 0:2] = X_min\n    if batch_size != 0:\n        X[0, 2] = X_max\n    W = np.zeros((output_channels, input_channels))\n    W = W.astype(np.float32)\n    for i in range(output_channels):\n        W_min = -100 + i\n        W_max = W_min + 255\n        W[i, :] = np.round(np.random.rand(input_channels) * (W_max - W_min) + W_min)\n        W[i, 0] = W_min\n        W[i, 1] = W_max\n        avoid_vpmaddubsw_overflow_fc(batch_size, input_channels, 1, X, X_min, X_max, W[i:i + 1,], W_min, W_max)\n        if i % 2 == 0:\n            W[i, :] = (W[i, :] - W_min) * 2 + W_min\n    b = np.random.randn(output_channels).astype(np.float32)\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('FC', ''), ('FC', 'DNNLOWP_ROWWISE'), ('FC', 'DNNLOWP_ROWWISE_16'), ('Int8FC', 'DNNLOWP_ROWWISE')]\n    for (op_type, engine) in op_engine_list:\n        init_net = core.Net('test_init_net')\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_prepack_weight = engine == 'DNNLOWP_ROWWISE' and prepack_weight\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        X_min = 0 if X.size == 0 else X.min()\n        X_max = 0 if X.size == 0 else X.max()\n        x_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n        if do_prepack_weight:\n            inputs = ['W']\n            if do_dequantize:\n                inputs += ['b']\n            pack = core.CreateOperator('Int8FCPackWeight', inputs, ['W_packed'], in_scale=x_q_param.scale, engine=engine)\n            init_net.Proto().op.extend([pack])\n        fc = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'W_packed' if do_prepack_weight else 'W', 'b'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n        if do_prepack_weight:\n            dnnlowp_utils.add_quantization_param_args(fc, outputs[0][0])\n        net.Proto().op.extend([fc])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        run_conv_or_fc(self, init_net, net, X, W, b, op_type, engine, None, gc, outputs)\n    check_quantized_results_close(outputs)",
            "@given(input_channels=st.sampled_from([3, 4, 5, 8, 16, 32]), output_channels=st.integers(2, 16), batch_size=st.integers(0, 16), in_quantized=st.booleans(), out_quantized=st.booleans(), prepack_weight=st.booleans(), **hu.gcs_cpu_only)\ndef test_rowwise_dnnlowp_fully_connected_int(self, input_channels, output_channels, batch_size, in_quantized, out_quantized, prepack_weight, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    X_min = -77\n    X_max = X_min + 255\n    X = np.round(np.random.rand(batch_size, input_channels) * (X_max - X_min) + X_min)\n    X = X.astype(np.float32)\n    X[:, 0:2] = X_min\n    if batch_size != 0:\n        X[0, 2] = X_max\n    W = np.zeros((output_channels, input_channels))\n    W = W.astype(np.float32)\n    for i in range(output_channels):\n        W_min = -100 + i\n        W_max = W_min + 255\n        W[i, :] = np.round(np.random.rand(input_channels) * (W_max - W_min) + W_min)\n        W[i, 0] = W_min\n        W[i, 1] = W_max\n        avoid_vpmaddubsw_overflow_fc(batch_size, input_channels, 1, X, X_min, X_max, W[i:i + 1,], W_min, W_max)\n        if i % 2 == 0:\n            W[i, :] = (W[i, :] - W_min) * 2 + W_min\n    b = np.random.randn(output_channels).astype(np.float32)\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('FC', ''), ('FC', 'DNNLOWP_ROWWISE'), ('FC', 'DNNLOWP_ROWWISE_16'), ('Int8FC', 'DNNLOWP_ROWWISE')]\n    for (op_type, engine) in op_engine_list:\n        init_net = core.Net('test_init_net')\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_prepack_weight = engine == 'DNNLOWP_ROWWISE' and prepack_weight\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        X_min = 0 if X.size == 0 else X.min()\n        X_max = 0 if X.size == 0 else X.max()\n        x_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n        if do_prepack_weight:\n            inputs = ['W']\n            if do_dequantize:\n                inputs += ['b']\n            pack = core.CreateOperator('Int8FCPackWeight', inputs, ['W_packed'], in_scale=x_q_param.scale, engine=engine)\n            init_net.Proto().op.extend([pack])\n        fc = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'W_packed' if do_prepack_weight else 'W', 'b'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n        if do_prepack_weight:\n            dnnlowp_utils.add_quantization_param_args(fc, outputs[0][0])\n        net.Proto().op.extend([fc])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        run_conv_or_fc(self, init_net, net, X, W, b, op_type, engine, None, gc, outputs)\n    check_quantized_results_close(outputs)"
        ]
    }
]