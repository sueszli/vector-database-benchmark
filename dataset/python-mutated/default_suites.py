"""Functions for loading the default (built-in) suites for various validation stages.

Each function returns a new suite that is initialized with a list of checks and default conditions.
It is possible to customize these suites by editing the checks and conditions inside it after the suites' creation.
"""
from typing import Callable, Dict, List, Union
from deepchecks.tabular import Suite
from deepchecks.tabular.checks import BoostingOverfit, CalibrationScore, ConflictingLabels, ConfusionMatrixReport, DataDuplicates, DatasetsSizeComparison, DateTrainTestLeakageDuplicates, DateTrainTestLeakageOverlap, FeatureDrift, FeatureFeatureCorrelation, FeatureLabelCorrelation, FeatureLabelCorrelationChange, IdentifierLabelCorrelation, IndexTrainTestLeakage, IsSingleValue, LabelDrift, MixedDataTypes, MixedNulls, ModelInferenceTime, MultivariateDrift, NewCategoryTrainTest, NewLabelTrainTest, OutlierSampleDetection, PercentOfNulls, PredictionDrift, RegressionErrorDistribution, RocReport, SimpleModelComparison, SingleDatasetPerformance, SpecialCharacters, StringLengthOutOfBounds, StringMismatch, StringMismatchComparison, TrainTestPerformance, TrainTestSamplesMix, UnusedFeatures, WeakSegmentsPerformance
from deepchecks.tabular.utils.task_type import TaskType
__all__ = ['data_integrity', 'train_test_validation', 'model_evaluation', 'production_suite', 'full_suite']
from deepchecks.utils.typing import Hashable

def data_integrity(columns: Union[Hashable, List[Hashable]]=None, ignore_columns: Union[Hashable, List[Hashable]]=None, n_top_columns: int=None, n_samples: int=None, random_state: int=42, n_to_show: int=5, **kwargs) -> Suite:
    if False:
        i = 10
        return i + 15
    "Suite for detecting integrity issues within a single dataset.\n\n    List of Checks:\n        .. list-table:: List of Checks\n           :widths: 50 50\n           :header-rows: 1\n\n           * - Check Example\n             - API Reference\n           * - :ref:`tabular__is_single_value`\n             - :class:`~deepchecks.tabular.checks.data_integrity.IsSingleValue`\n           * - :ref:`tabular__special_chars`\n             - :class:`~deepchecks.tabular.checks.data_integrity.SpecialCharacters`\n           * - :ref:`tabular__mixed_nulls`\n             - :class:`~deepchecks.tabular.checks.data_integrity.MixedNulls`\n           * - :ref:`tabular__mixed_data_types`\n             - :class:`~deepchecks.tabular.checks.data_integrity.MixedDataTypes`\n           * - :ref:`tabular__string_mismatch`\n             - :class:`~deepchecks.tabular.checks.data_integrity.StringMismatch`\n           * - :ref:`tabular__data_duplicates`\n             - :class:`~deepchecks.tabular.checks.data_integrity.DataDuplicates`\n           * - :ref:`tabular__string_length_out_of_bounds`\n             - :class:`~deepchecks.tabular.checks.data_integrity.StringLengthOutOfBounds`\n           * - :ref:`tabular__conflicting_labels`\n             - :class:`~deepchecks.tabular.checks.data_integrity.ConflictingLabels`\n           * - :ref:`tabular__outlier_sample_detection`\n             - :class:`~deepchecks.tabular.checks.data_integrity.OutlierSampleDetection`\n           * - :ref:`tabular__feature_label_correlation`\n             - :class:`~deepchecks.tabular.checks.data_integrity.FeatureLabelCorrelation`\n           * - :ref:`tabular__identifier_label_correlation`\n             - :class:`~deepchecks.tabular.checks.data_integrity.IdentifierLabelCorrelation`\n           * - :ref:`tabular__feature_feature_correlation`\n             - :class:`~deepchecks.tabular.checks.data_integrity.FeatureFeatureCorrelation`\n\n    Parameters\n    ----------\n    columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be checked. If None, all columns will be checked except the ones in `ignore_columns`.\n    ignore_columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be ignored. If None, no columns will be ignored.\n    n_top_columns : int , optional\n        number of columns to show ordered by feature importance (date, index, label are first) (check dependent)\n    n_samples : int , default: 1_000_000\n        number of samples to use for checks that sample data. If none, using the default n_samples per check.\n    random_state : int, default: 42\n        random seed for all checks.\n    n_to_show : int , default: 5\n        number of top results to show (check dependent)\n    **kwargs : dict\n        additional arguments to pass to the checks.\n\n    Returns\n    -------\n    Suite\n        A suite for detecting integrity issues within a single dataset.\n\n    Examples\n    --------\n    >>> from deepchecks.tabular.suites import data_integrity\n    >>> suite = data_integrity(columns=['a', 'b', 'c'], n_samples=1_000_000)\n    >>> result = suite.run()\n    >>> result.show()\n\n    See Also\n    --------\n    :ref:`quick_data_integrity`\n    "
    args = locals()
    args.pop('kwargs')
    non_none_args = {k: v for (k, v) in args.items() if v is not None}
    kwargs = {**non_none_args, **kwargs}
    return Suite('Data Integrity Suite', IsSingleValue(**kwargs).add_condition_not_single_value(), SpecialCharacters(**kwargs).add_condition_ratio_of_special_characters_less_or_equal(), MixedNulls(**kwargs).add_condition_different_nulls_less_equal_to(), MixedDataTypes(**kwargs).add_condition_rare_type_ratio_not_in_range(), StringMismatch(**kwargs).add_condition_no_variants(), DataDuplicates(**kwargs).add_condition_ratio_less_or_equal(), StringLengthOutOfBounds(**kwargs).add_condition_ratio_of_outliers_less_or_equal(), ConflictingLabels(**kwargs).add_condition_ratio_of_conflicting_labels_less_or_equal(), OutlierSampleDetection(**kwargs), FeatureLabelCorrelation(**kwargs).add_condition_feature_pps_less_than(), FeatureFeatureCorrelation(**kwargs).add_condition_max_number_of_pairs_above_threshold(), IdentifierLabelCorrelation(**kwargs).add_condition_pps_less_or_equal())

def train_test_validation(columns: Union[Hashable, List[Hashable]]=None, ignore_columns: Union[Hashable, List[Hashable]]=None, n_top_columns: int=None, n_samples: int=None, random_state: int=42, n_to_show: int=5, **kwargs) -> Suite:
    if False:
        while True:
            i = 10
    "Suite for validating correctness of train-test split, including distribution,     leakage and integrity checks.\n\n    List of Checks:\n        .. list-table:: List of Checks\n           :widths: 50 50\n           :header-rows: 1\n\n           * - Check Example\n             - API Reference\n           * - :ref:`tabular__datasets_size_comparison`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.DatasetsSizeComparison`\n           * - :ref:`tabular__new_label`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.NewLabelTrainTest`\n           * - :ref:`tabular__new_category`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.CategoryMismatchTrainTest`\n           * - :ref:`tabular__string_mismatch_comparison`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.StringMismatchComparison`\n           * - :ref:`tabular__date_train_test_validation_leakage_duplicates`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.DateTrainTestLeakageDuplicates`\n           * - :ref:`tabular__date_train_test_validation_leakage_overlap`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.DateTrainTestLeakageOverlap`\n           * - :ref:`tabular__index_leakage`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.IndexTrainTestLeakage`\n           * - :ref:`tabular__train_test_samples_mix`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.TrainTestSamplesMix`\n           * - :ref:`tabular__feature_label_correlation_change`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.FeatureLabelCorrelationChange`\n           * - :ref:`tabular__feature_drift`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.FeatureDrift`\n           * - :ref:`tabular__label_drift`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.LabelDrift`\n           * - :ref:`tabular__multivariate_drift`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.MultivariateDrift`\n\n    Parameters\n    ----------\n    columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be checked. If None, all columns will be checked except the ones in `ignore_columns`.\n    ignore_columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be ignored. If None, no columns will be ignored.\n    n_top_columns : int , optional\n        number of columns to show ordered by feature importance (date, index, label are first) (check dependent)\n    n_samples : int , default: None\n        number of samples to use for checks that sample data. If none, using the default n_samples per check.\n    random_state : int, default: 42\n        random seed for all checkss.\n    n_to_show : int , default: 5\n        number of top results to show (check dependent)\n    **kwargs : dict\n        additional arguments to pass to the checks.\n\n    Returns\n    -------\n    Suite\n        A suite for validating correctness of train-test split, including distribution,         leakage and integrity checks.\n\n    Examples\n    --------\n    >>> from deepchecks.tabular.suites import train_test_validation\n    >>> suite = train_test_validation(columns=['a', 'b', 'c'], n_samples=1_000_000)\n    >>> result = suite.run()\n    >>> result.show()\n\n    See Also\n    --------\n    :ref:`quick_train_test_validation`\n    "
    args = locals()
    args.pop('kwargs')
    non_none_args = {k: v for (k, v) in args.items() if v is not None}
    kwargs = {**non_none_args, **kwargs}
    return Suite('Train Test Validation Suite', DatasetsSizeComparison(**kwargs).add_condition_test_train_size_ratio_greater_than(), NewLabelTrainTest(**kwargs).add_condition_new_labels_number_less_or_equal(), NewCategoryTrainTest(**kwargs).add_condition_new_category_ratio_less_or_equal(), StringMismatchComparison(**kwargs).add_condition_no_new_variants(), DateTrainTestLeakageDuplicates(**kwargs).add_condition_leakage_ratio_less_or_equal(), DateTrainTestLeakageOverlap(**kwargs).add_condition_leakage_ratio_less_or_equal(), IndexTrainTestLeakage(**kwargs).add_condition_ratio_less_or_equal(), TrainTestSamplesMix(**kwargs).add_condition_duplicates_ratio_less_or_equal(), FeatureLabelCorrelationChange(**kwargs).add_condition_feature_pps_difference_less_than().add_condition_feature_pps_in_train_less_than(), FeatureDrift(**kwargs).add_condition_drift_score_less_than(), LabelDrift(**kwargs).add_condition_drift_score_less_than(), MultivariateDrift(**kwargs).add_condition_overall_drift_value_less_than())

def model_evaluation(alternative_scorers: Dict[str, Callable]=None, columns: Union[Hashable, List[Hashable]]=None, ignore_columns: Union[Hashable, List[Hashable]]=None, n_top_columns: int=None, n_samples: int=None, random_state: int=42, n_to_show: int=5, **kwargs) -> Suite:
    if False:
        print('Hello World!')
    "Suite for evaluating the model's performance over different metrics, segments, error analysis, examining        overfitting, comparing to baseline, and more.\n\n    List of Checks:\n        .. list-table:: List of Checks\n           :widths: 50 50\n           :header-rows: 1\n\n           * - Check Example\n             - API Reference\n           * - :ref:`tabular__roc_report`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.RocReport`\n           * - :ref:`tabular__confusion_matrix_report`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.ConfusionMatrixReport`\n           * - :ref:`tabular__weak_segments_performance`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.WeakSegmentPerformance`\n           * - :ref:`tabular__prediction_drift`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.PredictionDrift`\n           * - :ref:`tabular__simple_model_comparison`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.SimpleModelComparison`\n           * - :ref:`tabular__calibration_score`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.CalibrationScore`\n           * - :ref:`tabular__regression_systematic_error`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.RegressionSystematicError`\n           * - :ref:`tabular__regression_error_distribution`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.RegressionErrorDistribution`\n           * - :ref:`tabular__unused_features`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.UnusedFeatures`\n           * - :ref:`tabular__boosting_overfit`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.BoostingOverfit`\n           * - :ref:`tabular__model_inference_time`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.ModelInferenceTime`\n           * - :ref:`tabular__prediction_drift`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.PredictionDrift`\n\n    Parameters\n    ----------\n    alternative_scorers : Dict[str, Callable], default: None\n        An optional dictionary of scorer name to scorer functions.\n        If none given, use default scorers\n    columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be checked. If None, all columns will be checked except the ones in `ignore_columns`.\n    ignore_columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be ignored. If None, no columns will be ignored.\n    n_top_columns : int , optional\n        number of columns to show ordered by feature importance (date, index, label are first) (check dependent)\n    n_samples : int , default: 1_000_000\n        number of samples to use for checks that sample data. If none, use the default n_samples per check.\n    random_state : int, default: 42\n        random seed for all checks.\n    n_to_show : int , default: 5\n        number of top results to show (check dependent)\n    **kwargs : dict\n        additional arguments to pass to the checks.\n\n    Returns\n    -------\n    Suite\n        A suite for evaluating the model's performance.\n\n    Examples\n    --------\n    >>> from deepchecks.tabular.suites import model_evaluation\n    >>> suite = model_evaluation(columns=['a', 'b', 'c'], n_samples=1_000_000)\n    >>> result = suite.run()\n    >>> result.show()\n\n    See Also\n    --------\n    :ref:`quick_full_suite`\n    "
    args = locals()
    args.pop('kwargs')
    non_none_args = {k: v for (k, v) in args.items() if v is not None}
    kwargs = {**non_none_args, **kwargs}
    return Suite('Model Evaluation Suite', TrainTestPerformance(**kwargs).add_condition_train_test_relative_degradation_less_than(), RocReport(**kwargs).add_condition_auc_greater_than(), ConfusionMatrixReport(**kwargs), PredictionDrift(**kwargs).add_condition_drift_score_less_than(), SimpleModelComparison(**kwargs).add_condition_gain_greater_than(), WeakSegmentsPerformance(**kwargs).add_condition_segments_relative_performance_greater_than(), CalibrationScore(**kwargs), RegressionErrorDistribution(**kwargs).add_condition_kurtosis_greater_than().add_condition_systematic_error_ratio_to_rmse_less_than(), UnusedFeatures(**kwargs).add_condition_number_of_high_variance_unused_features_less_or_equal(), BoostingOverfit(**kwargs).add_condition_test_score_percent_decline_less_than(), ModelInferenceTime(**kwargs).add_condition_inference_time_less_than())

def production_suite(task_type: str=None, is_comparative: bool=True, alternative_scorers: Dict[str, Callable]=None, columns: Union[Hashable, List[Hashable]]=None, ignore_columns: Union[Hashable, List[Hashable]]=None, n_top_columns: int=None, n_samples: int=None, random_state: int=42, n_to_show: int=5, **kwargs) -> Suite:
    if False:
        while True:
            i = 10
    "Suite for testing the model in production.\n\n    The suite contains checks for evaluating the model's performance. Checks for detecting drift and checks for data\n    integrity issues that may occur in production.\n\n    List of Checks (exact checks depend on the task type and the is_comparative flag):\n        .. list-table:: List of Checks\n           :widths: 50 50\n           :header-rows: 1\n\n           * - Check Example\n             - API Reference\n           * - :ref:`tabular__roc_report`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.RocReport`\n           * - :ref:`tabular__confusion_matrix_report`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.ConfusionMatrixReport`\n           * - :ref:`tabular__weak_segments_performance`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.WeakSegmentPerformance`\n           * - :ref:`tabular__regression_error_distribution`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.RegressionErrorDistribution`\n           * - :ref:`tabular__string_mismatch_comparison`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.StringMismatchComparison`\n           * - :ref:`tabular__feature_label_correlation_change`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.FeatureLabelCorrelationChange`\n           * - :ref:`tabular__feature_drift`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.FeatureDrift`\n           * - :ref:`tabular__label_drift`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.LabelDrift`\n           * - :ref:`tabular__multivariate_drift`\n             - :class:`~deepchecks.tabular.checks.train_test_validation.MultivariateDrift`\n           * - :ref:`tabular__prediction_drift`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.PredictionDrift`\n           * - :ref:`tabular__prediction_drift`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.PredictionDrift`\n           * - :ref:`tabular__string_mismatch`\n             - :class:`~deepchecks.tabular.checks.data_integrity.StringMismatch`\n           * - :ref:`tabular__feature_label_correlation`\n             - :class:`~deepchecks.tabular.checks.data_integrity.FeatureLabelCorrelation`\n           * - :ref:`tabular__feature_feature_correlation`\n             - :class:`~deepchecks.tabular.checks.data_integrity.FeatureFeatureCorrelation`\n           * - :ref:`tabular__single_dataset_performance`\n             - :class:`~deepchecks.tabular.checks.model_evaluation.SingleDatasetPerformance`\n\n    Parameters\n    ----------\n    task_type : str, default: None\n        The type of the task. Must be one of 'binary', 'multiclass' or 'regression'. If not given, both checks for\n        classification and regression will be added to the suite.\n    is_comparative : bool, default: True\n        Whether to add the checks comparing the production data to some reference data, or if False, to add the\n        checks inspecting the production data only.\n    alternative_scorers : Dict[str, Callable], default: None\n        An optional dictionary of scorer name to scorer functions.\n        If none given, use default scorers\n    columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be checked. If None, all columns will be checked except the ones in `ignore_columns`.\n    ignore_columns : Union[Hashable, List[Hashable]] , default: None\n        The columns to be ignored. If None, no columns will be ignored.\n    n_top_columns : int , optional\n        number of columns to show ordered by feature importance (date, index, label are first) (check dependent)\n    n_samples : int , default: 1_000_000\n        number of samples to use for checks that sample data. If none, use the default n_samples per check.\n    random_state : int, default: 42\n        random seed for all checks.\n    n_to_show : int , default: 5\n        number of top results to show (check dependent)\n    **kwargs : dict\n        additional arguments to pass to the checks.\n\n    Returns\n    -------\n    Suite\n        A suite for evaluating the model's performance.\n\n    Examples\n    --------\n    >>> from deepchecks.tabular.suites import production_suite\n    >>> suite = production_suite(task_type='binary', n_samples=10_000)\n    >>> result = suite.run()\n    >>> result.show()\n\n    See Also\n    --------\n    :ref:`quick_full_suite`\n    "
    args = locals()
    args.pop('kwargs')
    non_none_args = {k: v for (k, v) in args.items() if v is not None}
    kwargs = {**non_none_args, **kwargs}
    checks = [WeakSegmentsPerformance(**kwargs).add_condition_segments_relative_performance_greater_than(), PercentOfNulls(**kwargs)]
    regression_checks = [RegressionErrorDistribution(**kwargs).add_condition_kurtosis_greater_than()]
    classification_checks = [ConfusionMatrixReport(**kwargs), RocReport(**kwargs).add_condition_auc_greater_than()]
    if task_type is None:
        checks.extend(classification_checks)
        checks.extend(regression_checks)
    elif task_type == TaskType.REGRESSION.value:
        checks.extend(regression_checks)
    else:
        checks.extend(classification_checks)
    if is_comparative:
        checks.append(StringMismatchComparison(**kwargs).add_condition_no_new_variants())
        checks.append(FeatureLabelCorrelationChange(**kwargs).add_condition_feature_pps_difference_less_than())
        checks.append(FeatureDrift(**kwargs).add_condition_drift_score_less_than())
        checks.append(MultivariateDrift(**kwargs).add_condition_overall_drift_value_less_than())
        checks.append(LabelDrift(ignore_na=True, **kwargs).add_condition_drift_score_less_than())
        checks.append(PredictionDrift(**kwargs).add_condition_drift_score_less_than())
        checks.append(TrainTestPerformance(**kwargs).add_condition_train_test_relative_degradation_less_than())
        checks.append(NewCategoryTrainTest(**kwargs).add_condition_new_category_ratio_less_or_equal())
    else:
        checks.append(StringMismatch(**kwargs).add_condition_no_variants())
        checks.append(FeatureLabelCorrelation(**kwargs).add_condition_feature_pps_less_than())
        checks.append(FeatureFeatureCorrelation(**kwargs).add_condition_max_number_of_pairs_above_threshold())
        checks.append(SingleDatasetPerformance(**kwargs))
    return Suite('Production Suite', *checks)

def full_suite(**kwargs) -> Suite:
    if False:
        print('Hello World!')
    'Create a suite that includes many of the implemented checks, for a quick overview of your model and data.'
    return Suite('Full Suite', model_evaluation(**kwargs), train_test_validation(**kwargs), data_integrity(**kwargs))