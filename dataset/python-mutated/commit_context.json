[
    {
        "func_name": "queue_comment_task_if_needed",
        "original": "def queue_comment_task_if_needed(commit: Commit, group_owner: GroupOwner, repo: Repository, installation: IntegrationInstallation):\n    from sentry.tasks.integrations.github.pr_comment import github_comment_workflow\n    logger.info('github.pr_comment.queue_comment_check', extra={'organization_id': commit.organization_id, 'merge_commit_sha': commit.key})\n    try:\n        response = installation.get_client().get_pullrequest_from_commit(repo=repo.name, sha=commit.key)\n    except Exception as e:\n        sentry_sdk.capture_exception(e)\n        return\n    if not isinstance(response, list) or len(response) != 1:\n        if len(response) > 1:\n            logger.info('github.pr_comment.queue_comment_check.commit_not_in_default_branch', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    merge_commit_sha = response[0]['merge_commit_sha']\n    pr_query = PullRequest.objects.filter(organization_id=commit.organization_id, repository_id=commit.repository_id, merge_commit_sha=merge_commit_sha)\n    if not pr_query.exists():\n        logger.info('github.pr_comment.queue_comment_check.missing_pr', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    pr = pr_query.first()\n    if pr.date_added >= datetime.now(tz=timezone.utc) - timedelta(days=PR_COMMENT_WINDOW) and (not pr.pullrequestcomment_set.exists() or group_owner.group_id not in pr.pullrequestcomment_set.get().group_ids):\n        lock = locks.get(DEBOUNCE_PR_COMMENT_LOCK_KEY(pr.id), duration=10, name='queue_comment_task')\n        with lock.acquire():\n            cache_key = DEBOUNCE_PR_COMMENT_CACHE_KEY(pullrequest_id=pr.id)\n            if cache.get(cache_key) is not None:\n                return\n            PullRequestCommit.objects.get_or_create(commit=commit, pull_request=pr)\n            logger.info('github.pr_comment.queue_comment_workflow', extra={'pullrequest_id': pr.id, 'project_id': group_owner.project_id})\n            cache.set(cache_key, True, PR_COMMENT_TASK_TTL)\n            github_comment_workflow.delay(pullrequest_id=pr.id, project_id=group_owner.project_id)",
        "mutated": [
            "def queue_comment_task_if_needed(commit: Commit, group_owner: GroupOwner, repo: Repository, installation: IntegrationInstallation):\n    if False:\n        i = 10\n    from sentry.tasks.integrations.github.pr_comment import github_comment_workflow\n    logger.info('github.pr_comment.queue_comment_check', extra={'organization_id': commit.organization_id, 'merge_commit_sha': commit.key})\n    try:\n        response = installation.get_client().get_pullrequest_from_commit(repo=repo.name, sha=commit.key)\n    except Exception as e:\n        sentry_sdk.capture_exception(e)\n        return\n    if not isinstance(response, list) or len(response) != 1:\n        if len(response) > 1:\n            logger.info('github.pr_comment.queue_comment_check.commit_not_in_default_branch', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    merge_commit_sha = response[0]['merge_commit_sha']\n    pr_query = PullRequest.objects.filter(organization_id=commit.organization_id, repository_id=commit.repository_id, merge_commit_sha=merge_commit_sha)\n    if not pr_query.exists():\n        logger.info('github.pr_comment.queue_comment_check.missing_pr', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    pr = pr_query.first()\n    if pr.date_added >= datetime.now(tz=timezone.utc) - timedelta(days=PR_COMMENT_WINDOW) and (not pr.pullrequestcomment_set.exists() or group_owner.group_id not in pr.pullrequestcomment_set.get().group_ids):\n        lock = locks.get(DEBOUNCE_PR_COMMENT_LOCK_KEY(pr.id), duration=10, name='queue_comment_task')\n        with lock.acquire():\n            cache_key = DEBOUNCE_PR_COMMENT_CACHE_KEY(pullrequest_id=pr.id)\n            if cache.get(cache_key) is not None:\n                return\n            PullRequestCommit.objects.get_or_create(commit=commit, pull_request=pr)\n            logger.info('github.pr_comment.queue_comment_workflow', extra={'pullrequest_id': pr.id, 'project_id': group_owner.project_id})\n            cache.set(cache_key, True, PR_COMMENT_TASK_TTL)\n            github_comment_workflow.delay(pullrequest_id=pr.id, project_id=group_owner.project_id)",
            "def queue_comment_task_if_needed(commit: Commit, group_owner: GroupOwner, repo: Repository, installation: IntegrationInstallation):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from sentry.tasks.integrations.github.pr_comment import github_comment_workflow\n    logger.info('github.pr_comment.queue_comment_check', extra={'organization_id': commit.organization_id, 'merge_commit_sha': commit.key})\n    try:\n        response = installation.get_client().get_pullrequest_from_commit(repo=repo.name, sha=commit.key)\n    except Exception as e:\n        sentry_sdk.capture_exception(e)\n        return\n    if not isinstance(response, list) or len(response) != 1:\n        if len(response) > 1:\n            logger.info('github.pr_comment.queue_comment_check.commit_not_in_default_branch', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    merge_commit_sha = response[0]['merge_commit_sha']\n    pr_query = PullRequest.objects.filter(organization_id=commit.organization_id, repository_id=commit.repository_id, merge_commit_sha=merge_commit_sha)\n    if not pr_query.exists():\n        logger.info('github.pr_comment.queue_comment_check.missing_pr', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    pr = pr_query.first()\n    if pr.date_added >= datetime.now(tz=timezone.utc) - timedelta(days=PR_COMMENT_WINDOW) and (not pr.pullrequestcomment_set.exists() or group_owner.group_id not in pr.pullrequestcomment_set.get().group_ids):\n        lock = locks.get(DEBOUNCE_PR_COMMENT_LOCK_KEY(pr.id), duration=10, name='queue_comment_task')\n        with lock.acquire():\n            cache_key = DEBOUNCE_PR_COMMENT_CACHE_KEY(pullrequest_id=pr.id)\n            if cache.get(cache_key) is not None:\n                return\n            PullRequestCommit.objects.get_or_create(commit=commit, pull_request=pr)\n            logger.info('github.pr_comment.queue_comment_workflow', extra={'pullrequest_id': pr.id, 'project_id': group_owner.project_id})\n            cache.set(cache_key, True, PR_COMMENT_TASK_TTL)\n            github_comment_workflow.delay(pullrequest_id=pr.id, project_id=group_owner.project_id)",
            "def queue_comment_task_if_needed(commit: Commit, group_owner: GroupOwner, repo: Repository, installation: IntegrationInstallation):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from sentry.tasks.integrations.github.pr_comment import github_comment_workflow\n    logger.info('github.pr_comment.queue_comment_check', extra={'organization_id': commit.organization_id, 'merge_commit_sha': commit.key})\n    try:\n        response = installation.get_client().get_pullrequest_from_commit(repo=repo.name, sha=commit.key)\n    except Exception as e:\n        sentry_sdk.capture_exception(e)\n        return\n    if not isinstance(response, list) or len(response) != 1:\n        if len(response) > 1:\n            logger.info('github.pr_comment.queue_comment_check.commit_not_in_default_branch', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    merge_commit_sha = response[0]['merge_commit_sha']\n    pr_query = PullRequest.objects.filter(organization_id=commit.organization_id, repository_id=commit.repository_id, merge_commit_sha=merge_commit_sha)\n    if not pr_query.exists():\n        logger.info('github.pr_comment.queue_comment_check.missing_pr', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    pr = pr_query.first()\n    if pr.date_added >= datetime.now(tz=timezone.utc) - timedelta(days=PR_COMMENT_WINDOW) and (not pr.pullrequestcomment_set.exists() or group_owner.group_id not in pr.pullrequestcomment_set.get().group_ids):\n        lock = locks.get(DEBOUNCE_PR_COMMENT_LOCK_KEY(pr.id), duration=10, name='queue_comment_task')\n        with lock.acquire():\n            cache_key = DEBOUNCE_PR_COMMENT_CACHE_KEY(pullrequest_id=pr.id)\n            if cache.get(cache_key) is not None:\n                return\n            PullRequestCommit.objects.get_or_create(commit=commit, pull_request=pr)\n            logger.info('github.pr_comment.queue_comment_workflow', extra={'pullrequest_id': pr.id, 'project_id': group_owner.project_id})\n            cache.set(cache_key, True, PR_COMMENT_TASK_TTL)\n            github_comment_workflow.delay(pullrequest_id=pr.id, project_id=group_owner.project_id)",
            "def queue_comment_task_if_needed(commit: Commit, group_owner: GroupOwner, repo: Repository, installation: IntegrationInstallation):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from sentry.tasks.integrations.github.pr_comment import github_comment_workflow\n    logger.info('github.pr_comment.queue_comment_check', extra={'organization_id': commit.organization_id, 'merge_commit_sha': commit.key})\n    try:\n        response = installation.get_client().get_pullrequest_from_commit(repo=repo.name, sha=commit.key)\n    except Exception as e:\n        sentry_sdk.capture_exception(e)\n        return\n    if not isinstance(response, list) or len(response) != 1:\n        if len(response) > 1:\n            logger.info('github.pr_comment.queue_comment_check.commit_not_in_default_branch', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    merge_commit_sha = response[0]['merge_commit_sha']\n    pr_query = PullRequest.objects.filter(organization_id=commit.organization_id, repository_id=commit.repository_id, merge_commit_sha=merge_commit_sha)\n    if not pr_query.exists():\n        logger.info('github.pr_comment.queue_comment_check.missing_pr', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    pr = pr_query.first()\n    if pr.date_added >= datetime.now(tz=timezone.utc) - timedelta(days=PR_COMMENT_WINDOW) and (not pr.pullrequestcomment_set.exists() or group_owner.group_id not in pr.pullrequestcomment_set.get().group_ids):\n        lock = locks.get(DEBOUNCE_PR_COMMENT_LOCK_KEY(pr.id), duration=10, name='queue_comment_task')\n        with lock.acquire():\n            cache_key = DEBOUNCE_PR_COMMENT_CACHE_KEY(pullrequest_id=pr.id)\n            if cache.get(cache_key) is not None:\n                return\n            PullRequestCommit.objects.get_or_create(commit=commit, pull_request=pr)\n            logger.info('github.pr_comment.queue_comment_workflow', extra={'pullrequest_id': pr.id, 'project_id': group_owner.project_id})\n            cache.set(cache_key, True, PR_COMMENT_TASK_TTL)\n            github_comment_workflow.delay(pullrequest_id=pr.id, project_id=group_owner.project_id)",
            "def queue_comment_task_if_needed(commit: Commit, group_owner: GroupOwner, repo: Repository, installation: IntegrationInstallation):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from sentry.tasks.integrations.github.pr_comment import github_comment_workflow\n    logger.info('github.pr_comment.queue_comment_check', extra={'organization_id': commit.organization_id, 'merge_commit_sha': commit.key})\n    try:\n        response = installation.get_client().get_pullrequest_from_commit(repo=repo.name, sha=commit.key)\n    except Exception as e:\n        sentry_sdk.capture_exception(e)\n        return\n    if not isinstance(response, list) or len(response) != 1:\n        if len(response) > 1:\n            logger.info('github.pr_comment.queue_comment_check.commit_not_in_default_branch', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    merge_commit_sha = response[0]['merge_commit_sha']\n    pr_query = PullRequest.objects.filter(organization_id=commit.organization_id, repository_id=commit.repository_id, merge_commit_sha=merge_commit_sha)\n    if not pr_query.exists():\n        logger.info('github.pr_comment.queue_comment_check.missing_pr', extra={'organization_id': commit.organization_id, 'repository_id': repo.id, 'commit_sha': commit.key})\n        return\n    pr = pr_query.first()\n    if pr.date_added >= datetime.now(tz=timezone.utc) - timedelta(days=PR_COMMENT_WINDOW) and (not pr.pullrequestcomment_set.exists() or group_owner.group_id not in pr.pullrequestcomment_set.get().group_ids):\n        lock = locks.get(DEBOUNCE_PR_COMMENT_LOCK_KEY(pr.id), duration=10, name='queue_comment_task')\n        with lock.acquire():\n            cache_key = DEBOUNCE_PR_COMMENT_CACHE_KEY(pullrequest_id=pr.id)\n            if cache.get(cache_key) is not None:\n                return\n            PullRequestCommit.objects.get_or_create(commit=commit, pull_request=pr)\n            logger.info('github.pr_comment.queue_comment_workflow', extra={'pullrequest_id': pr.id, 'project_id': group_owner.project_id})\n            cache.set(cache_key, True, PR_COMMENT_TASK_TTL)\n            github_comment_workflow.delay(pullrequest_id=pr.id, project_id=group_owner.project_id)"
        ]
    },
    {
        "func_name": "process_commit_context",
        "original": "@instrumented_task(name='sentry.tasks.process_commit_context', queue='group_owners.process_commit_context', autoretry_for=(ApiError,), max_retries=5, retry_backoff=True, retry_backoff_max=60 * 60 * 3, retry_jitter=False, silo_mode=SiloMode.REGION, bind=True)\ndef process_commit_context(self, event_id, event_platform, event_frames, group_id, project_id, sdk_name=None, **kwargs):\n    \"\"\"\n    For a given event, look at the first in_app frame, and if we can find who modified the line, we can then update who is assigned to the issue.\n    \"\"\"\n    lock = locks.get(f'process-commit-context:{group_id}', duration=10, name='process_commit_context')\n    try:\n        with lock.acquire():\n            metrics.incr('sentry.tasks.process_commit_context.start')\n            cache_key = DEBOUNCE_CACHE_KEY(group_id)\n            set_current_event_project(project_id)\n            project = Project.objects.get_from_cache(id=project_id)\n            set_tag('organization.slug', project.organization.slug)\n            owners = GroupOwner.objects.filter(group_id=group_id, project=project, organization_id=project.organization_id, type=GroupOwnerType.SUSPECT_COMMIT.value)\n            basic_logging_details = {'event': event_id, 'group': group_id, 'organization': project.organization_id}\n            to_be_deleted = owners.filter(date_added__lte=timezone.now() - PREFERRED_GROUP_OWNER_AGE)\n            if len(to_be_deleted):\n                for record in to_be_deleted:\n                    record.delete()\n            current_owners = owners.filter(date_added__gte=timezone.now() - PREFERRED_GROUP_OWNER_AGE).order_by('-date_added')\n            if len(current_owners) >= PREFERRED_GROUP_OWNERS:\n                cache_duration = timezone.now() - current_owners[0].date_added\n                cache_duration = cache_duration if cache_duration < PREFERRED_GROUP_OWNER_AGE else PREFERRED_GROUP_OWNER_AGE\n                cache.set(cache_key, True, cache_duration.total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'maxed_owners_none_old'})\n                logger.info('process_commit_context.maxed_owners', extra={**basic_logging_details, 'reason': 'maxed_owners_none_old'})\n                return\n            code_mappings = get_sorted_code_mapping_configs(project)\n            frames = event_frames or []\n            munged = munged_filename_and_frames(event_platform, frames, 'munged_filename', sdk_name)\n            if munged:\n                frames = munged[1]\n            in_app_frames = [f for f in frames if f and f.get('in_app', False)][::-1]\n            frame = next(iter(in_app_frames), None)\n            if not frame:\n                cache.set(cache_key, True, timedelta(days=1).total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_find_in_app_stacktrace_frame'})\n                logger.info('process_commit_context.find_frame', extra={**basic_logging_details, 'reason': 'could_not_find_in_app_stacktrace_frame', 'fallback': True})\n                process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                if features.has('organizations:suspect-commits-all-frames', project.organization):\n                    analytics.record('integrations.failed_to_fetch_commit_context_all_frames', organization_id=project.organization_id, project_id=project_id, group_id=basic_logging_details['group'], event_id=basic_logging_details['event'], num_frames=0, num_successfully_mapped_frames=0, reason='could_not_find_in_app_stacktrace_frame')\n                return\n            if features.has('organizations:suspect-commits-all-frames', project.organization):\n                metrics.incr('tasks.process_commit_context_all_frames.start')\n                blame = None\n                installation = None\n                try:\n                    (blame, installation) = find_commit_context_for_event_all_frames(code_mappings=code_mappings, frames=in_app_frames, organization_id=project.organization_id, project_id=project_id, extra=basic_logging_details)\n                except ApiError:\n                    logger.info('process_commit_context_all_frames.retry', extra={**basic_logging_details, 'retry_count': self.request.retries})\n                    metrics.incr('tasks.process_commit_context_all_frames.retry')\n                    self.retry()\n                if not blame or not installation:\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                selected_code_mapping = blame.code_mapping\n                commit = get_or_create_commit_from_blame(blame, organization_id=project.organization_id, extra=basic_logging_details)\n            else:\n                (found_contexts, installation) = find_commit_context_for_event(code_mappings=code_mappings, frame=frame, extra={**basic_logging_details})\n                if not len(found_contexts):\n                    cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n                    metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_fetch_commit_context'})\n                    logger.info('process_commit_context.find_commit_context', extra={**basic_logging_details, 'reason': 'could_not_fetch_commit_context', 'code_mappings_count': len(code_mappings), 'fallback': True})\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                commit = None\n                new_commit = None\n                selected_code_mapping = None\n                for (commit_context, code_mapping) in found_contexts:\n                    try:\n                        commit = Commit.objects.get(repository_id=code_mapping.repository_id, key=commit_context.get('commitId'))\n                        if commit.message == '':\n                            commit.message = commit_context.get('commitMessage')\n                            commit.save()\n                        selected_code_mapping = code_mapping\n                        break\n                    except Commit.DoesNotExist:\n                        if not new_commit and commit_context.get('committedDate'):\n                            new_commit = {'context': commit_context, 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id}\n                        logger.info('process_commit_context.no_commit_in_sentry', extra={**basic_logging_details, 'sha': commit_context.get('commitId'), 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id, 'reason': 'commit_sha_does_not_exist_in_sentry'})\n                if not commit:\n                    if new_commit:\n                        context = new_commit['context']\n                        (commit_author, _) = CommitAuthor.objects.get_or_create(organization_id=project.organization_id, email=context.get('commitAuthorEmail'), defaults={'name': context.get('commitAuthorName')})\n                        commit = Commit.objects.create(organization_id=project.organization_id, repository_id=new_commit['repository_id'], key=context.get('commitId'), date_added=context.get('committedDate'), author=commit_author, message=context.get('commitMessage'))\n                        logger.info('process_commit_context.added_commit_to_sentry_commit', extra={**basic_logging_details, 'sha': new_commit.get('commitId'), 'repository_id': new_commit['repository_id'], 'code_mapping_id': new_commit['code_mapping_id'], 'reason': 'commit_sha_does_not_exist_in_sentry_for_all_code_mappings'})\n                    else:\n                        metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'commit_sha_does_not_exist_in_sentry'})\n            authors = list(CommitAuthor.objects.get_many_from_cache([commit.author_id]))\n            author_to_user = get_users_for_authors(commit.organization_id, authors)\n            (group_owner, created) = GroupOwner.objects.update_or_create(group_id=group_id, type=GroupOwnerType.SUSPECT_COMMIT.value, user_id=author_to_user.get(str(commit.author_id), {}).get('id'), project=project, organization_id=project.organization_id, context={'commitId': commit.id}, defaults={'date_added': timezone.now()})\n            if OrganizationOption.objects.get_value(organization=project.organization, key='sentry:github_pr_bot', default=True):\n                logger.info('github.pr_comment', extra={'organization_id': project.organization_id})\n                repo = Repository.objects.filter(id=commit.repository_id)\n                if installation is not None and repo.exists() and (repo.get().provider == 'integrations:github'):\n                    queue_comment_task_if_needed(commit, group_owner, repo.get(), installation)\n                else:\n                    logger.info('github.pr_comment.incorrect_repo_config', extra={'organization_id': project.organization_id})\n            if created:\n                if len(current_owners) + 1 > PREFERRED_GROUP_OWNERS:\n                    try:\n                        owner = current_owners[0]\n                    except IndexError:\n                        pass\n                    else:\n                        owner.delete()\n            cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n            logger.info('process_commit_context.success', extra={**basic_logging_details, 'group_owner_id': group_owner.id, **({'repository_id': selected_code_mapping.repository_id, 'selected_code_mapping': selected_code_mapping.id} if selected_code_mapping is not None else {}), 'reason': 'created' if created else 'updated'})\n            metrics.incr('sentry.tasks.process_commit_context.success', tags={'detail': f\"successfully {('created' if created else 'updated')}\"})\n            analytics.record('groupowner.assignment', organization_id=project.organization_id, project_id=project.id, group_id=group_id, new_assignment=created)\n    except UnableToAcquireLock:\n        pass\n    except MaxRetriesExceededError:\n        metrics.incr('tasks.process_commit_context.max_retries_exceeded')\n        logger.info('process_commit_context.max_retries_exceeded', extra={**basic_logging_details, 'reason': 'max_retries_exceeded'})\n        process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)",
        "mutated": [
            "@instrumented_task(name='sentry.tasks.process_commit_context', queue='group_owners.process_commit_context', autoretry_for=(ApiError,), max_retries=5, retry_backoff=True, retry_backoff_max=60 * 60 * 3, retry_jitter=False, silo_mode=SiloMode.REGION, bind=True)\ndef process_commit_context(self, event_id, event_platform, event_frames, group_id, project_id, sdk_name=None, **kwargs):\n    if False:\n        i = 10\n    '\\n    For a given event, look at the first in_app frame, and if we can find who modified the line, we can then update who is assigned to the issue.\\n    '\n    lock = locks.get(f'process-commit-context:{group_id}', duration=10, name='process_commit_context')\n    try:\n        with lock.acquire():\n            metrics.incr('sentry.tasks.process_commit_context.start')\n            cache_key = DEBOUNCE_CACHE_KEY(group_id)\n            set_current_event_project(project_id)\n            project = Project.objects.get_from_cache(id=project_id)\n            set_tag('organization.slug', project.organization.slug)\n            owners = GroupOwner.objects.filter(group_id=group_id, project=project, organization_id=project.organization_id, type=GroupOwnerType.SUSPECT_COMMIT.value)\n            basic_logging_details = {'event': event_id, 'group': group_id, 'organization': project.organization_id}\n            to_be_deleted = owners.filter(date_added__lte=timezone.now() - PREFERRED_GROUP_OWNER_AGE)\n            if len(to_be_deleted):\n                for record in to_be_deleted:\n                    record.delete()\n            current_owners = owners.filter(date_added__gte=timezone.now() - PREFERRED_GROUP_OWNER_AGE).order_by('-date_added')\n            if len(current_owners) >= PREFERRED_GROUP_OWNERS:\n                cache_duration = timezone.now() - current_owners[0].date_added\n                cache_duration = cache_duration if cache_duration < PREFERRED_GROUP_OWNER_AGE else PREFERRED_GROUP_OWNER_AGE\n                cache.set(cache_key, True, cache_duration.total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'maxed_owners_none_old'})\n                logger.info('process_commit_context.maxed_owners', extra={**basic_logging_details, 'reason': 'maxed_owners_none_old'})\n                return\n            code_mappings = get_sorted_code_mapping_configs(project)\n            frames = event_frames or []\n            munged = munged_filename_and_frames(event_platform, frames, 'munged_filename', sdk_name)\n            if munged:\n                frames = munged[1]\n            in_app_frames = [f for f in frames if f and f.get('in_app', False)][::-1]\n            frame = next(iter(in_app_frames), None)\n            if not frame:\n                cache.set(cache_key, True, timedelta(days=1).total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_find_in_app_stacktrace_frame'})\n                logger.info('process_commit_context.find_frame', extra={**basic_logging_details, 'reason': 'could_not_find_in_app_stacktrace_frame', 'fallback': True})\n                process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                if features.has('organizations:suspect-commits-all-frames', project.organization):\n                    analytics.record('integrations.failed_to_fetch_commit_context_all_frames', organization_id=project.organization_id, project_id=project_id, group_id=basic_logging_details['group'], event_id=basic_logging_details['event'], num_frames=0, num_successfully_mapped_frames=0, reason='could_not_find_in_app_stacktrace_frame')\n                return\n            if features.has('organizations:suspect-commits-all-frames', project.organization):\n                metrics.incr('tasks.process_commit_context_all_frames.start')\n                blame = None\n                installation = None\n                try:\n                    (blame, installation) = find_commit_context_for_event_all_frames(code_mappings=code_mappings, frames=in_app_frames, organization_id=project.organization_id, project_id=project_id, extra=basic_logging_details)\n                except ApiError:\n                    logger.info('process_commit_context_all_frames.retry', extra={**basic_logging_details, 'retry_count': self.request.retries})\n                    metrics.incr('tasks.process_commit_context_all_frames.retry')\n                    self.retry()\n                if not blame or not installation:\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                selected_code_mapping = blame.code_mapping\n                commit = get_or_create_commit_from_blame(blame, organization_id=project.organization_id, extra=basic_logging_details)\n            else:\n                (found_contexts, installation) = find_commit_context_for_event(code_mappings=code_mappings, frame=frame, extra={**basic_logging_details})\n                if not len(found_contexts):\n                    cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n                    metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_fetch_commit_context'})\n                    logger.info('process_commit_context.find_commit_context', extra={**basic_logging_details, 'reason': 'could_not_fetch_commit_context', 'code_mappings_count': len(code_mappings), 'fallback': True})\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                commit = None\n                new_commit = None\n                selected_code_mapping = None\n                for (commit_context, code_mapping) in found_contexts:\n                    try:\n                        commit = Commit.objects.get(repository_id=code_mapping.repository_id, key=commit_context.get('commitId'))\n                        if commit.message == '':\n                            commit.message = commit_context.get('commitMessage')\n                            commit.save()\n                        selected_code_mapping = code_mapping\n                        break\n                    except Commit.DoesNotExist:\n                        if not new_commit and commit_context.get('committedDate'):\n                            new_commit = {'context': commit_context, 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id}\n                        logger.info('process_commit_context.no_commit_in_sentry', extra={**basic_logging_details, 'sha': commit_context.get('commitId'), 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id, 'reason': 'commit_sha_does_not_exist_in_sentry'})\n                if not commit:\n                    if new_commit:\n                        context = new_commit['context']\n                        (commit_author, _) = CommitAuthor.objects.get_or_create(organization_id=project.organization_id, email=context.get('commitAuthorEmail'), defaults={'name': context.get('commitAuthorName')})\n                        commit = Commit.objects.create(organization_id=project.organization_id, repository_id=new_commit['repository_id'], key=context.get('commitId'), date_added=context.get('committedDate'), author=commit_author, message=context.get('commitMessage'))\n                        logger.info('process_commit_context.added_commit_to_sentry_commit', extra={**basic_logging_details, 'sha': new_commit.get('commitId'), 'repository_id': new_commit['repository_id'], 'code_mapping_id': new_commit['code_mapping_id'], 'reason': 'commit_sha_does_not_exist_in_sentry_for_all_code_mappings'})\n                    else:\n                        metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'commit_sha_does_not_exist_in_sentry'})\n            authors = list(CommitAuthor.objects.get_many_from_cache([commit.author_id]))\n            author_to_user = get_users_for_authors(commit.organization_id, authors)\n            (group_owner, created) = GroupOwner.objects.update_or_create(group_id=group_id, type=GroupOwnerType.SUSPECT_COMMIT.value, user_id=author_to_user.get(str(commit.author_id), {}).get('id'), project=project, organization_id=project.organization_id, context={'commitId': commit.id}, defaults={'date_added': timezone.now()})\n            if OrganizationOption.objects.get_value(organization=project.organization, key='sentry:github_pr_bot', default=True):\n                logger.info('github.pr_comment', extra={'organization_id': project.organization_id})\n                repo = Repository.objects.filter(id=commit.repository_id)\n                if installation is not None and repo.exists() and (repo.get().provider == 'integrations:github'):\n                    queue_comment_task_if_needed(commit, group_owner, repo.get(), installation)\n                else:\n                    logger.info('github.pr_comment.incorrect_repo_config', extra={'organization_id': project.organization_id})\n            if created:\n                if len(current_owners) + 1 > PREFERRED_GROUP_OWNERS:\n                    try:\n                        owner = current_owners[0]\n                    except IndexError:\n                        pass\n                    else:\n                        owner.delete()\n            cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n            logger.info('process_commit_context.success', extra={**basic_logging_details, 'group_owner_id': group_owner.id, **({'repository_id': selected_code_mapping.repository_id, 'selected_code_mapping': selected_code_mapping.id} if selected_code_mapping is not None else {}), 'reason': 'created' if created else 'updated'})\n            metrics.incr('sentry.tasks.process_commit_context.success', tags={'detail': f\"successfully {('created' if created else 'updated')}\"})\n            analytics.record('groupowner.assignment', organization_id=project.organization_id, project_id=project.id, group_id=group_id, new_assignment=created)\n    except UnableToAcquireLock:\n        pass\n    except MaxRetriesExceededError:\n        metrics.incr('tasks.process_commit_context.max_retries_exceeded')\n        logger.info('process_commit_context.max_retries_exceeded', extra={**basic_logging_details, 'reason': 'max_retries_exceeded'})\n        process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)",
            "@instrumented_task(name='sentry.tasks.process_commit_context', queue='group_owners.process_commit_context', autoretry_for=(ApiError,), max_retries=5, retry_backoff=True, retry_backoff_max=60 * 60 * 3, retry_jitter=False, silo_mode=SiloMode.REGION, bind=True)\ndef process_commit_context(self, event_id, event_platform, event_frames, group_id, project_id, sdk_name=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    For a given event, look at the first in_app frame, and if we can find who modified the line, we can then update who is assigned to the issue.\\n    '\n    lock = locks.get(f'process-commit-context:{group_id}', duration=10, name='process_commit_context')\n    try:\n        with lock.acquire():\n            metrics.incr('sentry.tasks.process_commit_context.start')\n            cache_key = DEBOUNCE_CACHE_KEY(group_id)\n            set_current_event_project(project_id)\n            project = Project.objects.get_from_cache(id=project_id)\n            set_tag('organization.slug', project.organization.slug)\n            owners = GroupOwner.objects.filter(group_id=group_id, project=project, organization_id=project.organization_id, type=GroupOwnerType.SUSPECT_COMMIT.value)\n            basic_logging_details = {'event': event_id, 'group': group_id, 'organization': project.organization_id}\n            to_be_deleted = owners.filter(date_added__lte=timezone.now() - PREFERRED_GROUP_OWNER_AGE)\n            if len(to_be_deleted):\n                for record in to_be_deleted:\n                    record.delete()\n            current_owners = owners.filter(date_added__gte=timezone.now() - PREFERRED_GROUP_OWNER_AGE).order_by('-date_added')\n            if len(current_owners) >= PREFERRED_GROUP_OWNERS:\n                cache_duration = timezone.now() - current_owners[0].date_added\n                cache_duration = cache_duration if cache_duration < PREFERRED_GROUP_OWNER_AGE else PREFERRED_GROUP_OWNER_AGE\n                cache.set(cache_key, True, cache_duration.total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'maxed_owners_none_old'})\n                logger.info('process_commit_context.maxed_owners', extra={**basic_logging_details, 'reason': 'maxed_owners_none_old'})\n                return\n            code_mappings = get_sorted_code_mapping_configs(project)\n            frames = event_frames or []\n            munged = munged_filename_and_frames(event_platform, frames, 'munged_filename', sdk_name)\n            if munged:\n                frames = munged[1]\n            in_app_frames = [f for f in frames if f and f.get('in_app', False)][::-1]\n            frame = next(iter(in_app_frames), None)\n            if not frame:\n                cache.set(cache_key, True, timedelta(days=1).total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_find_in_app_stacktrace_frame'})\n                logger.info('process_commit_context.find_frame', extra={**basic_logging_details, 'reason': 'could_not_find_in_app_stacktrace_frame', 'fallback': True})\n                process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                if features.has('organizations:suspect-commits-all-frames', project.organization):\n                    analytics.record('integrations.failed_to_fetch_commit_context_all_frames', organization_id=project.organization_id, project_id=project_id, group_id=basic_logging_details['group'], event_id=basic_logging_details['event'], num_frames=0, num_successfully_mapped_frames=0, reason='could_not_find_in_app_stacktrace_frame')\n                return\n            if features.has('organizations:suspect-commits-all-frames', project.organization):\n                metrics.incr('tasks.process_commit_context_all_frames.start')\n                blame = None\n                installation = None\n                try:\n                    (blame, installation) = find_commit_context_for_event_all_frames(code_mappings=code_mappings, frames=in_app_frames, organization_id=project.organization_id, project_id=project_id, extra=basic_logging_details)\n                except ApiError:\n                    logger.info('process_commit_context_all_frames.retry', extra={**basic_logging_details, 'retry_count': self.request.retries})\n                    metrics.incr('tasks.process_commit_context_all_frames.retry')\n                    self.retry()\n                if not blame or not installation:\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                selected_code_mapping = blame.code_mapping\n                commit = get_or_create_commit_from_blame(blame, organization_id=project.organization_id, extra=basic_logging_details)\n            else:\n                (found_contexts, installation) = find_commit_context_for_event(code_mappings=code_mappings, frame=frame, extra={**basic_logging_details})\n                if not len(found_contexts):\n                    cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n                    metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_fetch_commit_context'})\n                    logger.info('process_commit_context.find_commit_context', extra={**basic_logging_details, 'reason': 'could_not_fetch_commit_context', 'code_mappings_count': len(code_mappings), 'fallback': True})\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                commit = None\n                new_commit = None\n                selected_code_mapping = None\n                for (commit_context, code_mapping) in found_contexts:\n                    try:\n                        commit = Commit.objects.get(repository_id=code_mapping.repository_id, key=commit_context.get('commitId'))\n                        if commit.message == '':\n                            commit.message = commit_context.get('commitMessage')\n                            commit.save()\n                        selected_code_mapping = code_mapping\n                        break\n                    except Commit.DoesNotExist:\n                        if not new_commit and commit_context.get('committedDate'):\n                            new_commit = {'context': commit_context, 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id}\n                        logger.info('process_commit_context.no_commit_in_sentry', extra={**basic_logging_details, 'sha': commit_context.get('commitId'), 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id, 'reason': 'commit_sha_does_not_exist_in_sentry'})\n                if not commit:\n                    if new_commit:\n                        context = new_commit['context']\n                        (commit_author, _) = CommitAuthor.objects.get_or_create(organization_id=project.organization_id, email=context.get('commitAuthorEmail'), defaults={'name': context.get('commitAuthorName')})\n                        commit = Commit.objects.create(organization_id=project.organization_id, repository_id=new_commit['repository_id'], key=context.get('commitId'), date_added=context.get('committedDate'), author=commit_author, message=context.get('commitMessage'))\n                        logger.info('process_commit_context.added_commit_to_sentry_commit', extra={**basic_logging_details, 'sha': new_commit.get('commitId'), 'repository_id': new_commit['repository_id'], 'code_mapping_id': new_commit['code_mapping_id'], 'reason': 'commit_sha_does_not_exist_in_sentry_for_all_code_mappings'})\n                    else:\n                        metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'commit_sha_does_not_exist_in_sentry'})\n            authors = list(CommitAuthor.objects.get_many_from_cache([commit.author_id]))\n            author_to_user = get_users_for_authors(commit.organization_id, authors)\n            (group_owner, created) = GroupOwner.objects.update_or_create(group_id=group_id, type=GroupOwnerType.SUSPECT_COMMIT.value, user_id=author_to_user.get(str(commit.author_id), {}).get('id'), project=project, organization_id=project.organization_id, context={'commitId': commit.id}, defaults={'date_added': timezone.now()})\n            if OrganizationOption.objects.get_value(organization=project.organization, key='sentry:github_pr_bot', default=True):\n                logger.info('github.pr_comment', extra={'organization_id': project.organization_id})\n                repo = Repository.objects.filter(id=commit.repository_id)\n                if installation is not None and repo.exists() and (repo.get().provider == 'integrations:github'):\n                    queue_comment_task_if_needed(commit, group_owner, repo.get(), installation)\n                else:\n                    logger.info('github.pr_comment.incorrect_repo_config', extra={'organization_id': project.organization_id})\n            if created:\n                if len(current_owners) + 1 > PREFERRED_GROUP_OWNERS:\n                    try:\n                        owner = current_owners[0]\n                    except IndexError:\n                        pass\n                    else:\n                        owner.delete()\n            cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n            logger.info('process_commit_context.success', extra={**basic_logging_details, 'group_owner_id': group_owner.id, **({'repository_id': selected_code_mapping.repository_id, 'selected_code_mapping': selected_code_mapping.id} if selected_code_mapping is not None else {}), 'reason': 'created' if created else 'updated'})\n            metrics.incr('sentry.tasks.process_commit_context.success', tags={'detail': f\"successfully {('created' if created else 'updated')}\"})\n            analytics.record('groupowner.assignment', organization_id=project.organization_id, project_id=project.id, group_id=group_id, new_assignment=created)\n    except UnableToAcquireLock:\n        pass\n    except MaxRetriesExceededError:\n        metrics.incr('tasks.process_commit_context.max_retries_exceeded')\n        logger.info('process_commit_context.max_retries_exceeded', extra={**basic_logging_details, 'reason': 'max_retries_exceeded'})\n        process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)",
            "@instrumented_task(name='sentry.tasks.process_commit_context', queue='group_owners.process_commit_context', autoretry_for=(ApiError,), max_retries=5, retry_backoff=True, retry_backoff_max=60 * 60 * 3, retry_jitter=False, silo_mode=SiloMode.REGION, bind=True)\ndef process_commit_context(self, event_id, event_platform, event_frames, group_id, project_id, sdk_name=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    For a given event, look at the first in_app frame, and if we can find who modified the line, we can then update who is assigned to the issue.\\n    '\n    lock = locks.get(f'process-commit-context:{group_id}', duration=10, name='process_commit_context')\n    try:\n        with lock.acquire():\n            metrics.incr('sentry.tasks.process_commit_context.start')\n            cache_key = DEBOUNCE_CACHE_KEY(group_id)\n            set_current_event_project(project_id)\n            project = Project.objects.get_from_cache(id=project_id)\n            set_tag('organization.slug', project.organization.slug)\n            owners = GroupOwner.objects.filter(group_id=group_id, project=project, organization_id=project.organization_id, type=GroupOwnerType.SUSPECT_COMMIT.value)\n            basic_logging_details = {'event': event_id, 'group': group_id, 'organization': project.organization_id}\n            to_be_deleted = owners.filter(date_added__lte=timezone.now() - PREFERRED_GROUP_OWNER_AGE)\n            if len(to_be_deleted):\n                for record in to_be_deleted:\n                    record.delete()\n            current_owners = owners.filter(date_added__gte=timezone.now() - PREFERRED_GROUP_OWNER_AGE).order_by('-date_added')\n            if len(current_owners) >= PREFERRED_GROUP_OWNERS:\n                cache_duration = timezone.now() - current_owners[0].date_added\n                cache_duration = cache_duration if cache_duration < PREFERRED_GROUP_OWNER_AGE else PREFERRED_GROUP_OWNER_AGE\n                cache.set(cache_key, True, cache_duration.total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'maxed_owners_none_old'})\n                logger.info('process_commit_context.maxed_owners', extra={**basic_logging_details, 'reason': 'maxed_owners_none_old'})\n                return\n            code_mappings = get_sorted_code_mapping_configs(project)\n            frames = event_frames or []\n            munged = munged_filename_and_frames(event_platform, frames, 'munged_filename', sdk_name)\n            if munged:\n                frames = munged[1]\n            in_app_frames = [f for f in frames if f and f.get('in_app', False)][::-1]\n            frame = next(iter(in_app_frames), None)\n            if not frame:\n                cache.set(cache_key, True, timedelta(days=1).total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_find_in_app_stacktrace_frame'})\n                logger.info('process_commit_context.find_frame', extra={**basic_logging_details, 'reason': 'could_not_find_in_app_stacktrace_frame', 'fallback': True})\n                process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                if features.has('organizations:suspect-commits-all-frames', project.organization):\n                    analytics.record('integrations.failed_to_fetch_commit_context_all_frames', organization_id=project.organization_id, project_id=project_id, group_id=basic_logging_details['group'], event_id=basic_logging_details['event'], num_frames=0, num_successfully_mapped_frames=0, reason='could_not_find_in_app_stacktrace_frame')\n                return\n            if features.has('organizations:suspect-commits-all-frames', project.organization):\n                metrics.incr('tasks.process_commit_context_all_frames.start')\n                blame = None\n                installation = None\n                try:\n                    (blame, installation) = find_commit_context_for_event_all_frames(code_mappings=code_mappings, frames=in_app_frames, organization_id=project.organization_id, project_id=project_id, extra=basic_logging_details)\n                except ApiError:\n                    logger.info('process_commit_context_all_frames.retry', extra={**basic_logging_details, 'retry_count': self.request.retries})\n                    metrics.incr('tasks.process_commit_context_all_frames.retry')\n                    self.retry()\n                if not blame or not installation:\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                selected_code_mapping = blame.code_mapping\n                commit = get_or_create_commit_from_blame(blame, organization_id=project.organization_id, extra=basic_logging_details)\n            else:\n                (found_contexts, installation) = find_commit_context_for_event(code_mappings=code_mappings, frame=frame, extra={**basic_logging_details})\n                if not len(found_contexts):\n                    cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n                    metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_fetch_commit_context'})\n                    logger.info('process_commit_context.find_commit_context', extra={**basic_logging_details, 'reason': 'could_not_fetch_commit_context', 'code_mappings_count': len(code_mappings), 'fallback': True})\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                commit = None\n                new_commit = None\n                selected_code_mapping = None\n                for (commit_context, code_mapping) in found_contexts:\n                    try:\n                        commit = Commit.objects.get(repository_id=code_mapping.repository_id, key=commit_context.get('commitId'))\n                        if commit.message == '':\n                            commit.message = commit_context.get('commitMessage')\n                            commit.save()\n                        selected_code_mapping = code_mapping\n                        break\n                    except Commit.DoesNotExist:\n                        if not new_commit and commit_context.get('committedDate'):\n                            new_commit = {'context': commit_context, 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id}\n                        logger.info('process_commit_context.no_commit_in_sentry', extra={**basic_logging_details, 'sha': commit_context.get('commitId'), 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id, 'reason': 'commit_sha_does_not_exist_in_sentry'})\n                if not commit:\n                    if new_commit:\n                        context = new_commit['context']\n                        (commit_author, _) = CommitAuthor.objects.get_or_create(organization_id=project.organization_id, email=context.get('commitAuthorEmail'), defaults={'name': context.get('commitAuthorName')})\n                        commit = Commit.objects.create(organization_id=project.organization_id, repository_id=new_commit['repository_id'], key=context.get('commitId'), date_added=context.get('committedDate'), author=commit_author, message=context.get('commitMessage'))\n                        logger.info('process_commit_context.added_commit_to_sentry_commit', extra={**basic_logging_details, 'sha': new_commit.get('commitId'), 'repository_id': new_commit['repository_id'], 'code_mapping_id': new_commit['code_mapping_id'], 'reason': 'commit_sha_does_not_exist_in_sentry_for_all_code_mappings'})\n                    else:\n                        metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'commit_sha_does_not_exist_in_sentry'})\n            authors = list(CommitAuthor.objects.get_many_from_cache([commit.author_id]))\n            author_to_user = get_users_for_authors(commit.organization_id, authors)\n            (group_owner, created) = GroupOwner.objects.update_or_create(group_id=group_id, type=GroupOwnerType.SUSPECT_COMMIT.value, user_id=author_to_user.get(str(commit.author_id), {}).get('id'), project=project, organization_id=project.organization_id, context={'commitId': commit.id}, defaults={'date_added': timezone.now()})\n            if OrganizationOption.objects.get_value(organization=project.organization, key='sentry:github_pr_bot', default=True):\n                logger.info('github.pr_comment', extra={'organization_id': project.organization_id})\n                repo = Repository.objects.filter(id=commit.repository_id)\n                if installation is not None and repo.exists() and (repo.get().provider == 'integrations:github'):\n                    queue_comment_task_if_needed(commit, group_owner, repo.get(), installation)\n                else:\n                    logger.info('github.pr_comment.incorrect_repo_config', extra={'organization_id': project.organization_id})\n            if created:\n                if len(current_owners) + 1 > PREFERRED_GROUP_OWNERS:\n                    try:\n                        owner = current_owners[0]\n                    except IndexError:\n                        pass\n                    else:\n                        owner.delete()\n            cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n            logger.info('process_commit_context.success', extra={**basic_logging_details, 'group_owner_id': group_owner.id, **({'repository_id': selected_code_mapping.repository_id, 'selected_code_mapping': selected_code_mapping.id} if selected_code_mapping is not None else {}), 'reason': 'created' if created else 'updated'})\n            metrics.incr('sentry.tasks.process_commit_context.success', tags={'detail': f\"successfully {('created' if created else 'updated')}\"})\n            analytics.record('groupowner.assignment', organization_id=project.organization_id, project_id=project.id, group_id=group_id, new_assignment=created)\n    except UnableToAcquireLock:\n        pass\n    except MaxRetriesExceededError:\n        metrics.incr('tasks.process_commit_context.max_retries_exceeded')\n        logger.info('process_commit_context.max_retries_exceeded', extra={**basic_logging_details, 'reason': 'max_retries_exceeded'})\n        process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)",
            "@instrumented_task(name='sentry.tasks.process_commit_context', queue='group_owners.process_commit_context', autoretry_for=(ApiError,), max_retries=5, retry_backoff=True, retry_backoff_max=60 * 60 * 3, retry_jitter=False, silo_mode=SiloMode.REGION, bind=True)\ndef process_commit_context(self, event_id, event_platform, event_frames, group_id, project_id, sdk_name=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    For a given event, look at the first in_app frame, and if we can find who modified the line, we can then update who is assigned to the issue.\\n    '\n    lock = locks.get(f'process-commit-context:{group_id}', duration=10, name='process_commit_context')\n    try:\n        with lock.acquire():\n            metrics.incr('sentry.tasks.process_commit_context.start')\n            cache_key = DEBOUNCE_CACHE_KEY(group_id)\n            set_current_event_project(project_id)\n            project = Project.objects.get_from_cache(id=project_id)\n            set_tag('organization.slug', project.organization.slug)\n            owners = GroupOwner.objects.filter(group_id=group_id, project=project, organization_id=project.organization_id, type=GroupOwnerType.SUSPECT_COMMIT.value)\n            basic_logging_details = {'event': event_id, 'group': group_id, 'organization': project.organization_id}\n            to_be_deleted = owners.filter(date_added__lte=timezone.now() - PREFERRED_GROUP_OWNER_AGE)\n            if len(to_be_deleted):\n                for record in to_be_deleted:\n                    record.delete()\n            current_owners = owners.filter(date_added__gte=timezone.now() - PREFERRED_GROUP_OWNER_AGE).order_by('-date_added')\n            if len(current_owners) >= PREFERRED_GROUP_OWNERS:\n                cache_duration = timezone.now() - current_owners[0].date_added\n                cache_duration = cache_duration if cache_duration < PREFERRED_GROUP_OWNER_AGE else PREFERRED_GROUP_OWNER_AGE\n                cache.set(cache_key, True, cache_duration.total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'maxed_owners_none_old'})\n                logger.info('process_commit_context.maxed_owners', extra={**basic_logging_details, 'reason': 'maxed_owners_none_old'})\n                return\n            code_mappings = get_sorted_code_mapping_configs(project)\n            frames = event_frames or []\n            munged = munged_filename_and_frames(event_platform, frames, 'munged_filename', sdk_name)\n            if munged:\n                frames = munged[1]\n            in_app_frames = [f for f in frames if f and f.get('in_app', False)][::-1]\n            frame = next(iter(in_app_frames), None)\n            if not frame:\n                cache.set(cache_key, True, timedelta(days=1).total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_find_in_app_stacktrace_frame'})\n                logger.info('process_commit_context.find_frame', extra={**basic_logging_details, 'reason': 'could_not_find_in_app_stacktrace_frame', 'fallback': True})\n                process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                if features.has('organizations:suspect-commits-all-frames', project.organization):\n                    analytics.record('integrations.failed_to_fetch_commit_context_all_frames', organization_id=project.organization_id, project_id=project_id, group_id=basic_logging_details['group'], event_id=basic_logging_details['event'], num_frames=0, num_successfully_mapped_frames=0, reason='could_not_find_in_app_stacktrace_frame')\n                return\n            if features.has('organizations:suspect-commits-all-frames', project.organization):\n                metrics.incr('tasks.process_commit_context_all_frames.start')\n                blame = None\n                installation = None\n                try:\n                    (blame, installation) = find_commit_context_for_event_all_frames(code_mappings=code_mappings, frames=in_app_frames, organization_id=project.organization_id, project_id=project_id, extra=basic_logging_details)\n                except ApiError:\n                    logger.info('process_commit_context_all_frames.retry', extra={**basic_logging_details, 'retry_count': self.request.retries})\n                    metrics.incr('tasks.process_commit_context_all_frames.retry')\n                    self.retry()\n                if not blame or not installation:\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                selected_code_mapping = blame.code_mapping\n                commit = get_or_create_commit_from_blame(blame, organization_id=project.organization_id, extra=basic_logging_details)\n            else:\n                (found_contexts, installation) = find_commit_context_for_event(code_mappings=code_mappings, frame=frame, extra={**basic_logging_details})\n                if not len(found_contexts):\n                    cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n                    metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_fetch_commit_context'})\n                    logger.info('process_commit_context.find_commit_context', extra={**basic_logging_details, 'reason': 'could_not_fetch_commit_context', 'code_mappings_count': len(code_mappings), 'fallback': True})\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                commit = None\n                new_commit = None\n                selected_code_mapping = None\n                for (commit_context, code_mapping) in found_contexts:\n                    try:\n                        commit = Commit.objects.get(repository_id=code_mapping.repository_id, key=commit_context.get('commitId'))\n                        if commit.message == '':\n                            commit.message = commit_context.get('commitMessage')\n                            commit.save()\n                        selected_code_mapping = code_mapping\n                        break\n                    except Commit.DoesNotExist:\n                        if not new_commit and commit_context.get('committedDate'):\n                            new_commit = {'context': commit_context, 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id}\n                        logger.info('process_commit_context.no_commit_in_sentry', extra={**basic_logging_details, 'sha': commit_context.get('commitId'), 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id, 'reason': 'commit_sha_does_not_exist_in_sentry'})\n                if not commit:\n                    if new_commit:\n                        context = new_commit['context']\n                        (commit_author, _) = CommitAuthor.objects.get_or_create(organization_id=project.organization_id, email=context.get('commitAuthorEmail'), defaults={'name': context.get('commitAuthorName')})\n                        commit = Commit.objects.create(organization_id=project.organization_id, repository_id=new_commit['repository_id'], key=context.get('commitId'), date_added=context.get('committedDate'), author=commit_author, message=context.get('commitMessage'))\n                        logger.info('process_commit_context.added_commit_to_sentry_commit', extra={**basic_logging_details, 'sha': new_commit.get('commitId'), 'repository_id': new_commit['repository_id'], 'code_mapping_id': new_commit['code_mapping_id'], 'reason': 'commit_sha_does_not_exist_in_sentry_for_all_code_mappings'})\n                    else:\n                        metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'commit_sha_does_not_exist_in_sentry'})\n            authors = list(CommitAuthor.objects.get_many_from_cache([commit.author_id]))\n            author_to_user = get_users_for_authors(commit.organization_id, authors)\n            (group_owner, created) = GroupOwner.objects.update_or_create(group_id=group_id, type=GroupOwnerType.SUSPECT_COMMIT.value, user_id=author_to_user.get(str(commit.author_id), {}).get('id'), project=project, organization_id=project.organization_id, context={'commitId': commit.id}, defaults={'date_added': timezone.now()})\n            if OrganizationOption.objects.get_value(organization=project.organization, key='sentry:github_pr_bot', default=True):\n                logger.info('github.pr_comment', extra={'organization_id': project.organization_id})\n                repo = Repository.objects.filter(id=commit.repository_id)\n                if installation is not None and repo.exists() and (repo.get().provider == 'integrations:github'):\n                    queue_comment_task_if_needed(commit, group_owner, repo.get(), installation)\n                else:\n                    logger.info('github.pr_comment.incorrect_repo_config', extra={'organization_id': project.organization_id})\n            if created:\n                if len(current_owners) + 1 > PREFERRED_GROUP_OWNERS:\n                    try:\n                        owner = current_owners[0]\n                    except IndexError:\n                        pass\n                    else:\n                        owner.delete()\n            cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n            logger.info('process_commit_context.success', extra={**basic_logging_details, 'group_owner_id': group_owner.id, **({'repository_id': selected_code_mapping.repository_id, 'selected_code_mapping': selected_code_mapping.id} if selected_code_mapping is not None else {}), 'reason': 'created' if created else 'updated'})\n            metrics.incr('sentry.tasks.process_commit_context.success', tags={'detail': f\"successfully {('created' if created else 'updated')}\"})\n            analytics.record('groupowner.assignment', organization_id=project.organization_id, project_id=project.id, group_id=group_id, new_assignment=created)\n    except UnableToAcquireLock:\n        pass\n    except MaxRetriesExceededError:\n        metrics.incr('tasks.process_commit_context.max_retries_exceeded')\n        logger.info('process_commit_context.max_retries_exceeded', extra={**basic_logging_details, 'reason': 'max_retries_exceeded'})\n        process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)",
            "@instrumented_task(name='sentry.tasks.process_commit_context', queue='group_owners.process_commit_context', autoretry_for=(ApiError,), max_retries=5, retry_backoff=True, retry_backoff_max=60 * 60 * 3, retry_jitter=False, silo_mode=SiloMode.REGION, bind=True)\ndef process_commit_context(self, event_id, event_platform, event_frames, group_id, project_id, sdk_name=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    For a given event, look at the first in_app frame, and if we can find who modified the line, we can then update who is assigned to the issue.\\n    '\n    lock = locks.get(f'process-commit-context:{group_id}', duration=10, name='process_commit_context')\n    try:\n        with lock.acquire():\n            metrics.incr('sentry.tasks.process_commit_context.start')\n            cache_key = DEBOUNCE_CACHE_KEY(group_id)\n            set_current_event_project(project_id)\n            project = Project.objects.get_from_cache(id=project_id)\n            set_tag('organization.slug', project.organization.slug)\n            owners = GroupOwner.objects.filter(group_id=group_id, project=project, organization_id=project.organization_id, type=GroupOwnerType.SUSPECT_COMMIT.value)\n            basic_logging_details = {'event': event_id, 'group': group_id, 'organization': project.organization_id}\n            to_be_deleted = owners.filter(date_added__lte=timezone.now() - PREFERRED_GROUP_OWNER_AGE)\n            if len(to_be_deleted):\n                for record in to_be_deleted:\n                    record.delete()\n            current_owners = owners.filter(date_added__gte=timezone.now() - PREFERRED_GROUP_OWNER_AGE).order_by('-date_added')\n            if len(current_owners) >= PREFERRED_GROUP_OWNERS:\n                cache_duration = timezone.now() - current_owners[0].date_added\n                cache_duration = cache_duration if cache_duration < PREFERRED_GROUP_OWNER_AGE else PREFERRED_GROUP_OWNER_AGE\n                cache.set(cache_key, True, cache_duration.total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'maxed_owners_none_old'})\n                logger.info('process_commit_context.maxed_owners', extra={**basic_logging_details, 'reason': 'maxed_owners_none_old'})\n                return\n            code_mappings = get_sorted_code_mapping_configs(project)\n            frames = event_frames or []\n            munged = munged_filename_and_frames(event_platform, frames, 'munged_filename', sdk_name)\n            if munged:\n                frames = munged[1]\n            in_app_frames = [f for f in frames if f and f.get('in_app', False)][::-1]\n            frame = next(iter(in_app_frames), None)\n            if not frame:\n                cache.set(cache_key, True, timedelta(days=1).total_seconds())\n                metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_find_in_app_stacktrace_frame'})\n                logger.info('process_commit_context.find_frame', extra={**basic_logging_details, 'reason': 'could_not_find_in_app_stacktrace_frame', 'fallback': True})\n                process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                if features.has('organizations:suspect-commits-all-frames', project.organization):\n                    analytics.record('integrations.failed_to_fetch_commit_context_all_frames', organization_id=project.organization_id, project_id=project_id, group_id=basic_logging_details['group'], event_id=basic_logging_details['event'], num_frames=0, num_successfully_mapped_frames=0, reason='could_not_find_in_app_stacktrace_frame')\n                return\n            if features.has('organizations:suspect-commits-all-frames', project.organization):\n                metrics.incr('tasks.process_commit_context_all_frames.start')\n                blame = None\n                installation = None\n                try:\n                    (blame, installation) = find_commit_context_for_event_all_frames(code_mappings=code_mappings, frames=in_app_frames, organization_id=project.organization_id, project_id=project_id, extra=basic_logging_details)\n                except ApiError:\n                    logger.info('process_commit_context_all_frames.retry', extra={**basic_logging_details, 'retry_count': self.request.retries})\n                    metrics.incr('tasks.process_commit_context_all_frames.retry')\n                    self.retry()\n                if not blame or not installation:\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                selected_code_mapping = blame.code_mapping\n                commit = get_or_create_commit_from_blame(blame, organization_id=project.organization_id, extra=basic_logging_details)\n            else:\n                (found_contexts, installation) = find_commit_context_for_event(code_mappings=code_mappings, frame=frame, extra={**basic_logging_details})\n                if not len(found_contexts):\n                    cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n                    metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'could_not_fetch_commit_context'})\n                    logger.info('process_commit_context.find_commit_context', extra={**basic_logging_details, 'reason': 'could_not_fetch_commit_context', 'code_mappings_count': len(code_mappings), 'fallback': True})\n                    process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)\n                    return\n                commit = None\n                new_commit = None\n                selected_code_mapping = None\n                for (commit_context, code_mapping) in found_contexts:\n                    try:\n                        commit = Commit.objects.get(repository_id=code_mapping.repository_id, key=commit_context.get('commitId'))\n                        if commit.message == '':\n                            commit.message = commit_context.get('commitMessage')\n                            commit.save()\n                        selected_code_mapping = code_mapping\n                        break\n                    except Commit.DoesNotExist:\n                        if not new_commit and commit_context.get('committedDate'):\n                            new_commit = {'context': commit_context, 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id}\n                        logger.info('process_commit_context.no_commit_in_sentry', extra={**basic_logging_details, 'sha': commit_context.get('commitId'), 'repository_id': code_mapping.repository_id, 'code_mapping_id': code_mapping.id, 'reason': 'commit_sha_does_not_exist_in_sentry'})\n                if not commit:\n                    if new_commit:\n                        context = new_commit['context']\n                        (commit_author, _) = CommitAuthor.objects.get_or_create(organization_id=project.organization_id, email=context.get('commitAuthorEmail'), defaults={'name': context.get('commitAuthorName')})\n                        commit = Commit.objects.create(organization_id=project.organization_id, repository_id=new_commit['repository_id'], key=context.get('commitId'), date_added=context.get('committedDate'), author=commit_author, message=context.get('commitMessage'))\n                        logger.info('process_commit_context.added_commit_to_sentry_commit', extra={**basic_logging_details, 'sha': new_commit.get('commitId'), 'repository_id': new_commit['repository_id'], 'code_mapping_id': new_commit['code_mapping_id'], 'reason': 'commit_sha_does_not_exist_in_sentry_for_all_code_mappings'})\n                    else:\n                        metrics.incr('sentry.tasks.process_commit_context.aborted', tags={'detail': 'commit_sha_does_not_exist_in_sentry'})\n            authors = list(CommitAuthor.objects.get_many_from_cache([commit.author_id]))\n            author_to_user = get_users_for_authors(commit.organization_id, authors)\n            (group_owner, created) = GroupOwner.objects.update_or_create(group_id=group_id, type=GroupOwnerType.SUSPECT_COMMIT.value, user_id=author_to_user.get(str(commit.author_id), {}).get('id'), project=project, organization_id=project.organization_id, context={'commitId': commit.id}, defaults={'date_added': timezone.now()})\n            if OrganizationOption.objects.get_value(organization=project.organization, key='sentry:github_pr_bot', default=True):\n                logger.info('github.pr_comment', extra={'organization_id': project.organization_id})\n                repo = Repository.objects.filter(id=commit.repository_id)\n                if installation is not None and repo.exists() and (repo.get().provider == 'integrations:github'):\n                    queue_comment_task_if_needed(commit, group_owner, repo.get(), installation)\n                else:\n                    logger.info('github.pr_comment.incorrect_repo_config', extra={'organization_id': project.organization_id})\n            if created:\n                if len(current_owners) + 1 > PREFERRED_GROUP_OWNERS:\n                    try:\n                        owner = current_owners[0]\n                    except IndexError:\n                        pass\n                    else:\n                        owner.delete()\n            cache.set(cache_key, True, PREFERRED_GROUP_OWNER_AGE.total_seconds())\n            logger.info('process_commit_context.success', extra={**basic_logging_details, 'group_owner_id': group_owner.id, **({'repository_id': selected_code_mapping.repository_id, 'selected_code_mapping': selected_code_mapping.id} if selected_code_mapping is not None else {}), 'reason': 'created' if created else 'updated'})\n            metrics.incr('sentry.tasks.process_commit_context.success', tags={'detail': f\"successfully {('created' if created else 'updated')}\"})\n            analytics.record('groupowner.assignment', organization_id=project.organization_id, project_id=project.id, group_id=group_id, new_assignment=created)\n    except UnableToAcquireLock:\n        pass\n    except MaxRetriesExceededError:\n        metrics.incr('tasks.process_commit_context.max_retries_exceeded')\n        logger.info('process_commit_context.max_retries_exceeded', extra={**basic_logging_details, 'reason': 'max_retries_exceeded'})\n        process_suspect_commits.delay(event_id=event_id, event_platform=event_platform, event_frames=event_frames, group_id=group_id, project_id=project_id, sdk_name=sdk_name)"
        ]
    }
]