[
    {
        "func_name": "metric",
        "original": "def metric(k, wh):\n    r = wh[:, None] / k[None]\n    x = torch.min(r, 1 / r).min(2)[0]\n    return (x, x.max(1)[0])",
        "mutated": [
            "def metric(k, wh):\n    if False:\n        i = 10\n    r = wh[:, None] / k[None]\n    x = torch.min(r, 1 / r).min(2)[0]\n    return (x, x.max(1)[0])",
            "def metric(k, wh):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    r = wh[:, None] / k[None]\n    x = torch.min(r, 1 / r).min(2)[0]\n    return (x, x.max(1)[0])",
            "def metric(k, wh):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    r = wh[:, None] / k[None]\n    x = torch.min(r, 1 / r).min(2)[0]\n    return (x, x.max(1)[0])",
            "def metric(k, wh):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    r = wh[:, None] / k[None]\n    x = torch.min(r, 1 / r).min(2)[0]\n    return (x, x.max(1)[0])",
            "def metric(k, wh):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    r = wh[:, None] / k[None]\n    x = torch.min(r, 1 / r).min(2)[0]\n    return (x, x.max(1)[0])"
        ]
    },
    {
        "func_name": "anchor_fitness",
        "original": "def anchor_fitness(k):\n    (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n    return (best * (best > thr).float()).mean()",
        "mutated": [
            "def anchor_fitness(k):\n    if False:\n        i = 10\n    (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n    return (best * (best > thr).float()).mean()",
            "def anchor_fitness(k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n    return (best * (best > thr).float()).mean()",
            "def anchor_fitness(k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n    return (best * (best > thr).float()).mean()",
            "def anchor_fitness(k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n    return (best * (best > thr).float()).mean()",
            "def anchor_fitness(k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n    return (best * (best > thr).float()).mean()"
        ]
    },
    {
        "func_name": "print_results",
        "original": "def print_results(k, verbose=True):\n    k = k[np.argsort(k.prod(1))]\n    if verbose:\n        (x, best) = metric(k, wh0)\n        (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n        s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n        print(s)\n    return k",
        "mutated": [
            "def print_results(k, verbose=True):\n    if False:\n        i = 10\n    k = k[np.argsort(k.prod(1))]\n    if verbose:\n        (x, best) = metric(k, wh0)\n        (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n        s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n        print(s)\n    return k",
            "def print_results(k, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    k = k[np.argsort(k.prod(1))]\n    if verbose:\n        (x, best) = metric(k, wh0)\n        (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n        s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n        print(s)\n    return k",
            "def print_results(k, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    k = k[np.argsort(k.prod(1))]\n    if verbose:\n        (x, best) = metric(k, wh0)\n        (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n        s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n        print(s)\n    return k",
            "def print_results(k, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    k = k[np.argsort(k.prod(1))]\n    if verbose:\n        (x, best) = metric(k, wh0)\n        (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n        s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n        print(s)\n    return k",
            "def print_results(k, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    k = k[np.argsort(k.prod(1))]\n    if verbose:\n        (x, best) = metric(k, wh0)\n        (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n        s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n        print(s)\n    return k"
        ]
    },
    {
        "func_name": "generate_anchors",
        "original": "def generate_anchors(dataset, n=9, img_size=416, thr=4.0, gen=1000, verbose=True):\n    \"\"\" Creates kmeans-evolved anchors from training dataset\n\n        Arguments:\n            dataset: a loaded dataset i.e. subclass of torch.utils.data.Dataset\n            n: number of anchors\n            img_size: image size used for training\n            thr: anchor-label wh ratio threshold used for training, default=4.0\n            gen: generations to evolve anchors using genetic algorithm\n            verbose: print all results\n\n        Return:\n            k: kmeans evolved anchors\n    \"\"\"\n    thr = 1 / thr\n\n    def metric(k, wh):\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]\n        return (x, x.max(1)[0])\n\n    def anchor_fitness(k):\n        (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n        return (best * (best > thr).float()).mean()\n\n    def print_results(k, verbose=True):\n        k = k[np.argsort(k.prod(1))]\n        if verbose:\n            (x, best) = metric(k, wh0)\n            (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n            s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n            print(s)\n        return k\n    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    wh0 = np.concatenate([l[:, 3:5] * s for (s, l) in zip(shapes, dataset.labels)])\n    i = (wh0 < 3.0).any(1).sum()\n    if i and verbose:\n        print(f'WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n    wh = wh0[(wh0 >= 2.0).any(1)]\n    s = wh.std(0)\n    (k, dist) = kmeans(wh / s, n, iter=30)\n    assert len(k) == n, f'ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}'\n    k *= s\n    wh = torch.tensor(wh, dtype=torch.float32)\n    wh0 = torch.tensor(wh0, dtype=torch.float32)\n    k = print_results(k, verbose=False)\n    npr = np.random\n    (f, sh, mp, s) = (anchor_fitness(k), k.shape, 0.9, 0.1)\n    if verbose:\n        print('Generating anchor boxes for training images...')\n    for _ in range(gen):\n        v = np.ones(sh)\n        while (v == 1).all():\n            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n        kg = (k.copy() * v).clip(min=2.0)\n        fg = anchor_fitness(kg)\n        if fg > f:\n            (f, k) = (fg, kg.copy())\n    return print_results(k)",
        "mutated": [
            "def generate_anchors(dataset, n=9, img_size=416, thr=4.0, gen=1000, verbose=True):\n    if False:\n        i = 10\n    ' Creates kmeans-evolved anchors from training dataset\\n\\n        Arguments:\\n            dataset: a loaded dataset i.e. subclass of torch.utils.data.Dataset\\n            n: number of anchors\\n            img_size: image size used for training\\n            thr: anchor-label wh ratio threshold used for training, default=4.0\\n            gen: generations to evolve anchors using genetic algorithm\\n            verbose: print all results\\n\\n        Return:\\n            k: kmeans evolved anchors\\n    '\n    thr = 1 / thr\n\n    def metric(k, wh):\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]\n        return (x, x.max(1)[0])\n\n    def anchor_fitness(k):\n        (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n        return (best * (best > thr).float()).mean()\n\n    def print_results(k, verbose=True):\n        k = k[np.argsort(k.prod(1))]\n        if verbose:\n            (x, best) = metric(k, wh0)\n            (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n            s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n            print(s)\n        return k\n    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    wh0 = np.concatenate([l[:, 3:5] * s for (s, l) in zip(shapes, dataset.labels)])\n    i = (wh0 < 3.0).any(1).sum()\n    if i and verbose:\n        print(f'WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n    wh = wh0[(wh0 >= 2.0).any(1)]\n    s = wh.std(0)\n    (k, dist) = kmeans(wh / s, n, iter=30)\n    assert len(k) == n, f'ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}'\n    k *= s\n    wh = torch.tensor(wh, dtype=torch.float32)\n    wh0 = torch.tensor(wh0, dtype=torch.float32)\n    k = print_results(k, verbose=False)\n    npr = np.random\n    (f, sh, mp, s) = (anchor_fitness(k), k.shape, 0.9, 0.1)\n    if verbose:\n        print('Generating anchor boxes for training images...')\n    for _ in range(gen):\n        v = np.ones(sh)\n        while (v == 1).all():\n            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n        kg = (k.copy() * v).clip(min=2.0)\n        fg = anchor_fitness(kg)\n        if fg > f:\n            (f, k) = (fg, kg.copy())\n    return print_results(k)",
            "def generate_anchors(dataset, n=9, img_size=416, thr=4.0, gen=1000, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ' Creates kmeans-evolved anchors from training dataset\\n\\n        Arguments:\\n            dataset: a loaded dataset i.e. subclass of torch.utils.data.Dataset\\n            n: number of anchors\\n            img_size: image size used for training\\n            thr: anchor-label wh ratio threshold used for training, default=4.0\\n            gen: generations to evolve anchors using genetic algorithm\\n            verbose: print all results\\n\\n        Return:\\n            k: kmeans evolved anchors\\n    '\n    thr = 1 / thr\n\n    def metric(k, wh):\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]\n        return (x, x.max(1)[0])\n\n    def anchor_fitness(k):\n        (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n        return (best * (best > thr).float()).mean()\n\n    def print_results(k, verbose=True):\n        k = k[np.argsort(k.prod(1))]\n        if verbose:\n            (x, best) = metric(k, wh0)\n            (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n            s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n            print(s)\n        return k\n    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    wh0 = np.concatenate([l[:, 3:5] * s for (s, l) in zip(shapes, dataset.labels)])\n    i = (wh0 < 3.0).any(1).sum()\n    if i and verbose:\n        print(f'WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n    wh = wh0[(wh0 >= 2.0).any(1)]\n    s = wh.std(0)\n    (k, dist) = kmeans(wh / s, n, iter=30)\n    assert len(k) == n, f'ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}'\n    k *= s\n    wh = torch.tensor(wh, dtype=torch.float32)\n    wh0 = torch.tensor(wh0, dtype=torch.float32)\n    k = print_results(k, verbose=False)\n    npr = np.random\n    (f, sh, mp, s) = (anchor_fitness(k), k.shape, 0.9, 0.1)\n    if verbose:\n        print('Generating anchor boxes for training images...')\n    for _ in range(gen):\n        v = np.ones(sh)\n        while (v == 1).all():\n            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n        kg = (k.copy() * v).clip(min=2.0)\n        fg = anchor_fitness(kg)\n        if fg > f:\n            (f, k) = (fg, kg.copy())\n    return print_results(k)",
            "def generate_anchors(dataset, n=9, img_size=416, thr=4.0, gen=1000, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ' Creates kmeans-evolved anchors from training dataset\\n\\n        Arguments:\\n            dataset: a loaded dataset i.e. subclass of torch.utils.data.Dataset\\n            n: number of anchors\\n            img_size: image size used for training\\n            thr: anchor-label wh ratio threshold used for training, default=4.0\\n            gen: generations to evolve anchors using genetic algorithm\\n            verbose: print all results\\n\\n        Return:\\n            k: kmeans evolved anchors\\n    '\n    thr = 1 / thr\n\n    def metric(k, wh):\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]\n        return (x, x.max(1)[0])\n\n    def anchor_fitness(k):\n        (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n        return (best * (best > thr).float()).mean()\n\n    def print_results(k, verbose=True):\n        k = k[np.argsort(k.prod(1))]\n        if verbose:\n            (x, best) = metric(k, wh0)\n            (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n            s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n            print(s)\n        return k\n    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    wh0 = np.concatenate([l[:, 3:5] * s for (s, l) in zip(shapes, dataset.labels)])\n    i = (wh0 < 3.0).any(1).sum()\n    if i and verbose:\n        print(f'WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n    wh = wh0[(wh0 >= 2.0).any(1)]\n    s = wh.std(0)\n    (k, dist) = kmeans(wh / s, n, iter=30)\n    assert len(k) == n, f'ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}'\n    k *= s\n    wh = torch.tensor(wh, dtype=torch.float32)\n    wh0 = torch.tensor(wh0, dtype=torch.float32)\n    k = print_results(k, verbose=False)\n    npr = np.random\n    (f, sh, mp, s) = (anchor_fitness(k), k.shape, 0.9, 0.1)\n    if verbose:\n        print('Generating anchor boxes for training images...')\n    for _ in range(gen):\n        v = np.ones(sh)\n        while (v == 1).all():\n            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n        kg = (k.copy() * v).clip(min=2.0)\n        fg = anchor_fitness(kg)\n        if fg > f:\n            (f, k) = (fg, kg.copy())\n    return print_results(k)",
            "def generate_anchors(dataset, n=9, img_size=416, thr=4.0, gen=1000, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ' Creates kmeans-evolved anchors from training dataset\\n\\n        Arguments:\\n            dataset: a loaded dataset i.e. subclass of torch.utils.data.Dataset\\n            n: number of anchors\\n            img_size: image size used for training\\n            thr: anchor-label wh ratio threshold used for training, default=4.0\\n            gen: generations to evolve anchors using genetic algorithm\\n            verbose: print all results\\n\\n        Return:\\n            k: kmeans evolved anchors\\n    '\n    thr = 1 / thr\n\n    def metric(k, wh):\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]\n        return (x, x.max(1)[0])\n\n    def anchor_fitness(k):\n        (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n        return (best * (best > thr).float()).mean()\n\n    def print_results(k, verbose=True):\n        k = k[np.argsort(k.prod(1))]\n        if verbose:\n            (x, best) = metric(k, wh0)\n            (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n            s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n            print(s)\n        return k\n    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    wh0 = np.concatenate([l[:, 3:5] * s for (s, l) in zip(shapes, dataset.labels)])\n    i = (wh0 < 3.0).any(1).sum()\n    if i and verbose:\n        print(f'WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n    wh = wh0[(wh0 >= 2.0).any(1)]\n    s = wh.std(0)\n    (k, dist) = kmeans(wh / s, n, iter=30)\n    assert len(k) == n, f'ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}'\n    k *= s\n    wh = torch.tensor(wh, dtype=torch.float32)\n    wh0 = torch.tensor(wh0, dtype=torch.float32)\n    k = print_results(k, verbose=False)\n    npr = np.random\n    (f, sh, mp, s) = (anchor_fitness(k), k.shape, 0.9, 0.1)\n    if verbose:\n        print('Generating anchor boxes for training images...')\n    for _ in range(gen):\n        v = np.ones(sh)\n        while (v == 1).all():\n            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n        kg = (k.copy() * v).clip(min=2.0)\n        fg = anchor_fitness(kg)\n        if fg > f:\n            (f, k) = (fg, kg.copy())\n    return print_results(k)",
            "def generate_anchors(dataset, n=9, img_size=416, thr=4.0, gen=1000, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ' Creates kmeans-evolved anchors from training dataset\\n\\n        Arguments:\\n            dataset: a loaded dataset i.e. subclass of torch.utils.data.Dataset\\n            n: number of anchors\\n            img_size: image size used for training\\n            thr: anchor-label wh ratio threshold used for training, default=4.0\\n            gen: generations to evolve anchors using genetic algorithm\\n            verbose: print all results\\n\\n        Return:\\n            k: kmeans evolved anchors\\n    '\n    thr = 1 / thr\n\n    def metric(k, wh):\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]\n        return (x, x.max(1)[0])\n\n    def anchor_fitness(k):\n        (_, best) = metric(torch.tensor(k, dtype=torch.float32), wh)\n        return (best * (best > thr).float()).mean()\n\n    def print_results(k, verbose=True):\n        k = k[np.argsort(k.prod(1))]\n        if verbose:\n            (x, best) = metric(k, wh0)\n            (bpr, aat) = ((best > thr).float().mean(), (x > thr).float().mean() * n)\n            s = f'thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\nn={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, past_thr={x[x > thr].mean():.3f}-mean: '\n            print(s)\n        return k\n    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    wh0 = np.concatenate([l[:, 3:5] * s for (s, l) in zip(shapes, dataset.labels)])\n    i = (wh0 < 3.0).any(1).sum()\n    if i and verbose:\n        print(f'WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n    wh = wh0[(wh0 >= 2.0).any(1)]\n    s = wh.std(0)\n    (k, dist) = kmeans(wh / s, n, iter=30)\n    assert len(k) == n, f'ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}'\n    k *= s\n    wh = torch.tensor(wh, dtype=torch.float32)\n    wh0 = torch.tensor(wh0, dtype=torch.float32)\n    k = print_results(k, verbose=False)\n    npr = np.random\n    (f, sh, mp, s) = (anchor_fitness(k), k.shape, 0.9, 0.1)\n    if verbose:\n        print('Generating anchor boxes for training images...')\n    for _ in range(gen):\n        v = np.ones(sh)\n        while (v == 1).all():\n            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n        kg = (k.copy() * v).clip(min=2.0)\n        fg = anchor_fitness(kg)\n        if fg > f:\n            (f, k) = (fg, kg.copy())\n    return print_results(k)"
        ]
    }
]