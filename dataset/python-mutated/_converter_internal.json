[
    {
        "func_name": "_test_module",
        "original": "def _test_module(m):\n    assert m.model_type in ['transformer', 'regressor', 'classifier'], m.__name__\n    if m.model_type == 'transformer':\n        assert hasattr(m, 'update_dimension'), m.__name__\n    if m.model_type == 'classifier':\n        assert hasattr(m, 'supports_output_scores'), m.__name__\n        assert hasattr(m, 'get_output_classes'), m.__name__\n    assert hasattr(m, 'sklearn_class'), m.__name__\n    assert hasattr(m, 'get_input_dimension'), m.__name__\n    return True",
        "mutated": [
            "def _test_module(m):\n    if False:\n        i = 10\n    assert m.model_type in ['transformer', 'regressor', 'classifier'], m.__name__\n    if m.model_type == 'transformer':\n        assert hasattr(m, 'update_dimension'), m.__name__\n    if m.model_type == 'classifier':\n        assert hasattr(m, 'supports_output_scores'), m.__name__\n        assert hasattr(m, 'get_output_classes'), m.__name__\n    assert hasattr(m, 'sklearn_class'), m.__name__\n    assert hasattr(m, 'get_input_dimension'), m.__name__\n    return True",
            "def _test_module(m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert m.model_type in ['transformer', 'regressor', 'classifier'], m.__name__\n    if m.model_type == 'transformer':\n        assert hasattr(m, 'update_dimension'), m.__name__\n    if m.model_type == 'classifier':\n        assert hasattr(m, 'supports_output_scores'), m.__name__\n        assert hasattr(m, 'get_output_classes'), m.__name__\n    assert hasattr(m, 'sklearn_class'), m.__name__\n    assert hasattr(m, 'get_input_dimension'), m.__name__\n    return True",
            "def _test_module(m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert m.model_type in ['transformer', 'regressor', 'classifier'], m.__name__\n    if m.model_type == 'transformer':\n        assert hasattr(m, 'update_dimension'), m.__name__\n    if m.model_type == 'classifier':\n        assert hasattr(m, 'supports_output_scores'), m.__name__\n        assert hasattr(m, 'get_output_classes'), m.__name__\n    assert hasattr(m, 'sklearn_class'), m.__name__\n    assert hasattr(m, 'get_input_dimension'), m.__name__\n    return True",
            "def _test_module(m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert m.model_type in ['transformer', 'regressor', 'classifier'], m.__name__\n    if m.model_type == 'transformer':\n        assert hasattr(m, 'update_dimension'), m.__name__\n    if m.model_type == 'classifier':\n        assert hasattr(m, 'supports_output_scores'), m.__name__\n        assert hasattr(m, 'get_output_classes'), m.__name__\n    assert hasattr(m, 'sklearn_class'), m.__name__\n    assert hasattr(m, 'get_input_dimension'), m.__name__\n    return True",
            "def _test_module(m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert m.model_type in ['transformer', 'regressor', 'classifier'], m.__name__\n    if m.model_type == 'transformer':\n        assert hasattr(m, 'update_dimension'), m.__name__\n    if m.model_type == 'classifier':\n        assert hasattr(m, 'supports_output_scores'), m.__name__\n        assert hasattr(m, 'get_output_classes'), m.__name__\n    assert hasattr(m, 'sklearn_class'), m.__name__\n    assert hasattr(m, 'get_input_dimension'), m.__name__\n    return True"
        ]
    },
    {
        "func_name": "_get_converter_module",
        "original": "def _get_converter_module(sk_obj):\n    \"\"\"\n    Returns the module holding the conversion functions for a\n    particular model).\n    \"\"\"\n    try:\n        cv_idx = _converter_lookup[sk_obj.__class__]\n    except KeyError:\n        raise ValueError(\"Transformer '%s' not supported; supported transformers are %s.\" % (repr(sk_obj), ','.join((k.__name__ for k in _converter_module_list))))\n    return _converter_module_list[cv_idx]",
        "mutated": [
            "def _get_converter_module(sk_obj):\n    if False:\n        i = 10\n    '\\n    Returns the module holding the conversion functions for a\\n    particular model).\\n    '\n    try:\n        cv_idx = _converter_lookup[sk_obj.__class__]\n    except KeyError:\n        raise ValueError(\"Transformer '%s' not supported; supported transformers are %s.\" % (repr(sk_obj), ','.join((k.__name__ for k in _converter_module_list))))\n    return _converter_module_list[cv_idx]",
            "def _get_converter_module(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Returns the module holding the conversion functions for a\\n    particular model).\\n    '\n    try:\n        cv_idx = _converter_lookup[sk_obj.__class__]\n    except KeyError:\n        raise ValueError(\"Transformer '%s' not supported; supported transformers are %s.\" % (repr(sk_obj), ','.join((k.__name__ for k in _converter_module_list))))\n    return _converter_module_list[cv_idx]",
            "def _get_converter_module(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Returns the module holding the conversion functions for a\\n    particular model).\\n    '\n    try:\n        cv_idx = _converter_lookup[sk_obj.__class__]\n    except KeyError:\n        raise ValueError(\"Transformer '%s' not supported; supported transformers are %s.\" % (repr(sk_obj), ','.join((k.__name__ for k in _converter_module_list))))\n    return _converter_module_list[cv_idx]",
            "def _get_converter_module(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Returns the module holding the conversion functions for a\\n    particular model).\\n    '\n    try:\n        cv_idx = _converter_lookup[sk_obj.__class__]\n    except KeyError:\n        raise ValueError(\"Transformer '%s' not supported; supported transformers are %s.\" % (repr(sk_obj), ','.join((k.__name__ for k in _converter_module_list))))\n    return _converter_module_list[cv_idx]",
            "def _get_converter_module(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Returns the module holding the conversion functions for a\\n    particular model).\\n    '\n    try:\n        cv_idx = _converter_lookup[sk_obj.__class__]\n    except KeyError:\n        raise ValueError(\"Transformer '%s' not supported; supported transformers are %s.\" % (repr(sk_obj), ','.join((k.__name__ for k in _converter_module_list))))\n    return _converter_module_list[cv_idx]"
        ]
    },
    {
        "func_name": "_is_sklearn_model",
        "original": "def _is_sklearn_model(sk_obj):\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    return isinstance(sk_obj, sk_Pipeline) or sk_obj.__class__ in _converter_lookup",
        "mutated": [
            "def _is_sklearn_model(sk_obj):\n    if False:\n        i = 10\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    return isinstance(sk_obj, sk_Pipeline) or sk_obj.__class__ in _converter_lookup",
            "def _is_sklearn_model(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    return isinstance(sk_obj, sk_Pipeline) or sk_obj.__class__ in _converter_lookup",
            "def _is_sklearn_model(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    return isinstance(sk_obj, sk_Pipeline) or sk_obj.__class__ in _converter_lookup",
            "def _is_sklearn_model(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    return isinstance(sk_obj, sk_Pipeline) or sk_obj.__class__ in _converter_lookup",
            "def _is_sklearn_model(sk_obj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    return isinstance(sk_obj, sk_Pipeline) or sk_obj.__class__ in _converter_lookup"
        ]
    },
    {
        "func_name": "_convert_sklearn_model",
        "original": "def _convert_sklearn_model(input_sk_obj, input_features=None, output_feature_names=None, class_labels=None):\n    \"\"\"\n    Converts a generic sklearn pipeline, transformer, classifier, or regressor\n    into an coreML specification.\n    \"\"\"\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    if input_features is None:\n        input_features = 'input'\n    if isinstance(input_sk_obj, sk_Pipeline):\n        sk_obj_list = input_sk_obj.steps\n    else:\n        sk_obj_list = [('SKObj', input_sk_obj)]\n    if len(sk_obj_list) == 0:\n        raise ValueError('No SKLearn transformers supplied.')\n    pipeline_list = []\n    Input = _namedtuple('InputTransformer', ['name', 'sk_obj', 'module'])\n    Output = _namedtuple('CoreMLTransformer', ['spec', 'input_features', 'output_features'])\n    obj_list = [Input(sk_obj_name, sk_obj, _get_converter_module(sk_obj)) for (sk_obj_name, sk_obj) in sk_obj_list]\n    if isinstance(obj_list[0].sk_obj, _dict_vectorizer.sklearn_class):\n        dv_obj = obj_list[0].sk_obj\n        output_dim = len(_dict_vectorizer.get_input_feature_names(dv_obj))\n        if not isinstance(input_features, _string_types):\n            raise TypeError('If the first transformer in a pipeline is a DictVectorizer, then the input feature must be the name of the input dictionary.')\n        input_features = [(input_features, datatypes.Dictionary(str))]\n        if len(obj_list) > 1:\n            output_feature_name = _PIPELINE_INTERNAL_FEATURE_NAME\n        elif output_feature_names is None:\n            output_feature_name = 'transformed_features'\n        elif isinstance(output_feature_names, _string_types):\n            output_feature_name = output_feature_names\n        else:\n            raise TypeError('For a transformer pipeline, the output_features needs to be None or a string for the predicted value.')\n        output_features = [(output_feature_name, datatypes.Array(output_dim))]\n        spec = _dict_vectorizer.convert(dv_obj, input_features, output_features)._spec\n        pipeline_list.append(Output(spec, input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = output_dim\n        if len(obj_list) == 1:\n            return spec\n        else:\n            del obj_list[0]\n    else:\n        first_sk_obj = obj_list[0].sk_obj\n        num_dimensions = _get_converter_module(first_sk_obj).get_input_dimension(first_sk_obj)\n        features = _fm.process_or_validate_features(input_features, num_dimensions)\n        current_num_dimensions = _fm.dimension_of_array_features(features)\n        if len(features) == 1 and isinstance(features[0][1], datatypes.Array):\n            current_input_features = features\n        else:\n            (spec, _output_dimension) = create_feature_vectorizer(features, _PIPELINE_INTERNAL_FEATURE_NAME)\n            assert _output_dimension == current_num_dimensions\n            ft_out_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(current_num_dimensions))]\n            pipeline_list.append(Output(spec, features, ft_out_features))\n            current_input_features = ft_out_features\n    for (i, (_, _, m)) in enumerate(obj_list[:-1]):\n        if m.model_type != 'transformer':\n            raise ValueError('Only a sequence of transformer classes followed by a single transformer, regressor, or classifier is currently supported. (object in position %d interpreted as %s)' % (i, m.model_type))\n    overall_mode = obj_list[-1].module.model_type\n    assert overall_mode in ('transformer', 'regressor', 'classifier')\n    for (_, sk_obj, sk_m) in obj_list[:-1]:\n        next_dimension = sk_m.update_dimension(sk_obj, current_num_dimensions)\n        output_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(next_dimension))]\n        spec = sk_m.convert(sk_obj, current_input_features, output_features)._spec\n        pipeline_list.append(Output(spec, current_input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = next_dimension\n    (_, last_sk_obj, last_sk_m) = obj_list[-1]\n    if overall_mode == 'classifier':\n        supports_output_scores = last_sk_m.supports_output_scores(last_sk_obj)\n        _internal_output_classes = list(last_sk_m.get_output_classes(last_sk_obj))\n        if class_labels is None:\n            class_labels = _internal_output_classes\n        output_features = _fm.process_or_validate_classifier_output_features(output_feature_names, class_labels, supports_output_scores)\n    elif overall_mode == 'regressor':\n        if output_feature_names is None:\n            output_features = [('prediction', datatypes.Double())]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Double())]\n        else:\n            raise TypeError('For a regressor object or regressor pipeline, the output_features needs to be None or a string for the predicted value.')\n    else:\n        final_output_dimension = last_sk_m.update_dimension(last_sk_obj, current_num_dimensions)\n        if output_feature_names is None:\n            output_features = [('transformed_features', datatypes.Array(final_output_dimension))]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Array(final_output_dimension))]\n        else:\n            raise TypeError('For a transformer object or transformer pipeline, the output_features needs to be None or a string for the name of the transformed value.')\n    last_spec = last_sk_m.convert(last_sk_obj, current_input_features, output_features)._spec\n    pipeline_list.append(Output(last_spec, current_input_features, output_features))\n    if len(pipeline_list) == 1:\n        return pipeline_list[0].spec\n    original_input_features = pipeline_list[0].input_features\n    if overall_mode == 'regressor':\n        pipeline = PipelineRegressor(original_input_features, output_features)\n    elif overall_mode == 'classifier':\n        pipeline = PipelineClassifier(original_input_features, class_labels, output_features)\n    else:\n        pipeline = Pipeline(original_input_features, output_features)\n    for (spec, input_features, output_features) in pipeline_list:\n        pipeline.add_model(spec)\n    return pipeline.spec",
        "mutated": [
            "def _convert_sklearn_model(input_sk_obj, input_features=None, output_feature_names=None, class_labels=None):\n    if False:\n        i = 10\n    '\\n    Converts a generic sklearn pipeline, transformer, classifier, or regressor\\n    into an coreML specification.\\n    '\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    if input_features is None:\n        input_features = 'input'\n    if isinstance(input_sk_obj, sk_Pipeline):\n        sk_obj_list = input_sk_obj.steps\n    else:\n        sk_obj_list = [('SKObj', input_sk_obj)]\n    if len(sk_obj_list) == 0:\n        raise ValueError('No SKLearn transformers supplied.')\n    pipeline_list = []\n    Input = _namedtuple('InputTransformer', ['name', 'sk_obj', 'module'])\n    Output = _namedtuple('CoreMLTransformer', ['spec', 'input_features', 'output_features'])\n    obj_list = [Input(sk_obj_name, sk_obj, _get_converter_module(sk_obj)) for (sk_obj_name, sk_obj) in sk_obj_list]\n    if isinstance(obj_list[0].sk_obj, _dict_vectorizer.sklearn_class):\n        dv_obj = obj_list[0].sk_obj\n        output_dim = len(_dict_vectorizer.get_input_feature_names(dv_obj))\n        if not isinstance(input_features, _string_types):\n            raise TypeError('If the first transformer in a pipeline is a DictVectorizer, then the input feature must be the name of the input dictionary.')\n        input_features = [(input_features, datatypes.Dictionary(str))]\n        if len(obj_list) > 1:\n            output_feature_name = _PIPELINE_INTERNAL_FEATURE_NAME\n        elif output_feature_names is None:\n            output_feature_name = 'transformed_features'\n        elif isinstance(output_feature_names, _string_types):\n            output_feature_name = output_feature_names\n        else:\n            raise TypeError('For a transformer pipeline, the output_features needs to be None or a string for the predicted value.')\n        output_features = [(output_feature_name, datatypes.Array(output_dim))]\n        spec = _dict_vectorizer.convert(dv_obj, input_features, output_features)._spec\n        pipeline_list.append(Output(spec, input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = output_dim\n        if len(obj_list) == 1:\n            return spec\n        else:\n            del obj_list[0]\n    else:\n        first_sk_obj = obj_list[0].sk_obj\n        num_dimensions = _get_converter_module(first_sk_obj).get_input_dimension(first_sk_obj)\n        features = _fm.process_or_validate_features(input_features, num_dimensions)\n        current_num_dimensions = _fm.dimension_of_array_features(features)\n        if len(features) == 1 and isinstance(features[0][1], datatypes.Array):\n            current_input_features = features\n        else:\n            (spec, _output_dimension) = create_feature_vectorizer(features, _PIPELINE_INTERNAL_FEATURE_NAME)\n            assert _output_dimension == current_num_dimensions\n            ft_out_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(current_num_dimensions))]\n            pipeline_list.append(Output(spec, features, ft_out_features))\n            current_input_features = ft_out_features\n    for (i, (_, _, m)) in enumerate(obj_list[:-1]):\n        if m.model_type != 'transformer':\n            raise ValueError('Only a sequence of transformer classes followed by a single transformer, regressor, or classifier is currently supported. (object in position %d interpreted as %s)' % (i, m.model_type))\n    overall_mode = obj_list[-1].module.model_type\n    assert overall_mode in ('transformer', 'regressor', 'classifier')\n    for (_, sk_obj, sk_m) in obj_list[:-1]:\n        next_dimension = sk_m.update_dimension(sk_obj, current_num_dimensions)\n        output_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(next_dimension))]\n        spec = sk_m.convert(sk_obj, current_input_features, output_features)._spec\n        pipeline_list.append(Output(spec, current_input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = next_dimension\n    (_, last_sk_obj, last_sk_m) = obj_list[-1]\n    if overall_mode == 'classifier':\n        supports_output_scores = last_sk_m.supports_output_scores(last_sk_obj)\n        _internal_output_classes = list(last_sk_m.get_output_classes(last_sk_obj))\n        if class_labels is None:\n            class_labels = _internal_output_classes\n        output_features = _fm.process_or_validate_classifier_output_features(output_feature_names, class_labels, supports_output_scores)\n    elif overall_mode == 'regressor':\n        if output_feature_names is None:\n            output_features = [('prediction', datatypes.Double())]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Double())]\n        else:\n            raise TypeError('For a regressor object or regressor pipeline, the output_features needs to be None or a string for the predicted value.')\n    else:\n        final_output_dimension = last_sk_m.update_dimension(last_sk_obj, current_num_dimensions)\n        if output_feature_names is None:\n            output_features = [('transformed_features', datatypes.Array(final_output_dimension))]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Array(final_output_dimension))]\n        else:\n            raise TypeError('For a transformer object or transformer pipeline, the output_features needs to be None or a string for the name of the transformed value.')\n    last_spec = last_sk_m.convert(last_sk_obj, current_input_features, output_features)._spec\n    pipeline_list.append(Output(last_spec, current_input_features, output_features))\n    if len(pipeline_list) == 1:\n        return pipeline_list[0].spec\n    original_input_features = pipeline_list[0].input_features\n    if overall_mode == 'regressor':\n        pipeline = PipelineRegressor(original_input_features, output_features)\n    elif overall_mode == 'classifier':\n        pipeline = PipelineClassifier(original_input_features, class_labels, output_features)\n    else:\n        pipeline = Pipeline(original_input_features, output_features)\n    for (spec, input_features, output_features) in pipeline_list:\n        pipeline.add_model(spec)\n    return pipeline.spec",
            "def _convert_sklearn_model(input_sk_obj, input_features=None, output_feature_names=None, class_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Converts a generic sklearn pipeline, transformer, classifier, or regressor\\n    into an coreML specification.\\n    '\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    if input_features is None:\n        input_features = 'input'\n    if isinstance(input_sk_obj, sk_Pipeline):\n        sk_obj_list = input_sk_obj.steps\n    else:\n        sk_obj_list = [('SKObj', input_sk_obj)]\n    if len(sk_obj_list) == 0:\n        raise ValueError('No SKLearn transformers supplied.')\n    pipeline_list = []\n    Input = _namedtuple('InputTransformer', ['name', 'sk_obj', 'module'])\n    Output = _namedtuple('CoreMLTransformer', ['spec', 'input_features', 'output_features'])\n    obj_list = [Input(sk_obj_name, sk_obj, _get_converter_module(sk_obj)) for (sk_obj_name, sk_obj) in sk_obj_list]\n    if isinstance(obj_list[0].sk_obj, _dict_vectorizer.sklearn_class):\n        dv_obj = obj_list[0].sk_obj\n        output_dim = len(_dict_vectorizer.get_input_feature_names(dv_obj))\n        if not isinstance(input_features, _string_types):\n            raise TypeError('If the first transformer in a pipeline is a DictVectorizer, then the input feature must be the name of the input dictionary.')\n        input_features = [(input_features, datatypes.Dictionary(str))]\n        if len(obj_list) > 1:\n            output_feature_name = _PIPELINE_INTERNAL_FEATURE_NAME\n        elif output_feature_names is None:\n            output_feature_name = 'transformed_features'\n        elif isinstance(output_feature_names, _string_types):\n            output_feature_name = output_feature_names\n        else:\n            raise TypeError('For a transformer pipeline, the output_features needs to be None or a string for the predicted value.')\n        output_features = [(output_feature_name, datatypes.Array(output_dim))]\n        spec = _dict_vectorizer.convert(dv_obj, input_features, output_features)._spec\n        pipeline_list.append(Output(spec, input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = output_dim\n        if len(obj_list) == 1:\n            return spec\n        else:\n            del obj_list[0]\n    else:\n        first_sk_obj = obj_list[0].sk_obj\n        num_dimensions = _get_converter_module(first_sk_obj).get_input_dimension(first_sk_obj)\n        features = _fm.process_or_validate_features(input_features, num_dimensions)\n        current_num_dimensions = _fm.dimension_of_array_features(features)\n        if len(features) == 1 and isinstance(features[0][1], datatypes.Array):\n            current_input_features = features\n        else:\n            (spec, _output_dimension) = create_feature_vectorizer(features, _PIPELINE_INTERNAL_FEATURE_NAME)\n            assert _output_dimension == current_num_dimensions\n            ft_out_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(current_num_dimensions))]\n            pipeline_list.append(Output(spec, features, ft_out_features))\n            current_input_features = ft_out_features\n    for (i, (_, _, m)) in enumerate(obj_list[:-1]):\n        if m.model_type != 'transformer':\n            raise ValueError('Only a sequence of transformer classes followed by a single transformer, regressor, or classifier is currently supported. (object in position %d interpreted as %s)' % (i, m.model_type))\n    overall_mode = obj_list[-1].module.model_type\n    assert overall_mode in ('transformer', 'regressor', 'classifier')\n    for (_, sk_obj, sk_m) in obj_list[:-1]:\n        next_dimension = sk_m.update_dimension(sk_obj, current_num_dimensions)\n        output_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(next_dimension))]\n        spec = sk_m.convert(sk_obj, current_input_features, output_features)._spec\n        pipeline_list.append(Output(spec, current_input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = next_dimension\n    (_, last_sk_obj, last_sk_m) = obj_list[-1]\n    if overall_mode == 'classifier':\n        supports_output_scores = last_sk_m.supports_output_scores(last_sk_obj)\n        _internal_output_classes = list(last_sk_m.get_output_classes(last_sk_obj))\n        if class_labels is None:\n            class_labels = _internal_output_classes\n        output_features = _fm.process_or_validate_classifier_output_features(output_feature_names, class_labels, supports_output_scores)\n    elif overall_mode == 'regressor':\n        if output_feature_names is None:\n            output_features = [('prediction', datatypes.Double())]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Double())]\n        else:\n            raise TypeError('For a regressor object or regressor pipeline, the output_features needs to be None or a string for the predicted value.')\n    else:\n        final_output_dimension = last_sk_m.update_dimension(last_sk_obj, current_num_dimensions)\n        if output_feature_names is None:\n            output_features = [('transformed_features', datatypes.Array(final_output_dimension))]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Array(final_output_dimension))]\n        else:\n            raise TypeError('For a transformer object or transformer pipeline, the output_features needs to be None or a string for the name of the transformed value.')\n    last_spec = last_sk_m.convert(last_sk_obj, current_input_features, output_features)._spec\n    pipeline_list.append(Output(last_spec, current_input_features, output_features))\n    if len(pipeline_list) == 1:\n        return pipeline_list[0].spec\n    original_input_features = pipeline_list[0].input_features\n    if overall_mode == 'regressor':\n        pipeline = PipelineRegressor(original_input_features, output_features)\n    elif overall_mode == 'classifier':\n        pipeline = PipelineClassifier(original_input_features, class_labels, output_features)\n    else:\n        pipeline = Pipeline(original_input_features, output_features)\n    for (spec, input_features, output_features) in pipeline_list:\n        pipeline.add_model(spec)\n    return pipeline.spec",
            "def _convert_sklearn_model(input_sk_obj, input_features=None, output_feature_names=None, class_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Converts a generic sklearn pipeline, transformer, classifier, or regressor\\n    into an coreML specification.\\n    '\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    if input_features is None:\n        input_features = 'input'\n    if isinstance(input_sk_obj, sk_Pipeline):\n        sk_obj_list = input_sk_obj.steps\n    else:\n        sk_obj_list = [('SKObj', input_sk_obj)]\n    if len(sk_obj_list) == 0:\n        raise ValueError('No SKLearn transformers supplied.')\n    pipeline_list = []\n    Input = _namedtuple('InputTransformer', ['name', 'sk_obj', 'module'])\n    Output = _namedtuple('CoreMLTransformer', ['spec', 'input_features', 'output_features'])\n    obj_list = [Input(sk_obj_name, sk_obj, _get_converter_module(sk_obj)) for (sk_obj_name, sk_obj) in sk_obj_list]\n    if isinstance(obj_list[0].sk_obj, _dict_vectorizer.sklearn_class):\n        dv_obj = obj_list[0].sk_obj\n        output_dim = len(_dict_vectorizer.get_input_feature_names(dv_obj))\n        if not isinstance(input_features, _string_types):\n            raise TypeError('If the first transformer in a pipeline is a DictVectorizer, then the input feature must be the name of the input dictionary.')\n        input_features = [(input_features, datatypes.Dictionary(str))]\n        if len(obj_list) > 1:\n            output_feature_name = _PIPELINE_INTERNAL_FEATURE_NAME\n        elif output_feature_names is None:\n            output_feature_name = 'transformed_features'\n        elif isinstance(output_feature_names, _string_types):\n            output_feature_name = output_feature_names\n        else:\n            raise TypeError('For a transformer pipeline, the output_features needs to be None or a string for the predicted value.')\n        output_features = [(output_feature_name, datatypes.Array(output_dim))]\n        spec = _dict_vectorizer.convert(dv_obj, input_features, output_features)._spec\n        pipeline_list.append(Output(spec, input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = output_dim\n        if len(obj_list) == 1:\n            return spec\n        else:\n            del obj_list[0]\n    else:\n        first_sk_obj = obj_list[0].sk_obj\n        num_dimensions = _get_converter_module(first_sk_obj).get_input_dimension(first_sk_obj)\n        features = _fm.process_or_validate_features(input_features, num_dimensions)\n        current_num_dimensions = _fm.dimension_of_array_features(features)\n        if len(features) == 1 and isinstance(features[0][1], datatypes.Array):\n            current_input_features = features\n        else:\n            (spec, _output_dimension) = create_feature_vectorizer(features, _PIPELINE_INTERNAL_FEATURE_NAME)\n            assert _output_dimension == current_num_dimensions\n            ft_out_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(current_num_dimensions))]\n            pipeline_list.append(Output(spec, features, ft_out_features))\n            current_input_features = ft_out_features\n    for (i, (_, _, m)) in enumerate(obj_list[:-1]):\n        if m.model_type != 'transformer':\n            raise ValueError('Only a sequence of transformer classes followed by a single transformer, regressor, or classifier is currently supported. (object in position %d interpreted as %s)' % (i, m.model_type))\n    overall_mode = obj_list[-1].module.model_type\n    assert overall_mode in ('transformer', 'regressor', 'classifier')\n    for (_, sk_obj, sk_m) in obj_list[:-1]:\n        next_dimension = sk_m.update_dimension(sk_obj, current_num_dimensions)\n        output_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(next_dimension))]\n        spec = sk_m.convert(sk_obj, current_input_features, output_features)._spec\n        pipeline_list.append(Output(spec, current_input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = next_dimension\n    (_, last_sk_obj, last_sk_m) = obj_list[-1]\n    if overall_mode == 'classifier':\n        supports_output_scores = last_sk_m.supports_output_scores(last_sk_obj)\n        _internal_output_classes = list(last_sk_m.get_output_classes(last_sk_obj))\n        if class_labels is None:\n            class_labels = _internal_output_classes\n        output_features = _fm.process_or_validate_classifier_output_features(output_feature_names, class_labels, supports_output_scores)\n    elif overall_mode == 'regressor':\n        if output_feature_names is None:\n            output_features = [('prediction', datatypes.Double())]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Double())]\n        else:\n            raise TypeError('For a regressor object or regressor pipeline, the output_features needs to be None or a string for the predicted value.')\n    else:\n        final_output_dimension = last_sk_m.update_dimension(last_sk_obj, current_num_dimensions)\n        if output_feature_names is None:\n            output_features = [('transformed_features', datatypes.Array(final_output_dimension))]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Array(final_output_dimension))]\n        else:\n            raise TypeError('For a transformer object or transformer pipeline, the output_features needs to be None or a string for the name of the transformed value.')\n    last_spec = last_sk_m.convert(last_sk_obj, current_input_features, output_features)._spec\n    pipeline_list.append(Output(last_spec, current_input_features, output_features))\n    if len(pipeline_list) == 1:\n        return pipeline_list[0].spec\n    original_input_features = pipeline_list[0].input_features\n    if overall_mode == 'regressor':\n        pipeline = PipelineRegressor(original_input_features, output_features)\n    elif overall_mode == 'classifier':\n        pipeline = PipelineClassifier(original_input_features, class_labels, output_features)\n    else:\n        pipeline = Pipeline(original_input_features, output_features)\n    for (spec, input_features, output_features) in pipeline_list:\n        pipeline.add_model(spec)\n    return pipeline.spec",
            "def _convert_sklearn_model(input_sk_obj, input_features=None, output_feature_names=None, class_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Converts a generic sklearn pipeline, transformer, classifier, or regressor\\n    into an coreML specification.\\n    '\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    if input_features is None:\n        input_features = 'input'\n    if isinstance(input_sk_obj, sk_Pipeline):\n        sk_obj_list = input_sk_obj.steps\n    else:\n        sk_obj_list = [('SKObj', input_sk_obj)]\n    if len(sk_obj_list) == 0:\n        raise ValueError('No SKLearn transformers supplied.')\n    pipeline_list = []\n    Input = _namedtuple('InputTransformer', ['name', 'sk_obj', 'module'])\n    Output = _namedtuple('CoreMLTransformer', ['spec', 'input_features', 'output_features'])\n    obj_list = [Input(sk_obj_name, sk_obj, _get_converter_module(sk_obj)) for (sk_obj_name, sk_obj) in sk_obj_list]\n    if isinstance(obj_list[0].sk_obj, _dict_vectorizer.sklearn_class):\n        dv_obj = obj_list[0].sk_obj\n        output_dim = len(_dict_vectorizer.get_input_feature_names(dv_obj))\n        if not isinstance(input_features, _string_types):\n            raise TypeError('If the first transformer in a pipeline is a DictVectorizer, then the input feature must be the name of the input dictionary.')\n        input_features = [(input_features, datatypes.Dictionary(str))]\n        if len(obj_list) > 1:\n            output_feature_name = _PIPELINE_INTERNAL_FEATURE_NAME\n        elif output_feature_names is None:\n            output_feature_name = 'transformed_features'\n        elif isinstance(output_feature_names, _string_types):\n            output_feature_name = output_feature_names\n        else:\n            raise TypeError('For a transformer pipeline, the output_features needs to be None or a string for the predicted value.')\n        output_features = [(output_feature_name, datatypes.Array(output_dim))]\n        spec = _dict_vectorizer.convert(dv_obj, input_features, output_features)._spec\n        pipeline_list.append(Output(spec, input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = output_dim\n        if len(obj_list) == 1:\n            return spec\n        else:\n            del obj_list[0]\n    else:\n        first_sk_obj = obj_list[0].sk_obj\n        num_dimensions = _get_converter_module(first_sk_obj).get_input_dimension(first_sk_obj)\n        features = _fm.process_or_validate_features(input_features, num_dimensions)\n        current_num_dimensions = _fm.dimension_of_array_features(features)\n        if len(features) == 1 and isinstance(features[0][1], datatypes.Array):\n            current_input_features = features\n        else:\n            (spec, _output_dimension) = create_feature_vectorizer(features, _PIPELINE_INTERNAL_FEATURE_NAME)\n            assert _output_dimension == current_num_dimensions\n            ft_out_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(current_num_dimensions))]\n            pipeline_list.append(Output(spec, features, ft_out_features))\n            current_input_features = ft_out_features\n    for (i, (_, _, m)) in enumerate(obj_list[:-1]):\n        if m.model_type != 'transformer':\n            raise ValueError('Only a sequence of transformer classes followed by a single transformer, regressor, or classifier is currently supported. (object in position %d interpreted as %s)' % (i, m.model_type))\n    overall_mode = obj_list[-1].module.model_type\n    assert overall_mode in ('transformer', 'regressor', 'classifier')\n    for (_, sk_obj, sk_m) in obj_list[:-1]:\n        next_dimension = sk_m.update_dimension(sk_obj, current_num_dimensions)\n        output_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(next_dimension))]\n        spec = sk_m.convert(sk_obj, current_input_features, output_features)._spec\n        pipeline_list.append(Output(spec, current_input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = next_dimension\n    (_, last_sk_obj, last_sk_m) = obj_list[-1]\n    if overall_mode == 'classifier':\n        supports_output_scores = last_sk_m.supports_output_scores(last_sk_obj)\n        _internal_output_classes = list(last_sk_m.get_output_classes(last_sk_obj))\n        if class_labels is None:\n            class_labels = _internal_output_classes\n        output_features = _fm.process_or_validate_classifier_output_features(output_feature_names, class_labels, supports_output_scores)\n    elif overall_mode == 'regressor':\n        if output_feature_names is None:\n            output_features = [('prediction', datatypes.Double())]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Double())]\n        else:\n            raise TypeError('For a regressor object or regressor pipeline, the output_features needs to be None or a string for the predicted value.')\n    else:\n        final_output_dimension = last_sk_m.update_dimension(last_sk_obj, current_num_dimensions)\n        if output_feature_names is None:\n            output_features = [('transformed_features', datatypes.Array(final_output_dimension))]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Array(final_output_dimension))]\n        else:\n            raise TypeError('For a transformer object or transformer pipeline, the output_features needs to be None or a string for the name of the transformed value.')\n    last_spec = last_sk_m.convert(last_sk_obj, current_input_features, output_features)._spec\n    pipeline_list.append(Output(last_spec, current_input_features, output_features))\n    if len(pipeline_list) == 1:\n        return pipeline_list[0].spec\n    original_input_features = pipeline_list[0].input_features\n    if overall_mode == 'regressor':\n        pipeline = PipelineRegressor(original_input_features, output_features)\n    elif overall_mode == 'classifier':\n        pipeline = PipelineClassifier(original_input_features, class_labels, output_features)\n    else:\n        pipeline = Pipeline(original_input_features, output_features)\n    for (spec, input_features, output_features) in pipeline_list:\n        pipeline.add_model(spec)\n    return pipeline.spec",
            "def _convert_sklearn_model(input_sk_obj, input_features=None, output_feature_names=None, class_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Converts a generic sklearn pipeline, transformer, classifier, or regressor\\n    into an coreML specification.\\n    '\n    if not _HAS_SKLEARN:\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n    from sklearn.pipeline import Pipeline as sk_Pipeline\n    if input_features is None:\n        input_features = 'input'\n    if isinstance(input_sk_obj, sk_Pipeline):\n        sk_obj_list = input_sk_obj.steps\n    else:\n        sk_obj_list = [('SKObj', input_sk_obj)]\n    if len(sk_obj_list) == 0:\n        raise ValueError('No SKLearn transformers supplied.')\n    pipeline_list = []\n    Input = _namedtuple('InputTransformer', ['name', 'sk_obj', 'module'])\n    Output = _namedtuple('CoreMLTransformer', ['spec', 'input_features', 'output_features'])\n    obj_list = [Input(sk_obj_name, sk_obj, _get_converter_module(sk_obj)) for (sk_obj_name, sk_obj) in sk_obj_list]\n    if isinstance(obj_list[0].sk_obj, _dict_vectorizer.sklearn_class):\n        dv_obj = obj_list[0].sk_obj\n        output_dim = len(_dict_vectorizer.get_input_feature_names(dv_obj))\n        if not isinstance(input_features, _string_types):\n            raise TypeError('If the first transformer in a pipeline is a DictVectorizer, then the input feature must be the name of the input dictionary.')\n        input_features = [(input_features, datatypes.Dictionary(str))]\n        if len(obj_list) > 1:\n            output_feature_name = _PIPELINE_INTERNAL_FEATURE_NAME\n        elif output_feature_names is None:\n            output_feature_name = 'transformed_features'\n        elif isinstance(output_feature_names, _string_types):\n            output_feature_name = output_feature_names\n        else:\n            raise TypeError('For a transformer pipeline, the output_features needs to be None or a string for the predicted value.')\n        output_features = [(output_feature_name, datatypes.Array(output_dim))]\n        spec = _dict_vectorizer.convert(dv_obj, input_features, output_features)._spec\n        pipeline_list.append(Output(spec, input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = output_dim\n        if len(obj_list) == 1:\n            return spec\n        else:\n            del obj_list[0]\n    else:\n        first_sk_obj = obj_list[0].sk_obj\n        num_dimensions = _get_converter_module(first_sk_obj).get_input_dimension(first_sk_obj)\n        features = _fm.process_or_validate_features(input_features, num_dimensions)\n        current_num_dimensions = _fm.dimension_of_array_features(features)\n        if len(features) == 1 and isinstance(features[0][1], datatypes.Array):\n            current_input_features = features\n        else:\n            (spec, _output_dimension) = create_feature_vectorizer(features, _PIPELINE_INTERNAL_FEATURE_NAME)\n            assert _output_dimension == current_num_dimensions\n            ft_out_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(current_num_dimensions))]\n            pipeline_list.append(Output(spec, features, ft_out_features))\n            current_input_features = ft_out_features\n    for (i, (_, _, m)) in enumerate(obj_list[:-1]):\n        if m.model_type != 'transformer':\n            raise ValueError('Only a sequence of transformer classes followed by a single transformer, regressor, or classifier is currently supported. (object in position %d interpreted as %s)' % (i, m.model_type))\n    overall_mode = obj_list[-1].module.model_type\n    assert overall_mode in ('transformer', 'regressor', 'classifier')\n    for (_, sk_obj, sk_m) in obj_list[:-1]:\n        next_dimension = sk_m.update_dimension(sk_obj, current_num_dimensions)\n        output_features = [(_PIPELINE_INTERNAL_FEATURE_NAME, datatypes.Array(next_dimension))]\n        spec = sk_m.convert(sk_obj, current_input_features, output_features)._spec\n        pipeline_list.append(Output(spec, current_input_features, output_features))\n        current_input_features = output_features\n        current_num_dimensions = next_dimension\n    (_, last_sk_obj, last_sk_m) = obj_list[-1]\n    if overall_mode == 'classifier':\n        supports_output_scores = last_sk_m.supports_output_scores(last_sk_obj)\n        _internal_output_classes = list(last_sk_m.get_output_classes(last_sk_obj))\n        if class_labels is None:\n            class_labels = _internal_output_classes\n        output_features = _fm.process_or_validate_classifier_output_features(output_feature_names, class_labels, supports_output_scores)\n    elif overall_mode == 'regressor':\n        if output_feature_names is None:\n            output_features = [('prediction', datatypes.Double())]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Double())]\n        else:\n            raise TypeError('For a regressor object or regressor pipeline, the output_features needs to be None or a string for the predicted value.')\n    else:\n        final_output_dimension = last_sk_m.update_dimension(last_sk_obj, current_num_dimensions)\n        if output_feature_names is None:\n            output_features = [('transformed_features', datatypes.Array(final_output_dimension))]\n        elif isinstance(output_feature_names, _string_types):\n            output_features = [(output_feature_names, datatypes.Array(final_output_dimension))]\n        else:\n            raise TypeError('For a transformer object or transformer pipeline, the output_features needs to be None or a string for the name of the transformed value.')\n    last_spec = last_sk_m.convert(last_sk_obj, current_input_features, output_features)._spec\n    pipeline_list.append(Output(last_spec, current_input_features, output_features))\n    if len(pipeline_list) == 1:\n        return pipeline_list[0].spec\n    original_input_features = pipeline_list[0].input_features\n    if overall_mode == 'regressor':\n        pipeline = PipelineRegressor(original_input_features, output_features)\n    elif overall_mode == 'classifier':\n        pipeline = PipelineClassifier(original_input_features, class_labels, output_features)\n    else:\n        pipeline = Pipeline(original_input_features, output_features)\n    for (spec, input_features, output_features) in pipeline_list:\n        pipeline.add_model(spec)\n    return pipeline.spec"
        ]
    }
]