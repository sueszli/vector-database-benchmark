import argparse
import yaml
from eager_gen import BaseAPI
indent = '  '
eager_header_include = '// Generated by paddle/fluid/prim/api/auto_code_generated/tensor_operants_gen.py\n\n#pragma once\n\n#include "paddle/phi/api/include/operants_base.h"\n#include "paddle/phi/api/include/tensor.h"\n#include "paddle/phi/common/scalar.h"\n#include "paddle/phi/common/int_array.h"\n#include "paddle/phi/core/macros.h"\n#include "paddle/utils/test_macros.h"\n\n'
eager_header_start = '\nnamespace paddle {\n\nnamespace prim {\n\nusing Tensor = paddle::Tensor;\nusing Scalar = paddle::experimental::Scalar;\nusing IntArray = paddle::experimental::IntArray;\nusing TensorOperantsBase = paddle::operants::TensorOperantsBase;\n\nclass TEST_API EagerTensorOperants : public TensorOperantsBase {\n private:\n  DISABLE_COPY_AND_ASSIGN(EagerTensorOperants);\n\n public:\n  EagerTensorOperants() = default;\n\n  Tensor add(const Tensor& x, const Scalar& y);\n\n  Tensor subtract(const Tensor& x, const Scalar& y);\n\n  Tensor multiply(const Tensor& x, const Scalar& y);\n\n  Tensor divide(const Tensor& x, const Scalar& y);\n\n  Tensor add(const Scalar& x, const Tensor& y);\n\n  Tensor subtract(const Scalar& x, const Tensor& y);\n\n  Tensor multiply(const Scalar& x, const Tensor& y);\n\n  Tensor divide(const Scalar& x, const Tensor& y);\n\n  Tensor pow(const Tensor& x, const Tensor& y);\n\n  Tensor pow(const Tensor& x, const Scalar& y);\n\n'
eager_header_end = '};\n\n}  // namespace prim\n}  // namespace paddle\n\n'
eager_source_include = '// Generated by paddle/fluid/prim/api/auto_code_generated/tensor_operants_gen.py\n\n#include "paddle/fluid/prim/utils/eager/eager_tensor_operants.h"\n\n#include "paddle/fluid/eager/api/generated/eager_generated/forwards/dygraph_functions.h"\n\n'
eager_source_start = '\nnamespace paddle {\n\nnamespace prim {\n\nTensor EagerTensorOperants::add(const Tensor& x, const Scalar& y) {\n  return ::add_ad_func(x, ::full_like_ad_func(x, y));\n}\n\nTensor EagerTensorOperants::subtract(const Tensor& x, const Scalar& y) {\n  return ::subtract_ad_func(x, ::full_like_ad_func(x, y));\n}\n\nTensor EagerTensorOperants::multiply(const Tensor& x, const Scalar& y) {\n  return ::scale_ad_func(x, y, 0.0f, true);\n}\n\nTensor EagerTensorOperants::divide(const Tensor& x, const Scalar& y) {\n  return ::divide_ad_func(x, ::full_like_ad_func(x, y));\n}\n\nTensor EagerTensorOperants::add(const Scalar& x, const Tensor& y) {\n  return ::add_ad_func(::full_like_ad_func(y, x), y);\n}\n\nTensor EagerTensorOperants::subtract(const Scalar& x, const Tensor& y) {\n  return ::subtract_ad_func(::full_like_ad_func(y, x), y);\n}\n\nTensor EagerTensorOperants::multiply(const Scalar& x, const Tensor& y) {\n  return ::scale_ad_func(y, x, 0.0f, true);\n}\n\nTensor EagerTensorOperants::divide(const Scalar& x, const Tensor& y) {\n  return ::divide_ad_func(::full_like_ad_func(y, x), y);\n}\n\nTensor EagerTensorOperants::pow(const Tensor& x, const Tensor& y) {\n  return ::elementwise_pow_ad_func(x, y);\n}\n\nTensor EagerTensorOperants::pow(const Tensor& x, const Scalar& y) {\n  return ::elementwise_pow_ad_func(x, ::full_like_ad_func(x, y));\n}\n\n'
eager_source_end = '\n}  // namespace prim\n}  // namespace paddle\n\n'
static_header_include = '// Generated by paddle/fluid/prim/api/auto_code_generated/tensor_operants_gen.py\n\n#pragma once\n\n#include "paddle/phi/api/include/operants_base.h"\n#include "paddle/phi/api/include/tensor.h"\n#include "paddle/phi/common/scalar.h"\n#include "paddle/phi/common/int_array.h"\n#include "paddle/phi/core/macros.h"\n#include "paddle/utils/test_macros.h"\n'
static_header_start = '\nnamespace paddle {\n\nnamespace prim {\n\nusing Tensor = paddle::Tensor;\nusing Scalar = paddle::experimental::Scalar;\nusing IntArray = paddle::experimental::IntArray;\nusing TensorOperantsBase = paddle::operants::TensorOperantsBase;\n\nclass TEST_API StaticTensorOperants : public TensorOperantsBase {\n private:\n  DISABLE_COPY_AND_ASSIGN(StaticTensorOperants);\n\n public:\n  StaticTensorOperants() = default;\n\n  Tensor add(const Tensor& x, const Scalar& y);\n\n  Tensor subtract(const Tensor& x, const Scalar& y);\n\n  Tensor multiply(const Tensor& x, const Scalar& y);\n\n  Tensor divide(const Tensor& x, const Scalar& y);\n\n  Tensor add(const Scalar& x, const Tensor& y);\n\n  Tensor subtract(const Scalar& x, const Tensor& y);\n\n  Tensor multiply(const Scalar& x, const Tensor& y);\n\n  Tensor divide(const Scalar& x, const Tensor& y);\n\n  Tensor pow(const Tensor& x, const Tensor& y);\n\n  Tensor pow(const Tensor& x, const Scalar& y);\n\n'
static_header_end = '};\n\n}  // namespace prim\n}  // namespace paddle\n\n'
static_source_include = '// Generated by paddle/fluid/prim/api/auto_code_generated/tensor_operants_gen.py\n\n#include "paddle/fluid/prim/utils/static/static_tensor_operants.h"\n\n#include "paddle/fluid/prim/api/generated_prim/prim_generated_api.h"\n#include "paddle/fluid/prim/api/manual_prim/prim_manual_api.h"\n#include "paddle/fluid/prim/utils/static/desc_tensor.h"\n\n#include "paddle/fluid/primitive/backend/backend.h"\n#include "paddle/fluid/primitive/type/lazy_tensor.h"\n\nPHI_DECLARE_bool(enable_pir_api);\n\n'
static_source_start = '\nnamespace paddle {\n\nnamespace prim {\nusing DescTensor = paddle::prim::DescTensor;\nusing LazyTensor = paddle::primitive::LazyTensor;\n\nTensor StaticTensorOperants::add(const Tensor& x, const Scalar& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::add<LazyTensor>(x, paddle::primitive::backend::full<LazyTensor>(x.shape(), y, x.dtype(), x.place()));\n  } else {\n    return paddle::prim::add<DescTensor>(x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));\n  }\n}\n\nTensor StaticTensorOperants::subtract(const Tensor& x, const Scalar& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::subtract<LazyTensor>(x, paddle::primitive::backend::full<LazyTensor>(x.shape(), y, x.dtype(), x.place()));\n  } else {\n    return paddle::prim::subtract<DescTensor>(x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));\n  }\n}\n\nTensor StaticTensorOperants::multiply(const Tensor& x, const Scalar& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::scale<LazyTensor>(x, y, 0.0f, true);\n  } else {\n    return paddle::prim::scale<DescTensor>(x, y, 0.0f, true);\n  }\n}\n\nTensor StaticTensorOperants::divide(const Tensor& x, const Scalar& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::divide<LazyTensor>(x, paddle::primitive::backend::full<LazyTensor>(x.shape(), y, x.dtype(), x.place()));\n  } else {\n    return paddle::prim::divide<DescTensor>(x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));\n  }\n}\n\nTensor StaticTensorOperants::add(const Scalar& x, const Tensor& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::add<LazyTensor>(paddle::primitive::backend::full<LazyTensor>(y.shape(), x, y.dtype(), y.place()), y);\n  } else {\n    return paddle::prim::add<DescTensor>(paddle::prim::full<DescTensor>(y.shape(), x, y.dtype(), y.place()), y);\n  }\n}\n\n\nTensor StaticTensorOperants::subtract(const Scalar& x, const Tensor& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::subtract<LazyTensor>(paddle::primitive::backend::full<LazyTensor>(y.shape(), x, y.dtype(), y.place()), y);\n  } else {\n    return paddle::prim::subtract<DescTensor>(paddle::prim::full<DescTensor>(y.shape(), x, y.dtype(), y.place()), y);\n  }\n}\n\nTensor StaticTensorOperants::multiply(const Scalar& x, const Tensor& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::scale<LazyTensor>(y, x, 0.0f, true);\n  } else {\n    return paddle::prim::scale<DescTensor>(y, x, 0.0f, true);\n  }\n}\n\nTensor StaticTensorOperants::divide(const Scalar& x, const Tensor& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::divide<LazyTensor>(paddle::primitive::backend::full<LazyTensor>(y.shape(), x, y.dtype(), y.place()), y);\n  } else {\n    return paddle::prim::divide<DescTensor>(paddle::prim::full<DescTensor>(y.shape(), x, y.dtype(), y.place()), y);\n  }\n}\n\nTensor StaticTensorOperants::pow(const Tensor& x, const Tensor& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::elementwise_pow<LazyTensor>(x, y);\n  } else {\n    return paddle::prim::elementwise_pow<DescTensor>(x, y);\n  }\n}\n\nTensor StaticTensorOperants::pow(const Tensor& x, const Scalar& y) {\n  if (FLAGS_enable_pir_api) {\n    return paddle::primitive::backend::elementwise_pow<LazyTensor>(x, paddle::primitive::backend::full<LazyTensor>(x.shape(), y, x.dtype(), x.place()));\n  } else {\n    return paddle::prim::elementwise_pow<DescTensor>(x, paddle::prim::full<DescTensor>(x.shape(), y, x.dtype(), x.place()));\n  }\n}\n'
static_source_end = '\n}  // namespace prim\n}  // namespace paddle\n\n'

class PrimTensorAPI(BaseAPI):

    def __init__(self, api_item_yaml, prims=()):
        if False:
            return 10
        super().__init__(api_item_yaml, prims)

    def get_api_func_name(self):
        if False:
            i = 10
            return i + 15
        return self.api

    def gene_tensor_operants_declaration(self):
        if False:
            for i in range(10):
                print('nop')
        api_func_name = self.get_api_func_name()
        if api_func_name[-1] != '_':
            return f'{indent}{self.get_return_type()} {api_func_name}({self.get_declare_args()});\n\n'
        else:
            return f'{indent}{self.get_return_type(inplace_flag=True)} {api_func_name}({self.get_declare_args(inplace_flag=True)});\n\n'

    def get_func_input_args(self, inplace_flag=False):
        if False:
            for i in range(10):
                print('nop')
        input_args = []
        for name in self.inputs['names']:
            name = name.split('@')[0]
            if inplace_flag and name in self.inplace_map.values():
                input_args.append(name)
            else:
                input_args.append(name)
        return input_args

    def get_func_args(self, inplace_flag=False):
        if False:
            print('Hello World!')
        ad_func_args = self.get_func_input_args(inplace_flag)
        for name in self.attrs['names']:
            default_value = ''
            if self.attrs['attr_info'][name][1] is not None:
                default_value = ' = ' + self.attrs['attr_info'][name][1]
            ad_func_args.append(name)
        ad_func_args_str = ', '.join(ad_func_args)
        return ad_func_args_str

    def gene_eager_tensor_func_call(self):
        if False:
            i = 10
            return i + 15
        api_func_name = self.get_api_func_name()
        dygraph_ad_func_name = '::' + api_func_name + '_ad_func'
        dygraph_ad_func_parameters = self.get_func_args()
        return f'return {dygraph_ad_func_name}({dygraph_ad_func_parameters});'

    def gene_eager_tensor_operants_implementation(self):
        if False:
            return 10
        api_func_name = self.get_api_func_name()
        if api_func_name[-1] != '_':
            api_code = f'{self.get_return_type()} EagerTensorOperants::{api_func_name}({self.get_declare_args_nodefault()}) {{'
        else:
            api_code = f'{self.get_return_type(inplace_flag=True)} EagerTensorOperants::{api_func_name}({self.get_declare_args_nodefault(inplace_flag=True)}) {{'
        api_code += f'\n{indent}{self.gene_eager_tensor_func_call()}\n}}\n\n'
        return api_code

    def gene_static_tensor_func_call(self):
        if False:
            print('Hello World!')
        api_func_name = self.get_api_func_name()
        backend_static_func_name = 'paddle::primitive::backend::' + api_func_name + '<LazyTensor>'
        prim_static_func_name = 'paddle::prim::' + api_func_name + '<DescTensor>'
        static_func_parameters = self.get_func_args()
        static_tensor_func_call = f'if (FLAGS_enable_pir_api) {{\n    return {backend_static_func_name}({static_func_parameters});\n  }} else {{\n    return {prim_static_func_name}({static_func_parameters});\n  }}'
        return static_tensor_func_call

    def gene_static_tensor_operants_implementation(self):
        if False:
            while True:
                i = 10
        api_code = ''
        indent = '  '
        api_func_name = self.get_api_func_name()
        if api_func_name[-1] != '_':
            api_code = f'{self.get_return_type()} StaticTensorOperants::{api_func_name}({self.get_declare_args_nodefault()}) {{'
        else:
            api_code = f'{self.get_return_type(inplace_flag=True)} StaticTensorOperants::{api_func_name}({self.get_declare_args_nodefault(inplace_flag=True)}) {{'
        function_call = self.gene_static_tensor_func_call()
        api_code += f'\n{indent}{function_call}\n}}\n\n'
        return api_code

def generate_tensor_operants_api(api_yaml_path, eager_header_path, eager_source_path, static_header_path, static_source_path, api_prim_path):
    if False:
        i = 10
        return i + 15
    apis = []
    for each_api_yaml in api_yaml_path:
        with open(each_api_yaml, 'r') as f:
            api_list = yaml.load(f, Loader=yaml.FullLoader)
            if api_list:
                apis.extend(api_list)
    eager_header_file = open(eager_header_path, 'w')
    eager_source_file = open(eager_source_path, 'w')
    static_header_file = open(static_header_path, 'w')
    static_source_file = open(static_source_path, 'w')
    eager_header_file.write(eager_header_include)
    eager_header_file.write(eager_header_start)
    eager_source_file.write(eager_source_include)
    eager_source_file.write(eager_source_start)
    static_header_file.write(static_header_include)
    static_header_file.write(static_header_start)
    static_source_file.write(static_source_include)
    static_source_file.write(static_source_start)
    with open(api_prim_path, 'rt') as f:
        api_prims = yaml.safe_load(f)
    for api in apis:
        eager_api = PrimTensorAPI(api, api_prims)
        if eager_api.is_prim_api:
            eager_header_file.write(eager_api.gene_tensor_operants_declaration())
            eager_source_file.write(eager_api.gene_eager_tensor_operants_implementation())
            static_header_file.write(eager_api.gene_tensor_operants_declaration())
            static_source_file.write(eager_api.gene_static_tensor_operants_implementation())
    eager_header_file.write(eager_header_end)
    eager_source_file.write(eager_source_end)
    static_header_file.write(static_header_end)
    static_source_file.write(static_source_end)
    eager_header_file.close()
    eager_source_file.close()
    static_header_file.close()
    static_source_file.close()

def main():
    if False:
        return 10
    parser = argparse.ArgumentParser(description='Generate PaddlePaddle C++ API files')
    parser.add_argument('--api_yaml_path', help='path to api yaml file', nargs='+', default=['paddle/phi/api/yaml/ops.yaml'])
    parser.add_argument('--eager_tensor_operants_header_path', help='output of generated eager_tensor_operants header code file', default='paddle/fluid/prim/utils/eager/eager_tensor_operants.h.tmp')
    parser.add_argument('--eager_tensor_operants_source_path', help='output of generated eager_tensor_operants source code file', default='paddle/fluid/prim/utils/eager/eager_tensor_operants.cc.tmp')
    parser.add_argument('--static_tensor_operants_header_path', help='output of generated eager_tensor_operants header code file', default='paddle/fluid/prim/utils/static/static_tensor_operants.h.tmp')
    parser.add_argument('--static_tensor_operants_source_path', help='output of generated eager_tensor_operants source code file', default='paddle/fluid/prim/utils/static/static_tensor_operants.cc.tmp')
    parser.add_argument('--api_prim_yaml_path', help='Primitive API list yaml file.', default='paddle/fluid/prim/api/auto_code_generated/api.yaml')
    options = parser.parse_args()
    api_yaml_path = options.api_yaml_path
    api_prim_yaml_path = options.api_prim_yaml_path
    eager_tensor_operants_header_path = options.eager_tensor_operants_header_path
    eager_tensor_operants_source_path = options.eager_tensor_operants_source_path
    static_tensor_operants_header_path = options.static_tensor_operants_header_path
    static_tensor_operants_source_path = options.static_tensor_operants_source_path
    generate_tensor_operants_api(api_yaml_path, eager_tensor_operants_header_path, eager_tensor_operants_source_path, static_tensor_operants_header_path, static_tensor_operants_source_path, api_prim_yaml_path)
if __name__ == '__main__':
    main()