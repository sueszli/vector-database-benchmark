[
    {
        "func_name": "missing_values_table",
        "original": "def missing_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\nThere are ' + str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values.')\n    return mis_val_table_ren_columns",
        "mutated": [
            "def missing_values_table(df):\n    if False:\n        i = 10\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\nThere are ' + str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values.')\n    return mis_val_table_ren_columns",
            "def missing_values_table(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\nThere are ' + str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values.')\n    return mis_val_table_ren_columns",
            "def missing_values_table(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\nThere are ' + str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values.')\n    return mis_val_table_ren_columns",
            "def missing_values_table(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\nThere are ' + str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values.')\n    return mis_val_table_ren_columns",
            "def missing_values_table(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\nThere are ' + str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values.')\n    return mis_val_table_ren_columns"
        ]
    },
    {
        "func_name": "corr_func",
        "original": "def corr_func(x, y, **kwargs):\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r), xy=(0.2, 0.8), xycoords=ax.transAxes, size=20)",
        "mutated": [
            "def corr_func(x, y, **kwargs):\n    if False:\n        i = 10\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r), xy=(0.2, 0.8), xycoords=ax.transAxes, size=20)",
            "def corr_func(x, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r), xy=(0.2, 0.8), xycoords=ax.transAxes, size=20)",
            "def corr_func(x, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r), xy=(0.2, 0.8), xycoords=ax.transAxes, size=20)",
            "def corr_func(x, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r), xy=(0.2, 0.8), xycoords=ax.transAxes, size=20)",
            "def corr_func(x, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r), xy=(0.2, 0.8), xycoords=ax.transAxes, size=20)"
        ]
    },
    {
        "func_name": "plot_feature_importances",
        "original": "def plot_feature_importances(df):\n    df = df.sort_values('importance', ascending=False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    return df",
        "mutated": [
            "def plot_feature_importances(df):\n    if False:\n        i = 10\n    df = df.sort_values('importance', ascending=False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    return df",
            "def plot_feature_importances(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    df = df.sort_values('importance', ascending=False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    return df",
            "def plot_feature_importances(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    df = df.sort_values('importance', ascending=False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    return df",
            "def plot_feature_importances(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    df = df.sort_values('importance', ascending=False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    return df",
            "def plot_feature_importances(df):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    df = df.sort_values('importance', ascending=False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), df['importance_normalized'].head(15), align='center', edgecolor='k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    return df"
        ]
    },
    {
        "func_name": "model",
        "original": "def model(features, test_features, encoding='ohe', n_folds=5):\n    test_ids = test_features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns=['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns=['SK_ID_CURR'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        (features, test_features) = features.align(test_features, join='inner', axis=1)\n        cat_indices = 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for (i, col) in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    feature_names = list(features.columns)\n    features = np.array(features)\n    test_features = np.array(test_features)\n    k_fold = KFold(n_splits=n_folds, shuffle=True, random_state=50)\n    feature_importance_values = np.zeros(len(feature_names))\n    test_predictions = np.zeros(test_features.shape[0])\n    out_of_fold = np.zeros(features.shape[0])\n    valid_scores = []\n    train_scores = []\n    for (train_indices, valid_indices) in k_fold.split(features):\n        (train_features, train_labels) = (features[train_indices], labels[train_indices])\n        (valid_features, valid_labels) = (features[valid_indices], labels[valid_indices])\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary', class_weight='balanced', learning_rate=0.05, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric='auc', eval_set=[(valid_features, valid_labels), (train_features, train_labels)], eval_names=['valid', 'train'], categorical_feature=cat_indices, early_stopping_rounds=100, verbose=200)\n        best_iteration = model.best_iteration_\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        test_predictions += model.predict_proba(test_features, num_iteration=best_iteration)[:, 1] / k_fold.n_splits\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:, 1]\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    metrics = pd.DataFrame({'fold': fold_names, 'train': train_scores, 'valid': valid_scores})\n    return (submission, feature_importances, metrics)",
        "mutated": [
            "def model(features, test_features, encoding='ohe', n_folds=5):\n    if False:\n        i = 10\n    test_ids = test_features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns=['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns=['SK_ID_CURR'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        (features, test_features) = features.align(test_features, join='inner', axis=1)\n        cat_indices = 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for (i, col) in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    feature_names = list(features.columns)\n    features = np.array(features)\n    test_features = np.array(test_features)\n    k_fold = KFold(n_splits=n_folds, shuffle=True, random_state=50)\n    feature_importance_values = np.zeros(len(feature_names))\n    test_predictions = np.zeros(test_features.shape[0])\n    out_of_fold = np.zeros(features.shape[0])\n    valid_scores = []\n    train_scores = []\n    for (train_indices, valid_indices) in k_fold.split(features):\n        (train_features, train_labels) = (features[train_indices], labels[train_indices])\n        (valid_features, valid_labels) = (features[valid_indices], labels[valid_indices])\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary', class_weight='balanced', learning_rate=0.05, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric='auc', eval_set=[(valid_features, valid_labels), (train_features, train_labels)], eval_names=['valid', 'train'], categorical_feature=cat_indices, early_stopping_rounds=100, verbose=200)\n        best_iteration = model.best_iteration_\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        test_predictions += model.predict_proba(test_features, num_iteration=best_iteration)[:, 1] / k_fold.n_splits\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:, 1]\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    metrics = pd.DataFrame({'fold': fold_names, 'train': train_scores, 'valid': valid_scores})\n    return (submission, feature_importances, metrics)",
            "def model(features, test_features, encoding='ohe', n_folds=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    test_ids = test_features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns=['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns=['SK_ID_CURR'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        (features, test_features) = features.align(test_features, join='inner', axis=1)\n        cat_indices = 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for (i, col) in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    feature_names = list(features.columns)\n    features = np.array(features)\n    test_features = np.array(test_features)\n    k_fold = KFold(n_splits=n_folds, shuffle=True, random_state=50)\n    feature_importance_values = np.zeros(len(feature_names))\n    test_predictions = np.zeros(test_features.shape[0])\n    out_of_fold = np.zeros(features.shape[0])\n    valid_scores = []\n    train_scores = []\n    for (train_indices, valid_indices) in k_fold.split(features):\n        (train_features, train_labels) = (features[train_indices], labels[train_indices])\n        (valid_features, valid_labels) = (features[valid_indices], labels[valid_indices])\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary', class_weight='balanced', learning_rate=0.05, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric='auc', eval_set=[(valid_features, valid_labels), (train_features, train_labels)], eval_names=['valid', 'train'], categorical_feature=cat_indices, early_stopping_rounds=100, verbose=200)\n        best_iteration = model.best_iteration_\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        test_predictions += model.predict_proba(test_features, num_iteration=best_iteration)[:, 1] / k_fold.n_splits\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:, 1]\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    metrics = pd.DataFrame({'fold': fold_names, 'train': train_scores, 'valid': valid_scores})\n    return (submission, feature_importances, metrics)",
            "def model(features, test_features, encoding='ohe', n_folds=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    test_ids = test_features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns=['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns=['SK_ID_CURR'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        (features, test_features) = features.align(test_features, join='inner', axis=1)\n        cat_indices = 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for (i, col) in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    feature_names = list(features.columns)\n    features = np.array(features)\n    test_features = np.array(test_features)\n    k_fold = KFold(n_splits=n_folds, shuffle=True, random_state=50)\n    feature_importance_values = np.zeros(len(feature_names))\n    test_predictions = np.zeros(test_features.shape[0])\n    out_of_fold = np.zeros(features.shape[0])\n    valid_scores = []\n    train_scores = []\n    for (train_indices, valid_indices) in k_fold.split(features):\n        (train_features, train_labels) = (features[train_indices], labels[train_indices])\n        (valid_features, valid_labels) = (features[valid_indices], labels[valid_indices])\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary', class_weight='balanced', learning_rate=0.05, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric='auc', eval_set=[(valid_features, valid_labels), (train_features, train_labels)], eval_names=['valid', 'train'], categorical_feature=cat_indices, early_stopping_rounds=100, verbose=200)\n        best_iteration = model.best_iteration_\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        test_predictions += model.predict_proba(test_features, num_iteration=best_iteration)[:, 1] / k_fold.n_splits\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:, 1]\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    metrics = pd.DataFrame({'fold': fold_names, 'train': train_scores, 'valid': valid_scores})\n    return (submission, feature_importances, metrics)",
            "def model(features, test_features, encoding='ohe', n_folds=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    test_ids = test_features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns=['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns=['SK_ID_CURR'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        (features, test_features) = features.align(test_features, join='inner', axis=1)\n        cat_indices = 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for (i, col) in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    feature_names = list(features.columns)\n    features = np.array(features)\n    test_features = np.array(test_features)\n    k_fold = KFold(n_splits=n_folds, shuffle=True, random_state=50)\n    feature_importance_values = np.zeros(len(feature_names))\n    test_predictions = np.zeros(test_features.shape[0])\n    out_of_fold = np.zeros(features.shape[0])\n    valid_scores = []\n    train_scores = []\n    for (train_indices, valid_indices) in k_fold.split(features):\n        (train_features, train_labels) = (features[train_indices], labels[train_indices])\n        (valid_features, valid_labels) = (features[valid_indices], labels[valid_indices])\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary', class_weight='balanced', learning_rate=0.05, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric='auc', eval_set=[(valid_features, valid_labels), (train_features, train_labels)], eval_names=['valid', 'train'], categorical_feature=cat_indices, early_stopping_rounds=100, verbose=200)\n        best_iteration = model.best_iteration_\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        test_predictions += model.predict_proba(test_features, num_iteration=best_iteration)[:, 1] / k_fold.n_splits\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:, 1]\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    metrics = pd.DataFrame({'fold': fold_names, 'train': train_scores, 'valid': valid_scores})\n    return (submission, feature_importances, metrics)",
            "def model(features, test_features, encoding='ohe', n_folds=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    test_ids = test_features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns=['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns=['SK_ID_CURR'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        (features, test_features) = features.align(test_features, join='inner', axis=1)\n        cat_indices = 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for (i, col) in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    feature_names = list(features.columns)\n    features = np.array(features)\n    test_features = np.array(test_features)\n    k_fold = KFold(n_splits=n_folds, shuffle=True, random_state=50)\n    feature_importance_values = np.zeros(len(feature_names))\n    test_predictions = np.zeros(test_features.shape[0])\n    out_of_fold = np.zeros(features.shape[0])\n    valid_scores = []\n    train_scores = []\n    for (train_indices, valid_indices) in k_fold.split(features):\n        (train_features, train_labels) = (features[train_indices], labels[train_indices])\n        (valid_features, valid_labels) = (features[valid_indices], labels[valid_indices])\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary', class_weight='balanced', learning_rate=0.05, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric='auc', eval_set=[(valid_features, valid_labels), (train_features, train_labels)], eval_names=['valid', 'train'], categorical_feature=cat_indices, early_stopping_rounds=100, verbose=200)\n        best_iteration = model.best_iteration_\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        test_predictions += model.predict_proba(test_features, num_iteration=best_iteration)[:, 1] / k_fold.n_splits\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:, 1]\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    metrics = pd.DataFrame({'fold': fold_names, 'train': train_scores, 'valid': valid_scores})\n    return (submission, feature_importances, metrics)"
        ]
    }
]