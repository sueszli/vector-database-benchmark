[
    {
        "func_name": "sql_functions_c_example",
        "original": "def sql_functions_c_example(spark):\n    df = spark.createDataFrame([(1,), (2,), (3,), (8,)], ['n1'])\n    df.select(cbrt(df.n1).alias('cube-root_value')).show()\n    print('cbrt API finished')\n    df = spark.createDataFrame([(1.1,), (2.6,), (3.3,), (8.7,)], ['n1'])\n    df.select(ceil(df.n1).alias('cube-root_value')).show()\n    print('ceil API finished')\n    cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], ('a', 'b'))\n    cDf.show()\n    cDf.select(coalesce(cDf['a'], cDf['b'])).show()\n    cDf.select('*', coalesce(cDf['a'], lit(0.0))).show()\n    print('coalesce API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(col('n1')).show()\n    print('col API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_list('age')).show()\n    print('collect_list API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_set('age')).show()\n    print('collect_set API finished')\n    df = spark.createDataFrame([([1, 2, 3, 4], [2, 3, 4, 5])], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    print('concat API finished')\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat_ws('-', df.s, df.d).alias('s')).show()\n    print('concat_ws API finished')\n    df = spark.createDataFrame([('010101',)], ['n'])\n    df.select(conv(df.n, 2, 16).alias('hex')).show()\n    print('conv API finished')\n    a = range(20)\n    b = [2 * x for x in range(20)]\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(corr('a', 'b').alias('c')).collect()\n    print('corr API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cos(df.n1)).show()\n    print('cos API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cosh(df.n1)).show()\n    print('cosh API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(count(df.n1)).show()\n    print('count API finished')\n    df = spark.createDataFrame([('1', '3'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    df = spark.createDataFrame([('1', '2'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    print('countDistinct API finished')\n    a = [1] * 10\n    b = [2] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_pop('a', 'b').alias('c')).show()\n    print('covar_pop API finished')\n    a = [1] * 10\n    b = [1] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_samp('a', 'b').alias('c')).collect()\n    print('covar_samp API finished')\n    spark.createDataFrame([('ABC',)], ['a']).select(crc32('a').alias('crc32')).show()\n    print('crc32 API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(create_map('name', 'age').alias('map')).show()\n    print('create_map API finished')\n    from pyspark.sql import Window\n    window = Window.orderBy('name')\n    df.withColumn('cumulative_distribution', cume_dist().over(window)).show()\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_date().alias('date')).show()\n    print('current_date API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_timestamp().alias('timestamp')).show()\n    print('current_timestamp API finished')\n    print('Finish running function_c API')",
        "mutated": [
            "def sql_functions_c_example(spark):\n    if False:\n        i = 10\n    df = spark.createDataFrame([(1,), (2,), (3,), (8,)], ['n1'])\n    df.select(cbrt(df.n1).alias('cube-root_value')).show()\n    print('cbrt API finished')\n    df = spark.createDataFrame([(1.1,), (2.6,), (3.3,), (8.7,)], ['n1'])\n    df.select(ceil(df.n1).alias('cube-root_value')).show()\n    print('ceil API finished')\n    cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], ('a', 'b'))\n    cDf.show()\n    cDf.select(coalesce(cDf['a'], cDf['b'])).show()\n    cDf.select('*', coalesce(cDf['a'], lit(0.0))).show()\n    print('coalesce API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(col('n1')).show()\n    print('col API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_list('age')).show()\n    print('collect_list API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_set('age')).show()\n    print('collect_set API finished')\n    df = spark.createDataFrame([([1, 2, 3, 4], [2, 3, 4, 5])], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    print('concat API finished')\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat_ws('-', df.s, df.d).alias('s')).show()\n    print('concat_ws API finished')\n    df = spark.createDataFrame([('010101',)], ['n'])\n    df.select(conv(df.n, 2, 16).alias('hex')).show()\n    print('conv API finished')\n    a = range(20)\n    b = [2 * x for x in range(20)]\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(corr('a', 'b').alias('c')).collect()\n    print('corr API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cos(df.n1)).show()\n    print('cos API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cosh(df.n1)).show()\n    print('cosh API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(count(df.n1)).show()\n    print('count API finished')\n    df = spark.createDataFrame([('1', '3'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    df = spark.createDataFrame([('1', '2'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    print('countDistinct API finished')\n    a = [1] * 10\n    b = [2] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_pop('a', 'b').alias('c')).show()\n    print('covar_pop API finished')\n    a = [1] * 10\n    b = [1] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_samp('a', 'b').alias('c')).collect()\n    print('covar_samp API finished')\n    spark.createDataFrame([('ABC',)], ['a']).select(crc32('a').alias('crc32')).show()\n    print('crc32 API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(create_map('name', 'age').alias('map')).show()\n    print('create_map API finished')\n    from pyspark.sql import Window\n    window = Window.orderBy('name')\n    df.withColumn('cumulative_distribution', cume_dist().over(window)).show()\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_date().alias('date')).show()\n    print('current_date API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_timestamp().alias('timestamp')).show()\n    print('current_timestamp API finished')\n    print('Finish running function_c API')",
            "def sql_functions_c_example(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    df = spark.createDataFrame([(1,), (2,), (3,), (8,)], ['n1'])\n    df.select(cbrt(df.n1).alias('cube-root_value')).show()\n    print('cbrt API finished')\n    df = spark.createDataFrame([(1.1,), (2.6,), (3.3,), (8.7,)], ['n1'])\n    df.select(ceil(df.n1).alias('cube-root_value')).show()\n    print('ceil API finished')\n    cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], ('a', 'b'))\n    cDf.show()\n    cDf.select(coalesce(cDf['a'], cDf['b'])).show()\n    cDf.select('*', coalesce(cDf['a'], lit(0.0))).show()\n    print('coalesce API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(col('n1')).show()\n    print('col API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_list('age')).show()\n    print('collect_list API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_set('age')).show()\n    print('collect_set API finished')\n    df = spark.createDataFrame([([1, 2, 3, 4], [2, 3, 4, 5])], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    print('concat API finished')\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat_ws('-', df.s, df.d).alias('s')).show()\n    print('concat_ws API finished')\n    df = spark.createDataFrame([('010101',)], ['n'])\n    df.select(conv(df.n, 2, 16).alias('hex')).show()\n    print('conv API finished')\n    a = range(20)\n    b = [2 * x for x in range(20)]\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(corr('a', 'b').alias('c')).collect()\n    print('corr API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cos(df.n1)).show()\n    print('cos API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cosh(df.n1)).show()\n    print('cosh API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(count(df.n1)).show()\n    print('count API finished')\n    df = spark.createDataFrame([('1', '3'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    df = spark.createDataFrame([('1', '2'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    print('countDistinct API finished')\n    a = [1] * 10\n    b = [2] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_pop('a', 'b').alias('c')).show()\n    print('covar_pop API finished')\n    a = [1] * 10\n    b = [1] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_samp('a', 'b').alias('c')).collect()\n    print('covar_samp API finished')\n    spark.createDataFrame([('ABC',)], ['a']).select(crc32('a').alias('crc32')).show()\n    print('crc32 API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(create_map('name', 'age').alias('map')).show()\n    print('create_map API finished')\n    from pyspark.sql import Window\n    window = Window.orderBy('name')\n    df.withColumn('cumulative_distribution', cume_dist().over(window)).show()\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_date().alias('date')).show()\n    print('current_date API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_timestamp().alias('timestamp')).show()\n    print('current_timestamp API finished')\n    print('Finish running function_c API')",
            "def sql_functions_c_example(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    df = spark.createDataFrame([(1,), (2,), (3,), (8,)], ['n1'])\n    df.select(cbrt(df.n1).alias('cube-root_value')).show()\n    print('cbrt API finished')\n    df = spark.createDataFrame([(1.1,), (2.6,), (3.3,), (8.7,)], ['n1'])\n    df.select(ceil(df.n1).alias('cube-root_value')).show()\n    print('ceil API finished')\n    cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], ('a', 'b'))\n    cDf.show()\n    cDf.select(coalesce(cDf['a'], cDf['b'])).show()\n    cDf.select('*', coalesce(cDf['a'], lit(0.0))).show()\n    print('coalesce API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(col('n1')).show()\n    print('col API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_list('age')).show()\n    print('collect_list API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_set('age')).show()\n    print('collect_set API finished')\n    df = spark.createDataFrame([([1, 2, 3, 4], [2, 3, 4, 5])], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    print('concat API finished')\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat_ws('-', df.s, df.d).alias('s')).show()\n    print('concat_ws API finished')\n    df = spark.createDataFrame([('010101',)], ['n'])\n    df.select(conv(df.n, 2, 16).alias('hex')).show()\n    print('conv API finished')\n    a = range(20)\n    b = [2 * x for x in range(20)]\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(corr('a', 'b').alias('c')).collect()\n    print('corr API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cos(df.n1)).show()\n    print('cos API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cosh(df.n1)).show()\n    print('cosh API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(count(df.n1)).show()\n    print('count API finished')\n    df = spark.createDataFrame([('1', '3'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    df = spark.createDataFrame([('1', '2'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    print('countDistinct API finished')\n    a = [1] * 10\n    b = [2] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_pop('a', 'b').alias('c')).show()\n    print('covar_pop API finished')\n    a = [1] * 10\n    b = [1] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_samp('a', 'b').alias('c')).collect()\n    print('covar_samp API finished')\n    spark.createDataFrame([('ABC',)], ['a']).select(crc32('a').alias('crc32')).show()\n    print('crc32 API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(create_map('name', 'age').alias('map')).show()\n    print('create_map API finished')\n    from pyspark.sql import Window\n    window = Window.orderBy('name')\n    df.withColumn('cumulative_distribution', cume_dist().over(window)).show()\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_date().alias('date')).show()\n    print('current_date API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_timestamp().alias('timestamp')).show()\n    print('current_timestamp API finished')\n    print('Finish running function_c API')",
            "def sql_functions_c_example(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    df = spark.createDataFrame([(1,), (2,), (3,), (8,)], ['n1'])\n    df.select(cbrt(df.n1).alias('cube-root_value')).show()\n    print('cbrt API finished')\n    df = spark.createDataFrame([(1.1,), (2.6,), (3.3,), (8.7,)], ['n1'])\n    df.select(ceil(df.n1).alias('cube-root_value')).show()\n    print('ceil API finished')\n    cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], ('a', 'b'))\n    cDf.show()\n    cDf.select(coalesce(cDf['a'], cDf['b'])).show()\n    cDf.select('*', coalesce(cDf['a'], lit(0.0))).show()\n    print('coalesce API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(col('n1')).show()\n    print('col API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_list('age')).show()\n    print('collect_list API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_set('age')).show()\n    print('collect_set API finished')\n    df = spark.createDataFrame([([1, 2, 3, 4], [2, 3, 4, 5])], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    print('concat API finished')\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat_ws('-', df.s, df.d).alias('s')).show()\n    print('concat_ws API finished')\n    df = spark.createDataFrame([('010101',)], ['n'])\n    df.select(conv(df.n, 2, 16).alias('hex')).show()\n    print('conv API finished')\n    a = range(20)\n    b = [2 * x for x in range(20)]\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(corr('a', 'b').alias('c')).collect()\n    print('corr API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cos(df.n1)).show()\n    print('cos API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cosh(df.n1)).show()\n    print('cosh API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(count(df.n1)).show()\n    print('count API finished')\n    df = spark.createDataFrame([('1', '3'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    df = spark.createDataFrame([('1', '2'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    print('countDistinct API finished')\n    a = [1] * 10\n    b = [2] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_pop('a', 'b').alias('c')).show()\n    print('covar_pop API finished')\n    a = [1] * 10\n    b = [1] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_samp('a', 'b').alias('c')).collect()\n    print('covar_samp API finished')\n    spark.createDataFrame([('ABC',)], ['a']).select(crc32('a').alias('crc32')).show()\n    print('crc32 API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(create_map('name', 'age').alias('map')).show()\n    print('create_map API finished')\n    from pyspark.sql import Window\n    window = Window.orderBy('name')\n    df.withColumn('cumulative_distribution', cume_dist().over(window)).show()\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_date().alias('date')).show()\n    print('current_date API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_timestamp().alias('timestamp')).show()\n    print('current_timestamp API finished')\n    print('Finish running function_c API')",
            "def sql_functions_c_example(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    df = spark.createDataFrame([(1,), (2,), (3,), (8,)], ['n1'])\n    df.select(cbrt(df.n1).alias('cube-root_value')).show()\n    print('cbrt API finished')\n    df = spark.createDataFrame([(1.1,), (2.6,), (3.3,), (8.7,)], ['n1'])\n    df.select(ceil(df.n1).alias('cube-root_value')).show()\n    print('ceil API finished')\n    cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], ('a', 'b'))\n    cDf.show()\n    cDf.select(coalesce(cDf['a'], cDf['b'])).show()\n    cDf.select('*', coalesce(cDf['a'], lit(0.0))).show()\n    print('coalesce API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(col('n1')).show()\n    print('col API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_list('age')).show()\n    print('collect_list API finished')\n    df2 = spark.createDataFrame([(2,), (5,), (5,)], ('age',))\n    df2.agg(collect_set('age')).show()\n    print('collect_set API finished')\n    df = spark.createDataFrame([([1, 2, 3, 4], [2, 3, 4, 5])], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat(df.s, df.d).alias('s')).show()\n    print('concat API finished')\n    df = spark.createDataFrame([('abcd', '123')], ['s', 'd'])\n    df.select(concat_ws('-', df.s, df.d).alias('s')).show()\n    print('concat_ws API finished')\n    df = spark.createDataFrame([('010101',)], ['n'])\n    df.select(conv(df.n, 2, 16).alias('hex')).show()\n    print('conv API finished')\n    a = range(20)\n    b = [2 * x for x in range(20)]\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(corr('a', 'b').alias('c')).collect()\n    print('corr API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cos(df.n1)).show()\n    print('cos API finished')\n    df = spark.createDataFrame([(30,), (60,)], ['n1'])\n    df.select(cosh(df.n1)).show()\n    print('cosh API finished')\n    df = spark.createDataFrame([('1', '3'), ('8', '9'), ('12', '24')], ['n1', 'n2'])\n    df.select(count(df.n1)).show()\n    print('count API finished')\n    df = spark.createDataFrame([('1', '3'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    df = spark.createDataFrame([('1', '2'), ('1', '3'), ('1', '4')], ['n1', 'n2'])\n    df.select(countDistinct(df.n1, df.n2)).show()\n    print('countDistinct API finished')\n    a = [1] * 10\n    b = [2] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_pop('a', 'b').alias('c')).show()\n    print('covar_pop API finished')\n    a = [1] * 10\n    b = [1] * 10\n    df = spark.createDataFrame(zip(a, b), ['a', 'b'])\n    df.agg(covar_samp('a', 'b').alias('c')).collect()\n    print('covar_samp API finished')\n    spark.createDataFrame([('ABC',)], ['a']).select(crc32('a').alias('crc32')).show()\n    print('crc32 API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(create_map('name', 'age').alias('map')).show()\n    print('create_map API finished')\n    from pyspark.sql import Window\n    window = Window.orderBy('name')\n    df.withColumn('cumulative_distribution', cume_dist().over(window)).show()\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_date().alias('date')).show()\n    print('current_date API finished')\n    df = spark.createDataFrame([('Alice', 20), ('Bob', 22)], ['name', 'age'])\n    df.select(current_timestamp().alias('timestamp')).show()\n    print('current_timestamp API finished')\n    print('Finish running function_c API')"
        ]
    }
]