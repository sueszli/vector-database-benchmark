[
    {
        "func_name": "load_fountain_dataset",
        "original": "def load_fountain_dataset():\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(fountain_rgbd_dataset.reconstruction_path)\n    return (mesh, rgbd_images, camera_trajectory)",
        "mutated": [
            "def load_fountain_dataset():\n    if False:\n        i = 10\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(fountain_rgbd_dataset.reconstruction_path)\n    return (mesh, rgbd_images, camera_trajectory)",
            "def load_fountain_dataset():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(fountain_rgbd_dataset.reconstruction_path)\n    return (mesh, rgbd_images, camera_trajectory)",
            "def load_fountain_dataset():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(fountain_rgbd_dataset.reconstruction_path)\n    return (mesh, rgbd_images, camera_trajectory)",
            "def load_fountain_dataset():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(fountain_rgbd_dataset.reconstruction_path)\n    return (mesh, rgbd_images, camera_trajectory)",
            "def load_fountain_dataset():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(fountain_rgbd_dataset.reconstruction_path)\n    return (mesh, rgbd_images, camera_trajectory)"
        ]
    },
    {
        "func_name": "test_color_map",
        "original": "def test_color_map():\n    \"\"\"\n    Hard-coded values are from the 0.12 release. We expect the values to match\n    exactly when OMP_NUM_THREADS=1. If more threads are used, there could be\n    some small numerical differences.\n    \"\"\"\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    (mesh, rgbd_images, camera_trajectory) = load_fountain_dataset()\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40322907, 0.37276872, 0.54375919]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.77003829, -0.10813595, 0.06467495, -0.56212008], [0.19100387, 0.86225833, -0.14664845, -0.81434887], [-0.05557141, 0.16504166, 0.82036438, 0.27867426], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40294861, 0.37250299, 0.54338467]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.7699379, -0.10768808, 0.06543989, -0.56320637], [0.19119488, 0.8619734, -0.14717332, -0.8137762], [-0.05608781, 0.16546427, 0.81995183, 0.27725451], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_non_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.NonRigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.4028204, 0.37237733, 0.54322786]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.76967962, -0.10824218, 0.0674025, -0.56381652], [0.19129921, 0.86245618, -0.14634957, -0.81500831], [-0.05765316, 0.16483281, 0.82054672, 0.27526268], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)",
        "mutated": [
            "def test_color_map():\n    if False:\n        i = 10\n    '\\n    Hard-coded values are from the 0.12 release. We expect the values to match\\n    exactly when OMP_NUM_THREADS=1. If more threads are used, there could be\\n    some small numerical differences.\\n    '\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    (mesh, rgbd_images, camera_trajectory) = load_fountain_dataset()\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40322907, 0.37276872, 0.54375919]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.77003829, -0.10813595, 0.06467495, -0.56212008], [0.19100387, 0.86225833, -0.14664845, -0.81434887], [-0.05557141, 0.16504166, 0.82036438, 0.27867426], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40294861, 0.37250299, 0.54338467]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.7699379, -0.10768808, 0.06543989, -0.56320637], [0.19119488, 0.8619734, -0.14717332, -0.8137762], [-0.05608781, 0.16546427, 0.81995183, 0.27725451], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_non_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.NonRigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.4028204, 0.37237733, 0.54322786]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.76967962, -0.10824218, 0.0674025, -0.56381652], [0.19129921, 0.86245618, -0.14634957, -0.81500831], [-0.05765316, 0.16483281, 0.82054672, 0.27526268], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)",
            "def test_color_map():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Hard-coded values are from the 0.12 release. We expect the values to match\\n    exactly when OMP_NUM_THREADS=1. If more threads are used, there could be\\n    some small numerical differences.\\n    '\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    (mesh, rgbd_images, camera_trajectory) = load_fountain_dataset()\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40322907, 0.37276872, 0.54375919]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.77003829, -0.10813595, 0.06467495, -0.56212008], [0.19100387, 0.86225833, -0.14664845, -0.81434887], [-0.05557141, 0.16504166, 0.82036438, 0.27867426], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40294861, 0.37250299, 0.54338467]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.7699379, -0.10768808, 0.06543989, -0.56320637], [0.19119488, 0.8619734, -0.14717332, -0.8137762], [-0.05608781, 0.16546427, 0.81995183, 0.27725451], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_non_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.NonRigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.4028204, 0.37237733, 0.54322786]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.76967962, -0.10824218, 0.0674025, -0.56381652], [0.19129921, 0.86245618, -0.14634957, -0.81500831], [-0.05765316, 0.16483281, 0.82054672, 0.27526268], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)",
            "def test_color_map():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Hard-coded values are from the 0.12 release. We expect the values to match\\n    exactly when OMP_NUM_THREADS=1. If more threads are used, there could be\\n    some small numerical differences.\\n    '\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    (mesh, rgbd_images, camera_trajectory) = load_fountain_dataset()\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40322907, 0.37276872, 0.54375919]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.77003829, -0.10813595, 0.06467495, -0.56212008], [0.19100387, 0.86225833, -0.14664845, -0.81434887], [-0.05557141, 0.16504166, 0.82036438, 0.27867426], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40294861, 0.37250299, 0.54338467]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.7699379, -0.10768808, 0.06543989, -0.56320637], [0.19119488, 0.8619734, -0.14717332, -0.8137762], [-0.05608781, 0.16546427, 0.81995183, 0.27725451], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_non_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.NonRigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.4028204, 0.37237733, 0.54322786]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.76967962, -0.10824218, 0.0674025, -0.56381652], [0.19129921, 0.86245618, -0.14634957, -0.81500831], [-0.05765316, 0.16483281, 0.82054672, 0.27526268], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)",
            "def test_color_map():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Hard-coded values are from the 0.12 release. We expect the values to match\\n    exactly when OMP_NUM_THREADS=1. If more threads are used, there could be\\n    some small numerical differences.\\n    '\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    (mesh, rgbd_images, camera_trajectory) = load_fountain_dataset()\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40322907, 0.37276872, 0.54375919]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.77003829, -0.10813595, 0.06467495, -0.56212008], [0.19100387, 0.86225833, -0.14664845, -0.81434887], [-0.05557141, 0.16504166, 0.82036438, 0.27867426], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40294861, 0.37250299, 0.54338467]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.7699379, -0.10768808, 0.06543989, -0.56320637], [0.19119488, 0.8619734, -0.14717332, -0.8137762], [-0.05608781, 0.16546427, 0.81995183, 0.27725451], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_non_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.NonRigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.4028204, 0.37237733, 0.54322786]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.76967962, -0.10824218, 0.0674025, -0.56381652], [0.19129921, 0.86245618, -0.14634957, -0.81500831], [-0.05765316, 0.16483281, 0.82054672, 0.27526268], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)",
            "def test_color_map():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Hard-coded values are from the 0.12 release. We expect the values to match\\n    exactly when OMP_NUM_THREADS=1. If more threads are used, there could be\\n    some small numerical differences.\\n    '\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    (mesh, rgbd_images, camera_trajectory) = load_fountain_dataset()\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40322907, 0.37276872, 0.54375919]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.77003829, -0.10813595, 0.06467495, -0.56212008], [0.19100387, 0.86225833, -0.14664845, -0.81434887], [-0.05557141, 0.16504166, 0.82036438, 0.27867426], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.40294861, 0.37250299, 0.54338467]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.7699379, -0.10768808, 0.06543989, -0.56320637], [0.19119488, 0.8619734, -0.14717332, -0.8137762], [-0.05608781, 0.16546427, 0.81995183, 0.27725451], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)\n    (mesh, camera_trajectory) = o3d.pipelines.color_map.run_non_rigid_optimizer(mesh, rgbd_images, camera_trajectory, o3d.pipelines.color_map.NonRigidOptimizerOption(maximum_iteration=10))\n    vertex_mean = np.mean(np.asarray(mesh.vertex_colors), axis=0)\n    extrinsic_mean = np.array([c.extrinsic for c in camera_trajectory.parameters]).mean(axis=0)\n    np.testing.assert_allclose(vertex_mean, np.array([0.4028204, 0.37237733, 0.54322786]), rtol=1e-05)\n    np.testing.assert_allclose(extrinsic_mean, np.array([[0.76967962, -0.10824218, 0.0674025, -0.56381652], [0.19129921, 0.86245618, -0.14634957, -0.81500831], [-0.05765316, 0.16483281, 0.82054672, 0.27526268], [0.0, 0.0, 0.0, 1.0]]), rtol=1e-05)"
        ]
    }
]