[
    {
        "func_name": "test_dnnlowp_batch_matmul_int",
        "original": "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), batch_size=st.integers(0, 4), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_dnnlowp_batch_matmul_int(self, m, n, k, batch_size, gc, dc):\n    A_min = -77\n    A_max = A_min + 255\n    A = np.round(np.random.rand(batch_size, m, k) * 255 + A_min)\n    A = A.astype(np.float32)\n    if batch_size > 0 and m > 0:\n        A[0, :, 0] = A_min\n        A[0, 0, 1] = A_max\n    B_min = -100\n    B_max = B_min + 255\n    B = np.round(np.random.rand(batch_size, n, k) * 255 + B_min)\n    B = B.astype(np.float32)\n    if batch_size > 0:\n        B[0, 0, 0] = B_min\n        B[0, 1, 0] = B_max\n    for i in range(batch_size):\n        avoid_vpmaddubsw_overflow_fc(m, k, n, A[i,], A_min, A_max, B[i,], B_min, B_max)\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('BatchMatMul', 'DNNLOWP_16'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            if 'DNNLOWP' in engine:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n                quantize_B = core.CreateOperator('Quantize', ['B'], ['B_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_B])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if 'DNNLOWP' in engine else 'A', 'B_q' if 'DNNLOWP' in engine else 'B'], ['Y_q' if 'DNNLOWP' in engine else 'Y'], trans_a=trans_a, trans_b=trans_b, engine=engine, device_option=gc)\n            net.Proto().op.extend([batch_matmul])\n            if 'DNNLOWP' in engine:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(np.transpose(A, (0, 2, 1)) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else np.transpose(B, (0, 2, 1)), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        check_quantized_results_close(outputs)",
        "mutated": [
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), batch_size=st.integers(0, 4), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_dnnlowp_batch_matmul_int(self, m, n, k, batch_size, gc, dc):\n    if False:\n        i = 10\n    A_min = -77\n    A_max = A_min + 255\n    A = np.round(np.random.rand(batch_size, m, k) * 255 + A_min)\n    A = A.astype(np.float32)\n    if batch_size > 0 and m > 0:\n        A[0, :, 0] = A_min\n        A[0, 0, 1] = A_max\n    B_min = -100\n    B_max = B_min + 255\n    B = np.round(np.random.rand(batch_size, n, k) * 255 + B_min)\n    B = B.astype(np.float32)\n    if batch_size > 0:\n        B[0, 0, 0] = B_min\n        B[0, 1, 0] = B_max\n    for i in range(batch_size):\n        avoid_vpmaddubsw_overflow_fc(m, k, n, A[i,], A_min, A_max, B[i,], B_min, B_max)\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('BatchMatMul', 'DNNLOWP_16'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            if 'DNNLOWP' in engine:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n                quantize_B = core.CreateOperator('Quantize', ['B'], ['B_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_B])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if 'DNNLOWP' in engine else 'A', 'B_q' if 'DNNLOWP' in engine else 'B'], ['Y_q' if 'DNNLOWP' in engine else 'Y'], trans_a=trans_a, trans_b=trans_b, engine=engine, device_option=gc)\n            net.Proto().op.extend([batch_matmul])\n            if 'DNNLOWP' in engine:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(np.transpose(A, (0, 2, 1)) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else np.transpose(B, (0, 2, 1)), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), batch_size=st.integers(0, 4), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_dnnlowp_batch_matmul_int(self, m, n, k, batch_size, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    A_min = -77\n    A_max = A_min + 255\n    A = np.round(np.random.rand(batch_size, m, k) * 255 + A_min)\n    A = A.astype(np.float32)\n    if batch_size > 0 and m > 0:\n        A[0, :, 0] = A_min\n        A[0, 0, 1] = A_max\n    B_min = -100\n    B_max = B_min + 255\n    B = np.round(np.random.rand(batch_size, n, k) * 255 + B_min)\n    B = B.astype(np.float32)\n    if batch_size > 0:\n        B[0, 0, 0] = B_min\n        B[0, 1, 0] = B_max\n    for i in range(batch_size):\n        avoid_vpmaddubsw_overflow_fc(m, k, n, A[i,], A_min, A_max, B[i,], B_min, B_max)\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('BatchMatMul', 'DNNLOWP_16'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            if 'DNNLOWP' in engine:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n                quantize_B = core.CreateOperator('Quantize', ['B'], ['B_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_B])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if 'DNNLOWP' in engine else 'A', 'B_q' if 'DNNLOWP' in engine else 'B'], ['Y_q' if 'DNNLOWP' in engine else 'Y'], trans_a=trans_a, trans_b=trans_b, engine=engine, device_option=gc)\n            net.Proto().op.extend([batch_matmul])\n            if 'DNNLOWP' in engine:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(np.transpose(A, (0, 2, 1)) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else np.transpose(B, (0, 2, 1)), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), batch_size=st.integers(0, 4), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_dnnlowp_batch_matmul_int(self, m, n, k, batch_size, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    A_min = -77\n    A_max = A_min + 255\n    A = np.round(np.random.rand(batch_size, m, k) * 255 + A_min)\n    A = A.astype(np.float32)\n    if batch_size > 0 and m > 0:\n        A[0, :, 0] = A_min\n        A[0, 0, 1] = A_max\n    B_min = -100\n    B_max = B_min + 255\n    B = np.round(np.random.rand(batch_size, n, k) * 255 + B_min)\n    B = B.astype(np.float32)\n    if batch_size > 0:\n        B[0, 0, 0] = B_min\n        B[0, 1, 0] = B_max\n    for i in range(batch_size):\n        avoid_vpmaddubsw_overflow_fc(m, k, n, A[i,], A_min, A_max, B[i,], B_min, B_max)\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('BatchMatMul', 'DNNLOWP_16'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            if 'DNNLOWP' in engine:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n                quantize_B = core.CreateOperator('Quantize', ['B'], ['B_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_B])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if 'DNNLOWP' in engine else 'A', 'B_q' if 'DNNLOWP' in engine else 'B'], ['Y_q' if 'DNNLOWP' in engine else 'Y'], trans_a=trans_a, trans_b=trans_b, engine=engine, device_option=gc)\n            net.Proto().op.extend([batch_matmul])\n            if 'DNNLOWP' in engine:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(np.transpose(A, (0, 2, 1)) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else np.transpose(B, (0, 2, 1)), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), batch_size=st.integers(0, 4), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_dnnlowp_batch_matmul_int(self, m, n, k, batch_size, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    A_min = -77\n    A_max = A_min + 255\n    A = np.round(np.random.rand(batch_size, m, k) * 255 + A_min)\n    A = A.astype(np.float32)\n    if batch_size > 0 and m > 0:\n        A[0, :, 0] = A_min\n        A[0, 0, 1] = A_max\n    B_min = -100\n    B_max = B_min + 255\n    B = np.round(np.random.rand(batch_size, n, k) * 255 + B_min)\n    B = B.astype(np.float32)\n    if batch_size > 0:\n        B[0, 0, 0] = B_min\n        B[0, 1, 0] = B_max\n    for i in range(batch_size):\n        avoid_vpmaddubsw_overflow_fc(m, k, n, A[i,], A_min, A_max, B[i,], B_min, B_max)\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('BatchMatMul', 'DNNLOWP_16'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            if 'DNNLOWP' in engine:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n                quantize_B = core.CreateOperator('Quantize', ['B'], ['B_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_B])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if 'DNNLOWP' in engine else 'A', 'B_q' if 'DNNLOWP' in engine else 'B'], ['Y_q' if 'DNNLOWP' in engine else 'Y'], trans_a=trans_a, trans_b=trans_b, engine=engine, device_option=gc)\n            net.Proto().op.extend([batch_matmul])\n            if 'DNNLOWP' in engine:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(np.transpose(A, (0, 2, 1)) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else np.transpose(B, (0, 2, 1)), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), batch_size=st.integers(0, 4), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_dnnlowp_batch_matmul_int(self, m, n, k, batch_size, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    A_min = -77\n    A_max = A_min + 255\n    A = np.round(np.random.rand(batch_size, m, k) * 255 + A_min)\n    A = A.astype(np.float32)\n    if batch_size > 0 and m > 0:\n        A[0, :, 0] = A_min\n        A[0, 0, 1] = A_max\n    B_min = -100\n    B_max = B_min + 255\n    B = np.round(np.random.rand(batch_size, n, k) * 255 + B_min)\n    B = B.astype(np.float32)\n    if batch_size > 0:\n        B[0, 0, 0] = B_min\n        B[0, 1, 0] = B_max\n    for i in range(batch_size):\n        avoid_vpmaddubsw_overflow_fc(m, k, n, A[i,], A_min, A_max, B[i,], B_min, B_max)\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('BatchMatMul', 'DNNLOWP_16'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            if 'DNNLOWP' in engine:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n                quantize_B = core.CreateOperator('Quantize', ['B'], ['B_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_B])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if 'DNNLOWP' in engine else 'A', 'B_q' if 'DNNLOWP' in engine else 'B'], ['Y_q' if 'DNNLOWP' in engine else 'Y'], trans_a=trans_a, trans_b=trans_b, engine=engine, device_option=gc)\n            net.Proto().op.extend([batch_matmul])\n            if 'DNNLOWP' in engine:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(np.transpose(A, (0, 2, 1)) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else np.transpose(B, (0, 2, 1)), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        check_quantized_results_close(outputs)"
        ]
    },
    {
        "func_name": "test_dnnlowp_batch_matmul_int_constant_B",
        "original": "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), C_1=st.integers(0, 3), C_2=st.integers(0, 3), A_quantized=st.booleans(), B_quantized=st.booleans(), out_quantized=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=2000)\ndef test_dnnlowp_batch_matmul_int_constant_B(self, m, n, k, C_1, C_2, A_quantized, B_quantized, out_quantized, gc, dc):\n    batch_dims = tuple(np.random.randint(3, size=max(C_1, C_2)))\n    batch_dims_A = batch_dims[-C_1:]\n    batch_dims_B = batch_dims[-C_2:]\n    A = np.zeros(batch_dims_A + (m, k)).astype(np.float32)\n    B = np.zeros(batch_dims_B + (n, k)).astype(np.float32)\n    if np.prod(batch_dims) > 0:\n        for index in np.ndindex(batch_dims_A):\n            A_min = -77\n            A_max = A_min + 255\n            A[index] = np.round(np.random.rand(m, k) * 255 + A_min)\n            A[index][:, 0] = A_min\n            if m != 0:\n                A[index][0, 1] = A_max\n        i = 0\n        for index in np.ndindex(batch_dims_B):\n            B_min = -100 if B_quantized else -100 + i\n            B_max = B_min + 255\n            B[index] = np.round(np.random.rand(n, k) * 255 + B_min)\n            B[index][0, 0] = B_min\n            B[index][1, 0] = B_max\n            if C_1 > C_2:\n                for outer_index in np.ndindex(batch_dims_A[:C_1 - C_2]):\n                    avoid_vpmaddubsw_overflow_fc(m, k, n, A[outer_index] if C_2 == 0 else A[outer_index + index], A_min, A_max, B[index], B_min, B_max)\n            else:\n                avoid_vpmaddubsw_overflow_fc(m, k, n, A[index[-C_1:]], A_min, A_max, B[index], B_min, B_max)\n            i += 1\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            do_quantize_A = 'DNNLOWP' in engine and A_quantized\n            do_quantize_B = 'DNNLOWP' in engine and B_quantized\n            do_dequantize = 'DNNLOWP' in engine and out_quantized\n            if do_quantize_A:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n            if do_quantize_B:\n                (int8_given_tensor_fill, B_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(B if trans_b else B.swapaxes(-1, -2), 'B_q')\n                net.Proto().op.extend([int8_given_tensor_fill])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if do_quantize_A else 'A', 'B_q' if do_quantize_B else 'B'], ['Y_q' if do_dequantize else 'Y'], trans_a=trans_a, trans_b=trans_b, broadcast=True, constant_B=True, dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n            if do_quantize_B:\n                dnnlowp_utils.add_quantization_param_args(batch_matmul, outputs[0][0])\n            net.Proto().op.extend([batch_matmul])\n            if do_dequantize:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(A.swapaxes(-1, -2) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else B.swapaxes(-1, -2), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        if np.prod(batch_dims) > 0:\n            check_quantized_results_close(outputs)",
        "mutated": [
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), C_1=st.integers(0, 3), C_2=st.integers(0, 3), A_quantized=st.booleans(), B_quantized=st.booleans(), out_quantized=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=2000)\ndef test_dnnlowp_batch_matmul_int_constant_B(self, m, n, k, C_1, C_2, A_quantized, B_quantized, out_quantized, gc, dc):\n    if False:\n        i = 10\n    batch_dims = tuple(np.random.randint(3, size=max(C_1, C_2)))\n    batch_dims_A = batch_dims[-C_1:]\n    batch_dims_B = batch_dims[-C_2:]\n    A = np.zeros(batch_dims_A + (m, k)).astype(np.float32)\n    B = np.zeros(batch_dims_B + (n, k)).astype(np.float32)\n    if np.prod(batch_dims) > 0:\n        for index in np.ndindex(batch_dims_A):\n            A_min = -77\n            A_max = A_min + 255\n            A[index] = np.round(np.random.rand(m, k) * 255 + A_min)\n            A[index][:, 0] = A_min\n            if m != 0:\n                A[index][0, 1] = A_max\n        i = 0\n        for index in np.ndindex(batch_dims_B):\n            B_min = -100 if B_quantized else -100 + i\n            B_max = B_min + 255\n            B[index] = np.round(np.random.rand(n, k) * 255 + B_min)\n            B[index][0, 0] = B_min\n            B[index][1, 0] = B_max\n            if C_1 > C_2:\n                for outer_index in np.ndindex(batch_dims_A[:C_1 - C_2]):\n                    avoid_vpmaddubsw_overflow_fc(m, k, n, A[outer_index] if C_2 == 0 else A[outer_index + index], A_min, A_max, B[index], B_min, B_max)\n            else:\n                avoid_vpmaddubsw_overflow_fc(m, k, n, A[index[-C_1:]], A_min, A_max, B[index], B_min, B_max)\n            i += 1\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            do_quantize_A = 'DNNLOWP' in engine and A_quantized\n            do_quantize_B = 'DNNLOWP' in engine and B_quantized\n            do_dequantize = 'DNNLOWP' in engine and out_quantized\n            if do_quantize_A:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n            if do_quantize_B:\n                (int8_given_tensor_fill, B_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(B if trans_b else B.swapaxes(-1, -2), 'B_q')\n                net.Proto().op.extend([int8_given_tensor_fill])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if do_quantize_A else 'A', 'B_q' if do_quantize_B else 'B'], ['Y_q' if do_dequantize else 'Y'], trans_a=trans_a, trans_b=trans_b, broadcast=True, constant_B=True, dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n            if do_quantize_B:\n                dnnlowp_utils.add_quantization_param_args(batch_matmul, outputs[0][0])\n            net.Proto().op.extend([batch_matmul])\n            if do_dequantize:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(A.swapaxes(-1, -2) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else B.swapaxes(-1, -2), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        if np.prod(batch_dims) > 0:\n            check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), C_1=st.integers(0, 3), C_2=st.integers(0, 3), A_quantized=st.booleans(), B_quantized=st.booleans(), out_quantized=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=2000)\ndef test_dnnlowp_batch_matmul_int_constant_B(self, m, n, k, C_1, C_2, A_quantized, B_quantized, out_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    batch_dims = tuple(np.random.randint(3, size=max(C_1, C_2)))\n    batch_dims_A = batch_dims[-C_1:]\n    batch_dims_B = batch_dims[-C_2:]\n    A = np.zeros(batch_dims_A + (m, k)).astype(np.float32)\n    B = np.zeros(batch_dims_B + (n, k)).astype(np.float32)\n    if np.prod(batch_dims) > 0:\n        for index in np.ndindex(batch_dims_A):\n            A_min = -77\n            A_max = A_min + 255\n            A[index] = np.round(np.random.rand(m, k) * 255 + A_min)\n            A[index][:, 0] = A_min\n            if m != 0:\n                A[index][0, 1] = A_max\n        i = 0\n        for index in np.ndindex(batch_dims_B):\n            B_min = -100 if B_quantized else -100 + i\n            B_max = B_min + 255\n            B[index] = np.round(np.random.rand(n, k) * 255 + B_min)\n            B[index][0, 0] = B_min\n            B[index][1, 0] = B_max\n            if C_1 > C_2:\n                for outer_index in np.ndindex(batch_dims_A[:C_1 - C_2]):\n                    avoid_vpmaddubsw_overflow_fc(m, k, n, A[outer_index] if C_2 == 0 else A[outer_index + index], A_min, A_max, B[index], B_min, B_max)\n            else:\n                avoid_vpmaddubsw_overflow_fc(m, k, n, A[index[-C_1:]], A_min, A_max, B[index], B_min, B_max)\n            i += 1\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            do_quantize_A = 'DNNLOWP' in engine and A_quantized\n            do_quantize_B = 'DNNLOWP' in engine and B_quantized\n            do_dequantize = 'DNNLOWP' in engine and out_quantized\n            if do_quantize_A:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n            if do_quantize_B:\n                (int8_given_tensor_fill, B_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(B if trans_b else B.swapaxes(-1, -2), 'B_q')\n                net.Proto().op.extend([int8_given_tensor_fill])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if do_quantize_A else 'A', 'B_q' if do_quantize_B else 'B'], ['Y_q' if do_dequantize else 'Y'], trans_a=trans_a, trans_b=trans_b, broadcast=True, constant_B=True, dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n            if do_quantize_B:\n                dnnlowp_utils.add_quantization_param_args(batch_matmul, outputs[0][0])\n            net.Proto().op.extend([batch_matmul])\n            if do_dequantize:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(A.swapaxes(-1, -2) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else B.swapaxes(-1, -2), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        if np.prod(batch_dims) > 0:\n            check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), C_1=st.integers(0, 3), C_2=st.integers(0, 3), A_quantized=st.booleans(), B_quantized=st.booleans(), out_quantized=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=2000)\ndef test_dnnlowp_batch_matmul_int_constant_B(self, m, n, k, C_1, C_2, A_quantized, B_quantized, out_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    batch_dims = tuple(np.random.randint(3, size=max(C_1, C_2)))\n    batch_dims_A = batch_dims[-C_1:]\n    batch_dims_B = batch_dims[-C_2:]\n    A = np.zeros(batch_dims_A + (m, k)).astype(np.float32)\n    B = np.zeros(batch_dims_B + (n, k)).astype(np.float32)\n    if np.prod(batch_dims) > 0:\n        for index in np.ndindex(batch_dims_A):\n            A_min = -77\n            A_max = A_min + 255\n            A[index] = np.round(np.random.rand(m, k) * 255 + A_min)\n            A[index][:, 0] = A_min\n            if m != 0:\n                A[index][0, 1] = A_max\n        i = 0\n        for index in np.ndindex(batch_dims_B):\n            B_min = -100 if B_quantized else -100 + i\n            B_max = B_min + 255\n            B[index] = np.round(np.random.rand(n, k) * 255 + B_min)\n            B[index][0, 0] = B_min\n            B[index][1, 0] = B_max\n            if C_1 > C_2:\n                for outer_index in np.ndindex(batch_dims_A[:C_1 - C_2]):\n                    avoid_vpmaddubsw_overflow_fc(m, k, n, A[outer_index] if C_2 == 0 else A[outer_index + index], A_min, A_max, B[index], B_min, B_max)\n            else:\n                avoid_vpmaddubsw_overflow_fc(m, k, n, A[index[-C_1:]], A_min, A_max, B[index], B_min, B_max)\n            i += 1\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            do_quantize_A = 'DNNLOWP' in engine and A_quantized\n            do_quantize_B = 'DNNLOWP' in engine and B_quantized\n            do_dequantize = 'DNNLOWP' in engine and out_quantized\n            if do_quantize_A:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n            if do_quantize_B:\n                (int8_given_tensor_fill, B_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(B if trans_b else B.swapaxes(-1, -2), 'B_q')\n                net.Proto().op.extend([int8_given_tensor_fill])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if do_quantize_A else 'A', 'B_q' if do_quantize_B else 'B'], ['Y_q' if do_dequantize else 'Y'], trans_a=trans_a, trans_b=trans_b, broadcast=True, constant_B=True, dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n            if do_quantize_B:\n                dnnlowp_utils.add_quantization_param_args(batch_matmul, outputs[0][0])\n            net.Proto().op.extend([batch_matmul])\n            if do_dequantize:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(A.swapaxes(-1, -2) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else B.swapaxes(-1, -2), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        if np.prod(batch_dims) > 0:\n            check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), C_1=st.integers(0, 3), C_2=st.integers(0, 3), A_quantized=st.booleans(), B_quantized=st.booleans(), out_quantized=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=2000)\ndef test_dnnlowp_batch_matmul_int_constant_B(self, m, n, k, C_1, C_2, A_quantized, B_quantized, out_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    batch_dims = tuple(np.random.randint(3, size=max(C_1, C_2)))\n    batch_dims_A = batch_dims[-C_1:]\n    batch_dims_B = batch_dims[-C_2:]\n    A = np.zeros(batch_dims_A + (m, k)).astype(np.float32)\n    B = np.zeros(batch_dims_B + (n, k)).astype(np.float32)\n    if np.prod(batch_dims) > 0:\n        for index in np.ndindex(batch_dims_A):\n            A_min = -77\n            A_max = A_min + 255\n            A[index] = np.round(np.random.rand(m, k) * 255 + A_min)\n            A[index][:, 0] = A_min\n            if m != 0:\n                A[index][0, 1] = A_max\n        i = 0\n        for index in np.ndindex(batch_dims_B):\n            B_min = -100 if B_quantized else -100 + i\n            B_max = B_min + 255\n            B[index] = np.round(np.random.rand(n, k) * 255 + B_min)\n            B[index][0, 0] = B_min\n            B[index][1, 0] = B_max\n            if C_1 > C_2:\n                for outer_index in np.ndindex(batch_dims_A[:C_1 - C_2]):\n                    avoid_vpmaddubsw_overflow_fc(m, k, n, A[outer_index] if C_2 == 0 else A[outer_index + index], A_min, A_max, B[index], B_min, B_max)\n            else:\n                avoid_vpmaddubsw_overflow_fc(m, k, n, A[index[-C_1:]], A_min, A_max, B[index], B_min, B_max)\n            i += 1\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            do_quantize_A = 'DNNLOWP' in engine and A_quantized\n            do_quantize_B = 'DNNLOWP' in engine and B_quantized\n            do_dequantize = 'DNNLOWP' in engine and out_quantized\n            if do_quantize_A:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n            if do_quantize_B:\n                (int8_given_tensor_fill, B_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(B if trans_b else B.swapaxes(-1, -2), 'B_q')\n                net.Proto().op.extend([int8_given_tensor_fill])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if do_quantize_A else 'A', 'B_q' if do_quantize_B else 'B'], ['Y_q' if do_dequantize else 'Y'], trans_a=trans_a, trans_b=trans_b, broadcast=True, constant_B=True, dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n            if do_quantize_B:\n                dnnlowp_utils.add_quantization_param_args(batch_matmul, outputs[0][0])\n            net.Proto().op.extend([batch_matmul])\n            if do_dequantize:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(A.swapaxes(-1, -2) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else B.swapaxes(-1, -2), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        if np.prod(batch_dims) > 0:\n            check_quantized_results_close(outputs)",
            "@given(m=st.integers(0, 32), n=st.integers(4, 32), k=st.integers(4, 32), C_1=st.integers(0, 3), C_2=st.integers(0, 3), A_quantized=st.booleans(), B_quantized=st.booleans(), out_quantized=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=2000)\ndef test_dnnlowp_batch_matmul_int_constant_B(self, m, n, k, C_1, C_2, A_quantized, B_quantized, out_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    batch_dims = tuple(np.random.randint(3, size=max(C_1, C_2)))\n    batch_dims_A = batch_dims[-C_1:]\n    batch_dims_B = batch_dims[-C_2:]\n    A = np.zeros(batch_dims_A + (m, k)).astype(np.float32)\n    B = np.zeros(batch_dims_B + (n, k)).astype(np.float32)\n    if np.prod(batch_dims) > 0:\n        for index in np.ndindex(batch_dims_A):\n            A_min = -77\n            A_max = A_min + 255\n            A[index] = np.round(np.random.rand(m, k) * 255 + A_min)\n            A[index][:, 0] = A_min\n            if m != 0:\n                A[index][0, 1] = A_max\n        i = 0\n        for index in np.ndindex(batch_dims_B):\n            B_min = -100 if B_quantized else -100 + i\n            B_max = B_min + 255\n            B[index] = np.round(np.random.rand(n, k) * 255 + B_min)\n            B[index][0, 0] = B_min\n            B[index][1, 0] = B_max\n            if C_1 > C_2:\n                for outer_index in np.ndindex(batch_dims_A[:C_1 - C_2]):\n                    avoid_vpmaddubsw_overflow_fc(m, k, n, A[outer_index] if C_2 == 0 else A[outer_index + index], A_min, A_max, B[index], B_min, B_max)\n            else:\n                avoid_vpmaddubsw_overflow_fc(m, k, n, A[index[-C_1:]], A_min, A_max, B[index], B_min, B_max)\n            i += 1\n    for (trans_a, trans_b) in product([0, 1], [0, 1]):\n        Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n        outputs = []\n        op_engine_list = [('BatchMatMul', ''), ('BatchMatMul', 'DNNLOWP'), ('Int8BatchMatMul', 'DNNLOWP')]\n        for (op_type, engine) in op_engine_list:\n            net = core.Net('test_net')\n            do_quantize_A = 'DNNLOWP' in engine and A_quantized\n            do_quantize_B = 'DNNLOWP' in engine and B_quantized\n            do_dequantize = 'DNNLOWP' in engine and out_quantized\n            if do_quantize_A:\n                quantize_A = core.CreateOperator('Quantize', ['A'], ['A_q'], engine=engine, device_option=gc)\n                net.Proto().op.extend([quantize_A])\n            if do_quantize_B:\n                (int8_given_tensor_fill, B_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(B if trans_b else B.swapaxes(-1, -2), 'B_q')\n                net.Proto().op.extend([int8_given_tensor_fill])\n            batch_matmul = core.CreateOperator(op_type, ['A_q' if do_quantize_A else 'A', 'B_q' if do_quantize_B else 'B'], ['Y_q' if do_dequantize else 'Y'], trans_a=trans_a, trans_b=trans_b, broadcast=True, constant_B=True, dequantize_output=not do_dequantize, engine=engine, device_option=gc)\n            if do_quantize_B:\n                dnnlowp_utils.add_quantization_param_args(batch_matmul, outputs[0][0])\n            net.Proto().op.extend([batch_matmul])\n            if do_dequantize:\n                dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n                net.Proto().op.extend([dequantize])\n            self.ws.create_blob('A').feed(A.swapaxes(-1, -2) if trans_a else A, device_option=gc)\n            self.ws.create_blob('B').feed(B if trans_b else B.swapaxes(-1, -2), device_option=gc)\n            self.ws.run(net)\n            outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n        if np.prod(batch_dims) > 0:\n            check_quantized_results_close(outputs)"
        ]
    }
]