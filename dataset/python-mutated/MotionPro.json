[
    {
        "func_name": "__init__",
        "original": "def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=128, number_points=512, kernel=5, globalchoice='multi'):\n    super(MotionPro, self).__init__()\n    self.embedding = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.embedding_motion = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.pad = kernel // 2\n    self.conv1 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.conv2 = nn.Conv1d(embeddingSize, embeddingSize // 2, 1)\n    self.conv3 = nn.Conv1d(embeddingSize // 2, 1, 1)\n    self.weighted = nn.Softmax(dim=2)\n    self.relu = nn.ReLU()\n    self.leakyRelu = nn.LeakyReLU(0.1)\n    self.m_conv1 = nn.Conv1d(embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv2 = nn.Conv1d(2 * embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv3 = nn.Conv1d(2 * embeddingSize, embeddingSize, 1)\n    self.fuse_conv1 = nn.Conv1d(embeddingSize + embeddingSize // 2, embeddingSize, 1)\n    self.fuse_conv2 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.decoder = nn.Linear(embeddingSize, 2, bias=False)\n    if globalchoice == 'multi':\n        self.homoEstimate = multiHomoEstimate\n    elif globalchoice == 'single':\n        self.homoEstimate = singleHomoEstimate\n    self.meidanPool = MedianPool2d(5, same=True)",
        "mutated": [
            "def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=128, number_points=512, kernel=5, globalchoice='multi'):\n    if False:\n        i = 10\n    super(MotionPro, self).__init__()\n    self.embedding = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.embedding_motion = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.pad = kernel // 2\n    self.conv1 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.conv2 = nn.Conv1d(embeddingSize, embeddingSize // 2, 1)\n    self.conv3 = nn.Conv1d(embeddingSize // 2, 1, 1)\n    self.weighted = nn.Softmax(dim=2)\n    self.relu = nn.ReLU()\n    self.leakyRelu = nn.LeakyReLU(0.1)\n    self.m_conv1 = nn.Conv1d(embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv2 = nn.Conv1d(2 * embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv3 = nn.Conv1d(2 * embeddingSize, embeddingSize, 1)\n    self.fuse_conv1 = nn.Conv1d(embeddingSize + embeddingSize // 2, embeddingSize, 1)\n    self.fuse_conv2 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.decoder = nn.Linear(embeddingSize, 2, bias=False)\n    if globalchoice == 'multi':\n        self.homoEstimate = multiHomoEstimate\n    elif globalchoice == 'single':\n        self.homoEstimate = singleHomoEstimate\n    self.meidanPool = MedianPool2d(5, same=True)",
            "def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=128, number_points=512, kernel=5, globalchoice='multi'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(MotionPro, self).__init__()\n    self.embedding = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.embedding_motion = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.pad = kernel // 2\n    self.conv1 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.conv2 = nn.Conv1d(embeddingSize, embeddingSize // 2, 1)\n    self.conv3 = nn.Conv1d(embeddingSize // 2, 1, 1)\n    self.weighted = nn.Softmax(dim=2)\n    self.relu = nn.ReLU()\n    self.leakyRelu = nn.LeakyReLU(0.1)\n    self.m_conv1 = nn.Conv1d(embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv2 = nn.Conv1d(2 * embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv3 = nn.Conv1d(2 * embeddingSize, embeddingSize, 1)\n    self.fuse_conv1 = nn.Conv1d(embeddingSize + embeddingSize // 2, embeddingSize, 1)\n    self.fuse_conv2 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.decoder = nn.Linear(embeddingSize, 2, bias=False)\n    if globalchoice == 'multi':\n        self.homoEstimate = multiHomoEstimate\n    elif globalchoice == 'single':\n        self.homoEstimate = singleHomoEstimate\n    self.meidanPool = MedianPool2d(5, same=True)",
            "def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=128, number_points=512, kernel=5, globalchoice='multi'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(MotionPro, self).__init__()\n    self.embedding = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.embedding_motion = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.pad = kernel // 2\n    self.conv1 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.conv2 = nn.Conv1d(embeddingSize, embeddingSize // 2, 1)\n    self.conv3 = nn.Conv1d(embeddingSize // 2, 1, 1)\n    self.weighted = nn.Softmax(dim=2)\n    self.relu = nn.ReLU()\n    self.leakyRelu = nn.LeakyReLU(0.1)\n    self.m_conv1 = nn.Conv1d(embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv2 = nn.Conv1d(2 * embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv3 = nn.Conv1d(2 * embeddingSize, embeddingSize, 1)\n    self.fuse_conv1 = nn.Conv1d(embeddingSize + embeddingSize // 2, embeddingSize, 1)\n    self.fuse_conv2 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.decoder = nn.Linear(embeddingSize, 2, bias=False)\n    if globalchoice == 'multi':\n        self.homoEstimate = multiHomoEstimate\n    elif globalchoice == 'single':\n        self.homoEstimate = singleHomoEstimate\n    self.meidanPool = MedianPool2d(5, same=True)",
            "def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=128, number_points=512, kernel=5, globalchoice='multi'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(MotionPro, self).__init__()\n    self.embedding = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.embedding_motion = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.pad = kernel // 2\n    self.conv1 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.conv2 = nn.Conv1d(embeddingSize, embeddingSize // 2, 1)\n    self.conv3 = nn.Conv1d(embeddingSize // 2, 1, 1)\n    self.weighted = nn.Softmax(dim=2)\n    self.relu = nn.ReLU()\n    self.leakyRelu = nn.LeakyReLU(0.1)\n    self.m_conv1 = nn.Conv1d(embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv2 = nn.Conv1d(2 * embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv3 = nn.Conv1d(2 * embeddingSize, embeddingSize, 1)\n    self.fuse_conv1 = nn.Conv1d(embeddingSize + embeddingSize // 2, embeddingSize, 1)\n    self.fuse_conv2 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.decoder = nn.Linear(embeddingSize, 2, bias=False)\n    if globalchoice == 'multi':\n        self.homoEstimate = multiHomoEstimate\n    elif globalchoice == 'single':\n        self.homoEstimate = singleHomoEstimate\n    self.meidanPool = MedianPool2d(5, same=True)",
            "def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=128, number_points=512, kernel=5, globalchoice='multi'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(MotionPro, self).__init__()\n    self.embedding = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.embedding_motion = nn.Sequential(nn.Conv1d(inplanes, embeddingSize, 1), nn.ReLU())\n    self.pad = kernel // 2\n    self.conv1 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.conv2 = nn.Conv1d(embeddingSize, embeddingSize // 2, 1)\n    self.conv3 = nn.Conv1d(embeddingSize // 2, 1, 1)\n    self.weighted = nn.Softmax(dim=2)\n    self.relu = nn.ReLU()\n    self.leakyRelu = nn.LeakyReLU(0.1)\n    self.m_conv1 = nn.Conv1d(embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv2 = nn.Conv1d(2 * embeddingSize, 2 * embeddingSize, 1)\n    self.m_conv3 = nn.Conv1d(2 * embeddingSize, embeddingSize, 1)\n    self.fuse_conv1 = nn.Conv1d(embeddingSize + embeddingSize // 2, embeddingSize, 1)\n    self.fuse_conv2 = nn.Conv1d(embeddingSize, embeddingSize, 1)\n    self.decoder = nn.Linear(embeddingSize, 2, bias=False)\n    if globalchoice == 'multi':\n        self.homoEstimate = multiHomoEstimate\n    elif globalchoice == 'single':\n        self.homoEstimate = singleHomoEstimate\n    self.meidanPool = MedianPool2d(5, same=True)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, motion):\n    \"\"\"\n        @param: motion contains distance info and motion info of keypoints\n\n        @return: return predicted motion for each grid vertex\n        \"\"\"\n    distance_info = motion[:, 0:2, :]\n    motion_info = motion[0:1, 2:4, :]\n    embedding_distance = self.embedding(distance_info)\n    embedding_distance = self.leakyRelu(self.conv1(embedding_distance))\n    embedding_distance = self.leakyRelu(self.conv2(embedding_distance))\n    distance_weighted = self.weighted(self.conv3(embedding_distance))\n    embedding_motion = self.embedding_motion(motion_info)\n    embedding_motion = self.leakyRelu(self.m_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv2(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv3(embedding_motion))\n    embedding_motion = embedding_motion.repeat(distance_info.shape[0], 1, 1)\n    embedding_motion = torch.cat([embedding_motion, embedding_distance], 1)\n    embedding_motion = self.leakyRelu(self.fuse_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.fuse_conv2(embedding_motion))\n    embedding_motion = torch.sum(embedding_motion * distance_weighted, 2)\n    out_motion = self.decoder(embedding_motion)\n    return out_motion",
        "mutated": [
            "def forward(self, motion):\n    if False:\n        i = 10\n    '\\n        @param: motion contains distance info and motion info of keypoints\\n\\n        @return: return predicted motion for each grid vertex\\n        '\n    distance_info = motion[:, 0:2, :]\n    motion_info = motion[0:1, 2:4, :]\n    embedding_distance = self.embedding(distance_info)\n    embedding_distance = self.leakyRelu(self.conv1(embedding_distance))\n    embedding_distance = self.leakyRelu(self.conv2(embedding_distance))\n    distance_weighted = self.weighted(self.conv3(embedding_distance))\n    embedding_motion = self.embedding_motion(motion_info)\n    embedding_motion = self.leakyRelu(self.m_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv2(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv3(embedding_motion))\n    embedding_motion = embedding_motion.repeat(distance_info.shape[0], 1, 1)\n    embedding_motion = torch.cat([embedding_motion, embedding_distance], 1)\n    embedding_motion = self.leakyRelu(self.fuse_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.fuse_conv2(embedding_motion))\n    embedding_motion = torch.sum(embedding_motion * distance_weighted, 2)\n    out_motion = self.decoder(embedding_motion)\n    return out_motion",
            "def forward(self, motion):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        @param: motion contains distance info and motion info of keypoints\\n\\n        @return: return predicted motion for each grid vertex\\n        '\n    distance_info = motion[:, 0:2, :]\n    motion_info = motion[0:1, 2:4, :]\n    embedding_distance = self.embedding(distance_info)\n    embedding_distance = self.leakyRelu(self.conv1(embedding_distance))\n    embedding_distance = self.leakyRelu(self.conv2(embedding_distance))\n    distance_weighted = self.weighted(self.conv3(embedding_distance))\n    embedding_motion = self.embedding_motion(motion_info)\n    embedding_motion = self.leakyRelu(self.m_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv2(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv3(embedding_motion))\n    embedding_motion = embedding_motion.repeat(distance_info.shape[0], 1, 1)\n    embedding_motion = torch.cat([embedding_motion, embedding_distance], 1)\n    embedding_motion = self.leakyRelu(self.fuse_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.fuse_conv2(embedding_motion))\n    embedding_motion = torch.sum(embedding_motion * distance_weighted, 2)\n    out_motion = self.decoder(embedding_motion)\n    return out_motion",
            "def forward(self, motion):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        @param: motion contains distance info and motion info of keypoints\\n\\n        @return: return predicted motion for each grid vertex\\n        '\n    distance_info = motion[:, 0:2, :]\n    motion_info = motion[0:1, 2:4, :]\n    embedding_distance = self.embedding(distance_info)\n    embedding_distance = self.leakyRelu(self.conv1(embedding_distance))\n    embedding_distance = self.leakyRelu(self.conv2(embedding_distance))\n    distance_weighted = self.weighted(self.conv3(embedding_distance))\n    embedding_motion = self.embedding_motion(motion_info)\n    embedding_motion = self.leakyRelu(self.m_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv2(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv3(embedding_motion))\n    embedding_motion = embedding_motion.repeat(distance_info.shape[0], 1, 1)\n    embedding_motion = torch.cat([embedding_motion, embedding_distance], 1)\n    embedding_motion = self.leakyRelu(self.fuse_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.fuse_conv2(embedding_motion))\n    embedding_motion = torch.sum(embedding_motion * distance_weighted, 2)\n    out_motion = self.decoder(embedding_motion)\n    return out_motion",
            "def forward(self, motion):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        @param: motion contains distance info and motion info of keypoints\\n\\n        @return: return predicted motion for each grid vertex\\n        '\n    distance_info = motion[:, 0:2, :]\n    motion_info = motion[0:1, 2:4, :]\n    embedding_distance = self.embedding(distance_info)\n    embedding_distance = self.leakyRelu(self.conv1(embedding_distance))\n    embedding_distance = self.leakyRelu(self.conv2(embedding_distance))\n    distance_weighted = self.weighted(self.conv3(embedding_distance))\n    embedding_motion = self.embedding_motion(motion_info)\n    embedding_motion = self.leakyRelu(self.m_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv2(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv3(embedding_motion))\n    embedding_motion = embedding_motion.repeat(distance_info.shape[0], 1, 1)\n    embedding_motion = torch.cat([embedding_motion, embedding_distance], 1)\n    embedding_motion = self.leakyRelu(self.fuse_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.fuse_conv2(embedding_motion))\n    embedding_motion = torch.sum(embedding_motion * distance_weighted, 2)\n    out_motion = self.decoder(embedding_motion)\n    return out_motion",
            "def forward(self, motion):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        @param: motion contains distance info and motion info of keypoints\\n\\n        @return: return predicted motion for each grid vertex\\n        '\n    distance_info = motion[:, 0:2, :]\n    motion_info = motion[0:1, 2:4, :]\n    embedding_distance = self.embedding(distance_info)\n    embedding_distance = self.leakyRelu(self.conv1(embedding_distance))\n    embedding_distance = self.leakyRelu(self.conv2(embedding_distance))\n    distance_weighted = self.weighted(self.conv3(embedding_distance))\n    embedding_motion = self.embedding_motion(motion_info)\n    embedding_motion = self.leakyRelu(self.m_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv2(embedding_motion))\n    embedding_motion = self.leakyRelu(self.m_conv3(embedding_motion))\n    embedding_motion = embedding_motion.repeat(distance_info.shape[0], 1, 1)\n    embedding_motion = torch.cat([embedding_motion, embedding_distance], 1)\n    embedding_motion = self.leakyRelu(self.fuse_conv1(embedding_motion))\n    embedding_motion = self.leakyRelu(self.fuse_conv2(embedding_motion))\n    embedding_motion = torch.sum(embedding_motion * distance_weighted, 2)\n    out_motion = self.decoder(embedding_motion)\n    return out_motion"
        ]
    },
    {
        "func_name": "inference",
        "original": "def inference(self, x_flow, y_flow, kp):\n    \"\"\"\n        @param x_flow [B, 1, H, W]\n        @param y_flow [B, 1, H, W]\n        @param kp     [B*topk, 4 / 2]->[N, 4/2]\n        \"\"\"\n    if kp.shape[1] == 4:\n        kp = kp[:, 2:]\n    index = kp.long()\n    origin_motion = torch.cat([x_flow, y_flow], 1)\n    extracted_motion = origin_motion[0, :, index[:, 0], index[:, 1]]\n    kp = kp.permute(1, 0).float()\n    concat_motion = torch.cat([kp[1:2, :], kp[0:1, :], extracted_motion], 0)\n    (motion, gridsMotion, _) = self.homoEstimate(concat_motion, kp)\n    GridMotion = (self.forward(motion) + gridsMotion.squeeze(-1)) * cfg.MODEL.FLOWC\n    GridMotion = GridMotion.view(cfg.MODEL.HEIGHT // cfg.MODEL.PIXELS, cfg.MODEL.WIDTH // cfg.MODEL.PIXELS, 2)\n    GridMotion = GridMotion.permute(2, 0, 1).unsqueeze(0)\n    GridMotion = self.meidanPool(GridMotion)\n    return GridMotion",
        "mutated": [
            "def inference(self, x_flow, y_flow, kp):\n    if False:\n        i = 10\n    '\\n        @param x_flow [B, 1, H, W]\\n        @param y_flow [B, 1, H, W]\\n        @param kp     [B*topk, 4 / 2]->[N, 4/2]\\n        '\n    if kp.shape[1] == 4:\n        kp = kp[:, 2:]\n    index = kp.long()\n    origin_motion = torch.cat([x_flow, y_flow], 1)\n    extracted_motion = origin_motion[0, :, index[:, 0], index[:, 1]]\n    kp = kp.permute(1, 0).float()\n    concat_motion = torch.cat([kp[1:2, :], kp[0:1, :], extracted_motion], 0)\n    (motion, gridsMotion, _) = self.homoEstimate(concat_motion, kp)\n    GridMotion = (self.forward(motion) + gridsMotion.squeeze(-1)) * cfg.MODEL.FLOWC\n    GridMotion = GridMotion.view(cfg.MODEL.HEIGHT // cfg.MODEL.PIXELS, cfg.MODEL.WIDTH // cfg.MODEL.PIXELS, 2)\n    GridMotion = GridMotion.permute(2, 0, 1).unsqueeze(0)\n    GridMotion = self.meidanPool(GridMotion)\n    return GridMotion",
            "def inference(self, x_flow, y_flow, kp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        @param x_flow [B, 1, H, W]\\n        @param y_flow [B, 1, H, W]\\n        @param kp     [B*topk, 4 / 2]->[N, 4/2]\\n        '\n    if kp.shape[1] == 4:\n        kp = kp[:, 2:]\n    index = kp.long()\n    origin_motion = torch.cat([x_flow, y_flow], 1)\n    extracted_motion = origin_motion[0, :, index[:, 0], index[:, 1]]\n    kp = kp.permute(1, 0).float()\n    concat_motion = torch.cat([kp[1:2, :], kp[0:1, :], extracted_motion], 0)\n    (motion, gridsMotion, _) = self.homoEstimate(concat_motion, kp)\n    GridMotion = (self.forward(motion) + gridsMotion.squeeze(-1)) * cfg.MODEL.FLOWC\n    GridMotion = GridMotion.view(cfg.MODEL.HEIGHT // cfg.MODEL.PIXELS, cfg.MODEL.WIDTH // cfg.MODEL.PIXELS, 2)\n    GridMotion = GridMotion.permute(2, 0, 1).unsqueeze(0)\n    GridMotion = self.meidanPool(GridMotion)\n    return GridMotion",
            "def inference(self, x_flow, y_flow, kp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        @param x_flow [B, 1, H, W]\\n        @param y_flow [B, 1, H, W]\\n        @param kp     [B*topk, 4 / 2]->[N, 4/2]\\n        '\n    if kp.shape[1] == 4:\n        kp = kp[:, 2:]\n    index = kp.long()\n    origin_motion = torch.cat([x_flow, y_flow], 1)\n    extracted_motion = origin_motion[0, :, index[:, 0], index[:, 1]]\n    kp = kp.permute(1, 0).float()\n    concat_motion = torch.cat([kp[1:2, :], kp[0:1, :], extracted_motion], 0)\n    (motion, gridsMotion, _) = self.homoEstimate(concat_motion, kp)\n    GridMotion = (self.forward(motion) + gridsMotion.squeeze(-1)) * cfg.MODEL.FLOWC\n    GridMotion = GridMotion.view(cfg.MODEL.HEIGHT // cfg.MODEL.PIXELS, cfg.MODEL.WIDTH // cfg.MODEL.PIXELS, 2)\n    GridMotion = GridMotion.permute(2, 0, 1).unsqueeze(0)\n    GridMotion = self.meidanPool(GridMotion)\n    return GridMotion",
            "def inference(self, x_flow, y_flow, kp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        @param x_flow [B, 1, H, W]\\n        @param y_flow [B, 1, H, W]\\n        @param kp     [B*topk, 4 / 2]->[N, 4/2]\\n        '\n    if kp.shape[1] == 4:\n        kp = kp[:, 2:]\n    index = kp.long()\n    origin_motion = torch.cat([x_flow, y_flow], 1)\n    extracted_motion = origin_motion[0, :, index[:, 0], index[:, 1]]\n    kp = kp.permute(1, 0).float()\n    concat_motion = torch.cat([kp[1:2, :], kp[0:1, :], extracted_motion], 0)\n    (motion, gridsMotion, _) = self.homoEstimate(concat_motion, kp)\n    GridMotion = (self.forward(motion) + gridsMotion.squeeze(-1)) * cfg.MODEL.FLOWC\n    GridMotion = GridMotion.view(cfg.MODEL.HEIGHT // cfg.MODEL.PIXELS, cfg.MODEL.WIDTH // cfg.MODEL.PIXELS, 2)\n    GridMotion = GridMotion.permute(2, 0, 1).unsqueeze(0)\n    GridMotion = self.meidanPool(GridMotion)\n    return GridMotion",
            "def inference(self, x_flow, y_flow, kp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        @param x_flow [B, 1, H, W]\\n        @param y_flow [B, 1, H, W]\\n        @param kp     [B*topk, 4 / 2]->[N, 4/2]\\n        '\n    if kp.shape[1] == 4:\n        kp = kp[:, 2:]\n    index = kp.long()\n    origin_motion = torch.cat([x_flow, y_flow], 1)\n    extracted_motion = origin_motion[0, :, index[:, 0], index[:, 1]]\n    kp = kp.permute(1, 0).float()\n    concat_motion = torch.cat([kp[1:2, :], kp[0:1, :], extracted_motion], 0)\n    (motion, gridsMotion, _) = self.homoEstimate(concat_motion, kp)\n    GridMotion = (self.forward(motion) + gridsMotion.squeeze(-1)) * cfg.MODEL.FLOWC\n    GridMotion = GridMotion.view(cfg.MODEL.HEIGHT // cfg.MODEL.PIXELS, cfg.MODEL.WIDTH // cfg.MODEL.PIXELS, 2)\n    GridMotion = GridMotion.permute(2, 0, 1).unsqueeze(0)\n    GridMotion = self.meidanPool(GridMotion)\n    return GridMotion"
        ]
    }
]