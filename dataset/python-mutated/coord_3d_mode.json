[
    {
        "func_name": "convert",
        "original": "@staticmethod\ndef convert(input, src, dst, rt_mat=None, with_yaw=True, is_point=True):\n    \"\"\"Convert boxes or points from `src` mode to `dst` mode.\n\n        Args:\n            input (tuple | list | np.ndarray | torch.Tensor |\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\n            src (:obj:`Box3DMode` | :obj:`Coord3DMode`): The source mode.\n            dst (:obj:`Box3DMode` | :obj:`Coord3DMode`): The target mode.\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\n                translation matrix between different coordinates.\n                Defaults to None.\n                The conversion from `src` coordinates to `dst` coordinates\n                usually comes along the change of sensors, e.g., from camera\n                to LiDAR. This requires a transformation matrix.\n            with_yaw (bool): If `box` is an instance of\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\n                Defaults to True.\n            is_point (bool): If `input` is neither an instance of\n                :obj:`BaseInstance3DBoxes` nor an instance of\n                :obj:`BasePoints`, whether or not it is point data.\n                Defaults to True.\n\n        Returns:\n            (tuple | list | np.ndarray | torch.Tensor |\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\n                The converted box of the same type.\n        \"\"\"\n    if isinstance(input, BaseInstance3DBoxes):\n        return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    elif isinstance(input, BasePoints):\n        return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n    elif isinstance(input, (tuple, list, np.ndarray, torch.Tensor)):\n        if is_point:\n            return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n        else:\n            return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    else:\n        raise NotImplementedError",
        "mutated": [
            "@staticmethod\ndef convert(input, src, dst, rt_mat=None, with_yaw=True, is_point=True):\n    if False:\n        i = 10\n    'Convert boxes or points from `src` mode to `dst` mode.\\n\\n        Args:\\n            input (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode` | :obj:`Coord3DMode`): The source mode.\\n            dst (:obj:`Box3DMode` | :obj:`Coord3DMode`): The target mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n            is_point (bool): If `input` is neither an instance of\\n                :obj:`BaseInstance3DBoxes` nor an instance of\\n                :obj:`BasePoints`, whether or not it is point data.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                The converted box of the same type.\\n        '\n    if isinstance(input, BaseInstance3DBoxes):\n        return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    elif isinstance(input, BasePoints):\n        return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n    elif isinstance(input, (tuple, list, np.ndarray, torch.Tensor)):\n        if is_point:\n            return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n        else:\n            return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    else:\n        raise NotImplementedError",
            "@staticmethod\ndef convert(input, src, dst, rt_mat=None, with_yaw=True, is_point=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Convert boxes or points from `src` mode to `dst` mode.\\n\\n        Args:\\n            input (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode` | :obj:`Coord3DMode`): The source mode.\\n            dst (:obj:`Box3DMode` | :obj:`Coord3DMode`): The target mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n            is_point (bool): If `input` is neither an instance of\\n                :obj:`BaseInstance3DBoxes` nor an instance of\\n                :obj:`BasePoints`, whether or not it is point data.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                The converted box of the same type.\\n        '\n    if isinstance(input, BaseInstance3DBoxes):\n        return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    elif isinstance(input, BasePoints):\n        return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n    elif isinstance(input, (tuple, list, np.ndarray, torch.Tensor)):\n        if is_point:\n            return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n        else:\n            return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    else:\n        raise NotImplementedError",
            "@staticmethod\ndef convert(input, src, dst, rt_mat=None, with_yaw=True, is_point=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Convert boxes or points from `src` mode to `dst` mode.\\n\\n        Args:\\n            input (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode` | :obj:`Coord3DMode`): The source mode.\\n            dst (:obj:`Box3DMode` | :obj:`Coord3DMode`): The target mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n            is_point (bool): If `input` is neither an instance of\\n                :obj:`BaseInstance3DBoxes` nor an instance of\\n                :obj:`BasePoints`, whether or not it is point data.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                The converted box of the same type.\\n        '\n    if isinstance(input, BaseInstance3DBoxes):\n        return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    elif isinstance(input, BasePoints):\n        return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n    elif isinstance(input, (tuple, list, np.ndarray, torch.Tensor)):\n        if is_point:\n            return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n        else:\n            return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    else:\n        raise NotImplementedError",
            "@staticmethod\ndef convert(input, src, dst, rt_mat=None, with_yaw=True, is_point=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Convert boxes or points from `src` mode to `dst` mode.\\n\\n        Args:\\n            input (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode` | :obj:`Coord3DMode`): The source mode.\\n            dst (:obj:`Box3DMode` | :obj:`Coord3DMode`): The target mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n            is_point (bool): If `input` is neither an instance of\\n                :obj:`BaseInstance3DBoxes` nor an instance of\\n                :obj:`BasePoints`, whether or not it is point data.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                The converted box of the same type.\\n        '\n    if isinstance(input, BaseInstance3DBoxes):\n        return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    elif isinstance(input, BasePoints):\n        return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n    elif isinstance(input, (tuple, list, np.ndarray, torch.Tensor)):\n        if is_point:\n            return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n        else:\n            return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    else:\n        raise NotImplementedError",
            "@staticmethod\ndef convert(input, src, dst, rt_mat=None, with_yaw=True, is_point=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Convert boxes or points from `src` mode to `dst` mode.\\n\\n        Args:\\n            input (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode` | :obj:`Coord3DMode`): The source mode.\\n            dst (:obj:`Box3DMode` | :obj:`Coord3DMode`): The target mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n            is_point (bool): If `input` is neither an instance of\\n                :obj:`BaseInstance3DBoxes` nor an instance of\\n                :obj:`BasePoints`, whether or not it is point data.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes` | :obj:`BasePoints`):\\n                The converted box of the same type.\\n        '\n    if isinstance(input, BaseInstance3DBoxes):\n        return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    elif isinstance(input, BasePoints):\n        return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n    elif isinstance(input, (tuple, list, np.ndarray, torch.Tensor)):\n        if is_point:\n            return Coord3DMode.convert_point(input, src, dst, rt_mat=rt_mat)\n        else:\n            return Coord3DMode.convert_box(input, src, dst, rt_mat=rt_mat, with_yaw=with_yaw)\n    else:\n        raise NotImplementedError"
        ]
    },
    {
        "func_name": "convert_box",
        "original": "@staticmethod\ndef convert_box(box, src, dst, rt_mat=None, with_yaw=True):\n    \"\"\"Convert boxes from `src` mode to `dst` mode.\n\n        Args:\n            box (tuple | list | np.ndarray |\n                torch.Tensor | :obj:`BaseInstance3DBoxes`):\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\n            src (:obj:`Box3DMode`): The src Box mode.\n            dst (:obj:`Box3DMode`): The target Box mode.\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\n                translation matrix between different coordinates.\n                Defaults to None.\n                The conversion from `src` coordinates to `dst` coordinates\n                usually comes along the change of sensors, e.g., from camera\n                to LiDAR. This requires a transformation matrix.\n            with_yaw (bool): If `box` is an instance of\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\n                Defaults to True.\n\n        Returns:\n            (tuple | list | np.ndarray | torch.Tensor |\n                :obj:`BaseInstance3DBoxes`):\n                The converted box of the same type.\n        \"\"\"\n    return Box3DMode.convert(box, src, dst, rt_mat=rt_mat)",
        "mutated": [
            "@staticmethod\ndef convert_box(box, src, dst, rt_mat=None, with_yaw=True):\n    if False:\n        i = 10\n    'Convert boxes from `src` mode to `dst` mode.\\n\\n        Args:\\n            box (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BaseInstance3DBoxes`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode`): The src Box mode.\\n            dst (:obj:`Box3DMode`): The target Box mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes`):\\n                The converted box of the same type.\\n        '\n    return Box3DMode.convert(box, src, dst, rt_mat=rt_mat)",
            "@staticmethod\ndef convert_box(box, src, dst, rt_mat=None, with_yaw=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Convert boxes from `src` mode to `dst` mode.\\n\\n        Args:\\n            box (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BaseInstance3DBoxes`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode`): The src Box mode.\\n            dst (:obj:`Box3DMode`): The target Box mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes`):\\n                The converted box of the same type.\\n        '\n    return Box3DMode.convert(box, src, dst, rt_mat=rt_mat)",
            "@staticmethod\ndef convert_box(box, src, dst, rt_mat=None, with_yaw=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Convert boxes from `src` mode to `dst` mode.\\n\\n        Args:\\n            box (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BaseInstance3DBoxes`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode`): The src Box mode.\\n            dst (:obj:`Box3DMode`): The target Box mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes`):\\n                The converted box of the same type.\\n        '\n    return Box3DMode.convert(box, src, dst, rt_mat=rt_mat)",
            "@staticmethod\ndef convert_box(box, src, dst, rt_mat=None, with_yaw=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Convert boxes from `src` mode to `dst` mode.\\n\\n        Args:\\n            box (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BaseInstance3DBoxes`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode`): The src Box mode.\\n            dst (:obj:`Box3DMode`): The target Box mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes`):\\n                The converted box of the same type.\\n        '\n    return Box3DMode.convert(box, src, dst, rt_mat=rt_mat)",
            "@staticmethod\ndef convert_box(box, src, dst, rt_mat=None, with_yaw=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Convert boxes from `src` mode to `dst` mode.\\n\\n        Args:\\n            box (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BaseInstance3DBoxes`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor, where k = 7.\\n            src (:obj:`Box3DMode`): The src Box mode.\\n            dst (:obj:`Box3DMode`): The target Box mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n            with_yaw (bool): If `box` is an instance of\\n                :obj:`BaseInstance3DBoxes`, whether or not it has a yaw angle.\\n                Defaults to True.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor |\\n                :obj:`BaseInstance3DBoxes`):\\n                The converted box of the same type.\\n        '\n    return Box3DMode.convert(box, src, dst, rt_mat=rt_mat)"
        ]
    },
    {
        "func_name": "convert_point",
        "original": "@staticmethod\ndef convert_point(point, src, dst, rt_mat=None):\n    \"\"\"Convert points from `src` mode to `dst` mode.\n\n        Args:\n            point (tuple | list | np.ndarray |\n                torch.Tensor | :obj:`BasePoints`):\n                Can be a k-tuple, k-list or an Nxk array/tensor.\n            src (:obj:`CoordMode`): The src Point mode.\n            dst (:obj:`CoordMode`): The target Point mode.\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\n                translation matrix between different coordinates.\n                Defaults to None.\n                The conversion from `src` coordinates to `dst` coordinates\n                usually comes along the change of sensors, e.g., from camera\n                to LiDAR. This requires a transformation matrix.\n\n        Returns:\n            (tuple | list | np.ndarray | torch.Tensor | :obj:`BasePoints`):\n                The converted point of the same type.\n        \"\"\"\n    if src == dst:\n        return point\n    is_numpy = isinstance(point, np.ndarray)\n    is_InstancePoints = isinstance(point, BasePoints)\n    single_point = isinstance(point, (list, tuple))\n    if single_point:\n        assert len(point) >= 3, 'CoordMode.convert takes either a k-tuple/list or an Nxk array/tensor, where k >= 3'\n        arr = torch.tensor(point)[None, :]\n    elif is_numpy:\n        arr = torch.from_numpy(np.asarray(point)).clone()\n    elif is_InstancePoints:\n        arr = point.tensor.clone()\n    else:\n        arr = point.clone()\n    if src == Coord3DMode.LIDAR and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [0, 0, -1], [1, 0, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 0, 1], [-1, 0, 0], [0, -1, 0]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n    elif src == Coord3DMode.LIDAR and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    else:\n        raise NotImplementedError(f'Conversion from Coord3DMode {src} to {dst} is not supported yet')\n    if not isinstance(rt_mat, torch.Tensor):\n        rt_mat = arr.new_tensor(rt_mat)\n    if rt_mat.size(1) == 4:\n        extended_xyz = torch.cat([arr[..., :3], arr.new_ones(arr.size(0), 1)], dim=-1)\n        xyz = extended_xyz @ rt_mat.t()\n    else:\n        xyz = arr[..., :3] @ rt_mat.t()\n    remains = arr[..., 3:]\n    arr = torch.cat([xyz[..., :3], remains], dim=-1)\n    original_type = type(point)\n    if single_point:\n        return original_type(arr.flatten().tolist())\n    if is_numpy:\n        return arr.numpy()\n    elif is_InstancePoints:\n        if dst == Coord3DMode.CAM:\n            target_type = CameraPoints\n        elif dst == Coord3DMode.LIDAR:\n            target_type = LiDARPoints\n        elif dst == Coord3DMode.DEPTH:\n            target_type = DepthPoints\n        else:\n            raise NotImplementedError(f'Conversion to {dst} through {original_type} is not supported yet')\n        return target_type(arr, points_dim=arr.size(-1), attribute_dims=point.attribute_dims)\n    else:\n        return arr",
        "mutated": [
            "@staticmethod\ndef convert_point(point, src, dst, rt_mat=None):\n    if False:\n        i = 10\n    'Convert points from `src` mode to `dst` mode.\\n\\n        Args:\\n            point (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor.\\n            src (:obj:`CoordMode`): The src Point mode.\\n            dst (:obj:`CoordMode`): The target Point mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor | :obj:`BasePoints`):\\n                The converted point of the same type.\\n        '\n    if src == dst:\n        return point\n    is_numpy = isinstance(point, np.ndarray)\n    is_InstancePoints = isinstance(point, BasePoints)\n    single_point = isinstance(point, (list, tuple))\n    if single_point:\n        assert len(point) >= 3, 'CoordMode.convert takes either a k-tuple/list or an Nxk array/tensor, where k >= 3'\n        arr = torch.tensor(point)[None, :]\n    elif is_numpy:\n        arr = torch.from_numpy(np.asarray(point)).clone()\n    elif is_InstancePoints:\n        arr = point.tensor.clone()\n    else:\n        arr = point.clone()\n    if src == Coord3DMode.LIDAR and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [0, 0, -1], [1, 0, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 0, 1], [-1, 0, 0], [0, -1, 0]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n    elif src == Coord3DMode.LIDAR and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    else:\n        raise NotImplementedError(f'Conversion from Coord3DMode {src} to {dst} is not supported yet')\n    if not isinstance(rt_mat, torch.Tensor):\n        rt_mat = arr.new_tensor(rt_mat)\n    if rt_mat.size(1) == 4:\n        extended_xyz = torch.cat([arr[..., :3], arr.new_ones(arr.size(0), 1)], dim=-1)\n        xyz = extended_xyz @ rt_mat.t()\n    else:\n        xyz = arr[..., :3] @ rt_mat.t()\n    remains = arr[..., 3:]\n    arr = torch.cat([xyz[..., :3], remains], dim=-1)\n    original_type = type(point)\n    if single_point:\n        return original_type(arr.flatten().tolist())\n    if is_numpy:\n        return arr.numpy()\n    elif is_InstancePoints:\n        if dst == Coord3DMode.CAM:\n            target_type = CameraPoints\n        elif dst == Coord3DMode.LIDAR:\n            target_type = LiDARPoints\n        elif dst == Coord3DMode.DEPTH:\n            target_type = DepthPoints\n        else:\n            raise NotImplementedError(f'Conversion to {dst} through {original_type} is not supported yet')\n        return target_type(arr, points_dim=arr.size(-1), attribute_dims=point.attribute_dims)\n    else:\n        return arr",
            "@staticmethod\ndef convert_point(point, src, dst, rt_mat=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Convert points from `src` mode to `dst` mode.\\n\\n        Args:\\n            point (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor.\\n            src (:obj:`CoordMode`): The src Point mode.\\n            dst (:obj:`CoordMode`): The target Point mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor | :obj:`BasePoints`):\\n                The converted point of the same type.\\n        '\n    if src == dst:\n        return point\n    is_numpy = isinstance(point, np.ndarray)\n    is_InstancePoints = isinstance(point, BasePoints)\n    single_point = isinstance(point, (list, tuple))\n    if single_point:\n        assert len(point) >= 3, 'CoordMode.convert takes either a k-tuple/list or an Nxk array/tensor, where k >= 3'\n        arr = torch.tensor(point)[None, :]\n    elif is_numpy:\n        arr = torch.from_numpy(np.asarray(point)).clone()\n    elif is_InstancePoints:\n        arr = point.tensor.clone()\n    else:\n        arr = point.clone()\n    if src == Coord3DMode.LIDAR and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [0, 0, -1], [1, 0, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 0, 1], [-1, 0, 0], [0, -1, 0]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n    elif src == Coord3DMode.LIDAR and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    else:\n        raise NotImplementedError(f'Conversion from Coord3DMode {src} to {dst} is not supported yet')\n    if not isinstance(rt_mat, torch.Tensor):\n        rt_mat = arr.new_tensor(rt_mat)\n    if rt_mat.size(1) == 4:\n        extended_xyz = torch.cat([arr[..., :3], arr.new_ones(arr.size(0), 1)], dim=-1)\n        xyz = extended_xyz @ rt_mat.t()\n    else:\n        xyz = arr[..., :3] @ rt_mat.t()\n    remains = arr[..., 3:]\n    arr = torch.cat([xyz[..., :3], remains], dim=-1)\n    original_type = type(point)\n    if single_point:\n        return original_type(arr.flatten().tolist())\n    if is_numpy:\n        return arr.numpy()\n    elif is_InstancePoints:\n        if dst == Coord3DMode.CAM:\n            target_type = CameraPoints\n        elif dst == Coord3DMode.LIDAR:\n            target_type = LiDARPoints\n        elif dst == Coord3DMode.DEPTH:\n            target_type = DepthPoints\n        else:\n            raise NotImplementedError(f'Conversion to {dst} through {original_type} is not supported yet')\n        return target_type(arr, points_dim=arr.size(-1), attribute_dims=point.attribute_dims)\n    else:\n        return arr",
            "@staticmethod\ndef convert_point(point, src, dst, rt_mat=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Convert points from `src` mode to `dst` mode.\\n\\n        Args:\\n            point (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor.\\n            src (:obj:`CoordMode`): The src Point mode.\\n            dst (:obj:`CoordMode`): The target Point mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor | :obj:`BasePoints`):\\n                The converted point of the same type.\\n        '\n    if src == dst:\n        return point\n    is_numpy = isinstance(point, np.ndarray)\n    is_InstancePoints = isinstance(point, BasePoints)\n    single_point = isinstance(point, (list, tuple))\n    if single_point:\n        assert len(point) >= 3, 'CoordMode.convert takes either a k-tuple/list or an Nxk array/tensor, where k >= 3'\n        arr = torch.tensor(point)[None, :]\n    elif is_numpy:\n        arr = torch.from_numpy(np.asarray(point)).clone()\n    elif is_InstancePoints:\n        arr = point.tensor.clone()\n    else:\n        arr = point.clone()\n    if src == Coord3DMode.LIDAR and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [0, 0, -1], [1, 0, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 0, 1], [-1, 0, 0], [0, -1, 0]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n    elif src == Coord3DMode.LIDAR and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    else:\n        raise NotImplementedError(f'Conversion from Coord3DMode {src} to {dst} is not supported yet')\n    if not isinstance(rt_mat, torch.Tensor):\n        rt_mat = arr.new_tensor(rt_mat)\n    if rt_mat.size(1) == 4:\n        extended_xyz = torch.cat([arr[..., :3], arr.new_ones(arr.size(0), 1)], dim=-1)\n        xyz = extended_xyz @ rt_mat.t()\n    else:\n        xyz = arr[..., :3] @ rt_mat.t()\n    remains = arr[..., 3:]\n    arr = torch.cat([xyz[..., :3], remains], dim=-1)\n    original_type = type(point)\n    if single_point:\n        return original_type(arr.flatten().tolist())\n    if is_numpy:\n        return arr.numpy()\n    elif is_InstancePoints:\n        if dst == Coord3DMode.CAM:\n            target_type = CameraPoints\n        elif dst == Coord3DMode.LIDAR:\n            target_type = LiDARPoints\n        elif dst == Coord3DMode.DEPTH:\n            target_type = DepthPoints\n        else:\n            raise NotImplementedError(f'Conversion to {dst} through {original_type} is not supported yet')\n        return target_type(arr, points_dim=arr.size(-1), attribute_dims=point.attribute_dims)\n    else:\n        return arr",
            "@staticmethod\ndef convert_point(point, src, dst, rt_mat=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Convert points from `src` mode to `dst` mode.\\n\\n        Args:\\n            point (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor.\\n            src (:obj:`CoordMode`): The src Point mode.\\n            dst (:obj:`CoordMode`): The target Point mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor | :obj:`BasePoints`):\\n                The converted point of the same type.\\n        '\n    if src == dst:\n        return point\n    is_numpy = isinstance(point, np.ndarray)\n    is_InstancePoints = isinstance(point, BasePoints)\n    single_point = isinstance(point, (list, tuple))\n    if single_point:\n        assert len(point) >= 3, 'CoordMode.convert takes either a k-tuple/list or an Nxk array/tensor, where k >= 3'\n        arr = torch.tensor(point)[None, :]\n    elif is_numpy:\n        arr = torch.from_numpy(np.asarray(point)).clone()\n    elif is_InstancePoints:\n        arr = point.tensor.clone()\n    else:\n        arr = point.clone()\n    if src == Coord3DMode.LIDAR and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [0, 0, -1], [1, 0, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 0, 1], [-1, 0, 0], [0, -1, 0]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n    elif src == Coord3DMode.LIDAR and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    else:\n        raise NotImplementedError(f'Conversion from Coord3DMode {src} to {dst} is not supported yet')\n    if not isinstance(rt_mat, torch.Tensor):\n        rt_mat = arr.new_tensor(rt_mat)\n    if rt_mat.size(1) == 4:\n        extended_xyz = torch.cat([arr[..., :3], arr.new_ones(arr.size(0), 1)], dim=-1)\n        xyz = extended_xyz @ rt_mat.t()\n    else:\n        xyz = arr[..., :3] @ rt_mat.t()\n    remains = arr[..., 3:]\n    arr = torch.cat([xyz[..., :3], remains], dim=-1)\n    original_type = type(point)\n    if single_point:\n        return original_type(arr.flatten().tolist())\n    if is_numpy:\n        return arr.numpy()\n    elif is_InstancePoints:\n        if dst == Coord3DMode.CAM:\n            target_type = CameraPoints\n        elif dst == Coord3DMode.LIDAR:\n            target_type = LiDARPoints\n        elif dst == Coord3DMode.DEPTH:\n            target_type = DepthPoints\n        else:\n            raise NotImplementedError(f'Conversion to {dst} through {original_type} is not supported yet')\n        return target_type(arr, points_dim=arr.size(-1), attribute_dims=point.attribute_dims)\n    else:\n        return arr",
            "@staticmethod\ndef convert_point(point, src, dst, rt_mat=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Convert points from `src` mode to `dst` mode.\\n\\n        Args:\\n            point (tuple | list | np.ndarray |\\n                torch.Tensor | :obj:`BasePoints`):\\n                Can be a k-tuple, k-list or an Nxk array/tensor.\\n            src (:obj:`CoordMode`): The src Point mode.\\n            dst (:obj:`CoordMode`): The target Point mode.\\n            rt_mat (np.ndarray | torch.Tensor, optional): The rotation and\\n                translation matrix between different coordinates.\\n                Defaults to None.\\n                The conversion from `src` coordinates to `dst` coordinates\\n                usually comes along the change of sensors, e.g., from camera\\n                to LiDAR. This requires a transformation matrix.\\n\\n        Returns:\\n            (tuple | list | np.ndarray | torch.Tensor | :obj:`BasePoints`):\\n                The converted point of the same type.\\n        '\n    if src == dst:\n        return point\n    is_numpy = isinstance(point, np.ndarray)\n    is_InstancePoints = isinstance(point, BasePoints)\n    single_point = isinstance(point, (list, tuple))\n    if single_point:\n        assert len(point) >= 3, 'CoordMode.convert takes either a k-tuple/list or an Nxk array/tensor, where k >= 3'\n        arr = torch.tensor(point)[None, :]\n    elif is_numpy:\n        arr = torch.from_numpy(np.asarray(point)).clone()\n    elif is_InstancePoints:\n        arr = point.tensor.clone()\n    else:\n        arr = point.clone()\n    if src == Coord3DMode.LIDAR and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [0, 0, -1], [1, 0, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 0, 1], [-1, 0, 0], [0, -1, 0]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.CAM:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\n    elif src == Coord3DMode.CAM and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[1, 0, 0], [0, 0, 1], [0, -1, 0]])\n    elif src == Coord3DMode.LIDAR and dst == Coord3DMode.DEPTH:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    elif src == Coord3DMode.DEPTH and dst == Coord3DMode.LIDAR:\n        if rt_mat is None:\n            rt_mat = arr.new_tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    else:\n        raise NotImplementedError(f'Conversion from Coord3DMode {src} to {dst} is not supported yet')\n    if not isinstance(rt_mat, torch.Tensor):\n        rt_mat = arr.new_tensor(rt_mat)\n    if rt_mat.size(1) == 4:\n        extended_xyz = torch.cat([arr[..., :3], arr.new_ones(arr.size(0), 1)], dim=-1)\n        xyz = extended_xyz @ rt_mat.t()\n    else:\n        xyz = arr[..., :3] @ rt_mat.t()\n    remains = arr[..., 3:]\n    arr = torch.cat([xyz[..., :3], remains], dim=-1)\n    original_type = type(point)\n    if single_point:\n        return original_type(arr.flatten().tolist())\n    if is_numpy:\n        return arr.numpy()\n    elif is_InstancePoints:\n        if dst == Coord3DMode.CAM:\n            target_type = CameraPoints\n        elif dst == Coord3DMode.LIDAR:\n            target_type = LiDARPoints\n        elif dst == Coord3DMode.DEPTH:\n            target_type = DepthPoints\n        else:\n            raise NotImplementedError(f'Conversion to {dst} through {original_type} is not supported yet')\n        return target_type(arr, points_dim=arr.size(-1), attribute_dims=point.attribute_dims)\n    else:\n        return arr"
        ]
    }
]