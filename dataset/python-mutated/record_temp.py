import logging
import warnings
import pandas as pd
import numpy as np
from tqdm import trange
from pprint import pprint
from typing import Union, List, Optional, Dict
from qlib.utils.exceptions import LoadObjectError
from ..contrib.evaluate import risk_analysis, indicator_analysis
from ..data.dataset import DatasetH
from ..data.dataset.handler import DataHandlerLP
from ..backtest import backtest as normal_backtest
from ..log import get_module_logger
from ..utils import fill_placeholder, flatten_dict, class_casting, get_date_by_shift
from ..utils.time import Freq
from ..utils.data import deepcopy_basic_type
from ..utils.exceptions import QlibException
from ..contrib.eva.alpha import calc_ic, calc_long_short_return, calc_long_short_prec
logger = get_module_logger('workflow', logging.INFO)

class RecordTemp:
    """
    This is the Records Template class that enables user to generate experiment results such as IC and
    backtest in a certain format.
    """
    artifact_path = None
    depend_cls = None

    @classmethod
    def get_path(cls, path=None):
        if False:
            i = 10
            return i + 15
        names = []
        if cls.artifact_path is not None:
            names.append(cls.artifact_path)
        if path is not None:
            names.append(path)
        return '/'.join(names)

    def save(self, **kwargs):
        if False:
            for i in range(10):
                print('nop')
        "\n        It behaves the same as self.recorder.save_objects.\n        But it is an easier interface because users don't have to care about `get_path` and `artifact_path`\n        "
        art_path = self.get_path()
        if art_path == '':
            art_path = None
        self.recorder.save_objects(artifact_path=art_path, **kwargs)

    def __init__(self, recorder):
        if False:
            i = 10
            return i + 15
        self._recorder = recorder

    @property
    def recorder(self):
        if False:
            i = 10
            return i + 15
        if self._recorder is None:
            raise ValueError('This RecordTemp did not set recorder yet.')
        return self._recorder

    def generate(self, **kwargs):
        if False:
            i = 10
            return i + 15
        '\n        Generate certain records such as IC, backtest etc., and save them.\n\n        Parameters\n        ----------\n        kwargs\n\n        Return\n        ------\n        '
        raise NotImplementedError(f'Please implement the `generate` method.')

    def load(self, name: str, parents: bool=True):
        if False:
            return 10
        "\n        It behaves the same as self.recorder.load_object.\n        But it is an easier interface because users don't have to care about `get_path` and `artifact_path`\n\n        Parameters\n        ----------\n        name : str\n            the name for the file to be load.\n\n        parents : bool\n            Each recorder has different `artifact_path`.\n            So parents recursively find the path in parents\n            Sub classes has higher priority\n\n        Return\n        ------\n        The stored records.\n        "
        try:
            return self.recorder.load_object(self.get_path(name))
        except LoadObjectError as e:
            if parents:
                if self.depend_cls is not None:
                    with class_casting(self, self.depend_cls):
                        return self.load(name, parents=True)
            raise e

    def list(self):
        if False:
            i = 10
            return i + 15
        "\n        List the supported artifacts.\n        Users don't have to consider self.get_path\n\n        Return\n        ------\n        A list of all the supported artifacts.\n        "
        return []

    def check(self, include_self: bool=False, parents: bool=True):
        if False:
            i = 10
            return i + 15
        '\n        Check if the records is properly generated and saved.\n        It is useful in following examples\n\n        - checking if the dependant files complete before generating new things.\n        - checking if the final files is completed\n\n        Parameters\n        ----------\n        include_self : bool\n            is the file generated by self included\n        parents : bool\n            will we check parents\n\n        Raise\n        ------\n        FileNotFoundError\n            whether the records are stored properly.\n        '
        if include_self:
            artifacts = {}

            def _get_arts(dirn):
                if False:
                    return 10
                if dirn not in artifacts:
                    artifacts[dirn] = self.recorder.list_artifacts(dirn)
                return artifacts[dirn]
            for item in self.list():
                ps = self.get_path(item).split('/')
                dirn = '/'.join(ps[:-1])
                if self.get_path(item) not in _get_arts(dirn):
                    raise FileNotFoundError
        if parents:
            if self.depend_cls is not None:
                with class_casting(self, self.depend_cls):
                    self.check(include_self=True)

class SignalRecord(RecordTemp):
    """
    This is the Signal Record class that generates the signal prediction. This class inherits the ``RecordTemp`` class.
    """

    def __init__(self, model=None, dataset=None, recorder=None):
        if False:
            print('Hello World!')
        super().__init__(recorder=recorder)
        self.model = model
        self.dataset = dataset

    @staticmethod
    def generate_label(dataset):
        if False:
            for i in range(10):
                print('nop')
        with class_casting(dataset, DatasetH):
            params = dict(segments='test', col_set='label', data_key=DataHandlerLP.DK_R)
            try:
                raw_label = dataset.prepare(**params)
            except TypeError:
                del params['data_key']
                raw_label = dataset.prepare(**params)
            except AttributeError as e:
                logger.warning(f'Exception: {e}')
                raw_label = None
        return raw_label

    def generate(self, **kwargs):
        if False:
            while True:
                i = 10
        pred = self.model.predict(self.dataset)
        if isinstance(pred, pd.Series):
            pred = pred.to_frame('score')
        self.save(**{'pred.pkl': pred})
        logger.info(f"Signal record 'pred.pkl' has been saved as the artifact of the Experiment {self.recorder.experiment_id}")
        pprint(f'The following are prediction results of the {type(self.model).__name__} model.')
        pprint(pred.head(5))
        if isinstance(self.dataset, DatasetH):
            raw_label = self.generate_label(self.dataset)
            self.save(**{'label.pkl': raw_label})

    def list(self):
        if False:
            for i in range(10):
                print('nop')
        return ['pred.pkl', 'label.pkl']

class ACRecordTemp(RecordTemp):
    """Automatically checking record template"""

    def __init__(self, recorder, skip_existing=False):
        if False:
            print('Hello World!')
        self.skip_existing = skip_existing
        super().__init__(recorder=recorder)

    def generate(self, *args, **kwargs):
        if False:
            i = 10
            return i + 15
        'automatically checking the files and then run the concrete generating task'
        if self.skip_existing:
            try:
                self.check(include_self=True, parents=False)
            except FileNotFoundError:
                pass
            else:
                logger.info('The results has previously generated, Generation skipped.')
                return
        try:
            self.check()
        except FileNotFoundError:
            logger.warning('The dependent data does not exists. Generation skipped.')
            return
        artifact_dict = self._generate(*args, **kwargs)
        if isinstance(artifact_dict, dict):
            self.save(**artifact_dict)
        return artifact_dict

    def _generate(self, *args, **kwargs) -> Dict[str, object]:
        if False:
            for i in range(10):
                print('nop')
        '\n        Run the concrete generating task, return the dictionary of the generated results.\n        The caller method will save the results to the recorder.\n        '
        raise NotImplementedError(f'Please implement the `_generate` method')

class HFSignalRecord(SignalRecord):
    """
    This is the Signal Analysis Record class that generates the analysis results such as IC and IR. This class inherits the ``RecordTemp`` class.
    """
    artifact_path = 'hg_sig_analysis'
    depend_cls = SignalRecord

    def __init__(self, recorder, **kwargs):
        if False:
            for i in range(10):
                print('nop')
        super().__init__(recorder=recorder)

    def generate(self):
        if False:
            print('Hello World!')
        pred = self.load('pred.pkl')
        raw_label = self.load('label.pkl')
        (long_pre, short_pre) = calc_long_short_prec(pred.iloc[:, 0], raw_label.iloc[:, 0], is_alpha=True)
        (ic, ric) = calc_ic(pred.iloc[:, 0], raw_label.iloc[:, 0])
        metrics = {'IC': ic.mean(), 'ICIR': ic.mean() / ic.std(), 'Rank IC': ric.mean(), 'Rank ICIR': ric.mean() / ric.std(), 'Long precision': long_pre.mean(), 'Short precision': short_pre.mean()}
        objects = {'ic.pkl': ic, 'ric.pkl': ric}
        objects.update({'long_pre.pkl': long_pre, 'short_pre.pkl': short_pre})
        (long_short_r, long_avg_r) = calc_long_short_return(pred.iloc[:, 0], raw_label.iloc[:, 0])
        metrics.update({'Long-Short Average Return': long_short_r.mean(), 'Long-Short Average Sharpe': long_short_r.mean() / long_short_r.std()})
        objects.update({'long_short_r.pkl': long_short_r, 'long_avg_r.pkl': long_avg_r})
        self.recorder.log_metrics(**metrics)
        self.save(**objects)
        pprint(metrics)

    def list(self):
        if False:
            print('Hello World!')
        return ['ic.pkl', 'ric.pkl', 'long_pre.pkl', 'short_pre.pkl', 'long_short_r.pkl', 'long_avg_r.pkl']

class SigAnaRecord(ACRecordTemp):
    """
    This is the Signal Analysis Record class that generates the analysis results such as IC and IR.
    This class inherits the ``RecordTemp`` class.
    """
    artifact_path = 'sig_analysis'
    depend_cls = SignalRecord

    def __init__(self, recorder, ana_long_short=False, ann_scaler=252, label_col=0, skip_existing=False):
        if False:
            for i in range(10):
                print('nop')
        super().__init__(recorder=recorder, skip_existing=skip_existing)
        self.ana_long_short = ana_long_short
        self.ann_scaler = ann_scaler
        self.label_col = label_col

    def _generate(self, label: Optional[pd.DataFrame]=None, **kwargs):
        if False:
            i = 10
            return i + 15
        '\n        Parameters\n        ----------\n        label : Optional[pd.DataFrame]\n            Label should be a dataframe.\n        '
        pred = self.load('pred.pkl')
        if label is None:
            label = self.load('label.pkl')
        if label is None or not isinstance(label, pd.DataFrame) or label.empty:
            logger.warning(f'Empty label.')
            return
        (ic, ric) = calc_ic(pred.iloc[:, 0], label.iloc[:, self.label_col])
        metrics = {'IC': ic.mean(), 'ICIR': ic.mean() / ic.std(), 'Rank IC': ric.mean(), 'Rank ICIR': ric.mean() / ric.std()}
        objects = {'ic.pkl': ic, 'ric.pkl': ric}
        if self.ana_long_short:
            (long_short_r, long_avg_r) = calc_long_short_return(pred.iloc[:, 0], label.iloc[:, self.label_col])
            metrics.update({'Long-Short Ann Return': long_short_r.mean() * self.ann_scaler, 'Long-Short Ann Sharpe': long_short_r.mean() / long_short_r.std() * self.ann_scaler ** 0.5, 'Long-Avg Ann Return': long_avg_r.mean() * self.ann_scaler, 'Long-Avg Ann Sharpe': long_avg_r.mean() / long_avg_r.std() * self.ann_scaler ** 0.5})
            objects.update({'long_short_r.pkl': long_short_r, 'long_avg_r.pkl': long_avg_r})
        self.recorder.log_metrics(**metrics)
        pprint(metrics)
        return objects

    def list(self):
        if False:
            i = 10
            return i + 15
        paths = ['ic.pkl', 'ric.pkl']
        if self.ana_long_short:
            paths.extend(['long_short_r.pkl', 'long_avg_r.pkl'])
        return paths

class PortAnaRecord(ACRecordTemp):
    """
    This is the Portfolio Analysis Record class that generates the analysis results such as those of backtest. This class inherits the ``RecordTemp`` class.

    The following files will be stored in recorder

    - report_normal.pkl & positions_normal.pkl:

        - The return report and detailed positions of the backtest, returned by `qlib/contrib/evaluate.py:backtest`
    - port_analysis.pkl : The risk analysis of your portfolio, returned by `qlib/contrib/evaluate.py:risk_analysis`
    """
    artifact_path = 'portfolio_analysis'
    depend_cls = SignalRecord

    def __init__(self, recorder, config=None, risk_analysis_freq: Union[List, str]=None, indicator_analysis_freq: Union[List, str]=None, indicator_analysis_method=None, skip_existing=False, **kwargs):
        if False:
            for i in range(10):
                print('nop')
        '\n        config["strategy"] : dict\n            define the strategy class as well as the kwargs.\n        config["executor"] : dict\n            define the executor class as well as the kwargs.\n        config["backtest"] : dict\n            define the backtest kwargs.\n        risk_analysis_freq : str|List[str]\n            risk analysis freq of report\n        indicator_analysis_freq : str|List[str]\n            indicator analysis freq of report\n        indicator_analysis_method : str, optional, default by None\n            the candidate values include \'mean\', \'amount_weighted\', \'value_weighted\'\n        '
        super().__init__(recorder=recorder, skip_existing=skip_existing, **kwargs)
        if config is None:
            config = {'strategy': {'class': 'TopkDropoutStrategy', 'module_path': 'qlib.contrib.strategy', 'kwargs': {'signal': '<PRED>', 'topk': 50, 'n_drop': 5}}, 'backtest': {'start_time': None, 'end_time': None, 'account': 100000000, 'benchmark': 'SH000300', 'exchange_kwargs': {'limit_threshold': 0.095, 'deal_price': 'close', 'open_cost': 0.0005, 'close_cost': 0.0015, 'min_cost': 5}}}
        config = deepcopy_basic_type(config)
        self.strategy_config = config['strategy']
        _default_executor_config = {'class': 'SimulatorExecutor', 'module_path': 'qlib.backtest.executor', 'kwargs': {'time_per_step': 'day', 'generate_portfolio_metrics': True}}
        self.executor_config = config.get('executor', _default_executor_config)
        self.backtest_config = config['backtest']
        self.all_freq = self._get_report_freq(self.executor_config)
        if risk_analysis_freq is None:
            risk_analysis_freq = [self.all_freq[0]]
        if indicator_analysis_freq is None:
            indicator_analysis_freq = [self.all_freq[0]]
        if isinstance(risk_analysis_freq, str):
            risk_analysis_freq = [risk_analysis_freq]
        if isinstance(indicator_analysis_freq, str):
            indicator_analysis_freq = [indicator_analysis_freq]
        self.risk_analysis_freq = ['{0}{1}'.format(*Freq.parse(_analysis_freq)) for _analysis_freq in risk_analysis_freq]
        self.indicator_analysis_freq = ['{0}{1}'.format(*Freq.parse(_analysis_freq)) for _analysis_freq in indicator_analysis_freq]
        self.indicator_analysis_method = indicator_analysis_method

    def _get_report_freq(self, executor_config):
        if False:
            print('Hello World!')
        ret_freq = []
        if executor_config['kwargs'].get('generate_portfolio_metrics', False):
            (_count, _freq) = Freq.parse(executor_config['kwargs']['time_per_step'])
            ret_freq.append(f'{_count}{_freq}')
        if 'inner_executor' in executor_config['kwargs']:
            ret_freq.extend(self._get_report_freq(executor_config['kwargs']['inner_executor']))
        return ret_freq

    def _generate(self, **kwargs):
        if False:
            i = 10
            return i + 15
        pred = self.load('pred.pkl')
        placeholder_value = {'<PRED>': pred}
        for k in ('executor_config', 'strategy_config'):
            setattr(self, k, fill_placeholder(getattr(self, k), placeholder_value))
        dt_values = pred.index.get_level_values('datetime')
        if self.backtest_config['start_time'] is None:
            self.backtest_config['start_time'] = dt_values.min()
        if self.backtest_config['end_time'] is None:
            self.backtest_config['end_time'] = get_date_by_shift(dt_values.max(), 1)
        artifact_objects = {}
        (portfolio_metric_dict, indicator_dict) = normal_backtest(executor=self.executor_config, strategy=self.strategy_config, **self.backtest_config)
        for (_freq, (report_normal, positions_normal)) in portfolio_metric_dict.items():
            artifact_objects.update({f'report_normal_{_freq}.pkl': report_normal})
            artifact_objects.update({f'positions_normal_{_freq}.pkl': positions_normal})
        for (_freq, indicators_normal) in indicator_dict.items():
            artifact_objects.update({f'indicators_normal_{_freq}.pkl': indicators_normal[0]})
            artifact_objects.update({f'indicators_normal_{_freq}_obj.pkl': indicators_normal[1]})
        for _analysis_freq in self.risk_analysis_freq:
            if _analysis_freq not in portfolio_metric_dict:
                warnings.warn(f'the freq {_analysis_freq} report is not found, please set the corresponding env with `generate_portfolio_metrics=True`')
            else:
                (report_normal, _) = portfolio_metric_dict.get(_analysis_freq)
                analysis = dict()
                analysis['excess_return_without_cost'] = risk_analysis(report_normal['return'] - report_normal['bench'], freq=_analysis_freq)
                analysis['excess_return_with_cost'] = risk_analysis(report_normal['return'] - report_normal['bench'] - report_normal['cost'], freq=_analysis_freq)
                analysis_df = pd.concat(analysis)
                analysis_dict = flatten_dict(analysis_df['risk'].unstack().T.to_dict())
                self.recorder.log_metrics(**{f'{_analysis_freq}.{k}': v for (k, v) in analysis_dict.items()})
                artifact_objects.update({f'port_analysis_{_analysis_freq}.pkl': analysis_df})
                logger.info(f"Portfolio analysis record 'port_analysis_{_analysis_freq}.pkl' has been saved as the artifact of the Experiment {self.recorder.experiment_id}")
                pprint(f'The following are analysis results of benchmark return({_analysis_freq}).')
                pprint(risk_analysis(report_normal['bench'], freq=_analysis_freq))
                pprint(f'The following are analysis results of the excess return without cost({_analysis_freq}).')
                pprint(analysis['excess_return_without_cost'])
                pprint(f'The following are analysis results of the excess return with cost({_analysis_freq}).')
                pprint(analysis['excess_return_with_cost'])
        for _analysis_freq in self.indicator_analysis_freq:
            if _analysis_freq not in indicator_dict:
                warnings.warn(f'the freq {_analysis_freq} indicator is not found')
            else:
                indicators_normal = indicator_dict.get(_analysis_freq)[0]
                if self.indicator_analysis_method is None:
                    analysis_df = indicator_analysis(indicators_normal)
                else:
                    analysis_df = indicator_analysis(indicators_normal, method=self.indicator_analysis_method)
                analysis_dict = analysis_df['value'].to_dict()
                self.recorder.log_metrics(**{f'{_analysis_freq}.{k}': v for (k, v) in analysis_dict.items()})
                artifact_objects.update({f'indicator_analysis_{_analysis_freq}.pkl': analysis_df})
                logger.info(f"Indicator analysis record 'indicator_analysis_{_analysis_freq}.pkl' has been saved as the artifact of the Experiment {self.recorder.experiment_id}")
                pprint(f'The following are analysis results of indicators({_analysis_freq}).')
                pprint(analysis_df)
        return artifact_objects

    def list(self):
        if False:
            for i in range(10):
                print('nop')
        list_path = []
        for _freq in self.all_freq:
            list_path.extend([f'report_normal_{_freq}.pkl', f'positions_normal_{_freq}.pkl'])
        for _analysis_freq in self.risk_analysis_freq:
            if _analysis_freq in self.all_freq:
                list_path.append(f'port_analysis_{_analysis_freq}.pkl')
            else:
                warnings.warn(f'risk_analysis freq {_analysis_freq} is not found')
        for _analysis_freq in self.indicator_analysis_freq:
            if _analysis_freq in self.all_freq:
                list_path.append(f'indicator_analysis_{_analysis_freq}.pkl')
            else:
                warnings.warn(f'indicator_analysis freq {_analysis_freq} is not found')
        return list_path

class MultiPassPortAnaRecord(PortAnaRecord):
    """
    This is the Multiple Pass Portfolio Analysis Record class that run backtest multiple times and generates the analysis results such as those of backtest. This class inherits the ``PortAnaRecord`` class.

    If shuffle_init_score enabled, the prediction score of the first backtest date will be shuffled, so that initial position will be random.
    The shuffle_init_score will only works when the signal is used as <PRED> placeholder. The placeholder will be replaced by pred.pkl saved in recorder.

    Parameters
    ----------
    recorder : Recorder
        The recorder used to save the backtest results.
    pass_num : int
        The number of backtest passes.
    shuffle_init_score : bool
        Whether to shuffle the prediction score of the first backtest date.
    """
    depend_cls = SignalRecord

    def __init__(self, recorder, pass_num=10, shuffle_init_score=True, **kwargs):
        if False:
            print('Hello World!')
        '\n        Parameters\n        ----------\n        recorder : Recorder\n            The recorder used to save the backtest results.\n        pass_num : int\n            The number of backtest passes.\n        shuffle_init_score : bool\n            Whether to shuffle the prediction score of the first backtest date.\n        '
        self.pass_num = pass_num
        self.shuffle_init_score = shuffle_init_score
        super().__init__(recorder, **kwargs)
        self.original_strategy = deepcopy_basic_type(self.strategy_config)
        if not isinstance(self.original_strategy, dict):
            raise QlibException('MultiPassPortAnaRecord require the passed in strategy to be a dict')
        if 'signal' not in self.original_strategy.get('kwargs', {}):
            raise QlibException('MultiPassPortAnaRecord require the passed in strategy to have signal as a parameter')

    def random_init(self):
        if False:
            for i in range(10):
                print('nop')
        pred_df = self.load('pred.pkl')
        all_pred_dates = pred_df.index.get_level_values('datetime')
        bt_start_date = pd.to_datetime(self.backtest_config.get('start_time'))
        if bt_start_date is None:
            first_bt_pred_date = all_pred_dates.min()
        else:
            first_bt_pred_date = all_pred_dates[all_pred_dates >= bt_start_date].min()
        first_date_score = pred_df.loc[first_bt_pred_date]['score']
        np.random.shuffle(first_date_score.values)
        self.strategy_config = deepcopy_basic_type(self.original_strategy)
        self.strategy_config['kwargs']['signal'] = pred_df

    def _generate(self, **kwargs):
        if False:
            while True:
                i = 10
        risk_analysis_df_map = {}
        for i in trange(self.pass_num):
            if self.shuffle_init_score:
                self.random_init()
            single_run_artifacts = super()._generate(**kwargs)
            for _analysis_freq in self.risk_analysis_freq:
                risk_analysis_df_list = risk_analysis_df_map.get(_analysis_freq, [])
                risk_analysis_df_map[_analysis_freq] = risk_analysis_df_list
                analysis_df = single_run_artifacts[f'port_analysis_{_analysis_freq}.pkl']
                analysis_df['run_id'] = i
                risk_analysis_df_list.append(analysis_df)
        result_artifacts = {}
        for _analysis_freq in self.risk_analysis_freq:
            combined_df = pd.concat(risk_analysis_df_map[_analysis_freq])
            multi_pass_port_analysis_df = combined_df.groupby(level=[0, 1]).apply(lambda x: pd.Series({'mean': x['risk'].mean(), 'std': x['risk'].std(), 'mean_std': x['risk'].mean() / x['risk'].std()}))
            multi_pass_port_analysis_df = multi_pass_port_analysis_df.loc[(slice(None), ['annualized_return', 'information_ratio']), :]
            pprint(multi_pass_port_analysis_df)
            result_artifacts.update({f'multi_pass_port_analysis_{_analysis_freq}.pkl': multi_pass_port_analysis_df})
            metrics = flatten_dict({'mean': multi_pass_port_analysis_df['mean'].unstack().T.to_dict(), 'std': multi_pass_port_analysis_df['std'].unstack().T.to_dict(), 'mean_std': multi_pass_port_analysis_df['mean_std'].unstack().T.to_dict()})
            self.recorder.log_metrics(**metrics)
        return result_artifacts

    def list(self):
        if False:
            return 10
        list_path = []
        for _analysis_freq in self.risk_analysis_freq:
            if _analysis_freq in self.all_freq:
                list_path.append(f'multi_pass_port_analysis_{_analysis_freq}.pkl')
            else:
                warnings.warn(f'risk_analysis freq {_analysis_freq} is not found')
        return list_path