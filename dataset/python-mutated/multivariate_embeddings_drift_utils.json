[
    {
        "func_name": "run_multivariable_drift_for_embeddings",
        "original": "def run_multivariable_drift_for_embeddings(train_dataset: TextData, test_dataset: TextData, sample_size: int, random_state: int, test_size: float, num_samples_in_display: int, dimension_reduction_method: str, model_classes: list, with_display: bool):\n    \"\"\"Calculate multivariable drift on embeddings.\"\"\"\n    np.random.seed(random_state)\n    train_sample = train_dataset.sample(sample_size, random_state=random_state)\n    test_sample = test_dataset.sample(sample_size, random_state=random_state)\n    train_sample_embeddings = train_sample.embeddings\n    test_sample_embeddings = test_sample.embeddings\n    domain_class_array = np.concatenate([train_sample_embeddings, test_sample_embeddings])\n    domain_class_labels = pd.Series([0] * len(train_sample_embeddings) + [1] * len(test_sample_embeddings))\n    use_reduction = not (dimension_reduction_method == 'none' or (dimension_reduction_method == 'auto' and domain_class_array.shape[1] < 30))\n    use_umap = dimension_reduction_method == 'umap' or (dimension_reduction_method == 'auto' and with_display)\n    if use_reduction:\n        if use_umap:\n            reducer = UMAP(n_components=10, n_neighbors=5, init='random', random_state=np.random.RandomState(random_state))\n        else:\n            reducer = PCA(n_components=10, random_state=random_state)\n        samples_for_reducer = min(SAMPLES_FOR_REDUCTION_FIT, len(domain_class_array))\n        samples = np.random.choice(len(domain_class_array), samples_for_reducer, replace=False)\n        reducer.fit(domain_class_array[samples])\n        domain_class_array = reducer.transform(domain_class_array)\n        new_embeddings_train = domain_class_array[:len(train_sample_embeddings)]\n        new_embeddings_test = domain_class_array[len(train_sample_embeddings):]\n        train_sample.set_embeddings(new_embeddings_train, verbose=False)\n        test_sample.set_embeddings(new_embeddings_test, verbose=False)\n    (x_train, x_test, y_train, y_test) = train_test_split(domain_class_array, domain_class_labels, stratify=domain_class_labels, random_state=random_state, test_size=test_size)\n    domain_classifier = GradientBoostingClassifier(max_depth=2, random_state=random_state)\n    domain_classifier.fit(x_train, y_train)\n    y_pred = domain_classifier.predict_proba(x_test)[:, 1]\n    domain_classifier_auc = roc_auc_score(y_test, y_pred)\n    drift_score = auc_to_drift_score(domain_classifier_auc)\n    values_dict = {'domain_classifier_auc': domain_classifier_auc, 'domain_classifier_drift_score': drift_score}\n    if with_display:\n        relevant_index_train = list(y_test[y_test == 0].index)\n        relevant_index_test = [x - len(train_sample_embeddings) for x in y_test[y_test == 1].index]\n        train_sample = train_sample.copy(rows_to_use=relevant_index_train)\n        test_sample = test_sample.copy(rows_to_use=relevant_index_test)\n        num_samples_in_display_train = min(int(num_samples_in_display / 2), sample_size, len(train_sample))\n        train_dataset_for_display = train_sample.sample(num_samples_in_display_train, random_state=random_state)\n        num_samples_in_display_test = min(int(num_samples_in_display / 2), sample_size, len(test_sample))\n        test_dataset_for_display = test_sample.sample(num_samples_in_display_test, random_state=random_state)\n        displays = [build_drift_plot(drift_score), display_embeddings(train_dataset=train_dataset_for_display, test_dataset=test_dataset_for_display, random_state=random_state, model_classes=model_classes)]\n    else:\n        displays = None\n    return (values_dict, displays)",
        "mutated": [
            "def run_multivariable_drift_for_embeddings(train_dataset: TextData, test_dataset: TextData, sample_size: int, random_state: int, test_size: float, num_samples_in_display: int, dimension_reduction_method: str, model_classes: list, with_display: bool):\n    if False:\n        i = 10\n    'Calculate multivariable drift on embeddings.'\n    np.random.seed(random_state)\n    train_sample = train_dataset.sample(sample_size, random_state=random_state)\n    test_sample = test_dataset.sample(sample_size, random_state=random_state)\n    train_sample_embeddings = train_sample.embeddings\n    test_sample_embeddings = test_sample.embeddings\n    domain_class_array = np.concatenate([train_sample_embeddings, test_sample_embeddings])\n    domain_class_labels = pd.Series([0] * len(train_sample_embeddings) + [1] * len(test_sample_embeddings))\n    use_reduction = not (dimension_reduction_method == 'none' or (dimension_reduction_method == 'auto' and domain_class_array.shape[1] < 30))\n    use_umap = dimension_reduction_method == 'umap' or (dimension_reduction_method == 'auto' and with_display)\n    if use_reduction:\n        if use_umap:\n            reducer = UMAP(n_components=10, n_neighbors=5, init='random', random_state=np.random.RandomState(random_state))\n        else:\n            reducer = PCA(n_components=10, random_state=random_state)\n        samples_for_reducer = min(SAMPLES_FOR_REDUCTION_FIT, len(domain_class_array))\n        samples = np.random.choice(len(domain_class_array), samples_for_reducer, replace=False)\n        reducer.fit(domain_class_array[samples])\n        domain_class_array = reducer.transform(domain_class_array)\n        new_embeddings_train = domain_class_array[:len(train_sample_embeddings)]\n        new_embeddings_test = domain_class_array[len(train_sample_embeddings):]\n        train_sample.set_embeddings(new_embeddings_train, verbose=False)\n        test_sample.set_embeddings(new_embeddings_test, verbose=False)\n    (x_train, x_test, y_train, y_test) = train_test_split(domain_class_array, domain_class_labels, stratify=domain_class_labels, random_state=random_state, test_size=test_size)\n    domain_classifier = GradientBoostingClassifier(max_depth=2, random_state=random_state)\n    domain_classifier.fit(x_train, y_train)\n    y_pred = domain_classifier.predict_proba(x_test)[:, 1]\n    domain_classifier_auc = roc_auc_score(y_test, y_pred)\n    drift_score = auc_to_drift_score(domain_classifier_auc)\n    values_dict = {'domain_classifier_auc': domain_classifier_auc, 'domain_classifier_drift_score': drift_score}\n    if with_display:\n        relevant_index_train = list(y_test[y_test == 0].index)\n        relevant_index_test = [x - len(train_sample_embeddings) for x in y_test[y_test == 1].index]\n        train_sample = train_sample.copy(rows_to_use=relevant_index_train)\n        test_sample = test_sample.copy(rows_to_use=relevant_index_test)\n        num_samples_in_display_train = min(int(num_samples_in_display / 2), sample_size, len(train_sample))\n        train_dataset_for_display = train_sample.sample(num_samples_in_display_train, random_state=random_state)\n        num_samples_in_display_test = min(int(num_samples_in_display / 2), sample_size, len(test_sample))\n        test_dataset_for_display = test_sample.sample(num_samples_in_display_test, random_state=random_state)\n        displays = [build_drift_plot(drift_score), display_embeddings(train_dataset=train_dataset_for_display, test_dataset=test_dataset_for_display, random_state=random_state, model_classes=model_classes)]\n    else:\n        displays = None\n    return (values_dict, displays)",
            "def run_multivariable_drift_for_embeddings(train_dataset: TextData, test_dataset: TextData, sample_size: int, random_state: int, test_size: float, num_samples_in_display: int, dimension_reduction_method: str, model_classes: list, with_display: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Calculate multivariable drift on embeddings.'\n    np.random.seed(random_state)\n    train_sample = train_dataset.sample(sample_size, random_state=random_state)\n    test_sample = test_dataset.sample(sample_size, random_state=random_state)\n    train_sample_embeddings = train_sample.embeddings\n    test_sample_embeddings = test_sample.embeddings\n    domain_class_array = np.concatenate([train_sample_embeddings, test_sample_embeddings])\n    domain_class_labels = pd.Series([0] * len(train_sample_embeddings) + [1] * len(test_sample_embeddings))\n    use_reduction = not (dimension_reduction_method == 'none' or (dimension_reduction_method == 'auto' and domain_class_array.shape[1] < 30))\n    use_umap = dimension_reduction_method == 'umap' or (dimension_reduction_method == 'auto' and with_display)\n    if use_reduction:\n        if use_umap:\n            reducer = UMAP(n_components=10, n_neighbors=5, init='random', random_state=np.random.RandomState(random_state))\n        else:\n            reducer = PCA(n_components=10, random_state=random_state)\n        samples_for_reducer = min(SAMPLES_FOR_REDUCTION_FIT, len(domain_class_array))\n        samples = np.random.choice(len(domain_class_array), samples_for_reducer, replace=False)\n        reducer.fit(domain_class_array[samples])\n        domain_class_array = reducer.transform(domain_class_array)\n        new_embeddings_train = domain_class_array[:len(train_sample_embeddings)]\n        new_embeddings_test = domain_class_array[len(train_sample_embeddings):]\n        train_sample.set_embeddings(new_embeddings_train, verbose=False)\n        test_sample.set_embeddings(new_embeddings_test, verbose=False)\n    (x_train, x_test, y_train, y_test) = train_test_split(domain_class_array, domain_class_labels, stratify=domain_class_labels, random_state=random_state, test_size=test_size)\n    domain_classifier = GradientBoostingClassifier(max_depth=2, random_state=random_state)\n    domain_classifier.fit(x_train, y_train)\n    y_pred = domain_classifier.predict_proba(x_test)[:, 1]\n    domain_classifier_auc = roc_auc_score(y_test, y_pred)\n    drift_score = auc_to_drift_score(domain_classifier_auc)\n    values_dict = {'domain_classifier_auc': domain_classifier_auc, 'domain_classifier_drift_score': drift_score}\n    if with_display:\n        relevant_index_train = list(y_test[y_test == 0].index)\n        relevant_index_test = [x - len(train_sample_embeddings) for x in y_test[y_test == 1].index]\n        train_sample = train_sample.copy(rows_to_use=relevant_index_train)\n        test_sample = test_sample.copy(rows_to_use=relevant_index_test)\n        num_samples_in_display_train = min(int(num_samples_in_display / 2), sample_size, len(train_sample))\n        train_dataset_for_display = train_sample.sample(num_samples_in_display_train, random_state=random_state)\n        num_samples_in_display_test = min(int(num_samples_in_display / 2), sample_size, len(test_sample))\n        test_dataset_for_display = test_sample.sample(num_samples_in_display_test, random_state=random_state)\n        displays = [build_drift_plot(drift_score), display_embeddings(train_dataset=train_dataset_for_display, test_dataset=test_dataset_for_display, random_state=random_state, model_classes=model_classes)]\n    else:\n        displays = None\n    return (values_dict, displays)",
            "def run_multivariable_drift_for_embeddings(train_dataset: TextData, test_dataset: TextData, sample_size: int, random_state: int, test_size: float, num_samples_in_display: int, dimension_reduction_method: str, model_classes: list, with_display: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Calculate multivariable drift on embeddings.'\n    np.random.seed(random_state)\n    train_sample = train_dataset.sample(sample_size, random_state=random_state)\n    test_sample = test_dataset.sample(sample_size, random_state=random_state)\n    train_sample_embeddings = train_sample.embeddings\n    test_sample_embeddings = test_sample.embeddings\n    domain_class_array = np.concatenate([train_sample_embeddings, test_sample_embeddings])\n    domain_class_labels = pd.Series([0] * len(train_sample_embeddings) + [1] * len(test_sample_embeddings))\n    use_reduction = not (dimension_reduction_method == 'none' or (dimension_reduction_method == 'auto' and domain_class_array.shape[1] < 30))\n    use_umap = dimension_reduction_method == 'umap' or (dimension_reduction_method == 'auto' and with_display)\n    if use_reduction:\n        if use_umap:\n            reducer = UMAP(n_components=10, n_neighbors=5, init='random', random_state=np.random.RandomState(random_state))\n        else:\n            reducer = PCA(n_components=10, random_state=random_state)\n        samples_for_reducer = min(SAMPLES_FOR_REDUCTION_FIT, len(domain_class_array))\n        samples = np.random.choice(len(domain_class_array), samples_for_reducer, replace=False)\n        reducer.fit(domain_class_array[samples])\n        domain_class_array = reducer.transform(domain_class_array)\n        new_embeddings_train = domain_class_array[:len(train_sample_embeddings)]\n        new_embeddings_test = domain_class_array[len(train_sample_embeddings):]\n        train_sample.set_embeddings(new_embeddings_train, verbose=False)\n        test_sample.set_embeddings(new_embeddings_test, verbose=False)\n    (x_train, x_test, y_train, y_test) = train_test_split(domain_class_array, domain_class_labels, stratify=domain_class_labels, random_state=random_state, test_size=test_size)\n    domain_classifier = GradientBoostingClassifier(max_depth=2, random_state=random_state)\n    domain_classifier.fit(x_train, y_train)\n    y_pred = domain_classifier.predict_proba(x_test)[:, 1]\n    domain_classifier_auc = roc_auc_score(y_test, y_pred)\n    drift_score = auc_to_drift_score(domain_classifier_auc)\n    values_dict = {'domain_classifier_auc': domain_classifier_auc, 'domain_classifier_drift_score': drift_score}\n    if with_display:\n        relevant_index_train = list(y_test[y_test == 0].index)\n        relevant_index_test = [x - len(train_sample_embeddings) for x in y_test[y_test == 1].index]\n        train_sample = train_sample.copy(rows_to_use=relevant_index_train)\n        test_sample = test_sample.copy(rows_to_use=relevant_index_test)\n        num_samples_in_display_train = min(int(num_samples_in_display / 2), sample_size, len(train_sample))\n        train_dataset_for_display = train_sample.sample(num_samples_in_display_train, random_state=random_state)\n        num_samples_in_display_test = min(int(num_samples_in_display / 2), sample_size, len(test_sample))\n        test_dataset_for_display = test_sample.sample(num_samples_in_display_test, random_state=random_state)\n        displays = [build_drift_plot(drift_score), display_embeddings(train_dataset=train_dataset_for_display, test_dataset=test_dataset_for_display, random_state=random_state, model_classes=model_classes)]\n    else:\n        displays = None\n    return (values_dict, displays)",
            "def run_multivariable_drift_for_embeddings(train_dataset: TextData, test_dataset: TextData, sample_size: int, random_state: int, test_size: float, num_samples_in_display: int, dimension_reduction_method: str, model_classes: list, with_display: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Calculate multivariable drift on embeddings.'\n    np.random.seed(random_state)\n    train_sample = train_dataset.sample(sample_size, random_state=random_state)\n    test_sample = test_dataset.sample(sample_size, random_state=random_state)\n    train_sample_embeddings = train_sample.embeddings\n    test_sample_embeddings = test_sample.embeddings\n    domain_class_array = np.concatenate([train_sample_embeddings, test_sample_embeddings])\n    domain_class_labels = pd.Series([0] * len(train_sample_embeddings) + [1] * len(test_sample_embeddings))\n    use_reduction = not (dimension_reduction_method == 'none' or (dimension_reduction_method == 'auto' and domain_class_array.shape[1] < 30))\n    use_umap = dimension_reduction_method == 'umap' or (dimension_reduction_method == 'auto' and with_display)\n    if use_reduction:\n        if use_umap:\n            reducer = UMAP(n_components=10, n_neighbors=5, init='random', random_state=np.random.RandomState(random_state))\n        else:\n            reducer = PCA(n_components=10, random_state=random_state)\n        samples_for_reducer = min(SAMPLES_FOR_REDUCTION_FIT, len(domain_class_array))\n        samples = np.random.choice(len(domain_class_array), samples_for_reducer, replace=False)\n        reducer.fit(domain_class_array[samples])\n        domain_class_array = reducer.transform(domain_class_array)\n        new_embeddings_train = domain_class_array[:len(train_sample_embeddings)]\n        new_embeddings_test = domain_class_array[len(train_sample_embeddings):]\n        train_sample.set_embeddings(new_embeddings_train, verbose=False)\n        test_sample.set_embeddings(new_embeddings_test, verbose=False)\n    (x_train, x_test, y_train, y_test) = train_test_split(domain_class_array, domain_class_labels, stratify=domain_class_labels, random_state=random_state, test_size=test_size)\n    domain_classifier = GradientBoostingClassifier(max_depth=2, random_state=random_state)\n    domain_classifier.fit(x_train, y_train)\n    y_pred = domain_classifier.predict_proba(x_test)[:, 1]\n    domain_classifier_auc = roc_auc_score(y_test, y_pred)\n    drift_score = auc_to_drift_score(domain_classifier_auc)\n    values_dict = {'domain_classifier_auc': domain_classifier_auc, 'domain_classifier_drift_score': drift_score}\n    if with_display:\n        relevant_index_train = list(y_test[y_test == 0].index)\n        relevant_index_test = [x - len(train_sample_embeddings) for x in y_test[y_test == 1].index]\n        train_sample = train_sample.copy(rows_to_use=relevant_index_train)\n        test_sample = test_sample.copy(rows_to_use=relevant_index_test)\n        num_samples_in_display_train = min(int(num_samples_in_display / 2), sample_size, len(train_sample))\n        train_dataset_for_display = train_sample.sample(num_samples_in_display_train, random_state=random_state)\n        num_samples_in_display_test = min(int(num_samples_in_display / 2), sample_size, len(test_sample))\n        test_dataset_for_display = test_sample.sample(num_samples_in_display_test, random_state=random_state)\n        displays = [build_drift_plot(drift_score), display_embeddings(train_dataset=train_dataset_for_display, test_dataset=test_dataset_for_display, random_state=random_state, model_classes=model_classes)]\n    else:\n        displays = None\n    return (values_dict, displays)",
            "def run_multivariable_drift_for_embeddings(train_dataset: TextData, test_dataset: TextData, sample_size: int, random_state: int, test_size: float, num_samples_in_display: int, dimension_reduction_method: str, model_classes: list, with_display: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Calculate multivariable drift on embeddings.'\n    np.random.seed(random_state)\n    train_sample = train_dataset.sample(sample_size, random_state=random_state)\n    test_sample = test_dataset.sample(sample_size, random_state=random_state)\n    train_sample_embeddings = train_sample.embeddings\n    test_sample_embeddings = test_sample.embeddings\n    domain_class_array = np.concatenate([train_sample_embeddings, test_sample_embeddings])\n    domain_class_labels = pd.Series([0] * len(train_sample_embeddings) + [1] * len(test_sample_embeddings))\n    use_reduction = not (dimension_reduction_method == 'none' or (dimension_reduction_method == 'auto' and domain_class_array.shape[1] < 30))\n    use_umap = dimension_reduction_method == 'umap' or (dimension_reduction_method == 'auto' and with_display)\n    if use_reduction:\n        if use_umap:\n            reducer = UMAP(n_components=10, n_neighbors=5, init='random', random_state=np.random.RandomState(random_state))\n        else:\n            reducer = PCA(n_components=10, random_state=random_state)\n        samples_for_reducer = min(SAMPLES_FOR_REDUCTION_FIT, len(domain_class_array))\n        samples = np.random.choice(len(domain_class_array), samples_for_reducer, replace=False)\n        reducer.fit(domain_class_array[samples])\n        domain_class_array = reducer.transform(domain_class_array)\n        new_embeddings_train = domain_class_array[:len(train_sample_embeddings)]\n        new_embeddings_test = domain_class_array[len(train_sample_embeddings):]\n        train_sample.set_embeddings(new_embeddings_train, verbose=False)\n        test_sample.set_embeddings(new_embeddings_test, verbose=False)\n    (x_train, x_test, y_train, y_test) = train_test_split(domain_class_array, domain_class_labels, stratify=domain_class_labels, random_state=random_state, test_size=test_size)\n    domain_classifier = GradientBoostingClassifier(max_depth=2, random_state=random_state)\n    domain_classifier.fit(x_train, y_train)\n    y_pred = domain_classifier.predict_proba(x_test)[:, 1]\n    domain_classifier_auc = roc_auc_score(y_test, y_pred)\n    drift_score = auc_to_drift_score(domain_classifier_auc)\n    values_dict = {'domain_classifier_auc': domain_classifier_auc, 'domain_classifier_drift_score': drift_score}\n    if with_display:\n        relevant_index_train = list(y_test[y_test == 0].index)\n        relevant_index_test = [x - len(train_sample_embeddings) for x in y_test[y_test == 1].index]\n        train_sample = train_sample.copy(rows_to_use=relevant_index_train)\n        test_sample = test_sample.copy(rows_to_use=relevant_index_test)\n        num_samples_in_display_train = min(int(num_samples_in_display / 2), sample_size, len(train_sample))\n        train_dataset_for_display = train_sample.sample(num_samples_in_display_train, random_state=random_state)\n        num_samples_in_display_test = min(int(num_samples_in_display / 2), sample_size, len(test_sample))\n        test_dataset_for_display = test_sample.sample(num_samples_in_display_test, random_state=random_state)\n        displays = [build_drift_plot(drift_score), display_embeddings(train_dataset=train_dataset_for_display, test_dataset=test_dataset_for_display, random_state=random_state, model_classes=model_classes)]\n    else:\n        displays = None\n    return (values_dict, displays)"
        ]
    },
    {
        "func_name": "display_embeddings",
        "original": "def display_embeddings(train_dataset: TextData, test_dataset: TextData, random_state: int, model_classes: list):\n    \"\"\"Display the embeddings with the domain classifier proba as the x-axis and the embeddings as the y-axis.\"\"\"\n    embeddings = np.concatenate([train_dataset.embeddings, test_dataset.embeddings])\n    reducer = UMAP(n_components=2, n_neighbors=5, init='random', min_dist=1, random_state=random_state)\n    reduced_embeddings = reducer.fit_transform(embeddings)\n    x_axis_title = 'Reduced Embedding (0)'\n    y_axis_title = 'Reduced Embedding (1)'\n    plot_data = pd.DataFrame({x_axis_title: reduced_embeddings[:, 0], y_axis_title: reduced_embeddings[:, 1]})\n    plot_title = 'Scatter Plot of Embeddings Space (reduced to 2 dimensions)'\n    return two_datasets_scatter_plot(plot_title=plot_title, plot_data=plot_data, train_dataset=train_dataset, test_dataset=test_dataset, model_classes=model_classes)",
        "mutated": [
            "def display_embeddings(train_dataset: TextData, test_dataset: TextData, random_state: int, model_classes: list):\n    if False:\n        i = 10\n    'Display the embeddings with the domain classifier proba as the x-axis and the embeddings as the y-axis.'\n    embeddings = np.concatenate([train_dataset.embeddings, test_dataset.embeddings])\n    reducer = UMAP(n_components=2, n_neighbors=5, init='random', min_dist=1, random_state=random_state)\n    reduced_embeddings = reducer.fit_transform(embeddings)\n    x_axis_title = 'Reduced Embedding (0)'\n    y_axis_title = 'Reduced Embedding (1)'\n    plot_data = pd.DataFrame({x_axis_title: reduced_embeddings[:, 0], y_axis_title: reduced_embeddings[:, 1]})\n    plot_title = 'Scatter Plot of Embeddings Space (reduced to 2 dimensions)'\n    return two_datasets_scatter_plot(plot_title=plot_title, plot_data=plot_data, train_dataset=train_dataset, test_dataset=test_dataset, model_classes=model_classes)",
            "def display_embeddings(train_dataset: TextData, test_dataset: TextData, random_state: int, model_classes: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Display the embeddings with the domain classifier proba as the x-axis and the embeddings as the y-axis.'\n    embeddings = np.concatenate([train_dataset.embeddings, test_dataset.embeddings])\n    reducer = UMAP(n_components=2, n_neighbors=5, init='random', min_dist=1, random_state=random_state)\n    reduced_embeddings = reducer.fit_transform(embeddings)\n    x_axis_title = 'Reduced Embedding (0)'\n    y_axis_title = 'Reduced Embedding (1)'\n    plot_data = pd.DataFrame({x_axis_title: reduced_embeddings[:, 0], y_axis_title: reduced_embeddings[:, 1]})\n    plot_title = 'Scatter Plot of Embeddings Space (reduced to 2 dimensions)'\n    return two_datasets_scatter_plot(plot_title=plot_title, plot_data=plot_data, train_dataset=train_dataset, test_dataset=test_dataset, model_classes=model_classes)",
            "def display_embeddings(train_dataset: TextData, test_dataset: TextData, random_state: int, model_classes: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Display the embeddings with the domain classifier proba as the x-axis and the embeddings as the y-axis.'\n    embeddings = np.concatenate([train_dataset.embeddings, test_dataset.embeddings])\n    reducer = UMAP(n_components=2, n_neighbors=5, init='random', min_dist=1, random_state=random_state)\n    reduced_embeddings = reducer.fit_transform(embeddings)\n    x_axis_title = 'Reduced Embedding (0)'\n    y_axis_title = 'Reduced Embedding (1)'\n    plot_data = pd.DataFrame({x_axis_title: reduced_embeddings[:, 0], y_axis_title: reduced_embeddings[:, 1]})\n    plot_title = 'Scatter Plot of Embeddings Space (reduced to 2 dimensions)'\n    return two_datasets_scatter_plot(plot_title=plot_title, plot_data=plot_data, train_dataset=train_dataset, test_dataset=test_dataset, model_classes=model_classes)",
            "def display_embeddings(train_dataset: TextData, test_dataset: TextData, random_state: int, model_classes: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Display the embeddings with the domain classifier proba as the x-axis and the embeddings as the y-axis.'\n    embeddings = np.concatenate([train_dataset.embeddings, test_dataset.embeddings])\n    reducer = UMAP(n_components=2, n_neighbors=5, init='random', min_dist=1, random_state=random_state)\n    reduced_embeddings = reducer.fit_transform(embeddings)\n    x_axis_title = 'Reduced Embedding (0)'\n    y_axis_title = 'Reduced Embedding (1)'\n    plot_data = pd.DataFrame({x_axis_title: reduced_embeddings[:, 0], y_axis_title: reduced_embeddings[:, 1]})\n    plot_title = 'Scatter Plot of Embeddings Space (reduced to 2 dimensions)'\n    return two_datasets_scatter_plot(plot_title=plot_title, plot_data=plot_data, train_dataset=train_dataset, test_dataset=test_dataset, model_classes=model_classes)",
            "def display_embeddings(train_dataset: TextData, test_dataset: TextData, random_state: int, model_classes: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Display the embeddings with the domain classifier proba as the x-axis and the embeddings as the y-axis.'\n    embeddings = np.concatenate([train_dataset.embeddings, test_dataset.embeddings])\n    reducer = UMAP(n_components=2, n_neighbors=5, init='random', min_dist=1, random_state=random_state)\n    reduced_embeddings = reducer.fit_transform(embeddings)\n    x_axis_title = 'Reduced Embedding (0)'\n    y_axis_title = 'Reduced Embedding (1)'\n    plot_data = pd.DataFrame({x_axis_title: reduced_embeddings[:, 0], y_axis_title: reduced_embeddings[:, 1]})\n    plot_title = 'Scatter Plot of Embeddings Space (reduced to 2 dimensions)'\n    return two_datasets_scatter_plot(plot_title=plot_title, plot_data=plot_data, train_dataset=train_dataset, test_dataset=test_dataset, model_classes=model_classes)"
        ]
    }
]