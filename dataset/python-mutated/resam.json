[
    {
        "func_name": "resam_calendar",
        "original": "def resam_calendar(calendar_raw: np.ndarray, freq_raw: Union[str, Freq], freq_sam: Union[str, Freq], region: str=None) -> np.ndarray:\n    \"\"\"\n    Resample the calendar with frequency freq_raw into the calendar with frequency freq_sam\n    Assumption:\n        - Fix length (240) of the calendar in each day.\n\n    Parameters\n    ----------\n    calendar_raw : np.ndarray\n        The calendar with frequency  freq_raw\n    freq_raw : str\n        Frequency of the raw calendar\n    freq_sam : str\n        Sample frequency\n    region: str\n        Region, for example, \"cn\", \"us\"\n    Returns\n    -------\n    np.ndarray\n        The calendar with frequency freq_sam\n    \"\"\"\n    if region is None:\n        region = C['region']\n    freq_raw = Freq(freq_raw)\n    freq_sam = Freq(freq_sam)\n    if not len(calendar_raw):\n        return calendar_raw\n    if freq_sam.base == Freq.NORM_FREQ_MINUTE:\n        if freq_raw.base != Freq.NORM_FREQ_MINUTE:\n            raise ValueError('when sampling minute calendar, freq of raw calendar must be minute or min')\n        elif freq_raw.count > freq_sam.count:\n            raise ValueError('raw freq must be higher than sampling freq')\n        _calendar_minute = np.unique(list(map(lambda x: cal_sam_minute(x, freq_sam.count, region), calendar_raw)))\n        return _calendar_minute\n    else:\n        _calendar_day = np.unique(list(map(lambda x: pd.Timestamp(x.year, x.month, x.day, 0, 0, 0), calendar_raw)))\n        if freq_sam.base == Freq.NORM_FREQ_DAY:\n            return _calendar_day[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_WEEK:\n            _day_in_week = np.array(list(map(lambda x: x.dayofweek, _calendar_day)))\n            _calendar_week = _calendar_day[np.ediff1d(_day_in_week, to_begin=-1) < 0]\n            return _calendar_week[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_MONTH:\n            _day_in_month = np.array(list(map(lambda x: x.day, _calendar_day)))\n            _calendar_month = _calendar_day[np.ediff1d(_day_in_month, to_begin=-1) < 0]\n            return _calendar_month[::freq_sam.count]\n        else:\n            raise ValueError('sampling freq must be xmin, xd, xw, xm')",
        "mutated": [
            "def resam_calendar(calendar_raw: np.ndarray, freq_raw: Union[str, Freq], freq_sam: Union[str, Freq], region: str=None) -> np.ndarray:\n    if False:\n        i = 10\n    '\\n    Resample the calendar with frequency freq_raw into the calendar with frequency freq_sam\\n    Assumption:\\n        - Fix length (240) of the calendar in each day.\\n\\n    Parameters\\n    ----------\\n    calendar_raw : np.ndarray\\n        The calendar with frequency  freq_raw\\n    freq_raw : str\\n        Frequency of the raw calendar\\n    freq_sam : str\\n        Sample frequency\\n    region: str\\n        Region, for example, \"cn\", \"us\"\\n    Returns\\n    -------\\n    np.ndarray\\n        The calendar with frequency freq_sam\\n    '\n    if region is None:\n        region = C['region']\n    freq_raw = Freq(freq_raw)\n    freq_sam = Freq(freq_sam)\n    if not len(calendar_raw):\n        return calendar_raw\n    if freq_sam.base == Freq.NORM_FREQ_MINUTE:\n        if freq_raw.base != Freq.NORM_FREQ_MINUTE:\n            raise ValueError('when sampling minute calendar, freq of raw calendar must be minute or min')\n        elif freq_raw.count > freq_sam.count:\n            raise ValueError('raw freq must be higher than sampling freq')\n        _calendar_minute = np.unique(list(map(lambda x: cal_sam_minute(x, freq_sam.count, region), calendar_raw)))\n        return _calendar_minute\n    else:\n        _calendar_day = np.unique(list(map(lambda x: pd.Timestamp(x.year, x.month, x.day, 0, 0, 0), calendar_raw)))\n        if freq_sam.base == Freq.NORM_FREQ_DAY:\n            return _calendar_day[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_WEEK:\n            _day_in_week = np.array(list(map(lambda x: x.dayofweek, _calendar_day)))\n            _calendar_week = _calendar_day[np.ediff1d(_day_in_week, to_begin=-1) < 0]\n            return _calendar_week[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_MONTH:\n            _day_in_month = np.array(list(map(lambda x: x.day, _calendar_day)))\n            _calendar_month = _calendar_day[np.ediff1d(_day_in_month, to_begin=-1) < 0]\n            return _calendar_month[::freq_sam.count]\n        else:\n            raise ValueError('sampling freq must be xmin, xd, xw, xm')",
            "def resam_calendar(calendar_raw: np.ndarray, freq_raw: Union[str, Freq], freq_sam: Union[str, Freq], region: str=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Resample the calendar with frequency freq_raw into the calendar with frequency freq_sam\\n    Assumption:\\n        - Fix length (240) of the calendar in each day.\\n\\n    Parameters\\n    ----------\\n    calendar_raw : np.ndarray\\n        The calendar with frequency  freq_raw\\n    freq_raw : str\\n        Frequency of the raw calendar\\n    freq_sam : str\\n        Sample frequency\\n    region: str\\n        Region, for example, \"cn\", \"us\"\\n    Returns\\n    -------\\n    np.ndarray\\n        The calendar with frequency freq_sam\\n    '\n    if region is None:\n        region = C['region']\n    freq_raw = Freq(freq_raw)\n    freq_sam = Freq(freq_sam)\n    if not len(calendar_raw):\n        return calendar_raw\n    if freq_sam.base == Freq.NORM_FREQ_MINUTE:\n        if freq_raw.base != Freq.NORM_FREQ_MINUTE:\n            raise ValueError('when sampling minute calendar, freq of raw calendar must be minute or min')\n        elif freq_raw.count > freq_sam.count:\n            raise ValueError('raw freq must be higher than sampling freq')\n        _calendar_minute = np.unique(list(map(lambda x: cal_sam_minute(x, freq_sam.count, region), calendar_raw)))\n        return _calendar_minute\n    else:\n        _calendar_day = np.unique(list(map(lambda x: pd.Timestamp(x.year, x.month, x.day, 0, 0, 0), calendar_raw)))\n        if freq_sam.base == Freq.NORM_FREQ_DAY:\n            return _calendar_day[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_WEEK:\n            _day_in_week = np.array(list(map(lambda x: x.dayofweek, _calendar_day)))\n            _calendar_week = _calendar_day[np.ediff1d(_day_in_week, to_begin=-1) < 0]\n            return _calendar_week[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_MONTH:\n            _day_in_month = np.array(list(map(lambda x: x.day, _calendar_day)))\n            _calendar_month = _calendar_day[np.ediff1d(_day_in_month, to_begin=-1) < 0]\n            return _calendar_month[::freq_sam.count]\n        else:\n            raise ValueError('sampling freq must be xmin, xd, xw, xm')",
            "def resam_calendar(calendar_raw: np.ndarray, freq_raw: Union[str, Freq], freq_sam: Union[str, Freq], region: str=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Resample the calendar with frequency freq_raw into the calendar with frequency freq_sam\\n    Assumption:\\n        - Fix length (240) of the calendar in each day.\\n\\n    Parameters\\n    ----------\\n    calendar_raw : np.ndarray\\n        The calendar with frequency  freq_raw\\n    freq_raw : str\\n        Frequency of the raw calendar\\n    freq_sam : str\\n        Sample frequency\\n    region: str\\n        Region, for example, \"cn\", \"us\"\\n    Returns\\n    -------\\n    np.ndarray\\n        The calendar with frequency freq_sam\\n    '\n    if region is None:\n        region = C['region']\n    freq_raw = Freq(freq_raw)\n    freq_sam = Freq(freq_sam)\n    if not len(calendar_raw):\n        return calendar_raw\n    if freq_sam.base == Freq.NORM_FREQ_MINUTE:\n        if freq_raw.base != Freq.NORM_FREQ_MINUTE:\n            raise ValueError('when sampling minute calendar, freq of raw calendar must be minute or min')\n        elif freq_raw.count > freq_sam.count:\n            raise ValueError('raw freq must be higher than sampling freq')\n        _calendar_minute = np.unique(list(map(lambda x: cal_sam_minute(x, freq_sam.count, region), calendar_raw)))\n        return _calendar_minute\n    else:\n        _calendar_day = np.unique(list(map(lambda x: pd.Timestamp(x.year, x.month, x.day, 0, 0, 0), calendar_raw)))\n        if freq_sam.base == Freq.NORM_FREQ_DAY:\n            return _calendar_day[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_WEEK:\n            _day_in_week = np.array(list(map(lambda x: x.dayofweek, _calendar_day)))\n            _calendar_week = _calendar_day[np.ediff1d(_day_in_week, to_begin=-1) < 0]\n            return _calendar_week[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_MONTH:\n            _day_in_month = np.array(list(map(lambda x: x.day, _calendar_day)))\n            _calendar_month = _calendar_day[np.ediff1d(_day_in_month, to_begin=-1) < 0]\n            return _calendar_month[::freq_sam.count]\n        else:\n            raise ValueError('sampling freq must be xmin, xd, xw, xm')",
            "def resam_calendar(calendar_raw: np.ndarray, freq_raw: Union[str, Freq], freq_sam: Union[str, Freq], region: str=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Resample the calendar with frequency freq_raw into the calendar with frequency freq_sam\\n    Assumption:\\n        - Fix length (240) of the calendar in each day.\\n\\n    Parameters\\n    ----------\\n    calendar_raw : np.ndarray\\n        The calendar with frequency  freq_raw\\n    freq_raw : str\\n        Frequency of the raw calendar\\n    freq_sam : str\\n        Sample frequency\\n    region: str\\n        Region, for example, \"cn\", \"us\"\\n    Returns\\n    -------\\n    np.ndarray\\n        The calendar with frequency freq_sam\\n    '\n    if region is None:\n        region = C['region']\n    freq_raw = Freq(freq_raw)\n    freq_sam = Freq(freq_sam)\n    if not len(calendar_raw):\n        return calendar_raw\n    if freq_sam.base == Freq.NORM_FREQ_MINUTE:\n        if freq_raw.base != Freq.NORM_FREQ_MINUTE:\n            raise ValueError('when sampling minute calendar, freq of raw calendar must be minute or min')\n        elif freq_raw.count > freq_sam.count:\n            raise ValueError('raw freq must be higher than sampling freq')\n        _calendar_minute = np.unique(list(map(lambda x: cal_sam_minute(x, freq_sam.count, region), calendar_raw)))\n        return _calendar_minute\n    else:\n        _calendar_day = np.unique(list(map(lambda x: pd.Timestamp(x.year, x.month, x.day, 0, 0, 0), calendar_raw)))\n        if freq_sam.base == Freq.NORM_FREQ_DAY:\n            return _calendar_day[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_WEEK:\n            _day_in_week = np.array(list(map(lambda x: x.dayofweek, _calendar_day)))\n            _calendar_week = _calendar_day[np.ediff1d(_day_in_week, to_begin=-1) < 0]\n            return _calendar_week[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_MONTH:\n            _day_in_month = np.array(list(map(lambda x: x.day, _calendar_day)))\n            _calendar_month = _calendar_day[np.ediff1d(_day_in_month, to_begin=-1) < 0]\n            return _calendar_month[::freq_sam.count]\n        else:\n            raise ValueError('sampling freq must be xmin, xd, xw, xm')",
            "def resam_calendar(calendar_raw: np.ndarray, freq_raw: Union[str, Freq], freq_sam: Union[str, Freq], region: str=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Resample the calendar with frequency freq_raw into the calendar with frequency freq_sam\\n    Assumption:\\n        - Fix length (240) of the calendar in each day.\\n\\n    Parameters\\n    ----------\\n    calendar_raw : np.ndarray\\n        The calendar with frequency  freq_raw\\n    freq_raw : str\\n        Frequency of the raw calendar\\n    freq_sam : str\\n        Sample frequency\\n    region: str\\n        Region, for example, \"cn\", \"us\"\\n    Returns\\n    -------\\n    np.ndarray\\n        The calendar with frequency freq_sam\\n    '\n    if region is None:\n        region = C['region']\n    freq_raw = Freq(freq_raw)\n    freq_sam = Freq(freq_sam)\n    if not len(calendar_raw):\n        return calendar_raw\n    if freq_sam.base == Freq.NORM_FREQ_MINUTE:\n        if freq_raw.base != Freq.NORM_FREQ_MINUTE:\n            raise ValueError('when sampling minute calendar, freq of raw calendar must be minute or min')\n        elif freq_raw.count > freq_sam.count:\n            raise ValueError('raw freq must be higher than sampling freq')\n        _calendar_minute = np.unique(list(map(lambda x: cal_sam_minute(x, freq_sam.count, region), calendar_raw)))\n        return _calendar_minute\n    else:\n        _calendar_day = np.unique(list(map(lambda x: pd.Timestamp(x.year, x.month, x.day, 0, 0, 0), calendar_raw)))\n        if freq_sam.base == Freq.NORM_FREQ_DAY:\n            return _calendar_day[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_WEEK:\n            _day_in_week = np.array(list(map(lambda x: x.dayofweek, _calendar_day)))\n            _calendar_week = _calendar_day[np.ediff1d(_day_in_week, to_begin=-1) < 0]\n            return _calendar_week[::freq_sam.count]\n        elif freq_sam.base == Freq.NORM_FREQ_MONTH:\n            _day_in_month = np.array(list(map(lambda x: x.day, _calendar_day)))\n            _calendar_month = _calendar_day[np.ediff1d(_day_in_month, to_begin=-1) < 0]\n            return _calendar_month[::freq_sam.count]\n        else:\n            raise ValueError('sampling freq must be xmin, xd, xw, xm')"
        ]
    },
    {
        "func_name": "get_higher_eq_freq_feature",
        "original": "def get_higher_eq_freq_feature(instruments, fields, start_time=None, end_time=None, freq='day', disk_cache=1):\n    \"\"\"get the feature with higher or equal frequency than `freq`.\n    Returns\n    -------\n    pd.DataFrame\n        the feature with higher or equal frequency\n    \"\"\"\n    from ..data.data import D\n    try:\n        _result = D.features(instruments, fields, start_time, end_time, freq=freq, disk_cache=disk_cache)\n        _freq = freq\n    except (ValueError, KeyError) as value_key_e:\n        (_, norm_freq) = Freq.parse(freq)\n        if norm_freq in [Freq.NORM_FREQ_MONTH, Freq.NORM_FREQ_WEEK, Freq.NORM_FREQ_DAY]:\n            try:\n                _result = D.features(instruments, fields, start_time, end_time, freq='day', disk_cache=disk_cache)\n                _freq = 'day'\n            except (ValueError, KeyError):\n                _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n                _freq = '1min'\n        elif norm_freq == Freq.NORM_FREQ_MINUTE:\n            _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n            _freq = '1min'\n        else:\n            raise ValueError(f'freq {freq} is not supported') from value_key_e\n    return (_result, _freq)",
        "mutated": [
            "def get_higher_eq_freq_feature(instruments, fields, start_time=None, end_time=None, freq='day', disk_cache=1):\n    if False:\n        i = 10\n    'get the feature with higher or equal frequency than `freq`.\\n    Returns\\n    -------\\n    pd.DataFrame\\n        the feature with higher or equal frequency\\n    '\n    from ..data.data import D\n    try:\n        _result = D.features(instruments, fields, start_time, end_time, freq=freq, disk_cache=disk_cache)\n        _freq = freq\n    except (ValueError, KeyError) as value_key_e:\n        (_, norm_freq) = Freq.parse(freq)\n        if norm_freq in [Freq.NORM_FREQ_MONTH, Freq.NORM_FREQ_WEEK, Freq.NORM_FREQ_DAY]:\n            try:\n                _result = D.features(instruments, fields, start_time, end_time, freq='day', disk_cache=disk_cache)\n                _freq = 'day'\n            except (ValueError, KeyError):\n                _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n                _freq = '1min'\n        elif norm_freq == Freq.NORM_FREQ_MINUTE:\n            _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n            _freq = '1min'\n        else:\n            raise ValueError(f'freq {freq} is not supported') from value_key_e\n    return (_result, _freq)",
            "def get_higher_eq_freq_feature(instruments, fields, start_time=None, end_time=None, freq='day', disk_cache=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'get the feature with higher or equal frequency than `freq`.\\n    Returns\\n    -------\\n    pd.DataFrame\\n        the feature with higher or equal frequency\\n    '\n    from ..data.data import D\n    try:\n        _result = D.features(instruments, fields, start_time, end_time, freq=freq, disk_cache=disk_cache)\n        _freq = freq\n    except (ValueError, KeyError) as value_key_e:\n        (_, norm_freq) = Freq.parse(freq)\n        if norm_freq in [Freq.NORM_FREQ_MONTH, Freq.NORM_FREQ_WEEK, Freq.NORM_FREQ_DAY]:\n            try:\n                _result = D.features(instruments, fields, start_time, end_time, freq='day', disk_cache=disk_cache)\n                _freq = 'day'\n            except (ValueError, KeyError):\n                _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n                _freq = '1min'\n        elif norm_freq == Freq.NORM_FREQ_MINUTE:\n            _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n            _freq = '1min'\n        else:\n            raise ValueError(f'freq {freq} is not supported') from value_key_e\n    return (_result, _freq)",
            "def get_higher_eq_freq_feature(instruments, fields, start_time=None, end_time=None, freq='day', disk_cache=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'get the feature with higher or equal frequency than `freq`.\\n    Returns\\n    -------\\n    pd.DataFrame\\n        the feature with higher or equal frequency\\n    '\n    from ..data.data import D\n    try:\n        _result = D.features(instruments, fields, start_time, end_time, freq=freq, disk_cache=disk_cache)\n        _freq = freq\n    except (ValueError, KeyError) as value_key_e:\n        (_, norm_freq) = Freq.parse(freq)\n        if norm_freq in [Freq.NORM_FREQ_MONTH, Freq.NORM_FREQ_WEEK, Freq.NORM_FREQ_DAY]:\n            try:\n                _result = D.features(instruments, fields, start_time, end_time, freq='day', disk_cache=disk_cache)\n                _freq = 'day'\n            except (ValueError, KeyError):\n                _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n                _freq = '1min'\n        elif norm_freq == Freq.NORM_FREQ_MINUTE:\n            _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n            _freq = '1min'\n        else:\n            raise ValueError(f'freq {freq} is not supported') from value_key_e\n    return (_result, _freq)",
            "def get_higher_eq_freq_feature(instruments, fields, start_time=None, end_time=None, freq='day', disk_cache=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'get the feature with higher or equal frequency than `freq`.\\n    Returns\\n    -------\\n    pd.DataFrame\\n        the feature with higher or equal frequency\\n    '\n    from ..data.data import D\n    try:\n        _result = D.features(instruments, fields, start_time, end_time, freq=freq, disk_cache=disk_cache)\n        _freq = freq\n    except (ValueError, KeyError) as value_key_e:\n        (_, norm_freq) = Freq.parse(freq)\n        if norm_freq in [Freq.NORM_FREQ_MONTH, Freq.NORM_FREQ_WEEK, Freq.NORM_FREQ_DAY]:\n            try:\n                _result = D.features(instruments, fields, start_time, end_time, freq='day', disk_cache=disk_cache)\n                _freq = 'day'\n            except (ValueError, KeyError):\n                _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n                _freq = '1min'\n        elif norm_freq == Freq.NORM_FREQ_MINUTE:\n            _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n            _freq = '1min'\n        else:\n            raise ValueError(f'freq {freq} is not supported') from value_key_e\n    return (_result, _freq)",
            "def get_higher_eq_freq_feature(instruments, fields, start_time=None, end_time=None, freq='day', disk_cache=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'get the feature with higher or equal frequency than `freq`.\\n    Returns\\n    -------\\n    pd.DataFrame\\n        the feature with higher or equal frequency\\n    '\n    from ..data.data import D\n    try:\n        _result = D.features(instruments, fields, start_time, end_time, freq=freq, disk_cache=disk_cache)\n        _freq = freq\n    except (ValueError, KeyError) as value_key_e:\n        (_, norm_freq) = Freq.parse(freq)\n        if norm_freq in [Freq.NORM_FREQ_MONTH, Freq.NORM_FREQ_WEEK, Freq.NORM_FREQ_DAY]:\n            try:\n                _result = D.features(instruments, fields, start_time, end_time, freq='day', disk_cache=disk_cache)\n                _freq = 'day'\n            except (ValueError, KeyError):\n                _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n                _freq = '1min'\n        elif norm_freq == Freq.NORM_FREQ_MINUTE:\n            _result = D.features(instruments, fields, start_time, end_time, freq='1min', disk_cache=disk_cache)\n            _freq = '1min'\n        else:\n            raise ValueError(f'freq {freq} is not supported') from value_key_e\n    return (_result, _freq)"
        ]
    },
    {
        "func_name": "resam_ts_data",
        "original": "def resam_ts_data(ts_feature: Union[pd.DataFrame, pd.Series], start_time: Union[str, pd.Timestamp]=None, end_time: Union[str, pd.Timestamp]=None, method: Union[str, Callable]='last', method_kwargs: dict={}):\n    \"\"\"\n    Resample value from time-series data\n\n        - If `feature` has MultiIndex[instrument, datetime], apply the `method` to each instruemnt data with datetime in [start_time, end_time]\n            Example:\n\n            .. code-block::\n\n                print(feature)\n                                        $close      $volume\n                instrument  datetime\n                SH600000    2010-01-04  86.778313   16162960.0\n                            2010-01-05  87.433578   28117442.0\n                            2010-01-06  85.713585   23632884.0\n                            2010-01-07  83.788803   20813402.0\n                            2010-01-08  84.730675   16044853.0\n\n                SH600655    2010-01-04  2699.567383  158193.328125\n                            2010-01-08  2612.359619   77501.406250\n                            2010-01-11  2712.982422  160852.390625\n                            2010-01-12  2788.688232  164587.937500\n                            2010-01-13  2790.604004  145460.453125\n\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", fields=[\"$close\", \"$volume\"], method=\"last\"))\n                            $close      $volume\n                instrument\n                SH600000    87.433578 28117442.0\n                SH600655    2699.567383  158193.328125\n\n        - Else, the `feature` should have Index[datetime], just apply the `method` to `feature` directly\n            Example:\n\n            .. code-block::\n                print(feature)\n                            $close      $volume\n                datetime\n                2010-01-04  86.778313   16162960.0\n                2010-01-05  87.433578   28117442.0\n                2010-01-06  85.713585   23632884.0\n                2010-01-07  83.788803   20813402.0\n                2010-01-08  84.730675   16044853.0\n\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\n\n                $close 87.433578\n                $volume 28117442.0\n\n                print(resam_ts_data(feature['$close'], start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\n\n                87.433578\n\n    Parameters\n    ----------\n    ts_feature : Union[pd.DataFrame, pd.Series]\n        Raw time-series feature to be resampled\n    start_time : Union[str, pd.Timestamp], optional\n        start sampling time, by default None\n    end_time : Union[str, pd.Timestamp], optional\n        end sampling time, by default None\n    method : Union[str, Callable], optional\n        sample method, apply method function to each stock series data, by default \"last\"\n        - If type(method) is str or callable function, it should be an attribute of SeriesGroupBy or DataFrameGroupby, and applies groupy.method for the sliced time-series data\n        - If method is None, do nothing for the sliced time-series data.\n    method_kwargs : dict, optional\n        arguments of method, by default {}\n\n    Returns\n    -------\n        The resampled DataFrame/Series/value, return None when the resampled data is empty.\n    \"\"\"\n    selector_datetime = slice(start_time, end_time)\n    from ..data.dataset.utils import get_level_index\n    feature = lazy_sort_index(ts_feature)\n    datetime_level = get_level_index(feature, level='datetime') == 0\n    if datetime_level:\n        feature = feature.loc[selector_datetime]\n    else:\n        feature = feature.loc(axis=0)[slice(None), selector_datetime]\n    if feature.empty:\n        return None\n    if isinstance(feature.index, pd.MultiIndex):\n        if callable(method):\n            method_func = method\n            return feature.groupby(level='instrument').apply(method_func, **method_kwargs)\n        elif isinstance(method, str):\n            return getattr(feature.groupby(level='instrument'), method)(**method_kwargs)\n    elif callable(method):\n        method_func = method\n        return method_func(feature, **method_kwargs)\n    elif isinstance(method, str):\n        return getattr(feature, method)(**method_kwargs)\n    return feature",
        "mutated": [
            "def resam_ts_data(ts_feature: Union[pd.DataFrame, pd.Series], start_time: Union[str, pd.Timestamp]=None, end_time: Union[str, pd.Timestamp]=None, method: Union[str, Callable]='last', method_kwargs: dict={}):\n    if False:\n        i = 10\n    '\\n    Resample value from time-series data\\n\\n        - If `feature` has MultiIndex[instrument, datetime], apply the `method` to each instruemnt data with datetime in [start_time, end_time]\\n            Example:\\n\\n            .. code-block::\\n\\n                print(feature)\\n                                        $close      $volume\\n                instrument  datetime\\n                SH600000    2010-01-04  86.778313   16162960.0\\n                            2010-01-05  87.433578   28117442.0\\n                            2010-01-06  85.713585   23632884.0\\n                            2010-01-07  83.788803   20813402.0\\n                            2010-01-08  84.730675   16044853.0\\n\\n                SH600655    2010-01-04  2699.567383  158193.328125\\n                            2010-01-08  2612.359619   77501.406250\\n                            2010-01-11  2712.982422  160852.390625\\n                            2010-01-12  2788.688232  164587.937500\\n                            2010-01-13  2790.604004  145460.453125\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", fields=[\"$close\", \"$volume\"], method=\"last\"))\\n                            $close      $volume\\n                instrument\\n                SH600000    87.433578 28117442.0\\n                SH600655    2699.567383  158193.328125\\n\\n        - Else, the `feature` should have Index[datetime], just apply the `method` to `feature` directly\\n            Example:\\n\\n            .. code-block::\\n                print(feature)\\n                            $close      $volume\\n                datetime\\n                2010-01-04  86.778313   16162960.0\\n                2010-01-05  87.433578   28117442.0\\n                2010-01-06  85.713585   23632884.0\\n                2010-01-07  83.788803   20813402.0\\n                2010-01-08  84.730675   16044853.0\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                $close 87.433578\\n                $volume 28117442.0\\n\\n                print(resam_ts_data(feature[\\'$close\\'], start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                87.433578\\n\\n    Parameters\\n    ----------\\n    ts_feature : Union[pd.DataFrame, pd.Series]\\n        Raw time-series feature to be resampled\\n    start_time : Union[str, pd.Timestamp], optional\\n        start sampling time, by default None\\n    end_time : Union[str, pd.Timestamp], optional\\n        end sampling time, by default None\\n    method : Union[str, Callable], optional\\n        sample method, apply method function to each stock series data, by default \"last\"\\n        - If type(method) is str or callable function, it should be an attribute of SeriesGroupBy or DataFrameGroupby, and applies groupy.method for the sliced time-series data\\n        - If method is None, do nothing for the sliced time-series data.\\n    method_kwargs : dict, optional\\n        arguments of method, by default {}\\n\\n    Returns\\n    -------\\n        The resampled DataFrame/Series/value, return None when the resampled data is empty.\\n    '\n    selector_datetime = slice(start_time, end_time)\n    from ..data.dataset.utils import get_level_index\n    feature = lazy_sort_index(ts_feature)\n    datetime_level = get_level_index(feature, level='datetime') == 0\n    if datetime_level:\n        feature = feature.loc[selector_datetime]\n    else:\n        feature = feature.loc(axis=0)[slice(None), selector_datetime]\n    if feature.empty:\n        return None\n    if isinstance(feature.index, pd.MultiIndex):\n        if callable(method):\n            method_func = method\n            return feature.groupby(level='instrument').apply(method_func, **method_kwargs)\n        elif isinstance(method, str):\n            return getattr(feature.groupby(level='instrument'), method)(**method_kwargs)\n    elif callable(method):\n        method_func = method\n        return method_func(feature, **method_kwargs)\n    elif isinstance(method, str):\n        return getattr(feature, method)(**method_kwargs)\n    return feature",
            "def resam_ts_data(ts_feature: Union[pd.DataFrame, pd.Series], start_time: Union[str, pd.Timestamp]=None, end_time: Union[str, pd.Timestamp]=None, method: Union[str, Callable]='last', method_kwargs: dict={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Resample value from time-series data\\n\\n        - If `feature` has MultiIndex[instrument, datetime], apply the `method` to each instruemnt data with datetime in [start_time, end_time]\\n            Example:\\n\\n            .. code-block::\\n\\n                print(feature)\\n                                        $close      $volume\\n                instrument  datetime\\n                SH600000    2010-01-04  86.778313   16162960.0\\n                            2010-01-05  87.433578   28117442.0\\n                            2010-01-06  85.713585   23632884.0\\n                            2010-01-07  83.788803   20813402.0\\n                            2010-01-08  84.730675   16044853.0\\n\\n                SH600655    2010-01-04  2699.567383  158193.328125\\n                            2010-01-08  2612.359619   77501.406250\\n                            2010-01-11  2712.982422  160852.390625\\n                            2010-01-12  2788.688232  164587.937500\\n                            2010-01-13  2790.604004  145460.453125\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", fields=[\"$close\", \"$volume\"], method=\"last\"))\\n                            $close      $volume\\n                instrument\\n                SH600000    87.433578 28117442.0\\n                SH600655    2699.567383  158193.328125\\n\\n        - Else, the `feature` should have Index[datetime], just apply the `method` to `feature` directly\\n            Example:\\n\\n            .. code-block::\\n                print(feature)\\n                            $close      $volume\\n                datetime\\n                2010-01-04  86.778313   16162960.0\\n                2010-01-05  87.433578   28117442.0\\n                2010-01-06  85.713585   23632884.0\\n                2010-01-07  83.788803   20813402.0\\n                2010-01-08  84.730675   16044853.0\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                $close 87.433578\\n                $volume 28117442.0\\n\\n                print(resam_ts_data(feature[\\'$close\\'], start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                87.433578\\n\\n    Parameters\\n    ----------\\n    ts_feature : Union[pd.DataFrame, pd.Series]\\n        Raw time-series feature to be resampled\\n    start_time : Union[str, pd.Timestamp], optional\\n        start sampling time, by default None\\n    end_time : Union[str, pd.Timestamp], optional\\n        end sampling time, by default None\\n    method : Union[str, Callable], optional\\n        sample method, apply method function to each stock series data, by default \"last\"\\n        - If type(method) is str or callable function, it should be an attribute of SeriesGroupBy or DataFrameGroupby, and applies groupy.method for the sliced time-series data\\n        - If method is None, do nothing for the sliced time-series data.\\n    method_kwargs : dict, optional\\n        arguments of method, by default {}\\n\\n    Returns\\n    -------\\n        The resampled DataFrame/Series/value, return None when the resampled data is empty.\\n    '\n    selector_datetime = slice(start_time, end_time)\n    from ..data.dataset.utils import get_level_index\n    feature = lazy_sort_index(ts_feature)\n    datetime_level = get_level_index(feature, level='datetime') == 0\n    if datetime_level:\n        feature = feature.loc[selector_datetime]\n    else:\n        feature = feature.loc(axis=0)[slice(None), selector_datetime]\n    if feature.empty:\n        return None\n    if isinstance(feature.index, pd.MultiIndex):\n        if callable(method):\n            method_func = method\n            return feature.groupby(level='instrument').apply(method_func, **method_kwargs)\n        elif isinstance(method, str):\n            return getattr(feature.groupby(level='instrument'), method)(**method_kwargs)\n    elif callable(method):\n        method_func = method\n        return method_func(feature, **method_kwargs)\n    elif isinstance(method, str):\n        return getattr(feature, method)(**method_kwargs)\n    return feature",
            "def resam_ts_data(ts_feature: Union[pd.DataFrame, pd.Series], start_time: Union[str, pd.Timestamp]=None, end_time: Union[str, pd.Timestamp]=None, method: Union[str, Callable]='last', method_kwargs: dict={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Resample value from time-series data\\n\\n        - If `feature` has MultiIndex[instrument, datetime], apply the `method` to each instruemnt data with datetime in [start_time, end_time]\\n            Example:\\n\\n            .. code-block::\\n\\n                print(feature)\\n                                        $close      $volume\\n                instrument  datetime\\n                SH600000    2010-01-04  86.778313   16162960.0\\n                            2010-01-05  87.433578   28117442.0\\n                            2010-01-06  85.713585   23632884.0\\n                            2010-01-07  83.788803   20813402.0\\n                            2010-01-08  84.730675   16044853.0\\n\\n                SH600655    2010-01-04  2699.567383  158193.328125\\n                            2010-01-08  2612.359619   77501.406250\\n                            2010-01-11  2712.982422  160852.390625\\n                            2010-01-12  2788.688232  164587.937500\\n                            2010-01-13  2790.604004  145460.453125\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", fields=[\"$close\", \"$volume\"], method=\"last\"))\\n                            $close      $volume\\n                instrument\\n                SH600000    87.433578 28117442.0\\n                SH600655    2699.567383  158193.328125\\n\\n        - Else, the `feature` should have Index[datetime], just apply the `method` to `feature` directly\\n            Example:\\n\\n            .. code-block::\\n                print(feature)\\n                            $close      $volume\\n                datetime\\n                2010-01-04  86.778313   16162960.0\\n                2010-01-05  87.433578   28117442.0\\n                2010-01-06  85.713585   23632884.0\\n                2010-01-07  83.788803   20813402.0\\n                2010-01-08  84.730675   16044853.0\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                $close 87.433578\\n                $volume 28117442.0\\n\\n                print(resam_ts_data(feature[\\'$close\\'], start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                87.433578\\n\\n    Parameters\\n    ----------\\n    ts_feature : Union[pd.DataFrame, pd.Series]\\n        Raw time-series feature to be resampled\\n    start_time : Union[str, pd.Timestamp], optional\\n        start sampling time, by default None\\n    end_time : Union[str, pd.Timestamp], optional\\n        end sampling time, by default None\\n    method : Union[str, Callable], optional\\n        sample method, apply method function to each stock series data, by default \"last\"\\n        - If type(method) is str or callable function, it should be an attribute of SeriesGroupBy or DataFrameGroupby, and applies groupy.method for the sliced time-series data\\n        - If method is None, do nothing for the sliced time-series data.\\n    method_kwargs : dict, optional\\n        arguments of method, by default {}\\n\\n    Returns\\n    -------\\n        The resampled DataFrame/Series/value, return None when the resampled data is empty.\\n    '\n    selector_datetime = slice(start_time, end_time)\n    from ..data.dataset.utils import get_level_index\n    feature = lazy_sort_index(ts_feature)\n    datetime_level = get_level_index(feature, level='datetime') == 0\n    if datetime_level:\n        feature = feature.loc[selector_datetime]\n    else:\n        feature = feature.loc(axis=0)[slice(None), selector_datetime]\n    if feature.empty:\n        return None\n    if isinstance(feature.index, pd.MultiIndex):\n        if callable(method):\n            method_func = method\n            return feature.groupby(level='instrument').apply(method_func, **method_kwargs)\n        elif isinstance(method, str):\n            return getattr(feature.groupby(level='instrument'), method)(**method_kwargs)\n    elif callable(method):\n        method_func = method\n        return method_func(feature, **method_kwargs)\n    elif isinstance(method, str):\n        return getattr(feature, method)(**method_kwargs)\n    return feature",
            "def resam_ts_data(ts_feature: Union[pd.DataFrame, pd.Series], start_time: Union[str, pd.Timestamp]=None, end_time: Union[str, pd.Timestamp]=None, method: Union[str, Callable]='last', method_kwargs: dict={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Resample value from time-series data\\n\\n        - If `feature` has MultiIndex[instrument, datetime], apply the `method` to each instruemnt data with datetime in [start_time, end_time]\\n            Example:\\n\\n            .. code-block::\\n\\n                print(feature)\\n                                        $close      $volume\\n                instrument  datetime\\n                SH600000    2010-01-04  86.778313   16162960.0\\n                            2010-01-05  87.433578   28117442.0\\n                            2010-01-06  85.713585   23632884.0\\n                            2010-01-07  83.788803   20813402.0\\n                            2010-01-08  84.730675   16044853.0\\n\\n                SH600655    2010-01-04  2699.567383  158193.328125\\n                            2010-01-08  2612.359619   77501.406250\\n                            2010-01-11  2712.982422  160852.390625\\n                            2010-01-12  2788.688232  164587.937500\\n                            2010-01-13  2790.604004  145460.453125\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", fields=[\"$close\", \"$volume\"], method=\"last\"))\\n                            $close      $volume\\n                instrument\\n                SH600000    87.433578 28117442.0\\n                SH600655    2699.567383  158193.328125\\n\\n        - Else, the `feature` should have Index[datetime], just apply the `method` to `feature` directly\\n            Example:\\n\\n            .. code-block::\\n                print(feature)\\n                            $close      $volume\\n                datetime\\n                2010-01-04  86.778313   16162960.0\\n                2010-01-05  87.433578   28117442.0\\n                2010-01-06  85.713585   23632884.0\\n                2010-01-07  83.788803   20813402.0\\n                2010-01-08  84.730675   16044853.0\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                $close 87.433578\\n                $volume 28117442.0\\n\\n                print(resam_ts_data(feature[\\'$close\\'], start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                87.433578\\n\\n    Parameters\\n    ----------\\n    ts_feature : Union[pd.DataFrame, pd.Series]\\n        Raw time-series feature to be resampled\\n    start_time : Union[str, pd.Timestamp], optional\\n        start sampling time, by default None\\n    end_time : Union[str, pd.Timestamp], optional\\n        end sampling time, by default None\\n    method : Union[str, Callable], optional\\n        sample method, apply method function to each stock series data, by default \"last\"\\n        - If type(method) is str or callable function, it should be an attribute of SeriesGroupBy or DataFrameGroupby, and applies groupy.method for the sliced time-series data\\n        - If method is None, do nothing for the sliced time-series data.\\n    method_kwargs : dict, optional\\n        arguments of method, by default {}\\n\\n    Returns\\n    -------\\n        The resampled DataFrame/Series/value, return None when the resampled data is empty.\\n    '\n    selector_datetime = slice(start_time, end_time)\n    from ..data.dataset.utils import get_level_index\n    feature = lazy_sort_index(ts_feature)\n    datetime_level = get_level_index(feature, level='datetime') == 0\n    if datetime_level:\n        feature = feature.loc[selector_datetime]\n    else:\n        feature = feature.loc(axis=0)[slice(None), selector_datetime]\n    if feature.empty:\n        return None\n    if isinstance(feature.index, pd.MultiIndex):\n        if callable(method):\n            method_func = method\n            return feature.groupby(level='instrument').apply(method_func, **method_kwargs)\n        elif isinstance(method, str):\n            return getattr(feature.groupby(level='instrument'), method)(**method_kwargs)\n    elif callable(method):\n        method_func = method\n        return method_func(feature, **method_kwargs)\n    elif isinstance(method, str):\n        return getattr(feature, method)(**method_kwargs)\n    return feature",
            "def resam_ts_data(ts_feature: Union[pd.DataFrame, pd.Series], start_time: Union[str, pd.Timestamp]=None, end_time: Union[str, pd.Timestamp]=None, method: Union[str, Callable]='last', method_kwargs: dict={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Resample value from time-series data\\n\\n        - If `feature` has MultiIndex[instrument, datetime], apply the `method` to each instruemnt data with datetime in [start_time, end_time]\\n            Example:\\n\\n            .. code-block::\\n\\n                print(feature)\\n                                        $close      $volume\\n                instrument  datetime\\n                SH600000    2010-01-04  86.778313   16162960.0\\n                            2010-01-05  87.433578   28117442.0\\n                            2010-01-06  85.713585   23632884.0\\n                            2010-01-07  83.788803   20813402.0\\n                            2010-01-08  84.730675   16044853.0\\n\\n                SH600655    2010-01-04  2699.567383  158193.328125\\n                            2010-01-08  2612.359619   77501.406250\\n                            2010-01-11  2712.982422  160852.390625\\n                            2010-01-12  2788.688232  164587.937500\\n                            2010-01-13  2790.604004  145460.453125\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", fields=[\"$close\", \"$volume\"], method=\"last\"))\\n                            $close      $volume\\n                instrument\\n                SH600000    87.433578 28117442.0\\n                SH600655    2699.567383  158193.328125\\n\\n        - Else, the `feature` should have Index[datetime], just apply the `method` to `feature` directly\\n            Example:\\n\\n            .. code-block::\\n                print(feature)\\n                            $close      $volume\\n                datetime\\n                2010-01-04  86.778313   16162960.0\\n                2010-01-05  87.433578   28117442.0\\n                2010-01-06  85.713585   23632884.0\\n                2010-01-07  83.788803   20813402.0\\n                2010-01-08  84.730675   16044853.0\\n\\n                print(resam_ts_data(feature, start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                $close 87.433578\\n                $volume 28117442.0\\n\\n                print(resam_ts_data(feature[\\'$close\\'], start_time=\"2010-01-04\", end_time=\"2010-01-05\", method=\"last\"))\\n\\n                87.433578\\n\\n    Parameters\\n    ----------\\n    ts_feature : Union[pd.DataFrame, pd.Series]\\n        Raw time-series feature to be resampled\\n    start_time : Union[str, pd.Timestamp], optional\\n        start sampling time, by default None\\n    end_time : Union[str, pd.Timestamp], optional\\n        end sampling time, by default None\\n    method : Union[str, Callable], optional\\n        sample method, apply method function to each stock series data, by default \"last\"\\n        - If type(method) is str or callable function, it should be an attribute of SeriesGroupBy or DataFrameGroupby, and applies groupy.method for the sliced time-series data\\n        - If method is None, do nothing for the sliced time-series data.\\n    method_kwargs : dict, optional\\n        arguments of method, by default {}\\n\\n    Returns\\n    -------\\n        The resampled DataFrame/Series/value, return None when the resampled data is empty.\\n    '\n    selector_datetime = slice(start_time, end_time)\n    from ..data.dataset.utils import get_level_index\n    feature = lazy_sort_index(ts_feature)\n    datetime_level = get_level_index(feature, level='datetime') == 0\n    if datetime_level:\n        feature = feature.loc[selector_datetime]\n    else:\n        feature = feature.loc(axis=0)[slice(None), selector_datetime]\n    if feature.empty:\n        return None\n    if isinstance(feature.index, pd.MultiIndex):\n        if callable(method):\n            method_func = method\n            return feature.groupby(level='instrument').apply(method_func, **method_kwargs)\n        elif isinstance(method, str):\n            return getattr(feature.groupby(level='instrument'), method)(**method_kwargs)\n    elif callable(method):\n        method_func = method\n        return method_func(feature, **method_kwargs)\n    elif isinstance(method, str):\n        return getattr(feature, method)(**method_kwargs)\n    return feature"
        ]
    },
    {
        "func_name": "get_valid_value",
        "original": "def get_valid_value(series, last=True):\n    \"\"\"get the first/last not nan value of pd.Series with single level index\n    Parameters\n    ----------\n    series : pd.Series\n        series should not be empty\n    last : bool, optional\n        whether to get the last valid value, by default True\n        - if last is True, get the last valid value\n        - else, get the first valid value\n\n    Returns\n    -------\n    Nan | float\n        the first/last valid value\n    \"\"\"\n    return series.fillna(method='ffill').iloc[-1] if last else series.fillna(method='bfill').iloc[0]",
        "mutated": [
            "def get_valid_value(series, last=True):\n    if False:\n        i = 10\n    'get the first/last not nan value of pd.Series with single level index\\n    Parameters\\n    ----------\\n    series : pd.Series\\n        series should not be empty\\n    last : bool, optional\\n        whether to get the last valid value, by default True\\n        - if last is True, get the last valid value\\n        - else, get the first valid value\\n\\n    Returns\\n    -------\\n    Nan | float\\n        the first/last valid value\\n    '\n    return series.fillna(method='ffill').iloc[-1] if last else series.fillna(method='bfill').iloc[0]",
            "def get_valid_value(series, last=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'get the first/last not nan value of pd.Series with single level index\\n    Parameters\\n    ----------\\n    series : pd.Series\\n        series should not be empty\\n    last : bool, optional\\n        whether to get the last valid value, by default True\\n        - if last is True, get the last valid value\\n        - else, get the first valid value\\n\\n    Returns\\n    -------\\n    Nan | float\\n        the first/last valid value\\n    '\n    return series.fillna(method='ffill').iloc[-1] if last else series.fillna(method='bfill').iloc[0]",
            "def get_valid_value(series, last=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'get the first/last not nan value of pd.Series with single level index\\n    Parameters\\n    ----------\\n    series : pd.Series\\n        series should not be empty\\n    last : bool, optional\\n        whether to get the last valid value, by default True\\n        - if last is True, get the last valid value\\n        - else, get the first valid value\\n\\n    Returns\\n    -------\\n    Nan | float\\n        the first/last valid value\\n    '\n    return series.fillna(method='ffill').iloc[-1] if last else series.fillna(method='bfill').iloc[0]",
            "def get_valid_value(series, last=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'get the first/last not nan value of pd.Series with single level index\\n    Parameters\\n    ----------\\n    series : pd.Series\\n        series should not be empty\\n    last : bool, optional\\n        whether to get the last valid value, by default True\\n        - if last is True, get the last valid value\\n        - else, get the first valid value\\n\\n    Returns\\n    -------\\n    Nan | float\\n        the first/last valid value\\n    '\n    return series.fillna(method='ffill').iloc[-1] if last else series.fillna(method='bfill').iloc[0]",
            "def get_valid_value(series, last=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'get the first/last not nan value of pd.Series with single level index\\n    Parameters\\n    ----------\\n    series : pd.Series\\n        series should not be empty\\n    last : bool, optional\\n        whether to get the last valid value, by default True\\n        - if last is True, get the last valid value\\n        - else, get the first valid value\\n\\n    Returns\\n    -------\\n    Nan | float\\n        the first/last valid value\\n    '\n    return series.fillna(method='ffill').iloc[-1] if last else series.fillna(method='bfill').iloc[0]"
        ]
    },
    {
        "func_name": "_ts_data_valid",
        "original": "def _ts_data_valid(ts_feature, last=False):\n    \"\"\"get the first/last not nan value of pd.Series|DataFrame with single level index\"\"\"\n    if isinstance(ts_feature, pd.DataFrame):\n        return ts_feature.apply(lambda column: get_valid_value(column, last=last))\n    elif isinstance(ts_feature, pd.Series):\n        return get_valid_value(ts_feature, last=last)\n    else:\n        raise TypeError(f'ts_feature should be pd.DataFrame/Series, not {type(ts_feature)}')",
        "mutated": [
            "def _ts_data_valid(ts_feature, last=False):\n    if False:\n        i = 10\n    'get the first/last not nan value of pd.Series|DataFrame with single level index'\n    if isinstance(ts_feature, pd.DataFrame):\n        return ts_feature.apply(lambda column: get_valid_value(column, last=last))\n    elif isinstance(ts_feature, pd.Series):\n        return get_valid_value(ts_feature, last=last)\n    else:\n        raise TypeError(f'ts_feature should be pd.DataFrame/Series, not {type(ts_feature)}')",
            "def _ts_data_valid(ts_feature, last=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'get the first/last not nan value of pd.Series|DataFrame with single level index'\n    if isinstance(ts_feature, pd.DataFrame):\n        return ts_feature.apply(lambda column: get_valid_value(column, last=last))\n    elif isinstance(ts_feature, pd.Series):\n        return get_valid_value(ts_feature, last=last)\n    else:\n        raise TypeError(f'ts_feature should be pd.DataFrame/Series, not {type(ts_feature)}')",
            "def _ts_data_valid(ts_feature, last=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'get the first/last not nan value of pd.Series|DataFrame with single level index'\n    if isinstance(ts_feature, pd.DataFrame):\n        return ts_feature.apply(lambda column: get_valid_value(column, last=last))\n    elif isinstance(ts_feature, pd.Series):\n        return get_valid_value(ts_feature, last=last)\n    else:\n        raise TypeError(f'ts_feature should be pd.DataFrame/Series, not {type(ts_feature)}')",
            "def _ts_data_valid(ts_feature, last=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'get the first/last not nan value of pd.Series|DataFrame with single level index'\n    if isinstance(ts_feature, pd.DataFrame):\n        return ts_feature.apply(lambda column: get_valid_value(column, last=last))\n    elif isinstance(ts_feature, pd.Series):\n        return get_valid_value(ts_feature, last=last)\n    else:\n        raise TypeError(f'ts_feature should be pd.DataFrame/Series, not {type(ts_feature)}')",
            "def _ts_data_valid(ts_feature, last=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'get the first/last not nan value of pd.Series|DataFrame with single level index'\n    if isinstance(ts_feature, pd.DataFrame):\n        return ts_feature.apply(lambda column: get_valid_value(column, last=last))\n    elif isinstance(ts_feature, pd.Series):\n        return get_valid_value(ts_feature, last=last)\n    else:\n        raise TypeError(f'ts_feature should be pd.DataFrame/Series, not {type(ts_feature)}')"
        ]
    }
]