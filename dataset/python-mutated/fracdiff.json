[
    {
        "func_name": "get_weights",
        "original": "@staticmethod\ndef get_weights(diff_amt, size):\n    \"\"\"\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 79.\n\n        The helper function generates weights that are used to compute fractionally\n        differentiated series. It computes the weights that get used in the computation\n        of  fractionally differentiated series. This generates a non-terminating series\n        that approaches zero asymptotically. The side effect of this function is that\n        it leads to negative drift \"caused by an expanding window's added weights\"\n        (see page 83 AFML)\n\n        When diff_amt is real (non-integer) positive number then it preserves memory.\n\n        The book does not discuss what should be expected if d is a negative real\n        number. Conceptually (from set theory) negative d leads to set of negative\n        number of elements. And that translates into a set whose elements can be\n        selected more than once or as many times as one chooses (multisets with\n        unbounded multiplicity) - see http://faculty.uml.edu/jpropp/msri-up12.pdf.\n\n        :param diff_amt: (float) Differencing amount\n        :param size: (int) Length of the series\n        :return: (np.ndarray) Weight vector\n        \"\"\"\n    pass",
        "mutated": [
            "@staticmethod\ndef get_weights(diff_amt, size):\n    if False:\n        i = 10\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 79.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiated series. It computes the weights that get used in the computation\\n        of  fractionally differentiated series. This generates a non-terminating series\\n        that approaches zero asymptotically. The side effect of this function is that\\n        it leads to negative drift \"caused by an expanding window\\'s added weights\"\\n        (see page 83 AFML)\\n\\n        When diff_amt is real (non-integer) positive number then it preserves memory.\\n\\n        The book does not discuss what should be expected if d is a negative real\\n        number. Conceptually (from set theory) negative d leads to set of negative\\n        number of elements. And that translates into a set whose elements can be\\n        selected more than once or as many times as one chooses (multisets with\\n        unbounded multiplicity) - see http://faculty.uml.edu/jpropp/msri-up12.pdf.\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param size: (int) Length of the series\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 79.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiated series. It computes the weights that get used in the computation\\n        of  fractionally differentiated series. This generates a non-terminating series\\n        that approaches zero asymptotically. The side effect of this function is that\\n        it leads to negative drift \"caused by an expanding window\\'s added weights\"\\n        (see page 83 AFML)\\n\\n        When diff_amt is real (non-integer) positive number then it preserves memory.\\n\\n        The book does not discuss what should be expected if d is a negative real\\n        number. Conceptually (from set theory) negative d leads to set of negative\\n        number of elements. And that translates into a set whose elements can be\\n        selected more than once or as many times as one chooses (multisets with\\n        unbounded multiplicity) - see http://faculty.uml.edu/jpropp/msri-up12.pdf.\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param size: (int) Length of the series\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 79.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiated series. It computes the weights that get used in the computation\\n        of  fractionally differentiated series. This generates a non-terminating series\\n        that approaches zero asymptotically. The side effect of this function is that\\n        it leads to negative drift \"caused by an expanding window\\'s added weights\"\\n        (see page 83 AFML)\\n\\n        When diff_amt is real (non-integer) positive number then it preserves memory.\\n\\n        The book does not discuss what should be expected if d is a negative real\\n        number. Conceptually (from set theory) negative d leads to set of negative\\n        number of elements. And that translates into a set whose elements can be\\n        selected more than once or as many times as one chooses (multisets with\\n        unbounded multiplicity) - see http://faculty.uml.edu/jpropp/msri-up12.pdf.\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param size: (int) Length of the series\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 79.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiated series. It computes the weights that get used in the computation\\n        of  fractionally differentiated series. This generates a non-terminating series\\n        that approaches zero asymptotically. The side effect of this function is that\\n        it leads to negative drift \"caused by an expanding window\\'s added weights\"\\n        (see page 83 AFML)\\n\\n        When diff_amt is real (non-integer) positive number then it preserves memory.\\n\\n        The book does not discuss what should be expected if d is a negative real\\n        number. Conceptually (from set theory) negative d leads to set of negative\\n        number of elements. And that translates into a set whose elements can be\\n        selected more than once or as many times as one chooses (multisets with\\n        unbounded multiplicity) - see http://faculty.uml.edu/jpropp/msri-up12.pdf.\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param size: (int) Length of the series\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 79.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiated series. It computes the weights that get used in the computation\\n        of  fractionally differentiated series. This generates a non-terminating series\\n        that approaches zero asymptotically. The side effect of this function is that\\n        it leads to negative drift \"caused by an expanding window\\'s added weights\"\\n        (see page 83 AFML)\\n\\n        When diff_amt is real (non-integer) positive number then it preserves memory.\\n\\n        The book does not discuss what should be expected if d is a negative real\\n        number. Conceptually (from set theory) negative d leads to set of negative\\n        number of elements. And that translates into a set whose elements can be\\n        selected more than once or as many times as one chooses (multisets with\\n        unbounded multiplicity) - see http://faculty.uml.edu/jpropp/msri-up12.pdf.\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param size: (int) Length of the series\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass"
        ]
    },
    {
        "func_name": "frac_diff",
        "original": "@staticmethod\ndef frac_diff(series, diff_amt, thresh=0.01):\n    \"\"\"\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 82.\n\n        References:\n        https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\n        https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\n        https://en.wikipedia.org/wiki/Fractional_calculus\n\n        The steps are as follows:\n        - Compute weights (this is a one-time exercise)\n        - Iteratively apply the weights to the price series and generate output points\n\n        This is the expanding window variant of the fracDiff algorithm\n        Note 1: For thresh-1, nothing is skipped\n        Note 2: diff_amt can be any positive fractional, not necessarility bounded [0, 1]\n\n        :param series: (pd.DataFrame) A time series that needs to be differenced\n        :param diff_amt: (float) Differencing amount\n        :param thresh: (float) Threshold or epsilon\n        :return: (pd.DataFrame) Differenced series\n        \"\"\"\n    pass",
        "mutated": [
            "@staticmethod\ndef frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 82.\\n\\n        References:\\n        https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        This is the expanding window variant of the fracDiff algorithm\\n        Note 1: For thresh-1, nothing is skipped\\n        Note 2: diff_amt can be any positive fractional, not necessarility bounded [0, 1]\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold or epsilon\\n        :return: (pd.DataFrame) Differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 82.\\n\\n        References:\\n        https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        This is the expanding window variant of the fracDiff algorithm\\n        Note 1: For thresh-1, nothing is skipped\\n        Note 2: diff_amt can be any positive fractional, not necessarility bounded [0, 1]\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold or epsilon\\n        :return: (pd.DataFrame) Differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 82.\\n\\n        References:\\n        https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        This is the expanding window variant of the fracDiff algorithm\\n        Note 1: For thresh-1, nothing is skipped\\n        Note 2: diff_amt can be any positive fractional, not necessarility bounded [0, 1]\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold or epsilon\\n        :return: (pd.DataFrame) Differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 82.\\n\\n        References:\\n        https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        This is the expanding window variant of the fracDiff algorithm\\n        Note 1: For thresh-1, nothing is skipped\\n        Note 2: diff_amt can be any positive fractional, not necessarility bounded [0, 1]\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold or epsilon\\n        :return: (pd.DataFrame) Differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 82.\\n\\n        References:\\n        https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        This is the expanding window variant of the fracDiff algorithm\\n        Note 1: For thresh-1, nothing is skipped\\n        Note 2: diff_amt can be any positive fractional, not necessarility bounded [0, 1]\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold or epsilon\\n        :return: (pd.DataFrame) Differenced series\\n        '\n    pass"
        ]
    },
    {
        "func_name": "get_weights_ffd",
        "original": "@staticmethod\ndef get_weights_ffd(diff_amt, thresh, lim):\n    \"\"\"\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 83.\n\n        The helper function generates weights that are used to compute fractionally\n        differentiate dseries. It computes the weights that get used in the computation\n        of fractionally differentiated series. The series is of fixed width and same\n        weights (generated by this function) can be used when creating fractional\n        differentiated series.\n        This makes the process more efficient. But the side-effect is that the\n        fractionally differentiated series is skewed and has excess kurtosis. In\n        other words, it is not Gaussian any more.\n\n        The discussion of positive and negative d is similar to that in get_weights\n        (see the function get_weights)\n\n        :param diff_amt: (float) Differencing amount\n        :param thresh: (float) Threshold for minimum weight\n        :param lim: (int) Maximum length of the weight vector\n        :return: (np.ndarray) Weight vector\n        \"\"\"\n    pass",
        "mutated": [
            "@staticmethod\ndef get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 83.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiate dseries. It computes the weights that get used in the computation\\n        of fractionally differentiated series. The series is of fixed width and same\\n        weights (generated by this function) can be used when creating fractional\\n        differentiated series.\\n        This makes the process more efficient. But the side-effect is that the\\n        fractionally differentiated series is skewed and has excess kurtosis. In\\n        other words, it is not Gaussian any more.\\n\\n        The discussion of positive and negative d is similar to that in get_weights\\n        (see the function get_weights)\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :param lim: (int) Maximum length of the weight vector\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 83.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiate dseries. It computes the weights that get used in the computation\\n        of fractionally differentiated series. The series is of fixed width and same\\n        weights (generated by this function) can be used when creating fractional\\n        differentiated series.\\n        This makes the process more efficient. But the side-effect is that the\\n        fractionally differentiated series is skewed and has excess kurtosis. In\\n        other words, it is not Gaussian any more.\\n\\n        The discussion of positive and negative d is similar to that in get_weights\\n        (see the function get_weights)\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :param lim: (int) Maximum length of the weight vector\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 83.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiate dseries. It computes the weights that get used in the computation\\n        of fractionally differentiated series. The series is of fixed width and same\\n        weights (generated by this function) can be used when creating fractional\\n        differentiated series.\\n        This makes the process more efficient. But the side-effect is that the\\n        fractionally differentiated series is skewed and has excess kurtosis. In\\n        other words, it is not Gaussian any more.\\n\\n        The discussion of positive and negative d is similar to that in get_weights\\n        (see the function get_weights)\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :param lim: (int) Maximum length of the weight vector\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 83.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiate dseries. It computes the weights that get used in the computation\\n        of fractionally differentiated series. The series is of fixed width and same\\n        weights (generated by this function) can be used when creating fractional\\n        differentiated series.\\n        This makes the process more efficient. But the side-effect is that the\\n        fractionally differentiated series is skewed and has excess kurtosis. In\\n        other words, it is not Gaussian any more.\\n\\n        The discussion of positive and negative d is similar to that in get_weights\\n        (see the function get_weights)\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :param lim: (int) Maximum length of the weight vector\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass",
            "@staticmethod\ndef get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.4.2, page 83.\\n\\n        The helper function generates weights that are used to compute fractionally\\n        differentiate dseries. It computes the weights that get used in the computation\\n        of fractionally differentiated series. The series is of fixed width and same\\n        weights (generated by this function) can be used when creating fractional\\n        differentiated series.\\n        This makes the process more efficient. But the side-effect is that the\\n        fractionally differentiated series is skewed and has excess kurtosis. In\\n        other words, it is not Gaussian any more.\\n\\n        The discussion of positive and negative d is similar to that in get_weights\\n        (see the function get_weights)\\n\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :param lim: (int) Maximum length of the weight vector\\n        :return: (np.ndarray) Weight vector\\n        '\n    pass"
        ]
    },
    {
        "func_name": "frac_diff_ffd",
        "original": "@staticmethod\ndef frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    \"\"\"\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\n\n        References:\n\n        * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\n        * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\n        * https://en.wikipedia.org/wiki/Fractional_calculus\n\n        The steps are as follows:\n\n        - Compute weights (this is a one-time exercise)\n        - Iteratively apply the weights to the price series and generate output points\n\n        Constant width window (new solution)\n        Note 1: thresh determines the cut-off weight for the window\n        Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\n\n        :param series: (pd.DataFrame) A time series that needs to be differenced\n        :param diff_amt: (float) Differencing amount\n        :param thresh: (float) Threshold for minimum weight\n        :return: (pd.DataFrame) A data frame of differenced series\n        \"\"\"\n    pass",
        "mutated": [
            "@staticmethod\ndef frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n        References:\\n\\n        * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        Constant width window (new solution)\\n        Note 1: thresh determines the cut-off weight for the window\\n        Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :return: (pd.DataFrame) A data frame of differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n        References:\\n\\n        * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        Constant width window (new solution)\\n        Note 1: thresh determines the cut-off weight for the window\\n        Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :return: (pd.DataFrame) A data frame of differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n        References:\\n\\n        * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        Constant width window (new solution)\\n        Note 1: thresh determines the cut-off weight for the window\\n        Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :return: (pd.DataFrame) A data frame of differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n        References:\\n\\n        * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        Constant width window (new solution)\\n        Note 1: thresh determines the cut-off weight for the window\\n        Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :return: (pd.DataFrame) A data frame of differenced series\\n        '\n    pass",
            "@staticmethod\ndef frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n        References:\\n\\n        * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n        * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n        * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n        The steps are as follows:\\n\\n        - Compute weights (this is a one-time exercise)\\n        - Iteratively apply the weights to the price series and generate output points\\n\\n        Constant width window (new solution)\\n        Note 1: thresh determines the cut-off weight for the window\\n        Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n        :param series: (pd.DataFrame) A time series that needs to be differenced\\n        :param diff_amt: (float) Differencing amount\\n        :param thresh: (float) Threshold for minimum weight\\n        :return: (pd.DataFrame) A data frame of differenced series\\n        '\n    pass"
        ]
    },
    {
        "func_name": "get_weights",
        "original": "def get_weights(diff_amt, size):\n    \"\"\" This is a pass-through function \"\"\"\n    pass",
        "mutated": [
            "def get_weights(diff_amt, size):\n    if False:\n        i = 10\n    ' This is a pass-through function '\n    pass",
            "def get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ' This is a pass-through function '\n    pass",
            "def get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ' This is a pass-through function '\n    pass",
            "def get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ' This is a pass-through function '\n    pass",
            "def get_weights(diff_amt, size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ' This is a pass-through function '\n    pass"
        ]
    },
    {
        "func_name": "frac_diff",
        "original": "def frac_diff(series, diff_amt, thresh=0.01):\n    \"\"\" This is a pass-through function \"\"\"\n    pass",
        "mutated": [
            "def frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n    ' This is a pass-through function '\n    pass",
            "def frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ' This is a pass-through function '\n    pass",
            "def frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ' This is a pass-through function '\n    pass",
            "def frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ' This is a pass-through function '\n    pass",
            "def frac_diff(series, diff_amt, thresh=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ' This is a pass-through function '\n    pass"
        ]
    },
    {
        "func_name": "get_weights_ffd",
        "original": "def get_weights_ffd(diff_amt, thresh, lim):\n    \"\"\" This is a pass-through function \"\"\"\n    pass",
        "mutated": [
            "def get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n    ' This is a pass-through function '\n    pass",
            "def get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ' This is a pass-through function '\n    pass",
            "def get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ' This is a pass-through function '\n    pass",
            "def get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ' This is a pass-through function '\n    pass",
            "def get_weights_ffd(diff_amt, thresh, lim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ' This is a pass-through function '\n    pass"
        ]
    },
    {
        "func_name": "frac_diff_ffd",
        "original": "def frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    \"\"\"\n    Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\n\n    References:\n\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\n    * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\n    * https://en.wikipedia.org/wiki/Fractional_calculus\n\n    The steps are as follows:\n\n    - Compute weights (this is a one-time exercise)\n    - Iteratively apply the weights to the price series and generate output points\n\n    Constant width window (new solution)\n    Note 1: thresh determines the cut-off weight for the window\n    Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\n\n    :param series: (pd.Series) A time series that needs to be differenced\n    :param diff_amt: (float) Differencing amount\n    :param thresh: (float) Threshold for minimum weight\n    :return: (pd.DataFrame) A data frame of differenced series\n    \"\"\"\n    pass",
        "mutated": [
            "def frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n    * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n    * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n    The steps are as follows:\\n\\n    - Compute weights (this is a one-time exercise)\\n    - Iteratively apply the weights to the price series and generate output points\\n\\n    Constant width window (new solution)\\n    Note 1: thresh determines the cut-off weight for the window\\n    Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n    :param series: (pd.Series) A time series that needs to be differenced\\n    :param diff_amt: (float) Differencing amount\\n    :param thresh: (float) Threshold for minimum weight\\n    :return: (pd.DataFrame) A data frame of differenced series\\n    '\n    pass",
            "def frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n    * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n    * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n    The steps are as follows:\\n\\n    - Compute weights (this is a one-time exercise)\\n    - Iteratively apply the weights to the price series and generate output points\\n\\n    Constant width window (new solution)\\n    Note 1: thresh determines the cut-off weight for the window\\n    Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n    :param series: (pd.Series) A time series that needs to be differenced\\n    :param diff_amt: (float) Differencing amount\\n    :param thresh: (float) Threshold for minimum weight\\n    :return: (pd.DataFrame) A data frame of differenced series\\n    '\n    pass",
            "def frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n    * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n    * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n    The steps are as follows:\\n\\n    - Compute weights (this is a one-time exercise)\\n    - Iteratively apply the weights to the price series and generate output points\\n\\n    Constant width window (new solution)\\n    Note 1: thresh determines the cut-off weight for the window\\n    Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n    :param series: (pd.Series) A time series that needs to be differenced\\n    :param diff_amt: (float) Differencing amount\\n    :param thresh: (float) Threshold for minimum weight\\n    :return: (pd.DataFrame) A data frame of differenced series\\n    '\n    pass",
            "def frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n    * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n    * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n    The steps are as follows:\\n\\n    - Compute weights (this is a one-time exercise)\\n    - Iteratively apply the weights to the price series and generate output points\\n\\n    Constant width window (new solution)\\n    Note 1: thresh determines the cut-off weight for the window\\n    Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n    :param series: (pd.Series) A time series that needs to be differenced\\n    :param diff_amt: (float) Differencing amount\\n    :param thresh: (float) Threshold for minimum weight\\n    :return: (pd.DataFrame) A data frame of differenced series\\n    '\n    pass",
            "def frac_diff_ffd(series, diff_amt, thresh=1e-05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.5, page 83.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n    * https://wwwf.imperial.ac.uk/~ejm/M3S8/Problems/hosking81.pdf\\n    * https://en.wikipedia.org/wiki/Fractional_calculus\\n\\n    The steps are as follows:\\n\\n    - Compute weights (this is a one-time exercise)\\n    - Iteratively apply the weights to the price series and generate output points\\n\\n    Constant width window (new solution)\\n    Note 1: thresh determines the cut-off weight for the window\\n    Note 2: diff_amt can be any positive fractional, not necessarity bounded [0, 1].\\n\\n    :param series: (pd.Series) A time series that needs to be differenced\\n    :param diff_amt: (float) Differencing amount\\n    :param thresh: (float) Threshold for minimum weight\\n    :return: (pd.DataFrame) A data frame of differenced series\\n    '\n    pass"
        ]
    },
    {
        "func_name": "plot_min_ffd",
        "original": "def plot_min_ffd(series):\n    \"\"\"\n    Advances in Financial Machine Learning, Chapter 5, section 5.6, page 85.\n\n    References:\n\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\n\n    This function plots the graph to find the minimum D value that passes the ADF test.\n\n    It allows to determine d - the amount of memory that needs to be removed to achieve\n    stationarity. This function covers the case of 0 < d << 1, when the original series is\n    \"mildly non-stationary.\"\n\n    The right y-axis on the plot is the ADF statistic computed on the input series downsampled\n    to a daily frequency.\n\n    The x-axis displays the d value used to generate the series on which the ADF statistic is computed.\n\n    The left y-axis plots the correlation between the original series (d=0) and the differentiated\n    series at various d values.\n\n    Examples on how to interpret the results of this function are available in the corresponding part\n    in the book Advances in Financial Machine Learning.\n\n    :param series: (pd.DataFrame) Dataframe that contains a 'close' column with prices to use.\n    :return: (plt.AxesSubplot) A plot that can be displayed or used to obtain resulting data.\n    \"\"\"\n    pass",
        "mutated": [
            "def plot_min_ffd(series):\n    if False:\n        i = 10\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.6, page 85.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n\\n    This function plots the graph to find the minimum D value that passes the ADF test.\\n\\n    It allows to determine d - the amount of memory that needs to be removed to achieve\\n    stationarity. This function covers the case of 0 < d << 1, when the original series is\\n    \"mildly non-stationary.\"\\n\\n    The right y-axis on the plot is the ADF statistic computed on the input series downsampled\\n    to a daily frequency.\\n\\n    The x-axis displays the d value used to generate the series on which the ADF statistic is computed.\\n\\n    The left y-axis plots the correlation between the original series (d=0) and the differentiated\\n    series at various d values.\\n\\n    Examples on how to interpret the results of this function are available in the corresponding part\\n    in the book Advances in Financial Machine Learning.\\n\\n    :param series: (pd.DataFrame) Dataframe that contains a \\'close\\' column with prices to use.\\n    :return: (plt.AxesSubplot) A plot that can be displayed or used to obtain resulting data.\\n    '\n    pass",
            "def plot_min_ffd(series):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.6, page 85.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n\\n    This function plots the graph to find the minimum D value that passes the ADF test.\\n\\n    It allows to determine d - the amount of memory that needs to be removed to achieve\\n    stationarity. This function covers the case of 0 < d << 1, when the original series is\\n    \"mildly non-stationary.\"\\n\\n    The right y-axis on the plot is the ADF statistic computed on the input series downsampled\\n    to a daily frequency.\\n\\n    The x-axis displays the d value used to generate the series on which the ADF statistic is computed.\\n\\n    The left y-axis plots the correlation between the original series (d=0) and the differentiated\\n    series at various d values.\\n\\n    Examples on how to interpret the results of this function are available in the corresponding part\\n    in the book Advances in Financial Machine Learning.\\n\\n    :param series: (pd.DataFrame) Dataframe that contains a \\'close\\' column with prices to use.\\n    :return: (plt.AxesSubplot) A plot that can be displayed or used to obtain resulting data.\\n    '\n    pass",
            "def plot_min_ffd(series):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.6, page 85.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n\\n    This function plots the graph to find the minimum D value that passes the ADF test.\\n\\n    It allows to determine d - the amount of memory that needs to be removed to achieve\\n    stationarity. This function covers the case of 0 < d << 1, when the original series is\\n    \"mildly non-stationary.\"\\n\\n    The right y-axis on the plot is the ADF statistic computed on the input series downsampled\\n    to a daily frequency.\\n\\n    The x-axis displays the d value used to generate the series on which the ADF statistic is computed.\\n\\n    The left y-axis plots the correlation between the original series (d=0) and the differentiated\\n    series at various d values.\\n\\n    Examples on how to interpret the results of this function are available in the corresponding part\\n    in the book Advances in Financial Machine Learning.\\n\\n    :param series: (pd.DataFrame) Dataframe that contains a \\'close\\' column with prices to use.\\n    :return: (plt.AxesSubplot) A plot that can be displayed or used to obtain resulting data.\\n    '\n    pass",
            "def plot_min_ffd(series):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.6, page 85.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n\\n    This function plots the graph to find the minimum D value that passes the ADF test.\\n\\n    It allows to determine d - the amount of memory that needs to be removed to achieve\\n    stationarity. This function covers the case of 0 < d << 1, when the original series is\\n    \"mildly non-stationary.\"\\n\\n    The right y-axis on the plot is the ADF statistic computed on the input series downsampled\\n    to a daily frequency.\\n\\n    The x-axis displays the d value used to generate the series on which the ADF statistic is computed.\\n\\n    The left y-axis plots the correlation between the original series (d=0) and the differentiated\\n    series at various d values.\\n\\n    Examples on how to interpret the results of this function are available in the corresponding part\\n    in the book Advances in Financial Machine Learning.\\n\\n    :param series: (pd.DataFrame) Dataframe that contains a \\'close\\' column with prices to use.\\n    :return: (plt.AxesSubplot) A plot that can be displayed or used to obtain resulting data.\\n    '\n    pass",
            "def plot_min_ffd(series):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Advances in Financial Machine Learning, Chapter 5, section 5.6, page 85.\\n\\n    References:\\n\\n    * https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086\\n\\n    This function plots the graph to find the minimum D value that passes the ADF test.\\n\\n    It allows to determine d - the amount of memory that needs to be removed to achieve\\n    stationarity. This function covers the case of 0 < d << 1, when the original series is\\n    \"mildly non-stationary.\"\\n\\n    The right y-axis on the plot is the ADF statistic computed on the input series downsampled\\n    to a daily frequency.\\n\\n    The x-axis displays the d value used to generate the series on which the ADF statistic is computed.\\n\\n    The left y-axis plots the correlation between the original series (d=0) and the differentiated\\n    series at various d values.\\n\\n    Examples on how to interpret the results of this function are available in the corresponding part\\n    in the book Advances in Financial Machine Learning.\\n\\n    :param series: (pd.DataFrame) Dataframe that contains a \\'close\\' column with prices to use.\\n    :return: (plt.AxesSubplot) A plot that can be displayed or used to obtain resulting data.\\n    '\n    pass"
        ]
    }
]