[
    {
        "func_name": "corr2_coeff",
        "original": "def corr2_coeff(A, B):\n    \"\"\"\n    Compute correlation coefficients and return as a np array\n    \"\"\"\n    (A, B) = (np.array(A), np.array(B))\n    A_mA = A - A.mean(1)[:, None]\n    B_mB = B - B.mean(1)[:, None]\n    ssA = (A_mA ** 2).sum(1)\n    ssB = (B_mB ** 2).sum(1)\n    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None], ssB[None]))",
        "mutated": [
            "def corr2_coeff(A, B):\n    if False:\n        i = 10\n    '\\n    Compute correlation coefficients and return as a np array\\n    '\n    (A, B) = (np.array(A), np.array(B))\n    A_mA = A - A.mean(1)[:, None]\n    B_mB = B - B.mean(1)[:, None]\n    ssA = (A_mA ** 2).sum(1)\n    ssB = (B_mB ** 2).sum(1)\n    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None], ssB[None]))",
            "def corr2_coeff(A, B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Compute correlation coefficients and return as a np array\\n    '\n    (A, B) = (np.array(A), np.array(B))\n    A_mA = A - A.mean(1)[:, None]\n    B_mB = B - B.mean(1)[:, None]\n    ssA = (A_mA ** 2).sum(1)\n    ssB = (B_mB ** 2).sum(1)\n    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None], ssB[None]))",
            "def corr2_coeff(A, B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Compute correlation coefficients and return as a np array\\n    '\n    (A, B) = (np.array(A), np.array(B))\n    A_mA = A - A.mean(1)[:, None]\n    B_mB = B - B.mean(1)[:, None]\n    ssA = (A_mA ** 2).sum(1)\n    ssB = (B_mB ** 2).sum(1)\n    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None], ssB[None]))",
            "def corr2_coeff(A, B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Compute correlation coefficients and return as a np array\\n    '\n    (A, B) = (np.array(A), np.array(B))\n    A_mA = A - A.mean(1)[:, None]\n    B_mB = B - B.mean(1)[:, None]\n    ssA = (A_mA ** 2).sum(1)\n    ssB = (B_mB ** 2).sum(1)\n    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None], ssB[None]))",
            "def corr2_coeff(A, B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Compute correlation coefficients and return as a np array\\n    '\n    (A, B) = (np.array(A), np.array(B))\n    A_mA = A - A.mean(1)[:, None]\n    B_mB = B - B.mean(1)[:, None]\n    ssA = (A_mA ** 2).sum(1)\n    ssB = (B_mB ** 2).sum(1)\n    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None], ssB[None]))"
        ]
    },
    {
        "func_name": "create_correlation_table",
        "original": "def create_correlation_table(A, B, names_cols_A, names_cols_B):\n    \"\"\"\n    Compute correlation coefficients and return as a DataFrame.\n\n    A and B: 2d array like.\n        The columns represent the different variables and the rows are\n        the samples of thos variables\n    names_cols_A/B : name to be added to the final pandas table\n\n    return: pandas DataFrame with the corelations.Columns and Indexes\n    represent the different variables of A and B (respectvely)\n    \"\"\"\n    corrs = corr2_coeff(A.T, B.T).T\n    df_corrs = pd.DataFrame(corrs, columns=names_cols_A, index=names_cols_B)\n    return df_corrs",
        "mutated": [
            "def create_correlation_table(A, B, names_cols_A, names_cols_B):\n    if False:\n        i = 10\n    '\\n    Compute correlation coefficients and return as a DataFrame.\\n\\n    A and B: 2d array like.\\n        The columns represent the different variables and the rows are\\n        the samples of thos variables\\n    names_cols_A/B : name to be added to the final pandas table\\n\\n    return: pandas DataFrame with the corelations.Columns and Indexes\\n    represent the different variables of A and B (respectvely)\\n    '\n    corrs = corr2_coeff(A.T, B.T).T\n    df_corrs = pd.DataFrame(corrs, columns=names_cols_A, index=names_cols_B)\n    return df_corrs",
            "def create_correlation_table(A, B, names_cols_A, names_cols_B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Compute correlation coefficients and return as a DataFrame.\\n\\n    A and B: 2d array like.\\n        The columns represent the different variables and the rows are\\n        the samples of thos variables\\n    names_cols_A/B : name to be added to the final pandas table\\n\\n    return: pandas DataFrame with the corelations.Columns and Indexes\\n    represent the different variables of A and B (respectvely)\\n    '\n    corrs = corr2_coeff(A.T, B.T).T\n    df_corrs = pd.DataFrame(corrs, columns=names_cols_A, index=names_cols_B)\n    return df_corrs",
            "def create_correlation_table(A, B, names_cols_A, names_cols_B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Compute correlation coefficients and return as a DataFrame.\\n\\n    A and B: 2d array like.\\n        The columns represent the different variables and the rows are\\n        the samples of thos variables\\n    names_cols_A/B : name to be added to the final pandas table\\n\\n    return: pandas DataFrame with the corelations.Columns and Indexes\\n    represent the different variables of A and B (respectvely)\\n    '\n    corrs = corr2_coeff(A.T, B.T).T\n    df_corrs = pd.DataFrame(corrs, columns=names_cols_A, index=names_cols_B)\n    return df_corrs",
            "def create_correlation_table(A, B, names_cols_A, names_cols_B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Compute correlation coefficients and return as a DataFrame.\\n\\n    A and B: 2d array like.\\n        The columns represent the different variables and the rows are\\n        the samples of thos variables\\n    names_cols_A/B : name to be added to the final pandas table\\n\\n    return: pandas DataFrame with the corelations.Columns and Indexes\\n    represent the different variables of A and B (respectvely)\\n    '\n    corrs = corr2_coeff(A.T, B.T).T\n    df_corrs = pd.DataFrame(corrs, columns=names_cols_A, index=names_cols_B)\n    return df_corrs",
            "def create_correlation_table(A, B, names_cols_A, names_cols_B):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Compute correlation coefficients and return as a DataFrame.\\n\\n    A and B: 2d array like.\\n        The columns represent the different variables and the rows are\\n        the samples of thos variables\\n    names_cols_A/B : name to be added to the final pandas table\\n\\n    return: pandas DataFrame with the corelations.Columns and Indexes\\n    represent the different variables of A and B (respectvely)\\n    '\n    corrs = corr2_coeff(A.T, B.T).T\n    df_corrs = pd.DataFrame(corrs, columns=names_cols_A, index=names_cols_B)\n    return df_corrs"
        ]
    },
    {
        "func_name": "plot_pca_correlation_graph",
        "original": "def plot_pca_correlation_graph(X, variables_names, dimensions=(1, 2), figure_axis_size=6, X_pca=None, explained_variance=None):\n    \"\"\"\n    Compute the PCA for X and plots the Correlation graph\n\n    Parameters\n    ----------\n    X : 2d array like.\n        The columns represent the different variables and the rows are the\n         samples of thos variables\n\n    variables_names : array like\n        Name of the columns (the variables) of X\n\n    dimensions: tuple with two elements.\n        dimensions to be plotted (x,y)\n\n    figure_axis_size :\n         size of the final frame. The figure created is a square with length\n         and width equal to figure_axis_size.\n\n    X_pca : np.ndarray, shape = [n_samples, n_components].\n        Optional.\n        `X_pca` is the matrix of the transformed components from X.\n        If not provided, the function computes PCA automatically using\n        mlxtend.feature_extraction.PrincipalComponentAnalysis\n        Expected `n_componentes >= max(dimensions)`\n\n    explained_variance : 1 dimension np.ndarray, length = n_components\n        Optional.\n        `explained_variance` are the eigenvalues from the diagonalized\n        covariance matrix on the PCA transformatiopn.\n        If not provided, the function computes PCA independently\n        Expected `n_componentes == X.shape[1]`\n\n    Returns\n    ----------\n        matplotlib_figure, correlation_matrix\n\n    Examples\n    -----------\n    For usage examples, please see\n    https://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/\n\n    \"\"\"\n    X = np.array(X)\n    X = X - X.mean(axis=0)\n    n_comp = max(dimensions)\n    if X_pca is None and explained_variance is None:\n        pca = PrincipalComponentAnalysis(n_components=n_comp)\n        pca.fit(X)\n        X_pca = pca.transform(X)\n        explained_variance = pca.e_vals_\n    elif X_pca is not None and explained_variance is None:\n        raise ValueError('If `X_pca` is not None, the `explained variance` values should not be `None`.')\n    elif X_pca is None and explained_variance is not None:\n        raise ValueError('If `explained variance` is not None, the `X_pca` values should not be `None`.')\n    elif X_pca is not None and explained_variance is not None:\n        if X_pca.shape[1] != len(explained_variance):\n            raise ValueError(f'Number of principal components must match the number of eigenvalues. Got {X_pca.shape[1]} != {len(explained_variance)}')\n    if X_pca.shape[1] < n_comp:\n        raise ValueError(f'Input array `X_pca` contains fewer principal components than expected based on `dimensions`. Got {X_pca.shape[1]} components in X_pca, expected at least `max(dimensions)={n_comp}`.')\n    if len(explained_variance) < n_comp:\n        raise ValueError(f'Input array `explained_variance` contains fewer elements than expected. Got {len(explained_variance)} elements, expected`X.shape[1]={X.shape[1]}`.')\n    corrs = create_correlation_table(X_pca, X, ['Dim ' + str(i + 1) for i in range(n_comp)], variables_names)\n    tot = sum(X.var(0)) * X.shape[0] / (X.shape[0] - 1)\n    explained_var_ratio = [i / tot * 100 for i in explained_variance]\n    fig_res = plt.figure(figsize=(figure_axis_size, figure_axis_size))\n    plt.Circle((0, 0), radius=1, color='k', fill=False)\n    circle1 = plt.Circle((0, 0), radius=1, color='k', fill=False)\n    fig = plt.gcf()\n    fig.gca().add_artist(circle1)\n    texts = []\n    for (name, row) in corrs.iterrows():\n        x = row['Dim ' + str(dimensions[0])]\n        y = row['Dim ' + str(dimensions[1])]\n        plt.arrow(0.0, 0.0, x, y, color='k', length_includes_head=True, head_width=0.05)\n        plt.plot([0.0, x], [0.0, y], 'k-')\n        texts.append(plt.text(x, y, name, fontsize=2 * figure_axis_size))\n    plt.plot([-1.1, 1.1], [0, 0], 'k--')\n    plt.plot([0, 0], [-1.1, 1.1], 'k--')\n    adjust_text(texts)\n    plt.xlim((-1.1, 1.1))\n    plt.ylim((-1.1, 1.1))\n    plt.title('Correlation Circle', fontsize=figure_axis_size * 3)\n    plt.xlabel('Dim ' + str(dimensions[0]) + ' (%s%%)' % str(explained_var_ratio[dimensions[0] - 1])[:4], fontsize=figure_axis_size * 2)\n    plt.ylabel('Dim ' + str(dimensions[1]) + ' (%s%%)' % str(explained_var_ratio[dimensions[1] - 1])[:4], fontsize=figure_axis_size * 2)\n    return (fig_res, corrs)",
        "mutated": [
            "def plot_pca_correlation_graph(X, variables_names, dimensions=(1, 2), figure_axis_size=6, X_pca=None, explained_variance=None):\n    if False:\n        i = 10\n    '\\n    Compute the PCA for X and plots the Correlation graph\\n\\n    Parameters\\n    ----------\\n    X : 2d array like.\\n        The columns represent the different variables and the rows are the\\n         samples of thos variables\\n\\n    variables_names : array like\\n        Name of the columns (the variables) of X\\n\\n    dimensions: tuple with two elements.\\n        dimensions to be plotted (x,y)\\n\\n    figure_axis_size :\\n         size of the final frame. The figure created is a square with length\\n         and width equal to figure_axis_size.\\n\\n    X_pca : np.ndarray, shape = [n_samples, n_components].\\n        Optional.\\n        `X_pca` is the matrix of the transformed components from X.\\n        If not provided, the function computes PCA automatically using\\n        mlxtend.feature_extraction.PrincipalComponentAnalysis\\n        Expected `n_componentes >= max(dimensions)`\\n\\n    explained_variance : 1 dimension np.ndarray, length = n_components\\n        Optional.\\n        `explained_variance` are the eigenvalues from the diagonalized\\n        covariance matrix on the PCA transformatiopn.\\n        If not provided, the function computes PCA independently\\n        Expected `n_componentes == X.shape[1]`\\n\\n    Returns\\n    ----------\\n        matplotlib_figure, correlation_matrix\\n\\n    Examples\\n    -----------\\n    For usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/\\n\\n    '\n    X = np.array(X)\n    X = X - X.mean(axis=0)\n    n_comp = max(dimensions)\n    if X_pca is None and explained_variance is None:\n        pca = PrincipalComponentAnalysis(n_components=n_comp)\n        pca.fit(X)\n        X_pca = pca.transform(X)\n        explained_variance = pca.e_vals_\n    elif X_pca is not None and explained_variance is None:\n        raise ValueError('If `X_pca` is not None, the `explained variance` values should not be `None`.')\n    elif X_pca is None and explained_variance is not None:\n        raise ValueError('If `explained variance` is not None, the `X_pca` values should not be `None`.')\n    elif X_pca is not None and explained_variance is not None:\n        if X_pca.shape[1] != len(explained_variance):\n            raise ValueError(f'Number of principal components must match the number of eigenvalues. Got {X_pca.shape[1]} != {len(explained_variance)}')\n    if X_pca.shape[1] < n_comp:\n        raise ValueError(f'Input array `X_pca` contains fewer principal components than expected based on `dimensions`. Got {X_pca.shape[1]} components in X_pca, expected at least `max(dimensions)={n_comp}`.')\n    if len(explained_variance) < n_comp:\n        raise ValueError(f'Input array `explained_variance` contains fewer elements than expected. Got {len(explained_variance)} elements, expected`X.shape[1]={X.shape[1]}`.')\n    corrs = create_correlation_table(X_pca, X, ['Dim ' + str(i + 1) for i in range(n_comp)], variables_names)\n    tot = sum(X.var(0)) * X.shape[0] / (X.shape[0] - 1)\n    explained_var_ratio = [i / tot * 100 for i in explained_variance]\n    fig_res = plt.figure(figsize=(figure_axis_size, figure_axis_size))\n    plt.Circle((0, 0), radius=1, color='k', fill=False)\n    circle1 = plt.Circle((0, 0), radius=1, color='k', fill=False)\n    fig = plt.gcf()\n    fig.gca().add_artist(circle1)\n    texts = []\n    for (name, row) in corrs.iterrows():\n        x = row['Dim ' + str(dimensions[0])]\n        y = row['Dim ' + str(dimensions[1])]\n        plt.arrow(0.0, 0.0, x, y, color='k', length_includes_head=True, head_width=0.05)\n        plt.plot([0.0, x], [0.0, y], 'k-')\n        texts.append(plt.text(x, y, name, fontsize=2 * figure_axis_size))\n    plt.plot([-1.1, 1.1], [0, 0], 'k--')\n    plt.plot([0, 0], [-1.1, 1.1], 'k--')\n    adjust_text(texts)\n    plt.xlim((-1.1, 1.1))\n    plt.ylim((-1.1, 1.1))\n    plt.title('Correlation Circle', fontsize=figure_axis_size * 3)\n    plt.xlabel('Dim ' + str(dimensions[0]) + ' (%s%%)' % str(explained_var_ratio[dimensions[0] - 1])[:4], fontsize=figure_axis_size * 2)\n    plt.ylabel('Dim ' + str(dimensions[1]) + ' (%s%%)' % str(explained_var_ratio[dimensions[1] - 1])[:4], fontsize=figure_axis_size * 2)\n    return (fig_res, corrs)",
            "def plot_pca_correlation_graph(X, variables_names, dimensions=(1, 2), figure_axis_size=6, X_pca=None, explained_variance=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Compute the PCA for X and plots the Correlation graph\\n\\n    Parameters\\n    ----------\\n    X : 2d array like.\\n        The columns represent the different variables and the rows are the\\n         samples of thos variables\\n\\n    variables_names : array like\\n        Name of the columns (the variables) of X\\n\\n    dimensions: tuple with two elements.\\n        dimensions to be plotted (x,y)\\n\\n    figure_axis_size :\\n         size of the final frame. The figure created is a square with length\\n         and width equal to figure_axis_size.\\n\\n    X_pca : np.ndarray, shape = [n_samples, n_components].\\n        Optional.\\n        `X_pca` is the matrix of the transformed components from X.\\n        If not provided, the function computes PCA automatically using\\n        mlxtend.feature_extraction.PrincipalComponentAnalysis\\n        Expected `n_componentes >= max(dimensions)`\\n\\n    explained_variance : 1 dimension np.ndarray, length = n_components\\n        Optional.\\n        `explained_variance` are the eigenvalues from the diagonalized\\n        covariance matrix on the PCA transformatiopn.\\n        If not provided, the function computes PCA independently\\n        Expected `n_componentes == X.shape[1]`\\n\\n    Returns\\n    ----------\\n        matplotlib_figure, correlation_matrix\\n\\n    Examples\\n    -----------\\n    For usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/\\n\\n    '\n    X = np.array(X)\n    X = X - X.mean(axis=0)\n    n_comp = max(dimensions)\n    if X_pca is None and explained_variance is None:\n        pca = PrincipalComponentAnalysis(n_components=n_comp)\n        pca.fit(X)\n        X_pca = pca.transform(X)\n        explained_variance = pca.e_vals_\n    elif X_pca is not None and explained_variance is None:\n        raise ValueError('If `X_pca` is not None, the `explained variance` values should not be `None`.')\n    elif X_pca is None and explained_variance is not None:\n        raise ValueError('If `explained variance` is not None, the `X_pca` values should not be `None`.')\n    elif X_pca is not None and explained_variance is not None:\n        if X_pca.shape[1] != len(explained_variance):\n            raise ValueError(f'Number of principal components must match the number of eigenvalues. Got {X_pca.shape[1]} != {len(explained_variance)}')\n    if X_pca.shape[1] < n_comp:\n        raise ValueError(f'Input array `X_pca` contains fewer principal components than expected based on `dimensions`. Got {X_pca.shape[1]} components in X_pca, expected at least `max(dimensions)={n_comp}`.')\n    if len(explained_variance) < n_comp:\n        raise ValueError(f'Input array `explained_variance` contains fewer elements than expected. Got {len(explained_variance)} elements, expected`X.shape[1]={X.shape[1]}`.')\n    corrs = create_correlation_table(X_pca, X, ['Dim ' + str(i + 1) for i in range(n_comp)], variables_names)\n    tot = sum(X.var(0)) * X.shape[0] / (X.shape[0] - 1)\n    explained_var_ratio = [i / tot * 100 for i in explained_variance]\n    fig_res = plt.figure(figsize=(figure_axis_size, figure_axis_size))\n    plt.Circle((0, 0), radius=1, color='k', fill=False)\n    circle1 = plt.Circle((0, 0), radius=1, color='k', fill=False)\n    fig = plt.gcf()\n    fig.gca().add_artist(circle1)\n    texts = []\n    for (name, row) in corrs.iterrows():\n        x = row['Dim ' + str(dimensions[0])]\n        y = row['Dim ' + str(dimensions[1])]\n        plt.arrow(0.0, 0.0, x, y, color='k', length_includes_head=True, head_width=0.05)\n        plt.plot([0.0, x], [0.0, y], 'k-')\n        texts.append(plt.text(x, y, name, fontsize=2 * figure_axis_size))\n    plt.plot([-1.1, 1.1], [0, 0], 'k--')\n    plt.plot([0, 0], [-1.1, 1.1], 'k--')\n    adjust_text(texts)\n    plt.xlim((-1.1, 1.1))\n    plt.ylim((-1.1, 1.1))\n    plt.title('Correlation Circle', fontsize=figure_axis_size * 3)\n    plt.xlabel('Dim ' + str(dimensions[0]) + ' (%s%%)' % str(explained_var_ratio[dimensions[0] - 1])[:4], fontsize=figure_axis_size * 2)\n    plt.ylabel('Dim ' + str(dimensions[1]) + ' (%s%%)' % str(explained_var_ratio[dimensions[1] - 1])[:4], fontsize=figure_axis_size * 2)\n    return (fig_res, corrs)",
            "def plot_pca_correlation_graph(X, variables_names, dimensions=(1, 2), figure_axis_size=6, X_pca=None, explained_variance=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Compute the PCA for X and plots the Correlation graph\\n\\n    Parameters\\n    ----------\\n    X : 2d array like.\\n        The columns represent the different variables and the rows are the\\n         samples of thos variables\\n\\n    variables_names : array like\\n        Name of the columns (the variables) of X\\n\\n    dimensions: tuple with two elements.\\n        dimensions to be plotted (x,y)\\n\\n    figure_axis_size :\\n         size of the final frame. The figure created is a square with length\\n         and width equal to figure_axis_size.\\n\\n    X_pca : np.ndarray, shape = [n_samples, n_components].\\n        Optional.\\n        `X_pca` is the matrix of the transformed components from X.\\n        If not provided, the function computes PCA automatically using\\n        mlxtend.feature_extraction.PrincipalComponentAnalysis\\n        Expected `n_componentes >= max(dimensions)`\\n\\n    explained_variance : 1 dimension np.ndarray, length = n_components\\n        Optional.\\n        `explained_variance` are the eigenvalues from the diagonalized\\n        covariance matrix on the PCA transformatiopn.\\n        If not provided, the function computes PCA independently\\n        Expected `n_componentes == X.shape[1]`\\n\\n    Returns\\n    ----------\\n        matplotlib_figure, correlation_matrix\\n\\n    Examples\\n    -----------\\n    For usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/\\n\\n    '\n    X = np.array(X)\n    X = X - X.mean(axis=0)\n    n_comp = max(dimensions)\n    if X_pca is None and explained_variance is None:\n        pca = PrincipalComponentAnalysis(n_components=n_comp)\n        pca.fit(X)\n        X_pca = pca.transform(X)\n        explained_variance = pca.e_vals_\n    elif X_pca is not None and explained_variance is None:\n        raise ValueError('If `X_pca` is not None, the `explained variance` values should not be `None`.')\n    elif X_pca is None and explained_variance is not None:\n        raise ValueError('If `explained variance` is not None, the `X_pca` values should not be `None`.')\n    elif X_pca is not None and explained_variance is not None:\n        if X_pca.shape[1] != len(explained_variance):\n            raise ValueError(f'Number of principal components must match the number of eigenvalues. Got {X_pca.shape[1]} != {len(explained_variance)}')\n    if X_pca.shape[1] < n_comp:\n        raise ValueError(f'Input array `X_pca` contains fewer principal components than expected based on `dimensions`. Got {X_pca.shape[1]} components in X_pca, expected at least `max(dimensions)={n_comp}`.')\n    if len(explained_variance) < n_comp:\n        raise ValueError(f'Input array `explained_variance` contains fewer elements than expected. Got {len(explained_variance)} elements, expected`X.shape[1]={X.shape[1]}`.')\n    corrs = create_correlation_table(X_pca, X, ['Dim ' + str(i + 1) for i in range(n_comp)], variables_names)\n    tot = sum(X.var(0)) * X.shape[0] / (X.shape[0] - 1)\n    explained_var_ratio = [i / tot * 100 for i in explained_variance]\n    fig_res = plt.figure(figsize=(figure_axis_size, figure_axis_size))\n    plt.Circle((0, 0), radius=1, color='k', fill=False)\n    circle1 = plt.Circle((0, 0), radius=1, color='k', fill=False)\n    fig = plt.gcf()\n    fig.gca().add_artist(circle1)\n    texts = []\n    for (name, row) in corrs.iterrows():\n        x = row['Dim ' + str(dimensions[0])]\n        y = row['Dim ' + str(dimensions[1])]\n        plt.arrow(0.0, 0.0, x, y, color='k', length_includes_head=True, head_width=0.05)\n        plt.plot([0.0, x], [0.0, y], 'k-')\n        texts.append(plt.text(x, y, name, fontsize=2 * figure_axis_size))\n    plt.plot([-1.1, 1.1], [0, 0], 'k--')\n    plt.plot([0, 0], [-1.1, 1.1], 'k--')\n    adjust_text(texts)\n    plt.xlim((-1.1, 1.1))\n    plt.ylim((-1.1, 1.1))\n    plt.title('Correlation Circle', fontsize=figure_axis_size * 3)\n    plt.xlabel('Dim ' + str(dimensions[0]) + ' (%s%%)' % str(explained_var_ratio[dimensions[0] - 1])[:4], fontsize=figure_axis_size * 2)\n    plt.ylabel('Dim ' + str(dimensions[1]) + ' (%s%%)' % str(explained_var_ratio[dimensions[1] - 1])[:4], fontsize=figure_axis_size * 2)\n    return (fig_res, corrs)",
            "def plot_pca_correlation_graph(X, variables_names, dimensions=(1, 2), figure_axis_size=6, X_pca=None, explained_variance=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Compute the PCA for X and plots the Correlation graph\\n\\n    Parameters\\n    ----------\\n    X : 2d array like.\\n        The columns represent the different variables and the rows are the\\n         samples of thos variables\\n\\n    variables_names : array like\\n        Name of the columns (the variables) of X\\n\\n    dimensions: tuple with two elements.\\n        dimensions to be plotted (x,y)\\n\\n    figure_axis_size :\\n         size of the final frame. The figure created is a square with length\\n         and width equal to figure_axis_size.\\n\\n    X_pca : np.ndarray, shape = [n_samples, n_components].\\n        Optional.\\n        `X_pca` is the matrix of the transformed components from X.\\n        If not provided, the function computes PCA automatically using\\n        mlxtend.feature_extraction.PrincipalComponentAnalysis\\n        Expected `n_componentes >= max(dimensions)`\\n\\n    explained_variance : 1 dimension np.ndarray, length = n_components\\n        Optional.\\n        `explained_variance` are the eigenvalues from the diagonalized\\n        covariance matrix on the PCA transformatiopn.\\n        If not provided, the function computes PCA independently\\n        Expected `n_componentes == X.shape[1]`\\n\\n    Returns\\n    ----------\\n        matplotlib_figure, correlation_matrix\\n\\n    Examples\\n    -----------\\n    For usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/\\n\\n    '\n    X = np.array(X)\n    X = X - X.mean(axis=0)\n    n_comp = max(dimensions)\n    if X_pca is None and explained_variance is None:\n        pca = PrincipalComponentAnalysis(n_components=n_comp)\n        pca.fit(X)\n        X_pca = pca.transform(X)\n        explained_variance = pca.e_vals_\n    elif X_pca is not None and explained_variance is None:\n        raise ValueError('If `X_pca` is not None, the `explained variance` values should not be `None`.')\n    elif X_pca is None and explained_variance is not None:\n        raise ValueError('If `explained variance` is not None, the `X_pca` values should not be `None`.')\n    elif X_pca is not None and explained_variance is not None:\n        if X_pca.shape[1] != len(explained_variance):\n            raise ValueError(f'Number of principal components must match the number of eigenvalues. Got {X_pca.shape[1]} != {len(explained_variance)}')\n    if X_pca.shape[1] < n_comp:\n        raise ValueError(f'Input array `X_pca` contains fewer principal components than expected based on `dimensions`. Got {X_pca.shape[1]} components in X_pca, expected at least `max(dimensions)={n_comp}`.')\n    if len(explained_variance) < n_comp:\n        raise ValueError(f'Input array `explained_variance` contains fewer elements than expected. Got {len(explained_variance)} elements, expected`X.shape[1]={X.shape[1]}`.')\n    corrs = create_correlation_table(X_pca, X, ['Dim ' + str(i + 1) for i in range(n_comp)], variables_names)\n    tot = sum(X.var(0)) * X.shape[0] / (X.shape[0] - 1)\n    explained_var_ratio = [i / tot * 100 for i in explained_variance]\n    fig_res = plt.figure(figsize=(figure_axis_size, figure_axis_size))\n    plt.Circle((0, 0), radius=1, color='k', fill=False)\n    circle1 = plt.Circle((0, 0), radius=1, color='k', fill=False)\n    fig = plt.gcf()\n    fig.gca().add_artist(circle1)\n    texts = []\n    for (name, row) in corrs.iterrows():\n        x = row['Dim ' + str(dimensions[0])]\n        y = row['Dim ' + str(dimensions[1])]\n        plt.arrow(0.0, 0.0, x, y, color='k', length_includes_head=True, head_width=0.05)\n        plt.plot([0.0, x], [0.0, y], 'k-')\n        texts.append(plt.text(x, y, name, fontsize=2 * figure_axis_size))\n    plt.plot([-1.1, 1.1], [0, 0], 'k--')\n    plt.plot([0, 0], [-1.1, 1.1], 'k--')\n    adjust_text(texts)\n    plt.xlim((-1.1, 1.1))\n    plt.ylim((-1.1, 1.1))\n    plt.title('Correlation Circle', fontsize=figure_axis_size * 3)\n    plt.xlabel('Dim ' + str(dimensions[0]) + ' (%s%%)' % str(explained_var_ratio[dimensions[0] - 1])[:4], fontsize=figure_axis_size * 2)\n    plt.ylabel('Dim ' + str(dimensions[1]) + ' (%s%%)' % str(explained_var_ratio[dimensions[1] - 1])[:4], fontsize=figure_axis_size * 2)\n    return (fig_res, corrs)",
            "def plot_pca_correlation_graph(X, variables_names, dimensions=(1, 2), figure_axis_size=6, X_pca=None, explained_variance=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Compute the PCA for X and plots the Correlation graph\\n\\n    Parameters\\n    ----------\\n    X : 2d array like.\\n        The columns represent the different variables and the rows are the\\n         samples of thos variables\\n\\n    variables_names : array like\\n        Name of the columns (the variables) of X\\n\\n    dimensions: tuple with two elements.\\n        dimensions to be plotted (x,y)\\n\\n    figure_axis_size :\\n         size of the final frame. The figure created is a square with length\\n         and width equal to figure_axis_size.\\n\\n    X_pca : np.ndarray, shape = [n_samples, n_components].\\n        Optional.\\n        `X_pca` is the matrix of the transformed components from X.\\n        If not provided, the function computes PCA automatically using\\n        mlxtend.feature_extraction.PrincipalComponentAnalysis\\n        Expected `n_componentes >= max(dimensions)`\\n\\n    explained_variance : 1 dimension np.ndarray, length = n_components\\n        Optional.\\n        `explained_variance` are the eigenvalues from the diagonalized\\n        covariance matrix on the PCA transformatiopn.\\n        If not provided, the function computes PCA independently\\n        Expected `n_componentes == X.shape[1]`\\n\\n    Returns\\n    ----------\\n        matplotlib_figure, correlation_matrix\\n\\n    Examples\\n    -----------\\n    For usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/\\n\\n    '\n    X = np.array(X)\n    X = X - X.mean(axis=0)\n    n_comp = max(dimensions)\n    if X_pca is None and explained_variance is None:\n        pca = PrincipalComponentAnalysis(n_components=n_comp)\n        pca.fit(X)\n        X_pca = pca.transform(X)\n        explained_variance = pca.e_vals_\n    elif X_pca is not None and explained_variance is None:\n        raise ValueError('If `X_pca` is not None, the `explained variance` values should not be `None`.')\n    elif X_pca is None and explained_variance is not None:\n        raise ValueError('If `explained variance` is not None, the `X_pca` values should not be `None`.')\n    elif X_pca is not None and explained_variance is not None:\n        if X_pca.shape[1] != len(explained_variance):\n            raise ValueError(f'Number of principal components must match the number of eigenvalues. Got {X_pca.shape[1]} != {len(explained_variance)}')\n    if X_pca.shape[1] < n_comp:\n        raise ValueError(f'Input array `X_pca` contains fewer principal components than expected based on `dimensions`. Got {X_pca.shape[1]} components in X_pca, expected at least `max(dimensions)={n_comp}`.')\n    if len(explained_variance) < n_comp:\n        raise ValueError(f'Input array `explained_variance` contains fewer elements than expected. Got {len(explained_variance)} elements, expected`X.shape[1]={X.shape[1]}`.')\n    corrs = create_correlation_table(X_pca, X, ['Dim ' + str(i + 1) for i in range(n_comp)], variables_names)\n    tot = sum(X.var(0)) * X.shape[0] / (X.shape[0] - 1)\n    explained_var_ratio = [i / tot * 100 for i in explained_variance]\n    fig_res = plt.figure(figsize=(figure_axis_size, figure_axis_size))\n    plt.Circle((0, 0), radius=1, color='k', fill=False)\n    circle1 = plt.Circle((0, 0), radius=1, color='k', fill=False)\n    fig = plt.gcf()\n    fig.gca().add_artist(circle1)\n    texts = []\n    for (name, row) in corrs.iterrows():\n        x = row['Dim ' + str(dimensions[0])]\n        y = row['Dim ' + str(dimensions[1])]\n        plt.arrow(0.0, 0.0, x, y, color='k', length_includes_head=True, head_width=0.05)\n        plt.plot([0.0, x], [0.0, y], 'k-')\n        texts.append(plt.text(x, y, name, fontsize=2 * figure_axis_size))\n    plt.plot([-1.1, 1.1], [0, 0], 'k--')\n    plt.plot([0, 0], [-1.1, 1.1], 'k--')\n    adjust_text(texts)\n    plt.xlim((-1.1, 1.1))\n    plt.ylim((-1.1, 1.1))\n    plt.title('Correlation Circle', fontsize=figure_axis_size * 3)\n    plt.xlabel('Dim ' + str(dimensions[0]) + ' (%s%%)' % str(explained_var_ratio[dimensions[0] - 1])[:4], fontsize=figure_axis_size * 2)\n    plt.ylabel('Dim ' + str(dimensions[1]) + ' (%s%%)' % str(explained_var_ratio[dimensions[1] - 1])[:4], fontsize=figure_axis_size * 2)\n    return (fig_res, corrs)"
        ]
    }
]