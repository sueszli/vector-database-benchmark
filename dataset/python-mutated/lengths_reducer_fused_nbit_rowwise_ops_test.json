[
    {
        "func_name": "test_sparse_lengths_sum",
        "original": "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_sum(self, num_rows, blocksize, weighted, seed, empty_indices, engine, bit_rate):\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int64)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    if weighted:\n        net.SparseLengthsWeightedSum(['dequantized_data', 'weights', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsWeightedSumFused8BitRowwise(['fake_quantized_data', 'weights', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsWeightedSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'weights', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    else:\n        net.SparseLengthsSum(['dequantized_data', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsSumFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_fake_quantized = workspace.FetchBlob('sum_fake_quantized')\n    sum_quantized = workspace.FetchBlob('sum_quantized')\n    np.testing.assert_array_almost_equal(sum_reference, sum_quantized)\n    np.testing.assert_array_equal(sum_fake_quantized, sum_quantized)",
        "mutated": [
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_sum(self, num_rows, blocksize, weighted, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int64)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    if weighted:\n        net.SparseLengthsWeightedSum(['dequantized_data', 'weights', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsWeightedSumFused8BitRowwise(['fake_quantized_data', 'weights', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsWeightedSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'weights', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    else:\n        net.SparseLengthsSum(['dequantized_data', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsSumFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_fake_quantized = workspace.FetchBlob('sum_fake_quantized')\n    sum_quantized = workspace.FetchBlob('sum_quantized')\n    np.testing.assert_array_almost_equal(sum_reference, sum_quantized)\n    np.testing.assert_array_equal(sum_fake_quantized, sum_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_sum(self, num_rows, blocksize, weighted, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int64)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    if weighted:\n        net.SparseLengthsWeightedSum(['dequantized_data', 'weights', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsWeightedSumFused8BitRowwise(['fake_quantized_data', 'weights', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsWeightedSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'weights', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    else:\n        net.SparseLengthsSum(['dequantized_data', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsSumFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_fake_quantized = workspace.FetchBlob('sum_fake_quantized')\n    sum_quantized = workspace.FetchBlob('sum_quantized')\n    np.testing.assert_array_almost_equal(sum_reference, sum_quantized)\n    np.testing.assert_array_equal(sum_fake_quantized, sum_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_sum(self, num_rows, blocksize, weighted, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int64)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    if weighted:\n        net.SparseLengthsWeightedSum(['dequantized_data', 'weights', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsWeightedSumFused8BitRowwise(['fake_quantized_data', 'weights', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsWeightedSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'weights', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    else:\n        net.SparseLengthsSum(['dequantized_data', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsSumFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_fake_quantized = workspace.FetchBlob('sum_fake_quantized')\n    sum_quantized = workspace.FetchBlob('sum_quantized')\n    np.testing.assert_array_almost_equal(sum_reference, sum_quantized)\n    np.testing.assert_array_equal(sum_fake_quantized, sum_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_sum(self, num_rows, blocksize, weighted, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int64)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    if weighted:\n        net.SparseLengthsWeightedSum(['dequantized_data', 'weights', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsWeightedSumFused8BitRowwise(['fake_quantized_data', 'weights', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsWeightedSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'weights', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    else:\n        net.SparseLengthsSum(['dequantized_data', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsSumFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_fake_quantized = workspace.FetchBlob('sum_fake_quantized')\n    sum_quantized = workspace.FetchBlob('sum_quantized')\n    np.testing.assert_array_almost_equal(sum_reference, sum_quantized)\n    np.testing.assert_array_equal(sum_fake_quantized, sum_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_sum(self, num_rows, blocksize, weighted, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int64)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    if weighted:\n        net.SparseLengthsWeightedSum(['dequantized_data', 'weights', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsWeightedSumFused8BitRowwise(['fake_quantized_data', 'weights', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsWeightedSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'weights', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    else:\n        net.SparseLengthsSum(['dequantized_data', 'indices', 'lengths'], 'sum_reference')\n        net.SparseLengthsSumFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'sum_fake_quantized')\n        op = core.CreateOperator('SparseLengthsSumFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'sum_quantized')\n        net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_fake_quantized = workspace.FetchBlob('sum_fake_quantized')\n    sum_quantized = workspace.FetchBlob('sum_quantized')\n    np.testing.assert_array_almost_equal(sum_reference, sum_quantized)\n    np.testing.assert_array_equal(sum_fake_quantized, sum_quantized)"
        ]
    },
    {
        "func_name": "test_sparse_lengths_mean",
        "original": "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)",
        "mutated": [
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    net.Proto().op.extend([op])\n    net.Proto().external_input.extend(['input_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)"
        ]
    },
    {
        "func_name": "test_sparse_lengths_sum_rowwise_sparse",
        "original": "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), empty_indices=st.booleans(), bit_rate=st.sampled_from([2, 4, 8]), indices_64bit=st.booleans())\ndef test_sparse_lengths_sum_rowwise_sparse(self, num_rows, blocksize, weighted, empty_indices, bit_rate, indices_64bit):\n    net = core.Net('bench')\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    index_type = np.int64 if indices_64bit else np.int32\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=index_type)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    sparsity = 0.7\n    mapping_table = np.zeros(num_rows, dtype=np.int32)\n    num_compressed_rows = 0\n    unpruned_ids = []\n    for i in range(num_rows):\n        if np.random.uniform() < sparsity:\n            mapping_table[i] = -1\n            quantized_data[i, :] = 0\n        else:\n            mapping_table[i] = num_compressed_rows\n            num_compressed_rows += 1\n            unpruned_ids.append(i)\n    pruned_quantized_data = quantized_data[unpruned_ids]\n    inputs = ['quantized_data'] + (['weights'] if weighted else []) + ['indices', 'lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_reference')\n    net.Proto().op.extend([op])\n    inputs[0] = 'pruned_quantized_data'\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'Sum' + str(bit_rate) + 'BitRowwiseSparse', inputs + ['mapping_table'], 'sum_pruned')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('SparseLengthsSumSparseLookup', ['indices', 'lengths', 'mapping_table'] + (['weights'] if weighted else []), ['new_indices', 'new_lengths'] + (['new_weights'] if weighted else []))\n    net.Proto().op.extend([op])\n    inputs = ['pruned_quantized_data'] + (['new_weights'] if weighted else []) + ['new_indices', 'new_lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_split')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.FeedBlob('pruned_quantized_data', pruned_quantized_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_pruned = workspace.FetchBlob('sum_pruned')\n    sum_split = workspace.FetchBlob('sum_split')\n    np.testing.assert_array_equal(sum_reference, sum_pruned)\n    np.testing.assert_array_equal(sum_reference, sum_split)",
        "mutated": [
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), empty_indices=st.booleans(), bit_rate=st.sampled_from([2, 4, 8]), indices_64bit=st.booleans())\ndef test_sparse_lengths_sum_rowwise_sparse(self, num_rows, blocksize, weighted, empty_indices, bit_rate, indices_64bit):\n    if False:\n        i = 10\n    net = core.Net('bench')\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    index_type = np.int64 if indices_64bit else np.int32\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=index_type)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    sparsity = 0.7\n    mapping_table = np.zeros(num_rows, dtype=np.int32)\n    num_compressed_rows = 0\n    unpruned_ids = []\n    for i in range(num_rows):\n        if np.random.uniform() < sparsity:\n            mapping_table[i] = -1\n            quantized_data[i, :] = 0\n        else:\n            mapping_table[i] = num_compressed_rows\n            num_compressed_rows += 1\n            unpruned_ids.append(i)\n    pruned_quantized_data = quantized_data[unpruned_ids]\n    inputs = ['quantized_data'] + (['weights'] if weighted else []) + ['indices', 'lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_reference')\n    net.Proto().op.extend([op])\n    inputs[0] = 'pruned_quantized_data'\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'Sum' + str(bit_rate) + 'BitRowwiseSparse', inputs + ['mapping_table'], 'sum_pruned')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('SparseLengthsSumSparseLookup', ['indices', 'lengths', 'mapping_table'] + (['weights'] if weighted else []), ['new_indices', 'new_lengths'] + (['new_weights'] if weighted else []))\n    net.Proto().op.extend([op])\n    inputs = ['pruned_quantized_data'] + (['new_weights'] if weighted else []) + ['new_indices', 'new_lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_split')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.FeedBlob('pruned_quantized_data', pruned_quantized_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_pruned = workspace.FetchBlob('sum_pruned')\n    sum_split = workspace.FetchBlob('sum_split')\n    np.testing.assert_array_equal(sum_reference, sum_pruned)\n    np.testing.assert_array_equal(sum_reference, sum_split)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), empty_indices=st.booleans(), bit_rate=st.sampled_from([2, 4, 8]), indices_64bit=st.booleans())\ndef test_sparse_lengths_sum_rowwise_sparse(self, num_rows, blocksize, weighted, empty_indices, bit_rate, indices_64bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    net = core.Net('bench')\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    index_type = np.int64 if indices_64bit else np.int32\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=index_type)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    sparsity = 0.7\n    mapping_table = np.zeros(num_rows, dtype=np.int32)\n    num_compressed_rows = 0\n    unpruned_ids = []\n    for i in range(num_rows):\n        if np.random.uniform() < sparsity:\n            mapping_table[i] = -1\n            quantized_data[i, :] = 0\n        else:\n            mapping_table[i] = num_compressed_rows\n            num_compressed_rows += 1\n            unpruned_ids.append(i)\n    pruned_quantized_data = quantized_data[unpruned_ids]\n    inputs = ['quantized_data'] + (['weights'] if weighted else []) + ['indices', 'lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_reference')\n    net.Proto().op.extend([op])\n    inputs[0] = 'pruned_quantized_data'\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'Sum' + str(bit_rate) + 'BitRowwiseSparse', inputs + ['mapping_table'], 'sum_pruned')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('SparseLengthsSumSparseLookup', ['indices', 'lengths', 'mapping_table'] + (['weights'] if weighted else []), ['new_indices', 'new_lengths'] + (['new_weights'] if weighted else []))\n    net.Proto().op.extend([op])\n    inputs = ['pruned_quantized_data'] + (['new_weights'] if weighted else []) + ['new_indices', 'new_lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_split')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.FeedBlob('pruned_quantized_data', pruned_quantized_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_pruned = workspace.FetchBlob('sum_pruned')\n    sum_split = workspace.FetchBlob('sum_split')\n    np.testing.assert_array_equal(sum_reference, sum_pruned)\n    np.testing.assert_array_equal(sum_reference, sum_split)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), empty_indices=st.booleans(), bit_rate=st.sampled_from([2, 4, 8]), indices_64bit=st.booleans())\ndef test_sparse_lengths_sum_rowwise_sparse(self, num_rows, blocksize, weighted, empty_indices, bit_rate, indices_64bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    net = core.Net('bench')\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    index_type = np.int64 if indices_64bit else np.int32\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=index_type)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    sparsity = 0.7\n    mapping_table = np.zeros(num_rows, dtype=np.int32)\n    num_compressed_rows = 0\n    unpruned_ids = []\n    for i in range(num_rows):\n        if np.random.uniform() < sparsity:\n            mapping_table[i] = -1\n            quantized_data[i, :] = 0\n        else:\n            mapping_table[i] = num_compressed_rows\n            num_compressed_rows += 1\n            unpruned_ids.append(i)\n    pruned_quantized_data = quantized_data[unpruned_ids]\n    inputs = ['quantized_data'] + (['weights'] if weighted else []) + ['indices', 'lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_reference')\n    net.Proto().op.extend([op])\n    inputs[0] = 'pruned_quantized_data'\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'Sum' + str(bit_rate) + 'BitRowwiseSparse', inputs + ['mapping_table'], 'sum_pruned')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('SparseLengthsSumSparseLookup', ['indices', 'lengths', 'mapping_table'] + (['weights'] if weighted else []), ['new_indices', 'new_lengths'] + (['new_weights'] if weighted else []))\n    net.Proto().op.extend([op])\n    inputs = ['pruned_quantized_data'] + (['new_weights'] if weighted else []) + ['new_indices', 'new_lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_split')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.FeedBlob('pruned_quantized_data', pruned_quantized_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_pruned = workspace.FetchBlob('sum_pruned')\n    sum_split = workspace.FetchBlob('sum_split')\n    np.testing.assert_array_equal(sum_reference, sum_pruned)\n    np.testing.assert_array_equal(sum_reference, sum_split)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), empty_indices=st.booleans(), bit_rate=st.sampled_from([2, 4, 8]), indices_64bit=st.booleans())\ndef test_sparse_lengths_sum_rowwise_sparse(self, num_rows, blocksize, weighted, empty_indices, bit_rate, indices_64bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    net = core.Net('bench')\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    index_type = np.int64 if indices_64bit else np.int32\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=index_type)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    sparsity = 0.7\n    mapping_table = np.zeros(num_rows, dtype=np.int32)\n    num_compressed_rows = 0\n    unpruned_ids = []\n    for i in range(num_rows):\n        if np.random.uniform() < sparsity:\n            mapping_table[i] = -1\n            quantized_data[i, :] = 0\n        else:\n            mapping_table[i] = num_compressed_rows\n            num_compressed_rows += 1\n            unpruned_ids.append(i)\n    pruned_quantized_data = quantized_data[unpruned_ids]\n    inputs = ['quantized_data'] + (['weights'] if weighted else []) + ['indices', 'lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_reference')\n    net.Proto().op.extend([op])\n    inputs[0] = 'pruned_quantized_data'\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'Sum' + str(bit_rate) + 'BitRowwiseSparse', inputs + ['mapping_table'], 'sum_pruned')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('SparseLengthsSumSparseLookup', ['indices', 'lengths', 'mapping_table'] + (['weights'] if weighted else []), ['new_indices', 'new_lengths'] + (['new_weights'] if weighted else []))\n    net.Proto().op.extend([op])\n    inputs = ['pruned_quantized_data'] + (['new_weights'] if weighted else []) + ['new_indices', 'new_lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_split')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.FeedBlob('pruned_quantized_data', pruned_quantized_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_pruned = workspace.FetchBlob('sum_pruned')\n    sum_split = workspace.FetchBlob('sum_split')\n    np.testing.assert_array_equal(sum_reference, sum_pruned)\n    np.testing.assert_array_equal(sum_reference, sum_split)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), weighted=st.booleans(), empty_indices=st.booleans(), bit_rate=st.sampled_from([2, 4, 8]), indices_64bit=st.booleans())\ndef test_sparse_lengths_sum_rowwise_sparse(self, num_rows, blocksize, weighted, empty_indices, bit_rate, indices_64bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    net = core.Net('bench')\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    index_type = np.int64 if indices_64bit else np.int32\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=index_type)\n    weights = np.random.uniform(size=[len(indices)]).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    sparsity = 0.7\n    mapping_table = np.zeros(num_rows, dtype=np.int32)\n    num_compressed_rows = 0\n    unpruned_ids = []\n    for i in range(num_rows):\n        if np.random.uniform() < sparsity:\n            mapping_table[i] = -1\n            quantized_data[i, :] = 0\n        else:\n            mapping_table[i] = num_compressed_rows\n            num_compressed_rows += 1\n            unpruned_ids.append(i)\n    pruned_quantized_data = quantized_data[unpruned_ids]\n    inputs = ['quantized_data'] + (['weights'] if weighted else []) + ['indices', 'lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_reference')\n    net.Proto().op.extend([op])\n    inputs[0] = 'pruned_quantized_data'\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'Sum' + str(bit_rate) + 'BitRowwiseSparse', inputs + ['mapping_table'], 'sum_pruned')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('SparseLengthsSumSparseLookup', ['indices', 'lengths', 'mapping_table'] + (['weights'] if weighted else []), ['new_indices', 'new_lengths'] + (['new_weights'] if weighted else []))\n    net.Proto().op.extend([op])\n    inputs = ['pruned_quantized_data'] + (['new_weights'] if weighted else []) + ['new_indices', 'new_lengths']\n    op = core.CreateOperator('SparseLengths' + ('Weighted' if weighted else '') + 'SumFused' + str(bit_rate) + 'BitRowwise', inputs, 'sum_split')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.FeedBlob('pruned_quantized_data', pruned_quantized_data)\n    workspace.FeedBlob('weights', weights)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.RunNetOnce(net)\n    sum_reference = workspace.FetchBlob('sum_reference')\n    sum_pruned = workspace.FetchBlob('sum_pruned')\n    sum_split = workspace.FetchBlob('sum_split')\n    np.testing.assert_array_equal(sum_reference, sum_pruned)\n    np.testing.assert_array_equal(sum_reference, sum_split)"
        ]
    },
    {
        "func_name": "test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning",
        "original": "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op1 = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    op2 = core.CreateOperator('SparseLengthsMean' + str(bit_rate) + 'BitRowwiseSparse', ['quantized_data', 'indices', 'lengths'] + ['mapping_table'], 'mean_quantized_pruned')\n    net.Proto().op.extend([op1, op2])\n    net.Proto().external_input.extend(['input_data', 'mapping_table'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    mapping_table = np.array([0]).astype(dtype=np.int32)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    mean_quantized_pruned = workspace.FetchBlob('mean_quantized_pruned')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)\n    np.testing.assert_array_equal(mean_quantized_pruned, mean_quantized)",
        "mutated": [
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op1 = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    op2 = core.CreateOperator('SparseLengthsMean' + str(bit_rate) + 'BitRowwiseSparse', ['quantized_data', 'indices', 'lengths'] + ['mapping_table'], 'mean_quantized_pruned')\n    net.Proto().op.extend([op1, op2])\n    net.Proto().external_input.extend(['input_data', 'mapping_table'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    mapping_table = np.array([0]).astype(dtype=np.int32)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    mean_quantized_pruned = workspace.FetchBlob('mean_quantized_pruned')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)\n    np.testing.assert_array_equal(mean_quantized_pruned, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op1 = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    op2 = core.CreateOperator('SparseLengthsMean' + str(bit_rate) + 'BitRowwiseSparse', ['quantized_data', 'indices', 'lengths'] + ['mapping_table'], 'mean_quantized_pruned')\n    net.Proto().op.extend([op1, op2])\n    net.Proto().external_input.extend(['input_data', 'mapping_table'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    mapping_table = np.array([0]).astype(dtype=np.int32)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    mean_quantized_pruned = workspace.FetchBlob('mean_quantized_pruned')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)\n    np.testing.assert_array_equal(mean_quantized_pruned, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op1 = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    op2 = core.CreateOperator('SparseLengthsMean' + str(bit_rate) + 'BitRowwiseSparse', ['quantized_data', 'indices', 'lengths'] + ['mapping_table'], 'mean_quantized_pruned')\n    net.Proto().op.extend([op1, op2])\n    net.Proto().external_input.extend(['input_data', 'mapping_table'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    mapping_table = np.array([0]).astype(dtype=np.int32)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    mean_quantized_pruned = workspace.FetchBlob('mean_quantized_pruned')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)\n    np.testing.assert_array_equal(mean_quantized_pruned, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op1 = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    op2 = core.CreateOperator('SparseLengthsMean' + str(bit_rate) + 'BitRowwiseSparse', ['quantized_data', 'indices', 'lengths'] + ['mapping_table'], 'mean_quantized_pruned')\n    net.Proto().op.extend([op1, op2])\n    net.Proto().external_input.extend(['input_data', 'mapping_table'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    mapping_table = np.array([0]).astype(dtype=np.int32)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    mean_quantized_pruned = workspace.FetchBlob('mean_quantized_pruned')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)\n    np.testing.assert_array_equal(mean_quantized_pruned, mean_quantized)",
            "@given(num_rows=st.integers(1, 20), blocksize=st.sampled_from([8, 12, 16, 32, 64, 96, 128]), seed=st.integers(0, 2 ** 32 - 1), empty_indices=st.booleans(), engine=st.sampled_from(['', 'GREEDY']), bit_rate=st.sampled_from([2, 4]))\ndef test_sparse_lengths_mean_rowwise_sparse_with_skipped_pruning(self, num_rows, blocksize, seed, empty_indices, engine, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    net = core.Net('bench')\n    np.random.seed(seed)\n    input_data = np.random.rand(num_rows, blocksize).astype(np.float32)\n    if empty_indices:\n        lengths = np.zeros(num_rows, dtype=np.int32)\n        num_indices = 0\n    else:\n        num_indices = np.random.randint(len(input_data))\n        lengths_split = np.clip(num_indices // 2, 1, 10)\n        lengths = np.ones([num_indices // lengths_split], dtype=np.int32) * lengths_split\n        num_indices = num_indices // lengths_split * lengths_split\n    indices = np.random.randint(low=0, high=len(input_data), size=[num_indices], dtype=np.int32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'quantized_data', 'dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'fake_quantized_data', engine=engine)\n    net.Proto().op.extend([op])\n    net.SparseLengthsMean(['dequantized_data', 'indices', 'lengths'], 'mean_reference')\n    net.SparseLengthsMeanFused8BitRowwise(['fake_quantized_data', 'indices', 'lengths'], 'mean_fake_quantized')\n    op1 = core.CreateOperator('SparseLengthsMeanFused' + str(bit_rate) + 'BitRowwise', ['quantized_data', 'indices', 'lengths'], 'mean_quantized')\n    op2 = core.CreateOperator('SparseLengthsMean' + str(bit_rate) + 'BitRowwiseSparse', ['quantized_data', 'indices', 'lengths'] + ['mapping_table'], 'mean_quantized_pruned')\n    net.Proto().op.extend([op1, op2])\n    net.Proto().external_input.extend(['input_data', 'mapping_table'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.FeedBlob('indices', indices)\n    workspace.FeedBlob('lengths', lengths)\n    mapping_table = np.array([0]).astype(dtype=np.int32)\n    workspace.FeedBlob('mapping_table', mapping_table)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    mean_reference = workspace.FetchBlob('mean_reference')\n    mean_fake_quantized = workspace.FetchBlob('mean_fake_quantized')\n    mean_quantized = workspace.FetchBlob('mean_quantized')\n    mean_quantized_pruned = workspace.FetchBlob('mean_quantized_pruned')\n    np.testing.assert_array_almost_equal(mean_reference, mean_quantized)\n    np.testing.assert_array_equal(mean_fake_quantized, mean_quantized)\n    np.testing.assert_array_equal(mean_quantized_pruned, mean_quantized)"
        ]
    }
]