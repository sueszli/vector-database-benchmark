[
    {
        "func_name": "create_indoor_info_file",
        "original": "def create_indoor_info_file(data_path, pkl_prefix='sunrgbd', save_path=None, workers=4, **kwargs):\n    \"\"\"Create indoor information file.\n\n    Get information of the raw data and save it to the pkl file.\n\n    Args:\n        data_path (str): Path of the data.\n        pkl_prefix (str, optional): Prefix of the pkl to be saved.\n            Default: 'sunrgbd'.\n        save_path (str, optional): Path of the pkl to be saved. Default: None.\n        workers (int, optional): Number of threads to be used. Default: 4.\n        kwargs (dict): Additional parameters for dataset-specific Data class.\n            May include `use_v1` for SUN RGB-D and `num_points`.\n    \"\"\"\n    assert os.path.exists(data_path)\n    assert pkl_prefix in ['sunrgbd', 'scannet', 's3dis'], f'unsupported indoor dataset {pkl_prefix}'\n    save_path = data_path if save_path is None else save_path\n    assert os.path.exists(save_path)\n    if pkl_prefix in ['sunrgbd', 'scannet']:\n        train_filename = os.path.join(save_path, f'{pkl_prefix}_infos_train.pkl')\n        val_filename = os.path.join(save_path, f'{pkl_prefix}_infos_val.pkl')\n        if pkl_prefix == 'sunrgbd':\n            num_points = kwargs.get('num_points', -1)\n            use_v1 = kwargs.get('use_v1', False)\n            train_dataset = SUNRGBDData(root_path=data_path, split='train', use_v1=use_v1, num_points=num_points)\n            val_dataset = SUNRGBDData(root_path=data_path, split='val', use_v1=use_v1, num_points=num_points)\n        else:\n            train_dataset = ScanNetData(root_path=data_path, split='train')\n            val_dataset = ScanNetData(root_path=data_path, split='val')\n            test_dataset = ScanNetData(root_path=data_path, split='test')\n            test_filename = os.path.join(save_path, f'{pkl_prefix}_infos_test.pkl')\n        infos_train = train_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_train, train_filename, 'pkl')\n        print(f'{pkl_prefix} info train file is saved to {train_filename}')\n        infos_val = val_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_val, val_filename, 'pkl')\n        print(f'{pkl_prefix} info val file is saved to {val_filename}')\n    if pkl_prefix == 'scannet':\n        infos_test = test_dataset.get_infos(num_workers=workers, has_label=False)\n        mmcv.dump(infos_test, test_filename, 'pkl')\n        print(f'{pkl_prefix} info test file is saved to {test_filename}')\n    if pkl_prefix == 'scannet':\n        num_points = kwargs.get('num_points', 8192)\n        train_dataset = ScanNetSegData(data_root=data_path, ann_file=train_filename, split='train', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        val_dataset = ScanNetSegData(data_root=data_path, ann_file=val_filename, split='val', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        train_dataset.get_seg_infos()\n        val_dataset.get_seg_infos()\n    elif pkl_prefix == 's3dis':\n        splits = [f'Area_{i}' for i in [1, 2, 3, 4, 5, 6]]\n        for split in splits:\n            dataset = S3DISData(root_path=data_path, split=split)\n            info = dataset.get_infos(num_workers=workers, has_label=True)\n            filename = os.path.join(save_path, f'{pkl_prefix}_infos_{split}.pkl')\n            mmcv.dump(info, filename, 'pkl')\n            print(f'{pkl_prefix} info {split} file is saved to {filename}')\n            num_points = kwargs.get('num_points', 4096)\n            seg_dataset = S3DISSegData(data_root=data_path, ann_file=filename, split=split, num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n            seg_dataset.get_seg_infos()",
        "mutated": [
            "def create_indoor_info_file(data_path, pkl_prefix='sunrgbd', save_path=None, workers=4, **kwargs):\n    if False:\n        i = 10\n    \"Create indoor information file.\\n\\n    Get information of the raw data and save it to the pkl file.\\n\\n    Args:\\n        data_path (str): Path of the data.\\n        pkl_prefix (str, optional): Prefix of the pkl to be saved.\\n            Default: 'sunrgbd'.\\n        save_path (str, optional): Path of the pkl to be saved. Default: None.\\n        workers (int, optional): Number of threads to be used. Default: 4.\\n        kwargs (dict): Additional parameters for dataset-specific Data class.\\n            May include `use_v1` for SUN RGB-D and `num_points`.\\n    \"\n    assert os.path.exists(data_path)\n    assert pkl_prefix in ['sunrgbd', 'scannet', 's3dis'], f'unsupported indoor dataset {pkl_prefix}'\n    save_path = data_path if save_path is None else save_path\n    assert os.path.exists(save_path)\n    if pkl_prefix in ['sunrgbd', 'scannet']:\n        train_filename = os.path.join(save_path, f'{pkl_prefix}_infos_train.pkl')\n        val_filename = os.path.join(save_path, f'{pkl_prefix}_infos_val.pkl')\n        if pkl_prefix == 'sunrgbd':\n            num_points = kwargs.get('num_points', -1)\n            use_v1 = kwargs.get('use_v1', False)\n            train_dataset = SUNRGBDData(root_path=data_path, split='train', use_v1=use_v1, num_points=num_points)\n            val_dataset = SUNRGBDData(root_path=data_path, split='val', use_v1=use_v1, num_points=num_points)\n        else:\n            train_dataset = ScanNetData(root_path=data_path, split='train')\n            val_dataset = ScanNetData(root_path=data_path, split='val')\n            test_dataset = ScanNetData(root_path=data_path, split='test')\n            test_filename = os.path.join(save_path, f'{pkl_prefix}_infos_test.pkl')\n        infos_train = train_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_train, train_filename, 'pkl')\n        print(f'{pkl_prefix} info train file is saved to {train_filename}')\n        infos_val = val_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_val, val_filename, 'pkl')\n        print(f'{pkl_prefix} info val file is saved to {val_filename}')\n    if pkl_prefix == 'scannet':\n        infos_test = test_dataset.get_infos(num_workers=workers, has_label=False)\n        mmcv.dump(infos_test, test_filename, 'pkl')\n        print(f'{pkl_prefix} info test file is saved to {test_filename}')\n    if pkl_prefix == 'scannet':\n        num_points = kwargs.get('num_points', 8192)\n        train_dataset = ScanNetSegData(data_root=data_path, ann_file=train_filename, split='train', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        val_dataset = ScanNetSegData(data_root=data_path, ann_file=val_filename, split='val', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        train_dataset.get_seg_infos()\n        val_dataset.get_seg_infos()\n    elif pkl_prefix == 's3dis':\n        splits = [f'Area_{i}' for i in [1, 2, 3, 4, 5, 6]]\n        for split in splits:\n            dataset = S3DISData(root_path=data_path, split=split)\n            info = dataset.get_infos(num_workers=workers, has_label=True)\n            filename = os.path.join(save_path, f'{pkl_prefix}_infos_{split}.pkl')\n            mmcv.dump(info, filename, 'pkl')\n            print(f'{pkl_prefix} info {split} file is saved to {filename}')\n            num_points = kwargs.get('num_points', 4096)\n            seg_dataset = S3DISSegData(data_root=data_path, ann_file=filename, split=split, num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n            seg_dataset.get_seg_infos()",
            "def create_indoor_info_file(data_path, pkl_prefix='sunrgbd', save_path=None, workers=4, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Create indoor information file.\\n\\n    Get information of the raw data and save it to the pkl file.\\n\\n    Args:\\n        data_path (str): Path of the data.\\n        pkl_prefix (str, optional): Prefix of the pkl to be saved.\\n            Default: 'sunrgbd'.\\n        save_path (str, optional): Path of the pkl to be saved. Default: None.\\n        workers (int, optional): Number of threads to be used. Default: 4.\\n        kwargs (dict): Additional parameters for dataset-specific Data class.\\n            May include `use_v1` for SUN RGB-D and `num_points`.\\n    \"\n    assert os.path.exists(data_path)\n    assert pkl_prefix in ['sunrgbd', 'scannet', 's3dis'], f'unsupported indoor dataset {pkl_prefix}'\n    save_path = data_path if save_path is None else save_path\n    assert os.path.exists(save_path)\n    if pkl_prefix in ['sunrgbd', 'scannet']:\n        train_filename = os.path.join(save_path, f'{pkl_prefix}_infos_train.pkl')\n        val_filename = os.path.join(save_path, f'{pkl_prefix}_infos_val.pkl')\n        if pkl_prefix == 'sunrgbd':\n            num_points = kwargs.get('num_points', -1)\n            use_v1 = kwargs.get('use_v1', False)\n            train_dataset = SUNRGBDData(root_path=data_path, split='train', use_v1=use_v1, num_points=num_points)\n            val_dataset = SUNRGBDData(root_path=data_path, split='val', use_v1=use_v1, num_points=num_points)\n        else:\n            train_dataset = ScanNetData(root_path=data_path, split='train')\n            val_dataset = ScanNetData(root_path=data_path, split='val')\n            test_dataset = ScanNetData(root_path=data_path, split='test')\n            test_filename = os.path.join(save_path, f'{pkl_prefix}_infos_test.pkl')\n        infos_train = train_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_train, train_filename, 'pkl')\n        print(f'{pkl_prefix} info train file is saved to {train_filename}')\n        infos_val = val_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_val, val_filename, 'pkl')\n        print(f'{pkl_prefix} info val file is saved to {val_filename}')\n    if pkl_prefix == 'scannet':\n        infos_test = test_dataset.get_infos(num_workers=workers, has_label=False)\n        mmcv.dump(infos_test, test_filename, 'pkl')\n        print(f'{pkl_prefix} info test file is saved to {test_filename}')\n    if pkl_prefix == 'scannet':\n        num_points = kwargs.get('num_points', 8192)\n        train_dataset = ScanNetSegData(data_root=data_path, ann_file=train_filename, split='train', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        val_dataset = ScanNetSegData(data_root=data_path, ann_file=val_filename, split='val', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        train_dataset.get_seg_infos()\n        val_dataset.get_seg_infos()\n    elif pkl_prefix == 's3dis':\n        splits = [f'Area_{i}' for i in [1, 2, 3, 4, 5, 6]]\n        for split in splits:\n            dataset = S3DISData(root_path=data_path, split=split)\n            info = dataset.get_infos(num_workers=workers, has_label=True)\n            filename = os.path.join(save_path, f'{pkl_prefix}_infos_{split}.pkl')\n            mmcv.dump(info, filename, 'pkl')\n            print(f'{pkl_prefix} info {split} file is saved to {filename}')\n            num_points = kwargs.get('num_points', 4096)\n            seg_dataset = S3DISSegData(data_root=data_path, ann_file=filename, split=split, num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n            seg_dataset.get_seg_infos()",
            "def create_indoor_info_file(data_path, pkl_prefix='sunrgbd', save_path=None, workers=4, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Create indoor information file.\\n\\n    Get information of the raw data and save it to the pkl file.\\n\\n    Args:\\n        data_path (str): Path of the data.\\n        pkl_prefix (str, optional): Prefix of the pkl to be saved.\\n            Default: 'sunrgbd'.\\n        save_path (str, optional): Path of the pkl to be saved. Default: None.\\n        workers (int, optional): Number of threads to be used. Default: 4.\\n        kwargs (dict): Additional parameters for dataset-specific Data class.\\n            May include `use_v1` for SUN RGB-D and `num_points`.\\n    \"\n    assert os.path.exists(data_path)\n    assert pkl_prefix in ['sunrgbd', 'scannet', 's3dis'], f'unsupported indoor dataset {pkl_prefix}'\n    save_path = data_path if save_path is None else save_path\n    assert os.path.exists(save_path)\n    if pkl_prefix in ['sunrgbd', 'scannet']:\n        train_filename = os.path.join(save_path, f'{pkl_prefix}_infos_train.pkl')\n        val_filename = os.path.join(save_path, f'{pkl_prefix}_infos_val.pkl')\n        if pkl_prefix == 'sunrgbd':\n            num_points = kwargs.get('num_points', -1)\n            use_v1 = kwargs.get('use_v1', False)\n            train_dataset = SUNRGBDData(root_path=data_path, split='train', use_v1=use_v1, num_points=num_points)\n            val_dataset = SUNRGBDData(root_path=data_path, split='val', use_v1=use_v1, num_points=num_points)\n        else:\n            train_dataset = ScanNetData(root_path=data_path, split='train')\n            val_dataset = ScanNetData(root_path=data_path, split='val')\n            test_dataset = ScanNetData(root_path=data_path, split='test')\n            test_filename = os.path.join(save_path, f'{pkl_prefix}_infos_test.pkl')\n        infos_train = train_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_train, train_filename, 'pkl')\n        print(f'{pkl_prefix} info train file is saved to {train_filename}')\n        infos_val = val_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_val, val_filename, 'pkl')\n        print(f'{pkl_prefix} info val file is saved to {val_filename}')\n    if pkl_prefix == 'scannet':\n        infos_test = test_dataset.get_infos(num_workers=workers, has_label=False)\n        mmcv.dump(infos_test, test_filename, 'pkl')\n        print(f'{pkl_prefix} info test file is saved to {test_filename}')\n    if pkl_prefix == 'scannet':\n        num_points = kwargs.get('num_points', 8192)\n        train_dataset = ScanNetSegData(data_root=data_path, ann_file=train_filename, split='train', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        val_dataset = ScanNetSegData(data_root=data_path, ann_file=val_filename, split='val', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        train_dataset.get_seg_infos()\n        val_dataset.get_seg_infos()\n    elif pkl_prefix == 's3dis':\n        splits = [f'Area_{i}' for i in [1, 2, 3, 4, 5, 6]]\n        for split in splits:\n            dataset = S3DISData(root_path=data_path, split=split)\n            info = dataset.get_infos(num_workers=workers, has_label=True)\n            filename = os.path.join(save_path, f'{pkl_prefix}_infos_{split}.pkl')\n            mmcv.dump(info, filename, 'pkl')\n            print(f'{pkl_prefix} info {split} file is saved to {filename}')\n            num_points = kwargs.get('num_points', 4096)\n            seg_dataset = S3DISSegData(data_root=data_path, ann_file=filename, split=split, num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n            seg_dataset.get_seg_infos()",
            "def create_indoor_info_file(data_path, pkl_prefix='sunrgbd', save_path=None, workers=4, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Create indoor information file.\\n\\n    Get information of the raw data and save it to the pkl file.\\n\\n    Args:\\n        data_path (str): Path of the data.\\n        pkl_prefix (str, optional): Prefix of the pkl to be saved.\\n            Default: 'sunrgbd'.\\n        save_path (str, optional): Path of the pkl to be saved. Default: None.\\n        workers (int, optional): Number of threads to be used. Default: 4.\\n        kwargs (dict): Additional parameters for dataset-specific Data class.\\n            May include `use_v1` for SUN RGB-D and `num_points`.\\n    \"\n    assert os.path.exists(data_path)\n    assert pkl_prefix in ['sunrgbd', 'scannet', 's3dis'], f'unsupported indoor dataset {pkl_prefix}'\n    save_path = data_path if save_path is None else save_path\n    assert os.path.exists(save_path)\n    if pkl_prefix in ['sunrgbd', 'scannet']:\n        train_filename = os.path.join(save_path, f'{pkl_prefix}_infos_train.pkl')\n        val_filename = os.path.join(save_path, f'{pkl_prefix}_infos_val.pkl')\n        if pkl_prefix == 'sunrgbd':\n            num_points = kwargs.get('num_points', -1)\n            use_v1 = kwargs.get('use_v1', False)\n            train_dataset = SUNRGBDData(root_path=data_path, split='train', use_v1=use_v1, num_points=num_points)\n            val_dataset = SUNRGBDData(root_path=data_path, split='val', use_v1=use_v1, num_points=num_points)\n        else:\n            train_dataset = ScanNetData(root_path=data_path, split='train')\n            val_dataset = ScanNetData(root_path=data_path, split='val')\n            test_dataset = ScanNetData(root_path=data_path, split='test')\n            test_filename = os.path.join(save_path, f'{pkl_prefix}_infos_test.pkl')\n        infos_train = train_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_train, train_filename, 'pkl')\n        print(f'{pkl_prefix} info train file is saved to {train_filename}')\n        infos_val = val_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_val, val_filename, 'pkl')\n        print(f'{pkl_prefix} info val file is saved to {val_filename}')\n    if pkl_prefix == 'scannet':\n        infos_test = test_dataset.get_infos(num_workers=workers, has_label=False)\n        mmcv.dump(infos_test, test_filename, 'pkl')\n        print(f'{pkl_prefix} info test file is saved to {test_filename}')\n    if pkl_prefix == 'scannet':\n        num_points = kwargs.get('num_points', 8192)\n        train_dataset = ScanNetSegData(data_root=data_path, ann_file=train_filename, split='train', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        val_dataset = ScanNetSegData(data_root=data_path, ann_file=val_filename, split='val', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        train_dataset.get_seg_infos()\n        val_dataset.get_seg_infos()\n    elif pkl_prefix == 's3dis':\n        splits = [f'Area_{i}' for i in [1, 2, 3, 4, 5, 6]]\n        for split in splits:\n            dataset = S3DISData(root_path=data_path, split=split)\n            info = dataset.get_infos(num_workers=workers, has_label=True)\n            filename = os.path.join(save_path, f'{pkl_prefix}_infos_{split}.pkl')\n            mmcv.dump(info, filename, 'pkl')\n            print(f'{pkl_prefix} info {split} file is saved to {filename}')\n            num_points = kwargs.get('num_points', 4096)\n            seg_dataset = S3DISSegData(data_root=data_path, ann_file=filename, split=split, num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n            seg_dataset.get_seg_infos()",
            "def create_indoor_info_file(data_path, pkl_prefix='sunrgbd', save_path=None, workers=4, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Create indoor information file.\\n\\n    Get information of the raw data and save it to the pkl file.\\n\\n    Args:\\n        data_path (str): Path of the data.\\n        pkl_prefix (str, optional): Prefix of the pkl to be saved.\\n            Default: 'sunrgbd'.\\n        save_path (str, optional): Path of the pkl to be saved. Default: None.\\n        workers (int, optional): Number of threads to be used. Default: 4.\\n        kwargs (dict): Additional parameters for dataset-specific Data class.\\n            May include `use_v1` for SUN RGB-D and `num_points`.\\n    \"\n    assert os.path.exists(data_path)\n    assert pkl_prefix in ['sunrgbd', 'scannet', 's3dis'], f'unsupported indoor dataset {pkl_prefix}'\n    save_path = data_path if save_path is None else save_path\n    assert os.path.exists(save_path)\n    if pkl_prefix in ['sunrgbd', 'scannet']:\n        train_filename = os.path.join(save_path, f'{pkl_prefix}_infos_train.pkl')\n        val_filename = os.path.join(save_path, f'{pkl_prefix}_infos_val.pkl')\n        if pkl_prefix == 'sunrgbd':\n            num_points = kwargs.get('num_points', -1)\n            use_v1 = kwargs.get('use_v1', False)\n            train_dataset = SUNRGBDData(root_path=data_path, split='train', use_v1=use_v1, num_points=num_points)\n            val_dataset = SUNRGBDData(root_path=data_path, split='val', use_v1=use_v1, num_points=num_points)\n        else:\n            train_dataset = ScanNetData(root_path=data_path, split='train')\n            val_dataset = ScanNetData(root_path=data_path, split='val')\n            test_dataset = ScanNetData(root_path=data_path, split='test')\n            test_filename = os.path.join(save_path, f'{pkl_prefix}_infos_test.pkl')\n        infos_train = train_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_train, train_filename, 'pkl')\n        print(f'{pkl_prefix} info train file is saved to {train_filename}')\n        infos_val = val_dataset.get_infos(num_workers=workers, has_label=True)\n        mmcv.dump(infos_val, val_filename, 'pkl')\n        print(f'{pkl_prefix} info val file is saved to {val_filename}')\n    if pkl_prefix == 'scannet':\n        infos_test = test_dataset.get_infos(num_workers=workers, has_label=False)\n        mmcv.dump(infos_test, test_filename, 'pkl')\n        print(f'{pkl_prefix} info test file is saved to {test_filename}')\n    if pkl_prefix == 'scannet':\n        num_points = kwargs.get('num_points', 8192)\n        train_dataset = ScanNetSegData(data_root=data_path, ann_file=train_filename, split='train', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        val_dataset = ScanNetSegData(data_root=data_path, ann_file=val_filename, split='val', num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n        train_dataset.get_seg_infos()\n        val_dataset.get_seg_infos()\n    elif pkl_prefix == 's3dis':\n        splits = [f'Area_{i}' for i in [1, 2, 3, 4, 5, 6]]\n        for split in splits:\n            dataset = S3DISData(root_path=data_path, split=split)\n            info = dataset.get_infos(num_workers=workers, has_label=True)\n            filename = os.path.join(save_path, f'{pkl_prefix}_infos_{split}.pkl')\n            mmcv.dump(info, filename, 'pkl')\n            print(f'{pkl_prefix} info {split} file is saved to {filename}')\n            num_points = kwargs.get('num_points', 4096)\n            seg_dataset = S3DISSegData(data_root=data_path, ann_file=filename, split=split, num_points=num_points, label_weight_func=lambda x: 1.0 / np.log(1.2 + x))\n            seg_dataset.get_seg_infos()"
        ]
    }
]