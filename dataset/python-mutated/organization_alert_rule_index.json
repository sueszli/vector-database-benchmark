[
    {
        "func_name": "fetch_metric_alert",
        "original": "def fetch_metric_alert(self, request, organization, project=None):\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    if not project:\n        projects = self.get_projects(request, organization)\n        alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    else:\n        alert_rules = AlertRule.objects.fetch_for_project(project)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    return self.paginate(request, queryset=alert_rules, order_by='-date_added', paginator_cls=OffsetPaginator, on_results=lambda x: serialize(x, request.user), default_per_page=25)",
        "mutated": [
            "def fetch_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    if not project:\n        projects = self.get_projects(request, organization)\n        alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    else:\n        alert_rules = AlertRule.objects.fetch_for_project(project)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    return self.paginate(request, queryset=alert_rules, order_by='-date_added', paginator_cls=OffsetPaginator, on_results=lambda x: serialize(x, request.user), default_per_page=25)",
            "def fetch_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    if not project:\n        projects = self.get_projects(request, organization)\n        alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    else:\n        alert_rules = AlertRule.objects.fetch_for_project(project)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    return self.paginate(request, queryset=alert_rules, order_by='-date_added', paginator_cls=OffsetPaginator, on_results=lambda x: serialize(x, request.user), default_per_page=25)",
            "def fetch_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    if not project:\n        projects = self.get_projects(request, organization)\n        alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    else:\n        alert_rules = AlertRule.objects.fetch_for_project(project)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    return self.paginate(request, queryset=alert_rules, order_by='-date_added', paginator_cls=OffsetPaginator, on_results=lambda x: serialize(x, request.user), default_per_page=25)",
            "def fetch_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    if not project:\n        projects = self.get_projects(request, organization)\n        alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    else:\n        alert_rules = AlertRule.objects.fetch_for_project(project)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    return self.paginate(request, queryset=alert_rules, order_by='-date_added', paginator_cls=OffsetPaginator, on_results=lambda x: serialize(x, request.user), default_per_page=25)",
            "def fetch_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    if not project:\n        projects = self.get_projects(request, organization)\n        alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    else:\n        alert_rules = AlertRule.objects.fetch_for_project(project)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    return self.paginate(request, queryset=alert_rules, order_by='-date_added', paginator_cls=OffsetPaginator, on_results=lambda x: serialize(x, request.user), default_per_page=25)"
        ]
    },
    {
        "func_name": "create_metric_alert",
        "original": "def create_metric_alert(self, request, organization, project=None):\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    data = deepcopy(request.data)\n    if project:\n        data['projects'] = [project.slug]\n    serializer = DrfAlertRuleSerializer(context={'organization': organization, 'access': request.access, 'user': request.user, 'ip_address': request.META.get('REMOTE_ADDR'), 'installations': app_service.get_installed_for_organization(organization_id=organization.id)}, data=data)\n    if serializer.is_valid():\n        trigger_sentry_app_action_creators_for_incidents(serializer.validated_data)\n        if get_slack_actions_with_async_lookups(organization, request.user, request.data):\n            client = RedisRuleStatus()\n            task_args = {'organization_id': organization.id, 'uuid': client.uuid, 'data': request.data, 'user_id': request.user.id}\n            find_channel_id_for_alert_rule.apply_async(kwargs=task_args)\n            return Response({'uuid': client.uuid}, status=202)\n        else:\n            alert_rule = serializer.save()\n            referrer = request.query_params.get('referrer')\n            session_id = request.query_params.get('sessionId')\n            duplicate_rule = request.query_params.get('duplicateRule')\n            wizard_v3 = request.query_params.get('wizardV3')\n            subscriptions = alert_rule.snuba_query.subscriptions.all()\n            for sub in subscriptions:\n                alert_rule_created.send_robust(user=request.user, project=sub.project, rule=alert_rule, rule_type='metric', sender=self, referrer=referrer, session_id=session_id, is_api_token=request.auth is not None, duplicate_rule=duplicate_rule, wizard_v3=wizard_v3)\n            return Response(serialize(alert_rule, request.user), status=status.HTTP_201_CREATED)\n    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)",
        "mutated": [
            "def create_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    data = deepcopy(request.data)\n    if project:\n        data['projects'] = [project.slug]\n    serializer = DrfAlertRuleSerializer(context={'organization': organization, 'access': request.access, 'user': request.user, 'ip_address': request.META.get('REMOTE_ADDR'), 'installations': app_service.get_installed_for_organization(organization_id=organization.id)}, data=data)\n    if serializer.is_valid():\n        trigger_sentry_app_action_creators_for_incidents(serializer.validated_data)\n        if get_slack_actions_with_async_lookups(organization, request.user, request.data):\n            client = RedisRuleStatus()\n            task_args = {'organization_id': organization.id, 'uuid': client.uuid, 'data': request.data, 'user_id': request.user.id}\n            find_channel_id_for_alert_rule.apply_async(kwargs=task_args)\n            return Response({'uuid': client.uuid}, status=202)\n        else:\n            alert_rule = serializer.save()\n            referrer = request.query_params.get('referrer')\n            session_id = request.query_params.get('sessionId')\n            duplicate_rule = request.query_params.get('duplicateRule')\n            wizard_v3 = request.query_params.get('wizardV3')\n            subscriptions = alert_rule.snuba_query.subscriptions.all()\n            for sub in subscriptions:\n                alert_rule_created.send_robust(user=request.user, project=sub.project, rule=alert_rule, rule_type='metric', sender=self, referrer=referrer, session_id=session_id, is_api_token=request.auth is not None, duplicate_rule=duplicate_rule, wizard_v3=wizard_v3)\n            return Response(serialize(alert_rule, request.user), status=status.HTTP_201_CREATED)\n    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)",
            "def create_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    data = deepcopy(request.data)\n    if project:\n        data['projects'] = [project.slug]\n    serializer = DrfAlertRuleSerializer(context={'organization': organization, 'access': request.access, 'user': request.user, 'ip_address': request.META.get('REMOTE_ADDR'), 'installations': app_service.get_installed_for_organization(organization_id=organization.id)}, data=data)\n    if serializer.is_valid():\n        trigger_sentry_app_action_creators_for_incidents(serializer.validated_data)\n        if get_slack_actions_with_async_lookups(organization, request.user, request.data):\n            client = RedisRuleStatus()\n            task_args = {'organization_id': organization.id, 'uuid': client.uuid, 'data': request.data, 'user_id': request.user.id}\n            find_channel_id_for_alert_rule.apply_async(kwargs=task_args)\n            return Response({'uuid': client.uuid}, status=202)\n        else:\n            alert_rule = serializer.save()\n            referrer = request.query_params.get('referrer')\n            session_id = request.query_params.get('sessionId')\n            duplicate_rule = request.query_params.get('duplicateRule')\n            wizard_v3 = request.query_params.get('wizardV3')\n            subscriptions = alert_rule.snuba_query.subscriptions.all()\n            for sub in subscriptions:\n                alert_rule_created.send_robust(user=request.user, project=sub.project, rule=alert_rule, rule_type='metric', sender=self, referrer=referrer, session_id=session_id, is_api_token=request.auth is not None, duplicate_rule=duplicate_rule, wizard_v3=wizard_v3)\n            return Response(serialize(alert_rule, request.user), status=status.HTTP_201_CREATED)\n    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)",
            "def create_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    data = deepcopy(request.data)\n    if project:\n        data['projects'] = [project.slug]\n    serializer = DrfAlertRuleSerializer(context={'organization': organization, 'access': request.access, 'user': request.user, 'ip_address': request.META.get('REMOTE_ADDR'), 'installations': app_service.get_installed_for_organization(organization_id=organization.id)}, data=data)\n    if serializer.is_valid():\n        trigger_sentry_app_action_creators_for_incidents(serializer.validated_data)\n        if get_slack_actions_with_async_lookups(organization, request.user, request.data):\n            client = RedisRuleStatus()\n            task_args = {'organization_id': organization.id, 'uuid': client.uuid, 'data': request.data, 'user_id': request.user.id}\n            find_channel_id_for_alert_rule.apply_async(kwargs=task_args)\n            return Response({'uuid': client.uuid}, status=202)\n        else:\n            alert_rule = serializer.save()\n            referrer = request.query_params.get('referrer')\n            session_id = request.query_params.get('sessionId')\n            duplicate_rule = request.query_params.get('duplicateRule')\n            wizard_v3 = request.query_params.get('wizardV3')\n            subscriptions = alert_rule.snuba_query.subscriptions.all()\n            for sub in subscriptions:\n                alert_rule_created.send_robust(user=request.user, project=sub.project, rule=alert_rule, rule_type='metric', sender=self, referrer=referrer, session_id=session_id, is_api_token=request.auth is not None, duplicate_rule=duplicate_rule, wizard_v3=wizard_v3)\n            return Response(serialize(alert_rule, request.user), status=status.HTTP_201_CREATED)\n    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)",
            "def create_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    data = deepcopy(request.data)\n    if project:\n        data['projects'] = [project.slug]\n    serializer = DrfAlertRuleSerializer(context={'organization': organization, 'access': request.access, 'user': request.user, 'ip_address': request.META.get('REMOTE_ADDR'), 'installations': app_service.get_installed_for_organization(organization_id=organization.id)}, data=data)\n    if serializer.is_valid():\n        trigger_sentry_app_action_creators_for_incidents(serializer.validated_data)\n        if get_slack_actions_with_async_lookups(organization, request.user, request.data):\n            client = RedisRuleStatus()\n            task_args = {'organization_id': organization.id, 'uuid': client.uuid, 'data': request.data, 'user_id': request.user.id}\n            find_channel_id_for_alert_rule.apply_async(kwargs=task_args)\n            return Response({'uuid': client.uuid}, status=202)\n        else:\n            alert_rule = serializer.save()\n            referrer = request.query_params.get('referrer')\n            session_id = request.query_params.get('sessionId')\n            duplicate_rule = request.query_params.get('duplicateRule')\n            wizard_v3 = request.query_params.get('wizardV3')\n            subscriptions = alert_rule.snuba_query.subscriptions.all()\n            for sub in subscriptions:\n                alert_rule_created.send_robust(user=request.user, project=sub.project, rule=alert_rule, rule_type='metric', sender=self, referrer=referrer, session_id=session_id, is_api_token=request.auth is not None, duplicate_rule=duplicate_rule, wizard_v3=wizard_v3)\n            return Response(serialize(alert_rule, request.user), status=status.HTTP_201_CREATED)\n    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)",
            "def create_metric_alert(self, request, organization, project=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not features.has('organizations:incidents', organization, actor=request.user):\n        raise ResourceDoesNotExist\n    data = deepcopy(request.data)\n    if project:\n        data['projects'] = [project.slug]\n    serializer = DrfAlertRuleSerializer(context={'organization': organization, 'access': request.access, 'user': request.user, 'ip_address': request.META.get('REMOTE_ADDR'), 'installations': app_service.get_installed_for_organization(organization_id=organization.id)}, data=data)\n    if serializer.is_valid():\n        trigger_sentry_app_action_creators_for_incidents(serializer.validated_data)\n        if get_slack_actions_with_async_lookups(organization, request.user, request.data):\n            client = RedisRuleStatus()\n            task_args = {'organization_id': organization.id, 'uuid': client.uuid, 'data': request.data, 'user_id': request.user.id}\n            find_channel_id_for_alert_rule.apply_async(kwargs=task_args)\n            return Response({'uuid': client.uuid}, status=202)\n        else:\n            alert_rule = serializer.save()\n            referrer = request.query_params.get('referrer')\n            session_id = request.query_params.get('sessionId')\n            duplicate_rule = request.query_params.get('duplicateRule')\n            wizard_v3 = request.query_params.get('wizardV3')\n            subscriptions = alert_rule.snuba_query.subscriptions.all()\n            for sub in subscriptions:\n                alert_rule_created.send_robust(user=request.user, project=sub.project, rule=alert_rule, rule_type='metric', sender=self, referrer=referrer, session_id=session_id, is_api_token=request.auth is not None, duplicate_rule=duplicate_rule, wizard_v3=wizard_v3)\n            return Response(serialize(alert_rule, request.user), status=status.HTTP_201_CREATED)\n    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)"
        ]
    },
    {
        "func_name": "get",
        "original": "def get(self, request: Request, organization) -> Response:\n    \"\"\"\n        Fetches (metric) alert rules and legacy (issue alert) rules for an organization\n        \"\"\"\n    project_ids = self.get_requested_project_ids_unchecked(request) or None\n    if project_ids == {-1}:\n        project_ids = Project.objects.filter(organization=organization, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    elif project_ids is None:\n        org_team_list = Team.objects.filter(organization=organization).values_list('id', flat=True)\n        user_team_list = OrganizationMemberTeam.objects.filter(organizationmember__user_id=request.user.id, team__in=org_team_list).values_list('team', flat=True)\n        project_ids = Project.objects.filter(teams__in=user_team_list, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    projects = self.get_projects(request, organization, project_ids=set(project_ids))\n    teams = request.GET.getlist('team', [])\n    team_filter_query = None\n    if len(teams) > 0:\n        try:\n            (teams_query, unassigned) = parse_team_params(request, organization, teams)\n        except InvalidParams as err:\n            return Response(str(err), status=status.HTTP_400_BAD_REQUEST)\n        team_filter_query = Q(owner_id__in=teams_query.values_list('actor_id', flat=True))\n        if unassigned:\n            team_filter_query = team_filter_query | Q(owner_id=None)\n    alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    issue_rules = Rule.objects.filter(status__in=[ObjectStatus.ACTIVE, ObjectStatus.DISABLED], source__in=[RuleSource.ISSUE], project__in=projects)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    else:\n        datasets = request.GET.getlist('dataset', [])\n        if len(datasets) > 0:\n            alert_rules = alert_rules.filter(snuba_query__dataset__in=datasets)\n            if Dataset.Events.value not in datasets:\n                issue_rules = Rule.objects.none()\n    name = request.GET.get('name', None)\n    if name:\n        alert_rules = alert_rules.filter(Q(name__icontains=name))\n        issue_rules = issue_rules.filter(Q(label__icontains=name))\n    if team_filter_query:\n        alert_rules = alert_rules.filter(team_filter_query)\n        issue_rules = issue_rules.filter(team_filter_query)\n    expand = request.GET.getlist('expand', [])\n    if 'latestIncident' in expand:\n        alert_rules = alert_rules.annotate(incident_id=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('id')[:1]), Value(-1)))\n    is_asc = request.GET.get('asc', False) == '1'\n    sort_key = request.GET.getlist('sort', ['date_added'])\n    rule_sort_key = ['label' if x == 'name' else x for x in sort_key]\n    case_insensitive = sort_key == ['name']\n    if 'incident_status' in sort_key:\n        alert_rules = alert_rules.annotate(incident_status=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('status')[:1]), Value(-1, output_field=IntegerField())))\n        issue_rules = issue_rules.annotate(incident_status=Value(-2, output_field=IntegerField()))\n    if 'date_triggered' in sort_key:\n        far_past_date = Value(make_aware(datetime.min), output_field=DateTimeField())\n        alert_rules = alert_rules.annotate(date_triggered=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('date_started')[:1]), far_past_date))\n        issue_rules = issue_rules.annotate(date_triggered=far_past_date)\n    alert_rules_count = alert_rules.count()\n    issue_rules_count = issue_rules.count()\n    alert_rule_intermediary = CombinedQuerysetIntermediary(alert_rules, sort_key)\n    rule_intermediary = CombinedQuerysetIntermediary(issue_rules, rule_sort_key)\n    response = self.paginate(request, paginator_cls=CombinedQuerysetPaginator, on_results=lambda x: serialize(x, request.user, CombinedRuleSerializer(expand=expand)), default_per_page=25, intermediaries=[alert_rule_intermediary, rule_intermediary], desc=not is_asc, cursor_cls=StringCursor if case_insensitive else Cursor, case_insensitive=case_insensitive)\n    response['X-Sentry-Issue-Rule-Hits'] = issue_rules_count\n    response['X-Sentry-Alert-Rule-Hits'] = alert_rules_count\n    return response",
        "mutated": [
            "def get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n    '\\n        Fetches (metric) alert rules and legacy (issue alert) rules for an organization\\n        '\n    project_ids = self.get_requested_project_ids_unchecked(request) or None\n    if project_ids == {-1}:\n        project_ids = Project.objects.filter(organization=organization, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    elif project_ids is None:\n        org_team_list = Team.objects.filter(organization=organization).values_list('id', flat=True)\n        user_team_list = OrganizationMemberTeam.objects.filter(organizationmember__user_id=request.user.id, team__in=org_team_list).values_list('team', flat=True)\n        project_ids = Project.objects.filter(teams__in=user_team_list, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    projects = self.get_projects(request, organization, project_ids=set(project_ids))\n    teams = request.GET.getlist('team', [])\n    team_filter_query = None\n    if len(teams) > 0:\n        try:\n            (teams_query, unassigned) = parse_team_params(request, organization, teams)\n        except InvalidParams as err:\n            return Response(str(err), status=status.HTTP_400_BAD_REQUEST)\n        team_filter_query = Q(owner_id__in=teams_query.values_list('actor_id', flat=True))\n        if unassigned:\n            team_filter_query = team_filter_query | Q(owner_id=None)\n    alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    issue_rules = Rule.objects.filter(status__in=[ObjectStatus.ACTIVE, ObjectStatus.DISABLED], source__in=[RuleSource.ISSUE], project__in=projects)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    else:\n        datasets = request.GET.getlist('dataset', [])\n        if len(datasets) > 0:\n            alert_rules = alert_rules.filter(snuba_query__dataset__in=datasets)\n            if Dataset.Events.value not in datasets:\n                issue_rules = Rule.objects.none()\n    name = request.GET.get('name', None)\n    if name:\n        alert_rules = alert_rules.filter(Q(name__icontains=name))\n        issue_rules = issue_rules.filter(Q(label__icontains=name))\n    if team_filter_query:\n        alert_rules = alert_rules.filter(team_filter_query)\n        issue_rules = issue_rules.filter(team_filter_query)\n    expand = request.GET.getlist('expand', [])\n    if 'latestIncident' in expand:\n        alert_rules = alert_rules.annotate(incident_id=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('id')[:1]), Value(-1)))\n    is_asc = request.GET.get('asc', False) == '1'\n    sort_key = request.GET.getlist('sort', ['date_added'])\n    rule_sort_key = ['label' if x == 'name' else x for x in sort_key]\n    case_insensitive = sort_key == ['name']\n    if 'incident_status' in sort_key:\n        alert_rules = alert_rules.annotate(incident_status=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('status')[:1]), Value(-1, output_field=IntegerField())))\n        issue_rules = issue_rules.annotate(incident_status=Value(-2, output_field=IntegerField()))\n    if 'date_triggered' in sort_key:\n        far_past_date = Value(make_aware(datetime.min), output_field=DateTimeField())\n        alert_rules = alert_rules.annotate(date_triggered=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('date_started')[:1]), far_past_date))\n        issue_rules = issue_rules.annotate(date_triggered=far_past_date)\n    alert_rules_count = alert_rules.count()\n    issue_rules_count = issue_rules.count()\n    alert_rule_intermediary = CombinedQuerysetIntermediary(alert_rules, sort_key)\n    rule_intermediary = CombinedQuerysetIntermediary(issue_rules, rule_sort_key)\n    response = self.paginate(request, paginator_cls=CombinedQuerysetPaginator, on_results=lambda x: serialize(x, request.user, CombinedRuleSerializer(expand=expand)), default_per_page=25, intermediaries=[alert_rule_intermediary, rule_intermediary], desc=not is_asc, cursor_cls=StringCursor if case_insensitive else Cursor, case_insensitive=case_insensitive)\n    response['X-Sentry-Issue-Rule-Hits'] = issue_rules_count\n    response['X-Sentry-Alert-Rule-Hits'] = alert_rules_count\n    return response",
            "def get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Fetches (metric) alert rules and legacy (issue alert) rules for an organization\\n        '\n    project_ids = self.get_requested_project_ids_unchecked(request) or None\n    if project_ids == {-1}:\n        project_ids = Project.objects.filter(organization=organization, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    elif project_ids is None:\n        org_team_list = Team.objects.filter(organization=organization).values_list('id', flat=True)\n        user_team_list = OrganizationMemberTeam.objects.filter(organizationmember__user_id=request.user.id, team__in=org_team_list).values_list('team', flat=True)\n        project_ids = Project.objects.filter(teams__in=user_team_list, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    projects = self.get_projects(request, organization, project_ids=set(project_ids))\n    teams = request.GET.getlist('team', [])\n    team_filter_query = None\n    if len(teams) > 0:\n        try:\n            (teams_query, unassigned) = parse_team_params(request, organization, teams)\n        except InvalidParams as err:\n            return Response(str(err), status=status.HTTP_400_BAD_REQUEST)\n        team_filter_query = Q(owner_id__in=teams_query.values_list('actor_id', flat=True))\n        if unassigned:\n            team_filter_query = team_filter_query | Q(owner_id=None)\n    alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    issue_rules = Rule.objects.filter(status__in=[ObjectStatus.ACTIVE, ObjectStatus.DISABLED], source__in=[RuleSource.ISSUE], project__in=projects)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    else:\n        datasets = request.GET.getlist('dataset', [])\n        if len(datasets) > 0:\n            alert_rules = alert_rules.filter(snuba_query__dataset__in=datasets)\n            if Dataset.Events.value not in datasets:\n                issue_rules = Rule.objects.none()\n    name = request.GET.get('name', None)\n    if name:\n        alert_rules = alert_rules.filter(Q(name__icontains=name))\n        issue_rules = issue_rules.filter(Q(label__icontains=name))\n    if team_filter_query:\n        alert_rules = alert_rules.filter(team_filter_query)\n        issue_rules = issue_rules.filter(team_filter_query)\n    expand = request.GET.getlist('expand', [])\n    if 'latestIncident' in expand:\n        alert_rules = alert_rules.annotate(incident_id=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('id')[:1]), Value(-1)))\n    is_asc = request.GET.get('asc', False) == '1'\n    sort_key = request.GET.getlist('sort', ['date_added'])\n    rule_sort_key = ['label' if x == 'name' else x for x in sort_key]\n    case_insensitive = sort_key == ['name']\n    if 'incident_status' in sort_key:\n        alert_rules = alert_rules.annotate(incident_status=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('status')[:1]), Value(-1, output_field=IntegerField())))\n        issue_rules = issue_rules.annotate(incident_status=Value(-2, output_field=IntegerField()))\n    if 'date_triggered' in sort_key:\n        far_past_date = Value(make_aware(datetime.min), output_field=DateTimeField())\n        alert_rules = alert_rules.annotate(date_triggered=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('date_started')[:1]), far_past_date))\n        issue_rules = issue_rules.annotate(date_triggered=far_past_date)\n    alert_rules_count = alert_rules.count()\n    issue_rules_count = issue_rules.count()\n    alert_rule_intermediary = CombinedQuerysetIntermediary(alert_rules, sort_key)\n    rule_intermediary = CombinedQuerysetIntermediary(issue_rules, rule_sort_key)\n    response = self.paginate(request, paginator_cls=CombinedQuerysetPaginator, on_results=lambda x: serialize(x, request.user, CombinedRuleSerializer(expand=expand)), default_per_page=25, intermediaries=[alert_rule_intermediary, rule_intermediary], desc=not is_asc, cursor_cls=StringCursor if case_insensitive else Cursor, case_insensitive=case_insensitive)\n    response['X-Sentry-Issue-Rule-Hits'] = issue_rules_count\n    response['X-Sentry-Alert-Rule-Hits'] = alert_rules_count\n    return response",
            "def get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Fetches (metric) alert rules and legacy (issue alert) rules for an organization\\n        '\n    project_ids = self.get_requested_project_ids_unchecked(request) or None\n    if project_ids == {-1}:\n        project_ids = Project.objects.filter(organization=organization, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    elif project_ids is None:\n        org_team_list = Team.objects.filter(organization=organization).values_list('id', flat=True)\n        user_team_list = OrganizationMemberTeam.objects.filter(organizationmember__user_id=request.user.id, team__in=org_team_list).values_list('team', flat=True)\n        project_ids = Project.objects.filter(teams__in=user_team_list, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    projects = self.get_projects(request, organization, project_ids=set(project_ids))\n    teams = request.GET.getlist('team', [])\n    team_filter_query = None\n    if len(teams) > 0:\n        try:\n            (teams_query, unassigned) = parse_team_params(request, organization, teams)\n        except InvalidParams as err:\n            return Response(str(err), status=status.HTTP_400_BAD_REQUEST)\n        team_filter_query = Q(owner_id__in=teams_query.values_list('actor_id', flat=True))\n        if unassigned:\n            team_filter_query = team_filter_query | Q(owner_id=None)\n    alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    issue_rules = Rule.objects.filter(status__in=[ObjectStatus.ACTIVE, ObjectStatus.DISABLED], source__in=[RuleSource.ISSUE], project__in=projects)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    else:\n        datasets = request.GET.getlist('dataset', [])\n        if len(datasets) > 0:\n            alert_rules = alert_rules.filter(snuba_query__dataset__in=datasets)\n            if Dataset.Events.value not in datasets:\n                issue_rules = Rule.objects.none()\n    name = request.GET.get('name', None)\n    if name:\n        alert_rules = alert_rules.filter(Q(name__icontains=name))\n        issue_rules = issue_rules.filter(Q(label__icontains=name))\n    if team_filter_query:\n        alert_rules = alert_rules.filter(team_filter_query)\n        issue_rules = issue_rules.filter(team_filter_query)\n    expand = request.GET.getlist('expand', [])\n    if 'latestIncident' in expand:\n        alert_rules = alert_rules.annotate(incident_id=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('id')[:1]), Value(-1)))\n    is_asc = request.GET.get('asc', False) == '1'\n    sort_key = request.GET.getlist('sort', ['date_added'])\n    rule_sort_key = ['label' if x == 'name' else x for x in sort_key]\n    case_insensitive = sort_key == ['name']\n    if 'incident_status' in sort_key:\n        alert_rules = alert_rules.annotate(incident_status=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('status')[:1]), Value(-1, output_field=IntegerField())))\n        issue_rules = issue_rules.annotate(incident_status=Value(-2, output_field=IntegerField()))\n    if 'date_triggered' in sort_key:\n        far_past_date = Value(make_aware(datetime.min), output_field=DateTimeField())\n        alert_rules = alert_rules.annotate(date_triggered=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('date_started')[:1]), far_past_date))\n        issue_rules = issue_rules.annotate(date_triggered=far_past_date)\n    alert_rules_count = alert_rules.count()\n    issue_rules_count = issue_rules.count()\n    alert_rule_intermediary = CombinedQuerysetIntermediary(alert_rules, sort_key)\n    rule_intermediary = CombinedQuerysetIntermediary(issue_rules, rule_sort_key)\n    response = self.paginate(request, paginator_cls=CombinedQuerysetPaginator, on_results=lambda x: serialize(x, request.user, CombinedRuleSerializer(expand=expand)), default_per_page=25, intermediaries=[alert_rule_intermediary, rule_intermediary], desc=not is_asc, cursor_cls=StringCursor if case_insensitive else Cursor, case_insensitive=case_insensitive)\n    response['X-Sentry-Issue-Rule-Hits'] = issue_rules_count\n    response['X-Sentry-Alert-Rule-Hits'] = alert_rules_count\n    return response",
            "def get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Fetches (metric) alert rules and legacy (issue alert) rules for an organization\\n        '\n    project_ids = self.get_requested_project_ids_unchecked(request) or None\n    if project_ids == {-1}:\n        project_ids = Project.objects.filter(organization=organization, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    elif project_ids is None:\n        org_team_list = Team.objects.filter(organization=organization).values_list('id', flat=True)\n        user_team_list = OrganizationMemberTeam.objects.filter(organizationmember__user_id=request.user.id, team__in=org_team_list).values_list('team', flat=True)\n        project_ids = Project.objects.filter(teams__in=user_team_list, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    projects = self.get_projects(request, organization, project_ids=set(project_ids))\n    teams = request.GET.getlist('team', [])\n    team_filter_query = None\n    if len(teams) > 0:\n        try:\n            (teams_query, unassigned) = parse_team_params(request, organization, teams)\n        except InvalidParams as err:\n            return Response(str(err), status=status.HTTP_400_BAD_REQUEST)\n        team_filter_query = Q(owner_id__in=teams_query.values_list('actor_id', flat=True))\n        if unassigned:\n            team_filter_query = team_filter_query | Q(owner_id=None)\n    alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    issue_rules = Rule.objects.filter(status__in=[ObjectStatus.ACTIVE, ObjectStatus.DISABLED], source__in=[RuleSource.ISSUE], project__in=projects)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    else:\n        datasets = request.GET.getlist('dataset', [])\n        if len(datasets) > 0:\n            alert_rules = alert_rules.filter(snuba_query__dataset__in=datasets)\n            if Dataset.Events.value not in datasets:\n                issue_rules = Rule.objects.none()\n    name = request.GET.get('name', None)\n    if name:\n        alert_rules = alert_rules.filter(Q(name__icontains=name))\n        issue_rules = issue_rules.filter(Q(label__icontains=name))\n    if team_filter_query:\n        alert_rules = alert_rules.filter(team_filter_query)\n        issue_rules = issue_rules.filter(team_filter_query)\n    expand = request.GET.getlist('expand', [])\n    if 'latestIncident' in expand:\n        alert_rules = alert_rules.annotate(incident_id=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('id')[:1]), Value(-1)))\n    is_asc = request.GET.get('asc', False) == '1'\n    sort_key = request.GET.getlist('sort', ['date_added'])\n    rule_sort_key = ['label' if x == 'name' else x for x in sort_key]\n    case_insensitive = sort_key == ['name']\n    if 'incident_status' in sort_key:\n        alert_rules = alert_rules.annotate(incident_status=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('status')[:1]), Value(-1, output_field=IntegerField())))\n        issue_rules = issue_rules.annotate(incident_status=Value(-2, output_field=IntegerField()))\n    if 'date_triggered' in sort_key:\n        far_past_date = Value(make_aware(datetime.min), output_field=DateTimeField())\n        alert_rules = alert_rules.annotate(date_triggered=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('date_started')[:1]), far_past_date))\n        issue_rules = issue_rules.annotate(date_triggered=far_past_date)\n    alert_rules_count = alert_rules.count()\n    issue_rules_count = issue_rules.count()\n    alert_rule_intermediary = CombinedQuerysetIntermediary(alert_rules, sort_key)\n    rule_intermediary = CombinedQuerysetIntermediary(issue_rules, rule_sort_key)\n    response = self.paginate(request, paginator_cls=CombinedQuerysetPaginator, on_results=lambda x: serialize(x, request.user, CombinedRuleSerializer(expand=expand)), default_per_page=25, intermediaries=[alert_rule_intermediary, rule_intermediary], desc=not is_asc, cursor_cls=StringCursor if case_insensitive else Cursor, case_insensitive=case_insensitive)\n    response['X-Sentry-Issue-Rule-Hits'] = issue_rules_count\n    response['X-Sentry-Alert-Rule-Hits'] = alert_rules_count\n    return response",
            "def get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Fetches (metric) alert rules and legacy (issue alert) rules for an organization\\n        '\n    project_ids = self.get_requested_project_ids_unchecked(request) or None\n    if project_ids == {-1}:\n        project_ids = Project.objects.filter(organization=organization, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    elif project_ids is None:\n        org_team_list = Team.objects.filter(organization=organization).values_list('id', flat=True)\n        user_team_list = OrganizationMemberTeam.objects.filter(organizationmember__user_id=request.user.id, team__in=org_team_list).values_list('team', flat=True)\n        project_ids = Project.objects.filter(teams__in=user_team_list, status=ObjectStatus.ACTIVE).values_list('id', flat=True)\n    projects = self.get_projects(request, organization, project_ids=set(project_ids))\n    teams = request.GET.getlist('team', [])\n    team_filter_query = None\n    if len(teams) > 0:\n        try:\n            (teams_query, unassigned) = parse_team_params(request, organization, teams)\n        except InvalidParams as err:\n            return Response(str(err), status=status.HTTP_400_BAD_REQUEST)\n        team_filter_query = Q(owner_id__in=teams_query.values_list('actor_id', flat=True))\n        if unassigned:\n            team_filter_query = team_filter_query | Q(owner_id=None)\n    alert_rules = AlertRule.objects.fetch_for_organization(organization, projects)\n    issue_rules = Rule.objects.filter(status__in=[ObjectStatus.ACTIVE, ObjectStatus.DISABLED], source__in=[RuleSource.ISSUE], project__in=projects)\n    if not features.has('organizations:performance-view', organization):\n        alert_rules = alert_rules.filter(snuba_query__dataset=Dataset.Events.value)\n    else:\n        datasets = request.GET.getlist('dataset', [])\n        if len(datasets) > 0:\n            alert_rules = alert_rules.filter(snuba_query__dataset__in=datasets)\n            if Dataset.Events.value not in datasets:\n                issue_rules = Rule.objects.none()\n    name = request.GET.get('name', None)\n    if name:\n        alert_rules = alert_rules.filter(Q(name__icontains=name))\n        issue_rules = issue_rules.filter(Q(label__icontains=name))\n    if team_filter_query:\n        alert_rules = alert_rules.filter(team_filter_query)\n        issue_rules = issue_rules.filter(team_filter_query)\n    expand = request.GET.getlist('expand', [])\n    if 'latestIncident' in expand:\n        alert_rules = alert_rules.annotate(incident_id=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('id')[:1]), Value(-1)))\n    is_asc = request.GET.get('asc', False) == '1'\n    sort_key = request.GET.getlist('sort', ['date_added'])\n    rule_sort_key = ['label' if x == 'name' else x for x in sort_key]\n    case_insensitive = sort_key == ['name']\n    if 'incident_status' in sort_key:\n        alert_rules = alert_rules.annotate(incident_status=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('status')[:1]), Value(-1, output_field=IntegerField())))\n        issue_rules = issue_rules.annotate(incident_status=Value(-2, output_field=IntegerField()))\n    if 'date_triggered' in sort_key:\n        far_past_date = Value(make_aware(datetime.min), output_field=DateTimeField())\n        alert_rules = alert_rules.annotate(date_triggered=Coalesce(Subquery(Incident.objects.filter(alert_rule=OuterRef('pk')).order_by('-date_started').values('date_started')[:1]), far_past_date))\n        issue_rules = issue_rules.annotate(date_triggered=far_past_date)\n    alert_rules_count = alert_rules.count()\n    issue_rules_count = issue_rules.count()\n    alert_rule_intermediary = CombinedQuerysetIntermediary(alert_rules, sort_key)\n    rule_intermediary = CombinedQuerysetIntermediary(issue_rules, rule_sort_key)\n    response = self.paginate(request, paginator_cls=CombinedQuerysetPaginator, on_results=lambda x: serialize(x, request.user, CombinedRuleSerializer(expand=expand)), default_per_page=25, intermediaries=[alert_rule_intermediary, rule_intermediary], desc=not is_asc, cursor_cls=StringCursor if case_insensitive else Cursor, case_insensitive=case_insensitive)\n    response['X-Sentry-Issue-Rule-Hits'] = issue_rules_count\n    response['X-Sentry-Alert-Rule-Hits'] = alert_rules_count\n    return response"
        ]
    },
    {
        "func_name": "get",
        "original": "@extend_schema(operation_id=\"List an Organization's Metric Alert Rules\", parameters=[GlobalParams.ORG_SLUG], request=None, responses={200: inline_sentry_response_serializer('ListMetricAlertRules', List[AlertRuleSerializerResponse]), 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.LIST_METRIC_ALERT_RULES)\ndef get(self, request: Request, organization) -> Response:\n    \"\"\"\n        Return a list of active metric alert rules bound to an organization.\n\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\n        It specifies the metric type, function, time interval, and threshold\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\n        predefined threshold. These rules help you proactively identify and address issues in your\n        project.\n        \"\"\"\n    return self.fetch_metric_alert(request, organization)",
        "mutated": [
            "@extend_schema(operation_id=\"List an Organization's Metric Alert Rules\", parameters=[GlobalParams.ORG_SLUG], request=None, responses={200: inline_sentry_response_serializer('ListMetricAlertRules', List[AlertRuleSerializerResponse]), 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.LIST_METRIC_ALERT_RULES)\ndef get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n    '\\n        Return a list of active metric alert rules bound to an organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n        '\n    return self.fetch_metric_alert(request, organization)",
            "@extend_schema(operation_id=\"List an Organization's Metric Alert Rules\", parameters=[GlobalParams.ORG_SLUG], request=None, responses={200: inline_sentry_response_serializer('ListMetricAlertRules', List[AlertRuleSerializerResponse]), 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.LIST_METRIC_ALERT_RULES)\ndef get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return a list of active metric alert rules bound to an organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n        '\n    return self.fetch_metric_alert(request, organization)",
            "@extend_schema(operation_id=\"List an Organization's Metric Alert Rules\", parameters=[GlobalParams.ORG_SLUG], request=None, responses={200: inline_sentry_response_serializer('ListMetricAlertRules', List[AlertRuleSerializerResponse]), 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.LIST_METRIC_ALERT_RULES)\ndef get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return a list of active metric alert rules bound to an organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n        '\n    return self.fetch_metric_alert(request, organization)",
            "@extend_schema(operation_id=\"List an Organization's Metric Alert Rules\", parameters=[GlobalParams.ORG_SLUG], request=None, responses={200: inline_sentry_response_serializer('ListMetricAlertRules', List[AlertRuleSerializerResponse]), 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.LIST_METRIC_ALERT_RULES)\ndef get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return a list of active metric alert rules bound to an organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n        '\n    return self.fetch_metric_alert(request, organization)",
            "@extend_schema(operation_id=\"List an Organization's Metric Alert Rules\", parameters=[GlobalParams.ORG_SLUG], request=None, responses={200: inline_sentry_response_serializer('ListMetricAlertRules', List[AlertRuleSerializerResponse]), 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.LIST_METRIC_ALERT_RULES)\ndef get(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return a list of active metric alert rules bound to an organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n        '\n    return self.fetch_metric_alert(request, organization)"
        ]
    },
    {
        "func_name": "post",
        "original": "@extend_schema(operation_id='Create a Metric Alert Rule for an Organization', parameters=[GlobalParams.ORG_SLUG], request=OrganizationAlertRuleIndexPostSerializer, responses={201: AlertRuleSerializer, 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.CREATE_METRIC_ALERT_RULE)\ndef post(self, request: Request, organization) -> Response:\n    \"\"\"\n        Create a new metric alert rule for the given organization.\n\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\n        It specifies the metric type, function, time interval, and threshold\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\n        predefined threshold. These rules help you proactively identify and address issues in your\n        project.\n\n        ## Metric Alert Rule Types\n        Below are the types of metric alert rules you can create and the parameter values required\n        to set them up. All other parameters can be customized based on how you want the alert\n        rule to work. Scroll down to Body Parameters for more information. Visit the\n        [Alert Types](/product/alerts/alert-types/#metric-alerts) docs for more details on each\n        metric alert rule type.\n\n        ### [Number of Errors](/product/alerts/alert-types/#number-of-errors)\n        - `eventTypes`: Any of `error` or `default`.\n        ```json\n        {\n            \"queryType\": 0,\n            \"dataset\": \"events\",\n            \"aggregate\": \"count()\",\n            \"eventTypes\": [\"error\", \"default\"]\n        }\n        ```\n\n        ### [Users Experiencing Errors](/product/alerts/alert-types/#users-experiencing-errors)\n        - `eventTypes`: Any of `error` or `default`.\n        ```json\n        {\n            \"queryType\": 0,\n            \"dataset\": \"events\",\n            \"aggregate\": \"count_unique(user)\"\n        }\n        ```\n\n        ### [Crash Free Session Rate](/product/alerts/alert-types/#crash-free-session-rate)\n        ```json\n        {\n            \"queryType\": 2,\n            \"dataset\": \"metrics\",\n            \"aggregate\": \"percentage(sessions_crashed, sessions) AS _crash_rate_alert_aggregate\"\n        }\n        ```\n\n        ### [Crash Free User Rate](/product/alerts/alert-types/#crash-free-user-rate)\n        ```json\n        {\n            \"queryType\": 2,\n            \"dataset\": \"metrics\",\n            \"aggregate\": \"percentage(users_crashed, users) AS _crash_rate_alert_aggregate\"\n        }\n        ```\n\n        ### [Throughput](/product/alerts/alert-types/#throughput)\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"transactions\",\n            \"aggregate\": \"count()\"\n        }\n        ```\n\n        ### [Transaction Duration](/product/alerts/alert-types/#transaction-duration)\n        -  `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\n        -  `aggregate`: Valid values are `avg(transaction.duration)`, `p50(transaction.duration)`, `p75(transaction.duration)`, `p95(transaction.duration)`, `p99(transaction.duration)`, `p100(transaction.duration)`, and `percentile(transaction.duration,x)`, where `x` is your custom percentile.\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"generic_metrics\",\n            \"aggregate\": \"avg(transaction.duration)\"\n        }\n        ```\n\n        ### [Apdex](/product/alerts/alert-types/#apdex)\n        - `aggregate`: `apdex(x)` where `x` is the value of the Apdex score.\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"transactions\",\n            \"aggregate\": \"apdex(300)\"\n        }\n        ```\n\n        ### [Failure Rate](/product/alerts/alert-types/#failure-rate)\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"transactions\",\n            \"aggregate\": \"failure_rate()\"\n        }\n        ```\n\n        ### [Largest Contentful Paint](/product/alerts/alert-types/#largest-contentful-display)\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\n        - `aggregate`: Valid values are `avg(measurements.lcp)`, `p50(measurements.lcp)`, `p75(measurements.lcp)`, `p95(measurements.lcp)`, `p99(measurements.lcp)`, `p100(measurements.lcp)`, and `percentile(measurements.lcp,x)`, where `x` is your custom percentile.\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"generic_metrics\",\n            \"aggregate\": \"p50(measurements.lcp)\"\n        }\n        ```\n\n        ### [First Input Delay](/product/alerts/alert-types/#first-input-delay)\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\n        - `aggregate`: Valid values are `avg(measurements.fid)`, `p50(measurements.fid)`, `p75(measurements.fid)`, `p95(measurements.fid)`, `p99(measurements.fid)`, `p100(measurements.fid)`, and `percentile(measurements.fid,x)`, where `x` is your custom percentile.\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"generic_metrics\",\n            \"aggregate\": \"p100(measurements.fid)\"\n        }\n        ```\n\n        ### [Cumulative Layout Shift](/product/alerts/alert-types/#cumulative-layout-shift)\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\n        - `aggregate`: Valid values are `avg(measurements.cls)`, `p50(measurements.cls)`, `p75(measurements.cls)`, `p95(measurements.cls)`, `p99(measurements.cls)`, `p100(measurements.cls)`, and `percentile(measurements.cls,x)`, where `x` is your custom percentile.\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"transactions\",\n            \"aggregate\": \"percentile(measurements.cls,0.2)\"\n        }\n        ```\n\n        ### [Custom Metric](/product/alerts/alert-types/#custom-metric)\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\n        - `aggregate`: Valid values are:\n            - `avg(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\n            - `p50(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\n            - `p75(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\n            - `p95(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\n            - `p99(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\n            - `p100(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\n            - `percentile(x,y)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`, and `y` is the custom percentile.\n            - `failure_rate()`\n            - `apdex(x)`, where `x` is the value of the Apdex score.\n            - `count()`\n        ```json\n        {\n            \"queryType\": 1,\n            \"dataset\": \"generic_metrics\",\n            \"aggregate\": \"p75(measurements.ttfb)\"\n        }\n        ```\n        \"\"\"\n    return self.create_metric_alert(request, organization)",
        "mutated": [
            "@extend_schema(operation_id='Create a Metric Alert Rule for an Organization', parameters=[GlobalParams.ORG_SLUG], request=OrganizationAlertRuleIndexPostSerializer, responses={201: AlertRuleSerializer, 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.CREATE_METRIC_ALERT_RULE)\ndef post(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n    '\\n        Create a new metric alert rule for the given organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n\\n        ## Metric Alert Rule Types\\n        Below are the types of metric alert rules you can create and the parameter values required\\n        to set them up. All other parameters can be customized based on how you want the alert\\n        rule to work. Scroll down to Body Parameters for more information. Visit the\\n        [Alert Types](/product/alerts/alert-types/#metric-alerts) docs for more details on each\\n        metric alert rule type.\\n\\n        ### [Number of Errors](/product/alerts/alert-types/#number-of-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count()\",\\n            \"eventTypes\": [\"error\", \"default\"]\\n        }\\n        ```\\n\\n        ### [Users Experiencing Errors](/product/alerts/alert-types/#users-experiencing-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count_unique(user)\"\\n        }\\n        ```\\n\\n        ### [Crash Free Session Rate](/product/alerts/alert-types/#crash-free-session-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(sessions_crashed, sessions) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Crash Free User Rate](/product/alerts/alert-types/#crash-free-user-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(users_crashed, users) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Throughput](/product/alerts/alert-types/#throughput)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"count()\"\\n        }\\n        ```\\n\\n        ### [Transaction Duration](/product/alerts/alert-types/#transaction-duration)\\n        -  `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        -  `aggregate`: Valid values are `avg(transaction.duration)`, `p50(transaction.duration)`, `p75(transaction.duration)`, `p95(transaction.duration)`, `p99(transaction.duration)`, `p100(transaction.duration)`, and `percentile(transaction.duration,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"avg(transaction.duration)\"\\n        }\\n        ```\\n\\n        ### [Apdex](/product/alerts/alert-types/#apdex)\\n        - `aggregate`: `apdex(x)` where `x` is the value of the Apdex score.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"apdex(300)\"\\n        }\\n        ```\\n\\n        ### [Failure Rate](/product/alerts/alert-types/#failure-rate)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"failure_rate()\"\\n        }\\n        ```\\n\\n        ### [Largest Contentful Paint](/product/alerts/alert-types/#largest-contentful-display)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.lcp)`, `p50(measurements.lcp)`, `p75(measurements.lcp)`, `p95(measurements.lcp)`, `p99(measurements.lcp)`, `p100(measurements.lcp)`, and `percentile(measurements.lcp,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p50(measurements.lcp)\"\\n        }\\n        ```\\n\\n        ### [First Input Delay](/product/alerts/alert-types/#first-input-delay)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.fid)`, `p50(measurements.fid)`, `p75(measurements.fid)`, `p95(measurements.fid)`, `p99(measurements.fid)`, `p100(measurements.fid)`, and `percentile(measurements.fid,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p100(measurements.fid)\"\\n        }\\n        ```\\n\\n        ### [Cumulative Layout Shift](/product/alerts/alert-types/#cumulative-layout-shift)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.cls)`, `p50(measurements.cls)`, `p75(measurements.cls)`, `p95(measurements.cls)`, `p99(measurements.cls)`, `p100(measurements.cls)`, and `percentile(measurements.cls,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"percentile(measurements.cls,0.2)\"\\n        }\\n        ```\\n\\n        ### [Custom Metric](/product/alerts/alert-types/#custom-metric)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are:\\n            - `avg(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p50(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p75(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p95(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p99(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p100(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `percentile(x,y)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`, and `y` is the custom percentile.\\n            - `failure_rate()`\\n            - `apdex(x)`, where `x` is the value of the Apdex score.\\n            - `count()`\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p75(measurements.ttfb)\"\\n        }\\n        ```\\n        '\n    return self.create_metric_alert(request, organization)",
            "@extend_schema(operation_id='Create a Metric Alert Rule for an Organization', parameters=[GlobalParams.ORG_SLUG], request=OrganizationAlertRuleIndexPostSerializer, responses={201: AlertRuleSerializer, 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.CREATE_METRIC_ALERT_RULE)\ndef post(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Create a new metric alert rule for the given organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n\\n        ## Metric Alert Rule Types\\n        Below are the types of metric alert rules you can create and the parameter values required\\n        to set them up. All other parameters can be customized based on how you want the alert\\n        rule to work. Scroll down to Body Parameters for more information. Visit the\\n        [Alert Types](/product/alerts/alert-types/#metric-alerts) docs for more details on each\\n        metric alert rule type.\\n\\n        ### [Number of Errors](/product/alerts/alert-types/#number-of-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count()\",\\n            \"eventTypes\": [\"error\", \"default\"]\\n        }\\n        ```\\n\\n        ### [Users Experiencing Errors](/product/alerts/alert-types/#users-experiencing-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count_unique(user)\"\\n        }\\n        ```\\n\\n        ### [Crash Free Session Rate](/product/alerts/alert-types/#crash-free-session-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(sessions_crashed, sessions) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Crash Free User Rate](/product/alerts/alert-types/#crash-free-user-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(users_crashed, users) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Throughput](/product/alerts/alert-types/#throughput)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"count()\"\\n        }\\n        ```\\n\\n        ### [Transaction Duration](/product/alerts/alert-types/#transaction-duration)\\n        -  `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        -  `aggregate`: Valid values are `avg(transaction.duration)`, `p50(transaction.duration)`, `p75(transaction.duration)`, `p95(transaction.duration)`, `p99(transaction.duration)`, `p100(transaction.duration)`, and `percentile(transaction.duration,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"avg(transaction.duration)\"\\n        }\\n        ```\\n\\n        ### [Apdex](/product/alerts/alert-types/#apdex)\\n        - `aggregate`: `apdex(x)` where `x` is the value of the Apdex score.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"apdex(300)\"\\n        }\\n        ```\\n\\n        ### [Failure Rate](/product/alerts/alert-types/#failure-rate)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"failure_rate()\"\\n        }\\n        ```\\n\\n        ### [Largest Contentful Paint](/product/alerts/alert-types/#largest-contentful-display)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.lcp)`, `p50(measurements.lcp)`, `p75(measurements.lcp)`, `p95(measurements.lcp)`, `p99(measurements.lcp)`, `p100(measurements.lcp)`, and `percentile(measurements.lcp,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p50(measurements.lcp)\"\\n        }\\n        ```\\n\\n        ### [First Input Delay](/product/alerts/alert-types/#first-input-delay)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.fid)`, `p50(measurements.fid)`, `p75(measurements.fid)`, `p95(measurements.fid)`, `p99(measurements.fid)`, `p100(measurements.fid)`, and `percentile(measurements.fid,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p100(measurements.fid)\"\\n        }\\n        ```\\n\\n        ### [Cumulative Layout Shift](/product/alerts/alert-types/#cumulative-layout-shift)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.cls)`, `p50(measurements.cls)`, `p75(measurements.cls)`, `p95(measurements.cls)`, `p99(measurements.cls)`, `p100(measurements.cls)`, and `percentile(measurements.cls,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"percentile(measurements.cls,0.2)\"\\n        }\\n        ```\\n\\n        ### [Custom Metric](/product/alerts/alert-types/#custom-metric)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are:\\n            - `avg(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p50(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p75(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p95(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p99(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p100(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `percentile(x,y)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`, and `y` is the custom percentile.\\n            - `failure_rate()`\\n            - `apdex(x)`, where `x` is the value of the Apdex score.\\n            - `count()`\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p75(measurements.ttfb)\"\\n        }\\n        ```\\n        '\n    return self.create_metric_alert(request, organization)",
            "@extend_schema(operation_id='Create a Metric Alert Rule for an Organization', parameters=[GlobalParams.ORG_SLUG], request=OrganizationAlertRuleIndexPostSerializer, responses={201: AlertRuleSerializer, 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.CREATE_METRIC_ALERT_RULE)\ndef post(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Create a new metric alert rule for the given organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n\\n        ## Metric Alert Rule Types\\n        Below are the types of metric alert rules you can create and the parameter values required\\n        to set them up. All other parameters can be customized based on how you want the alert\\n        rule to work. Scroll down to Body Parameters for more information. Visit the\\n        [Alert Types](/product/alerts/alert-types/#metric-alerts) docs for more details on each\\n        metric alert rule type.\\n\\n        ### [Number of Errors](/product/alerts/alert-types/#number-of-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count()\",\\n            \"eventTypes\": [\"error\", \"default\"]\\n        }\\n        ```\\n\\n        ### [Users Experiencing Errors](/product/alerts/alert-types/#users-experiencing-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count_unique(user)\"\\n        }\\n        ```\\n\\n        ### [Crash Free Session Rate](/product/alerts/alert-types/#crash-free-session-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(sessions_crashed, sessions) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Crash Free User Rate](/product/alerts/alert-types/#crash-free-user-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(users_crashed, users) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Throughput](/product/alerts/alert-types/#throughput)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"count()\"\\n        }\\n        ```\\n\\n        ### [Transaction Duration](/product/alerts/alert-types/#transaction-duration)\\n        -  `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        -  `aggregate`: Valid values are `avg(transaction.duration)`, `p50(transaction.duration)`, `p75(transaction.duration)`, `p95(transaction.duration)`, `p99(transaction.duration)`, `p100(transaction.duration)`, and `percentile(transaction.duration,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"avg(transaction.duration)\"\\n        }\\n        ```\\n\\n        ### [Apdex](/product/alerts/alert-types/#apdex)\\n        - `aggregate`: `apdex(x)` where `x` is the value of the Apdex score.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"apdex(300)\"\\n        }\\n        ```\\n\\n        ### [Failure Rate](/product/alerts/alert-types/#failure-rate)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"failure_rate()\"\\n        }\\n        ```\\n\\n        ### [Largest Contentful Paint](/product/alerts/alert-types/#largest-contentful-display)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.lcp)`, `p50(measurements.lcp)`, `p75(measurements.lcp)`, `p95(measurements.lcp)`, `p99(measurements.lcp)`, `p100(measurements.lcp)`, and `percentile(measurements.lcp,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p50(measurements.lcp)\"\\n        }\\n        ```\\n\\n        ### [First Input Delay](/product/alerts/alert-types/#first-input-delay)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.fid)`, `p50(measurements.fid)`, `p75(measurements.fid)`, `p95(measurements.fid)`, `p99(measurements.fid)`, `p100(measurements.fid)`, and `percentile(measurements.fid,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p100(measurements.fid)\"\\n        }\\n        ```\\n\\n        ### [Cumulative Layout Shift](/product/alerts/alert-types/#cumulative-layout-shift)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.cls)`, `p50(measurements.cls)`, `p75(measurements.cls)`, `p95(measurements.cls)`, `p99(measurements.cls)`, `p100(measurements.cls)`, and `percentile(measurements.cls,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"percentile(measurements.cls,0.2)\"\\n        }\\n        ```\\n\\n        ### [Custom Metric](/product/alerts/alert-types/#custom-metric)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are:\\n            - `avg(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p50(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p75(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p95(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p99(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p100(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `percentile(x,y)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`, and `y` is the custom percentile.\\n            - `failure_rate()`\\n            - `apdex(x)`, where `x` is the value of the Apdex score.\\n            - `count()`\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p75(measurements.ttfb)\"\\n        }\\n        ```\\n        '\n    return self.create_metric_alert(request, organization)",
            "@extend_schema(operation_id='Create a Metric Alert Rule for an Organization', parameters=[GlobalParams.ORG_SLUG], request=OrganizationAlertRuleIndexPostSerializer, responses={201: AlertRuleSerializer, 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.CREATE_METRIC_ALERT_RULE)\ndef post(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Create a new metric alert rule for the given organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n\\n        ## Metric Alert Rule Types\\n        Below are the types of metric alert rules you can create and the parameter values required\\n        to set them up. All other parameters can be customized based on how you want the alert\\n        rule to work. Scroll down to Body Parameters for more information. Visit the\\n        [Alert Types](/product/alerts/alert-types/#metric-alerts) docs for more details on each\\n        metric alert rule type.\\n\\n        ### [Number of Errors](/product/alerts/alert-types/#number-of-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count()\",\\n            \"eventTypes\": [\"error\", \"default\"]\\n        }\\n        ```\\n\\n        ### [Users Experiencing Errors](/product/alerts/alert-types/#users-experiencing-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count_unique(user)\"\\n        }\\n        ```\\n\\n        ### [Crash Free Session Rate](/product/alerts/alert-types/#crash-free-session-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(sessions_crashed, sessions) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Crash Free User Rate](/product/alerts/alert-types/#crash-free-user-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(users_crashed, users) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Throughput](/product/alerts/alert-types/#throughput)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"count()\"\\n        }\\n        ```\\n\\n        ### [Transaction Duration](/product/alerts/alert-types/#transaction-duration)\\n        -  `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        -  `aggregate`: Valid values are `avg(transaction.duration)`, `p50(transaction.duration)`, `p75(transaction.duration)`, `p95(transaction.duration)`, `p99(transaction.duration)`, `p100(transaction.duration)`, and `percentile(transaction.duration,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"avg(transaction.duration)\"\\n        }\\n        ```\\n\\n        ### [Apdex](/product/alerts/alert-types/#apdex)\\n        - `aggregate`: `apdex(x)` where `x` is the value of the Apdex score.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"apdex(300)\"\\n        }\\n        ```\\n\\n        ### [Failure Rate](/product/alerts/alert-types/#failure-rate)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"failure_rate()\"\\n        }\\n        ```\\n\\n        ### [Largest Contentful Paint](/product/alerts/alert-types/#largest-contentful-display)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.lcp)`, `p50(measurements.lcp)`, `p75(measurements.lcp)`, `p95(measurements.lcp)`, `p99(measurements.lcp)`, `p100(measurements.lcp)`, and `percentile(measurements.lcp,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p50(measurements.lcp)\"\\n        }\\n        ```\\n\\n        ### [First Input Delay](/product/alerts/alert-types/#first-input-delay)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.fid)`, `p50(measurements.fid)`, `p75(measurements.fid)`, `p95(measurements.fid)`, `p99(measurements.fid)`, `p100(measurements.fid)`, and `percentile(measurements.fid,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p100(measurements.fid)\"\\n        }\\n        ```\\n\\n        ### [Cumulative Layout Shift](/product/alerts/alert-types/#cumulative-layout-shift)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.cls)`, `p50(measurements.cls)`, `p75(measurements.cls)`, `p95(measurements.cls)`, `p99(measurements.cls)`, `p100(measurements.cls)`, and `percentile(measurements.cls,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"percentile(measurements.cls,0.2)\"\\n        }\\n        ```\\n\\n        ### [Custom Metric](/product/alerts/alert-types/#custom-metric)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are:\\n            - `avg(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p50(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p75(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p95(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p99(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p100(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `percentile(x,y)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`, and `y` is the custom percentile.\\n            - `failure_rate()`\\n            - `apdex(x)`, where `x` is the value of the Apdex score.\\n            - `count()`\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p75(measurements.ttfb)\"\\n        }\\n        ```\\n        '\n    return self.create_metric_alert(request, organization)",
            "@extend_schema(operation_id='Create a Metric Alert Rule for an Organization', parameters=[GlobalParams.ORG_SLUG], request=OrganizationAlertRuleIndexPostSerializer, responses={201: AlertRuleSerializer, 401: RESPONSE_UNAUTHORIZED, 403: RESPONSE_FORBIDDEN, 404: RESPONSE_NOT_FOUND}, examples=MetricAlertExamples.CREATE_METRIC_ALERT_RULE)\ndef post(self, request: Request, organization) -> Response:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Create a new metric alert rule for the given organization.\\n\\n        A metric alert rule is a configuration that defines the conditions for triggering an alert.\\n        It specifies the metric type, function, time interval, and threshold\\n        values that determine when an alert should be triggered. Metric alert rules are used to monitor\\n        and notify you when certain metrics, like error count, latency, or failure rate, cross a\\n        predefined threshold. These rules help you proactively identify and address issues in your\\n        project.\\n\\n        ## Metric Alert Rule Types\\n        Below are the types of metric alert rules you can create and the parameter values required\\n        to set them up. All other parameters can be customized based on how you want the alert\\n        rule to work. Scroll down to Body Parameters for more information. Visit the\\n        [Alert Types](/product/alerts/alert-types/#metric-alerts) docs for more details on each\\n        metric alert rule type.\\n\\n        ### [Number of Errors](/product/alerts/alert-types/#number-of-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count()\",\\n            \"eventTypes\": [\"error\", \"default\"]\\n        }\\n        ```\\n\\n        ### [Users Experiencing Errors](/product/alerts/alert-types/#users-experiencing-errors)\\n        - `eventTypes`: Any of `error` or `default`.\\n        ```json\\n        {\\n            \"queryType\": 0,\\n            \"dataset\": \"events\",\\n            \"aggregate\": \"count_unique(user)\"\\n        }\\n        ```\\n\\n        ### [Crash Free Session Rate](/product/alerts/alert-types/#crash-free-session-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(sessions_crashed, sessions) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Crash Free User Rate](/product/alerts/alert-types/#crash-free-user-rate)\\n        ```json\\n        {\\n            \"queryType\": 2,\\n            \"dataset\": \"metrics\",\\n            \"aggregate\": \"percentage(users_crashed, users) AS _crash_rate_alert_aggregate\"\\n        }\\n        ```\\n\\n        ### [Throughput](/product/alerts/alert-types/#throughput)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"count()\"\\n        }\\n        ```\\n\\n        ### [Transaction Duration](/product/alerts/alert-types/#transaction-duration)\\n        -  `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        -  `aggregate`: Valid values are `avg(transaction.duration)`, `p50(transaction.duration)`, `p75(transaction.duration)`, `p95(transaction.duration)`, `p99(transaction.duration)`, `p100(transaction.duration)`, and `percentile(transaction.duration,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"avg(transaction.duration)\"\\n        }\\n        ```\\n\\n        ### [Apdex](/product/alerts/alert-types/#apdex)\\n        - `aggregate`: `apdex(x)` where `x` is the value of the Apdex score.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"apdex(300)\"\\n        }\\n        ```\\n\\n        ### [Failure Rate](/product/alerts/alert-types/#failure-rate)\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"failure_rate()\"\\n        }\\n        ```\\n\\n        ### [Largest Contentful Paint](/product/alerts/alert-types/#largest-contentful-display)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.lcp)`, `p50(measurements.lcp)`, `p75(measurements.lcp)`, `p95(measurements.lcp)`, `p99(measurements.lcp)`, `p100(measurements.lcp)`, and `percentile(measurements.lcp,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p50(measurements.lcp)\"\\n        }\\n        ```\\n\\n        ### [First Input Delay](/product/alerts/alert-types/#first-input-delay)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.fid)`, `p50(measurements.fid)`, `p75(measurements.fid)`, `p95(measurements.fid)`, `p99(measurements.fid)`, `p100(measurements.fid)`, and `percentile(measurements.fid,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p100(measurements.fid)\"\\n        }\\n        ```\\n\\n        ### [Cumulative Layout Shift](/product/alerts/alert-types/#cumulative-layout-shift)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are `avg(measurements.cls)`, `p50(measurements.cls)`, `p75(measurements.cls)`, `p95(measurements.cls)`, `p99(measurements.cls)`, `p100(measurements.cls)`, and `percentile(measurements.cls,x)`, where `x` is your custom percentile.\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"transactions\",\\n            \"aggregate\": \"percentile(measurements.cls,0.2)\"\\n        }\\n        ```\\n\\n        ### [Custom Metric](/product/alerts/alert-types/#custom-metric)\\n        - `dataset`: If a custom percentile is used, `dataset` is `transactions`. Otherwise, `dataset` is `generic_metrics`.\\n        - `aggregate`: Valid values are:\\n            - `avg(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p50(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p75(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p95(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p99(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `p100(x)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`.\\n            - `percentile(x,y)`, where `x` is `transaction.duration`, `measurements.cls`, `measurements.fcp`, `measurements.fid`, `measurements.fp`, `measurements.lcp`, `measurements.ttfb`, or `measurements.ttfb.requesttime`, and `y` is the custom percentile.\\n            - `failure_rate()`\\n            - `apdex(x)`, where `x` is the value of the Apdex score.\\n            - `count()`\\n        ```json\\n        {\\n            \"queryType\": 1,\\n            \"dataset\": \"generic_metrics\",\\n            \"aggregate\": \"p75(measurements.ttfb)\"\\n        }\\n        ```\\n        '\n    return self.create_metric_alert(request, organization)"
        ]
    }
]