[
    {
        "func_name": "compute_dist",
        "original": "def compute_dist(source_embs, target_embs, k=5, return_sim_mat=False):\n    target_ids = [tid for tid in target_embs]\n    source_mat = np.stack(source_embs.values(), axis=0)\n    normalized_source_mat = source_mat / np.linalg.norm(source_mat, axis=1, keepdims=True)\n    target_mat = np.stack(target_embs.values(), axis=0)\n    normalized_target_mat = target_mat / np.linalg.norm(target_mat, axis=1, keepdims=True)\n    sim_mat = normalized_source_mat.dot(normalized_target_mat.T)\n    if return_sim_mat:\n        return sim_mat\n    neighbors_map = {}\n    for (i, sentence_id) in enumerate(source_embs):\n        idx = np.argsort(sim_mat[i, :])[::-1][:k]\n        neighbors_map[sentence_id] = [target_ids[tid] for tid in idx]\n    return neighbors_map",
        "mutated": [
            "def compute_dist(source_embs, target_embs, k=5, return_sim_mat=False):\n    if False:\n        i = 10\n    target_ids = [tid for tid in target_embs]\n    source_mat = np.stack(source_embs.values(), axis=0)\n    normalized_source_mat = source_mat / np.linalg.norm(source_mat, axis=1, keepdims=True)\n    target_mat = np.stack(target_embs.values(), axis=0)\n    normalized_target_mat = target_mat / np.linalg.norm(target_mat, axis=1, keepdims=True)\n    sim_mat = normalized_source_mat.dot(normalized_target_mat.T)\n    if return_sim_mat:\n        return sim_mat\n    neighbors_map = {}\n    for (i, sentence_id) in enumerate(source_embs):\n        idx = np.argsort(sim_mat[i, :])[::-1][:k]\n        neighbors_map[sentence_id] = [target_ids[tid] for tid in idx]\n    return neighbors_map",
            "def compute_dist(source_embs, target_embs, k=5, return_sim_mat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    target_ids = [tid for tid in target_embs]\n    source_mat = np.stack(source_embs.values(), axis=0)\n    normalized_source_mat = source_mat / np.linalg.norm(source_mat, axis=1, keepdims=True)\n    target_mat = np.stack(target_embs.values(), axis=0)\n    normalized_target_mat = target_mat / np.linalg.norm(target_mat, axis=1, keepdims=True)\n    sim_mat = normalized_source_mat.dot(normalized_target_mat.T)\n    if return_sim_mat:\n        return sim_mat\n    neighbors_map = {}\n    for (i, sentence_id) in enumerate(source_embs):\n        idx = np.argsort(sim_mat[i, :])[::-1][:k]\n        neighbors_map[sentence_id] = [target_ids[tid] for tid in idx]\n    return neighbors_map",
            "def compute_dist(source_embs, target_embs, k=5, return_sim_mat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    target_ids = [tid for tid in target_embs]\n    source_mat = np.stack(source_embs.values(), axis=0)\n    normalized_source_mat = source_mat / np.linalg.norm(source_mat, axis=1, keepdims=True)\n    target_mat = np.stack(target_embs.values(), axis=0)\n    normalized_target_mat = target_mat / np.linalg.norm(target_mat, axis=1, keepdims=True)\n    sim_mat = normalized_source_mat.dot(normalized_target_mat.T)\n    if return_sim_mat:\n        return sim_mat\n    neighbors_map = {}\n    for (i, sentence_id) in enumerate(source_embs):\n        idx = np.argsort(sim_mat[i, :])[::-1][:k]\n        neighbors_map[sentence_id] = [target_ids[tid] for tid in idx]\n    return neighbors_map",
            "def compute_dist(source_embs, target_embs, k=5, return_sim_mat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    target_ids = [tid for tid in target_embs]\n    source_mat = np.stack(source_embs.values(), axis=0)\n    normalized_source_mat = source_mat / np.linalg.norm(source_mat, axis=1, keepdims=True)\n    target_mat = np.stack(target_embs.values(), axis=0)\n    normalized_target_mat = target_mat / np.linalg.norm(target_mat, axis=1, keepdims=True)\n    sim_mat = normalized_source_mat.dot(normalized_target_mat.T)\n    if return_sim_mat:\n        return sim_mat\n    neighbors_map = {}\n    for (i, sentence_id) in enumerate(source_embs):\n        idx = np.argsort(sim_mat[i, :])[::-1][:k]\n        neighbors_map[sentence_id] = [target_ids[tid] for tid in idx]\n    return neighbors_map",
            "def compute_dist(source_embs, target_embs, k=5, return_sim_mat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    target_ids = [tid for tid in target_embs]\n    source_mat = np.stack(source_embs.values(), axis=0)\n    normalized_source_mat = source_mat / np.linalg.norm(source_mat, axis=1, keepdims=True)\n    target_mat = np.stack(target_embs.values(), axis=0)\n    normalized_target_mat = target_mat / np.linalg.norm(target_mat, axis=1, keepdims=True)\n    sim_mat = normalized_source_mat.dot(normalized_target_mat.T)\n    if return_sim_mat:\n        return sim_mat\n    neighbors_map = {}\n    for (i, sentence_id) in enumerate(source_embs):\n        idx = np.argsort(sim_mat[i, :])[::-1][:k]\n        neighbors_map[sentence_id] = [target_ids[tid] for tid in idx]\n    return neighbors_map"
        ]
    },
    {
        "func_name": "load_embeddings",
        "original": "def load_embeddings(directory, LANGS):\n    sentence_embeddings = {}\n    sentence_texts = {}\n    for lang in LANGS:\n        sentence_embeddings[lang] = {}\n        sentence_texts[lang] = {}\n        lang_dir = f'{directory}/{lang}'\n        embedding_files = glob.glob(f'{lang_dir}/all_avg_pool.{lang}.*')\n        for embed_file in embedding_files:\n            shard_id = embed_file.split('.')[-1]\n            embeddings = np.fromfile(embed_file, dtype=np.float32)\n            num_rows = embeddings.shape[0] // DIM\n            embeddings = embeddings.reshape((num_rows, DIM))\n            with open(f'{lang_dir}/sentences.{lang}.{shard_id}') as sentence_file:\n                for (idx, line) in enumerate(sentence_file):\n                    (sentence_id, sentence) = line.strip().split('\\t')\n                    sentence_texts[lang][sentence_id] = sentence\n                    sentence_embeddings[lang][sentence_id] = embeddings[idx, :]\n    return (sentence_embeddings, sentence_texts)",
        "mutated": [
            "def load_embeddings(directory, LANGS):\n    if False:\n        i = 10\n    sentence_embeddings = {}\n    sentence_texts = {}\n    for lang in LANGS:\n        sentence_embeddings[lang] = {}\n        sentence_texts[lang] = {}\n        lang_dir = f'{directory}/{lang}'\n        embedding_files = glob.glob(f'{lang_dir}/all_avg_pool.{lang}.*')\n        for embed_file in embedding_files:\n            shard_id = embed_file.split('.')[-1]\n            embeddings = np.fromfile(embed_file, dtype=np.float32)\n            num_rows = embeddings.shape[0] // DIM\n            embeddings = embeddings.reshape((num_rows, DIM))\n            with open(f'{lang_dir}/sentences.{lang}.{shard_id}') as sentence_file:\n                for (idx, line) in enumerate(sentence_file):\n                    (sentence_id, sentence) = line.strip().split('\\t')\n                    sentence_texts[lang][sentence_id] = sentence\n                    sentence_embeddings[lang][sentence_id] = embeddings[idx, :]\n    return (sentence_embeddings, sentence_texts)",
            "def load_embeddings(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    sentence_embeddings = {}\n    sentence_texts = {}\n    for lang in LANGS:\n        sentence_embeddings[lang] = {}\n        sentence_texts[lang] = {}\n        lang_dir = f'{directory}/{lang}'\n        embedding_files = glob.glob(f'{lang_dir}/all_avg_pool.{lang}.*')\n        for embed_file in embedding_files:\n            shard_id = embed_file.split('.')[-1]\n            embeddings = np.fromfile(embed_file, dtype=np.float32)\n            num_rows = embeddings.shape[0] // DIM\n            embeddings = embeddings.reshape((num_rows, DIM))\n            with open(f'{lang_dir}/sentences.{lang}.{shard_id}') as sentence_file:\n                for (idx, line) in enumerate(sentence_file):\n                    (sentence_id, sentence) = line.strip().split('\\t')\n                    sentence_texts[lang][sentence_id] = sentence\n                    sentence_embeddings[lang][sentence_id] = embeddings[idx, :]\n    return (sentence_embeddings, sentence_texts)",
            "def load_embeddings(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    sentence_embeddings = {}\n    sentence_texts = {}\n    for lang in LANGS:\n        sentence_embeddings[lang] = {}\n        sentence_texts[lang] = {}\n        lang_dir = f'{directory}/{lang}'\n        embedding_files = glob.glob(f'{lang_dir}/all_avg_pool.{lang}.*')\n        for embed_file in embedding_files:\n            shard_id = embed_file.split('.')[-1]\n            embeddings = np.fromfile(embed_file, dtype=np.float32)\n            num_rows = embeddings.shape[0] // DIM\n            embeddings = embeddings.reshape((num_rows, DIM))\n            with open(f'{lang_dir}/sentences.{lang}.{shard_id}') as sentence_file:\n                for (idx, line) in enumerate(sentence_file):\n                    (sentence_id, sentence) = line.strip().split('\\t')\n                    sentence_texts[lang][sentence_id] = sentence\n                    sentence_embeddings[lang][sentence_id] = embeddings[idx, :]\n    return (sentence_embeddings, sentence_texts)",
            "def load_embeddings(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    sentence_embeddings = {}\n    sentence_texts = {}\n    for lang in LANGS:\n        sentence_embeddings[lang] = {}\n        sentence_texts[lang] = {}\n        lang_dir = f'{directory}/{lang}'\n        embedding_files = glob.glob(f'{lang_dir}/all_avg_pool.{lang}.*')\n        for embed_file in embedding_files:\n            shard_id = embed_file.split('.')[-1]\n            embeddings = np.fromfile(embed_file, dtype=np.float32)\n            num_rows = embeddings.shape[0] // DIM\n            embeddings = embeddings.reshape((num_rows, DIM))\n            with open(f'{lang_dir}/sentences.{lang}.{shard_id}') as sentence_file:\n                for (idx, line) in enumerate(sentence_file):\n                    (sentence_id, sentence) = line.strip().split('\\t')\n                    sentence_texts[lang][sentence_id] = sentence\n                    sentence_embeddings[lang][sentence_id] = embeddings[idx, :]\n    return (sentence_embeddings, sentence_texts)",
            "def load_embeddings(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    sentence_embeddings = {}\n    sentence_texts = {}\n    for lang in LANGS:\n        sentence_embeddings[lang] = {}\n        sentence_texts[lang] = {}\n        lang_dir = f'{directory}/{lang}'\n        embedding_files = glob.glob(f'{lang_dir}/all_avg_pool.{lang}.*')\n        for embed_file in embedding_files:\n            shard_id = embed_file.split('.')[-1]\n            embeddings = np.fromfile(embed_file, dtype=np.float32)\n            num_rows = embeddings.shape[0] // DIM\n            embeddings = embeddings.reshape((num_rows, DIM))\n            with open(f'{lang_dir}/sentences.{lang}.{shard_id}') as sentence_file:\n                for (idx, line) in enumerate(sentence_file):\n                    (sentence_id, sentence) = line.strip().split('\\t')\n                    sentence_texts[lang][sentence_id] = sentence\n                    sentence_embeddings[lang][sentence_id] = embeddings[idx, :]\n    return (sentence_embeddings, sentence_texts)"
        ]
    },
    {
        "func_name": "compute_accuracy",
        "original": "def compute_accuracy(directory, LANGS):\n    (sentence_embeddings, sentence_texts) = load_embeddings(directory, LANGS)\n    top_1_accuracy = {}\n    top1_str = ' '.join(LANGS) + '\\n'\n    for source_lang in LANGS:\n        top_1_accuracy[source_lang] = {}\n        top1_str += f'{source_lang} '\n        for target_lang in LANGS:\n            top1 = 0\n            top5 = 0\n            neighbors_map = compute_dist(sentence_embeddings[source_lang], sentence_embeddings[target_lang])\n            for (sentence_id, neighbors) in neighbors_map.items():\n                if sentence_id == neighbors[0]:\n                    top1 += 1\n                if sentence_id in neighbors[:5]:\n                    top5 += 1\n            n = len(sentence_embeddings[target_lang])\n            top1_str += f'{top1 / n} '\n        top1_str += '\\n'\n    print(top1_str)\n    print(top1_str, file=open(f'{directory}/accuracy', 'w'))",
        "mutated": [
            "def compute_accuracy(directory, LANGS):\n    if False:\n        i = 10\n    (sentence_embeddings, sentence_texts) = load_embeddings(directory, LANGS)\n    top_1_accuracy = {}\n    top1_str = ' '.join(LANGS) + '\\n'\n    for source_lang in LANGS:\n        top_1_accuracy[source_lang] = {}\n        top1_str += f'{source_lang} '\n        for target_lang in LANGS:\n            top1 = 0\n            top5 = 0\n            neighbors_map = compute_dist(sentence_embeddings[source_lang], sentence_embeddings[target_lang])\n            for (sentence_id, neighbors) in neighbors_map.items():\n                if sentence_id == neighbors[0]:\n                    top1 += 1\n                if sentence_id in neighbors[:5]:\n                    top5 += 1\n            n = len(sentence_embeddings[target_lang])\n            top1_str += f'{top1 / n} '\n        top1_str += '\\n'\n    print(top1_str)\n    print(top1_str, file=open(f'{directory}/accuracy', 'w'))",
            "def compute_accuracy(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (sentence_embeddings, sentence_texts) = load_embeddings(directory, LANGS)\n    top_1_accuracy = {}\n    top1_str = ' '.join(LANGS) + '\\n'\n    for source_lang in LANGS:\n        top_1_accuracy[source_lang] = {}\n        top1_str += f'{source_lang} '\n        for target_lang in LANGS:\n            top1 = 0\n            top5 = 0\n            neighbors_map = compute_dist(sentence_embeddings[source_lang], sentence_embeddings[target_lang])\n            for (sentence_id, neighbors) in neighbors_map.items():\n                if sentence_id == neighbors[0]:\n                    top1 += 1\n                if sentence_id in neighbors[:5]:\n                    top5 += 1\n            n = len(sentence_embeddings[target_lang])\n            top1_str += f'{top1 / n} '\n        top1_str += '\\n'\n    print(top1_str)\n    print(top1_str, file=open(f'{directory}/accuracy', 'w'))",
            "def compute_accuracy(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (sentence_embeddings, sentence_texts) = load_embeddings(directory, LANGS)\n    top_1_accuracy = {}\n    top1_str = ' '.join(LANGS) + '\\n'\n    for source_lang in LANGS:\n        top_1_accuracy[source_lang] = {}\n        top1_str += f'{source_lang} '\n        for target_lang in LANGS:\n            top1 = 0\n            top5 = 0\n            neighbors_map = compute_dist(sentence_embeddings[source_lang], sentence_embeddings[target_lang])\n            for (sentence_id, neighbors) in neighbors_map.items():\n                if sentence_id == neighbors[0]:\n                    top1 += 1\n                if sentence_id in neighbors[:5]:\n                    top5 += 1\n            n = len(sentence_embeddings[target_lang])\n            top1_str += f'{top1 / n} '\n        top1_str += '\\n'\n    print(top1_str)\n    print(top1_str, file=open(f'{directory}/accuracy', 'w'))",
            "def compute_accuracy(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (sentence_embeddings, sentence_texts) = load_embeddings(directory, LANGS)\n    top_1_accuracy = {}\n    top1_str = ' '.join(LANGS) + '\\n'\n    for source_lang in LANGS:\n        top_1_accuracy[source_lang] = {}\n        top1_str += f'{source_lang} '\n        for target_lang in LANGS:\n            top1 = 0\n            top5 = 0\n            neighbors_map = compute_dist(sentence_embeddings[source_lang], sentence_embeddings[target_lang])\n            for (sentence_id, neighbors) in neighbors_map.items():\n                if sentence_id == neighbors[0]:\n                    top1 += 1\n                if sentence_id in neighbors[:5]:\n                    top5 += 1\n            n = len(sentence_embeddings[target_lang])\n            top1_str += f'{top1 / n} '\n        top1_str += '\\n'\n    print(top1_str)\n    print(top1_str, file=open(f'{directory}/accuracy', 'w'))",
            "def compute_accuracy(directory, LANGS):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (sentence_embeddings, sentence_texts) = load_embeddings(directory, LANGS)\n    top_1_accuracy = {}\n    top1_str = ' '.join(LANGS) + '\\n'\n    for source_lang in LANGS:\n        top_1_accuracy[source_lang] = {}\n        top1_str += f'{source_lang} '\n        for target_lang in LANGS:\n            top1 = 0\n            top5 = 0\n            neighbors_map = compute_dist(sentence_embeddings[source_lang], sentence_embeddings[target_lang])\n            for (sentence_id, neighbors) in neighbors_map.items():\n                if sentence_id == neighbors[0]:\n                    top1 += 1\n                if sentence_id in neighbors[:5]:\n                    top5 += 1\n            n = len(sentence_embeddings[target_lang])\n            top1_str += f'{top1 / n} '\n        top1_str += '\\n'\n    print(top1_str)\n    print(top1_str, file=open(f'{directory}/accuracy', 'w'))"
        ]
    }
]