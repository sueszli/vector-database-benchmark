[
    {
        "func_name": "__init__",
        "original": "def __init__(self, generated_reports: OrderedDict[str, Any]):\n    \"\"\"\n        Initializes the ModelReportVisualizer instance with the necessary reports.\n\n        Args:\n            generated_reports (Dict[str, Any]): The reports generated by the ModelReport class\n                can also be a dictionary generated in another manner, as long as format is same\n        \"\"\"\n    self.generated_reports = generated_reports",
        "mutated": [
            "def __init__(self, generated_reports: OrderedDict[str, Any]):\n    if False:\n        i = 10\n    '\\n        Initializes the ModelReportVisualizer instance with the necessary reports.\\n\\n        Args:\\n            generated_reports (Dict[str, Any]): The reports generated by the ModelReport class\\n                can also be a dictionary generated in another manner, as long as format is same\\n        '\n    self.generated_reports = generated_reports",
            "def __init__(self, generated_reports: OrderedDict[str, Any]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Initializes the ModelReportVisualizer instance with the necessary reports.\\n\\n        Args:\\n            generated_reports (Dict[str, Any]): The reports generated by the ModelReport class\\n                can also be a dictionary generated in another manner, as long as format is same\\n        '\n    self.generated_reports = generated_reports",
            "def __init__(self, generated_reports: OrderedDict[str, Any]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Initializes the ModelReportVisualizer instance with the necessary reports.\\n\\n        Args:\\n            generated_reports (Dict[str, Any]): The reports generated by the ModelReport class\\n                can also be a dictionary generated in another manner, as long as format is same\\n        '\n    self.generated_reports = generated_reports",
            "def __init__(self, generated_reports: OrderedDict[str, Any]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Initializes the ModelReportVisualizer instance with the necessary reports.\\n\\n        Args:\\n            generated_reports (Dict[str, Any]): The reports generated by the ModelReport class\\n                can also be a dictionary generated in another manner, as long as format is same\\n        '\n    self.generated_reports = generated_reports",
            "def __init__(self, generated_reports: OrderedDict[str, Any]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Initializes the ModelReportVisualizer instance with the necessary reports.\\n\\n        Args:\\n            generated_reports (Dict[str, Any]): The reports generated by the ModelReport class\\n                can also be a dictionary generated in another manner, as long as format is same\\n        '\n    self.generated_reports = generated_reports"
        ]
    },
    {
        "func_name": "get_all_unique_module_fqns",
        "original": "def get_all_unique_module_fqns(self) -> Set[str]:\n    \"\"\"\n        The purpose of this method is to provide a user the set of all module_fqns so that if\n        they wish to use some of the filtering capabilities of the ModelReportVisualizer class,\n        they don't need to manually parse the generated_reports dictionary to get this information.\n\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\n        instance was initialized with.\n        \"\"\"\n    return set(self.generated_reports.keys())",
        "mutated": [
            "def get_all_unique_module_fqns(self) -> Set[str]:\n    if False:\n        i = 10\n    \"\\n        The purpose of this method is to provide a user the set of all module_fqns so that if\\n        they wish to use some of the filtering capabilities of the ModelReportVisualizer class,\\n        they don't need to manually parse the generated_reports dictionary to get this information.\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    return set(self.generated_reports.keys())",
            "def get_all_unique_module_fqns(self) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        The purpose of this method is to provide a user the set of all module_fqns so that if\\n        they wish to use some of the filtering capabilities of the ModelReportVisualizer class,\\n        they don't need to manually parse the generated_reports dictionary to get this information.\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    return set(self.generated_reports.keys())",
            "def get_all_unique_module_fqns(self) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        The purpose of this method is to provide a user the set of all module_fqns so that if\\n        they wish to use some of the filtering capabilities of the ModelReportVisualizer class,\\n        they don't need to manually parse the generated_reports dictionary to get this information.\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    return set(self.generated_reports.keys())",
            "def get_all_unique_module_fqns(self) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        The purpose of this method is to provide a user the set of all module_fqns so that if\\n        they wish to use some of the filtering capabilities of the ModelReportVisualizer class,\\n        they don't need to manually parse the generated_reports dictionary to get this information.\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    return set(self.generated_reports.keys())",
            "def get_all_unique_module_fqns(self) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        The purpose of this method is to provide a user the set of all module_fqns so that if\\n        they wish to use some of the filtering capabilities of the ModelReportVisualizer class,\\n        they don't need to manually parse the generated_reports dictionary to get this information.\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    return set(self.generated_reports.keys())"
        ]
    },
    {
        "func_name": "get_all_unique_feature_names",
        "original": "def get_all_unique_feature_names(self, plottable_features_only: bool=True) -> Set[str]:\n    \"\"\"\n        The purpose of this method is to provide a user the set of all feature names so that if\n        they wish to use the filtering capabilities of the generate_table_view(), or use either of\n        the generate_plot_view() or generate_histogram_view(), they don't need to manually parse\n        the generated_reports dictionary to get this information.\n\n        Args:\n            plottable_features_only (bool): True if the user is only looking for plottable features,\n                False otherwise\n                plottable features are those that are tensor values\n                Default: True (only return those feature names that are plottable)\n\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\n        instance was initialized with.\n        \"\"\"\n    unique_feature_names = set()\n    for module_fqn in self.generated_reports:\n        feature_dict: Dict[str, Any] = self.generated_reports[module_fqn]\n        for feature_name in feature_dict:\n            if not plottable_features_only or type(feature_dict[feature_name]) == torch.Tensor:\n                unique_feature_names.add(feature_name)\n    return unique_feature_names",
        "mutated": [
            "def get_all_unique_feature_names(self, plottable_features_only: bool=True) -> Set[str]:\n    if False:\n        i = 10\n    \"\\n        The purpose of this method is to provide a user the set of all feature names so that if\\n        they wish to use the filtering capabilities of the generate_table_view(), or use either of\\n        the generate_plot_view() or generate_histogram_view(), they don't need to manually parse\\n        the generated_reports dictionary to get this information.\\n\\n        Args:\\n            plottable_features_only (bool): True if the user is only looking for plottable features,\\n                False otherwise\\n                plottable features are those that are tensor values\\n                Default: True (only return those feature names that are plottable)\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    unique_feature_names = set()\n    for module_fqn in self.generated_reports:\n        feature_dict: Dict[str, Any] = self.generated_reports[module_fqn]\n        for feature_name in feature_dict:\n            if not plottable_features_only or type(feature_dict[feature_name]) == torch.Tensor:\n                unique_feature_names.add(feature_name)\n    return unique_feature_names",
            "def get_all_unique_feature_names(self, plottable_features_only: bool=True) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        The purpose of this method is to provide a user the set of all feature names so that if\\n        they wish to use the filtering capabilities of the generate_table_view(), or use either of\\n        the generate_plot_view() or generate_histogram_view(), they don't need to manually parse\\n        the generated_reports dictionary to get this information.\\n\\n        Args:\\n            plottable_features_only (bool): True if the user is only looking for plottable features,\\n                False otherwise\\n                plottable features are those that are tensor values\\n                Default: True (only return those feature names that are plottable)\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    unique_feature_names = set()\n    for module_fqn in self.generated_reports:\n        feature_dict: Dict[str, Any] = self.generated_reports[module_fqn]\n        for feature_name in feature_dict:\n            if not plottable_features_only or type(feature_dict[feature_name]) == torch.Tensor:\n                unique_feature_names.add(feature_name)\n    return unique_feature_names",
            "def get_all_unique_feature_names(self, plottable_features_only: bool=True) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        The purpose of this method is to provide a user the set of all feature names so that if\\n        they wish to use the filtering capabilities of the generate_table_view(), or use either of\\n        the generate_plot_view() or generate_histogram_view(), they don't need to manually parse\\n        the generated_reports dictionary to get this information.\\n\\n        Args:\\n            plottable_features_only (bool): True if the user is only looking for plottable features,\\n                False otherwise\\n                plottable features are those that are tensor values\\n                Default: True (only return those feature names that are plottable)\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    unique_feature_names = set()\n    for module_fqn in self.generated_reports:\n        feature_dict: Dict[str, Any] = self.generated_reports[module_fqn]\n        for feature_name in feature_dict:\n            if not plottable_features_only or type(feature_dict[feature_name]) == torch.Tensor:\n                unique_feature_names.add(feature_name)\n    return unique_feature_names",
            "def get_all_unique_feature_names(self, plottable_features_only: bool=True) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        The purpose of this method is to provide a user the set of all feature names so that if\\n        they wish to use the filtering capabilities of the generate_table_view(), or use either of\\n        the generate_plot_view() or generate_histogram_view(), they don't need to manually parse\\n        the generated_reports dictionary to get this information.\\n\\n        Args:\\n            plottable_features_only (bool): True if the user is only looking for plottable features,\\n                False otherwise\\n                plottable features are those that are tensor values\\n                Default: True (only return those feature names that are plottable)\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    unique_feature_names = set()\n    for module_fqn in self.generated_reports:\n        feature_dict: Dict[str, Any] = self.generated_reports[module_fqn]\n        for feature_name in feature_dict:\n            if not plottable_features_only or type(feature_dict[feature_name]) == torch.Tensor:\n                unique_feature_names.add(feature_name)\n    return unique_feature_names",
            "def get_all_unique_feature_names(self, plottable_features_only: bool=True) -> Set[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        The purpose of this method is to provide a user the set of all feature names so that if\\n        they wish to use the filtering capabilities of the generate_table_view(), or use either of\\n        the generate_plot_view() or generate_histogram_view(), they don't need to manually parse\\n        the generated_reports dictionary to get this information.\\n\\n        Args:\\n            plottable_features_only (bool): True if the user is only looking for plottable features,\\n                False otherwise\\n                plottable features are those that are tensor values\\n                Default: True (only return those feature names that are plottable)\\n\\n        Returns all the unique module fqns present in the reports the ModelReportVisualizer\\n        instance was initialized with.\\n        \"\n    unique_feature_names = set()\n    for module_fqn in self.generated_reports:\n        feature_dict: Dict[str, Any] = self.generated_reports[module_fqn]\n        for feature_name in feature_dict:\n            if not plottable_features_only or type(feature_dict[feature_name]) == torch.Tensor:\n                unique_feature_names.add(feature_name)\n    return unique_feature_names"
        ]
    },
    {
        "func_name": "_get_filtered_data",
        "original": "def _get_filtered_data(self, feature_filter: str, module_fqn_filter: str) -> OrderedDict[str, Any]:\n    \"\"\"\n        Filters the data and returns it in the same ordered dictionary format so the relevant views can be displayed.\n\n        Args:\n            feature_filter (str): The feature filter, if we want to filter the set of data to only include\n                a certain set of features that include feature_filter\n                If feature = \"\", then we do not filter based on any features\n            module_fqn_filter (str): The filter on prefix for the module fqn. All modules that have fqn with\n                this prefix will be included\n                If module_fqn_filter = \"\" we do not filter based on module fqn, and include all modules\n\n        First, the data is filtered based on module_fqn, and then filtered based on feature\n        Returns an OrderedDict (sorted in order of model) mapping:\n            module_fqns -> feature_names -> values\n        \"\"\"\n    filtered_dict: OrderedDict[str, Any] = OrdDict()\n    for module_fqn in self.generated_reports:\n        if module_fqn_filter == '' or module_fqn_filter in module_fqn:\n            filtered_dict[module_fqn] = {}\n            module_reports = self.generated_reports[module_fqn]\n            for feature_name in module_reports:\n                if feature_filter == '' or feature_filter in feature_name:\n                    filtered_dict[module_fqn][feature_name] = module_reports[feature_name]\n    return filtered_dict",
        "mutated": [
            "def _get_filtered_data(self, feature_filter: str, module_fqn_filter: str) -> OrderedDict[str, Any]:\n    if False:\n        i = 10\n    '\\n        Filters the data and returns it in the same ordered dictionary format so the relevant views can be displayed.\\n\\n        Args:\\n            feature_filter (str): The feature filter, if we want to filter the set of data to only include\\n                a certain set of features that include feature_filter\\n                If feature = \"\", then we do not filter based on any features\\n            module_fqn_filter (str): The filter on prefix for the module fqn. All modules that have fqn with\\n                this prefix will be included\\n                If module_fqn_filter = \"\" we do not filter based on module fqn, and include all modules\\n\\n        First, the data is filtered based on module_fqn, and then filtered based on feature\\n        Returns an OrderedDict (sorted in order of model) mapping:\\n            module_fqns -> feature_names -> values\\n        '\n    filtered_dict: OrderedDict[str, Any] = OrdDict()\n    for module_fqn in self.generated_reports:\n        if module_fqn_filter == '' or module_fqn_filter in module_fqn:\n            filtered_dict[module_fqn] = {}\n            module_reports = self.generated_reports[module_fqn]\n            for feature_name in module_reports:\n                if feature_filter == '' or feature_filter in feature_name:\n                    filtered_dict[module_fqn][feature_name] = module_reports[feature_name]\n    return filtered_dict",
            "def _get_filtered_data(self, feature_filter: str, module_fqn_filter: str) -> OrderedDict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Filters the data and returns it in the same ordered dictionary format so the relevant views can be displayed.\\n\\n        Args:\\n            feature_filter (str): The feature filter, if we want to filter the set of data to only include\\n                a certain set of features that include feature_filter\\n                If feature = \"\", then we do not filter based on any features\\n            module_fqn_filter (str): The filter on prefix for the module fqn. All modules that have fqn with\\n                this prefix will be included\\n                If module_fqn_filter = \"\" we do not filter based on module fqn, and include all modules\\n\\n        First, the data is filtered based on module_fqn, and then filtered based on feature\\n        Returns an OrderedDict (sorted in order of model) mapping:\\n            module_fqns -> feature_names -> values\\n        '\n    filtered_dict: OrderedDict[str, Any] = OrdDict()\n    for module_fqn in self.generated_reports:\n        if module_fqn_filter == '' or module_fqn_filter in module_fqn:\n            filtered_dict[module_fqn] = {}\n            module_reports = self.generated_reports[module_fqn]\n            for feature_name in module_reports:\n                if feature_filter == '' or feature_filter in feature_name:\n                    filtered_dict[module_fqn][feature_name] = module_reports[feature_name]\n    return filtered_dict",
            "def _get_filtered_data(self, feature_filter: str, module_fqn_filter: str) -> OrderedDict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Filters the data and returns it in the same ordered dictionary format so the relevant views can be displayed.\\n\\n        Args:\\n            feature_filter (str): The feature filter, if we want to filter the set of data to only include\\n                a certain set of features that include feature_filter\\n                If feature = \"\", then we do not filter based on any features\\n            module_fqn_filter (str): The filter on prefix for the module fqn. All modules that have fqn with\\n                this prefix will be included\\n                If module_fqn_filter = \"\" we do not filter based on module fqn, and include all modules\\n\\n        First, the data is filtered based on module_fqn, and then filtered based on feature\\n        Returns an OrderedDict (sorted in order of model) mapping:\\n            module_fqns -> feature_names -> values\\n        '\n    filtered_dict: OrderedDict[str, Any] = OrdDict()\n    for module_fqn in self.generated_reports:\n        if module_fqn_filter == '' or module_fqn_filter in module_fqn:\n            filtered_dict[module_fqn] = {}\n            module_reports = self.generated_reports[module_fqn]\n            for feature_name in module_reports:\n                if feature_filter == '' or feature_filter in feature_name:\n                    filtered_dict[module_fqn][feature_name] = module_reports[feature_name]\n    return filtered_dict",
            "def _get_filtered_data(self, feature_filter: str, module_fqn_filter: str) -> OrderedDict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Filters the data and returns it in the same ordered dictionary format so the relevant views can be displayed.\\n\\n        Args:\\n            feature_filter (str): The feature filter, if we want to filter the set of data to only include\\n                a certain set of features that include feature_filter\\n                If feature = \"\", then we do not filter based on any features\\n            module_fqn_filter (str): The filter on prefix for the module fqn. All modules that have fqn with\\n                this prefix will be included\\n                If module_fqn_filter = \"\" we do not filter based on module fqn, and include all modules\\n\\n        First, the data is filtered based on module_fqn, and then filtered based on feature\\n        Returns an OrderedDict (sorted in order of model) mapping:\\n            module_fqns -> feature_names -> values\\n        '\n    filtered_dict: OrderedDict[str, Any] = OrdDict()\n    for module_fqn in self.generated_reports:\n        if module_fqn_filter == '' or module_fqn_filter in module_fqn:\n            filtered_dict[module_fqn] = {}\n            module_reports = self.generated_reports[module_fqn]\n            for feature_name in module_reports:\n                if feature_filter == '' or feature_filter in feature_name:\n                    filtered_dict[module_fqn][feature_name] = module_reports[feature_name]\n    return filtered_dict",
            "def _get_filtered_data(self, feature_filter: str, module_fqn_filter: str) -> OrderedDict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Filters the data and returns it in the same ordered dictionary format so the relevant views can be displayed.\\n\\n        Args:\\n            feature_filter (str): The feature filter, if we want to filter the set of data to only include\\n                a certain set of features that include feature_filter\\n                If feature = \"\", then we do not filter based on any features\\n            module_fqn_filter (str): The filter on prefix for the module fqn. All modules that have fqn with\\n                this prefix will be included\\n                If module_fqn_filter = \"\" we do not filter based on module fqn, and include all modules\\n\\n        First, the data is filtered based on module_fqn, and then filtered based on feature\\n        Returns an OrderedDict (sorted in order of model) mapping:\\n            module_fqns -> feature_names -> values\\n        '\n    filtered_dict: OrderedDict[str, Any] = OrdDict()\n    for module_fqn in self.generated_reports:\n        if module_fqn_filter == '' or module_fqn_filter in module_fqn:\n            filtered_dict[module_fqn] = {}\n            module_reports = self.generated_reports[module_fqn]\n            for feature_name in module_reports:\n                if feature_filter == '' or feature_filter in feature_name:\n                    filtered_dict[module_fqn][feature_name] = module_reports[feature_name]\n    return filtered_dict"
        ]
    },
    {
        "func_name": "_generate_tensor_table",
        "original": "def _generate_tensor_table(self, filtered_data: OrderedDict[str, Dict[str, Any]], tensor_features: List[str]) -> Tuple[List, List]:\n    \"\"\"\n        Takes in the filtered data and features list and generates the tensor headers and table\n\n        Currently meant to generate the headers and table for both the tensor information.\n\n        Args:\n            filtered_data (OrderedDict[str, Dict[str, Any]]): An OrderedDict (sorted in order of model) mapping:\n                module_fqns -> feature_names -> values\n            tensor_features (List[str]): A list of the tensor level features\n\n        Returns a tuple with:\n            A list of the headers of the tensor table\n            A list of lists containing the table information row by row\n            The 0th index row will contain the headers of the columns\n            The rest of the rows will contain data\n        \"\"\"\n    tensor_table: List[List[Any]] = []\n    tensor_headers: List[str] = []\n    if len(tensor_features) > 0:\n        for (index, module_fqn) in enumerate(filtered_data):\n            tensor_table_row = [index, module_fqn]\n            for feature in tensor_features:\n                if feature in filtered_data[module_fqn]:\n                    feature_val = filtered_data[module_fqn][feature]\n                else:\n                    feature_val = 'Not Applicable'\n                if isinstance(feature_val, torch.Tensor):\n                    feature_val = feature_val.item()\n                tensor_table_row.append(feature_val)\n            tensor_table.append(tensor_table_row)\n    if len(tensor_table) != 0:\n        tensor_headers = ['idx', 'layer_fqn'] + tensor_features\n    return (tensor_headers, tensor_table)",
        "mutated": [
            "def _generate_tensor_table(self, filtered_data: OrderedDict[str, Dict[str, Any]], tensor_features: List[str]) -> Tuple[List, List]:\n    if False:\n        i = 10\n    '\\n        Takes in the filtered data and features list and generates the tensor headers and table\\n\\n        Currently meant to generate the headers and table for both the tensor information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Dict[str, Any]]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            tensor_features (List[str]): A list of the tensor level features\\n\\n        Returns a tuple with:\\n            A list of the headers of the tensor table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    tensor_table: List[List[Any]] = []\n    tensor_headers: List[str] = []\n    if len(tensor_features) > 0:\n        for (index, module_fqn) in enumerate(filtered_data):\n            tensor_table_row = [index, module_fqn]\n            for feature in tensor_features:\n                if feature in filtered_data[module_fqn]:\n                    feature_val = filtered_data[module_fqn][feature]\n                else:\n                    feature_val = 'Not Applicable'\n                if isinstance(feature_val, torch.Tensor):\n                    feature_val = feature_val.item()\n                tensor_table_row.append(feature_val)\n            tensor_table.append(tensor_table_row)\n    if len(tensor_table) != 0:\n        tensor_headers = ['idx', 'layer_fqn'] + tensor_features\n    return (tensor_headers, tensor_table)",
            "def _generate_tensor_table(self, filtered_data: OrderedDict[str, Dict[str, Any]], tensor_features: List[str]) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in the filtered data and features list and generates the tensor headers and table\\n\\n        Currently meant to generate the headers and table for both the tensor information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Dict[str, Any]]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            tensor_features (List[str]): A list of the tensor level features\\n\\n        Returns a tuple with:\\n            A list of the headers of the tensor table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    tensor_table: List[List[Any]] = []\n    tensor_headers: List[str] = []\n    if len(tensor_features) > 0:\n        for (index, module_fqn) in enumerate(filtered_data):\n            tensor_table_row = [index, module_fqn]\n            for feature in tensor_features:\n                if feature in filtered_data[module_fqn]:\n                    feature_val = filtered_data[module_fqn][feature]\n                else:\n                    feature_val = 'Not Applicable'\n                if isinstance(feature_val, torch.Tensor):\n                    feature_val = feature_val.item()\n                tensor_table_row.append(feature_val)\n            tensor_table.append(tensor_table_row)\n    if len(tensor_table) != 0:\n        tensor_headers = ['idx', 'layer_fqn'] + tensor_features\n    return (tensor_headers, tensor_table)",
            "def _generate_tensor_table(self, filtered_data: OrderedDict[str, Dict[str, Any]], tensor_features: List[str]) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in the filtered data and features list and generates the tensor headers and table\\n\\n        Currently meant to generate the headers and table for both the tensor information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Dict[str, Any]]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            tensor_features (List[str]): A list of the tensor level features\\n\\n        Returns a tuple with:\\n            A list of the headers of the tensor table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    tensor_table: List[List[Any]] = []\n    tensor_headers: List[str] = []\n    if len(tensor_features) > 0:\n        for (index, module_fqn) in enumerate(filtered_data):\n            tensor_table_row = [index, module_fqn]\n            for feature in tensor_features:\n                if feature in filtered_data[module_fqn]:\n                    feature_val = filtered_data[module_fqn][feature]\n                else:\n                    feature_val = 'Not Applicable'\n                if isinstance(feature_val, torch.Tensor):\n                    feature_val = feature_val.item()\n                tensor_table_row.append(feature_val)\n            tensor_table.append(tensor_table_row)\n    if len(tensor_table) != 0:\n        tensor_headers = ['idx', 'layer_fqn'] + tensor_features\n    return (tensor_headers, tensor_table)",
            "def _generate_tensor_table(self, filtered_data: OrderedDict[str, Dict[str, Any]], tensor_features: List[str]) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in the filtered data and features list and generates the tensor headers and table\\n\\n        Currently meant to generate the headers and table for both the tensor information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Dict[str, Any]]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            tensor_features (List[str]): A list of the tensor level features\\n\\n        Returns a tuple with:\\n            A list of the headers of the tensor table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    tensor_table: List[List[Any]] = []\n    tensor_headers: List[str] = []\n    if len(tensor_features) > 0:\n        for (index, module_fqn) in enumerate(filtered_data):\n            tensor_table_row = [index, module_fqn]\n            for feature in tensor_features:\n                if feature in filtered_data[module_fqn]:\n                    feature_val = filtered_data[module_fqn][feature]\n                else:\n                    feature_val = 'Not Applicable'\n                if isinstance(feature_val, torch.Tensor):\n                    feature_val = feature_val.item()\n                tensor_table_row.append(feature_val)\n            tensor_table.append(tensor_table_row)\n    if len(tensor_table) != 0:\n        tensor_headers = ['idx', 'layer_fqn'] + tensor_features\n    return (tensor_headers, tensor_table)",
            "def _generate_tensor_table(self, filtered_data: OrderedDict[str, Dict[str, Any]], tensor_features: List[str]) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in the filtered data and features list and generates the tensor headers and table\\n\\n        Currently meant to generate the headers and table for both the tensor information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Dict[str, Any]]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            tensor_features (List[str]): A list of the tensor level features\\n\\n        Returns a tuple with:\\n            A list of the headers of the tensor table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    tensor_table: List[List[Any]] = []\n    tensor_headers: List[str] = []\n    if len(tensor_features) > 0:\n        for (index, module_fqn) in enumerate(filtered_data):\n            tensor_table_row = [index, module_fqn]\n            for feature in tensor_features:\n                if feature in filtered_data[module_fqn]:\n                    feature_val = filtered_data[module_fqn][feature]\n                else:\n                    feature_val = 'Not Applicable'\n                if isinstance(feature_val, torch.Tensor):\n                    feature_val = feature_val.item()\n                tensor_table_row.append(feature_val)\n            tensor_table.append(tensor_table_row)\n    if len(tensor_table) != 0:\n        tensor_headers = ['idx', 'layer_fqn'] + tensor_features\n    return (tensor_headers, tensor_table)"
        ]
    },
    {
        "func_name": "_generate_channels_table",
        "original": "def _generate_channels_table(self, filtered_data: OrderedDict[str, Any], channel_features: List[str], num_channels: int) -> Tuple[List, List]:\n    \"\"\"\n        Takes in the filtered data and features list and generates the channels headers and table\n\n        Currently meant to generate the headers and table for both the channels information.\n\n        Args:\n            filtered_data (OrderedDict[str, Any]): An OrderedDict (sorted in order of model) mapping:\n                module_fqns -> feature_names -> values\n            channel_features (List[str]): A list of the channel level features\n            num_channels (int): Number of channels in the channel data\n\n        Returns a tuple with:\n            A list of the headers of the channel table\n            A list of lists containing the table information row by row\n            The 0th index row will contain the headers of the columns\n            The rest of the rows will contain data\n        \"\"\"\n    channel_table: List[List[Any]] = []\n    channel_headers: List[str] = []\n    channel_table_entry_counter: int = 0\n    if len(channel_features) > 0:\n        for module_fqn in filtered_data:\n            for channel in range(num_channels):\n                new_channel_row = [channel_table_entry_counter, module_fqn, channel]\n                for feature in channel_features:\n                    if feature in filtered_data[module_fqn]:\n                        feature_val = filtered_data[module_fqn][feature][channel]\n                    else:\n                        feature_val = 'Not Applicable'\n                    if type(feature_val) is torch.Tensor:\n                        feature_val = feature_val.item()\n                    new_channel_row.append(feature_val)\n                channel_table.append(new_channel_row)\n                channel_table_entry_counter += 1\n    if len(channel_table) != 0:\n        channel_headers = ['idx', 'layer_fqn', 'channel'] + channel_features\n    return (channel_headers, channel_table)",
        "mutated": [
            "def _generate_channels_table(self, filtered_data: OrderedDict[str, Any], channel_features: List[str], num_channels: int) -> Tuple[List, List]:\n    if False:\n        i = 10\n    '\\n        Takes in the filtered data and features list and generates the channels headers and table\\n\\n        Currently meant to generate the headers and table for both the channels information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Any]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            channel_features (List[str]): A list of the channel level features\\n            num_channels (int): Number of channels in the channel data\\n\\n        Returns a tuple with:\\n            A list of the headers of the channel table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    channel_table: List[List[Any]] = []\n    channel_headers: List[str] = []\n    channel_table_entry_counter: int = 0\n    if len(channel_features) > 0:\n        for module_fqn in filtered_data:\n            for channel in range(num_channels):\n                new_channel_row = [channel_table_entry_counter, module_fqn, channel]\n                for feature in channel_features:\n                    if feature in filtered_data[module_fqn]:\n                        feature_val = filtered_data[module_fqn][feature][channel]\n                    else:\n                        feature_val = 'Not Applicable'\n                    if type(feature_val) is torch.Tensor:\n                        feature_val = feature_val.item()\n                    new_channel_row.append(feature_val)\n                channel_table.append(new_channel_row)\n                channel_table_entry_counter += 1\n    if len(channel_table) != 0:\n        channel_headers = ['idx', 'layer_fqn', 'channel'] + channel_features\n    return (channel_headers, channel_table)",
            "def _generate_channels_table(self, filtered_data: OrderedDict[str, Any], channel_features: List[str], num_channels: int) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in the filtered data and features list and generates the channels headers and table\\n\\n        Currently meant to generate the headers and table for both the channels information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Any]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            channel_features (List[str]): A list of the channel level features\\n            num_channels (int): Number of channels in the channel data\\n\\n        Returns a tuple with:\\n            A list of the headers of the channel table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    channel_table: List[List[Any]] = []\n    channel_headers: List[str] = []\n    channel_table_entry_counter: int = 0\n    if len(channel_features) > 0:\n        for module_fqn in filtered_data:\n            for channel in range(num_channels):\n                new_channel_row = [channel_table_entry_counter, module_fqn, channel]\n                for feature in channel_features:\n                    if feature in filtered_data[module_fqn]:\n                        feature_val = filtered_data[module_fqn][feature][channel]\n                    else:\n                        feature_val = 'Not Applicable'\n                    if type(feature_val) is torch.Tensor:\n                        feature_val = feature_val.item()\n                    new_channel_row.append(feature_val)\n                channel_table.append(new_channel_row)\n                channel_table_entry_counter += 1\n    if len(channel_table) != 0:\n        channel_headers = ['idx', 'layer_fqn', 'channel'] + channel_features\n    return (channel_headers, channel_table)",
            "def _generate_channels_table(self, filtered_data: OrderedDict[str, Any], channel_features: List[str], num_channels: int) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in the filtered data and features list and generates the channels headers and table\\n\\n        Currently meant to generate the headers and table for both the channels information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Any]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            channel_features (List[str]): A list of the channel level features\\n            num_channels (int): Number of channels in the channel data\\n\\n        Returns a tuple with:\\n            A list of the headers of the channel table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    channel_table: List[List[Any]] = []\n    channel_headers: List[str] = []\n    channel_table_entry_counter: int = 0\n    if len(channel_features) > 0:\n        for module_fqn in filtered_data:\n            for channel in range(num_channels):\n                new_channel_row = [channel_table_entry_counter, module_fqn, channel]\n                for feature in channel_features:\n                    if feature in filtered_data[module_fqn]:\n                        feature_val = filtered_data[module_fqn][feature][channel]\n                    else:\n                        feature_val = 'Not Applicable'\n                    if type(feature_val) is torch.Tensor:\n                        feature_val = feature_val.item()\n                    new_channel_row.append(feature_val)\n                channel_table.append(new_channel_row)\n                channel_table_entry_counter += 1\n    if len(channel_table) != 0:\n        channel_headers = ['idx', 'layer_fqn', 'channel'] + channel_features\n    return (channel_headers, channel_table)",
            "def _generate_channels_table(self, filtered_data: OrderedDict[str, Any], channel_features: List[str], num_channels: int) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in the filtered data and features list and generates the channels headers and table\\n\\n        Currently meant to generate the headers and table for both the channels information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Any]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            channel_features (List[str]): A list of the channel level features\\n            num_channels (int): Number of channels in the channel data\\n\\n        Returns a tuple with:\\n            A list of the headers of the channel table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    channel_table: List[List[Any]] = []\n    channel_headers: List[str] = []\n    channel_table_entry_counter: int = 0\n    if len(channel_features) > 0:\n        for module_fqn in filtered_data:\n            for channel in range(num_channels):\n                new_channel_row = [channel_table_entry_counter, module_fqn, channel]\n                for feature in channel_features:\n                    if feature in filtered_data[module_fqn]:\n                        feature_val = filtered_data[module_fqn][feature][channel]\n                    else:\n                        feature_val = 'Not Applicable'\n                    if type(feature_val) is torch.Tensor:\n                        feature_val = feature_val.item()\n                    new_channel_row.append(feature_val)\n                channel_table.append(new_channel_row)\n                channel_table_entry_counter += 1\n    if len(channel_table) != 0:\n        channel_headers = ['idx', 'layer_fqn', 'channel'] + channel_features\n    return (channel_headers, channel_table)",
            "def _generate_channels_table(self, filtered_data: OrderedDict[str, Any], channel_features: List[str], num_channels: int) -> Tuple[List, List]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in the filtered data and features list and generates the channels headers and table\\n\\n        Currently meant to generate the headers and table for both the channels information.\\n\\n        Args:\\n            filtered_data (OrderedDict[str, Any]): An OrderedDict (sorted in order of model) mapping:\\n                module_fqns -> feature_names -> values\\n            channel_features (List[str]): A list of the channel level features\\n            num_channels (int): Number of channels in the channel data\\n\\n        Returns a tuple with:\\n            A list of the headers of the channel table\\n            A list of lists containing the table information row by row\\n            The 0th index row will contain the headers of the columns\\n            The rest of the rows will contain data\\n        '\n    channel_table: List[List[Any]] = []\n    channel_headers: List[str] = []\n    channel_table_entry_counter: int = 0\n    if len(channel_features) > 0:\n        for module_fqn in filtered_data:\n            for channel in range(num_channels):\n                new_channel_row = [channel_table_entry_counter, module_fqn, channel]\n                for feature in channel_features:\n                    if feature in filtered_data[module_fqn]:\n                        feature_val = filtered_data[module_fqn][feature][channel]\n                    else:\n                        feature_val = 'Not Applicable'\n                    if type(feature_val) is torch.Tensor:\n                        feature_val = feature_val.item()\n                    new_channel_row.append(feature_val)\n                channel_table.append(new_channel_row)\n                channel_table_entry_counter += 1\n    if len(channel_table) != 0:\n        channel_headers = ['idx', 'layer_fqn', 'channel'] + channel_features\n    return (channel_headers, channel_table)"
        ]
    },
    {
        "func_name": "generate_filtered_tables",
        "original": "def generate_filtered_tables(self, feature_filter: str='', module_fqn_filter: str='') -> Dict[str, Tuple[List, List]]:\n    \"\"\"\n        Takes in optional filter values and generates two tables with desired information.\n\n        The generated tables are presented in both a list-of-lists format\n\n        The reason for the two tables are that they handle different things:\n        1.) the first table handles all tensor level information\n        2.) the second table handles and displays all channel based information\n\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\n            statistics are global, and which are actually per-channel, so it's better to split it up into two\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\n\n        Tensor table columns:\n            idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\n            ----  ---------  ---------   ---------   ---------        ---------\n\n        Per-Channel table columns:\n            idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\n            ----  ---------  -------  ---------   ---------   ---------        ---------\n\n        Args:\n            feature_filter (str, optional): Filters the features presented to only those that\n                contain this filter substring\n                Default = \"\", results in all the features being printed\n            module_fqn_filter (str, optional): Only includes modules that contains this string\n                Default = \"\", results in all the modules in the reports to be visible in the table\n\n        Returns a dictionary with two keys:\n            (Dict[str, Tuple[List, List]]) A dict containing two keys:\n            \"tensor_level_info\", \"channel_level_info\"\n                Each key maps to a tuple with:\n                    A list of the headers of each table\n                    A list of lists containing the table information row by row\n                    The 0th index row will contain the headers of the columns\n                    The rest of the rows will contain data\n\n        Example Use:\n            >>> # xdoctest: +SKIP(\"undefined variables\")\n            >>> mod_report_visualizer.generate_filtered_tables(\n            ...     feature_filter = \"per_channel_min\",\n            ...     module_fqn_filter = \"block1\"\n            ... ) # generates table with per_channel_min info for all modules in block 1 of the model\n        \"\"\"\n    filtered_data: OrderedDict[str, Any] = self._get_filtered_data(feature_filter, module_fqn_filter)\n    tensor_features: Set[str] = set()\n    channel_features: Set[str] = set()\n    num_channels: int = 0\n    for module_fqn in filtered_data:\n        for feature_name in filtered_data[module_fqn]:\n            feature_data = filtered_data[module_fqn][feature_name]\n            is_tensor: bool = isinstance(feature_data, torch.Tensor)\n            is_not_zero_dim: bool = is_tensor and len(feature_data.shape) != 0\n            if is_not_zero_dim or isinstance(feature_data, list):\n                channel_features.add(feature_name)\n                num_channels = len(feature_data)\n            else:\n                tensor_features.add(feature_name)\n    tensor_features_list: List[str] = sorted(tensor_features)\n    channel_features_list: List[str] = sorted(channel_features)\n    (tensor_headers, tensor_table) = self._generate_tensor_table(filtered_data, tensor_features_list)\n    (channel_headers, channel_table) = self._generate_channels_table(filtered_data, channel_features_list, num_channels)\n    table_dict = {self.TABLE_TENSOR_KEY: (tensor_headers, tensor_table), self.TABLE_CHANNEL_KEY: (channel_headers, channel_table)}\n    return table_dict",
        "mutated": [
            "def generate_filtered_tables(self, feature_filter: str='', module_fqn_filter: str='') -> Dict[str, Tuple[List, List]]:\n    if False:\n        i = 10\n    '\\n        Takes in optional filter values and generates two tables with desired information.\\n\\n        The generated tables are presented in both a list-of-lists format\\n\\n        The reason for the two tables are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n            idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n            idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Returns a dictionary with two keys:\\n            (Dict[str, Tuple[List, List]]) A dict containing two keys:\\n            \"tensor_level_info\", \"channel_level_info\"\\n                Each key maps to a tuple with:\\n                    A list of the headers of each table\\n                    A list of lists containing the table information row by row\\n                    The 0th index row will contain the headers of the columns\\n                    The rest of the rows will contain data\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_filtered_tables(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... ) # generates table with per_channel_min info for all modules in block 1 of the model\\n        '\n    filtered_data: OrderedDict[str, Any] = self._get_filtered_data(feature_filter, module_fqn_filter)\n    tensor_features: Set[str] = set()\n    channel_features: Set[str] = set()\n    num_channels: int = 0\n    for module_fqn in filtered_data:\n        for feature_name in filtered_data[module_fqn]:\n            feature_data = filtered_data[module_fqn][feature_name]\n            is_tensor: bool = isinstance(feature_data, torch.Tensor)\n            is_not_zero_dim: bool = is_tensor and len(feature_data.shape) != 0\n            if is_not_zero_dim or isinstance(feature_data, list):\n                channel_features.add(feature_name)\n                num_channels = len(feature_data)\n            else:\n                tensor_features.add(feature_name)\n    tensor_features_list: List[str] = sorted(tensor_features)\n    channel_features_list: List[str] = sorted(channel_features)\n    (tensor_headers, tensor_table) = self._generate_tensor_table(filtered_data, tensor_features_list)\n    (channel_headers, channel_table) = self._generate_channels_table(filtered_data, channel_features_list, num_channels)\n    table_dict = {self.TABLE_TENSOR_KEY: (tensor_headers, tensor_table), self.TABLE_CHANNEL_KEY: (channel_headers, channel_table)}\n    return table_dict",
            "def generate_filtered_tables(self, feature_filter: str='', module_fqn_filter: str='') -> Dict[str, Tuple[List, List]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in optional filter values and generates two tables with desired information.\\n\\n        The generated tables are presented in both a list-of-lists format\\n\\n        The reason for the two tables are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n            idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n            idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Returns a dictionary with two keys:\\n            (Dict[str, Tuple[List, List]]) A dict containing two keys:\\n            \"tensor_level_info\", \"channel_level_info\"\\n                Each key maps to a tuple with:\\n                    A list of the headers of each table\\n                    A list of lists containing the table information row by row\\n                    The 0th index row will contain the headers of the columns\\n                    The rest of the rows will contain data\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_filtered_tables(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... ) # generates table with per_channel_min info for all modules in block 1 of the model\\n        '\n    filtered_data: OrderedDict[str, Any] = self._get_filtered_data(feature_filter, module_fqn_filter)\n    tensor_features: Set[str] = set()\n    channel_features: Set[str] = set()\n    num_channels: int = 0\n    for module_fqn in filtered_data:\n        for feature_name in filtered_data[module_fqn]:\n            feature_data = filtered_data[module_fqn][feature_name]\n            is_tensor: bool = isinstance(feature_data, torch.Tensor)\n            is_not_zero_dim: bool = is_tensor and len(feature_data.shape) != 0\n            if is_not_zero_dim or isinstance(feature_data, list):\n                channel_features.add(feature_name)\n                num_channels = len(feature_data)\n            else:\n                tensor_features.add(feature_name)\n    tensor_features_list: List[str] = sorted(tensor_features)\n    channel_features_list: List[str] = sorted(channel_features)\n    (tensor_headers, tensor_table) = self._generate_tensor_table(filtered_data, tensor_features_list)\n    (channel_headers, channel_table) = self._generate_channels_table(filtered_data, channel_features_list, num_channels)\n    table_dict = {self.TABLE_TENSOR_KEY: (tensor_headers, tensor_table), self.TABLE_CHANNEL_KEY: (channel_headers, channel_table)}\n    return table_dict",
            "def generate_filtered_tables(self, feature_filter: str='', module_fqn_filter: str='') -> Dict[str, Tuple[List, List]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in optional filter values and generates two tables with desired information.\\n\\n        The generated tables are presented in both a list-of-lists format\\n\\n        The reason for the two tables are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n            idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n            idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Returns a dictionary with two keys:\\n            (Dict[str, Tuple[List, List]]) A dict containing two keys:\\n            \"tensor_level_info\", \"channel_level_info\"\\n                Each key maps to a tuple with:\\n                    A list of the headers of each table\\n                    A list of lists containing the table information row by row\\n                    The 0th index row will contain the headers of the columns\\n                    The rest of the rows will contain data\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_filtered_tables(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... ) # generates table with per_channel_min info for all modules in block 1 of the model\\n        '\n    filtered_data: OrderedDict[str, Any] = self._get_filtered_data(feature_filter, module_fqn_filter)\n    tensor_features: Set[str] = set()\n    channel_features: Set[str] = set()\n    num_channels: int = 0\n    for module_fqn in filtered_data:\n        for feature_name in filtered_data[module_fqn]:\n            feature_data = filtered_data[module_fqn][feature_name]\n            is_tensor: bool = isinstance(feature_data, torch.Tensor)\n            is_not_zero_dim: bool = is_tensor and len(feature_data.shape) != 0\n            if is_not_zero_dim or isinstance(feature_data, list):\n                channel_features.add(feature_name)\n                num_channels = len(feature_data)\n            else:\n                tensor_features.add(feature_name)\n    tensor_features_list: List[str] = sorted(tensor_features)\n    channel_features_list: List[str] = sorted(channel_features)\n    (tensor_headers, tensor_table) = self._generate_tensor_table(filtered_data, tensor_features_list)\n    (channel_headers, channel_table) = self._generate_channels_table(filtered_data, channel_features_list, num_channels)\n    table_dict = {self.TABLE_TENSOR_KEY: (tensor_headers, tensor_table), self.TABLE_CHANNEL_KEY: (channel_headers, channel_table)}\n    return table_dict",
            "def generate_filtered_tables(self, feature_filter: str='', module_fqn_filter: str='') -> Dict[str, Tuple[List, List]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in optional filter values and generates two tables with desired information.\\n\\n        The generated tables are presented in both a list-of-lists format\\n\\n        The reason for the two tables are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n            idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n            idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Returns a dictionary with two keys:\\n            (Dict[str, Tuple[List, List]]) A dict containing two keys:\\n            \"tensor_level_info\", \"channel_level_info\"\\n                Each key maps to a tuple with:\\n                    A list of the headers of each table\\n                    A list of lists containing the table information row by row\\n                    The 0th index row will contain the headers of the columns\\n                    The rest of the rows will contain data\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_filtered_tables(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... ) # generates table with per_channel_min info for all modules in block 1 of the model\\n        '\n    filtered_data: OrderedDict[str, Any] = self._get_filtered_data(feature_filter, module_fqn_filter)\n    tensor_features: Set[str] = set()\n    channel_features: Set[str] = set()\n    num_channels: int = 0\n    for module_fqn in filtered_data:\n        for feature_name in filtered_data[module_fqn]:\n            feature_data = filtered_data[module_fqn][feature_name]\n            is_tensor: bool = isinstance(feature_data, torch.Tensor)\n            is_not_zero_dim: bool = is_tensor and len(feature_data.shape) != 0\n            if is_not_zero_dim or isinstance(feature_data, list):\n                channel_features.add(feature_name)\n                num_channels = len(feature_data)\n            else:\n                tensor_features.add(feature_name)\n    tensor_features_list: List[str] = sorted(tensor_features)\n    channel_features_list: List[str] = sorted(channel_features)\n    (tensor_headers, tensor_table) = self._generate_tensor_table(filtered_data, tensor_features_list)\n    (channel_headers, channel_table) = self._generate_channels_table(filtered_data, channel_features_list, num_channels)\n    table_dict = {self.TABLE_TENSOR_KEY: (tensor_headers, tensor_table), self.TABLE_CHANNEL_KEY: (channel_headers, channel_table)}\n    return table_dict",
            "def generate_filtered_tables(self, feature_filter: str='', module_fqn_filter: str='') -> Dict[str, Tuple[List, List]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in optional filter values and generates two tables with desired information.\\n\\n        The generated tables are presented in both a list-of-lists format\\n\\n        The reason for the two tables are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n            idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n            idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n            ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Returns a dictionary with two keys:\\n            (Dict[str, Tuple[List, List]]) A dict containing two keys:\\n            \"tensor_level_info\", \"channel_level_info\"\\n                Each key maps to a tuple with:\\n                    A list of the headers of each table\\n                    A list of lists containing the table information row by row\\n                    The 0th index row will contain the headers of the columns\\n                    The rest of the rows will contain data\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_filtered_tables(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... ) # generates table with per_channel_min info for all modules in block 1 of the model\\n        '\n    filtered_data: OrderedDict[str, Any] = self._get_filtered_data(feature_filter, module_fqn_filter)\n    tensor_features: Set[str] = set()\n    channel_features: Set[str] = set()\n    num_channels: int = 0\n    for module_fqn in filtered_data:\n        for feature_name in filtered_data[module_fqn]:\n            feature_data = filtered_data[module_fqn][feature_name]\n            is_tensor: bool = isinstance(feature_data, torch.Tensor)\n            is_not_zero_dim: bool = is_tensor and len(feature_data.shape) != 0\n            if is_not_zero_dim or isinstance(feature_data, list):\n                channel_features.add(feature_name)\n                num_channels = len(feature_data)\n            else:\n                tensor_features.add(feature_name)\n    tensor_features_list: List[str] = sorted(tensor_features)\n    channel_features_list: List[str] = sorted(channel_features)\n    (tensor_headers, tensor_table) = self._generate_tensor_table(filtered_data, tensor_features_list)\n    (channel_headers, channel_table) = self._generate_channels_table(filtered_data, channel_features_list, num_channels)\n    table_dict = {self.TABLE_TENSOR_KEY: (tensor_headers, tensor_table), self.TABLE_CHANNEL_KEY: (channel_headers, channel_table)}\n    return table_dict"
        ]
    },
    {
        "func_name": "generate_table_visualization",
        "original": "def generate_table_visualization(self, feature_filter: str='', module_fqn_filter: str=''):\n    \"\"\"\n        Takes in optional filter values and prints out formatted tables of the information.\n\n        The reason for the two tables printed out instead of one large one are that they handle different things:\n        1.) the first table handles all tensor level information\n        2.) the second table handles and displays all channel based information\n\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\n            statistics are global, and which are actually per-channel, so it's better to split it up into two\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\n\n        Tensor table columns:\n         idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\n        ----  ---------  ---------   ---------   ---------        ---------\n\n        Per-Channel table columns:\n\n         idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\n        ----  ---------  -------  ---------   ---------   ---------        ---------\n\n        Args:\n            feature_filter (str, optional): Filters the features presented to only those that\n                contain this filter substring\n                Default = \"\", results in all the features being printed\n            module_fqn_filter (str, optional): Only includes modules that contains this string\n                Default = \"\", results in all the modules in the reports to be visible in the table\n\n        Example Use:\n            >>> # xdoctest: +SKIP(\"undefined variables\")\n            >>> mod_report_visualizer.generate_table_visualization(\n            ...     feature_filter = \"per_channel_min\",\n            ...     module_fqn_filter = \"block1\"\n            ... )\n            >>> # prints out neatly formatted table with per_channel_min info\n            >>> # for all modules in block 1 of the model\n        \"\"\"\n    if not got_tabulate:\n        print('Make sure to install tabulate and try again.')\n        return None\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    table_str = ''\n    if len(tensor_headers) > self.NUM_NON_FEATURE_TENSOR_HEADERS:\n        table_str += 'Tensor Level Information \\n'\n        table_str += tabulate(tensor_table, headers=tensor_headers)\n    if len(channel_headers) > self.NUM_NON_FEATURE_CHANNEL_HEADERS:\n        table_str += '\\n\\n Channel Level Information \\n'\n        table_str += tabulate(channel_table, headers=channel_headers)\n    if table_str == '':\n        table_str = 'No data points to generate table with.'\n    print(table_str)",
        "mutated": [
            "def generate_table_visualization(self, feature_filter: str='', module_fqn_filter: str=''):\n    if False:\n        i = 10\n    '\\n        Takes in optional filter values and prints out formatted tables of the information.\\n\\n        The reason for the two tables printed out instead of one large one are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n         idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n\\n         idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_table_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # prints out neatly formatted table with per_channel_min info\\n            >>> # for all modules in block 1 of the model\\n        '\n    if not got_tabulate:\n        print('Make sure to install tabulate and try again.')\n        return None\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    table_str = ''\n    if len(tensor_headers) > self.NUM_NON_FEATURE_TENSOR_HEADERS:\n        table_str += 'Tensor Level Information \\n'\n        table_str += tabulate(tensor_table, headers=tensor_headers)\n    if len(channel_headers) > self.NUM_NON_FEATURE_CHANNEL_HEADERS:\n        table_str += '\\n\\n Channel Level Information \\n'\n        table_str += tabulate(channel_table, headers=channel_headers)\n    if table_str == '':\n        table_str = 'No data points to generate table with.'\n    print(table_str)",
            "def generate_table_visualization(self, feature_filter: str='', module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in optional filter values and prints out formatted tables of the information.\\n\\n        The reason for the two tables printed out instead of one large one are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n         idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n\\n         idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_table_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # prints out neatly formatted table with per_channel_min info\\n            >>> # for all modules in block 1 of the model\\n        '\n    if not got_tabulate:\n        print('Make sure to install tabulate and try again.')\n        return None\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    table_str = ''\n    if len(tensor_headers) > self.NUM_NON_FEATURE_TENSOR_HEADERS:\n        table_str += 'Tensor Level Information \\n'\n        table_str += tabulate(tensor_table, headers=tensor_headers)\n    if len(channel_headers) > self.NUM_NON_FEATURE_CHANNEL_HEADERS:\n        table_str += '\\n\\n Channel Level Information \\n'\n        table_str += tabulate(channel_table, headers=channel_headers)\n    if table_str == '':\n        table_str = 'No data points to generate table with.'\n    print(table_str)",
            "def generate_table_visualization(self, feature_filter: str='', module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in optional filter values and prints out formatted tables of the information.\\n\\n        The reason for the two tables printed out instead of one large one are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n         idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n\\n         idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_table_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # prints out neatly formatted table with per_channel_min info\\n            >>> # for all modules in block 1 of the model\\n        '\n    if not got_tabulate:\n        print('Make sure to install tabulate and try again.')\n        return None\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    table_str = ''\n    if len(tensor_headers) > self.NUM_NON_FEATURE_TENSOR_HEADERS:\n        table_str += 'Tensor Level Information \\n'\n        table_str += tabulate(tensor_table, headers=tensor_headers)\n    if len(channel_headers) > self.NUM_NON_FEATURE_CHANNEL_HEADERS:\n        table_str += '\\n\\n Channel Level Information \\n'\n        table_str += tabulate(channel_table, headers=channel_headers)\n    if table_str == '':\n        table_str = 'No data points to generate table with.'\n    print(table_str)",
            "def generate_table_visualization(self, feature_filter: str='', module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in optional filter values and prints out formatted tables of the information.\\n\\n        The reason for the two tables printed out instead of one large one are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n         idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n\\n         idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_table_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # prints out neatly formatted table with per_channel_min info\\n            >>> # for all modules in block 1 of the model\\n        '\n    if not got_tabulate:\n        print('Make sure to install tabulate and try again.')\n        return None\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    table_str = ''\n    if len(tensor_headers) > self.NUM_NON_FEATURE_TENSOR_HEADERS:\n        table_str += 'Tensor Level Information \\n'\n        table_str += tabulate(tensor_table, headers=tensor_headers)\n    if len(channel_headers) > self.NUM_NON_FEATURE_CHANNEL_HEADERS:\n        table_str += '\\n\\n Channel Level Information \\n'\n        table_str += tabulate(channel_table, headers=channel_headers)\n    if table_str == '':\n        table_str = 'No data points to generate table with.'\n    print(table_str)",
            "def generate_table_visualization(self, feature_filter: str='', module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in optional filter values and prints out formatted tables of the information.\\n\\n        The reason for the two tables printed out instead of one large one are that they handle different things:\\n        1.) the first table handles all tensor level information\\n        2.) the second table handles and displays all channel based information\\n\\n        The reasoning for this is that having all the info in one table can make it ambiguous which collected\\n            statistics are global, and which are actually per-channel, so it\\'s better to split it up into two\\n            tables. This also makes the information much easier to digest given the plethora of statistics collected\\n\\n        Tensor table columns:\\n         idx  layer_fqn  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  ---------   ---------   ---------        ---------\\n\\n        Per-Channel table columns:\\n\\n         idx  layer_fqn  channel  feature_1   feature_2   feature_3   .... feature_n\\n        ----  ---------  -------  ---------   ---------   ---------        ---------\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_table_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # prints out neatly formatted table with per_channel_min info\\n            >>> # for all modules in block 1 of the model\\n        '\n    if not got_tabulate:\n        print('Make sure to install tabulate and try again.')\n        return None\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    table_str = ''\n    if len(tensor_headers) > self.NUM_NON_FEATURE_TENSOR_HEADERS:\n        table_str += 'Tensor Level Information \\n'\n        table_str += tabulate(tensor_table, headers=tensor_headers)\n    if len(channel_headers) > self.NUM_NON_FEATURE_CHANNEL_HEADERS:\n        table_str += '\\n\\n Channel Level Information \\n'\n        table_str += tabulate(channel_table, headers=channel_headers)\n    if table_str == '':\n        table_str = 'No data points to generate table with.'\n    print(table_str)"
        ]
    },
    {
        "func_name": "_get_plottable_data",
        "original": "def _get_plottable_data(self, feature_filter: str, module_fqn_filter: str) -> Tuple[List, List[List], bool]:\n    \"\"\"\n        Takes in the feature filters and module filters and outputs the x and y data for plotting\n\n        Args:\n            feature_filter (str): Filters the features presented to only those that\n                contain this filter substring\n            module_fqn_filter (str): Only includes modules that contains this string\n\n        Returns a tuple of three elements\n            The first is a list containing relevant x-axis data\n            The second is a list containing the corresponding y-axis data\n            If the data is per channel\n        \"\"\"\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    tensor_info_features_count = len(tensor_headers) - ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    channel_info_features_count = len(channel_headers) - ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n    is_valid_per_tensor_plot: bool = tensor_info_features_count == 1\n    is_valid_per_channel_plot: bool = channel_info_features_count == 1\n    feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    table = tensor_table\n    if is_valid_per_channel_plot:\n        feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n        table = channel_table\n    x_data: List = []\n    y_data: List[List] = []\n    if is_valid_per_tensor_plot:\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                x_data.append(x_val_to_append)\n                y_data.append(row_value)\n    elif is_valid_per_channel_plot:\n        num_channels: int = max((row[self.CHANNEL_NUM_INDEX] for row in table)) + 1\n        for channel in range(num_channels):\n            y_data.append([])\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            current_channel = row[self.CHANNEL_NUM_INDEX]\n            new_module_index: int = table_row_num // num_channels\n            x_val_to_append = new_module_index\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                if len(x_data) == 0 or x_data[-1] != x_val_to_append:\n                    x_data.append(x_val_to_append)\n                y_data[current_channel].append(row_value)\n    else:\n        error_str = 'Make sure to pick only a single feature with your filter to plot a graph.'\n        error_str += ' We recommend calling get_all_unique_feature_names() to find unique feature names.'\n        error_str += ' Pick one of those features to plot.'\n        raise ValueError(error_str)\n    return (x_data, y_data, is_valid_per_channel_plot)",
        "mutated": [
            "def _get_plottable_data(self, feature_filter: str, module_fqn_filter: str) -> Tuple[List, List[List], bool]:\n    if False:\n        i = 10\n    '\\n        Takes in the feature filters and module filters and outputs the x and y data for plotting\\n\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str): Only includes modules that contains this string\\n\\n        Returns a tuple of three elements\\n            The first is a list containing relevant x-axis data\\n            The second is a list containing the corresponding y-axis data\\n            If the data is per channel\\n        '\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    tensor_info_features_count = len(tensor_headers) - ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    channel_info_features_count = len(channel_headers) - ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n    is_valid_per_tensor_plot: bool = tensor_info_features_count == 1\n    is_valid_per_channel_plot: bool = channel_info_features_count == 1\n    feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    table = tensor_table\n    if is_valid_per_channel_plot:\n        feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n        table = channel_table\n    x_data: List = []\n    y_data: List[List] = []\n    if is_valid_per_tensor_plot:\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                x_data.append(x_val_to_append)\n                y_data.append(row_value)\n    elif is_valid_per_channel_plot:\n        num_channels: int = max((row[self.CHANNEL_NUM_INDEX] for row in table)) + 1\n        for channel in range(num_channels):\n            y_data.append([])\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            current_channel = row[self.CHANNEL_NUM_INDEX]\n            new_module_index: int = table_row_num // num_channels\n            x_val_to_append = new_module_index\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                if len(x_data) == 0 or x_data[-1] != x_val_to_append:\n                    x_data.append(x_val_to_append)\n                y_data[current_channel].append(row_value)\n    else:\n        error_str = 'Make sure to pick only a single feature with your filter to plot a graph.'\n        error_str += ' We recommend calling get_all_unique_feature_names() to find unique feature names.'\n        error_str += ' Pick one of those features to plot.'\n        raise ValueError(error_str)\n    return (x_data, y_data, is_valid_per_channel_plot)",
            "def _get_plottable_data(self, feature_filter: str, module_fqn_filter: str) -> Tuple[List, List[List], bool]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in the feature filters and module filters and outputs the x and y data for plotting\\n\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str): Only includes modules that contains this string\\n\\n        Returns a tuple of three elements\\n            The first is a list containing relevant x-axis data\\n            The second is a list containing the corresponding y-axis data\\n            If the data is per channel\\n        '\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    tensor_info_features_count = len(tensor_headers) - ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    channel_info_features_count = len(channel_headers) - ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n    is_valid_per_tensor_plot: bool = tensor_info_features_count == 1\n    is_valid_per_channel_plot: bool = channel_info_features_count == 1\n    feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    table = tensor_table\n    if is_valid_per_channel_plot:\n        feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n        table = channel_table\n    x_data: List = []\n    y_data: List[List] = []\n    if is_valid_per_tensor_plot:\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                x_data.append(x_val_to_append)\n                y_data.append(row_value)\n    elif is_valid_per_channel_plot:\n        num_channels: int = max((row[self.CHANNEL_NUM_INDEX] for row in table)) + 1\n        for channel in range(num_channels):\n            y_data.append([])\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            current_channel = row[self.CHANNEL_NUM_INDEX]\n            new_module_index: int = table_row_num // num_channels\n            x_val_to_append = new_module_index\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                if len(x_data) == 0 or x_data[-1] != x_val_to_append:\n                    x_data.append(x_val_to_append)\n                y_data[current_channel].append(row_value)\n    else:\n        error_str = 'Make sure to pick only a single feature with your filter to plot a graph.'\n        error_str += ' We recommend calling get_all_unique_feature_names() to find unique feature names.'\n        error_str += ' Pick one of those features to plot.'\n        raise ValueError(error_str)\n    return (x_data, y_data, is_valid_per_channel_plot)",
            "def _get_plottable_data(self, feature_filter: str, module_fqn_filter: str) -> Tuple[List, List[List], bool]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in the feature filters and module filters and outputs the x and y data for plotting\\n\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str): Only includes modules that contains this string\\n\\n        Returns a tuple of three elements\\n            The first is a list containing relevant x-axis data\\n            The second is a list containing the corresponding y-axis data\\n            If the data is per channel\\n        '\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    tensor_info_features_count = len(tensor_headers) - ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    channel_info_features_count = len(channel_headers) - ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n    is_valid_per_tensor_plot: bool = tensor_info_features_count == 1\n    is_valid_per_channel_plot: bool = channel_info_features_count == 1\n    feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    table = tensor_table\n    if is_valid_per_channel_plot:\n        feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n        table = channel_table\n    x_data: List = []\n    y_data: List[List] = []\n    if is_valid_per_tensor_plot:\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                x_data.append(x_val_to_append)\n                y_data.append(row_value)\n    elif is_valid_per_channel_plot:\n        num_channels: int = max((row[self.CHANNEL_NUM_INDEX] for row in table)) + 1\n        for channel in range(num_channels):\n            y_data.append([])\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            current_channel = row[self.CHANNEL_NUM_INDEX]\n            new_module_index: int = table_row_num // num_channels\n            x_val_to_append = new_module_index\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                if len(x_data) == 0 or x_data[-1] != x_val_to_append:\n                    x_data.append(x_val_to_append)\n                y_data[current_channel].append(row_value)\n    else:\n        error_str = 'Make sure to pick only a single feature with your filter to plot a graph.'\n        error_str += ' We recommend calling get_all_unique_feature_names() to find unique feature names.'\n        error_str += ' Pick one of those features to plot.'\n        raise ValueError(error_str)\n    return (x_data, y_data, is_valid_per_channel_plot)",
            "def _get_plottable_data(self, feature_filter: str, module_fqn_filter: str) -> Tuple[List, List[List], bool]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in the feature filters and module filters and outputs the x and y data for plotting\\n\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str): Only includes modules that contains this string\\n\\n        Returns a tuple of three elements\\n            The first is a list containing relevant x-axis data\\n            The second is a list containing the corresponding y-axis data\\n            If the data is per channel\\n        '\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    tensor_info_features_count = len(tensor_headers) - ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    channel_info_features_count = len(channel_headers) - ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n    is_valid_per_tensor_plot: bool = tensor_info_features_count == 1\n    is_valid_per_channel_plot: bool = channel_info_features_count == 1\n    feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    table = tensor_table\n    if is_valid_per_channel_plot:\n        feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n        table = channel_table\n    x_data: List = []\n    y_data: List[List] = []\n    if is_valid_per_tensor_plot:\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                x_data.append(x_val_to_append)\n                y_data.append(row_value)\n    elif is_valid_per_channel_plot:\n        num_channels: int = max((row[self.CHANNEL_NUM_INDEX] for row in table)) + 1\n        for channel in range(num_channels):\n            y_data.append([])\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            current_channel = row[self.CHANNEL_NUM_INDEX]\n            new_module_index: int = table_row_num // num_channels\n            x_val_to_append = new_module_index\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                if len(x_data) == 0 or x_data[-1] != x_val_to_append:\n                    x_data.append(x_val_to_append)\n                y_data[current_channel].append(row_value)\n    else:\n        error_str = 'Make sure to pick only a single feature with your filter to plot a graph.'\n        error_str += ' We recommend calling get_all_unique_feature_names() to find unique feature names.'\n        error_str += ' Pick one of those features to plot.'\n        raise ValueError(error_str)\n    return (x_data, y_data, is_valid_per_channel_plot)",
            "def _get_plottable_data(self, feature_filter: str, module_fqn_filter: str) -> Tuple[List, List[List], bool]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in the feature filters and module filters and outputs the x and y data for plotting\\n\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str): Only includes modules that contains this string\\n\\n        Returns a tuple of three elements\\n            The first is a list containing relevant x-axis data\\n            The second is a list containing the corresponding y-axis data\\n            If the data is per channel\\n        '\n    table_dict = self.generate_filtered_tables(feature_filter, module_fqn_filter)\n    (tensor_headers, tensor_table) = table_dict[self.TABLE_TENSOR_KEY]\n    (channel_headers, channel_table) = table_dict[self.TABLE_CHANNEL_KEY]\n    tensor_info_features_count = len(tensor_headers) - ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    channel_info_features_count = len(channel_headers) - ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n    is_valid_per_tensor_plot: bool = tensor_info_features_count == 1\n    is_valid_per_channel_plot: bool = channel_info_features_count == 1\n    feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_TENSOR_HEADERS\n    table = tensor_table\n    if is_valid_per_channel_plot:\n        feature_column_offset = ModelReportVisualizer.NUM_NON_FEATURE_CHANNEL_HEADERS\n        table = channel_table\n    x_data: List = []\n    y_data: List[List] = []\n    if is_valid_per_tensor_plot:\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                x_data.append(x_val_to_append)\n                y_data.append(row_value)\n    elif is_valid_per_channel_plot:\n        num_channels: int = max((row[self.CHANNEL_NUM_INDEX] for row in table)) + 1\n        for channel in range(num_channels):\n            y_data.append([])\n        for (table_row_num, row) in enumerate(table):\n            x_val_to_append = table_row_num\n            current_channel = row[self.CHANNEL_NUM_INDEX]\n            new_module_index: int = table_row_num // num_channels\n            x_val_to_append = new_module_index\n            tensor_feature_index = feature_column_offset\n            row_value = row[tensor_feature_index]\n            if not type(row_value) == str:\n                if len(x_data) == 0 or x_data[-1] != x_val_to_append:\n                    x_data.append(x_val_to_append)\n                y_data[current_channel].append(row_value)\n    else:\n        error_str = 'Make sure to pick only a single feature with your filter to plot a graph.'\n        error_str += ' We recommend calling get_all_unique_feature_names() to find unique feature names.'\n        error_str += ' Pick one of those features to plot.'\n        raise ValueError(error_str)\n    return (x_data, y_data, is_valid_per_channel_plot)"
        ]
    },
    {
        "func_name": "generate_plot_visualization",
        "original": "def generate_plot_visualization(self, feature_filter: str, module_fqn_filter: str=''):\n    \"\"\"\n        Takes in a feature and optional module_filter and plots of the desired data.\n\n        For per channel features, it averages the value across the channels and plots a point\n        per module. The reason for this is that for models with hundreds of channels, it can\n        be hard to differentiate one channel line from another, and so the point of generating\n        a single average point per module is to give a sense of general trends that encourage\n        further deep dives.\n\n        Note:\n            Only features in the report that have tensor value data are plottable by this class\n            When the tensor information is plotted, it will plot:\n                idx as the x val, feature value as the y_val\n            When the channel information is plotted, it will plot:\n                the first idx of each module as the x val, feature value as the y_val [for each channel]\n                The reason for this is that we want to be able to compare values across the\n                channels for same layer, and it will be hard if values are staggered by idx\n                This means each module is represented by only 1 x value\n        Args:\n            feature_filter (str): Filters the features presented to only those that\n                contain this filter substring\n            module_fqn_filter (str, optional): Only includes modules that contains this string\n                Default = \"\", results in all the modules in the reports to be visible in the table\n\n        Example Use:\n            >>> # xdoctest: +SKIP(\"undefined variables\")\n            >>> mod_report_visualizer.generate_plot_visualization(\n            ...     feature_filter = \"per_channel_min\",\n            ...     module_fqn_filter = \"block1\"\n            ... )\n            >>> # outputs line plot of per_channel_min information for all\n            >>> # modules in block1 of model each channel gets it's own line,\n            >>> # and it's plotted across the in-order modules on the x-axis\n        \"\"\"\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_ylabel(feature_filter)\n    ax.set_title(feature_filter + ' Plot')\n    plt.xticks(x_data)\n    if data_per_channel:\n        ax.set_xlabel('First idx of module')\n        num_modules = len(y_data[0])\n        num_channels = len(y_data)\n        avg_vals = [sum(y_data[:][index]) / num_channels for index in range(num_modules)]\n        ax.plot(x_data, avg_vals, label=f'Average Value Across {num_channels} Channels')\n        ax.legend(loc='upper right')\n    else:\n        ax.set_xlabel('idx')\n        ax.plot(x_data, y_data)\n    plt.show()",
        "mutated": [
            "def generate_plot_visualization(self, feature_filter: str, module_fqn_filter: str=''):\n    if False:\n        i = 10\n    '\\n        Takes in a feature and optional module_filter and plots of the desired data.\\n\\n        For per channel features, it averages the value across the channels and plots a point\\n        per module. The reason for this is that for models with hundreds of channels, it can\\n        be hard to differentiate one channel line from another, and so the point of generating\\n        a single average point per module is to give a sense of general trends that encourage\\n        further deep dives.\\n\\n        Note:\\n            Only features in the report that have tensor value data are plottable by this class\\n            When the tensor information is plotted, it will plot:\\n                idx as the x val, feature value as the y_val\\n            When the channel information is plotted, it will plot:\\n                the first idx of each module as the x val, feature value as the y_val [for each channel]\\n                The reason for this is that we want to be able to compare values across the\\n                channels for same layer, and it will be hard if values are staggered by idx\\n                This means each module is represented by only 1 x value\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # outputs line plot of per_channel_min information for all\\n            >>> # modules in block1 of model each channel gets it\\'s own line,\\n            >>> # and it\\'s plotted across the in-order modules on the x-axis\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_ylabel(feature_filter)\n    ax.set_title(feature_filter + ' Plot')\n    plt.xticks(x_data)\n    if data_per_channel:\n        ax.set_xlabel('First idx of module')\n        num_modules = len(y_data[0])\n        num_channels = len(y_data)\n        avg_vals = [sum(y_data[:][index]) / num_channels for index in range(num_modules)]\n        ax.plot(x_data, avg_vals, label=f'Average Value Across {num_channels} Channels')\n        ax.legend(loc='upper right')\n    else:\n        ax.set_xlabel('idx')\n        ax.plot(x_data, y_data)\n    plt.show()",
            "def generate_plot_visualization(self, feature_filter: str, module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in a feature and optional module_filter and plots of the desired data.\\n\\n        For per channel features, it averages the value across the channels and plots a point\\n        per module. The reason for this is that for models with hundreds of channels, it can\\n        be hard to differentiate one channel line from another, and so the point of generating\\n        a single average point per module is to give a sense of general trends that encourage\\n        further deep dives.\\n\\n        Note:\\n            Only features in the report that have tensor value data are plottable by this class\\n            When the tensor information is plotted, it will plot:\\n                idx as the x val, feature value as the y_val\\n            When the channel information is plotted, it will plot:\\n                the first idx of each module as the x val, feature value as the y_val [for each channel]\\n                The reason for this is that we want to be able to compare values across the\\n                channels for same layer, and it will be hard if values are staggered by idx\\n                This means each module is represented by only 1 x value\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # outputs line plot of per_channel_min information for all\\n            >>> # modules in block1 of model each channel gets it\\'s own line,\\n            >>> # and it\\'s plotted across the in-order modules on the x-axis\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_ylabel(feature_filter)\n    ax.set_title(feature_filter + ' Plot')\n    plt.xticks(x_data)\n    if data_per_channel:\n        ax.set_xlabel('First idx of module')\n        num_modules = len(y_data[0])\n        num_channels = len(y_data)\n        avg_vals = [sum(y_data[:][index]) / num_channels for index in range(num_modules)]\n        ax.plot(x_data, avg_vals, label=f'Average Value Across {num_channels} Channels')\n        ax.legend(loc='upper right')\n    else:\n        ax.set_xlabel('idx')\n        ax.plot(x_data, y_data)\n    plt.show()",
            "def generate_plot_visualization(self, feature_filter: str, module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in a feature and optional module_filter and plots of the desired data.\\n\\n        For per channel features, it averages the value across the channels and plots a point\\n        per module. The reason for this is that for models with hundreds of channels, it can\\n        be hard to differentiate one channel line from another, and so the point of generating\\n        a single average point per module is to give a sense of general trends that encourage\\n        further deep dives.\\n\\n        Note:\\n            Only features in the report that have tensor value data are plottable by this class\\n            When the tensor information is plotted, it will plot:\\n                idx as the x val, feature value as the y_val\\n            When the channel information is plotted, it will plot:\\n                the first idx of each module as the x val, feature value as the y_val [for each channel]\\n                The reason for this is that we want to be able to compare values across the\\n                channels for same layer, and it will be hard if values are staggered by idx\\n                This means each module is represented by only 1 x value\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # outputs line plot of per_channel_min information for all\\n            >>> # modules in block1 of model each channel gets it\\'s own line,\\n            >>> # and it\\'s plotted across the in-order modules on the x-axis\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_ylabel(feature_filter)\n    ax.set_title(feature_filter + ' Plot')\n    plt.xticks(x_data)\n    if data_per_channel:\n        ax.set_xlabel('First idx of module')\n        num_modules = len(y_data[0])\n        num_channels = len(y_data)\n        avg_vals = [sum(y_data[:][index]) / num_channels for index in range(num_modules)]\n        ax.plot(x_data, avg_vals, label=f'Average Value Across {num_channels} Channels')\n        ax.legend(loc='upper right')\n    else:\n        ax.set_xlabel('idx')\n        ax.plot(x_data, y_data)\n    plt.show()",
            "def generate_plot_visualization(self, feature_filter: str, module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in a feature and optional module_filter and plots of the desired data.\\n\\n        For per channel features, it averages the value across the channels and plots a point\\n        per module. The reason for this is that for models with hundreds of channels, it can\\n        be hard to differentiate one channel line from another, and so the point of generating\\n        a single average point per module is to give a sense of general trends that encourage\\n        further deep dives.\\n\\n        Note:\\n            Only features in the report that have tensor value data are plottable by this class\\n            When the tensor information is plotted, it will plot:\\n                idx as the x val, feature value as the y_val\\n            When the channel information is plotted, it will plot:\\n                the first idx of each module as the x val, feature value as the y_val [for each channel]\\n                The reason for this is that we want to be able to compare values across the\\n                channels for same layer, and it will be hard if values are staggered by idx\\n                This means each module is represented by only 1 x value\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # outputs line plot of per_channel_min information for all\\n            >>> # modules in block1 of model each channel gets it\\'s own line,\\n            >>> # and it\\'s plotted across the in-order modules on the x-axis\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_ylabel(feature_filter)\n    ax.set_title(feature_filter + ' Plot')\n    plt.xticks(x_data)\n    if data_per_channel:\n        ax.set_xlabel('First idx of module')\n        num_modules = len(y_data[0])\n        num_channels = len(y_data)\n        avg_vals = [sum(y_data[:][index]) / num_channels for index in range(num_modules)]\n        ax.plot(x_data, avg_vals, label=f'Average Value Across {num_channels} Channels')\n        ax.legend(loc='upper right')\n    else:\n        ax.set_xlabel('idx')\n        ax.plot(x_data, y_data)\n    plt.show()",
            "def generate_plot_visualization(self, feature_filter: str, module_fqn_filter: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in a feature and optional module_filter and plots of the desired data.\\n\\n        For per channel features, it averages the value across the channels and plots a point\\n        per module. The reason for this is that for models with hundreds of channels, it can\\n        be hard to differentiate one channel line from another, and so the point of generating\\n        a single average point per module is to give a sense of general trends that encourage\\n        further deep dives.\\n\\n        Note:\\n            Only features in the report that have tensor value data are plottable by this class\\n            When the tensor information is plotted, it will plot:\\n                idx as the x val, feature value as the y_val\\n            When the channel information is plotted, it will plot:\\n                the first idx of each module as the x val, feature value as the y_val [for each channel]\\n                The reason for this is that we want to be able to compare values across the\\n                channels for same layer, and it will be hard if values are staggered by idx\\n                This means each module is represented by only 1 x value\\n        Args:\\n            feature_filter (str): Filters the features presented to only those that\\n                contain this filter substring\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP(\"undefined variables\")\\n            >>> mod_report_visualizer.generate_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            >>> # outputs line plot of per_channel_min information for all\\n            >>> # modules in block1 of model each channel gets it\\'s own line,\\n            >>> # and it\\'s plotted across the in-order modules on the x-axis\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_ylabel(feature_filter)\n    ax.set_title(feature_filter + ' Plot')\n    plt.xticks(x_data)\n    if data_per_channel:\n        ax.set_xlabel('First idx of module')\n        num_modules = len(y_data[0])\n        num_channels = len(y_data)\n        avg_vals = [sum(y_data[:][index]) / num_channels for index in range(num_modules)]\n        ax.plot(x_data, avg_vals, label=f'Average Value Across {num_channels} Channels')\n        ax.legend(loc='upper right')\n    else:\n        ax.set_xlabel('idx')\n        ax.plot(x_data, y_data)\n    plt.show()"
        ]
    },
    {
        "func_name": "generate_histogram_visualization",
        "original": "def generate_histogram_visualization(self, feature_filter: str, module_fqn_filter: str='', num_bins: int=10):\n    \"\"\"\n        Takes in a feature and optional module_filter and plots the histogram of desired data.\n\n        Note:\n            Only features in the report that have tensor value data can be viewed as a histogram\n            If you want to plot a histogram from all the channel values of a specific feature for\n                a specific model, make sure to specify both the model and the feature properly\n                in the filters and you should be able to see a distribution of the channel data\n\n        Args:\n            feature_filter (str, optional): Filters the features presented to only those that\n                contain this filter substring\n                Default = \"\", results in all the features being printed\n            module_fqn_filter (str, optional): Only includes modules that contains this string\n                Default = \"\", results in all the modules in the reports to be visible in the table\n            num_bins (int, optional): The number of bins to create the histogram with\n                Default = 10, the values will be split into 10 equal sized bins\n\n        Example Use:\n            >>> # xdoctest: +SKIP\n            >>> mod_report_visualizer.generategenerate_histogram_visualization_plot_visualization(\n            ...     feature_filter = \"per_channel_min\",\n            ...     module_fqn_filter = \"block1\"\n            ... )\n            # outputs histogram of per_channel_min information for all modules in block1 of model\n                information is gathered across all channels for all modules in block 1 for the\n                per_channel_min and is displayed in a histogram of equally sized bins\n        \"\"\"\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_xlabel(feature_filter)\n    ax.set_ylabel('Frequency')\n    ax.set_title(feature_filter + ' Histogram')\n    if data_per_channel:\n        all_data = []\n        for channel_info in y_data:\n            all_data.extend(channel_info)\n        (val, bins, _) = plt.hist(all_data, bins=num_bins, stacked=True, rwidth=0.8)\n        plt.xticks(bins)\n    else:\n        (val, bins, _) = plt.hist(y_data, bins=num_bins, stacked=False, rwidth=0.8)\n        plt.xticks(bins)\n    plt.show()",
        "mutated": [
            "def generate_histogram_visualization(self, feature_filter: str, module_fqn_filter: str='', num_bins: int=10):\n    if False:\n        i = 10\n    '\\n        Takes in a feature and optional module_filter and plots the histogram of desired data.\\n\\n        Note:\\n            Only features in the report that have tensor value data can be viewed as a histogram\\n            If you want to plot a histogram from all the channel values of a specific feature for\\n                a specific model, make sure to specify both the model and the feature properly\\n                in the filters and you should be able to see a distribution of the channel data\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n            num_bins (int, optional): The number of bins to create the histogram with\\n                Default = 10, the values will be split into 10 equal sized bins\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP\\n            >>> mod_report_visualizer.generategenerate_histogram_visualization_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            # outputs histogram of per_channel_min information for all modules in block1 of model\\n                information is gathered across all channels for all modules in block 1 for the\\n                per_channel_min and is displayed in a histogram of equally sized bins\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_xlabel(feature_filter)\n    ax.set_ylabel('Frequency')\n    ax.set_title(feature_filter + ' Histogram')\n    if data_per_channel:\n        all_data = []\n        for channel_info in y_data:\n            all_data.extend(channel_info)\n        (val, bins, _) = plt.hist(all_data, bins=num_bins, stacked=True, rwidth=0.8)\n        plt.xticks(bins)\n    else:\n        (val, bins, _) = plt.hist(y_data, bins=num_bins, stacked=False, rwidth=0.8)\n        plt.xticks(bins)\n    plt.show()",
            "def generate_histogram_visualization(self, feature_filter: str, module_fqn_filter: str='', num_bins: int=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Takes in a feature and optional module_filter and plots the histogram of desired data.\\n\\n        Note:\\n            Only features in the report that have tensor value data can be viewed as a histogram\\n            If you want to plot a histogram from all the channel values of a specific feature for\\n                a specific model, make sure to specify both the model and the feature properly\\n                in the filters and you should be able to see a distribution of the channel data\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n            num_bins (int, optional): The number of bins to create the histogram with\\n                Default = 10, the values will be split into 10 equal sized bins\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP\\n            >>> mod_report_visualizer.generategenerate_histogram_visualization_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            # outputs histogram of per_channel_min information for all modules in block1 of model\\n                information is gathered across all channels for all modules in block 1 for the\\n                per_channel_min and is displayed in a histogram of equally sized bins\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_xlabel(feature_filter)\n    ax.set_ylabel('Frequency')\n    ax.set_title(feature_filter + ' Histogram')\n    if data_per_channel:\n        all_data = []\n        for channel_info in y_data:\n            all_data.extend(channel_info)\n        (val, bins, _) = plt.hist(all_data, bins=num_bins, stacked=True, rwidth=0.8)\n        plt.xticks(bins)\n    else:\n        (val, bins, _) = plt.hist(y_data, bins=num_bins, stacked=False, rwidth=0.8)\n        plt.xticks(bins)\n    plt.show()",
            "def generate_histogram_visualization(self, feature_filter: str, module_fqn_filter: str='', num_bins: int=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Takes in a feature and optional module_filter and plots the histogram of desired data.\\n\\n        Note:\\n            Only features in the report that have tensor value data can be viewed as a histogram\\n            If you want to plot a histogram from all the channel values of a specific feature for\\n                a specific model, make sure to specify both the model and the feature properly\\n                in the filters and you should be able to see a distribution of the channel data\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n            num_bins (int, optional): The number of bins to create the histogram with\\n                Default = 10, the values will be split into 10 equal sized bins\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP\\n            >>> mod_report_visualizer.generategenerate_histogram_visualization_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            # outputs histogram of per_channel_min information for all modules in block1 of model\\n                information is gathered across all channels for all modules in block 1 for the\\n                per_channel_min and is displayed in a histogram of equally sized bins\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_xlabel(feature_filter)\n    ax.set_ylabel('Frequency')\n    ax.set_title(feature_filter + ' Histogram')\n    if data_per_channel:\n        all_data = []\n        for channel_info in y_data:\n            all_data.extend(channel_info)\n        (val, bins, _) = plt.hist(all_data, bins=num_bins, stacked=True, rwidth=0.8)\n        plt.xticks(bins)\n    else:\n        (val, bins, _) = plt.hist(y_data, bins=num_bins, stacked=False, rwidth=0.8)\n        plt.xticks(bins)\n    plt.show()",
            "def generate_histogram_visualization(self, feature_filter: str, module_fqn_filter: str='', num_bins: int=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Takes in a feature and optional module_filter and plots the histogram of desired data.\\n\\n        Note:\\n            Only features in the report that have tensor value data can be viewed as a histogram\\n            If you want to plot a histogram from all the channel values of a specific feature for\\n                a specific model, make sure to specify both the model and the feature properly\\n                in the filters and you should be able to see a distribution of the channel data\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n            num_bins (int, optional): The number of bins to create the histogram with\\n                Default = 10, the values will be split into 10 equal sized bins\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP\\n            >>> mod_report_visualizer.generategenerate_histogram_visualization_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            # outputs histogram of per_channel_min information for all modules in block1 of model\\n                information is gathered across all channels for all modules in block 1 for the\\n                per_channel_min and is displayed in a histogram of equally sized bins\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_xlabel(feature_filter)\n    ax.set_ylabel('Frequency')\n    ax.set_title(feature_filter + ' Histogram')\n    if data_per_channel:\n        all_data = []\n        for channel_info in y_data:\n            all_data.extend(channel_info)\n        (val, bins, _) = plt.hist(all_data, bins=num_bins, stacked=True, rwidth=0.8)\n        plt.xticks(bins)\n    else:\n        (val, bins, _) = plt.hist(y_data, bins=num_bins, stacked=False, rwidth=0.8)\n        plt.xticks(bins)\n    plt.show()",
            "def generate_histogram_visualization(self, feature_filter: str, module_fqn_filter: str='', num_bins: int=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Takes in a feature and optional module_filter and plots the histogram of desired data.\\n\\n        Note:\\n            Only features in the report that have tensor value data can be viewed as a histogram\\n            If you want to plot a histogram from all the channel values of a specific feature for\\n                a specific model, make sure to specify both the model and the feature properly\\n                in the filters and you should be able to see a distribution of the channel data\\n\\n        Args:\\n            feature_filter (str, optional): Filters the features presented to only those that\\n                contain this filter substring\\n                Default = \"\", results in all the features being printed\\n            module_fqn_filter (str, optional): Only includes modules that contains this string\\n                Default = \"\", results in all the modules in the reports to be visible in the table\\n            num_bins (int, optional): The number of bins to create the histogram with\\n                Default = 10, the values will be split into 10 equal sized bins\\n\\n        Example Use:\\n            >>> # xdoctest: +SKIP\\n            >>> mod_report_visualizer.generategenerate_histogram_visualization_plot_visualization(\\n            ...     feature_filter = \"per_channel_min\",\\n            ...     module_fqn_filter = \"block1\"\\n            ... )\\n            # outputs histogram of per_channel_min information for all modules in block1 of model\\n                information is gathered across all channels for all modules in block 1 for the\\n                per_channel_min and is displayed in a histogram of equally sized bins\\n        '\n    if not got_matplotlib:\n        print('make sure to install matplotlib and try again.')\n        return None\n    (x_data, y_data, data_per_channel) = self._get_plottable_data(feature_filter, module_fqn_filter)\n    ax = plt.subplot()\n    ax.set_xlabel(feature_filter)\n    ax.set_ylabel('Frequency')\n    ax.set_title(feature_filter + ' Histogram')\n    if data_per_channel:\n        all_data = []\n        for channel_info in y_data:\n            all_data.extend(channel_info)\n        (val, bins, _) = plt.hist(all_data, bins=num_bins, stacked=True, rwidth=0.8)\n        plt.xticks(bins)\n    else:\n        (val, bins, _) = plt.hist(y_data, bins=num_bins, stacked=False, rwidth=0.8)\n        plt.xticks(bins)\n    plt.show()"
        ]
    }
]