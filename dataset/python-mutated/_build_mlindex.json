[
    {
        "func_name": "build_index",
        "original": "def build_index(*, output_index_name: str, vector_store: str, embeddings_model: str=None, aoai_connection_id: str=None, data_source_url: str=None, chunk_size: int=1024, chunk_overlap: int=0, input_glob: str='**/*', max_sample_files: int=None, chunk_prepend_summary: bool=None, document_path_replacement_regex: str=None, embeddings_cache_path: str=None, index_input_config: Union[ACSSource, LocalSource]=None, acs_config: ACSOutputConfig=None) -> Index:\n    \"\"\"Generates embeddings locally and stores Index reference in memory\n    \"\"\"\n    try:\n        from azure.ai.generative.index._documents import DocumentChunksIterator, split_documents\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._tasks.update_acs import create_index_from_raw_embeddings\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n        from azure.ai.generative.index._utils.logging import disable_mlflow\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    disable_mlflow()\n    embeddings_model = build_open_ai_protocol(embeddings_model)\n    if vector_store == 'azure_cognitive_search' and isinstance(index_input_config, ACSSource):\n        return _create_mlindex_from_existing_acs(output_index_name=output_index_name, embedding_model=embeddings_model, aoai_connection=aoai_connection_id, acs_config=index_input_config)\n    embeddings_cache_path = Path(embeddings_cache_path) if embeddings_cache_path else Path.cwd()\n    save_path = embeddings_cache_path / f'{output_index_name}-mlindex'\n    splitter_args = {'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n    if max_sample_files is not None:\n        splitter_args['max_sample_files'] = max_sample_files\n    if chunk_prepend_summary is not None:\n        splitter_args['chunk_preprend_summary'] = chunk_prepend_summary\n    chunked_docs = DocumentChunksIterator(files_source=index_input_config.input_data.path, glob=input_glob, base_url=data_source_url, document_path_replacement_regex=document_path_replacement_regex, chunked_document_processors=[lambda docs: split_documents(docs, splitter_args=splitter_args)])\n    connection_args = {}\n    if 'open_ai' in embeddings_model:\n        import os\n        if aoai_connection_id:\n            aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection_id}, 'endpoint': aoai_connection['properties']['target']}\n        else:\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'OPENAI_API_KEY'}, 'endpoint': os.getenv('OPENAI_API_BASE')}\n    embedder = EmbeddingsContainer.from_uri(uri=embeddings_model, **connection_args)\n    embeddings = embedder.embed(chunked_docs)\n    if vector_store.lower() == 'faiss':\n        embeddings.write_as_faiss_mlindex(save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    if vector_store.lower() == 'azure_cognitive_search':\n        acs_args = {'index_name': acs_config.acs_index_name}\n        if not acs_config.acs_connection_id:\n            import os\n            acs_args = {**acs_args, **{'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'api_version': '2023-07-01-preview'}}\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n        else:\n            acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n            acs_args = {**acs_args, **{'endpoint': acs_connection['properties']['target'], 'api_version': acs_connection['properties'].get('metadata', {}).get('apiVersion', '2023-07-01-preview')}}\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n        create_index_from_raw_embeddings(emb=embedder, acs_config=acs_args, connection=connection_args, output_path=save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    return Index(name=output_index_name, path=save_path, properties=mlindex_properties)",
        "mutated": [
            "def build_index(*, output_index_name: str, vector_store: str, embeddings_model: str=None, aoai_connection_id: str=None, data_source_url: str=None, chunk_size: int=1024, chunk_overlap: int=0, input_glob: str='**/*', max_sample_files: int=None, chunk_prepend_summary: bool=None, document_path_replacement_regex: str=None, embeddings_cache_path: str=None, index_input_config: Union[ACSSource, LocalSource]=None, acs_config: ACSOutputConfig=None) -> Index:\n    if False:\n        i = 10\n    'Generates embeddings locally and stores Index reference in memory\\n    '\n    try:\n        from azure.ai.generative.index._documents import DocumentChunksIterator, split_documents\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._tasks.update_acs import create_index_from_raw_embeddings\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n        from azure.ai.generative.index._utils.logging import disable_mlflow\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    disable_mlflow()\n    embeddings_model = build_open_ai_protocol(embeddings_model)\n    if vector_store == 'azure_cognitive_search' and isinstance(index_input_config, ACSSource):\n        return _create_mlindex_from_existing_acs(output_index_name=output_index_name, embedding_model=embeddings_model, aoai_connection=aoai_connection_id, acs_config=index_input_config)\n    embeddings_cache_path = Path(embeddings_cache_path) if embeddings_cache_path else Path.cwd()\n    save_path = embeddings_cache_path / f'{output_index_name}-mlindex'\n    splitter_args = {'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n    if max_sample_files is not None:\n        splitter_args['max_sample_files'] = max_sample_files\n    if chunk_prepend_summary is not None:\n        splitter_args['chunk_preprend_summary'] = chunk_prepend_summary\n    chunked_docs = DocumentChunksIterator(files_source=index_input_config.input_data.path, glob=input_glob, base_url=data_source_url, document_path_replacement_regex=document_path_replacement_regex, chunked_document_processors=[lambda docs: split_documents(docs, splitter_args=splitter_args)])\n    connection_args = {}\n    if 'open_ai' in embeddings_model:\n        import os\n        if aoai_connection_id:\n            aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection_id}, 'endpoint': aoai_connection['properties']['target']}\n        else:\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'OPENAI_API_KEY'}, 'endpoint': os.getenv('OPENAI_API_BASE')}\n    embedder = EmbeddingsContainer.from_uri(uri=embeddings_model, **connection_args)\n    embeddings = embedder.embed(chunked_docs)\n    if vector_store.lower() == 'faiss':\n        embeddings.write_as_faiss_mlindex(save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    if vector_store.lower() == 'azure_cognitive_search':\n        acs_args = {'index_name': acs_config.acs_index_name}\n        if not acs_config.acs_connection_id:\n            import os\n            acs_args = {**acs_args, **{'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'api_version': '2023-07-01-preview'}}\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n        else:\n            acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n            acs_args = {**acs_args, **{'endpoint': acs_connection['properties']['target'], 'api_version': acs_connection['properties'].get('metadata', {}).get('apiVersion', '2023-07-01-preview')}}\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n        create_index_from_raw_embeddings(emb=embedder, acs_config=acs_args, connection=connection_args, output_path=save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    return Index(name=output_index_name, path=save_path, properties=mlindex_properties)",
            "def build_index(*, output_index_name: str, vector_store: str, embeddings_model: str=None, aoai_connection_id: str=None, data_source_url: str=None, chunk_size: int=1024, chunk_overlap: int=0, input_glob: str='**/*', max_sample_files: int=None, chunk_prepend_summary: bool=None, document_path_replacement_regex: str=None, embeddings_cache_path: str=None, index_input_config: Union[ACSSource, LocalSource]=None, acs_config: ACSOutputConfig=None) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generates embeddings locally and stores Index reference in memory\\n    '\n    try:\n        from azure.ai.generative.index._documents import DocumentChunksIterator, split_documents\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._tasks.update_acs import create_index_from_raw_embeddings\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n        from azure.ai.generative.index._utils.logging import disable_mlflow\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    disable_mlflow()\n    embeddings_model = build_open_ai_protocol(embeddings_model)\n    if vector_store == 'azure_cognitive_search' and isinstance(index_input_config, ACSSource):\n        return _create_mlindex_from_existing_acs(output_index_name=output_index_name, embedding_model=embeddings_model, aoai_connection=aoai_connection_id, acs_config=index_input_config)\n    embeddings_cache_path = Path(embeddings_cache_path) if embeddings_cache_path else Path.cwd()\n    save_path = embeddings_cache_path / f'{output_index_name}-mlindex'\n    splitter_args = {'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n    if max_sample_files is not None:\n        splitter_args['max_sample_files'] = max_sample_files\n    if chunk_prepend_summary is not None:\n        splitter_args['chunk_preprend_summary'] = chunk_prepend_summary\n    chunked_docs = DocumentChunksIterator(files_source=index_input_config.input_data.path, glob=input_glob, base_url=data_source_url, document_path_replacement_regex=document_path_replacement_regex, chunked_document_processors=[lambda docs: split_documents(docs, splitter_args=splitter_args)])\n    connection_args = {}\n    if 'open_ai' in embeddings_model:\n        import os\n        if aoai_connection_id:\n            aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection_id}, 'endpoint': aoai_connection['properties']['target']}\n        else:\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'OPENAI_API_KEY'}, 'endpoint': os.getenv('OPENAI_API_BASE')}\n    embedder = EmbeddingsContainer.from_uri(uri=embeddings_model, **connection_args)\n    embeddings = embedder.embed(chunked_docs)\n    if vector_store.lower() == 'faiss':\n        embeddings.write_as_faiss_mlindex(save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    if vector_store.lower() == 'azure_cognitive_search':\n        acs_args = {'index_name': acs_config.acs_index_name}\n        if not acs_config.acs_connection_id:\n            import os\n            acs_args = {**acs_args, **{'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'api_version': '2023-07-01-preview'}}\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n        else:\n            acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n            acs_args = {**acs_args, **{'endpoint': acs_connection['properties']['target'], 'api_version': acs_connection['properties'].get('metadata', {}).get('apiVersion', '2023-07-01-preview')}}\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n        create_index_from_raw_embeddings(emb=embedder, acs_config=acs_args, connection=connection_args, output_path=save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    return Index(name=output_index_name, path=save_path, properties=mlindex_properties)",
            "def build_index(*, output_index_name: str, vector_store: str, embeddings_model: str=None, aoai_connection_id: str=None, data_source_url: str=None, chunk_size: int=1024, chunk_overlap: int=0, input_glob: str='**/*', max_sample_files: int=None, chunk_prepend_summary: bool=None, document_path_replacement_regex: str=None, embeddings_cache_path: str=None, index_input_config: Union[ACSSource, LocalSource]=None, acs_config: ACSOutputConfig=None) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generates embeddings locally and stores Index reference in memory\\n    '\n    try:\n        from azure.ai.generative.index._documents import DocumentChunksIterator, split_documents\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._tasks.update_acs import create_index_from_raw_embeddings\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n        from azure.ai.generative.index._utils.logging import disable_mlflow\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    disable_mlflow()\n    embeddings_model = build_open_ai_protocol(embeddings_model)\n    if vector_store == 'azure_cognitive_search' and isinstance(index_input_config, ACSSource):\n        return _create_mlindex_from_existing_acs(output_index_name=output_index_name, embedding_model=embeddings_model, aoai_connection=aoai_connection_id, acs_config=index_input_config)\n    embeddings_cache_path = Path(embeddings_cache_path) if embeddings_cache_path else Path.cwd()\n    save_path = embeddings_cache_path / f'{output_index_name}-mlindex'\n    splitter_args = {'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n    if max_sample_files is not None:\n        splitter_args['max_sample_files'] = max_sample_files\n    if chunk_prepend_summary is not None:\n        splitter_args['chunk_preprend_summary'] = chunk_prepend_summary\n    chunked_docs = DocumentChunksIterator(files_source=index_input_config.input_data.path, glob=input_glob, base_url=data_source_url, document_path_replacement_regex=document_path_replacement_regex, chunked_document_processors=[lambda docs: split_documents(docs, splitter_args=splitter_args)])\n    connection_args = {}\n    if 'open_ai' in embeddings_model:\n        import os\n        if aoai_connection_id:\n            aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection_id}, 'endpoint': aoai_connection['properties']['target']}\n        else:\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'OPENAI_API_KEY'}, 'endpoint': os.getenv('OPENAI_API_BASE')}\n    embedder = EmbeddingsContainer.from_uri(uri=embeddings_model, **connection_args)\n    embeddings = embedder.embed(chunked_docs)\n    if vector_store.lower() == 'faiss':\n        embeddings.write_as_faiss_mlindex(save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    if vector_store.lower() == 'azure_cognitive_search':\n        acs_args = {'index_name': acs_config.acs_index_name}\n        if not acs_config.acs_connection_id:\n            import os\n            acs_args = {**acs_args, **{'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'api_version': '2023-07-01-preview'}}\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n        else:\n            acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n            acs_args = {**acs_args, **{'endpoint': acs_connection['properties']['target'], 'api_version': acs_connection['properties'].get('metadata', {}).get('apiVersion', '2023-07-01-preview')}}\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n        create_index_from_raw_embeddings(emb=embedder, acs_config=acs_args, connection=connection_args, output_path=save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    return Index(name=output_index_name, path=save_path, properties=mlindex_properties)",
            "def build_index(*, output_index_name: str, vector_store: str, embeddings_model: str=None, aoai_connection_id: str=None, data_source_url: str=None, chunk_size: int=1024, chunk_overlap: int=0, input_glob: str='**/*', max_sample_files: int=None, chunk_prepend_summary: bool=None, document_path_replacement_regex: str=None, embeddings_cache_path: str=None, index_input_config: Union[ACSSource, LocalSource]=None, acs_config: ACSOutputConfig=None) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generates embeddings locally and stores Index reference in memory\\n    '\n    try:\n        from azure.ai.generative.index._documents import DocumentChunksIterator, split_documents\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._tasks.update_acs import create_index_from_raw_embeddings\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n        from azure.ai.generative.index._utils.logging import disable_mlflow\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    disable_mlflow()\n    embeddings_model = build_open_ai_protocol(embeddings_model)\n    if vector_store == 'azure_cognitive_search' and isinstance(index_input_config, ACSSource):\n        return _create_mlindex_from_existing_acs(output_index_name=output_index_name, embedding_model=embeddings_model, aoai_connection=aoai_connection_id, acs_config=index_input_config)\n    embeddings_cache_path = Path(embeddings_cache_path) if embeddings_cache_path else Path.cwd()\n    save_path = embeddings_cache_path / f'{output_index_name}-mlindex'\n    splitter_args = {'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n    if max_sample_files is not None:\n        splitter_args['max_sample_files'] = max_sample_files\n    if chunk_prepend_summary is not None:\n        splitter_args['chunk_preprend_summary'] = chunk_prepend_summary\n    chunked_docs = DocumentChunksIterator(files_source=index_input_config.input_data.path, glob=input_glob, base_url=data_source_url, document_path_replacement_regex=document_path_replacement_regex, chunked_document_processors=[lambda docs: split_documents(docs, splitter_args=splitter_args)])\n    connection_args = {}\n    if 'open_ai' in embeddings_model:\n        import os\n        if aoai_connection_id:\n            aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection_id}, 'endpoint': aoai_connection['properties']['target']}\n        else:\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'OPENAI_API_KEY'}, 'endpoint': os.getenv('OPENAI_API_BASE')}\n    embedder = EmbeddingsContainer.from_uri(uri=embeddings_model, **connection_args)\n    embeddings = embedder.embed(chunked_docs)\n    if vector_store.lower() == 'faiss':\n        embeddings.write_as_faiss_mlindex(save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    if vector_store.lower() == 'azure_cognitive_search':\n        acs_args = {'index_name': acs_config.acs_index_name}\n        if not acs_config.acs_connection_id:\n            import os\n            acs_args = {**acs_args, **{'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'api_version': '2023-07-01-preview'}}\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n        else:\n            acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n            acs_args = {**acs_args, **{'endpoint': acs_connection['properties']['target'], 'api_version': acs_connection['properties'].get('metadata', {}).get('apiVersion', '2023-07-01-preview')}}\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n        create_index_from_raw_embeddings(emb=embedder, acs_config=acs_args, connection=connection_args, output_path=save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    return Index(name=output_index_name, path=save_path, properties=mlindex_properties)",
            "def build_index(*, output_index_name: str, vector_store: str, embeddings_model: str=None, aoai_connection_id: str=None, data_source_url: str=None, chunk_size: int=1024, chunk_overlap: int=0, input_glob: str='**/*', max_sample_files: int=None, chunk_prepend_summary: bool=None, document_path_replacement_regex: str=None, embeddings_cache_path: str=None, index_input_config: Union[ACSSource, LocalSource]=None, acs_config: ACSOutputConfig=None) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generates embeddings locally and stores Index reference in memory\\n    '\n    try:\n        from azure.ai.generative.index._documents import DocumentChunksIterator, split_documents\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._tasks.update_acs import create_index_from_raw_embeddings\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n        from azure.ai.generative.index._utils.logging import disable_mlflow\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    disable_mlflow()\n    embeddings_model = build_open_ai_protocol(embeddings_model)\n    if vector_store == 'azure_cognitive_search' and isinstance(index_input_config, ACSSource):\n        return _create_mlindex_from_existing_acs(output_index_name=output_index_name, embedding_model=embeddings_model, aoai_connection=aoai_connection_id, acs_config=index_input_config)\n    embeddings_cache_path = Path(embeddings_cache_path) if embeddings_cache_path else Path.cwd()\n    save_path = embeddings_cache_path / f'{output_index_name}-mlindex'\n    splitter_args = {'chunk_size': chunk_size, 'chunk_overlap': chunk_overlap}\n    if max_sample_files is not None:\n        splitter_args['max_sample_files'] = max_sample_files\n    if chunk_prepend_summary is not None:\n        splitter_args['chunk_preprend_summary'] = chunk_prepend_summary\n    chunked_docs = DocumentChunksIterator(files_source=index_input_config.input_data.path, glob=input_glob, base_url=data_source_url, document_path_replacement_regex=document_path_replacement_regex, chunked_document_processors=[lambda docs: split_documents(docs, splitter_args=splitter_args)])\n    connection_args = {}\n    if 'open_ai' in embeddings_model:\n        import os\n        if aoai_connection_id:\n            aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection_id}, 'endpoint': aoai_connection['properties']['target']}\n        else:\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'OPENAI_API_KEY'}, 'endpoint': os.getenv('OPENAI_API_BASE')}\n    embedder = EmbeddingsContainer.from_uri(uri=embeddings_model, **connection_args)\n    embeddings = embedder.embed(chunked_docs)\n    if vector_store.lower() == 'faiss':\n        embeddings.write_as_faiss_mlindex(save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    if vector_store.lower() == 'azure_cognitive_search':\n        acs_args = {'index_name': acs_config.acs_index_name}\n        if not acs_config.acs_connection_id:\n            import os\n            acs_args = {**acs_args, **{'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'api_version': '2023-07-01-preview'}}\n            connection_args = {'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n        else:\n            acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n            acs_args = {**acs_args, **{'endpoint': acs_connection['properties']['target'], 'api_version': acs_connection['properties'].get('metadata', {}).get('apiVersion', '2023-07-01-preview')}}\n            connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n        create_index_from_raw_embeddings(emb=embedder, acs_config=acs_args, connection=connection_args, output_path=save_path)\n        mlindex_properties = {'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetSource': 'AzureML Data', 'azureml.mlIndexAssetPipelineRunId': 'Local'}\n    return Index(name=output_index_name, path=save_path, properties=mlindex_properties)"
        ]
    },
    {
        "func_name": "_create_mlindex_from_existing_acs",
        "original": "def _create_mlindex_from_existing_acs(output_index_name: str, embedding_model: str, aoai_connection: str, acs_config: ACSSource) -> Index:\n    try:\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    mlindex_config = {}\n    connection_info = {}\n    if not acs_config.acs_connection_id:\n        import os\n        connection_info = {'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n    else:\n        acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n        connection_info = {'endpoint': acs_connection['properties']['target'], 'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n    mlindex_config['index'] = {'kind': 'acs', 'engine': 'azure-sdk', 'index': acs_config.acs_index_name, 'api_version': '2023-07-01-preview', 'field_mapping': {'content': acs_config.acs_content_key, 'embedding': acs_config.acs_embedding_key}, **connection_info}\n    if acs_config.acs_title_key:\n        mlindex_config['index']['field_mapping']['title'] = acs_config.acs_title_key\n    if acs_config.acs_metadata_key:\n        mlindex_config['index']['field_mapping']['metadata'] = acs_config.acs_metadata_key\n    if not aoai_connection:\n        import openai\n        model_connection_args = {'key': openai.api_key}\n    else:\n        model_connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection}}\n    embedding = EmbeddingsContainer.from_uri(embedding_model, **model_connection_args)\n    mlindex_config['embeddings'] = embedding.get_metadata()\n    path = Path.cwd() / f'import-acs-{acs_config.acs_index_name}-mlindex'\n    path.mkdir(exist_ok=True)\n    with open(path / 'MLIndex', 'w') as f:\n        yaml.dump(mlindex_config, f)\n    return Index(name=output_index_name, path=path, properties={'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetPipelineRunId': 'Local'})",
        "mutated": [
            "def _create_mlindex_from_existing_acs(output_index_name: str, embedding_model: str, aoai_connection: str, acs_config: ACSSource) -> Index:\n    if False:\n        i = 10\n    try:\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    mlindex_config = {}\n    connection_info = {}\n    if not acs_config.acs_connection_id:\n        import os\n        connection_info = {'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n    else:\n        acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n        connection_info = {'endpoint': acs_connection['properties']['target'], 'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n    mlindex_config['index'] = {'kind': 'acs', 'engine': 'azure-sdk', 'index': acs_config.acs_index_name, 'api_version': '2023-07-01-preview', 'field_mapping': {'content': acs_config.acs_content_key, 'embedding': acs_config.acs_embedding_key}, **connection_info}\n    if acs_config.acs_title_key:\n        mlindex_config['index']['field_mapping']['title'] = acs_config.acs_title_key\n    if acs_config.acs_metadata_key:\n        mlindex_config['index']['field_mapping']['metadata'] = acs_config.acs_metadata_key\n    if not aoai_connection:\n        import openai\n        model_connection_args = {'key': openai.api_key}\n    else:\n        model_connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection}}\n    embedding = EmbeddingsContainer.from_uri(embedding_model, **model_connection_args)\n    mlindex_config['embeddings'] = embedding.get_metadata()\n    path = Path.cwd() / f'import-acs-{acs_config.acs_index_name}-mlindex'\n    path.mkdir(exist_ok=True)\n    with open(path / 'MLIndex', 'w') as f:\n        yaml.dump(mlindex_config, f)\n    return Index(name=output_index_name, path=path, properties={'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetPipelineRunId': 'Local'})",
            "def _create_mlindex_from_existing_acs(output_index_name: str, embedding_model: str, aoai_connection: str, acs_config: ACSSource) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    try:\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    mlindex_config = {}\n    connection_info = {}\n    if not acs_config.acs_connection_id:\n        import os\n        connection_info = {'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n    else:\n        acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n        connection_info = {'endpoint': acs_connection['properties']['target'], 'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n    mlindex_config['index'] = {'kind': 'acs', 'engine': 'azure-sdk', 'index': acs_config.acs_index_name, 'api_version': '2023-07-01-preview', 'field_mapping': {'content': acs_config.acs_content_key, 'embedding': acs_config.acs_embedding_key}, **connection_info}\n    if acs_config.acs_title_key:\n        mlindex_config['index']['field_mapping']['title'] = acs_config.acs_title_key\n    if acs_config.acs_metadata_key:\n        mlindex_config['index']['field_mapping']['metadata'] = acs_config.acs_metadata_key\n    if not aoai_connection:\n        import openai\n        model_connection_args = {'key': openai.api_key}\n    else:\n        model_connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection}}\n    embedding = EmbeddingsContainer.from_uri(embedding_model, **model_connection_args)\n    mlindex_config['embeddings'] = embedding.get_metadata()\n    path = Path.cwd() / f'import-acs-{acs_config.acs_index_name}-mlindex'\n    path.mkdir(exist_ok=True)\n    with open(path / 'MLIndex', 'w') as f:\n        yaml.dump(mlindex_config, f)\n    return Index(name=output_index_name, path=path, properties={'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetPipelineRunId': 'Local'})",
            "def _create_mlindex_from_existing_acs(output_index_name: str, embedding_model: str, aoai_connection: str, acs_config: ACSSource) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    try:\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    mlindex_config = {}\n    connection_info = {}\n    if not acs_config.acs_connection_id:\n        import os\n        connection_info = {'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n    else:\n        acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n        connection_info = {'endpoint': acs_connection['properties']['target'], 'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n    mlindex_config['index'] = {'kind': 'acs', 'engine': 'azure-sdk', 'index': acs_config.acs_index_name, 'api_version': '2023-07-01-preview', 'field_mapping': {'content': acs_config.acs_content_key, 'embedding': acs_config.acs_embedding_key}, **connection_info}\n    if acs_config.acs_title_key:\n        mlindex_config['index']['field_mapping']['title'] = acs_config.acs_title_key\n    if acs_config.acs_metadata_key:\n        mlindex_config['index']['field_mapping']['metadata'] = acs_config.acs_metadata_key\n    if not aoai_connection:\n        import openai\n        model_connection_args = {'key': openai.api_key}\n    else:\n        model_connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection}}\n    embedding = EmbeddingsContainer.from_uri(embedding_model, **model_connection_args)\n    mlindex_config['embeddings'] = embedding.get_metadata()\n    path = Path.cwd() / f'import-acs-{acs_config.acs_index_name}-mlindex'\n    path.mkdir(exist_ok=True)\n    with open(path / 'MLIndex', 'w') as f:\n        yaml.dump(mlindex_config, f)\n    return Index(name=output_index_name, path=path, properties={'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetPipelineRunId': 'Local'})",
            "def _create_mlindex_from_existing_acs(output_index_name: str, embedding_model: str, aoai_connection: str, acs_config: ACSSource) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    try:\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    mlindex_config = {}\n    connection_info = {}\n    if not acs_config.acs_connection_id:\n        import os\n        connection_info = {'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n    else:\n        acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n        connection_info = {'endpoint': acs_connection['properties']['target'], 'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n    mlindex_config['index'] = {'kind': 'acs', 'engine': 'azure-sdk', 'index': acs_config.acs_index_name, 'api_version': '2023-07-01-preview', 'field_mapping': {'content': acs_config.acs_content_key, 'embedding': acs_config.acs_embedding_key}, **connection_info}\n    if acs_config.acs_title_key:\n        mlindex_config['index']['field_mapping']['title'] = acs_config.acs_title_key\n    if acs_config.acs_metadata_key:\n        mlindex_config['index']['field_mapping']['metadata'] = acs_config.acs_metadata_key\n    if not aoai_connection:\n        import openai\n        model_connection_args = {'key': openai.api_key}\n    else:\n        model_connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection}}\n    embedding = EmbeddingsContainer.from_uri(embedding_model, **model_connection_args)\n    mlindex_config['embeddings'] = embedding.get_metadata()\n    path = Path.cwd() / f'import-acs-{acs_config.acs_index_name}-mlindex'\n    path.mkdir(exist_ok=True)\n    with open(path / 'MLIndex', 'w') as f:\n        yaml.dump(mlindex_config, f)\n    return Index(name=output_index_name, path=path, properties={'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetPipelineRunId': 'Local'})",
            "def _create_mlindex_from_existing_acs(output_index_name: str, embedding_model: str, aoai_connection: str, acs_config: ACSSource) -> Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    try:\n        from azure.ai.generative.index._embeddings import EmbeddingsContainer\n        from azure.ai.generative.index._utils.connections import get_connection_by_id_v2\n    except ImportError as e:\n        print('In order to use build_index to build an Index locally, you must have azure-ai-generative[index] installed')\n        raise e\n    mlindex_config = {}\n    connection_info = {}\n    if not acs_config.acs_connection_id:\n        import os\n        connection_info = {'endpoint': os.getenv('AZURE_AI_SEARCH_ENDPOINT') if 'AZURE_AI_SEARCH_ENDPOINT' in os.environ else os.getenv('AZURE_COGNITIVE_SEARCH_TARGET'), 'connection_type': 'environment', 'connection': {'key': 'AZURE_AI_SEARCH_KEY'}}\n    else:\n        acs_connection = get_connection_by_id_v2(acs_config.acs_connection_id)\n        connection_info = {'endpoint': acs_connection['properties']['target'], 'connection_type': 'workspace_connection', 'connection': {'id': acs_config.acs_connection_id}}\n    mlindex_config['index'] = {'kind': 'acs', 'engine': 'azure-sdk', 'index': acs_config.acs_index_name, 'api_version': '2023-07-01-preview', 'field_mapping': {'content': acs_config.acs_content_key, 'embedding': acs_config.acs_embedding_key}, **connection_info}\n    if acs_config.acs_title_key:\n        mlindex_config['index']['field_mapping']['title'] = acs_config.acs_title_key\n    if acs_config.acs_metadata_key:\n        mlindex_config['index']['field_mapping']['metadata'] = acs_config.acs_metadata_key\n    if not aoai_connection:\n        import openai\n        model_connection_args = {'key': openai.api_key}\n    else:\n        model_connection_args = {'connection_type': 'workspace_connection', 'connection': {'id': aoai_connection}}\n    embedding = EmbeddingsContainer.from_uri(embedding_model, **model_connection_args)\n    mlindex_config['embeddings'] = embedding.get_metadata()\n    path = Path.cwd() / f'import-acs-{acs_config.acs_index_name}-mlindex'\n    path.mkdir(exist_ok=True)\n    with open(path / 'MLIndex', 'w') as f:\n        yaml.dump(mlindex_config, f)\n    return Index(name=output_index_name, path=path, properties={'azureml.mlIndexAssetKind': 'acs', 'azureml.mlIndexAsset': 'true', 'azureml.mlIndexAssetPipelineRunId': 'Local'})"
        ]
    }
]