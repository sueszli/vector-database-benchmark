[
    {
        "func_name": "check_model_right",
        "original": "def check_model_right(self, dirname):\n    model_filename = os.path.join(dirname, '__model__')\n    with open(model_filename, 'rb') as f:\n        program_desc_str = f.read()\n    program = base.Program.parse_from_string(program_desc_str)\n    with open(os.path.join(dirname, '__model__.proto'), 'w') as wn:\n        wn.write(str(program))",
        "mutated": [
            "def check_model_right(self, dirname):\n    if False:\n        i = 10\n    model_filename = os.path.join(dirname, '__model__')\n    with open(model_filename, 'rb') as f:\n        program_desc_str = f.read()\n    program = base.Program.parse_from_string(program_desc_str)\n    with open(os.path.join(dirname, '__model__.proto'), 'w') as wn:\n        wn.write(str(program))",
            "def check_model_right(self, dirname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    model_filename = os.path.join(dirname, '__model__')\n    with open(model_filename, 'rb') as f:\n        program_desc_str = f.read()\n    program = base.Program.parse_from_string(program_desc_str)\n    with open(os.path.join(dirname, '__model__.proto'), 'w') as wn:\n        wn.write(str(program))",
            "def check_model_right(self, dirname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    model_filename = os.path.join(dirname, '__model__')\n    with open(model_filename, 'rb') as f:\n        program_desc_str = f.read()\n    program = base.Program.parse_from_string(program_desc_str)\n    with open(os.path.join(dirname, '__model__.proto'), 'w') as wn:\n        wn.write(str(program))",
            "def check_model_right(self, dirname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    model_filename = os.path.join(dirname, '__model__')\n    with open(model_filename, 'rb') as f:\n        program_desc_str = f.read()\n    program = base.Program.parse_from_string(program_desc_str)\n    with open(os.path.join(dirname, '__model__.proto'), 'w') as wn:\n        wn.write(str(program))",
            "def check_model_right(self, dirname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    model_filename = os.path.join(dirname, '__model__')\n    with open(model_filename, 'rb') as f:\n        program_desc_str = f.read()\n    program = base.Program.parse_from_string(program_desc_str)\n    with open(os.path.join(dirname, '__model__.proto'), 'w') as wn:\n        wn.write(str(program))"
        ]
    },
    {
        "func_name": "do_pyreader_training",
        "original": "def do_pyreader_training(self, fleet):\n    \"\"\"\n        do training using dataset, using fetch handler to catch variable\n        Args:\n            fleet(Fleet api): the fleet object of Parameter Server, define distribute training role\n        \"\"\"\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    batch_size = 4\n    train_reader = paddle.batch(fake_ctr_reader(), batch_size=batch_size)\n    self.reader.decorate_sample_list_generator(train_reader)\n    for epoch_id in range(1):\n        self.reader.start()\n        try:\n            pass_start = time.time()\n            while True:\n                loss_val = exe.run(program=fleet.main_program, fetch_list=[self.avg_cost.name])\n                loss_val = np.mean(loss_val)\n                reduce_output = fleet.util.all_reduce(np.array(loss_val), mode='sum')\n                loss_all_trainer = fleet.util.all_gather(float(loss_val))\n                loss_val = float(reduce_output) / len(loss_all_trainer)\n                message = f'TRAIN ---> pass: {epoch_id} loss: {loss_val}\\n'\n                fleet.util.print_on_rank(message, 0)\n            pass_time = time.time() - pass_start\n        except base.core.EOFException:\n            self.reader.reset()\n    model_dir = tempfile.mkdtemp()\n    fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n    if fleet.is_first_worker():\n        self.check_model_right(model_dir)\n    if fleet.is_first_worker():\n        fleet.save_persistables(executor=exe, dirname=model_dir)\n    shutil.rmtree(model_dir)",
        "mutated": [
            "def do_pyreader_training(self, fleet):\n    if False:\n        i = 10\n    '\\n        do training using dataset, using fetch handler to catch variable\\n        Args:\\n            fleet(Fleet api): the fleet object of Parameter Server, define distribute training role\\n        '\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    batch_size = 4\n    train_reader = paddle.batch(fake_ctr_reader(), batch_size=batch_size)\n    self.reader.decorate_sample_list_generator(train_reader)\n    for epoch_id in range(1):\n        self.reader.start()\n        try:\n            pass_start = time.time()\n            while True:\n                loss_val = exe.run(program=fleet.main_program, fetch_list=[self.avg_cost.name])\n                loss_val = np.mean(loss_val)\n                reduce_output = fleet.util.all_reduce(np.array(loss_val), mode='sum')\n                loss_all_trainer = fleet.util.all_gather(float(loss_val))\n                loss_val = float(reduce_output) / len(loss_all_trainer)\n                message = f'TRAIN ---> pass: {epoch_id} loss: {loss_val}\\n'\n                fleet.util.print_on_rank(message, 0)\n            pass_time = time.time() - pass_start\n        except base.core.EOFException:\n            self.reader.reset()\n    model_dir = tempfile.mkdtemp()\n    fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n    if fleet.is_first_worker():\n        self.check_model_right(model_dir)\n    if fleet.is_first_worker():\n        fleet.save_persistables(executor=exe, dirname=model_dir)\n    shutil.rmtree(model_dir)",
            "def do_pyreader_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        do training using dataset, using fetch handler to catch variable\\n        Args:\\n            fleet(Fleet api): the fleet object of Parameter Server, define distribute training role\\n        '\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    batch_size = 4\n    train_reader = paddle.batch(fake_ctr_reader(), batch_size=batch_size)\n    self.reader.decorate_sample_list_generator(train_reader)\n    for epoch_id in range(1):\n        self.reader.start()\n        try:\n            pass_start = time.time()\n            while True:\n                loss_val = exe.run(program=fleet.main_program, fetch_list=[self.avg_cost.name])\n                loss_val = np.mean(loss_val)\n                reduce_output = fleet.util.all_reduce(np.array(loss_val), mode='sum')\n                loss_all_trainer = fleet.util.all_gather(float(loss_val))\n                loss_val = float(reduce_output) / len(loss_all_trainer)\n                message = f'TRAIN ---> pass: {epoch_id} loss: {loss_val}\\n'\n                fleet.util.print_on_rank(message, 0)\n            pass_time = time.time() - pass_start\n        except base.core.EOFException:\n            self.reader.reset()\n    model_dir = tempfile.mkdtemp()\n    fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n    if fleet.is_first_worker():\n        self.check_model_right(model_dir)\n    if fleet.is_first_worker():\n        fleet.save_persistables(executor=exe, dirname=model_dir)\n    shutil.rmtree(model_dir)",
            "def do_pyreader_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        do training using dataset, using fetch handler to catch variable\\n        Args:\\n            fleet(Fleet api): the fleet object of Parameter Server, define distribute training role\\n        '\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    batch_size = 4\n    train_reader = paddle.batch(fake_ctr_reader(), batch_size=batch_size)\n    self.reader.decorate_sample_list_generator(train_reader)\n    for epoch_id in range(1):\n        self.reader.start()\n        try:\n            pass_start = time.time()\n            while True:\n                loss_val = exe.run(program=fleet.main_program, fetch_list=[self.avg_cost.name])\n                loss_val = np.mean(loss_val)\n                reduce_output = fleet.util.all_reduce(np.array(loss_val), mode='sum')\n                loss_all_trainer = fleet.util.all_gather(float(loss_val))\n                loss_val = float(reduce_output) / len(loss_all_trainer)\n                message = f'TRAIN ---> pass: {epoch_id} loss: {loss_val}\\n'\n                fleet.util.print_on_rank(message, 0)\n            pass_time = time.time() - pass_start\n        except base.core.EOFException:\n            self.reader.reset()\n    model_dir = tempfile.mkdtemp()\n    fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n    if fleet.is_first_worker():\n        self.check_model_right(model_dir)\n    if fleet.is_first_worker():\n        fleet.save_persistables(executor=exe, dirname=model_dir)\n    shutil.rmtree(model_dir)",
            "def do_pyreader_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        do training using dataset, using fetch handler to catch variable\\n        Args:\\n            fleet(Fleet api): the fleet object of Parameter Server, define distribute training role\\n        '\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    batch_size = 4\n    train_reader = paddle.batch(fake_ctr_reader(), batch_size=batch_size)\n    self.reader.decorate_sample_list_generator(train_reader)\n    for epoch_id in range(1):\n        self.reader.start()\n        try:\n            pass_start = time.time()\n            while True:\n                loss_val = exe.run(program=fleet.main_program, fetch_list=[self.avg_cost.name])\n                loss_val = np.mean(loss_val)\n                reduce_output = fleet.util.all_reduce(np.array(loss_val), mode='sum')\n                loss_all_trainer = fleet.util.all_gather(float(loss_val))\n                loss_val = float(reduce_output) / len(loss_all_trainer)\n                message = f'TRAIN ---> pass: {epoch_id} loss: {loss_val}\\n'\n                fleet.util.print_on_rank(message, 0)\n            pass_time = time.time() - pass_start\n        except base.core.EOFException:\n            self.reader.reset()\n    model_dir = tempfile.mkdtemp()\n    fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n    if fleet.is_first_worker():\n        self.check_model_right(model_dir)\n    if fleet.is_first_worker():\n        fleet.save_persistables(executor=exe, dirname=model_dir)\n    shutil.rmtree(model_dir)",
            "def do_pyreader_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        do training using dataset, using fetch handler to catch variable\\n        Args:\\n            fleet(Fleet api): the fleet object of Parameter Server, define distribute training role\\n        '\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    batch_size = 4\n    train_reader = paddle.batch(fake_ctr_reader(), batch_size=batch_size)\n    self.reader.decorate_sample_list_generator(train_reader)\n    for epoch_id in range(1):\n        self.reader.start()\n        try:\n            pass_start = time.time()\n            while True:\n                loss_val = exe.run(program=fleet.main_program, fetch_list=[self.avg_cost.name])\n                loss_val = np.mean(loss_val)\n                reduce_output = fleet.util.all_reduce(np.array(loss_val), mode='sum')\n                loss_all_trainer = fleet.util.all_gather(float(loss_val))\n                loss_val = float(reduce_output) / len(loss_all_trainer)\n                message = f'TRAIN ---> pass: {epoch_id} loss: {loss_val}\\n'\n                fleet.util.print_on_rank(message, 0)\n            pass_time = time.time() - pass_start\n        except base.core.EOFException:\n            self.reader.reset()\n    model_dir = tempfile.mkdtemp()\n    fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n    if fleet.is_first_worker():\n        self.check_model_right(model_dir)\n    if fleet.is_first_worker():\n        fleet.save_persistables(executor=exe, dirname=model_dir)\n    shutil.rmtree(model_dir)"
        ]
    },
    {
        "func_name": "do_dataset_training",
        "original": "def do_dataset_training(self, fleet):\n    (dnn_input_dim, lr_input_dim, train_file_path) = ctr_dataset_reader.prepare_data()\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    thread_num = 2\n    batch_size = 128\n    filelist = []\n    for _ in range(thread_num):\n        filelist.append(train_file_path)\n    dataset = paddle.distributed.QueueDataset()\n    dataset._set_batch_size(batch_size)\n    dataset._set_use_var(self.feeds)\n    pipe_command = 'python ctr_dataset_reader.py'\n    dataset._set_pipe_command(pipe_command)\n    dataset.set_filelist(filelist)\n    dataset._set_thread(thread_num)\n    for epoch_id in range(1):\n        pass_start = time.time()\n        dataset.set_filelist(filelist)\n        exe.train_from_dataset(program=fleet.main_program, dataset=dataset, fetch_list=[self.avg_cost], fetch_info=['cost'], print_period=2, debug=int(os.getenv('Debug', '0')))\n        pass_time = time.time() - pass_start\n    if os.getenv('SAVE_MODEL') == '1':\n        model_dir = tempfile.mkdtemp()\n        fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n        if fleet.is_first_worker():\n            self.check_model_right(model_dir)\n        if fleet.is_first_worker():\n            fleet.save_persistables(executor=exe, dirname=model_dir)\n        shutil.rmtree(model_dir)",
        "mutated": [
            "def do_dataset_training(self, fleet):\n    if False:\n        i = 10\n    (dnn_input_dim, lr_input_dim, train_file_path) = ctr_dataset_reader.prepare_data()\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    thread_num = 2\n    batch_size = 128\n    filelist = []\n    for _ in range(thread_num):\n        filelist.append(train_file_path)\n    dataset = paddle.distributed.QueueDataset()\n    dataset._set_batch_size(batch_size)\n    dataset._set_use_var(self.feeds)\n    pipe_command = 'python ctr_dataset_reader.py'\n    dataset._set_pipe_command(pipe_command)\n    dataset.set_filelist(filelist)\n    dataset._set_thread(thread_num)\n    for epoch_id in range(1):\n        pass_start = time.time()\n        dataset.set_filelist(filelist)\n        exe.train_from_dataset(program=fleet.main_program, dataset=dataset, fetch_list=[self.avg_cost], fetch_info=['cost'], print_period=2, debug=int(os.getenv('Debug', '0')))\n        pass_time = time.time() - pass_start\n    if os.getenv('SAVE_MODEL') == '1':\n        model_dir = tempfile.mkdtemp()\n        fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n        if fleet.is_first_worker():\n            self.check_model_right(model_dir)\n        if fleet.is_first_worker():\n            fleet.save_persistables(executor=exe, dirname=model_dir)\n        shutil.rmtree(model_dir)",
            "def do_dataset_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (dnn_input_dim, lr_input_dim, train_file_path) = ctr_dataset_reader.prepare_data()\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    thread_num = 2\n    batch_size = 128\n    filelist = []\n    for _ in range(thread_num):\n        filelist.append(train_file_path)\n    dataset = paddle.distributed.QueueDataset()\n    dataset._set_batch_size(batch_size)\n    dataset._set_use_var(self.feeds)\n    pipe_command = 'python ctr_dataset_reader.py'\n    dataset._set_pipe_command(pipe_command)\n    dataset.set_filelist(filelist)\n    dataset._set_thread(thread_num)\n    for epoch_id in range(1):\n        pass_start = time.time()\n        dataset.set_filelist(filelist)\n        exe.train_from_dataset(program=fleet.main_program, dataset=dataset, fetch_list=[self.avg_cost], fetch_info=['cost'], print_period=2, debug=int(os.getenv('Debug', '0')))\n        pass_time = time.time() - pass_start\n    if os.getenv('SAVE_MODEL') == '1':\n        model_dir = tempfile.mkdtemp()\n        fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n        if fleet.is_first_worker():\n            self.check_model_right(model_dir)\n        if fleet.is_first_worker():\n            fleet.save_persistables(executor=exe, dirname=model_dir)\n        shutil.rmtree(model_dir)",
            "def do_dataset_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (dnn_input_dim, lr_input_dim, train_file_path) = ctr_dataset_reader.prepare_data()\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    thread_num = 2\n    batch_size = 128\n    filelist = []\n    for _ in range(thread_num):\n        filelist.append(train_file_path)\n    dataset = paddle.distributed.QueueDataset()\n    dataset._set_batch_size(batch_size)\n    dataset._set_use_var(self.feeds)\n    pipe_command = 'python ctr_dataset_reader.py'\n    dataset._set_pipe_command(pipe_command)\n    dataset.set_filelist(filelist)\n    dataset._set_thread(thread_num)\n    for epoch_id in range(1):\n        pass_start = time.time()\n        dataset.set_filelist(filelist)\n        exe.train_from_dataset(program=fleet.main_program, dataset=dataset, fetch_list=[self.avg_cost], fetch_info=['cost'], print_period=2, debug=int(os.getenv('Debug', '0')))\n        pass_time = time.time() - pass_start\n    if os.getenv('SAVE_MODEL') == '1':\n        model_dir = tempfile.mkdtemp()\n        fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n        if fleet.is_first_worker():\n            self.check_model_right(model_dir)\n        if fleet.is_first_worker():\n            fleet.save_persistables(executor=exe, dirname=model_dir)\n        shutil.rmtree(model_dir)",
            "def do_dataset_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (dnn_input_dim, lr_input_dim, train_file_path) = ctr_dataset_reader.prepare_data()\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    thread_num = 2\n    batch_size = 128\n    filelist = []\n    for _ in range(thread_num):\n        filelist.append(train_file_path)\n    dataset = paddle.distributed.QueueDataset()\n    dataset._set_batch_size(batch_size)\n    dataset._set_use_var(self.feeds)\n    pipe_command = 'python ctr_dataset_reader.py'\n    dataset._set_pipe_command(pipe_command)\n    dataset.set_filelist(filelist)\n    dataset._set_thread(thread_num)\n    for epoch_id in range(1):\n        pass_start = time.time()\n        dataset.set_filelist(filelist)\n        exe.train_from_dataset(program=fleet.main_program, dataset=dataset, fetch_list=[self.avg_cost], fetch_info=['cost'], print_period=2, debug=int(os.getenv('Debug', '0')))\n        pass_time = time.time() - pass_start\n    if os.getenv('SAVE_MODEL') == '1':\n        model_dir = tempfile.mkdtemp()\n        fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n        if fleet.is_first_worker():\n            self.check_model_right(model_dir)\n        if fleet.is_first_worker():\n            fleet.save_persistables(executor=exe, dirname=model_dir)\n        shutil.rmtree(model_dir)",
            "def do_dataset_training(self, fleet):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (dnn_input_dim, lr_input_dim, train_file_path) = ctr_dataset_reader.prepare_data()\n    device_id = int(os.getenv('FLAGS_selected_gpus', '0'))\n    place = base.CUDAPlace(device_id)\n    exe = base.Executor(place)\n    exe.run(fleet.startup_program)\n    fleet.init_worker()\n    thread_num = 2\n    batch_size = 128\n    filelist = []\n    for _ in range(thread_num):\n        filelist.append(train_file_path)\n    dataset = paddle.distributed.QueueDataset()\n    dataset._set_batch_size(batch_size)\n    dataset._set_use_var(self.feeds)\n    pipe_command = 'python ctr_dataset_reader.py'\n    dataset._set_pipe_command(pipe_command)\n    dataset.set_filelist(filelist)\n    dataset._set_thread(thread_num)\n    for epoch_id in range(1):\n        pass_start = time.time()\n        dataset.set_filelist(filelist)\n        exe.train_from_dataset(program=fleet.main_program, dataset=dataset, fetch_list=[self.avg_cost], fetch_info=['cost'], print_period=2, debug=int(os.getenv('Debug', '0')))\n        pass_time = time.time() - pass_start\n    if os.getenv('SAVE_MODEL') == '1':\n        model_dir = tempfile.mkdtemp()\n        fleet.save_inference_model(exe, model_dir, [feed.name for feed in self.feeds], self.avg_cost)\n        if fleet.is_first_worker():\n            self.check_model_right(model_dir)\n        if fleet.is_first_worker():\n            fleet.save_persistables(executor=exe, dirname=model_dir)\n        shutil.rmtree(model_dir)"
        ]
    }
]