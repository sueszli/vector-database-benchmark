[
    {
        "func_name": "map_fn",
        "original": "def map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None):\n    \"\"\"map on the list of tensors unpacked from `elems` on dimension 0.\n\n  The simplest version of `map_fn` repeatedly applies the callable `fn` to a\n  sequence of elements from first to last. The elements are made of the\n  tensors unpacked from `elems`. `dtype` is the data type of the return\n  value of `fn`. Users must provide `dtype` if it is different from\n  the data type of `elems`.\n\n  Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n  of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\n\n  This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n  is a (possibly nested) list or tuple of tensors, then each of these tensors\n  must have a matching first (unpack) dimension.  The signature of `fn` may\n  match the structure of `elems`.  That is, if `elems` is\n  `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n  `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n\n  Furthermore, `fn` may emit a different structure than its input.  For example,\n  `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\n  the `dtype` parameter is not optional: `dtype` must be a type or (possibly\n  nested) tuple of types matching the output of `fn`.\n\n  To apply a functional operation to the nonzero elements of a SparseTensor\n  one of the following methods is recommended. First, if the function is\n  expressible as TensorFlow ops, use\n\n  ```python\n    result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\n  ```\n\n  If, however, the function is not expressible as a TensorFlow op, then use\n\n  ```python\n  result = SparseTensor(\n    input.indices, map_fn(fn, input.values), input.dense_shape)\n  ```\n\n  instead.\n\n  When executing eagerly, map_fn does not execute in parallel even if\n  `parallel_iterations` is set to a value > 1. You can still get the\n  performance benefits of running a function in parallel by using the\n  `tf.contrib.eager.defun` decorator,\n\n  ```python\n  # Assume the function being used in map_fn is fn.\n  # To ensure map_fn calls fn in parallel, use the defun decorator.\n  @tf.contrib.eager.defun\n  def func(tensor):\n    return tf.map_fn(fn, tensor)\n  ```\n\n  Note that if you use the defun decorator, any non-TensorFlow Python code\n  that you may have written in your function won't get executed. See\n  `tf.contrib.eager.defun` for more details. The recommendation would be to\n  debug without defun but switch to defun to get performance benefits of\n  running map_fn in parallel.\n\n  Args:\n    fn: The callable to be performed.  It accepts one argument, which will have\n      the same (possibly nested) structure as `elems`.  Its output must have the\n      same structure as `dtype` if one is provided, otherwise it must have the\n      same structure as `elems`.\n    elems: A tensor or (possibly nested) sequence of tensors, each of which will\n      be unpacked along their first dimension.  The nested sequence of the\n      resulting slices will be applied to `fn`.\n    dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\n      of Tensors differing from the structure of `elems`, then `dtype` is not\n      optional and must have the same structure as the output of `fn`. Use\n      `RaggedTensorType` to declare an output of type `RaggedTensor`.\n    parallel_iterations: (optional) The number of iterations allowed to run in\n      parallel. When graph building, the default value is 10. While executing\n      eagerly, the default value is set to 1.\n    back_prop: (optional) True enables support for back propagation.\n    swap_memory: (optional) True enables GPU-CPU memory swapping.\n    infer_shape: (optional) False disables tests for consistent output shapes.\n    name: (optional) Name prefix for the returned tensors.\n\n  Returns:\n    A possibly nested sequence of potentially ragged tensors.  Each\n    tensor packs the results of applying `fn` to tensors unpacked from `elems`\n    along the first dimension, from first to last.\n\n  Raises:\n    TypeError: if `fn` is not callable or the structure of the output of\n      `fn` and `dtype` do not match, or if elems is a SparseTensor.\n    ValueError: if the lengths of the output of `fn` and `dtype` do not match.\n\n  #### Examples:\n\n    ```python\n    elems = np.array([1, 2, 3, 4, 5, 6])\n    squares = map_fn(lambda x: x * x, elems)\n    # squares == [1, 4, 9, 16, 25, 36]\n    ```\n\n    ```python\n    elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n    alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n    # alternate == [-1, 2, -3]\n    ```\n\n    ```python\n    elems = np.array([1, 2, 3])\n    alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\n    # alternates[0] == [1, 2, 3]\n    # alternates[1] == [-1, -2, -3]\n    ```\n\n    ```python\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]])\n    mean = map_fn(tf.reduce_mean, elems)\n    # mean == [2, 4, 6]\n    ```\n\n    ```python\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]], dtype=tf.int64)\n    out = map_fn(fn=lambda x: x+1, elems,\n      dtype=ragged.RaggedTensorType(type=tf.int64, ragged_rank=0))\n    # out = tf.ragged.constant([[2, 3, 4], [5, 6], [7, 8]])\n    ```\n  \"\"\"\n    if dtype is None:\n        dtype = nest.map_structure(lambda e: e.dtype, elems)\n    dtype = nest.map_structure(_ragged_type_to_spec, dtype)\n    return map_fn_lib.map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)",
        "mutated": [
            "def map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None):\n    if False:\n        i = 10\n    \"map on the list of tensors unpacked from `elems` on dimension 0.\\n\\n  The simplest version of `map_fn` repeatedly applies the callable `fn` to a\\n  sequence of elements from first to last. The elements are made of the\\n  tensors unpacked from `elems`. `dtype` is the data type of the return\\n  value of `fn`. Users must provide `dtype` if it is different from\\n  the data type of `elems`.\\n\\n  Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\\n  of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\\n\\n  This method also allows multi-arity `elems` and output of `fn`.  If `elems`\\n  is a (possibly nested) list or tuple of tensors, then each of these tensors\\n  must have a matching first (unpack) dimension.  The signature of `fn` may\\n  match the structure of `elems`.  That is, if `elems` is\\n  `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\\n  `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\\n\\n  Furthermore, `fn` may emit a different structure than its input.  For example,\\n  `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\\n  the `dtype` parameter is not optional: `dtype` must be a type or (possibly\\n  nested) tuple of types matching the output of `fn`.\\n\\n  To apply a functional operation to the nonzero elements of a SparseTensor\\n  one of the following methods is recommended. First, if the function is\\n  expressible as TensorFlow ops, use\\n\\n  ```python\\n    result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\\n  ```\\n\\n  If, however, the function is not expressible as a TensorFlow op, then use\\n\\n  ```python\\n  result = SparseTensor(\\n    input.indices, map_fn(fn, input.values), input.dense_shape)\\n  ```\\n\\n  instead.\\n\\n  When executing eagerly, map_fn does not execute in parallel even if\\n  `parallel_iterations` is set to a value > 1. You can still get the\\n  performance benefits of running a function in parallel by using the\\n  `tf.contrib.eager.defun` decorator,\\n\\n  ```python\\n  # Assume the function being used in map_fn is fn.\\n  # To ensure map_fn calls fn in parallel, use the defun decorator.\\n  @tf.contrib.eager.defun\\n  def func(tensor):\\n    return tf.map_fn(fn, tensor)\\n  ```\\n\\n  Note that if you use the defun decorator, any non-TensorFlow Python code\\n  that you may have written in your function won't get executed. See\\n  `tf.contrib.eager.defun` for more details. The recommendation would be to\\n  debug without defun but switch to defun to get performance benefits of\\n  running map_fn in parallel.\\n\\n  Args:\\n    fn: The callable to be performed.  It accepts one argument, which will have\\n      the same (possibly nested) structure as `elems`.  Its output must have the\\n      same structure as `dtype` if one is provided, otherwise it must have the\\n      same structure as `elems`.\\n    elems: A tensor or (possibly nested) sequence of tensors, each of which will\\n      be unpacked along their first dimension.  The nested sequence of the\\n      resulting slices will be applied to `fn`.\\n    dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\\n      of Tensors differing from the structure of `elems`, then `dtype` is not\\n      optional and must have the same structure as the output of `fn`. Use\\n      `RaggedTensorType` to declare an output of type `RaggedTensor`.\\n    parallel_iterations: (optional) The number of iterations allowed to run in\\n      parallel. When graph building, the default value is 10. While executing\\n      eagerly, the default value is set to 1.\\n    back_prop: (optional) True enables support for back propagation.\\n    swap_memory: (optional) True enables GPU-CPU memory swapping.\\n    infer_shape: (optional) False disables tests for consistent output shapes.\\n    name: (optional) Name prefix for the returned tensors.\\n\\n  Returns:\\n    A possibly nested sequence of potentially ragged tensors.  Each\\n    tensor packs the results of applying `fn` to tensors unpacked from `elems`\\n    along the first dimension, from first to last.\\n\\n  Raises:\\n    TypeError: if `fn` is not callable or the structure of the output of\\n      `fn` and `dtype` do not match, or if elems is a SparseTensor.\\n    ValueError: if the lengths of the output of `fn` and `dtype` do not match.\\n\\n  #### Examples:\\n\\n    ```python\\n    elems = np.array([1, 2, 3, 4, 5, 6])\\n    squares = map_fn(lambda x: x * x, elems)\\n    # squares == [1, 4, 9, 16, 25, 36]\\n    ```\\n\\n    ```python\\n    elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\\n    alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\\n    # alternate == [-1, 2, -3]\\n    ```\\n\\n    ```python\\n    elems = np.array([1, 2, 3])\\n    alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\\n    # alternates[0] == [1, 2, 3]\\n    # alternates[1] == [-1, -2, -3]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]])\\n    mean = map_fn(tf.reduce_mean, elems)\\n    # mean == [2, 4, 6]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]], dtype=tf.int64)\\n    out = map_fn(fn=lambda x: x+1, elems,\\n      dtype=ragged.RaggedTensorType(type=tf.int64, ragged_rank=0))\\n    # out = tf.ragged.constant([[2, 3, 4], [5, 6], [7, 8]])\\n    ```\\n  \"\n    if dtype is None:\n        dtype = nest.map_structure(lambda e: e.dtype, elems)\n    dtype = nest.map_structure(_ragged_type_to_spec, dtype)\n    return map_fn_lib.map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)",
            "def map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"map on the list of tensors unpacked from `elems` on dimension 0.\\n\\n  The simplest version of `map_fn` repeatedly applies the callable `fn` to a\\n  sequence of elements from first to last. The elements are made of the\\n  tensors unpacked from `elems`. `dtype` is the data type of the return\\n  value of `fn`. Users must provide `dtype` if it is different from\\n  the data type of `elems`.\\n\\n  Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\\n  of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\\n\\n  This method also allows multi-arity `elems` and output of `fn`.  If `elems`\\n  is a (possibly nested) list or tuple of tensors, then each of these tensors\\n  must have a matching first (unpack) dimension.  The signature of `fn` may\\n  match the structure of `elems`.  That is, if `elems` is\\n  `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\\n  `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\\n\\n  Furthermore, `fn` may emit a different structure than its input.  For example,\\n  `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\\n  the `dtype` parameter is not optional: `dtype` must be a type or (possibly\\n  nested) tuple of types matching the output of `fn`.\\n\\n  To apply a functional operation to the nonzero elements of a SparseTensor\\n  one of the following methods is recommended. First, if the function is\\n  expressible as TensorFlow ops, use\\n\\n  ```python\\n    result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\\n  ```\\n\\n  If, however, the function is not expressible as a TensorFlow op, then use\\n\\n  ```python\\n  result = SparseTensor(\\n    input.indices, map_fn(fn, input.values), input.dense_shape)\\n  ```\\n\\n  instead.\\n\\n  When executing eagerly, map_fn does not execute in parallel even if\\n  `parallel_iterations` is set to a value > 1. You can still get the\\n  performance benefits of running a function in parallel by using the\\n  `tf.contrib.eager.defun` decorator,\\n\\n  ```python\\n  # Assume the function being used in map_fn is fn.\\n  # To ensure map_fn calls fn in parallel, use the defun decorator.\\n  @tf.contrib.eager.defun\\n  def func(tensor):\\n    return tf.map_fn(fn, tensor)\\n  ```\\n\\n  Note that if you use the defun decorator, any non-TensorFlow Python code\\n  that you may have written in your function won't get executed. See\\n  `tf.contrib.eager.defun` for more details. The recommendation would be to\\n  debug without defun but switch to defun to get performance benefits of\\n  running map_fn in parallel.\\n\\n  Args:\\n    fn: The callable to be performed.  It accepts one argument, which will have\\n      the same (possibly nested) structure as `elems`.  Its output must have the\\n      same structure as `dtype` if one is provided, otherwise it must have the\\n      same structure as `elems`.\\n    elems: A tensor or (possibly nested) sequence of tensors, each of which will\\n      be unpacked along their first dimension.  The nested sequence of the\\n      resulting slices will be applied to `fn`.\\n    dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\\n      of Tensors differing from the structure of `elems`, then `dtype` is not\\n      optional and must have the same structure as the output of `fn`. Use\\n      `RaggedTensorType` to declare an output of type `RaggedTensor`.\\n    parallel_iterations: (optional) The number of iterations allowed to run in\\n      parallel. When graph building, the default value is 10. While executing\\n      eagerly, the default value is set to 1.\\n    back_prop: (optional) True enables support for back propagation.\\n    swap_memory: (optional) True enables GPU-CPU memory swapping.\\n    infer_shape: (optional) False disables tests for consistent output shapes.\\n    name: (optional) Name prefix for the returned tensors.\\n\\n  Returns:\\n    A possibly nested sequence of potentially ragged tensors.  Each\\n    tensor packs the results of applying `fn` to tensors unpacked from `elems`\\n    along the first dimension, from first to last.\\n\\n  Raises:\\n    TypeError: if `fn` is not callable or the structure of the output of\\n      `fn` and `dtype` do not match, or if elems is a SparseTensor.\\n    ValueError: if the lengths of the output of `fn` and `dtype` do not match.\\n\\n  #### Examples:\\n\\n    ```python\\n    elems = np.array([1, 2, 3, 4, 5, 6])\\n    squares = map_fn(lambda x: x * x, elems)\\n    # squares == [1, 4, 9, 16, 25, 36]\\n    ```\\n\\n    ```python\\n    elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\\n    alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\\n    # alternate == [-1, 2, -3]\\n    ```\\n\\n    ```python\\n    elems = np.array([1, 2, 3])\\n    alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\\n    # alternates[0] == [1, 2, 3]\\n    # alternates[1] == [-1, -2, -3]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]])\\n    mean = map_fn(tf.reduce_mean, elems)\\n    # mean == [2, 4, 6]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]], dtype=tf.int64)\\n    out = map_fn(fn=lambda x: x+1, elems,\\n      dtype=ragged.RaggedTensorType(type=tf.int64, ragged_rank=0))\\n    # out = tf.ragged.constant([[2, 3, 4], [5, 6], [7, 8]])\\n    ```\\n  \"\n    if dtype is None:\n        dtype = nest.map_structure(lambda e: e.dtype, elems)\n    dtype = nest.map_structure(_ragged_type_to_spec, dtype)\n    return map_fn_lib.map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)",
            "def map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"map on the list of tensors unpacked from `elems` on dimension 0.\\n\\n  The simplest version of `map_fn` repeatedly applies the callable `fn` to a\\n  sequence of elements from first to last. The elements are made of the\\n  tensors unpacked from `elems`. `dtype` is the data type of the return\\n  value of `fn`. Users must provide `dtype` if it is different from\\n  the data type of `elems`.\\n\\n  Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\\n  of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\\n\\n  This method also allows multi-arity `elems` and output of `fn`.  If `elems`\\n  is a (possibly nested) list or tuple of tensors, then each of these tensors\\n  must have a matching first (unpack) dimension.  The signature of `fn` may\\n  match the structure of `elems`.  That is, if `elems` is\\n  `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\\n  `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\\n\\n  Furthermore, `fn` may emit a different structure than its input.  For example,\\n  `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\\n  the `dtype` parameter is not optional: `dtype` must be a type or (possibly\\n  nested) tuple of types matching the output of `fn`.\\n\\n  To apply a functional operation to the nonzero elements of a SparseTensor\\n  one of the following methods is recommended. First, if the function is\\n  expressible as TensorFlow ops, use\\n\\n  ```python\\n    result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\\n  ```\\n\\n  If, however, the function is not expressible as a TensorFlow op, then use\\n\\n  ```python\\n  result = SparseTensor(\\n    input.indices, map_fn(fn, input.values), input.dense_shape)\\n  ```\\n\\n  instead.\\n\\n  When executing eagerly, map_fn does not execute in parallel even if\\n  `parallel_iterations` is set to a value > 1. You can still get the\\n  performance benefits of running a function in parallel by using the\\n  `tf.contrib.eager.defun` decorator,\\n\\n  ```python\\n  # Assume the function being used in map_fn is fn.\\n  # To ensure map_fn calls fn in parallel, use the defun decorator.\\n  @tf.contrib.eager.defun\\n  def func(tensor):\\n    return tf.map_fn(fn, tensor)\\n  ```\\n\\n  Note that if you use the defun decorator, any non-TensorFlow Python code\\n  that you may have written in your function won't get executed. See\\n  `tf.contrib.eager.defun` for more details. The recommendation would be to\\n  debug without defun but switch to defun to get performance benefits of\\n  running map_fn in parallel.\\n\\n  Args:\\n    fn: The callable to be performed.  It accepts one argument, which will have\\n      the same (possibly nested) structure as `elems`.  Its output must have the\\n      same structure as `dtype` if one is provided, otherwise it must have the\\n      same structure as `elems`.\\n    elems: A tensor or (possibly nested) sequence of tensors, each of which will\\n      be unpacked along their first dimension.  The nested sequence of the\\n      resulting slices will be applied to `fn`.\\n    dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\\n      of Tensors differing from the structure of `elems`, then `dtype` is not\\n      optional and must have the same structure as the output of `fn`. Use\\n      `RaggedTensorType` to declare an output of type `RaggedTensor`.\\n    parallel_iterations: (optional) The number of iterations allowed to run in\\n      parallel. When graph building, the default value is 10. While executing\\n      eagerly, the default value is set to 1.\\n    back_prop: (optional) True enables support for back propagation.\\n    swap_memory: (optional) True enables GPU-CPU memory swapping.\\n    infer_shape: (optional) False disables tests for consistent output shapes.\\n    name: (optional) Name prefix for the returned tensors.\\n\\n  Returns:\\n    A possibly nested sequence of potentially ragged tensors.  Each\\n    tensor packs the results of applying `fn` to tensors unpacked from `elems`\\n    along the first dimension, from first to last.\\n\\n  Raises:\\n    TypeError: if `fn` is not callable or the structure of the output of\\n      `fn` and `dtype` do not match, or if elems is a SparseTensor.\\n    ValueError: if the lengths of the output of `fn` and `dtype` do not match.\\n\\n  #### Examples:\\n\\n    ```python\\n    elems = np.array([1, 2, 3, 4, 5, 6])\\n    squares = map_fn(lambda x: x * x, elems)\\n    # squares == [1, 4, 9, 16, 25, 36]\\n    ```\\n\\n    ```python\\n    elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\\n    alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\\n    # alternate == [-1, 2, -3]\\n    ```\\n\\n    ```python\\n    elems = np.array([1, 2, 3])\\n    alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\\n    # alternates[0] == [1, 2, 3]\\n    # alternates[1] == [-1, -2, -3]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]])\\n    mean = map_fn(tf.reduce_mean, elems)\\n    # mean == [2, 4, 6]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]], dtype=tf.int64)\\n    out = map_fn(fn=lambda x: x+1, elems,\\n      dtype=ragged.RaggedTensorType(type=tf.int64, ragged_rank=0))\\n    # out = tf.ragged.constant([[2, 3, 4], [5, 6], [7, 8]])\\n    ```\\n  \"\n    if dtype is None:\n        dtype = nest.map_structure(lambda e: e.dtype, elems)\n    dtype = nest.map_structure(_ragged_type_to_spec, dtype)\n    return map_fn_lib.map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)",
            "def map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"map on the list of tensors unpacked from `elems` on dimension 0.\\n\\n  The simplest version of `map_fn` repeatedly applies the callable `fn` to a\\n  sequence of elements from first to last. The elements are made of the\\n  tensors unpacked from `elems`. `dtype` is the data type of the return\\n  value of `fn`. Users must provide `dtype` if it is different from\\n  the data type of `elems`.\\n\\n  Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\\n  of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\\n\\n  This method also allows multi-arity `elems` and output of `fn`.  If `elems`\\n  is a (possibly nested) list or tuple of tensors, then each of these tensors\\n  must have a matching first (unpack) dimension.  The signature of `fn` may\\n  match the structure of `elems`.  That is, if `elems` is\\n  `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\\n  `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\\n\\n  Furthermore, `fn` may emit a different structure than its input.  For example,\\n  `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\\n  the `dtype` parameter is not optional: `dtype` must be a type or (possibly\\n  nested) tuple of types matching the output of `fn`.\\n\\n  To apply a functional operation to the nonzero elements of a SparseTensor\\n  one of the following methods is recommended. First, if the function is\\n  expressible as TensorFlow ops, use\\n\\n  ```python\\n    result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\\n  ```\\n\\n  If, however, the function is not expressible as a TensorFlow op, then use\\n\\n  ```python\\n  result = SparseTensor(\\n    input.indices, map_fn(fn, input.values), input.dense_shape)\\n  ```\\n\\n  instead.\\n\\n  When executing eagerly, map_fn does not execute in parallel even if\\n  `parallel_iterations` is set to a value > 1. You can still get the\\n  performance benefits of running a function in parallel by using the\\n  `tf.contrib.eager.defun` decorator,\\n\\n  ```python\\n  # Assume the function being used in map_fn is fn.\\n  # To ensure map_fn calls fn in parallel, use the defun decorator.\\n  @tf.contrib.eager.defun\\n  def func(tensor):\\n    return tf.map_fn(fn, tensor)\\n  ```\\n\\n  Note that if you use the defun decorator, any non-TensorFlow Python code\\n  that you may have written in your function won't get executed. See\\n  `tf.contrib.eager.defun` for more details. The recommendation would be to\\n  debug without defun but switch to defun to get performance benefits of\\n  running map_fn in parallel.\\n\\n  Args:\\n    fn: The callable to be performed.  It accepts one argument, which will have\\n      the same (possibly nested) structure as `elems`.  Its output must have the\\n      same structure as `dtype` if one is provided, otherwise it must have the\\n      same structure as `elems`.\\n    elems: A tensor or (possibly nested) sequence of tensors, each of which will\\n      be unpacked along their first dimension.  The nested sequence of the\\n      resulting slices will be applied to `fn`.\\n    dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\\n      of Tensors differing from the structure of `elems`, then `dtype` is not\\n      optional and must have the same structure as the output of `fn`. Use\\n      `RaggedTensorType` to declare an output of type `RaggedTensor`.\\n    parallel_iterations: (optional) The number of iterations allowed to run in\\n      parallel. When graph building, the default value is 10. While executing\\n      eagerly, the default value is set to 1.\\n    back_prop: (optional) True enables support for back propagation.\\n    swap_memory: (optional) True enables GPU-CPU memory swapping.\\n    infer_shape: (optional) False disables tests for consistent output shapes.\\n    name: (optional) Name prefix for the returned tensors.\\n\\n  Returns:\\n    A possibly nested sequence of potentially ragged tensors.  Each\\n    tensor packs the results of applying `fn` to tensors unpacked from `elems`\\n    along the first dimension, from first to last.\\n\\n  Raises:\\n    TypeError: if `fn` is not callable or the structure of the output of\\n      `fn` and `dtype` do not match, or if elems is a SparseTensor.\\n    ValueError: if the lengths of the output of `fn` and `dtype` do not match.\\n\\n  #### Examples:\\n\\n    ```python\\n    elems = np.array([1, 2, 3, 4, 5, 6])\\n    squares = map_fn(lambda x: x * x, elems)\\n    # squares == [1, 4, 9, 16, 25, 36]\\n    ```\\n\\n    ```python\\n    elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\\n    alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\\n    # alternate == [-1, 2, -3]\\n    ```\\n\\n    ```python\\n    elems = np.array([1, 2, 3])\\n    alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\\n    # alternates[0] == [1, 2, 3]\\n    # alternates[1] == [-1, -2, -3]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]])\\n    mean = map_fn(tf.reduce_mean, elems)\\n    # mean == [2, 4, 6]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]], dtype=tf.int64)\\n    out = map_fn(fn=lambda x: x+1, elems,\\n      dtype=ragged.RaggedTensorType(type=tf.int64, ragged_rank=0))\\n    # out = tf.ragged.constant([[2, 3, 4], [5, 6], [7, 8]])\\n    ```\\n  \"\n    if dtype is None:\n        dtype = nest.map_structure(lambda e: e.dtype, elems)\n    dtype = nest.map_structure(_ragged_type_to_spec, dtype)\n    return map_fn_lib.map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)",
            "def map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"map on the list of tensors unpacked from `elems` on dimension 0.\\n\\n  The simplest version of `map_fn` repeatedly applies the callable `fn` to a\\n  sequence of elements from first to last. The elements are made of the\\n  tensors unpacked from `elems`. `dtype` is the data type of the return\\n  value of `fn`. Users must provide `dtype` if it is different from\\n  the data type of `elems`.\\n\\n  Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\\n  of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\\n\\n  This method also allows multi-arity `elems` and output of `fn`.  If `elems`\\n  is a (possibly nested) list or tuple of tensors, then each of these tensors\\n  must have a matching first (unpack) dimension.  The signature of `fn` may\\n  match the structure of `elems`.  That is, if `elems` is\\n  `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\\n  `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\\n\\n  Furthermore, `fn` may emit a different structure than its input.  For example,\\n  `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\\n  the `dtype` parameter is not optional: `dtype` must be a type or (possibly\\n  nested) tuple of types matching the output of `fn`.\\n\\n  To apply a functional operation to the nonzero elements of a SparseTensor\\n  one of the following methods is recommended. First, if the function is\\n  expressible as TensorFlow ops, use\\n\\n  ```python\\n    result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\\n  ```\\n\\n  If, however, the function is not expressible as a TensorFlow op, then use\\n\\n  ```python\\n  result = SparseTensor(\\n    input.indices, map_fn(fn, input.values), input.dense_shape)\\n  ```\\n\\n  instead.\\n\\n  When executing eagerly, map_fn does not execute in parallel even if\\n  `parallel_iterations` is set to a value > 1. You can still get the\\n  performance benefits of running a function in parallel by using the\\n  `tf.contrib.eager.defun` decorator,\\n\\n  ```python\\n  # Assume the function being used in map_fn is fn.\\n  # To ensure map_fn calls fn in parallel, use the defun decorator.\\n  @tf.contrib.eager.defun\\n  def func(tensor):\\n    return tf.map_fn(fn, tensor)\\n  ```\\n\\n  Note that if you use the defun decorator, any non-TensorFlow Python code\\n  that you may have written in your function won't get executed. See\\n  `tf.contrib.eager.defun` for more details. The recommendation would be to\\n  debug without defun but switch to defun to get performance benefits of\\n  running map_fn in parallel.\\n\\n  Args:\\n    fn: The callable to be performed.  It accepts one argument, which will have\\n      the same (possibly nested) structure as `elems`.  Its output must have the\\n      same structure as `dtype` if one is provided, otherwise it must have the\\n      same structure as `elems`.\\n    elems: A tensor or (possibly nested) sequence of tensors, each of which will\\n      be unpacked along their first dimension.  The nested sequence of the\\n      resulting slices will be applied to `fn`.\\n    dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\\n      of Tensors differing from the structure of `elems`, then `dtype` is not\\n      optional and must have the same structure as the output of `fn`. Use\\n      `RaggedTensorType` to declare an output of type `RaggedTensor`.\\n    parallel_iterations: (optional) The number of iterations allowed to run in\\n      parallel. When graph building, the default value is 10. While executing\\n      eagerly, the default value is set to 1.\\n    back_prop: (optional) True enables support for back propagation.\\n    swap_memory: (optional) True enables GPU-CPU memory swapping.\\n    infer_shape: (optional) False disables tests for consistent output shapes.\\n    name: (optional) Name prefix for the returned tensors.\\n\\n  Returns:\\n    A possibly nested sequence of potentially ragged tensors.  Each\\n    tensor packs the results of applying `fn` to tensors unpacked from `elems`\\n    along the first dimension, from first to last.\\n\\n  Raises:\\n    TypeError: if `fn` is not callable or the structure of the output of\\n      `fn` and `dtype` do not match, or if elems is a SparseTensor.\\n    ValueError: if the lengths of the output of `fn` and `dtype` do not match.\\n\\n  #### Examples:\\n\\n    ```python\\n    elems = np.array([1, 2, 3, 4, 5, 6])\\n    squares = map_fn(lambda x: x * x, elems)\\n    # squares == [1, 4, 9, 16, 25, 36]\\n    ```\\n\\n    ```python\\n    elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\\n    alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\\n    # alternate == [-1, 2, -3]\\n    ```\\n\\n    ```python\\n    elems = np.array([1, 2, 3])\\n    alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\\n    # alternates[0] == [1, 2, 3]\\n    # alternates[1] == [-1, -2, -3]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]])\\n    mean = map_fn(tf.reduce_mean, elems)\\n    # mean == [2, 4, 6]\\n    ```\\n\\n    ```python\\n    elems=ragged.constant([[1, 2, 3], [4, 5], [6, 7]], dtype=tf.int64)\\n    out = map_fn(fn=lambda x: x+1, elems,\\n      dtype=ragged.RaggedTensorType(type=tf.int64, ragged_rank=0))\\n    # out = tf.ragged.constant([[2, 3, 4], [5, 6], [7, 8]])\\n    ```\\n  \"\n    if dtype is None:\n        dtype = nest.map_structure(lambda e: e.dtype, elems)\n    dtype = nest.map_structure(_ragged_type_to_spec, dtype)\n    return map_fn_lib.map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)"
        ]
    },
    {
        "func_name": "_ragged_type_to_spec",
        "original": "def _ragged_type_to_spec(t):\n    if isinstance(t, ragged_tensor.RaggedTensorType):\n        return ragged_tensor.RaggedTensorSpec(None, t.dtype, t.ragged_rank - 1, t.row_splits_dtype)\n    else:\n        return t",
        "mutated": [
            "def _ragged_type_to_spec(t):\n    if False:\n        i = 10\n    if isinstance(t, ragged_tensor.RaggedTensorType):\n        return ragged_tensor.RaggedTensorSpec(None, t.dtype, t.ragged_rank - 1, t.row_splits_dtype)\n    else:\n        return t",
            "def _ragged_type_to_spec(t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(t, ragged_tensor.RaggedTensorType):\n        return ragged_tensor.RaggedTensorSpec(None, t.dtype, t.ragged_rank - 1, t.row_splits_dtype)\n    else:\n        return t",
            "def _ragged_type_to_spec(t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(t, ragged_tensor.RaggedTensorType):\n        return ragged_tensor.RaggedTensorSpec(None, t.dtype, t.ragged_rank - 1, t.row_splits_dtype)\n    else:\n        return t",
            "def _ragged_type_to_spec(t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(t, ragged_tensor.RaggedTensorType):\n        return ragged_tensor.RaggedTensorSpec(None, t.dtype, t.ragged_rank - 1, t.row_splits_dtype)\n    else:\n        return t",
            "def _ragged_type_to_spec(t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(t, ragged_tensor.RaggedTensorType):\n        return ragged_tensor.RaggedTensorSpec(None, t.dtype, t.ragged_rank - 1, t.row_splits_dtype)\n    else:\n        return t"
        ]
    }
]