[
    {
        "func_name": "load_sframe",
        "original": "def load_sframe(filename):\n    \"\"\"\n    Load an SFrame. The filename extension is used to determine the format\n    automatically. This function is particularly useful for SFrames previously\n    saved in binary format. For CSV imports the ``SFrame.read_csv`` function\n    provides greater control. If the SFrame is in binary format, ``filename`` is\n    actually a directory, created when the SFrame is saved.\n\n    Parameters\n    ----------\n    filename : string\n        Location of the file to load. Can be a local path or a remote URL.\n\n    Returns\n    -------\n    out : SFrame\n\n    See Also\n    --------\n    SFrame.save, SFrame.read_csv\n\n    Examples\n    --------\n    >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\n    >>> sf.save('my_sframe')        # 'my_sframe' is a directory\n    >>> sf_loaded = turicreate.load_sframe('my_sframe')\n    \"\"\"\n    sf = SFrame(data=filename)\n    return sf",
        "mutated": [
            "def load_sframe(filename):\n    if False:\n        i = 10\n    \"\\n    Load an SFrame. The filename extension is used to determine the format\\n    automatically. This function is particularly useful for SFrames previously\\n    saved in binary format. For CSV imports the ``SFrame.read_csv`` function\\n    provides greater control. If the SFrame is in binary format, ``filename`` is\\n    actually a directory, created when the SFrame is saved.\\n\\n    Parameters\\n    ----------\\n    filename : string\\n        Location of the file to load. Can be a local path or a remote URL.\\n\\n    Returns\\n    -------\\n    out : SFrame\\n\\n    See Also\\n    --------\\n    SFrame.save, SFrame.read_csv\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n    >>> sf.save('my_sframe')        # 'my_sframe' is a directory\\n    >>> sf_loaded = turicreate.load_sframe('my_sframe')\\n    \"\n    sf = SFrame(data=filename)\n    return sf",
            "def load_sframe(filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Load an SFrame. The filename extension is used to determine the format\\n    automatically. This function is particularly useful for SFrames previously\\n    saved in binary format. For CSV imports the ``SFrame.read_csv`` function\\n    provides greater control. If the SFrame is in binary format, ``filename`` is\\n    actually a directory, created when the SFrame is saved.\\n\\n    Parameters\\n    ----------\\n    filename : string\\n        Location of the file to load. Can be a local path or a remote URL.\\n\\n    Returns\\n    -------\\n    out : SFrame\\n\\n    See Also\\n    --------\\n    SFrame.save, SFrame.read_csv\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n    >>> sf.save('my_sframe')        # 'my_sframe' is a directory\\n    >>> sf_loaded = turicreate.load_sframe('my_sframe')\\n    \"\n    sf = SFrame(data=filename)\n    return sf",
            "def load_sframe(filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Load an SFrame. The filename extension is used to determine the format\\n    automatically. This function is particularly useful for SFrames previously\\n    saved in binary format. For CSV imports the ``SFrame.read_csv`` function\\n    provides greater control. If the SFrame is in binary format, ``filename`` is\\n    actually a directory, created when the SFrame is saved.\\n\\n    Parameters\\n    ----------\\n    filename : string\\n        Location of the file to load. Can be a local path or a remote URL.\\n\\n    Returns\\n    -------\\n    out : SFrame\\n\\n    See Also\\n    --------\\n    SFrame.save, SFrame.read_csv\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n    >>> sf.save('my_sframe')        # 'my_sframe' is a directory\\n    >>> sf_loaded = turicreate.load_sframe('my_sframe')\\n    \"\n    sf = SFrame(data=filename)\n    return sf",
            "def load_sframe(filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Load an SFrame. The filename extension is used to determine the format\\n    automatically. This function is particularly useful for SFrames previously\\n    saved in binary format. For CSV imports the ``SFrame.read_csv`` function\\n    provides greater control. If the SFrame is in binary format, ``filename`` is\\n    actually a directory, created when the SFrame is saved.\\n\\n    Parameters\\n    ----------\\n    filename : string\\n        Location of the file to load. Can be a local path or a remote URL.\\n\\n    Returns\\n    -------\\n    out : SFrame\\n\\n    See Also\\n    --------\\n    SFrame.save, SFrame.read_csv\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n    >>> sf.save('my_sframe')        # 'my_sframe' is a directory\\n    >>> sf_loaded = turicreate.load_sframe('my_sframe')\\n    \"\n    sf = SFrame(data=filename)\n    return sf",
            "def load_sframe(filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Load an SFrame. The filename extension is used to determine the format\\n    automatically. This function is particularly useful for SFrames previously\\n    saved in binary format. For CSV imports the ``SFrame.read_csv`` function\\n    provides greater control. If the SFrame is in binary format, ``filename`` is\\n    actually a directory, created when the SFrame is saved.\\n\\n    Parameters\\n    ----------\\n    filename : string\\n        Location of the file to load. Can be a local path or a remote URL.\\n\\n    Returns\\n    -------\\n    out : SFrame\\n\\n    See Also\\n    --------\\n    SFrame.save, SFrame.read_csv\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n    >>> sf.save('my_sframe')        # 'my_sframe' is a directory\\n    >>> sf_loaded = turicreate.load_sframe('my_sframe')\\n    \"\n    sf = SFrame(data=filename)\n    return sf"
        ]
    },
    {
        "func_name": "_get_global_dbapi_info",
        "original": "def _get_global_dbapi_info(dbapi_module, conn):\n    \"\"\"\n    Fetches all needed information from the top-level DBAPI module,\n    guessing at the module if it wasn't passed as a parameter. Returns a\n    dictionary of all the needed variables. This is put in one place to\n    make sure the error message is clear if the module \"guess\" is wrong.\n    \"\"\"\n    module_given_msg = 'The DBAPI2 module given ({0}) is missing the global\\n' + \"variable '{1}'. Please make sure you are supplying a module that\\n\" + 'conforms to the DBAPI 2.0 standard (PEP 0249).'\n    module_not_given_msg = 'Hello! I gave my best effort to find the\\n' + 'top-level module that the connection object you gave me came from.\\n' + \"I found '{0}' which doesn't have the global variable '{1}'.\\n\" + 'To avoid this confusion, you can pass the module as a parameter using\\n' + \"the 'dbapi_module' argument to either from_sql or to_sql.\"\n    if dbapi_module is None:\n        dbapi_module = _get_module_from_object(conn)\n        module_given = False\n    else:\n        module_given = True\n    module_name = dbapi_module.__name__ if hasattr(dbapi_module, '__name__') else None\n    needed_vars = ['apilevel', 'paramstyle', 'Error', 'DATETIME', 'NUMBER', 'ROWID']\n    ret_dict = {}\n    ret_dict['module_name'] = module_name\n    for i in needed_vars:\n        tmp = None\n        try:\n            tmp = eval('dbapi_module.' + i)\n        except AttributeError as e:\n            if i not in ['apilevel', 'paramstyle', 'Error']:\n                pass\n            elif module_given:\n                raise AttributeError(module_given_msg.format(module_name, i))\n            else:\n                raise AttributeError(module_not_given_msg.format(module_name, i))\n        ret_dict[i] = tmp\n    try:\n        if ret_dict['apilevel'][0:3] != '2.0':\n            raise NotImplementedError('Unsupported API version ' + str(ret_dict['apilevel']) + '. Only DBAPI 2.0 is supported.')\n    except TypeError as e:\n        e.message = \"Module's 'apilevel' value is invalid.\"\n        raise e\n    acceptable_paramstyles = ['qmark', 'numeric', 'named', 'format', 'pyformat']\n    try:\n        if ret_dict['paramstyle'] not in acceptable_paramstyles:\n            raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    except TypeError as e:\n        raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    return ret_dict",
        "mutated": [
            "def _get_global_dbapi_info(dbapi_module, conn):\n    if False:\n        i = 10\n    '\\n    Fetches all needed information from the top-level DBAPI module,\\n    guessing at the module if it wasn\\'t passed as a parameter. Returns a\\n    dictionary of all the needed variables. This is put in one place to\\n    make sure the error message is clear if the module \"guess\" is wrong.\\n    '\n    module_given_msg = 'The DBAPI2 module given ({0}) is missing the global\\n' + \"variable '{1}'. Please make sure you are supplying a module that\\n\" + 'conforms to the DBAPI 2.0 standard (PEP 0249).'\n    module_not_given_msg = 'Hello! I gave my best effort to find the\\n' + 'top-level module that the connection object you gave me came from.\\n' + \"I found '{0}' which doesn't have the global variable '{1}'.\\n\" + 'To avoid this confusion, you can pass the module as a parameter using\\n' + \"the 'dbapi_module' argument to either from_sql or to_sql.\"\n    if dbapi_module is None:\n        dbapi_module = _get_module_from_object(conn)\n        module_given = False\n    else:\n        module_given = True\n    module_name = dbapi_module.__name__ if hasattr(dbapi_module, '__name__') else None\n    needed_vars = ['apilevel', 'paramstyle', 'Error', 'DATETIME', 'NUMBER', 'ROWID']\n    ret_dict = {}\n    ret_dict['module_name'] = module_name\n    for i in needed_vars:\n        tmp = None\n        try:\n            tmp = eval('dbapi_module.' + i)\n        except AttributeError as e:\n            if i not in ['apilevel', 'paramstyle', 'Error']:\n                pass\n            elif module_given:\n                raise AttributeError(module_given_msg.format(module_name, i))\n            else:\n                raise AttributeError(module_not_given_msg.format(module_name, i))\n        ret_dict[i] = tmp\n    try:\n        if ret_dict['apilevel'][0:3] != '2.0':\n            raise NotImplementedError('Unsupported API version ' + str(ret_dict['apilevel']) + '. Only DBAPI 2.0 is supported.')\n    except TypeError as e:\n        e.message = \"Module's 'apilevel' value is invalid.\"\n        raise e\n    acceptable_paramstyles = ['qmark', 'numeric', 'named', 'format', 'pyformat']\n    try:\n        if ret_dict['paramstyle'] not in acceptable_paramstyles:\n            raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    except TypeError as e:\n        raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    return ret_dict",
            "def _get_global_dbapi_info(dbapi_module, conn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Fetches all needed information from the top-level DBAPI module,\\n    guessing at the module if it wasn\\'t passed as a parameter. Returns a\\n    dictionary of all the needed variables. This is put in one place to\\n    make sure the error message is clear if the module \"guess\" is wrong.\\n    '\n    module_given_msg = 'The DBAPI2 module given ({0}) is missing the global\\n' + \"variable '{1}'. Please make sure you are supplying a module that\\n\" + 'conforms to the DBAPI 2.0 standard (PEP 0249).'\n    module_not_given_msg = 'Hello! I gave my best effort to find the\\n' + 'top-level module that the connection object you gave me came from.\\n' + \"I found '{0}' which doesn't have the global variable '{1}'.\\n\" + 'To avoid this confusion, you can pass the module as a parameter using\\n' + \"the 'dbapi_module' argument to either from_sql or to_sql.\"\n    if dbapi_module is None:\n        dbapi_module = _get_module_from_object(conn)\n        module_given = False\n    else:\n        module_given = True\n    module_name = dbapi_module.__name__ if hasattr(dbapi_module, '__name__') else None\n    needed_vars = ['apilevel', 'paramstyle', 'Error', 'DATETIME', 'NUMBER', 'ROWID']\n    ret_dict = {}\n    ret_dict['module_name'] = module_name\n    for i in needed_vars:\n        tmp = None\n        try:\n            tmp = eval('dbapi_module.' + i)\n        except AttributeError as e:\n            if i not in ['apilevel', 'paramstyle', 'Error']:\n                pass\n            elif module_given:\n                raise AttributeError(module_given_msg.format(module_name, i))\n            else:\n                raise AttributeError(module_not_given_msg.format(module_name, i))\n        ret_dict[i] = tmp\n    try:\n        if ret_dict['apilevel'][0:3] != '2.0':\n            raise NotImplementedError('Unsupported API version ' + str(ret_dict['apilevel']) + '. Only DBAPI 2.0 is supported.')\n    except TypeError as e:\n        e.message = \"Module's 'apilevel' value is invalid.\"\n        raise e\n    acceptable_paramstyles = ['qmark', 'numeric', 'named', 'format', 'pyformat']\n    try:\n        if ret_dict['paramstyle'] not in acceptable_paramstyles:\n            raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    except TypeError as e:\n        raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    return ret_dict",
            "def _get_global_dbapi_info(dbapi_module, conn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Fetches all needed information from the top-level DBAPI module,\\n    guessing at the module if it wasn\\'t passed as a parameter. Returns a\\n    dictionary of all the needed variables. This is put in one place to\\n    make sure the error message is clear if the module \"guess\" is wrong.\\n    '\n    module_given_msg = 'The DBAPI2 module given ({0}) is missing the global\\n' + \"variable '{1}'. Please make sure you are supplying a module that\\n\" + 'conforms to the DBAPI 2.0 standard (PEP 0249).'\n    module_not_given_msg = 'Hello! I gave my best effort to find the\\n' + 'top-level module that the connection object you gave me came from.\\n' + \"I found '{0}' which doesn't have the global variable '{1}'.\\n\" + 'To avoid this confusion, you can pass the module as a parameter using\\n' + \"the 'dbapi_module' argument to either from_sql or to_sql.\"\n    if dbapi_module is None:\n        dbapi_module = _get_module_from_object(conn)\n        module_given = False\n    else:\n        module_given = True\n    module_name = dbapi_module.__name__ if hasattr(dbapi_module, '__name__') else None\n    needed_vars = ['apilevel', 'paramstyle', 'Error', 'DATETIME', 'NUMBER', 'ROWID']\n    ret_dict = {}\n    ret_dict['module_name'] = module_name\n    for i in needed_vars:\n        tmp = None\n        try:\n            tmp = eval('dbapi_module.' + i)\n        except AttributeError as e:\n            if i not in ['apilevel', 'paramstyle', 'Error']:\n                pass\n            elif module_given:\n                raise AttributeError(module_given_msg.format(module_name, i))\n            else:\n                raise AttributeError(module_not_given_msg.format(module_name, i))\n        ret_dict[i] = tmp\n    try:\n        if ret_dict['apilevel'][0:3] != '2.0':\n            raise NotImplementedError('Unsupported API version ' + str(ret_dict['apilevel']) + '. Only DBAPI 2.0 is supported.')\n    except TypeError as e:\n        e.message = \"Module's 'apilevel' value is invalid.\"\n        raise e\n    acceptable_paramstyles = ['qmark', 'numeric', 'named', 'format', 'pyformat']\n    try:\n        if ret_dict['paramstyle'] not in acceptable_paramstyles:\n            raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    except TypeError as e:\n        raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    return ret_dict",
            "def _get_global_dbapi_info(dbapi_module, conn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Fetches all needed information from the top-level DBAPI module,\\n    guessing at the module if it wasn\\'t passed as a parameter. Returns a\\n    dictionary of all the needed variables. This is put in one place to\\n    make sure the error message is clear if the module \"guess\" is wrong.\\n    '\n    module_given_msg = 'The DBAPI2 module given ({0}) is missing the global\\n' + \"variable '{1}'. Please make sure you are supplying a module that\\n\" + 'conforms to the DBAPI 2.0 standard (PEP 0249).'\n    module_not_given_msg = 'Hello! I gave my best effort to find the\\n' + 'top-level module that the connection object you gave me came from.\\n' + \"I found '{0}' which doesn't have the global variable '{1}'.\\n\" + 'To avoid this confusion, you can pass the module as a parameter using\\n' + \"the 'dbapi_module' argument to either from_sql or to_sql.\"\n    if dbapi_module is None:\n        dbapi_module = _get_module_from_object(conn)\n        module_given = False\n    else:\n        module_given = True\n    module_name = dbapi_module.__name__ if hasattr(dbapi_module, '__name__') else None\n    needed_vars = ['apilevel', 'paramstyle', 'Error', 'DATETIME', 'NUMBER', 'ROWID']\n    ret_dict = {}\n    ret_dict['module_name'] = module_name\n    for i in needed_vars:\n        tmp = None\n        try:\n            tmp = eval('dbapi_module.' + i)\n        except AttributeError as e:\n            if i not in ['apilevel', 'paramstyle', 'Error']:\n                pass\n            elif module_given:\n                raise AttributeError(module_given_msg.format(module_name, i))\n            else:\n                raise AttributeError(module_not_given_msg.format(module_name, i))\n        ret_dict[i] = tmp\n    try:\n        if ret_dict['apilevel'][0:3] != '2.0':\n            raise NotImplementedError('Unsupported API version ' + str(ret_dict['apilevel']) + '. Only DBAPI 2.0 is supported.')\n    except TypeError as e:\n        e.message = \"Module's 'apilevel' value is invalid.\"\n        raise e\n    acceptable_paramstyles = ['qmark', 'numeric', 'named', 'format', 'pyformat']\n    try:\n        if ret_dict['paramstyle'] not in acceptable_paramstyles:\n            raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    except TypeError as e:\n        raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    return ret_dict",
            "def _get_global_dbapi_info(dbapi_module, conn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Fetches all needed information from the top-level DBAPI module,\\n    guessing at the module if it wasn\\'t passed as a parameter. Returns a\\n    dictionary of all the needed variables. This is put in one place to\\n    make sure the error message is clear if the module \"guess\" is wrong.\\n    '\n    module_given_msg = 'The DBAPI2 module given ({0}) is missing the global\\n' + \"variable '{1}'. Please make sure you are supplying a module that\\n\" + 'conforms to the DBAPI 2.0 standard (PEP 0249).'\n    module_not_given_msg = 'Hello! I gave my best effort to find the\\n' + 'top-level module that the connection object you gave me came from.\\n' + \"I found '{0}' which doesn't have the global variable '{1}'.\\n\" + 'To avoid this confusion, you can pass the module as a parameter using\\n' + \"the 'dbapi_module' argument to either from_sql or to_sql.\"\n    if dbapi_module is None:\n        dbapi_module = _get_module_from_object(conn)\n        module_given = False\n    else:\n        module_given = True\n    module_name = dbapi_module.__name__ if hasattr(dbapi_module, '__name__') else None\n    needed_vars = ['apilevel', 'paramstyle', 'Error', 'DATETIME', 'NUMBER', 'ROWID']\n    ret_dict = {}\n    ret_dict['module_name'] = module_name\n    for i in needed_vars:\n        tmp = None\n        try:\n            tmp = eval('dbapi_module.' + i)\n        except AttributeError as e:\n            if i not in ['apilevel', 'paramstyle', 'Error']:\n                pass\n            elif module_given:\n                raise AttributeError(module_given_msg.format(module_name, i))\n            else:\n                raise AttributeError(module_not_given_msg.format(module_name, i))\n        ret_dict[i] = tmp\n    try:\n        if ret_dict['apilevel'][0:3] != '2.0':\n            raise NotImplementedError('Unsupported API version ' + str(ret_dict['apilevel']) + '. Only DBAPI 2.0 is supported.')\n    except TypeError as e:\n        e.message = \"Module's 'apilevel' value is invalid.\"\n        raise e\n    acceptable_paramstyles = ['qmark', 'numeric', 'named', 'format', 'pyformat']\n    try:\n        if ret_dict['paramstyle'] not in acceptable_paramstyles:\n            raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    except TypeError as e:\n        raise TypeError(\"Module's 'paramstyle' value is invalid.\")\n    return ret_dict"
        ]
    },
    {
        "func_name": "_convert_rows_to_builtin_seq",
        "original": "def _convert_rows_to_builtin_seq(data):\n    if len(data) > 0 and type(data[0]) != list:\n        data = [list(row) for row in data]\n    return data",
        "mutated": [
            "def _convert_rows_to_builtin_seq(data):\n    if False:\n        i = 10\n    if len(data) > 0 and type(data[0]) != list:\n        data = [list(row) for row in data]\n    return data",
            "def _convert_rows_to_builtin_seq(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(data) > 0 and type(data[0]) != list:\n        data = [list(row) for row in data]\n    return data",
            "def _convert_rows_to_builtin_seq(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(data) > 0 and type(data[0]) != list:\n        data = [list(row) for row in data]\n    return data",
            "def _convert_rows_to_builtin_seq(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(data) > 0 and type(data[0]) != list:\n        data = [list(row) for row in data]\n    return data",
            "def _convert_rows_to_builtin_seq(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(data) > 0 and type(data[0]) != list:\n        data = [list(row) for row in data]\n    return data"
        ]
    },
    {
        "func_name": "_force_cast_sql_types",
        "original": "def _force_cast_sql_types(data, result_types, force_cast_cols):\n    if len(force_cast_cols) == 0:\n        return data\n    ret_data = []\n    for row in data:\n        for idx in force_cast_cols:\n            if row[idx] is not None and result_types[idx] != datetime.datetime:\n                row[idx] = result_types[idx](row[idx])\n        ret_data.append(row)\n    return ret_data",
        "mutated": [
            "def _force_cast_sql_types(data, result_types, force_cast_cols):\n    if False:\n        i = 10\n    if len(force_cast_cols) == 0:\n        return data\n    ret_data = []\n    for row in data:\n        for idx in force_cast_cols:\n            if row[idx] is not None and result_types[idx] != datetime.datetime:\n                row[idx] = result_types[idx](row[idx])\n        ret_data.append(row)\n    return ret_data",
            "def _force_cast_sql_types(data, result_types, force_cast_cols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(force_cast_cols) == 0:\n        return data\n    ret_data = []\n    for row in data:\n        for idx in force_cast_cols:\n            if row[idx] is not None and result_types[idx] != datetime.datetime:\n                row[idx] = result_types[idx](row[idx])\n        ret_data.append(row)\n    return ret_data",
            "def _force_cast_sql_types(data, result_types, force_cast_cols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(force_cast_cols) == 0:\n        return data\n    ret_data = []\n    for row in data:\n        for idx in force_cast_cols:\n            if row[idx] is not None and result_types[idx] != datetime.datetime:\n                row[idx] = result_types[idx](row[idx])\n        ret_data.append(row)\n    return ret_data",
            "def _force_cast_sql_types(data, result_types, force_cast_cols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(force_cast_cols) == 0:\n        return data\n    ret_data = []\n    for row in data:\n        for idx in force_cast_cols:\n            if row[idx] is not None and result_types[idx] != datetime.datetime:\n                row[idx] = result_types[idx](row[idx])\n        ret_data.append(row)\n    return ret_data",
            "def _force_cast_sql_types(data, result_types, force_cast_cols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(force_cast_cols) == 0:\n        return data\n    ret_data = []\n    for row in data:\n        for idx in force_cast_cols:\n            if row[idx] is not None and result_types[idx] != datetime.datetime:\n                row[idx] = result_types[idx](row[idx])\n        ret_data.append(row)\n    return ret_data"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, data=None, format='auto', _proxy=None):\n    \"\"\"__init__(data=list(), format='auto')\n        Construct a new SFrame from a url or a pandas.DataFrame.\n        \"\"\"\n    if _proxy:\n        self.__proxy__ = _proxy\n    else:\n        self.__proxy__ = UnitySFrameProxy()\n        _format = None\n        if six.PY2 and isinstance(data, unicode):\n            data = data.encode('utf-8')\n        if format == 'auto':\n            if HAS_PANDAS and isinstance(data, pandas.DataFrame):\n                _format = 'dataframe'\n            elif isinstance(data, str) or (sys.version_info.major < 3 and isinstance(data, unicode)):\n                if data.endswith(('.csv', '.csv.gz')):\n                    _format = 'csv'\n                elif data.endswith(('.tsv', '.tsv.gz')):\n                    _format = 'tsv'\n                elif data.endswith(('.txt', '.txt.gz')):\n                    print('Assuming file is csv. For other delimiters, ' + 'please use `SFrame.read_csv`.')\n                    _format = 'csv'\n                else:\n                    _format = 'sframe'\n            elif type(data) == SArray:\n                _format = 'sarray'\n            elif isinstance(data, SFrame):\n                _format = 'sframe_obj'\n            elif isinstance(data, dict):\n                _format = 'dict'\n            elif _is_non_string_iterable(data):\n                _format = 'array'\n            elif data is None:\n                _format = 'empty'\n            else:\n                raise ValueError('Cannot infer input type for data ' + str(data))\n        else:\n            _format = format\n        with cython_context():\n            if _format == 'dataframe':\n                for c in data.columns.values:\n                    self.add_column(SArray(data[c].values), str(c), inplace=True)\n            elif _format == 'sframe_obj':\n                for col in data.column_names():\n                    self.__proxy__.add_column(data[col].__proxy__, col)\n            elif _format == 'sarray':\n                self.__proxy__.add_column(data.__proxy__, '')\n            elif _format == 'array':\n                if len(data) > 0:\n                    unique_types = set([type(x) for x in data if x is not None])\n                    if len(unique_types) == 1 and SArray in unique_types:\n                        for arr in data:\n                            self.add_column(arr, inplace=True)\n                    elif SArray in unique_types:\n                        raise ValueError('Cannot create SFrame from mix of regular values and SArrays')\n                    else:\n                        self.__proxy__.add_column(SArray(data).__proxy__, '')\n            elif _format == 'dict':\n                if len(set((len(value) for value in data.values()))) > 1:\n                    raise RuntimeError('All column should be of the same length')\n                sarray_keys = sorted((key for (key, value) in six.iteritems(data) if isinstance(value, SArray)))\n                self.__proxy__.load_from_dataframe({key: value for (key, value) in six.iteritems(data) if not isinstance(value, SArray)})\n                for key in sarray_keys:\n                    self.__proxy__.add_column(data[key].__proxy__, key)\n            elif _format == 'csv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter=',', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'tsv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter='\\t', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'sframe':\n                url = _make_internal_url(data)\n                self.__proxy__.load_from_sframe_index(url)\n            elif _format == 'empty':\n                pass\n            else:\n                raise ValueError('Unknown input type: ' + format)",
        "mutated": [
            "def __init__(self, data=None, format='auto', _proxy=None):\n    if False:\n        i = 10\n    \"__init__(data=list(), format='auto')\\n        Construct a new SFrame from a url or a pandas.DataFrame.\\n        \"\n    if _proxy:\n        self.__proxy__ = _proxy\n    else:\n        self.__proxy__ = UnitySFrameProxy()\n        _format = None\n        if six.PY2 and isinstance(data, unicode):\n            data = data.encode('utf-8')\n        if format == 'auto':\n            if HAS_PANDAS and isinstance(data, pandas.DataFrame):\n                _format = 'dataframe'\n            elif isinstance(data, str) or (sys.version_info.major < 3 and isinstance(data, unicode)):\n                if data.endswith(('.csv', '.csv.gz')):\n                    _format = 'csv'\n                elif data.endswith(('.tsv', '.tsv.gz')):\n                    _format = 'tsv'\n                elif data.endswith(('.txt', '.txt.gz')):\n                    print('Assuming file is csv. For other delimiters, ' + 'please use `SFrame.read_csv`.')\n                    _format = 'csv'\n                else:\n                    _format = 'sframe'\n            elif type(data) == SArray:\n                _format = 'sarray'\n            elif isinstance(data, SFrame):\n                _format = 'sframe_obj'\n            elif isinstance(data, dict):\n                _format = 'dict'\n            elif _is_non_string_iterable(data):\n                _format = 'array'\n            elif data is None:\n                _format = 'empty'\n            else:\n                raise ValueError('Cannot infer input type for data ' + str(data))\n        else:\n            _format = format\n        with cython_context():\n            if _format == 'dataframe':\n                for c in data.columns.values:\n                    self.add_column(SArray(data[c].values), str(c), inplace=True)\n            elif _format == 'sframe_obj':\n                for col in data.column_names():\n                    self.__proxy__.add_column(data[col].__proxy__, col)\n            elif _format == 'sarray':\n                self.__proxy__.add_column(data.__proxy__, '')\n            elif _format == 'array':\n                if len(data) > 0:\n                    unique_types = set([type(x) for x in data if x is not None])\n                    if len(unique_types) == 1 and SArray in unique_types:\n                        for arr in data:\n                            self.add_column(arr, inplace=True)\n                    elif SArray in unique_types:\n                        raise ValueError('Cannot create SFrame from mix of regular values and SArrays')\n                    else:\n                        self.__proxy__.add_column(SArray(data).__proxy__, '')\n            elif _format == 'dict':\n                if len(set((len(value) for value in data.values()))) > 1:\n                    raise RuntimeError('All column should be of the same length')\n                sarray_keys = sorted((key for (key, value) in six.iteritems(data) if isinstance(value, SArray)))\n                self.__proxy__.load_from_dataframe({key: value for (key, value) in six.iteritems(data) if not isinstance(value, SArray)})\n                for key in sarray_keys:\n                    self.__proxy__.add_column(data[key].__proxy__, key)\n            elif _format == 'csv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter=',', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'tsv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter='\\t', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'sframe':\n                url = _make_internal_url(data)\n                self.__proxy__.load_from_sframe_index(url)\n            elif _format == 'empty':\n                pass\n            else:\n                raise ValueError('Unknown input type: ' + format)",
            "def __init__(self, data=None, format='auto', _proxy=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"__init__(data=list(), format='auto')\\n        Construct a new SFrame from a url or a pandas.DataFrame.\\n        \"\n    if _proxy:\n        self.__proxy__ = _proxy\n    else:\n        self.__proxy__ = UnitySFrameProxy()\n        _format = None\n        if six.PY2 and isinstance(data, unicode):\n            data = data.encode('utf-8')\n        if format == 'auto':\n            if HAS_PANDAS and isinstance(data, pandas.DataFrame):\n                _format = 'dataframe'\n            elif isinstance(data, str) or (sys.version_info.major < 3 and isinstance(data, unicode)):\n                if data.endswith(('.csv', '.csv.gz')):\n                    _format = 'csv'\n                elif data.endswith(('.tsv', '.tsv.gz')):\n                    _format = 'tsv'\n                elif data.endswith(('.txt', '.txt.gz')):\n                    print('Assuming file is csv. For other delimiters, ' + 'please use `SFrame.read_csv`.')\n                    _format = 'csv'\n                else:\n                    _format = 'sframe'\n            elif type(data) == SArray:\n                _format = 'sarray'\n            elif isinstance(data, SFrame):\n                _format = 'sframe_obj'\n            elif isinstance(data, dict):\n                _format = 'dict'\n            elif _is_non_string_iterable(data):\n                _format = 'array'\n            elif data is None:\n                _format = 'empty'\n            else:\n                raise ValueError('Cannot infer input type for data ' + str(data))\n        else:\n            _format = format\n        with cython_context():\n            if _format == 'dataframe':\n                for c in data.columns.values:\n                    self.add_column(SArray(data[c].values), str(c), inplace=True)\n            elif _format == 'sframe_obj':\n                for col in data.column_names():\n                    self.__proxy__.add_column(data[col].__proxy__, col)\n            elif _format == 'sarray':\n                self.__proxy__.add_column(data.__proxy__, '')\n            elif _format == 'array':\n                if len(data) > 0:\n                    unique_types = set([type(x) for x in data if x is not None])\n                    if len(unique_types) == 1 and SArray in unique_types:\n                        for arr in data:\n                            self.add_column(arr, inplace=True)\n                    elif SArray in unique_types:\n                        raise ValueError('Cannot create SFrame from mix of regular values and SArrays')\n                    else:\n                        self.__proxy__.add_column(SArray(data).__proxy__, '')\n            elif _format == 'dict':\n                if len(set((len(value) for value in data.values()))) > 1:\n                    raise RuntimeError('All column should be of the same length')\n                sarray_keys = sorted((key for (key, value) in six.iteritems(data) if isinstance(value, SArray)))\n                self.__proxy__.load_from_dataframe({key: value for (key, value) in six.iteritems(data) if not isinstance(value, SArray)})\n                for key in sarray_keys:\n                    self.__proxy__.add_column(data[key].__proxy__, key)\n            elif _format == 'csv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter=',', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'tsv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter='\\t', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'sframe':\n                url = _make_internal_url(data)\n                self.__proxy__.load_from_sframe_index(url)\n            elif _format == 'empty':\n                pass\n            else:\n                raise ValueError('Unknown input type: ' + format)",
            "def __init__(self, data=None, format='auto', _proxy=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"__init__(data=list(), format='auto')\\n        Construct a new SFrame from a url or a pandas.DataFrame.\\n        \"\n    if _proxy:\n        self.__proxy__ = _proxy\n    else:\n        self.__proxy__ = UnitySFrameProxy()\n        _format = None\n        if six.PY2 and isinstance(data, unicode):\n            data = data.encode('utf-8')\n        if format == 'auto':\n            if HAS_PANDAS and isinstance(data, pandas.DataFrame):\n                _format = 'dataframe'\n            elif isinstance(data, str) or (sys.version_info.major < 3 and isinstance(data, unicode)):\n                if data.endswith(('.csv', '.csv.gz')):\n                    _format = 'csv'\n                elif data.endswith(('.tsv', '.tsv.gz')):\n                    _format = 'tsv'\n                elif data.endswith(('.txt', '.txt.gz')):\n                    print('Assuming file is csv. For other delimiters, ' + 'please use `SFrame.read_csv`.')\n                    _format = 'csv'\n                else:\n                    _format = 'sframe'\n            elif type(data) == SArray:\n                _format = 'sarray'\n            elif isinstance(data, SFrame):\n                _format = 'sframe_obj'\n            elif isinstance(data, dict):\n                _format = 'dict'\n            elif _is_non_string_iterable(data):\n                _format = 'array'\n            elif data is None:\n                _format = 'empty'\n            else:\n                raise ValueError('Cannot infer input type for data ' + str(data))\n        else:\n            _format = format\n        with cython_context():\n            if _format == 'dataframe':\n                for c in data.columns.values:\n                    self.add_column(SArray(data[c].values), str(c), inplace=True)\n            elif _format == 'sframe_obj':\n                for col in data.column_names():\n                    self.__proxy__.add_column(data[col].__proxy__, col)\n            elif _format == 'sarray':\n                self.__proxy__.add_column(data.__proxy__, '')\n            elif _format == 'array':\n                if len(data) > 0:\n                    unique_types = set([type(x) for x in data if x is not None])\n                    if len(unique_types) == 1 and SArray in unique_types:\n                        for arr in data:\n                            self.add_column(arr, inplace=True)\n                    elif SArray in unique_types:\n                        raise ValueError('Cannot create SFrame from mix of regular values and SArrays')\n                    else:\n                        self.__proxy__.add_column(SArray(data).__proxy__, '')\n            elif _format == 'dict':\n                if len(set((len(value) for value in data.values()))) > 1:\n                    raise RuntimeError('All column should be of the same length')\n                sarray_keys = sorted((key for (key, value) in six.iteritems(data) if isinstance(value, SArray)))\n                self.__proxy__.load_from_dataframe({key: value for (key, value) in six.iteritems(data) if not isinstance(value, SArray)})\n                for key in sarray_keys:\n                    self.__proxy__.add_column(data[key].__proxy__, key)\n            elif _format == 'csv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter=',', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'tsv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter='\\t', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'sframe':\n                url = _make_internal_url(data)\n                self.__proxy__.load_from_sframe_index(url)\n            elif _format == 'empty':\n                pass\n            else:\n                raise ValueError('Unknown input type: ' + format)",
            "def __init__(self, data=None, format='auto', _proxy=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"__init__(data=list(), format='auto')\\n        Construct a new SFrame from a url or a pandas.DataFrame.\\n        \"\n    if _proxy:\n        self.__proxy__ = _proxy\n    else:\n        self.__proxy__ = UnitySFrameProxy()\n        _format = None\n        if six.PY2 and isinstance(data, unicode):\n            data = data.encode('utf-8')\n        if format == 'auto':\n            if HAS_PANDAS and isinstance(data, pandas.DataFrame):\n                _format = 'dataframe'\n            elif isinstance(data, str) or (sys.version_info.major < 3 and isinstance(data, unicode)):\n                if data.endswith(('.csv', '.csv.gz')):\n                    _format = 'csv'\n                elif data.endswith(('.tsv', '.tsv.gz')):\n                    _format = 'tsv'\n                elif data.endswith(('.txt', '.txt.gz')):\n                    print('Assuming file is csv. For other delimiters, ' + 'please use `SFrame.read_csv`.')\n                    _format = 'csv'\n                else:\n                    _format = 'sframe'\n            elif type(data) == SArray:\n                _format = 'sarray'\n            elif isinstance(data, SFrame):\n                _format = 'sframe_obj'\n            elif isinstance(data, dict):\n                _format = 'dict'\n            elif _is_non_string_iterable(data):\n                _format = 'array'\n            elif data is None:\n                _format = 'empty'\n            else:\n                raise ValueError('Cannot infer input type for data ' + str(data))\n        else:\n            _format = format\n        with cython_context():\n            if _format == 'dataframe':\n                for c in data.columns.values:\n                    self.add_column(SArray(data[c].values), str(c), inplace=True)\n            elif _format == 'sframe_obj':\n                for col in data.column_names():\n                    self.__proxy__.add_column(data[col].__proxy__, col)\n            elif _format == 'sarray':\n                self.__proxy__.add_column(data.__proxy__, '')\n            elif _format == 'array':\n                if len(data) > 0:\n                    unique_types = set([type(x) for x in data if x is not None])\n                    if len(unique_types) == 1 and SArray in unique_types:\n                        for arr in data:\n                            self.add_column(arr, inplace=True)\n                    elif SArray in unique_types:\n                        raise ValueError('Cannot create SFrame from mix of regular values and SArrays')\n                    else:\n                        self.__proxy__.add_column(SArray(data).__proxy__, '')\n            elif _format == 'dict':\n                if len(set((len(value) for value in data.values()))) > 1:\n                    raise RuntimeError('All column should be of the same length')\n                sarray_keys = sorted((key for (key, value) in six.iteritems(data) if isinstance(value, SArray)))\n                self.__proxy__.load_from_dataframe({key: value for (key, value) in six.iteritems(data) if not isinstance(value, SArray)})\n                for key in sarray_keys:\n                    self.__proxy__.add_column(data[key].__proxy__, key)\n            elif _format == 'csv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter=',', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'tsv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter='\\t', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'sframe':\n                url = _make_internal_url(data)\n                self.__proxy__.load_from_sframe_index(url)\n            elif _format == 'empty':\n                pass\n            else:\n                raise ValueError('Unknown input type: ' + format)",
            "def __init__(self, data=None, format='auto', _proxy=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"__init__(data=list(), format='auto')\\n        Construct a new SFrame from a url or a pandas.DataFrame.\\n        \"\n    if _proxy:\n        self.__proxy__ = _proxy\n    else:\n        self.__proxy__ = UnitySFrameProxy()\n        _format = None\n        if six.PY2 and isinstance(data, unicode):\n            data = data.encode('utf-8')\n        if format == 'auto':\n            if HAS_PANDAS and isinstance(data, pandas.DataFrame):\n                _format = 'dataframe'\n            elif isinstance(data, str) or (sys.version_info.major < 3 and isinstance(data, unicode)):\n                if data.endswith(('.csv', '.csv.gz')):\n                    _format = 'csv'\n                elif data.endswith(('.tsv', '.tsv.gz')):\n                    _format = 'tsv'\n                elif data.endswith(('.txt', '.txt.gz')):\n                    print('Assuming file is csv. For other delimiters, ' + 'please use `SFrame.read_csv`.')\n                    _format = 'csv'\n                else:\n                    _format = 'sframe'\n            elif type(data) == SArray:\n                _format = 'sarray'\n            elif isinstance(data, SFrame):\n                _format = 'sframe_obj'\n            elif isinstance(data, dict):\n                _format = 'dict'\n            elif _is_non_string_iterable(data):\n                _format = 'array'\n            elif data is None:\n                _format = 'empty'\n            else:\n                raise ValueError('Cannot infer input type for data ' + str(data))\n        else:\n            _format = format\n        with cython_context():\n            if _format == 'dataframe':\n                for c in data.columns.values:\n                    self.add_column(SArray(data[c].values), str(c), inplace=True)\n            elif _format == 'sframe_obj':\n                for col in data.column_names():\n                    self.__proxy__.add_column(data[col].__proxy__, col)\n            elif _format == 'sarray':\n                self.__proxy__.add_column(data.__proxy__, '')\n            elif _format == 'array':\n                if len(data) > 0:\n                    unique_types = set([type(x) for x in data if x is not None])\n                    if len(unique_types) == 1 and SArray in unique_types:\n                        for arr in data:\n                            self.add_column(arr, inplace=True)\n                    elif SArray in unique_types:\n                        raise ValueError('Cannot create SFrame from mix of regular values and SArrays')\n                    else:\n                        self.__proxy__.add_column(SArray(data).__proxy__, '')\n            elif _format == 'dict':\n                if len(set((len(value) for value in data.values()))) > 1:\n                    raise RuntimeError('All column should be of the same length')\n                sarray_keys = sorted((key for (key, value) in six.iteritems(data) if isinstance(value, SArray)))\n                self.__proxy__.load_from_dataframe({key: value for (key, value) in six.iteritems(data) if not isinstance(value, SArray)})\n                for key in sarray_keys:\n                    self.__proxy__.add_column(data[key].__proxy__, key)\n            elif _format == 'csv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter=',', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'tsv':\n                url = data\n                tmpsf = SFrame.read_csv(url, delimiter='\\t', header=True)\n                self.__proxy__ = tmpsf.__proxy__\n            elif _format == 'sframe':\n                url = _make_internal_url(data)\n                self.__proxy__.load_from_sframe_index(url)\n            elif _format == 'empty':\n                pass\n            else:\n                raise ValueError('Unknown input type: ' + format)"
        ]
    },
    {
        "func_name": "_infer_column_types_from_lines",
        "original": "@staticmethod\ndef _infer_column_types_from_lines(first_rows):\n    if len(first_rows.column_names()) < 1:\n        print('Insufficient number of columns to perform type inference')\n        raise RuntimeError('Insufficient columns ')\n    if len(first_rows) < 1:\n        print('Insufficient number of rows to perform type inference')\n        raise RuntimeError('Insufficient rows')\n    all_column_values_transposed = [list(first_rows[col]) for col in first_rows.column_names()]\n    all_column_values = [list(x) for x in list(zip(*all_column_values_transposed))]\n    all_column_type_hints = [[type(t) for t in vals] for vals in all_column_values]\n    if len(set((len(x) for x in all_column_type_hints))) != 1:\n        print('Unable to infer column types. Defaulting to str')\n        return str\n    column_type_hints = all_column_type_hints[0]\n    for i in range(1, len(all_column_type_hints)):\n        currow = all_column_type_hints[i]\n        for j in range(len(column_type_hints)):\n            d = set([currow[j], column_type_hints[j]])\n            if len(d) == 1:\n                continue\n            if (long in d or int in d) and float in d:\n                column_type_hints[j] = float\n            elif array.array in d and list in d:\n                column_type_hints[j] = list\n            elif type(None) in d:\n                if currow[j] != type(None):\n                    column_type_hints[j] = currow[j]\n            else:\n                column_type_hints[j] = str\n    for i in range(len(column_type_hints)):\n        if column_type_hints[i] == type(None):\n            column_type_hints[i] = str\n    return column_type_hints",
        "mutated": [
            "@staticmethod\ndef _infer_column_types_from_lines(first_rows):\n    if False:\n        i = 10\n    if len(first_rows.column_names()) < 1:\n        print('Insufficient number of columns to perform type inference')\n        raise RuntimeError('Insufficient columns ')\n    if len(first_rows) < 1:\n        print('Insufficient number of rows to perform type inference')\n        raise RuntimeError('Insufficient rows')\n    all_column_values_transposed = [list(first_rows[col]) for col in first_rows.column_names()]\n    all_column_values = [list(x) for x in list(zip(*all_column_values_transposed))]\n    all_column_type_hints = [[type(t) for t in vals] for vals in all_column_values]\n    if len(set((len(x) for x in all_column_type_hints))) != 1:\n        print('Unable to infer column types. Defaulting to str')\n        return str\n    column_type_hints = all_column_type_hints[0]\n    for i in range(1, len(all_column_type_hints)):\n        currow = all_column_type_hints[i]\n        for j in range(len(column_type_hints)):\n            d = set([currow[j], column_type_hints[j]])\n            if len(d) == 1:\n                continue\n            if (long in d or int in d) and float in d:\n                column_type_hints[j] = float\n            elif array.array in d and list in d:\n                column_type_hints[j] = list\n            elif type(None) in d:\n                if currow[j] != type(None):\n                    column_type_hints[j] = currow[j]\n            else:\n                column_type_hints[j] = str\n    for i in range(len(column_type_hints)):\n        if column_type_hints[i] == type(None):\n            column_type_hints[i] = str\n    return column_type_hints",
            "@staticmethod\ndef _infer_column_types_from_lines(first_rows):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(first_rows.column_names()) < 1:\n        print('Insufficient number of columns to perform type inference')\n        raise RuntimeError('Insufficient columns ')\n    if len(first_rows) < 1:\n        print('Insufficient number of rows to perform type inference')\n        raise RuntimeError('Insufficient rows')\n    all_column_values_transposed = [list(first_rows[col]) for col in first_rows.column_names()]\n    all_column_values = [list(x) for x in list(zip(*all_column_values_transposed))]\n    all_column_type_hints = [[type(t) for t in vals] for vals in all_column_values]\n    if len(set((len(x) for x in all_column_type_hints))) != 1:\n        print('Unable to infer column types. Defaulting to str')\n        return str\n    column_type_hints = all_column_type_hints[0]\n    for i in range(1, len(all_column_type_hints)):\n        currow = all_column_type_hints[i]\n        for j in range(len(column_type_hints)):\n            d = set([currow[j], column_type_hints[j]])\n            if len(d) == 1:\n                continue\n            if (long in d or int in d) and float in d:\n                column_type_hints[j] = float\n            elif array.array in d and list in d:\n                column_type_hints[j] = list\n            elif type(None) in d:\n                if currow[j] != type(None):\n                    column_type_hints[j] = currow[j]\n            else:\n                column_type_hints[j] = str\n    for i in range(len(column_type_hints)):\n        if column_type_hints[i] == type(None):\n            column_type_hints[i] = str\n    return column_type_hints",
            "@staticmethod\ndef _infer_column_types_from_lines(first_rows):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(first_rows.column_names()) < 1:\n        print('Insufficient number of columns to perform type inference')\n        raise RuntimeError('Insufficient columns ')\n    if len(first_rows) < 1:\n        print('Insufficient number of rows to perform type inference')\n        raise RuntimeError('Insufficient rows')\n    all_column_values_transposed = [list(first_rows[col]) for col in first_rows.column_names()]\n    all_column_values = [list(x) for x in list(zip(*all_column_values_transposed))]\n    all_column_type_hints = [[type(t) for t in vals] for vals in all_column_values]\n    if len(set((len(x) for x in all_column_type_hints))) != 1:\n        print('Unable to infer column types. Defaulting to str')\n        return str\n    column_type_hints = all_column_type_hints[0]\n    for i in range(1, len(all_column_type_hints)):\n        currow = all_column_type_hints[i]\n        for j in range(len(column_type_hints)):\n            d = set([currow[j], column_type_hints[j]])\n            if len(d) == 1:\n                continue\n            if (long in d or int in d) and float in d:\n                column_type_hints[j] = float\n            elif array.array in d and list in d:\n                column_type_hints[j] = list\n            elif type(None) in d:\n                if currow[j] != type(None):\n                    column_type_hints[j] = currow[j]\n            else:\n                column_type_hints[j] = str\n    for i in range(len(column_type_hints)):\n        if column_type_hints[i] == type(None):\n            column_type_hints[i] = str\n    return column_type_hints",
            "@staticmethod\ndef _infer_column_types_from_lines(first_rows):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(first_rows.column_names()) < 1:\n        print('Insufficient number of columns to perform type inference')\n        raise RuntimeError('Insufficient columns ')\n    if len(first_rows) < 1:\n        print('Insufficient number of rows to perform type inference')\n        raise RuntimeError('Insufficient rows')\n    all_column_values_transposed = [list(first_rows[col]) for col in first_rows.column_names()]\n    all_column_values = [list(x) for x in list(zip(*all_column_values_transposed))]\n    all_column_type_hints = [[type(t) for t in vals] for vals in all_column_values]\n    if len(set((len(x) for x in all_column_type_hints))) != 1:\n        print('Unable to infer column types. Defaulting to str')\n        return str\n    column_type_hints = all_column_type_hints[0]\n    for i in range(1, len(all_column_type_hints)):\n        currow = all_column_type_hints[i]\n        for j in range(len(column_type_hints)):\n            d = set([currow[j], column_type_hints[j]])\n            if len(d) == 1:\n                continue\n            if (long in d or int in d) and float in d:\n                column_type_hints[j] = float\n            elif array.array in d and list in d:\n                column_type_hints[j] = list\n            elif type(None) in d:\n                if currow[j] != type(None):\n                    column_type_hints[j] = currow[j]\n            else:\n                column_type_hints[j] = str\n    for i in range(len(column_type_hints)):\n        if column_type_hints[i] == type(None):\n            column_type_hints[i] = str\n    return column_type_hints",
            "@staticmethod\ndef _infer_column_types_from_lines(first_rows):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(first_rows.column_names()) < 1:\n        print('Insufficient number of columns to perform type inference')\n        raise RuntimeError('Insufficient columns ')\n    if len(first_rows) < 1:\n        print('Insufficient number of rows to perform type inference')\n        raise RuntimeError('Insufficient rows')\n    all_column_values_transposed = [list(first_rows[col]) for col in first_rows.column_names()]\n    all_column_values = [list(x) for x in list(zip(*all_column_values_transposed))]\n    all_column_type_hints = [[type(t) for t in vals] for vals in all_column_values]\n    if len(set((len(x) for x in all_column_type_hints))) != 1:\n        print('Unable to infer column types. Defaulting to str')\n        return str\n    column_type_hints = all_column_type_hints[0]\n    for i in range(1, len(all_column_type_hints)):\n        currow = all_column_type_hints[i]\n        for j in range(len(column_type_hints)):\n            d = set([currow[j], column_type_hints[j]])\n            if len(d) == 1:\n                continue\n            if (long in d or int in d) and float in d:\n                column_type_hints[j] = float\n            elif array.array in d and list in d:\n                column_type_hints[j] = list\n            elif type(None) in d:\n                if currow[j] != type(None):\n                    column_type_hints[j] = currow[j]\n            else:\n                column_type_hints[j] = str\n    for i in range(len(column_type_hints)):\n        if column_type_hints[i] == type(None):\n            column_type_hints[i] = str\n    return column_type_hints"
        ]
    },
    {
        "func_name": "_read_csv_impl",
        "original": "@classmethod\ndef _read_csv_impl(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, store_errors=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    \"\"\"\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\n        returns a pair containing the SFrame and optionally\n        (if store_errors=True) a dict of filenames to SArrays\n        indicating for each file, what are the incorrectly parsed lines\n        encountered.\n\n        Parameters\n        ----------\n        store_errors : bool\n            If true, the output errors dict will be filled.\n\n        See `read_csv` for the rest of the parameters.\n        \"\"\"\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'comment' in kwargs:\n        comment_char = kwargs['comment']\n        del kwargs['comment']\n        if comment_char is None:\n            comment_char = ''\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(kwargs.keys()))\n    parsing_config = dict()\n    parsing_config['delimiter'] = delimiter\n    parsing_config['use_header'] = header\n    parsing_config['continue_on_failure'] = not error_bad_lines\n    parsing_config['comment_char'] = comment_char\n    parsing_config['escape_char'] = '\\x00' if escape_char is None else escape_char\n    parsing_config['use_escape_char'] = escape_char is None\n    parsing_config['double_quote'] = double_quote\n    parsing_config['quote_char'] = quote_char\n    parsing_config['skip_initial_space'] = skip_initial_space\n    parsing_config['store_errors'] = store_errors\n    parsing_config['line_terminator'] = line_terminator\n    parsing_config['output_columns'] = usecols\n    parsing_config['skip_rows'] = skiprows\n    parsing_config['true_values'] = true_values\n    parsing_config['false_values'] = false_values\n    parsing_config['only_raw_string_substitutions'] = _only_raw_string_substitutions\n    if type(na_values) is str:\n        na_values = [na_values]\n    if na_values is not None and len(na_values) > 0:\n        parsing_config['na_values'] = na_values\n    if nrows is not None:\n        parsing_config['row_limit'] = nrows\n    proxy = UnitySFrameProxy()\n    internal_url = _make_internal_url(url)\n    column_type_inference_was_used = False\n    if column_type_hints is None:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            column_type_hints = SFrame._infer_column_types_from_lines(first_rows)\n            typelist = '[' + ','.join((t.__name__ for t in column_type_hints)) + ']'\n            if verbose:\n                print('------------------------------------------------------')\n                print('Inferred types from first %d line(s) of file as ' % nrows_to_infer)\n                print('column_type_hints=' + typelist)\n                print('If parsing fails due to incorrect types, you can correct')\n                print('the inferred type list above and pass it to read_csv in')\n                print('the column_type_hints argument')\n                print('------------------------------------------------------')\n            column_type_inference_was_used = True\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e.args[0]) or 'Cancel' in str(e.args[0])):\n                raise e\n            column_type_hints = str\n            if verbose:\n                print('Could not detect types. Using str for each column.')\n    if type(column_type_hints) is type:\n        type_hints = {'__all_columns__': column_type_hints}\n    elif type(column_type_hints) is list:\n        type_hints = dict(list(zip(['__X%d__' % i for i in range(len(column_type_hints))], column_type_hints)))\n    elif type(column_type_hints) is dict:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            inferred_types = SFrame._infer_column_types_from_lines(first_rows)\n            inferred_types = dict(list(zip(first_rows.column_names(), inferred_types)))\n            for key in column_type_hints:\n                inferred_types[key] = column_type_hints[key]\n            column_type_hints = inferred_types\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e) or 'Cancel' in str(e)):\n                raise e\n            if verbose:\n                print('Could not detect types. Using str for all unspecified columns.')\n        type_hints = column_type_hints\n    else:\n        raise TypeError('Invalid type for column_type_hints. Must be a dictionary, list or a single type.')\n    try:\n        if not verbose:\n            glconnect.get_server().set_log_progress(False)\n        with cython_context():\n            errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n    except Exception as e:\n        if type(e) == RuntimeError and 'CSV parsing cancelled' in str(e.args[0]):\n            raise e\n        if column_type_inference_was_used:\n            if verbose:\n                print('Unable to parse the file with automatic type inference.')\n                print('Defaulting to column_type_hints=str')\n            type_hints = {'__all_columns__': str}\n            try:\n                with cython_context():\n                    errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n            except:\n                glconnect.get_server().set_log_progress(True)\n                raise\n        else:\n            glconnect.get_server().set_log_progress(True)\n            raise\n    glconnect.get_server().set_log_progress(True)\n    return (cls(_proxy=proxy), {f: SArray(_proxy=es) for (f, es) in errors.items()})",
        "mutated": [
            "@classmethod\ndef _read_csv_impl(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, store_errors=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and optionally\\n        (if store_errors=True) a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        store_errors : bool\\n            If true, the output errors dict will be filled.\\n\\n        See `read_csv` for the rest of the parameters.\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'comment' in kwargs:\n        comment_char = kwargs['comment']\n        del kwargs['comment']\n        if comment_char is None:\n            comment_char = ''\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(kwargs.keys()))\n    parsing_config = dict()\n    parsing_config['delimiter'] = delimiter\n    parsing_config['use_header'] = header\n    parsing_config['continue_on_failure'] = not error_bad_lines\n    parsing_config['comment_char'] = comment_char\n    parsing_config['escape_char'] = '\\x00' if escape_char is None else escape_char\n    parsing_config['use_escape_char'] = escape_char is None\n    parsing_config['double_quote'] = double_quote\n    parsing_config['quote_char'] = quote_char\n    parsing_config['skip_initial_space'] = skip_initial_space\n    parsing_config['store_errors'] = store_errors\n    parsing_config['line_terminator'] = line_terminator\n    parsing_config['output_columns'] = usecols\n    parsing_config['skip_rows'] = skiprows\n    parsing_config['true_values'] = true_values\n    parsing_config['false_values'] = false_values\n    parsing_config['only_raw_string_substitutions'] = _only_raw_string_substitutions\n    if type(na_values) is str:\n        na_values = [na_values]\n    if na_values is not None and len(na_values) > 0:\n        parsing_config['na_values'] = na_values\n    if nrows is not None:\n        parsing_config['row_limit'] = nrows\n    proxy = UnitySFrameProxy()\n    internal_url = _make_internal_url(url)\n    column_type_inference_was_used = False\n    if column_type_hints is None:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            column_type_hints = SFrame._infer_column_types_from_lines(first_rows)\n            typelist = '[' + ','.join((t.__name__ for t in column_type_hints)) + ']'\n            if verbose:\n                print('------------------------------------------------------')\n                print('Inferred types from first %d line(s) of file as ' % nrows_to_infer)\n                print('column_type_hints=' + typelist)\n                print('If parsing fails due to incorrect types, you can correct')\n                print('the inferred type list above and pass it to read_csv in')\n                print('the column_type_hints argument')\n                print('------------------------------------------------------')\n            column_type_inference_was_used = True\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e.args[0]) or 'Cancel' in str(e.args[0])):\n                raise e\n            column_type_hints = str\n            if verbose:\n                print('Could not detect types. Using str for each column.')\n    if type(column_type_hints) is type:\n        type_hints = {'__all_columns__': column_type_hints}\n    elif type(column_type_hints) is list:\n        type_hints = dict(list(zip(['__X%d__' % i for i in range(len(column_type_hints))], column_type_hints)))\n    elif type(column_type_hints) is dict:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            inferred_types = SFrame._infer_column_types_from_lines(first_rows)\n            inferred_types = dict(list(zip(first_rows.column_names(), inferred_types)))\n            for key in column_type_hints:\n                inferred_types[key] = column_type_hints[key]\n            column_type_hints = inferred_types\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e) or 'Cancel' in str(e)):\n                raise e\n            if verbose:\n                print('Could not detect types. Using str for all unspecified columns.')\n        type_hints = column_type_hints\n    else:\n        raise TypeError('Invalid type for column_type_hints. Must be a dictionary, list or a single type.')\n    try:\n        if not verbose:\n            glconnect.get_server().set_log_progress(False)\n        with cython_context():\n            errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n    except Exception as e:\n        if type(e) == RuntimeError and 'CSV parsing cancelled' in str(e.args[0]):\n            raise e\n        if column_type_inference_was_used:\n            if verbose:\n                print('Unable to parse the file with automatic type inference.')\n                print('Defaulting to column_type_hints=str')\n            type_hints = {'__all_columns__': str}\n            try:\n                with cython_context():\n                    errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n            except:\n                glconnect.get_server().set_log_progress(True)\n                raise\n        else:\n            glconnect.get_server().set_log_progress(True)\n            raise\n    glconnect.get_server().set_log_progress(True)\n    return (cls(_proxy=proxy), {f: SArray(_proxy=es) for (f, es) in errors.items()})",
            "@classmethod\ndef _read_csv_impl(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, store_errors=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and optionally\\n        (if store_errors=True) a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        store_errors : bool\\n            If true, the output errors dict will be filled.\\n\\n        See `read_csv` for the rest of the parameters.\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'comment' in kwargs:\n        comment_char = kwargs['comment']\n        del kwargs['comment']\n        if comment_char is None:\n            comment_char = ''\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(kwargs.keys()))\n    parsing_config = dict()\n    parsing_config['delimiter'] = delimiter\n    parsing_config['use_header'] = header\n    parsing_config['continue_on_failure'] = not error_bad_lines\n    parsing_config['comment_char'] = comment_char\n    parsing_config['escape_char'] = '\\x00' if escape_char is None else escape_char\n    parsing_config['use_escape_char'] = escape_char is None\n    parsing_config['double_quote'] = double_quote\n    parsing_config['quote_char'] = quote_char\n    parsing_config['skip_initial_space'] = skip_initial_space\n    parsing_config['store_errors'] = store_errors\n    parsing_config['line_terminator'] = line_terminator\n    parsing_config['output_columns'] = usecols\n    parsing_config['skip_rows'] = skiprows\n    parsing_config['true_values'] = true_values\n    parsing_config['false_values'] = false_values\n    parsing_config['only_raw_string_substitutions'] = _only_raw_string_substitutions\n    if type(na_values) is str:\n        na_values = [na_values]\n    if na_values is not None and len(na_values) > 0:\n        parsing_config['na_values'] = na_values\n    if nrows is not None:\n        parsing_config['row_limit'] = nrows\n    proxy = UnitySFrameProxy()\n    internal_url = _make_internal_url(url)\n    column_type_inference_was_used = False\n    if column_type_hints is None:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            column_type_hints = SFrame._infer_column_types_from_lines(first_rows)\n            typelist = '[' + ','.join((t.__name__ for t in column_type_hints)) + ']'\n            if verbose:\n                print('------------------------------------------------------')\n                print('Inferred types from first %d line(s) of file as ' % nrows_to_infer)\n                print('column_type_hints=' + typelist)\n                print('If parsing fails due to incorrect types, you can correct')\n                print('the inferred type list above and pass it to read_csv in')\n                print('the column_type_hints argument')\n                print('------------------------------------------------------')\n            column_type_inference_was_used = True\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e.args[0]) or 'Cancel' in str(e.args[0])):\n                raise e\n            column_type_hints = str\n            if verbose:\n                print('Could not detect types. Using str for each column.')\n    if type(column_type_hints) is type:\n        type_hints = {'__all_columns__': column_type_hints}\n    elif type(column_type_hints) is list:\n        type_hints = dict(list(zip(['__X%d__' % i for i in range(len(column_type_hints))], column_type_hints)))\n    elif type(column_type_hints) is dict:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            inferred_types = SFrame._infer_column_types_from_lines(first_rows)\n            inferred_types = dict(list(zip(first_rows.column_names(), inferred_types)))\n            for key in column_type_hints:\n                inferred_types[key] = column_type_hints[key]\n            column_type_hints = inferred_types\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e) or 'Cancel' in str(e)):\n                raise e\n            if verbose:\n                print('Could not detect types. Using str for all unspecified columns.')\n        type_hints = column_type_hints\n    else:\n        raise TypeError('Invalid type for column_type_hints. Must be a dictionary, list or a single type.')\n    try:\n        if not verbose:\n            glconnect.get_server().set_log_progress(False)\n        with cython_context():\n            errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n    except Exception as e:\n        if type(e) == RuntimeError and 'CSV parsing cancelled' in str(e.args[0]):\n            raise e\n        if column_type_inference_was_used:\n            if verbose:\n                print('Unable to parse the file with automatic type inference.')\n                print('Defaulting to column_type_hints=str')\n            type_hints = {'__all_columns__': str}\n            try:\n                with cython_context():\n                    errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n            except:\n                glconnect.get_server().set_log_progress(True)\n                raise\n        else:\n            glconnect.get_server().set_log_progress(True)\n            raise\n    glconnect.get_server().set_log_progress(True)\n    return (cls(_proxy=proxy), {f: SArray(_proxy=es) for (f, es) in errors.items()})",
            "@classmethod\ndef _read_csv_impl(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, store_errors=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and optionally\\n        (if store_errors=True) a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        store_errors : bool\\n            If true, the output errors dict will be filled.\\n\\n        See `read_csv` for the rest of the parameters.\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'comment' in kwargs:\n        comment_char = kwargs['comment']\n        del kwargs['comment']\n        if comment_char is None:\n            comment_char = ''\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(kwargs.keys()))\n    parsing_config = dict()\n    parsing_config['delimiter'] = delimiter\n    parsing_config['use_header'] = header\n    parsing_config['continue_on_failure'] = not error_bad_lines\n    parsing_config['comment_char'] = comment_char\n    parsing_config['escape_char'] = '\\x00' if escape_char is None else escape_char\n    parsing_config['use_escape_char'] = escape_char is None\n    parsing_config['double_quote'] = double_quote\n    parsing_config['quote_char'] = quote_char\n    parsing_config['skip_initial_space'] = skip_initial_space\n    parsing_config['store_errors'] = store_errors\n    parsing_config['line_terminator'] = line_terminator\n    parsing_config['output_columns'] = usecols\n    parsing_config['skip_rows'] = skiprows\n    parsing_config['true_values'] = true_values\n    parsing_config['false_values'] = false_values\n    parsing_config['only_raw_string_substitutions'] = _only_raw_string_substitutions\n    if type(na_values) is str:\n        na_values = [na_values]\n    if na_values is not None and len(na_values) > 0:\n        parsing_config['na_values'] = na_values\n    if nrows is not None:\n        parsing_config['row_limit'] = nrows\n    proxy = UnitySFrameProxy()\n    internal_url = _make_internal_url(url)\n    column_type_inference_was_used = False\n    if column_type_hints is None:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            column_type_hints = SFrame._infer_column_types_from_lines(first_rows)\n            typelist = '[' + ','.join((t.__name__ for t in column_type_hints)) + ']'\n            if verbose:\n                print('------------------------------------------------------')\n                print('Inferred types from first %d line(s) of file as ' % nrows_to_infer)\n                print('column_type_hints=' + typelist)\n                print('If parsing fails due to incorrect types, you can correct')\n                print('the inferred type list above and pass it to read_csv in')\n                print('the column_type_hints argument')\n                print('------------------------------------------------------')\n            column_type_inference_was_used = True\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e.args[0]) or 'Cancel' in str(e.args[0])):\n                raise e\n            column_type_hints = str\n            if verbose:\n                print('Could not detect types. Using str for each column.')\n    if type(column_type_hints) is type:\n        type_hints = {'__all_columns__': column_type_hints}\n    elif type(column_type_hints) is list:\n        type_hints = dict(list(zip(['__X%d__' % i for i in range(len(column_type_hints))], column_type_hints)))\n    elif type(column_type_hints) is dict:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            inferred_types = SFrame._infer_column_types_from_lines(first_rows)\n            inferred_types = dict(list(zip(first_rows.column_names(), inferred_types)))\n            for key in column_type_hints:\n                inferred_types[key] = column_type_hints[key]\n            column_type_hints = inferred_types\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e) or 'Cancel' in str(e)):\n                raise e\n            if verbose:\n                print('Could not detect types. Using str for all unspecified columns.')\n        type_hints = column_type_hints\n    else:\n        raise TypeError('Invalid type for column_type_hints. Must be a dictionary, list or a single type.')\n    try:\n        if not verbose:\n            glconnect.get_server().set_log_progress(False)\n        with cython_context():\n            errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n    except Exception as e:\n        if type(e) == RuntimeError and 'CSV parsing cancelled' in str(e.args[0]):\n            raise e\n        if column_type_inference_was_used:\n            if verbose:\n                print('Unable to parse the file with automatic type inference.')\n                print('Defaulting to column_type_hints=str')\n            type_hints = {'__all_columns__': str}\n            try:\n                with cython_context():\n                    errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n            except:\n                glconnect.get_server().set_log_progress(True)\n                raise\n        else:\n            glconnect.get_server().set_log_progress(True)\n            raise\n    glconnect.get_server().set_log_progress(True)\n    return (cls(_proxy=proxy), {f: SArray(_proxy=es) for (f, es) in errors.items()})",
            "@classmethod\ndef _read_csv_impl(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, store_errors=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and optionally\\n        (if store_errors=True) a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        store_errors : bool\\n            If true, the output errors dict will be filled.\\n\\n        See `read_csv` for the rest of the parameters.\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'comment' in kwargs:\n        comment_char = kwargs['comment']\n        del kwargs['comment']\n        if comment_char is None:\n            comment_char = ''\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(kwargs.keys()))\n    parsing_config = dict()\n    parsing_config['delimiter'] = delimiter\n    parsing_config['use_header'] = header\n    parsing_config['continue_on_failure'] = not error_bad_lines\n    parsing_config['comment_char'] = comment_char\n    parsing_config['escape_char'] = '\\x00' if escape_char is None else escape_char\n    parsing_config['use_escape_char'] = escape_char is None\n    parsing_config['double_quote'] = double_quote\n    parsing_config['quote_char'] = quote_char\n    parsing_config['skip_initial_space'] = skip_initial_space\n    parsing_config['store_errors'] = store_errors\n    parsing_config['line_terminator'] = line_terminator\n    parsing_config['output_columns'] = usecols\n    parsing_config['skip_rows'] = skiprows\n    parsing_config['true_values'] = true_values\n    parsing_config['false_values'] = false_values\n    parsing_config['only_raw_string_substitutions'] = _only_raw_string_substitutions\n    if type(na_values) is str:\n        na_values = [na_values]\n    if na_values is not None and len(na_values) > 0:\n        parsing_config['na_values'] = na_values\n    if nrows is not None:\n        parsing_config['row_limit'] = nrows\n    proxy = UnitySFrameProxy()\n    internal_url = _make_internal_url(url)\n    column_type_inference_was_used = False\n    if column_type_hints is None:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            column_type_hints = SFrame._infer_column_types_from_lines(first_rows)\n            typelist = '[' + ','.join((t.__name__ for t in column_type_hints)) + ']'\n            if verbose:\n                print('------------------------------------------------------')\n                print('Inferred types from first %d line(s) of file as ' % nrows_to_infer)\n                print('column_type_hints=' + typelist)\n                print('If parsing fails due to incorrect types, you can correct')\n                print('the inferred type list above and pass it to read_csv in')\n                print('the column_type_hints argument')\n                print('------------------------------------------------------')\n            column_type_inference_was_used = True\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e.args[0]) or 'Cancel' in str(e.args[0])):\n                raise e\n            column_type_hints = str\n            if verbose:\n                print('Could not detect types. Using str for each column.')\n    if type(column_type_hints) is type:\n        type_hints = {'__all_columns__': column_type_hints}\n    elif type(column_type_hints) is list:\n        type_hints = dict(list(zip(['__X%d__' % i for i in range(len(column_type_hints))], column_type_hints)))\n    elif type(column_type_hints) is dict:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            inferred_types = SFrame._infer_column_types_from_lines(first_rows)\n            inferred_types = dict(list(zip(first_rows.column_names(), inferred_types)))\n            for key in column_type_hints:\n                inferred_types[key] = column_type_hints[key]\n            column_type_hints = inferred_types\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e) or 'Cancel' in str(e)):\n                raise e\n            if verbose:\n                print('Could not detect types. Using str for all unspecified columns.')\n        type_hints = column_type_hints\n    else:\n        raise TypeError('Invalid type for column_type_hints. Must be a dictionary, list or a single type.')\n    try:\n        if not verbose:\n            glconnect.get_server().set_log_progress(False)\n        with cython_context():\n            errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n    except Exception as e:\n        if type(e) == RuntimeError and 'CSV parsing cancelled' in str(e.args[0]):\n            raise e\n        if column_type_inference_was_used:\n            if verbose:\n                print('Unable to parse the file with automatic type inference.')\n                print('Defaulting to column_type_hints=str')\n            type_hints = {'__all_columns__': str}\n            try:\n                with cython_context():\n                    errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n            except:\n                glconnect.get_server().set_log_progress(True)\n                raise\n        else:\n            glconnect.get_server().set_log_progress(True)\n            raise\n    glconnect.get_server().set_log_progress(True)\n    return (cls(_proxy=proxy), {f: SArray(_proxy=es) for (f, es) in errors.items()})",
            "@classmethod\ndef _read_csv_impl(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, store_errors=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and optionally\\n        (if store_errors=True) a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        store_errors : bool\\n            If true, the output errors dict will be filled.\\n\\n        See `read_csv` for the rest of the parameters.\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'comment' in kwargs:\n        comment_char = kwargs['comment']\n        del kwargs['comment']\n        if comment_char is None:\n            comment_char = ''\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(kwargs.keys()))\n    parsing_config = dict()\n    parsing_config['delimiter'] = delimiter\n    parsing_config['use_header'] = header\n    parsing_config['continue_on_failure'] = not error_bad_lines\n    parsing_config['comment_char'] = comment_char\n    parsing_config['escape_char'] = '\\x00' if escape_char is None else escape_char\n    parsing_config['use_escape_char'] = escape_char is None\n    parsing_config['double_quote'] = double_quote\n    parsing_config['quote_char'] = quote_char\n    parsing_config['skip_initial_space'] = skip_initial_space\n    parsing_config['store_errors'] = store_errors\n    parsing_config['line_terminator'] = line_terminator\n    parsing_config['output_columns'] = usecols\n    parsing_config['skip_rows'] = skiprows\n    parsing_config['true_values'] = true_values\n    parsing_config['false_values'] = false_values\n    parsing_config['only_raw_string_substitutions'] = _only_raw_string_substitutions\n    if type(na_values) is str:\n        na_values = [na_values]\n    if na_values is not None and len(na_values) > 0:\n        parsing_config['na_values'] = na_values\n    if nrows is not None:\n        parsing_config['row_limit'] = nrows\n    proxy = UnitySFrameProxy()\n    internal_url = _make_internal_url(url)\n    column_type_inference_was_used = False\n    if column_type_hints is None:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            column_type_hints = SFrame._infer_column_types_from_lines(first_rows)\n            typelist = '[' + ','.join((t.__name__ for t in column_type_hints)) + ']'\n            if verbose:\n                print('------------------------------------------------------')\n                print('Inferred types from first %d line(s) of file as ' % nrows_to_infer)\n                print('column_type_hints=' + typelist)\n                print('If parsing fails due to incorrect types, you can correct')\n                print('the inferred type list above and pass it to read_csv in')\n                print('the column_type_hints argument')\n                print('------------------------------------------------------')\n            column_type_inference_was_used = True\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e.args[0]) or 'Cancel' in str(e.args[0])):\n                raise e\n            column_type_hints = str\n            if verbose:\n                print('Could not detect types. Using str for each column.')\n    if type(column_type_hints) is type:\n        type_hints = {'__all_columns__': column_type_hints}\n    elif type(column_type_hints) is list:\n        type_hints = dict(list(zip(['__X%d__' % i for i in range(len(column_type_hints))], column_type_hints)))\n    elif type(column_type_hints) is dict:\n        try:\n            first_rows = SFrame.read_csv(url, nrows=nrows_to_infer, column_type_hints=type(None), header=header, delimiter=delimiter, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, na_values=na_values, line_terminator=line_terminator, usecols=usecols, skiprows=skiprows, verbose=verbose, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions)\n            inferred_types = SFrame._infer_column_types_from_lines(first_rows)\n            inferred_types = dict(list(zip(first_rows.column_names(), inferred_types)))\n            for key in column_type_hints:\n                inferred_types[key] = column_type_hints[key]\n            column_type_hints = inferred_types\n        except RuntimeError as e:\n            if type(e) == RuntimeError and ('cancel' in str(e) or 'Cancel' in str(e)):\n                raise e\n            if verbose:\n                print('Could not detect types. Using str for all unspecified columns.')\n        type_hints = column_type_hints\n    else:\n        raise TypeError('Invalid type for column_type_hints. Must be a dictionary, list or a single type.')\n    try:\n        if not verbose:\n            glconnect.get_server().set_log_progress(False)\n        with cython_context():\n            errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n    except Exception as e:\n        if type(e) == RuntimeError and 'CSV parsing cancelled' in str(e.args[0]):\n            raise e\n        if column_type_inference_was_used:\n            if verbose:\n                print('Unable to parse the file with automatic type inference.')\n                print('Defaulting to column_type_hints=str')\n            type_hints = {'__all_columns__': str}\n            try:\n                with cython_context():\n                    errors = proxy.load_from_csvs(internal_url, parsing_config, type_hints)\n            except:\n                glconnect.get_server().set_log_progress(True)\n                raise\n        else:\n            glconnect.get_server().set_log_progress(True)\n            raise\n    glconnect.get_server().set_log_progress(True)\n    return (cls(_proxy=proxy), {f: SArray(_proxy=es) for (f, es) in errors.items()})"
        ]
    },
    {
        "func_name": "read_csv_with_errors",
        "original": "@classmethod\ndef read_csv_with_errors(cls, url, delimiter=',', header=True, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    \"\"\"\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\n        returns a pair containing the SFrame and a dict of filenames to SArrays\n        indicating for each file, what are the incorrectly parsed lines\n        encountered.\n\n        Parameters\n        ----------\n        url : string\n            Location of the CSV file or directory to load. If URL is a directory\n            or a \"glob\" pattern, all matching files will be loaded.\n\n        delimiter : string, optional\n            This describes the delimiter used for parsing csv files.\n\n        header : bool, optional\n            If true, uses the first row as the column names. Otherwise use the\n            default column names: 'X1, X2, ...'.\n\n        comment_char : string, optional\n            The character which denotes that the\n            remainder of the line is a comment.\n\n        escape_char : string, optional\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\n            Set to None to disable.\n\n        double_quote : bool, optional\n            If True, two consecutive quotes in a string are parsed to a single\n            quote.\n\n        quote_char : string, optional\n            Character sequence that indicates a quote.\n\n        skip_initial_space : bool, optional\n            Ignore extra spaces at the start of a field\n\n        column_type_hints : None, type, list[type], dict[string, type], optional\n            This provides type hints for each column. By default, this method\n            attempts to detect the type of each column automatically.\n\n            Supported types are int, float, str, list, dict, and array.array.\n\n            * If a single type is provided, the type will be\n              applied to all columns. For instance, column_type_hints=float\n              will force all columns to be parsed as float.\n            * If a list of types is provided, the types applies\n              to each column in order, e.g.[int, float, str]\n              will parse the first column as int, second as float and third as\n              string.\n            * If a dictionary of column name to type is provided,\n              each type value in the dictionary is applied to the key it\n              belongs to.\n              For instance {'user':int} will hint that the column called \"user\"\n              should be parsed as an integer, and the rest will be type inferred.\n\n        na_values : str | list of str, optional\n            A string or list of strings to be interpreted as missing values.\n\n        true_values : str | list of str, optional\n            A string or list of strings to be interpreted as 1\n\n        false_values : str | list of str, optional\n            A string or list of strings to be interpreted as 0\n\n        line_terminator : str, optional\n            A string to be interpreted as the line terminator. Defaults to \"\\\\n\"\n            which will also correctly match Mac, Linux and Windows line endings\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\n\n        usecols : list of str, optional\n            A subset of column names to output. If unspecified (default),\n            all columns will be read. This can provide performance gains if the\n            number of columns are large. If the input file has no headers,\n            usecols=['X1','X3'] will read columns 1 and 3.\n\n        nrows : int, optional\n            If set, only this many rows will be read from the file.\n\n        skiprows : int, optional\n            If set, this number of rows at the start of the file are skipped.\n\n        verbose : bool, optional\n            If True, print the progress.\n\n        Returns\n        -------\n        out : tuple\n            The first element is the SFrame with good data. The second element\n            is a dictionary of filenames to SArrays indicating for each file,\n            what are the incorrectly parsed lines encountered.\n\n        See Also\n        --------\n        read_csv, SFrame\n\n        Examples\n        --------\n        >>> bad_url = 'https://static.turi.com/datasets/bad_csv_example.csv'\n        >>> (sf, bad_lines) = turicreate.SFrame.read_csv_with_errors(bad_url)\n        >>> sf\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |   3    |\n        |  25907  |   1663   |   3    |\n        |  25923  |   1663   |   3    |\n        |  25924  |   1663   |   3    |\n        |  25928  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [98 rows x 3 columns]\n\n        >>> bad_lines\n        {'https://static.turi.com/datasets/bad_csv_example.csv': dtype: str\n         Rows: 1\n         ['x,y,z,a,b,c']}\n       \"\"\"\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=False, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, verbose=verbose, skiprows=skiprows, store_errors=True, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)",
        "mutated": [
            "@classmethod\ndef read_csv_with_errors(cls, url, delimiter=',', header=True, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names: \\'X1, X2, ...\\'.\\n\\n        comment_char : string, optional\\n            The character which denotes that the\\n            remainder of the line is a comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        Returns\\n        -------\\n        out : tuple\\n            The first element is the SFrame with good data. The second element\\n            is a dictionary of filenames to SArrays indicating for each file,\\n            what are the incorrectly parsed lines encountered.\\n\\n        See Also\\n        --------\\n        read_csv, SFrame\\n\\n        Examples\\n        --------\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> (sf, bad_lines) = turicreate.SFrame.read_csv_with_errors(bad_url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [98 rows x 3 columns]\\n\\n        >>> bad_lines\\n        {\\'https://static.turi.com/datasets/bad_csv_example.csv\\': dtype: str\\n         Rows: 1\\n         [\\'x,y,z,a,b,c\\']}\\n       '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=False, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, verbose=verbose, skiprows=skiprows, store_errors=True, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)",
            "@classmethod\ndef read_csv_with_errors(cls, url, delimiter=',', header=True, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names: \\'X1, X2, ...\\'.\\n\\n        comment_char : string, optional\\n            The character which denotes that the\\n            remainder of the line is a comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        Returns\\n        -------\\n        out : tuple\\n            The first element is the SFrame with good data. The second element\\n            is a dictionary of filenames to SArrays indicating for each file,\\n            what are the incorrectly parsed lines encountered.\\n\\n        See Also\\n        --------\\n        read_csv, SFrame\\n\\n        Examples\\n        --------\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> (sf, bad_lines) = turicreate.SFrame.read_csv_with_errors(bad_url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [98 rows x 3 columns]\\n\\n        >>> bad_lines\\n        {\\'https://static.turi.com/datasets/bad_csv_example.csv\\': dtype: str\\n         Rows: 1\\n         [\\'x,y,z,a,b,c\\']}\\n       '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=False, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, verbose=verbose, skiprows=skiprows, store_errors=True, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)",
            "@classmethod\ndef read_csv_with_errors(cls, url, delimiter=',', header=True, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names: \\'X1, X2, ...\\'.\\n\\n        comment_char : string, optional\\n            The character which denotes that the\\n            remainder of the line is a comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        Returns\\n        -------\\n        out : tuple\\n            The first element is the SFrame with good data. The second element\\n            is a dictionary of filenames to SArrays indicating for each file,\\n            what are the incorrectly parsed lines encountered.\\n\\n        See Also\\n        --------\\n        read_csv, SFrame\\n\\n        Examples\\n        --------\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> (sf, bad_lines) = turicreate.SFrame.read_csv_with_errors(bad_url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [98 rows x 3 columns]\\n\\n        >>> bad_lines\\n        {\\'https://static.turi.com/datasets/bad_csv_example.csv\\': dtype: str\\n         Rows: 1\\n         [\\'x,y,z,a,b,c\\']}\\n       '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=False, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, verbose=verbose, skiprows=skiprows, store_errors=True, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)",
            "@classmethod\ndef read_csv_with_errors(cls, url, delimiter=',', header=True, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names: \\'X1, X2, ...\\'.\\n\\n        comment_char : string, optional\\n            The character which denotes that the\\n            remainder of the line is a comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        Returns\\n        -------\\n        out : tuple\\n            The first element is the SFrame with good data. The second element\\n            is a dictionary of filenames to SArrays indicating for each file,\\n            what are the incorrectly parsed lines encountered.\\n\\n        See Also\\n        --------\\n        read_csv, SFrame\\n\\n        Examples\\n        --------\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> (sf, bad_lines) = turicreate.SFrame.read_csv_with_errors(bad_url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [98 rows x 3 columns]\\n\\n        >>> bad_lines\\n        {\\'https://static.turi.com/datasets/bad_csv_example.csv\\': dtype: str\\n         Rows: 1\\n         [\\'x,y,z,a,b,c\\']}\\n       '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=False, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, verbose=verbose, skiprows=skiprows, store_errors=True, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)",
            "@classmethod\ndef read_csv_with_errors(cls, url, delimiter=',', header=True, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs, and\\n        returns a pair containing the SFrame and a dict of filenames to SArrays\\n        indicating for each file, what are the incorrectly parsed lines\\n        encountered.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names: \\'X1, X2, ...\\'.\\n\\n        comment_char : string, optional\\n            The character which denotes that the\\n            remainder of the line is a comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        Returns\\n        -------\\n        out : tuple\\n            The first element is the SFrame with good data. The second element\\n            is a dictionary of filenames to SArrays indicating for each file,\\n            what are the incorrectly parsed lines encountered.\\n\\n        See Also\\n        --------\\n        read_csv, SFrame\\n\\n        Examples\\n        --------\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> (sf, bad_lines) = turicreate.SFrame.read_csv_with_errors(bad_url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [98 rows x 3 columns]\\n\\n        >>> bad_lines\\n        {\\'https://static.turi.com/datasets/bad_csv_example.csv\\': dtype: str\\n         Rows: 1\\n         [\\'x,y,z,a,b,c\\']}\\n       '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=False, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, verbose=verbose, skiprows=skiprows, store_errors=True, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)"
        ]
    },
    {
        "func_name": "read_csv",
        "original": "@classmethod\ndef read_csv(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    \"\"\"\n        Constructs an SFrame from a CSV file or a path to multiple CSVs.\n\n        Parameters\n        ----------\n        url : string\n            Location of the CSV file or directory to load. If URL is a directory\n            or a \"glob\" pattern, all matching files will be loaded.\n\n        delimiter : string, optional\n            This describes the delimiter used for parsing csv files.\n\n        header : bool, optional\n            If true, uses the first row as the column names. Otherwise use the\n            default column names : 'X1, X2, ...'.\n\n        error_bad_lines : bool\n            If true, will fail upon encountering a bad line. If false, will\n            continue parsing skipping lines which fail to parse correctly.\n            A sample of the first 10 encountered bad lines will be printed.\n\n        comment_char : string, optional\n            The character which denotes that the remainder of the line is a\n            comment.\n\n        escape_char : string, optional\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\n            Set to None to disable.\n\n        double_quote : bool, optional\n            If True, two consecutive quotes in a string are parsed to a single\n            quote.\n\n        quote_char : string, optional\n            Character sequence that indicates a quote.\n\n        skip_initial_space : bool, optional\n            Ignore extra spaces at the start of a field\n\n        column_type_hints : None, type, list[type], dict[string, type], optional\n            This provides type hints for each column. By default, this method\n            attempts to detect the type of each column automatically.\n\n            Supported types are int, float, str, list, dict, and array.array.\n\n            * If a single type is provided, the type will be\n              applied to all columns. For instance, column_type_hints=float\n              will force all columns to be parsed as float.\n            * If a list of types is provided, the types applies\n              to each column in order, e.g.[int, float, str]\n              will parse the first column as int, second as float and third as\n              string.\n            * If a dictionary of column name to type is provided,\n              each type value in the dictionary is applied to the key it\n              belongs to.\n              For instance {'user':int} will hint that the column called \"user\"\n              should be parsed as an integer, and the rest will be type inferred.\n\n        na_values : str | list of str, optional\n            A string or list of strings to be interpreted as missing values.\n\n        true_values : str | list of str, optional\n            A string or list of strings to be interpreted as 1\n\n        false_values : str | list of str, optional\n            A string or list of strings to be interpreted as 0\n\n\n        line_terminator : str, optional\n            A string to be interpreted as the line terminator. Defaults to \"\n\"\n            which will also correctly match Mac, Linux and Windows line endings\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\n\n        usecols : list of str, optional\n            A subset of column names to output. If unspecified (default),\n            all columns will be read. This can provide performance gains if the\n            number of columns are large. If the input file has no headers,\n            usecols=['X1','X3'] will read columns 1 and 3.\n\n        nrows : int, optional\n            If set, only this many rows will be read from the file.\n\n        skiprows : int, optional\n            If set, this number of rows at the start of the file are skipped.\n\n        verbose : bool, optional\n            If True, print the progress.\n\n        nrows_to_infer : integer\n            The number of rows used to infer column types.\n\n        Returns\n        -------\n        out : SFrame\n\n        See Also\n        --------\n        read_csv_with_errors, SFrame\n\n        Examples\n        --------\n\n        Read a regular csv file, with all default options, automatically\n        determine types:\n\n        >>> url = 'https://static.turi.com/datasets/rating_data_example.csv'\n        >>> sf = turicreate.SFrame.read_csv(url)\n        >>> sf\n        Columns:\n          user_id int\n          movie_id  int\n          rating  int\n        Rows: 10000\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |   3    |\n        |  25907  |   1663   |   3    |\n        |  25923  |   1663   |   3    |\n        |  25924  |   1663   |   3    |\n        |  25928  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [10000 rows x 3 columns]\n\n        Read only the first 100 lines of the csv file:\n\n        >>> sf = turicreate.SFrame.read_csv(url, nrows=100)\n        >>> sf\n        Columns:\n          user_id int\n          movie_id  int\n          rating  int\n        Rows: 100\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |   3    |\n        |  25907  |   1663   |   3    |\n        |  25923  |   1663   |   3    |\n        |  25924  |   1663   |   3    |\n        |  25928  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [100 rows x 3 columns]\n\n        Read all columns as str type\n\n        >>> sf = turicreate.SFrame.read_csv(url, column_type_hints=str)\n        >>> sf\n        Columns:\n          user_id  str\n          movie_id  str\n          rating  str\n        Rows: 10000\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |   3    |\n        |  25907  |   1663   |   3    |\n        |  25923  |   1663   |   3    |\n        |  25924  |   1663   |   3    |\n        |  25928  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [10000 rows x 3 columns]\n\n        Specify types for a subset of columns and leave the rest to be str.\n\n        >>> sf = turicreate.SFrame.read_csv(url,\n        ...                               column_type_hints={\n        ...                               'user_id':int, 'rating':float\n        ...                               })\n        >>> sf\n        Columns:\n          user_id str\n          movie_id  str\n          rating  float\n        Rows: 10000\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |  3.0   |\n        |  25907  |   1663   |  3.0   |\n        |  25923  |   1663   |  3.0   |\n        |  25924  |   1663   |  3.0   |\n        |  25928  |   1663   |  2.0   |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [10000 rows x 3 columns]\n\n        Not treat first line as header:\n\n        >>> sf = turicreate.SFrame.read_csv(url, header=False)\n        >>> sf\n        Columns:\n          X1  str\n          X2  str\n          X3  str\n        Rows: 10001\n        +---------+----------+--------+\n        |    X1   |    X2    |   X3   |\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        |  25904  |   1663   |   3    |\n        |  25907  |   1663   |   3    |\n        |  25923  |   1663   |   3    |\n        |  25924  |   1663   |   3    |\n        |  25928  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [10001 rows x 3 columns]\n\n        Treat '3' as missing value:\n\n        >>> sf = turicreate.SFrame.read_csv(url, na_values=['3'], column_type_hints=str)\n        >>> sf\n        Columns:\n          user_id str\n          movie_id  str\n          rating  str\n        Rows: 10000\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |  None  |\n        |  25907  |   1663   |  None  |\n        |  25923  |   1663   |  None  |\n        |  25924  |   1663   |  None  |\n        |  25928  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [10000 rows x 3 columns]\n\n        Throw error on parse failure:\n\n        >>> bad_url = 'https://static.turi.com/datasets/bad_csv_example.csv'\n        >>> sf = turicreate.SFrame.read_csv(bad_url, error_bad_lines=True)\n        RuntimeError: Runtime Exception. Unable to parse line \"x,y,z,a,b,c\"\n        Set error_bad_lines=False to skip bad lines\n        \"\"\"\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=error_bad_lines, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, skiprows=skiprows, verbose=verbose, store_errors=False, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)[0]",
        "mutated": [
            "@classmethod\ndef read_csv(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names : \\'X1, X2, ...\\'.\\n\\n        error_bad_lines : bool\\n            If true, will fail upon encountering a bad line. If false, will\\n            continue parsing skipping lines which fail to parse correctly.\\n            A sample of the first 10 encountered bad lines will be printed.\\n\\n        comment_char : string, optional\\n            The character which denotes that the remainder of the line is a\\n            comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        nrows_to_infer : integer\\n            The number of rows used to infer column types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        --------\\n        read_csv_with_errors, SFrame\\n\\n        Examples\\n        --------\\n\\n        Read a regular csv file, with all default options, automatically\\n        determine types:\\n\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Read only the first 100 lines of the csv file:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, nrows=100)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 100\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [100 rows x 3 columns]\\n\\n        Read all columns as str type\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id  str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Specify types for a subset of columns and leave the rest to be str.\\n\\n        >>> sf = turicreate.SFrame.read_csv(url,\\n        ...                               column_type_hints={\\n        ...                               \\'user_id\\':int, \\'rating\\':float\\n        ...                               })\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  float\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  3.0   |\\n        |  25907  |   1663   |  3.0   |\\n        |  25923  |   1663   |  3.0   |\\n        |  25924  |   1663   |  3.0   |\\n        |  25928  |   1663   |  2.0   |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Not treat first line as header:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, header=False)\\n        >>> sf\\n        Columns:\\n          X1  str\\n          X2  str\\n          X3  str\\n        Rows: 10001\\n        +---------+----------+--------+\\n        |    X1   |    X2    |   X3   |\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10001 rows x 3 columns]\\n\\n        Treat \\'3\\' as missing value:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, na_values=[\\'3\\'], column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  None  |\\n        |  25907  |   1663   |  None  |\\n        |  25923  |   1663   |  None  |\\n        |  25924  |   1663   |  None  |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Throw error on parse failure:\\n\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(bad_url, error_bad_lines=True)\\n        RuntimeError: Runtime Exception. Unable to parse line \"x,y,z,a,b,c\"\\n        Set error_bad_lines=False to skip bad lines\\n        '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=error_bad_lines, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, skiprows=skiprows, verbose=verbose, store_errors=False, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)[0]",
            "@classmethod\ndef read_csv(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names : \\'X1, X2, ...\\'.\\n\\n        error_bad_lines : bool\\n            If true, will fail upon encountering a bad line. If false, will\\n            continue parsing skipping lines which fail to parse correctly.\\n            A sample of the first 10 encountered bad lines will be printed.\\n\\n        comment_char : string, optional\\n            The character which denotes that the remainder of the line is a\\n            comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        nrows_to_infer : integer\\n            The number of rows used to infer column types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        --------\\n        read_csv_with_errors, SFrame\\n\\n        Examples\\n        --------\\n\\n        Read a regular csv file, with all default options, automatically\\n        determine types:\\n\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Read only the first 100 lines of the csv file:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, nrows=100)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 100\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [100 rows x 3 columns]\\n\\n        Read all columns as str type\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id  str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Specify types for a subset of columns and leave the rest to be str.\\n\\n        >>> sf = turicreate.SFrame.read_csv(url,\\n        ...                               column_type_hints={\\n        ...                               \\'user_id\\':int, \\'rating\\':float\\n        ...                               })\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  float\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  3.0   |\\n        |  25907  |   1663   |  3.0   |\\n        |  25923  |   1663   |  3.0   |\\n        |  25924  |   1663   |  3.0   |\\n        |  25928  |   1663   |  2.0   |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Not treat first line as header:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, header=False)\\n        >>> sf\\n        Columns:\\n          X1  str\\n          X2  str\\n          X3  str\\n        Rows: 10001\\n        +---------+----------+--------+\\n        |    X1   |    X2    |   X3   |\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10001 rows x 3 columns]\\n\\n        Treat \\'3\\' as missing value:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, na_values=[\\'3\\'], column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  None  |\\n        |  25907  |   1663   |  None  |\\n        |  25923  |   1663   |  None  |\\n        |  25924  |   1663   |  None  |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Throw error on parse failure:\\n\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(bad_url, error_bad_lines=True)\\n        RuntimeError: Runtime Exception. Unable to parse line \"x,y,z,a,b,c\"\\n        Set error_bad_lines=False to skip bad lines\\n        '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=error_bad_lines, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, skiprows=skiprows, verbose=verbose, store_errors=False, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)[0]",
            "@classmethod\ndef read_csv(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names : \\'X1, X2, ...\\'.\\n\\n        error_bad_lines : bool\\n            If true, will fail upon encountering a bad line. If false, will\\n            continue parsing skipping lines which fail to parse correctly.\\n            A sample of the first 10 encountered bad lines will be printed.\\n\\n        comment_char : string, optional\\n            The character which denotes that the remainder of the line is a\\n            comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        nrows_to_infer : integer\\n            The number of rows used to infer column types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        --------\\n        read_csv_with_errors, SFrame\\n\\n        Examples\\n        --------\\n\\n        Read a regular csv file, with all default options, automatically\\n        determine types:\\n\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Read only the first 100 lines of the csv file:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, nrows=100)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 100\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [100 rows x 3 columns]\\n\\n        Read all columns as str type\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id  str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Specify types for a subset of columns and leave the rest to be str.\\n\\n        >>> sf = turicreate.SFrame.read_csv(url,\\n        ...                               column_type_hints={\\n        ...                               \\'user_id\\':int, \\'rating\\':float\\n        ...                               })\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  float\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  3.0   |\\n        |  25907  |   1663   |  3.0   |\\n        |  25923  |   1663   |  3.0   |\\n        |  25924  |   1663   |  3.0   |\\n        |  25928  |   1663   |  2.0   |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Not treat first line as header:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, header=False)\\n        >>> sf\\n        Columns:\\n          X1  str\\n          X2  str\\n          X3  str\\n        Rows: 10001\\n        +---------+----------+--------+\\n        |    X1   |    X2    |   X3   |\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10001 rows x 3 columns]\\n\\n        Treat \\'3\\' as missing value:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, na_values=[\\'3\\'], column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  None  |\\n        |  25907  |   1663   |  None  |\\n        |  25923  |   1663   |  None  |\\n        |  25924  |   1663   |  None  |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Throw error on parse failure:\\n\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(bad_url, error_bad_lines=True)\\n        RuntimeError: Runtime Exception. Unable to parse line \"x,y,z,a,b,c\"\\n        Set error_bad_lines=False to skip bad lines\\n        '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=error_bad_lines, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, skiprows=skiprows, verbose=verbose, store_errors=False, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)[0]",
            "@classmethod\ndef read_csv(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names : \\'X1, X2, ...\\'.\\n\\n        error_bad_lines : bool\\n            If true, will fail upon encountering a bad line. If false, will\\n            continue parsing skipping lines which fail to parse correctly.\\n            A sample of the first 10 encountered bad lines will be printed.\\n\\n        comment_char : string, optional\\n            The character which denotes that the remainder of the line is a\\n            comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        nrows_to_infer : integer\\n            The number of rows used to infer column types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        --------\\n        read_csv_with_errors, SFrame\\n\\n        Examples\\n        --------\\n\\n        Read a regular csv file, with all default options, automatically\\n        determine types:\\n\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Read only the first 100 lines of the csv file:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, nrows=100)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 100\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [100 rows x 3 columns]\\n\\n        Read all columns as str type\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id  str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Specify types for a subset of columns and leave the rest to be str.\\n\\n        >>> sf = turicreate.SFrame.read_csv(url,\\n        ...                               column_type_hints={\\n        ...                               \\'user_id\\':int, \\'rating\\':float\\n        ...                               })\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  float\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  3.0   |\\n        |  25907  |   1663   |  3.0   |\\n        |  25923  |   1663   |  3.0   |\\n        |  25924  |   1663   |  3.0   |\\n        |  25928  |   1663   |  2.0   |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Not treat first line as header:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, header=False)\\n        >>> sf\\n        Columns:\\n          X1  str\\n          X2  str\\n          X3  str\\n        Rows: 10001\\n        +---------+----------+--------+\\n        |    X1   |    X2    |   X3   |\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10001 rows x 3 columns]\\n\\n        Treat \\'3\\' as missing value:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, na_values=[\\'3\\'], column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  None  |\\n        |  25907  |   1663   |  None  |\\n        |  25923  |   1663   |  None  |\\n        |  25924  |   1663   |  None  |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Throw error on parse failure:\\n\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(bad_url, error_bad_lines=True)\\n        RuntimeError: Runtime Exception. Unable to parse line \"x,y,z,a,b,c\"\\n        Set error_bad_lines=False to skip bad lines\\n        '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=error_bad_lines, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, skiprows=skiprows, verbose=verbose, store_errors=False, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)[0]",
            "@classmethod\ndef read_csv(cls, url, delimiter=',', header=True, error_bad_lines=False, comment_char='', escape_char='\\\\', double_quote=True, quote_char='\"', skip_initial_space=True, column_type_hints=None, na_values=['NA'], line_terminator='\\n', usecols=[], nrows=None, skiprows=0, verbose=True, nrows_to_infer=100, true_values=[], false_values=[], _only_raw_string_substitutions=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Constructs an SFrame from a CSV file or a path to multiple CSVs.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for parsing csv files.\\n\\n        header : bool, optional\\n            If true, uses the first row as the column names. Otherwise use the\\n            default column names : \\'X1, X2, ...\\'.\\n\\n        error_bad_lines : bool\\n            If true, will fail upon encountering a bad line. If false, will\\n            continue parsing skipping lines which fail to parse correctly.\\n            A sample of the first 10 encountered bad lines will be printed.\\n\\n        comment_char : string, optional\\n            The character which denotes that the remainder of the line is a\\n            comment.\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence. Defaults to backslash(\\\\)\\n            Set to None to disable.\\n\\n        double_quote : bool, optional\\n            If True, two consecutive quotes in a string are parsed to a single\\n            quote.\\n\\n        quote_char : string, optional\\n            Character sequence that indicates a quote.\\n\\n        skip_initial_space : bool, optional\\n            Ignore extra spaces at the start of a field\\n\\n        column_type_hints : None, type, list[type], dict[string, type], optional\\n            This provides type hints for each column. By default, this method\\n            attempts to detect the type of each column automatically.\\n\\n            Supported types are int, float, str, list, dict, and array.array.\\n\\n            * If a single type is provided, the type will be\\n              applied to all columns. For instance, column_type_hints=float\\n              will force all columns to be parsed as float.\\n            * If a list of types is provided, the types applies\\n              to each column in order, e.g.[int, float, str]\\n              will parse the first column as int, second as float and third as\\n              string.\\n            * If a dictionary of column name to type is provided,\\n              each type value in the dictionary is applied to the key it\\n              belongs to.\\n              For instance {\\'user\\':int} will hint that the column called \"user\"\\n              should be parsed as an integer, and the rest will be type inferred.\\n\\n        na_values : str | list of str, optional\\n            A string or list of strings to be interpreted as missing values.\\n\\n        true_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 1\\n\\n        false_values : str | list of str, optional\\n            A string or list of strings to be interpreted as 0\\n\\n\\n        line_terminator : str, optional\\n            A string to be interpreted as the line terminator. Defaults to \"\\n\"\\n            which will also correctly match Mac, Linux and Windows line endings\\n            (\"\\\\r\", \"\\\\n\" and \"\\\\r\\\\n\" respectively)\\n\\n        usecols : list of str, optional\\n            A subset of column names to output. If unspecified (default),\\n            all columns will be read. This can provide performance gains if the\\n            number of columns are large. If the input file has no headers,\\n            usecols=[\\'X1\\',\\'X3\\'] will read columns 1 and 3.\\n\\n        nrows : int, optional\\n            If set, only this many rows will be read from the file.\\n\\n        skiprows : int, optional\\n            If set, this number of rows at the start of the file are skipped.\\n\\n        verbose : bool, optional\\n            If True, print the progress.\\n\\n        nrows_to_infer : integer\\n            The number of rows used to infer column types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        --------\\n        read_csv_with_errors, SFrame\\n\\n        Examples\\n        --------\\n\\n        Read a regular csv file, with all default options, automatically\\n        determine types:\\n\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Read only the first 100 lines of the csv file:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, nrows=100)\\n        >>> sf\\n        Columns:\\n          user_id int\\n          movie_id  int\\n          rating  int\\n        Rows: 100\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [100 rows x 3 columns]\\n\\n        Read all columns as str type\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id  str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Specify types for a subset of columns and leave the rest to be str.\\n\\n        >>> sf = turicreate.SFrame.read_csv(url,\\n        ...                               column_type_hints={\\n        ...                               \\'user_id\\':int, \\'rating\\':float\\n        ...                               })\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  float\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  3.0   |\\n        |  25907  |   1663   |  3.0   |\\n        |  25923  |   1663   |  3.0   |\\n        |  25924  |   1663   |  3.0   |\\n        |  25928  |   1663   |  2.0   |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Not treat first line as header:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, header=False)\\n        >>> sf\\n        Columns:\\n          X1  str\\n          X2  str\\n          X3  str\\n        Rows: 10001\\n        +---------+----------+--------+\\n        |    X1   |    X2    |   X3   |\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10001 rows x 3 columns]\\n\\n        Treat \\'3\\' as missing value:\\n\\n        >>> sf = turicreate.SFrame.read_csv(url, na_values=[\\'3\\'], column_type_hints=str)\\n        >>> sf\\n        Columns:\\n          user_id str\\n          movie_id  str\\n          rating  str\\n        Rows: 10000\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |  None  |\\n        |  25907  |   1663   |  None  |\\n        |  25923  |   1663   |  None  |\\n        |  25924  |   1663   |  None  |\\n        |  25928  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Throw error on parse failure:\\n\\n        >>> bad_url = \\'https://static.turi.com/datasets/bad_csv_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(bad_url, error_bad_lines=True)\\n        RuntimeError: Runtime Exception. Unable to parse line \"x,y,z,a,b,c\"\\n        Set error_bad_lines=False to skip bad lines\\n        '\n    return cls._read_csv_impl(url, delimiter=delimiter, header=header, error_bad_lines=error_bad_lines, comment_char=comment_char, escape_char=escape_char, double_quote=double_quote, quote_char=quote_char, skip_initial_space=skip_initial_space, column_type_hints=column_type_hints, na_values=na_values, line_terminator=line_terminator, usecols=usecols, nrows=nrows, skiprows=skiprows, verbose=verbose, store_errors=False, nrows_to_infer=nrows_to_infer, true_values=true_values, false_values=false_values, _only_raw_string_substitutions=_only_raw_string_substitutions, **kwargs)[0]"
        ]
    },
    {
        "func_name": "read_json",
        "original": "@classmethod\ndef read_json(cls, url, orient='records'):\n    \"\"\"\n        Reads a JSON file representing a table into an SFrame.\n\n        Parameters\n        ----------\n        url : string\n            Location of the CSV file or directory to load. If URL is a directory\n            or a \"glob\" pattern, all matching files will be loaded.\n\n        orient : string, optional. Either \"records\" or \"lines\"\n            If orient=\"records\" the file is expected to contain a single JSON\n            array, where each array element is a dictionary. If orient=\"lines\",\n            the file is expected to contain a JSON element per line.\n\n        Examples\n        --------\n        The orient parameter describes the expected input format of the JSON\n        file.\n\n        If orient=\"records\", the JSON file is expected to contain a single\n        JSON Array where each array element is a dictionary describing the row.\n        For instance:\n\n        >>> !cat input.json\n        [{'a':1,'b':1}, {'a':2,'b':2}, {'a':3,'b':3}]\n        >>> SFrame.read_json('input.json', orient='records')\n        Columns:\n                a\tint\n                b\tint\n        Rows: 3\n        Data:\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | 1 |\n        | 2 | 2 |\n        | 3 | 3 |\n        +---+---+\n\n        If orient=\"lines\", the JSON file is expected to contain a JSON element\n        per line. If each line contains a dictionary, it is automatically\n        unpacked.\n\n        >>> !cat input.json\n        {'a':1,'b':1}\n        {'a':2,'b':2}\n        {'a':3,'b':3}\n        >>> g = SFrame.read_json('input.json', orient='lines')\n        Columns:\n                a\tint\n                b\tint\n        Rows: 3\n        Data:\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | 1 |\n        | 2 | 2 |\n        | 3 | 3 |\n        +---+---+\n\n        If the lines are not dictionaries, the original format is maintained.\n\n        >>> !cat input.json\n        ['a','b','c']\n        ['d','e','f']\n        ['g','h','i']\n        [1,2,3]\n        >>> g = SFrame.read_json('input.json', orient='lines')\n        Columns:\n                X1\tlist\n        Rows: 3\n        Data:\n        +-----------+\n        |     X1    |\n        +-----------+\n        | [a, b, c] |\n        | [d, e, f] |\n        | [g, h, i] |\n        +-----------+\n        [3 rows x 1 columns]\n        \"\"\"\n    if orient == 'records':\n        g = SArray.read_json(url)\n        if len(g) == 0:\n            return SFrame()\n        if g.dtype != dict:\n            raise RuntimeError('Invalid input JSON format. Expected list of dictionaries')\n        g = SFrame({'X1': g})\n        return g.unpack('X1', '')\n    elif orient == 'lines':\n        g = cls.read_csv(url, header=False, na_values=['null'], true_values=['true'], false_values=['false'], _only_raw_string_substitutions=True)\n        if g.num_rows() == 0:\n            return SFrame()\n        if g.num_columns() != 1:\n            raise RuntimeError('Input JSON not of expected format')\n        if g['X1'].dtype == dict:\n            return g.unpack('X1', '')\n        else:\n            return g\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
        "mutated": [
            "@classmethod\ndef read_json(cls, url, orient='records'):\n    if False:\n        i = 10\n    '\\n        Reads a JSON file representing a table into an SFrame.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is expected to contain a single JSON\\n            array, where each array element is a dictionary. If orient=\"lines\",\\n            the file is expected to contain a JSON element per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the JSON file is expected to contain a single\\n        JSON Array where each array element is a dictionary describing the row.\\n        For instance:\\n\\n        >>> !cat input.json\\n        [{\\'a\\':1,\\'b\\':1}, {\\'a\\':2,\\'b\\':2}, {\\'a\\':3,\\'b\\':3}]\\n        >>> SFrame.read_json(\\'input.json\\', orient=\\'records\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If orient=\"lines\", the JSON file is expected to contain a JSON element\\n        per line. If each line contains a dictionary, it is automatically\\n        unpacked.\\n\\n        >>> !cat input.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If the lines are not dictionaries, the original format is maintained.\\n\\n        >>> !cat input.json\\n        [\\'a\\',\\'b\\',\\'c\\']\\n        [\\'d\\',\\'e\\',\\'f\\']\\n        [\\'g\\',\\'h\\',\\'i\\']\\n        [1,2,3]\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                X1\\tlist\\n        Rows: 3\\n        Data:\\n        +-----------+\\n        |     X1    |\\n        +-----------+\\n        | [a, b, c] |\\n        | [d, e, f] |\\n        | [g, h, i] |\\n        +-----------+\\n        [3 rows x 1 columns]\\n        '\n    if orient == 'records':\n        g = SArray.read_json(url)\n        if len(g) == 0:\n            return SFrame()\n        if g.dtype != dict:\n            raise RuntimeError('Invalid input JSON format. Expected list of dictionaries')\n        g = SFrame({'X1': g})\n        return g.unpack('X1', '')\n    elif orient == 'lines':\n        g = cls.read_csv(url, header=False, na_values=['null'], true_values=['true'], false_values=['false'], _only_raw_string_substitutions=True)\n        if g.num_rows() == 0:\n            return SFrame()\n        if g.num_columns() != 1:\n            raise RuntimeError('Input JSON not of expected format')\n        if g['X1'].dtype == dict:\n            return g.unpack('X1', '')\n        else:\n            return g\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "@classmethod\ndef read_json(cls, url, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Reads a JSON file representing a table into an SFrame.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is expected to contain a single JSON\\n            array, where each array element is a dictionary. If orient=\"lines\",\\n            the file is expected to contain a JSON element per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the JSON file is expected to contain a single\\n        JSON Array where each array element is a dictionary describing the row.\\n        For instance:\\n\\n        >>> !cat input.json\\n        [{\\'a\\':1,\\'b\\':1}, {\\'a\\':2,\\'b\\':2}, {\\'a\\':3,\\'b\\':3}]\\n        >>> SFrame.read_json(\\'input.json\\', orient=\\'records\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If orient=\"lines\", the JSON file is expected to contain a JSON element\\n        per line. If each line contains a dictionary, it is automatically\\n        unpacked.\\n\\n        >>> !cat input.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If the lines are not dictionaries, the original format is maintained.\\n\\n        >>> !cat input.json\\n        [\\'a\\',\\'b\\',\\'c\\']\\n        [\\'d\\',\\'e\\',\\'f\\']\\n        [\\'g\\',\\'h\\',\\'i\\']\\n        [1,2,3]\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                X1\\tlist\\n        Rows: 3\\n        Data:\\n        +-----------+\\n        |     X1    |\\n        +-----------+\\n        | [a, b, c] |\\n        | [d, e, f] |\\n        | [g, h, i] |\\n        +-----------+\\n        [3 rows x 1 columns]\\n        '\n    if orient == 'records':\n        g = SArray.read_json(url)\n        if len(g) == 0:\n            return SFrame()\n        if g.dtype != dict:\n            raise RuntimeError('Invalid input JSON format. Expected list of dictionaries')\n        g = SFrame({'X1': g})\n        return g.unpack('X1', '')\n    elif orient == 'lines':\n        g = cls.read_csv(url, header=False, na_values=['null'], true_values=['true'], false_values=['false'], _only_raw_string_substitutions=True)\n        if g.num_rows() == 0:\n            return SFrame()\n        if g.num_columns() != 1:\n            raise RuntimeError('Input JSON not of expected format')\n        if g['X1'].dtype == dict:\n            return g.unpack('X1', '')\n        else:\n            return g\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "@classmethod\ndef read_json(cls, url, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Reads a JSON file representing a table into an SFrame.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is expected to contain a single JSON\\n            array, where each array element is a dictionary. If orient=\"lines\",\\n            the file is expected to contain a JSON element per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the JSON file is expected to contain a single\\n        JSON Array where each array element is a dictionary describing the row.\\n        For instance:\\n\\n        >>> !cat input.json\\n        [{\\'a\\':1,\\'b\\':1}, {\\'a\\':2,\\'b\\':2}, {\\'a\\':3,\\'b\\':3}]\\n        >>> SFrame.read_json(\\'input.json\\', orient=\\'records\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If orient=\"lines\", the JSON file is expected to contain a JSON element\\n        per line. If each line contains a dictionary, it is automatically\\n        unpacked.\\n\\n        >>> !cat input.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If the lines are not dictionaries, the original format is maintained.\\n\\n        >>> !cat input.json\\n        [\\'a\\',\\'b\\',\\'c\\']\\n        [\\'d\\',\\'e\\',\\'f\\']\\n        [\\'g\\',\\'h\\',\\'i\\']\\n        [1,2,3]\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                X1\\tlist\\n        Rows: 3\\n        Data:\\n        +-----------+\\n        |     X1    |\\n        +-----------+\\n        | [a, b, c] |\\n        | [d, e, f] |\\n        | [g, h, i] |\\n        +-----------+\\n        [3 rows x 1 columns]\\n        '\n    if orient == 'records':\n        g = SArray.read_json(url)\n        if len(g) == 0:\n            return SFrame()\n        if g.dtype != dict:\n            raise RuntimeError('Invalid input JSON format. Expected list of dictionaries')\n        g = SFrame({'X1': g})\n        return g.unpack('X1', '')\n    elif orient == 'lines':\n        g = cls.read_csv(url, header=False, na_values=['null'], true_values=['true'], false_values=['false'], _only_raw_string_substitutions=True)\n        if g.num_rows() == 0:\n            return SFrame()\n        if g.num_columns() != 1:\n            raise RuntimeError('Input JSON not of expected format')\n        if g['X1'].dtype == dict:\n            return g.unpack('X1', '')\n        else:\n            return g\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "@classmethod\ndef read_json(cls, url, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Reads a JSON file representing a table into an SFrame.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is expected to contain a single JSON\\n            array, where each array element is a dictionary. If orient=\"lines\",\\n            the file is expected to contain a JSON element per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the JSON file is expected to contain a single\\n        JSON Array where each array element is a dictionary describing the row.\\n        For instance:\\n\\n        >>> !cat input.json\\n        [{\\'a\\':1,\\'b\\':1}, {\\'a\\':2,\\'b\\':2}, {\\'a\\':3,\\'b\\':3}]\\n        >>> SFrame.read_json(\\'input.json\\', orient=\\'records\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If orient=\"lines\", the JSON file is expected to contain a JSON element\\n        per line. If each line contains a dictionary, it is automatically\\n        unpacked.\\n\\n        >>> !cat input.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If the lines are not dictionaries, the original format is maintained.\\n\\n        >>> !cat input.json\\n        [\\'a\\',\\'b\\',\\'c\\']\\n        [\\'d\\',\\'e\\',\\'f\\']\\n        [\\'g\\',\\'h\\',\\'i\\']\\n        [1,2,3]\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                X1\\tlist\\n        Rows: 3\\n        Data:\\n        +-----------+\\n        |     X1    |\\n        +-----------+\\n        | [a, b, c] |\\n        | [d, e, f] |\\n        | [g, h, i] |\\n        +-----------+\\n        [3 rows x 1 columns]\\n        '\n    if orient == 'records':\n        g = SArray.read_json(url)\n        if len(g) == 0:\n            return SFrame()\n        if g.dtype != dict:\n            raise RuntimeError('Invalid input JSON format. Expected list of dictionaries')\n        g = SFrame({'X1': g})\n        return g.unpack('X1', '')\n    elif orient == 'lines':\n        g = cls.read_csv(url, header=False, na_values=['null'], true_values=['true'], false_values=['false'], _only_raw_string_substitutions=True)\n        if g.num_rows() == 0:\n            return SFrame()\n        if g.num_columns() != 1:\n            raise RuntimeError('Input JSON not of expected format')\n        if g['X1'].dtype == dict:\n            return g.unpack('X1', '')\n        else:\n            return g\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "@classmethod\ndef read_json(cls, url, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Reads a JSON file representing a table into an SFrame.\\n\\n        Parameters\\n        ----------\\n        url : string\\n            Location of the CSV file or directory to load. If URL is a directory\\n            or a \"glob\" pattern, all matching files will be loaded.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is expected to contain a single JSON\\n            array, where each array element is a dictionary. If orient=\"lines\",\\n            the file is expected to contain a JSON element per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the JSON file is expected to contain a single\\n        JSON Array where each array element is a dictionary describing the row.\\n        For instance:\\n\\n        >>> !cat input.json\\n        [{\\'a\\':1,\\'b\\':1}, {\\'a\\':2,\\'b\\':2}, {\\'a\\':3,\\'b\\':3}]\\n        >>> SFrame.read_json(\\'input.json\\', orient=\\'records\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If orient=\"lines\", the JSON file is expected to contain a JSON element\\n        per line. If each line contains a dictionary, it is automatically\\n        unpacked.\\n\\n        >>> !cat input.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n\\n        If the lines are not dictionaries, the original format is maintained.\\n\\n        >>> !cat input.json\\n        [\\'a\\',\\'b\\',\\'c\\']\\n        [\\'d\\',\\'e\\',\\'f\\']\\n        [\\'g\\',\\'h\\',\\'i\\']\\n        [1,2,3]\\n        >>> g = SFrame.read_json(\\'input.json\\', orient=\\'lines\\')\\n        Columns:\\n                X1\\tlist\\n        Rows: 3\\n        Data:\\n        +-----------+\\n        |     X1    |\\n        +-----------+\\n        | [a, b, c] |\\n        | [d, e, f] |\\n        | [g, h, i] |\\n        +-----------+\\n        [3 rows x 1 columns]\\n        '\n    if orient == 'records':\n        g = SArray.read_json(url)\n        if len(g) == 0:\n            return SFrame()\n        if g.dtype != dict:\n            raise RuntimeError('Invalid input JSON format. Expected list of dictionaries')\n        g = SFrame({'X1': g})\n        return g.unpack('X1', '')\n    elif orient == 'lines':\n        g = cls.read_csv(url, header=False, na_values=['null'], true_values=['true'], false_values=['false'], _only_raw_string_substitutions=True)\n        if g.num_rows() == 0:\n            return SFrame()\n        if g.num_columns() != 1:\n            raise RuntimeError('Input JSON not of expected format')\n        if g['X1'].dtype == dict:\n            return g.unpack('X1', '')\n        else:\n            return g\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')"
        ]
    },
    {
        "func_name": "from_sql",
        "original": "@classmethod\ndef from_sql(cls, conn, sql_statement, params=None, type_inference_rows=100, dbapi_module=None, column_type_hints=None, cursor_arraysize=128):\n    \"\"\"\n        Convert the result of a SQL database query to an SFrame.\n\n        Parameters\n        ----------\n        conn : dbapi2.Connection\n          A DBAPI2 connection object. Any connection object originating from\n          the 'connect' method of a DBAPI2-compliant package can be used.\n\n        sql_statement : str\n          The query to be sent to the database through the given connection.\n          No checks are performed on the `sql_statement`. Any side effects from\n          the query will be reflected on the database.  If no result rows are\n          returned, an empty SFrame is created.\n\n        params : iterable | dict, optional\n          Parameters to substitute for any parameter markers in the\n          `sql_statement`. Be aware that the style of parameters may vary\n          between different DBAPI2 packages.\n\n        type_inference_rows : int, optional\n          The maximum number of rows to use for determining the column types of\n          the SFrame. These rows are held in Python until all column types are\n          determined or the maximum is reached.\n\n        dbapi_module : module | package, optional\n          The top-level DBAPI2 module/package that constructed the given\n          connection object. By default, a best guess of which module the\n          connection came from is made. In the event that this guess is wrong,\n          this will need to be specified.\n\n        column_type_hints : dict | list | type, optional\n          Specifies the types of the output SFrame. If a dict is given, it must\n          have result column names as keys, but need not have all of the result\n          column names. If a list is given, the length of the list must match\n          the number of result columns. If a single type is given, all columns\n          in the output SFrame will be this type. If the result type is\n          incompatible with the types given in this argument, a casting error\n          will occur.\n\n        cursor_arraysize : int, optional\n          The number of rows to fetch from the database at one time.\n\n        Returns\n        -------\n        out : SFrame\n\n        Examples\n        --------\n        >>> import sqlite3\n\n        >>> conn = sqlite3.connect('example.db')\n\n        >>> turicreate.SFrame.from_sql(conn, \"SELECT * FROM foo\")\n        Columns:\n                a       int\n                b       int\n        Rows: 1\n        Data:\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | 2 |\n        +---+---+\n        [1 rows x 2 columns]\n        \"\"\"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    from .sframe_builder import SFrameBuilder\n    c = conn.cursor()\n    try:\n        if params is None:\n            c.execute(sql_statement)\n        else:\n            c.execute(sql_statement, params)\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    c.arraysize = cursor_arraysize\n    result_desc = c.description\n    result_names = [i[0] for i in result_desc]\n    result_types = [None for i in result_desc]\n    cols_to_force_cast = set()\n    temp_vals = []\n    col_name_to_num = {result_names[i]: i for i in range(len(result_names))}\n    if column_type_hints is not None:\n        if type(column_type_hints) is dict:\n            for (k, v) in column_type_hints.items():\n                col_num = col_name_to_num[k]\n                cols_to_force_cast.add(col_num)\n                result_types[col_num] = v\n        elif type(column_type_hints) is list:\n            if len(column_type_hints) != len(result_names):\n                __LOGGER__.warn('If column_type_hints is specified as a ' + 'list, it must be of the same size as the result ' + \"set's number of columns. Ignoring (use dict instead).\")\n            else:\n                result_types = column_type_hints\n                cols_to_force_cast.update(range(len(result_desc)))\n        elif type(column_type_hints) is type:\n            result_types = [column_type_hints for i in result_desc]\n            cols_to_force_cast.update(range(len(result_desc)))\n    hintable_types = [int, float, str]\n    if not all([i in hintable_types or i is None for i in result_types]):\n        raise TypeError('Only ' + str(hintable_types) + ' can be provided as type hints!')\n    if not all(result_types):\n        try:\n            row = c.fetchone()\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n        while row is not None:\n            temp_vals.append(row)\n            val_count = 0\n            for val in row:\n                if result_types[val_count] is None and val is not None:\n                    result_types[val_count] = type(val)\n                val_count += 1\n            if all(result_types) or len(temp_vals) >= type_inference_rows:\n                break\n            row = c.fetchone()\n    if not all(result_types):\n        missing_val_cols = [i for (i, v) in enumerate(result_types) if v is None]\n        cols_to_force_cast.update(missing_val_cols)\n        inferred_types = _infer_dbapi2_types(c, mod_info)\n        cnt = 0\n        for i in result_types:\n            if i is None:\n                result_types[cnt] = inferred_types[cnt]\n            cnt += 1\n    sb = SFrameBuilder(result_types, column_names=result_names)\n    unsupported_cols = [i for (i, v) in enumerate(sb.column_types()) if v is type(None)]\n    if len(unsupported_cols) > 0:\n        cols_to_force_cast.update(unsupported_cols)\n        for i in unsupported_cols:\n            result_types[i] = str\n        sb = SFrameBuilder(result_types, column_names=result_names)\n    temp_vals = _convert_rows_to_builtin_seq(temp_vals)\n    sb.append_multiple(_force_cast_sql_types(temp_vals, result_types, cols_to_force_cast))\n    rows = c.fetchmany()\n    while len(rows) > 0:\n        rows = _convert_rows_to_builtin_seq(rows)\n        sb.append_multiple(_force_cast_sql_types(rows, result_types, cols_to_force_cast))\n        rows = c.fetchmany()\n    cls = sb.close()\n    try:\n        c.close()\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    return cls",
        "mutated": [
            "@classmethod\ndef from_sql(cls, conn, sql_statement, params=None, type_inference_rows=100, dbapi_module=None, column_type_hints=None, cursor_arraysize=128):\n    if False:\n        i = 10\n    '\\n        Convert the result of a SQL database query to an SFrame.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the \\'connect\\' method of a DBAPI2-compliant package can be used.\\n\\n        sql_statement : str\\n          The query to be sent to the database through the given connection.\\n          No checks are performed on the `sql_statement`. Any side effects from\\n          the query will be reflected on the database.  If no result rows are\\n          returned, an empty SFrame is created.\\n\\n        params : iterable | dict, optional\\n          Parameters to substitute for any parameter markers in the\\n          `sql_statement`. Be aware that the style of parameters may vary\\n          between different DBAPI2 packages.\\n\\n        type_inference_rows : int, optional\\n          The maximum number of rows to use for determining the column types of\\n          the SFrame. These rows are held in Python until all column types are\\n          determined or the maximum is reached.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        column_type_hints : dict | list | type, optional\\n          Specifies the types of the output SFrame. If a dict is given, it must\\n          have result column names as keys, but need not have all of the result\\n          column names. If a list is given, the length of the list must match\\n          the number of result columns. If a single type is given, all columns\\n          in the output SFrame will be this type. If the result type is\\n          incompatible with the types given in this argument, a casting error\\n          will occur.\\n\\n        cursor_arraysize : int, optional\\n          The number of rows to fetch from the database at one time.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> import sqlite3\\n\\n        >>> conn = sqlite3.connect(\\'example.db\\')\\n\\n        >>> turicreate.SFrame.from_sql(conn, \"SELECT * FROM foo\")\\n        Columns:\\n                a       int\\n                b       int\\n        Rows: 1\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 2 |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    from .sframe_builder import SFrameBuilder\n    c = conn.cursor()\n    try:\n        if params is None:\n            c.execute(sql_statement)\n        else:\n            c.execute(sql_statement, params)\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    c.arraysize = cursor_arraysize\n    result_desc = c.description\n    result_names = [i[0] for i in result_desc]\n    result_types = [None for i in result_desc]\n    cols_to_force_cast = set()\n    temp_vals = []\n    col_name_to_num = {result_names[i]: i for i in range(len(result_names))}\n    if column_type_hints is not None:\n        if type(column_type_hints) is dict:\n            for (k, v) in column_type_hints.items():\n                col_num = col_name_to_num[k]\n                cols_to_force_cast.add(col_num)\n                result_types[col_num] = v\n        elif type(column_type_hints) is list:\n            if len(column_type_hints) != len(result_names):\n                __LOGGER__.warn('If column_type_hints is specified as a ' + 'list, it must be of the same size as the result ' + \"set's number of columns. Ignoring (use dict instead).\")\n            else:\n                result_types = column_type_hints\n                cols_to_force_cast.update(range(len(result_desc)))\n        elif type(column_type_hints) is type:\n            result_types = [column_type_hints for i in result_desc]\n            cols_to_force_cast.update(range(len(result_desc)))\n    hintable_types = [int, float, str]\n    if not all([i in hintable_types or i is None for i in result_types]):\n        raise TypeError('Only ' + str(hintable_types) + ' can be provided as type hints!')\n    if not all(result_types):\n        try:\n            row = c.fetchone()\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n        while row is not None:\n            temp_vals.append(row)\n            val_count = 0\n            for val in row:\n                if result_types[val_count] is None and val is not None:\n                    result_types[val_count] = type(val)\n                val_count += 1\n            if all(result_types) or len(temp_vals) >= type_inference_rows:\n                break\n            row = c.fetchone()\n    if not all(result_types):\n        missing_val_cols = [i for (i, v) in enumerate(result_types) if v is None]\n        cols_to_force_cast.update(missing_val_cols)\n        inferred_types = _infer_dbapi2_types(c, mod_info)\n        cnt = 0\n        for i in result_types:\n            if i is None:\n                result_types[cnt] = inferred_types[cnt]\n            cnt += 1\n    sb = SFrameBuilder(result_types, column_names=result_names)\n    unsupported_cols = [i for (i, v) in enumerate(sb.column_types()) if v is type(None)]\n    if len(unsupported_cols) > 0:\n        cols_to_force_cast.update(unsupported_cols)\n        for i in unsupported_cols:\n            result_types[i] = str\n        sb = SFrameBuilder(result_types, column_names=result_names)\n    temp_vals = _convert_rows_to_builtin_seq(temp_vals)\n    sb.append_multiple(_force_cast_sql_types(temp_vals, result_types, cols_to_force_cast))\n    rows = c.fetchmany()\n    while len(rows) > 0:\n        rows = _convert_rows_to_builtin_seq(rows)\n        sb.append_multiple(_force_cast_sql_types(rows, result_types, cols_to_force_cast))\n        rows = c.fetchmany()\n    cls = sb.close()\n    try:\n        c.close()\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    return cls",
            "@classmethod\ndef from_sql(cls, conn, sql_statement, params=None, type_inference_rows=100, dbapi_module=None, column_type_hints=None, cursor_arraysize=128):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Convert the result of a SQL database query to an SFrame.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the \\'connect\\' method of a DBAPI2-compliant package can be used.\\n\\n        sql_statement : str\\n          The query to be sent to the database through the given connection.\\n          No checks are performed on the `sql_statement`. Any side effects from\\n          the query will be reflected on the database.  If no result rows are\\n          returned, an empty SFrame is created.\\n\\n        params : iterable | dict, optional\\n          Parameters to substitute for any parameter markers in the\\n          `sql_statement`. Be aware that the style of parameters may vary\\n          between different DBAPI2 packages.\\n\\n        type_inference_rows : int, optional\\n          The maximum number of rows to use for determining the column types of\\n          the SFrame. These rows are held in Python until all column types are\\n          determined or the maximum is reached.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        column_type_hints : dict | list | type, optional\\n          Specifies the types of the output SFrame. If a dict is given, it must\\n          have result column names as keys, but need not have all of the result\\n          column names. If a list is given, the length of the list must match\\n          the number of result columns. If a single type is given, all columns\\n          in the output SFrame will be this type. If the result type is\\n          incompatible with the types given in this argument, a casting error\\n          will occur.\\n\\n        cursor_arraysize : int, optional\\n          The number of rows to fetch from the database at one time.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> import sqlite3\\n\\n        >>> conn = sqlite3.connect(\\'example.db\\')\\n\\n        >>> turicreate.SFrame.from_sql(conn, \"SELECT * FROM foo\")\\n        Columns:\\n                a       int\\n                b       int\\n        Rows: 1\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 2 |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    from .sframe_builder import SFrameBuilder\n    c = conn.cursor()\n    try:\n        if params is None:\n            c.execute(sql_statement)\n        else:\n            c.execute(sql_statement, params)\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    c.arraysize = cursor_arraysize\n    result_desc = c.description\n    result_names = [i[0] for i in result_desc]\n    result_types = [None for i in result_desc]\n    cols_to_force_cast = set()\n    temp_vals = []\n    col_name_to_num = {result_names[i]: i for i in range(len(result_names))}\n    if column_type_hints is not None:\n        if type(column_type_hints) is dict:\n            for (k, v) in column_type_hints.items():\n                col_num = col_name_to_num[k]\n                cols_to_force_cast.add(col_num)\n                result_types[col_num] = v\n        elif type(column_type_hints) is list:\n            if len(column_type_hints) != len(result_names):\n                __LOGGER__.warn('If column_type_hints is specified as a ' + 'list, it must be of the same size as the result ' + \"set's number of columns. Ignoring (use dict instead).\")\n            else:\n                result_types = column_type_hints\n                cols_to_force_cast.update(range(len(result_desc)))\n        elif type(column_type_hints) is type:\n            result_types = [column_type_hints for i in result_desc]\n            cols_to_force_cast.update(range(len(result_desc)))\n    hintable_types = [int, float, str]\n    if not all([i in hintable_types or i is None for i in result_types]):\n        raise TypeError('Only ' + str(hintable_types) + ' can be provided as type hints!')\n    if not all(result_types):\n        try:\n            row = c.fetchone()\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n        while row is not None:\n            temp_vals.append(row)\n            val_count = 0\n            for val in row:\n                if result_types[val_count] is None and val is not None:\n                    result_types[val_count] = type(val)\n                val_count += 1\n            if all(result_types) or len(temp_vals) >= type_inference_rows:\n                break\n            row = c.fetchone()\n    if not all(result_types):\n        missing_val_cols = [i for (i, v) in enumerate(result_types) if v is None]\n        cols_to_force_cast.update(missing_val_cols)\n        inferred_types = _infer_dbapi2_types(c, mod_info)\n        cnt = 0\n        for i in result_types:\n            if i is None:\n                result_types[cnt] = inferred_types[cnt]\n            cnt += 1\n    sb = SFrameBuilder(result_types, column_names=result_names)\n    unsupported_cols = [i for (i, v) in enumerate(sb.column_types()) if v is type(None)]\n    if len(unsupported_cols) > 0:\n        cols_to_force_cast.update(unsupported_cols)\n        for i in unsupported_cols:\n            result_types[i] = str\n        sb = SFrameBuilder(result_types, column_names=result_names)\n    temp_vals = _convert_rows_to_builtin_seq(temp_vals)\n    sb.append_multiple(_force_cast_sql_types(temp_vals, result_types, cols_to_force_cast))\n    rows = c.fetchmany()\n    while len(rows) > 0:\n        rows = _convert_rows_to_builtin_seq(rows)\n        sb.append_multiple(_force_cast_sql_types(rows, result_types, cols_to_force_cast))\n        rows = c.fetchmany()\n    cls = sb.close()\n    try:\n        c.close()\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    return cls",
            "@classmethod\ndef from_sql(cls, conn, sql_statement, params=None, type_inference_rows=100, dbapi_module=None, column_type_hints=None, cursor_arraysize=128):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Convert the result of a SQL database query to an SFrame.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the \\'connect\\' method of a DBAPI2-compliant package can be used.\\n\\n        sql_statement : str\\n          The query to be sent to the database through the given connection.\\n          No checks are performed on the `sql_statement`. Any side effects from\\n          the query will be reflected on the database.  If no result rows are\\n          returned, an empty SFrame is created.\\n\\n        params : iterable | dict, optional\\n          Parameters to substitute for any parameter markers in the\\n          `sql_statement`. Be aware that the style of parameters may vary\\n          between different DBAPI2 packages.\\n\\n        type_inference_rows : int, optional\\n          The maximum number of rows to use for determining the column types of\\n          the SFrame. These rows are held in Python until all column types are\\n          determined or the maximum is reached.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        column_type_hints : dict | list | type, optional\\n          Specifies the types of the output SFrame. If a dict is given, it must\\n          have result column names as keys, but need not have all of the result\\n          column names. If a list is given, the length of the list must match\\n          the number of result columns. If a single type is given, all columns\\n          in the output SFrame will be this type. If the result type is\\n          incompatible with the types given in this argument, a casting error\\n          will occur.\\n\\n        cursor_arraysize : int, optional\\n          The number of rows to fetch from the database at one time.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> import sqlite3\\n\\n        >>> conn = sqlite3.connect(\\'example.db\\')\\n\\n        >>> turicreate.SFrame.from_sql(conn, \"SELECT * FROM foo\")\\n        Columns:\\n                a       int\\n                b       int\\n        Rows: 1\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 2 |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    from .sframe_builder import SFrameBuilder\n    c = conn.cursor()\n    try:\n        if params is None:\n            c.execute(sql_statement)\n        else:\n            c.execute(sql_statement, params)\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    c.arraysize = cursor_arraysize\n    result_desc = c.description\n    result_names = [i[0] for i in result_desc]\n    result_types = [None for i in result_desc]\n    cols_to_force_cast = set()\n    temp_vals = []\n    col_name_to_num = {result_names[i]: i for i in range(len(result_names))}\n    if column_type_hints is not None:\n        if type(column_type_hints) is dict:\n            for (k, v) in column_type_hints.items():\n                col_num = col_name_to_num[k]\n                cols_to_force_cast.add(col_num)\n                result_types[col_num] = v\n        elif type(column_type_hints) is list:\n            if len(column_type_hints) != len(result_names):\n                __LOGGER__.warn('If column_type_hints is specified as a ' + 'list, it must be of the same size as the result ' + \"set's number of columns. Ignoring (use dict instead).\")\n            else:\n                result_types = column_type_hints\n                cols_to_force_cast.update(range(len(result_desc)))\n        elif type(column_type_hints) is type:\n            result_types = [column_type_hints for i in result_desc]\n            cols_to_force_cast.update(range(len(result_desc)))\n    hintable_types = [int, float, str]\n    if not all([i in hintable_types or i is None for i in result_types]):\n        raise TypeError('Only ' + str(hintable_types) + ' can be provided as type hints!')\n    if not all(result_types):\n        try:\n            row = c.fetchone()\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n        while row is not None:\n            temp_vals.append(row)\n            val_count = 0\n            for val in row:\n                if result_types[val_count] is None and val is not None:\n                    result_types[val_count] = type(val)\n                val_count += 1\n            if all(result_types) or len(temp_vals) >= type_inference_rows:\n                break\n            row = c.fetchone()\n    if not all(result_types):\n        missing_val_cols = [i for (i, v) in enumerate(result_types) if v is None]\n        cols_to_force_cast.update(missing_val_cols)\n        inferred_types = _infer_dbapi2_types(c, mod_info)\n        cnt = 0\n        for i in result_types:\n            if i is None:\n                result_types[cnt] = inferred_types[cnt]\n            cnt += 1\n    sb = SFrameBuilder(result_types, column_names=result_names)\n    unsupported_cols = [i for (i, v) in enumerate(sb.column_types()) if v is type(None)]\n    if len(unsupported_cols) > 0:\n        cols_to_force_cast.update(unsupported_cols)\n        for i in unsupported_cols:\n            result_types[i] = str\n        sb = SFrameBuilder(result_types, column_names=result_names)\n    temp_vals = _convert_rows_to_builtin_seq(temp_vals)\n    sb.append_multiple(_force_cast_sql_types(temp_vals, result_types, cols_to_force_cast))\n    rows = c.fetchmany()\n    while len(rows) > 0:\n        rows = _convert_rows_to_builtin_seq(rows)\n        sb.append_multiple(_force_cast_sql_types(rows, result_types, cols_to_force_cast))\n        rows = c.fetchmany()\n    cls = sb.close()\n    try:\n        c.close()\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    return cls",
            "@classmethod\ndef from_sql(cls, conn, sql_statement, params=None, type_inference_rows=100, dbapi_module=None, column_type_hints=None, cursor_arraysize=128):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Convert the result of a SQL database query to an SFrame.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the \\'connect\\' method of a DBAPI2-compliant package can be used.\\n\\n        sql_statement : str\\n          The query to be sent to the database through the given connection.\\n          No checks are performed on the `sql_statement`. Any side effects from\\n          the query will be reflected on the database.  If no result rows are\\n          returned, an empty SFrame is created.\\n\\n        params : iterable | dict, optional\\n          Parameters to substitute for any parameter markers in the\\n          `sql_statement`. Be aware that the style of parameters may vary\\n          between different DBAPI2 packages.\\n\\n        type_inference_rows : int, optional\\n          The maximum number of rows to use for determining the column types of\\n          the SFrame. These rows are held in Python until all column types are\\n          determined or the maximum is reached.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        column_type_hints : dict | list | type, optional\\n          Specifies the types of the output SFrame. If a dict is given, it must\\n          have result column names as keys, but need not have all of the result\\n          column names. If a list is given, the length of the list must match\\n          the number of result columns. If a single type is given, all columns\\n          in the output SFrame will be this type. If the result type is\\n          incompatible with the types given in this argument, a casting error\\n          will occur.\\n\\n        cursor_arraysize : int, optional\\n          The number of rows to fetch from the database at one time.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> import sqlite3\\n\\n        >>> conn = sqlite3.connect(\\'example.db\\')\\n\\n        >>> turicreate.SFrame.from_sql(conn, \"SELECT * FROM foo\")\\n        Columns:\\n                a       int\\n                b       int\\n        Rows: 1\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 2 |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    from .sframe_builder import SFrameBuilder\n    c = conn.cursor()\n    try:\n        if params is None:\n            c.execute(sql_statement)\n        else:\n            c.execute(sql_statement, params)\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    c.arraysize = cursor_arraysize\n    result_desc = c.description\n    result_names = [i[0] for i in result_desc]\n    result_types = [None for i in result_desc]\n    cols_to_force_cast = set()\n    temp_vals = []\n    col_name_to_num = {result_names[i]: i for i in range(len(result_names))}\n    if column_type_hints is not None:\n        if type(column_type_hints) is dict:\n            for (k, v) in column_type_hints.items():\n                col_num = col_name_to_num[k]\n                cols_to_force_cast.add(col_num)\n                result_types[col_num] = v\n        elif type(column_type_hints) is list:\n            if len(column_type_hints) != len(result_names):\n                __LOGGER__.warn('If column_type_hints is specified as a ' + 'list, it must be of the same size as the result ' + \"set's number of columns. Ignoring (use dict instead).\")\n            else:\n                result_types = column_type_hints\n                cols_to_force_cast.update(range(len(result_desc)))\n        elif type(column_type_hints) is type:\n            result_types = [column_type_hints for i in result_desc]\n            cols_to_force_cast.update(range(len(result_desc)))\n    hintable_types = [int, float, str]\n    if not all([i in hintable_types or i is None for i in result_types]):\n        raise TypeError('Only ' + str(hintable_types) + ' can be provided as type hints!')\n    if not all(result_types):\n        try:\n            row = c.fetchone()\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n        while row is not None:\n            temp_vals.append(row)\n            val_count = 0\n            for val in row:\n                if result_types[val_count] is None and val is not None:\n                    result_types[val_count] = type(val)\n                val_count += 1\n            if all(result_types) or len(temp_vals) >= type_inference_rows:\n                break\n            row = c.fetchone()\n    if not all(result_types):\n        missing_val_cols = [i for (i, v) in enumerate(result_types) if v is None]\n        cols_to_force_cast.update(missing_val_cols)\n        inferred_types = _infer_dbapi2_types(c, mod_info)\n        cnt = 0\n        for i in result_types:\n            if i is None:\n                result_types[cnt] = inferred_types[cnt]\n            cnt += 1\n    sb = SFrameBuilder(result_types, column_names=result_names)\n    unsupported_cols = [i for (i, v) in enumerate(sb.column_types()) if v is type(None)]\n    if len(unsupported_cols) > 0:\n        cols_to_force_cast.update(unsupported_cols)\n        for i in unsupported_cols:\n            result_types[i] = str\n        sb = SFrameBuilder(result_types, column_names=result_names)\n    temp_vals = _convert_rows_to_builtin_seq(temp_vals)\n    sb.append_multiple(_force_cast_sql_types(temp_vals, result_types, cols_to_force_cast))\n    rows = c.fetchmany()\n    while len(rows) > 0:\n        rows = _convert_rows_to_builtin_seq(rows)\n        sb.append_multiple(_force_cast_sql_types(rows, result_types, cols_to_force_cast))\n        rows = c.fetchmany()\n    cls = sb.close()\n    try:\n        c.close()\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    return cls",
            "@classmethod\ndef from_sql(cls, conn, sql_statement, params=None, type_inference_rows=100, dbapi_module=None, column_type_hints=None, cursor_arraysize=128):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Convert the result of a SQL database query to an SFrame.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the \\'connect\\' method of a DBAPI2-compliant package can be used.\\n\\n        sql_statement : str\\n          The query to be sent to the database through the given connection.\\n          No checks are performed on the `sql_statement`. Any side effects from\\n          the query will be reflected on the database.  If no result rows are\\n          returned, an empty SFrame is created.\\n\\n        params : iterable | dict, optional\\n          Parameters to substitute for any parameter markers in the\\n          `sql_statement`. Be aware that the style of parameters may vary\\n          between different DBAPI2 packages.\\n\\n        type_inference_rows : int, optional\\n          The maximum number of rows to use for determining the column types of\\n          the SFrame. These rows are held in Python until all column types are\\n          determined or the maximum is reached.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        column_type_hints : dict | list | type, optional\\n          Specifies the types of the output SFrame. If a dict is given, it must\\n          have result column names as keys, but need not have all of the result\\n          column names. If a list is given, the length of the list must match\\n          the number of result columns. If a single type is given, all columns\\n          in the output SFrame will be this type. If the result type is\\n          incompatible with the types given in this argument, a casting error\\n          will occur.\\n\\n        cursor_arraysize : int, optional\\n          The number of rows to fetch from the database at one time.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> import sqlite3\\n\\n        >>> conn = sqlite3.connect(\\'example.db\\')\\n\\n        >>> turicreate.SFrame.from_sql(conn, \"SELECT * FROM foo\")\\n        Columns:\\n                a       int\\n                b       int\\n        Rows: 1\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 2 |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    from .sframe_builder import SFrameBuilder\n    c = conn.cursor()\n    try:\n        if params is None:\n            c.execute(sql_statement)\n        else:\n            c.execute(sql_statement, params)\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    c.arraysize = cursor_arraysize\n    result_desc = c.description\n    result_names = [i[0] for i in result_desc]\n    result_types = [None for i in result_desc]\n    cols_to_force_cast = set()\n    temp_vals = []\n    col_name_to_num = {result_names[i]: i for i in range(len(result_names))}\n    if column_type_hints is not None:\n        if type(column_type_hints) is dict:\n            for (k, v) in column_type_hints.items():\n                col_num = col_name_to_num[k]\n                cols_to_force_cast.add(col_num)\n                result_types[col_num] = v\n        elif type(column_type_hints) is list:\n            if len(column_type_hints) != len(result_names):\n                __LOGGER__.warn('If column_type_hints is specified as a ' + 'list, it must be of the same size as the result ' + \"set's number of columns. Ignoring (use dict instead).\")\n            else:\n                result_types = column_type_hints\n                cols_to_force_cast.update(range(len(result_desc)))\n        elif type(column_type_hints) is type:\n            result_types = [column_type_hints for i in result_desc]\n            cols_to_force_cast.update(range(len(result_desc)))\n    hintable_types = [int, float, str]\n    if not all([i in hintable_types or i is None for i in result_types]):\n        raise TypeError('Only ' + str(hintable_types) + ' can be provided as type hints!')\n    if not all(result_types):\n        try:\n            row = c.fetchone()\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n        while row is not None:\n            temp_vals.append(row)\n            val_count = 0\n            for val in row:\n                if result_types[val_count] is None and val is not None:\n                    result_types[val_count] = type(val)\n                val_count += 1\n            if all(result_types) or len(temp_vals) >= type_inference_rows:\n                break\n            row = c.fetchone()\n    if not all(result_types):\n        missing_val_cols = [i for (i, v) in enumerate(result_types) if v is None]\n        cols_to_force_cast.update(missing_val_cols)\n        inferred_types = _infer_dbapi2_types(c, mod_info)\n        cnt = 0\n        for i in result_types:\n            if i is None:\n                result_types[cnt] = inferred_types[cnt]\n            cnt += 1\n    sb = SFrameBuilder(result_types, column_names=result_names)\n    unsupported_cols = [i for (i, v) in enumerate(sb.column_types()) if v is type(None)]\n    if len(unsupported_cols) > 0:\n        cols_to_force_cast.update(unsupported_cols)\n        for i in unsupported_cols:\n            result_types[i] = str\n        sb = SFrameBuilder(result_types, column_names=result_names)\n    temp_vals = _convert_rows_to_builtin_seq(temp_vals)\n    sb.append_multiple(_force_cast_sql_types(temp_vals, result_types, cols_to_force_cast))\n    rows = c.fetchmany()\n    while len(rows) > 0:\n        rows = _convert_rows_to_builtin_seq(rows)\n        sb.append_multiple(_force_cast_sql_types(rows, result_types, cols_to_force_cast))\n        rows = c.fetchmany()\n    cls = sb.close()\n    try:\n        c.close()\n    except mod_info['Error'] as e:\n        if hasattr(conn, 'rollback'):\n            conn.rollback()\n        raise e\n    return cls"
        ]
    },
    {
        "func_name": "to_sql",
        "original": "def to_sql(self, conn, table_name, dbapi_module=None, use_python_type_specifiers=False, use_exact_column_names=True):\n    \"\"\"\n        Convert an SFrame to a single table in a SQL database.\n\n        This function does not attempt to create the table or check if a table\n        named `table_name` exists in the database. It simply assumes that\n        `table_name` exists in the database and appends to it.\n\n        `to_sql` can be thought of as a convenience wrapper around\n        parameterized SQL insert statements.\n\n        Parameters\n        ----------\n        conn : dbapi2.Connection\n          A DBAPI2 connection object. Any connection object originating from\n          the 'connect' method of a DBAPI2-compliant package can be used.\n\n        table_name : str\n          The name of the table to append the data in this SFrame.\n\n        dbapi_module : module | package, optional\n          The top-level DBAPI2 module/package that constructed the given\n          connection object. By default, a best guess of which module the\n          connection came from is made. In the event that this guess is wrong,\n          this will need to be specified.\n\n        use_python_type_specifiers : bool, optional\n          If the DBAPI2 module's parameter marker style is 'format' or\n          'pyformat', attempt to use accurate type specifiers for each value\n          ('s' for string, 'd' for integer, etc.). Many DBAPI2 modules simply\n          use 's' for all types if they use these parameter markers, so this is\n          False by default.\n\n        use_exact_column_names : bool, optional\n          Specify the column names of the SFrame when inserting its contents\n          into the DB. If the specified table does not have the exact same\n          column names as the SFrame, inserting the data will fail. If False,\n          the columns in the SFrame are inserted in order without care of the\n          schema of the DB table. True by default.\n        \"\"\"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    c = conn.cursor()\n    col_info = list(zip(self.column_names(), self.column_types()))\n    if not use_python_type_specifiers:\n        _pytype_to_printf = lambda x: 's'\n    sql_param = {'qmark': lambda name, col_num, col_type: '?', 'numeric': lambda name, col_num, col_type: ':' + str(col_num + 1), 'named': lambda name, col_num, col_type: ':' + str(name), 'format': lambda name, col_num, col_type: '%' + _pytype_to_printf(col_type), 'pyformat': lambda name, col_num, col_type: '%(' + str(name) + ')' + _pytype_to_printf(col_type)}\n    get_sql_param = sql_param[mod_info['paramstyle']]\n    ins_str = 'INSERT INTO ' + str(table_name)\n    value_str = ' VALUES ('\n    col_str = ' ('\n    count = 0\n    for i in col_info:\n        col_str += i[0]\n        value_str += get_sql_param(i[0], count, i[1])\n        if count < len(col_info) - 1:\n            col_str += ','\n            value_str += ','\n        count += 1\n    col_str += ')'\n    value_str += ')'\n    if use_exact_column_names:\n        ins_str += col_str\n    ins_str += value_str\n    if mod_info['paramstyle'] == 'named' or mod_info['paramstyle'] == 'pyformat':\n        prepare_sf_row = lambda x: x\n    else:\n        col_names = self.column_names()\n        prepare_sf_row = lambda x: [x[i] for i in col_names]\n    for i in self:\n        try:\n            c.execute(ins_str, prepare_sf_row(i))\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n    conn.commit()\n    c.close()",
        "mutated": [
            "def to_sql(self, conn, table_name, dbapi_module=None, use_python_type_specifiers=False, use_exact_column_names=True):\n    if False:\n        i = 10\n    \"\\n        Convert an SFrame to a single table in a SQL database.\\n\\n        This function does not attempt to create the table or check if a table\\n        named `table_name` exists in the database. It simply assumes that\\n        `table_name` exists in the database and appends to it.\\n\\n        `to_sql` can be thought of as a convenience wrapper around\\n        parameterized SQL insert statements.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the 'connect' method of a DBAPI2-compliant package can be used.\\n\\n        table_name : str\\n          The name of the table to append the data in this SFrame.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        use_python_type_specifiers : bool, optional\\n          If the DBAPI2 module's parameter marker style is 'format' or\\n          'pyformat', attempt to use accurate type specifiers for each value\\n          ('s' for string, 'd' for integer, etc.). Many DBAPI2 modules simply\\n          use 's' for all types if they use these parameter markers, so this is\\n          False by default.\\n\\n        use_exact_column_names : bool, optional\\n          Specify the column names of the SFrame when inserting its contents\\n          into the DB. If the specified table does not have the exact same\\n          column names as the SFrame, inserting the data will fail. If False,\\n          the columns in the SFrame are inserted in order without care of the\\n          schema of the DB table. True by default.\\n        \"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    c = conn.cursor()\n    col_info = list(zip(self.column_names(), self.column_types()))\n    if not use_python_type_specifiers:\n        _pytype_to_printf = lambda x: 's'\n    sql_param = {'qmark': lambda name, col_num, col_type: '?', 'numeric': lambda name, col_num, col_type: ':' + str(col_num + 1), 'named': lambda name, col_num, col_type: ':' + str(name), 'format': lambda name, col_num, col_type: '%' + _pytype_to_printf(col_type), 'pyformat': lambda name, col_num, col_type: '%(' + str(name) + ')' + _pytype_to_printf(col_type)}\n    get_sql_param = sql_param[mod_info['paramstyle']]\n    ins_str = 'INSERT INTO ' + str(table_name)\n    value_str = ' VALUES ('\n    col_str = ' ('\n    count = 0\n    for i in col_info:\n        col_str += i[0]\n        value_str += get_sql_param(i[0], count, i[1])\n        if count < len(col_info) - 1:\n            col_str += ','\n            value_str += ','\n        count += 1\n    col_str += ')'\n    value_str += ')'\n    if use_exact_column_names:\n        ins_str += col_str\n    ins_str += value_str\n    if mod_info['paramstyle'] == 'named' or mod_info['paramstyle'] == 'pyformat':\n        prepare_sf_row = lambda x: x\n    else:\n        col_names = self.column_names()\n        prepare_sf_row = lambda x: [x[i] for i in col_names]\n    for i in self:\n        try:\n            c.execute(ins_str, prepare_sf_row(i))\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n    conn.commit()\n    c.close()",
            "def to_sql(self, conn, table_name, dbapi_module=None, use_python_type_specifiers=False, use_exact_column_names=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Convert an SFrame to a single table in a SQL database.\\n\\n        This function does not attempt to create the table or check if a table\\n        named `table_name` exists in the database. It simply assumes that\\n        `table_name` exists in the database and appends to it.\\n\\n        `to_sql` can be thought of as a convenience wrapper around\\n        parameterized SQL insert statements.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the 'connect' method of a DBAPI2-compliant package can be used.\\n\\n        table_name : str\\n          The name of the table to append the data in this SFrame.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        use_python_type_specifiers : bool, optional\\n          If the DBAPI2 module's parameter marker style is 'format' or\\n          'pyformat', attempt to use accurate type specifiers for each value\\n          ('s' for string, 'd' for integer, etc.). Many DBAPI2 modules simply\\n          use 's' for all types if they use these parameter markers, so this is\\n          False by default.\\n\\n        use_exact_column_names : bool, optional\\n          Specify the column names of the SFrame when inserting its contents\\n          into the DB. If the specified table does not have the exact same\\n          column names as the SFrame, inserting the data will fail. If False,\\n          the columns in the SFrame are inserted in order without care of the\\n          schema of the DB table. True by default.\\n        \"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    c = conn.cursor()\n    col_info = list(zip(self.column_names(), self.column_types()))\n    if not use_python_type_specifiers:\n        _pytype_to_printf = lambda x: 's'\n    sql_param = {'qmark': lambda name, col_num, col_type: '?', 'numeric': lambda name, col_num, col_type: ':' + str(col_num + 1), 'named': lambda name, col_num, col_type: ':' + str(name), 'format': lambda name, col_num, col_type: '%' + _pytype_to_printf(col_type), 'pyformat': lambda name, col_num, col_type: '%(' + str(name) + ')' + _pytype_to_printf(col_type)}\n    get_sql_param = sql_param[mod_info['paramstyle']]\n    ins_str = 'INSERT INTO ' + str(table_name)\n    value_str = ' VALUES ('\n    col_str = ' ('\n    count = 0\n    for i in col_info:\n        col_str += i[0]\n        value_str += get_sql_param(i[0], count, i[1])\n        if count < len(col_info) - 1:\n            col_str += ','\n            value_str += ','\n        count += 1\n    col_str += ')'\n    value_str += ')'\n    if use_exact_column_names:\n        ins_str += col_str\n    ins_str += value_str\n    if mod_info['paramstyle'] == 'named' or mod_info['paramstyle'] == 'pyformat':\n        prepare_sf_row = lambda x: x\n    else:\n        col_names = self.column_names()\n        prepare_sf_row = lambda x: [x[i] for i in col_names]\n    for i in self:\n        try:\n            c.execute(ins_str, prepare_sf_row(i))\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n    conn.commit()\n    c.close()",
            "def to_sql(self, conn, table_name, dbapi_module=None, use_python_type_specifiers=False, use_exact_column_names=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Convert an SFrame to a single table in a SQL database.\\n\\n        This function does not attempt to create the table or check if a table\\n        named `table_name` exists in the database. It simply assumes that\\n        `table_name` exists in the database and appends to it.\\n\\n        `to_sql` can be thought of as a convenience wrapper around\\n        parameterized SQL insert statements.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the 'connect' method of a DBAPI2-compliant package can be used.\\n\\n        table_name : str\\n          The name of the table to append the data in this SFrame.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        use_python_type_specifiers : bool, optional\\n          If the DBAPI2 module's parameter marker style is 'format' or\\n          'pyformat', attempt to use accurate type specifiers for each value\\n          ('s' for string, 'd' for integer, etc.). Many DBAPI2 modules simply\\n          use 's' for all types if they use these parameter markers, so this is\\n          False by default.\\n\\n        use_exact_column_names : bool, optional\\n          Specify the column names of the SFrame when inserting its contents\\n          into the DB. If the specified table does not have the exact same\\n          column names as the SFrame, inserting the data will fail. If False,\\n          the columns in the SFrame are inserted in order without care of the\\n          schema of the DB table. True by default.\\n        \"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    c = conn.cursor()\n    col_info = list(zip(self.column_names(), self.column_types()))\n    if not use_python_type_specifiers:\n        _pytype_to_printf = lambda x: 's'\n    sql_param = {'qmark': lambda name, col_num, col_type: '?', 'numeric': lambda name, col_num, col_type: ':' + str(col_num + 1), 'named': lambda name, col_num, col_type: ':' + str(name), 'format': lambda name, col_num, col_type: '%' + _pytype_to_printf(col_type), 'pyformat': lambda name, col_num, col_type: '%(' + str(name) + ')' + _pytype_to_printf(col_type)}\n    get_sql_param = sql_param[mod_info['paramstyle']]\n    ins_str = 'INSERT INTO ' + str(table_name)\n    value_str = ' VALUES ('\n    col_str = ' ('\n    count = 0\n    for i in col_info:\n        col_str += i[0]\n        value_str += get_sql_param(i[0], count, i[1])\n        if count < len(col_info) - 1:\n            col_str += ','\n            value_str += ','\n        count += 1\n    col_str += ')'\n    value_str += ')'\n    if use_exact_column_names:\n        ins_str += col_str\n    ins_str += value_str\n    if mod_info['paramstyle'] == 'named' or mod_info['paramstyle'] == 'pyformat':\n        prepare_sf_row = lambda x: x\n    else:\n        col_names = self.column_names()\n        prepare_sf_row = lambda x: [x[i] for i in col_names]\n    for i in self:\n        try:\n            c.execute(ins_str, prepare_sf_row(i))\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n    conn.commit()\n    c.close()",
            "def to_sql(self, conn, table_name, dbapi_module=None, use_python_type_specifiers=False, use_exact_column_names=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Convert an SFrame to a single table in a SQL database.\\n\\n        This function does not attempt to create the table or check if a table\\n        named `table_name` exists in the database. It simply assumes that\\n        `table_name` exists in the database and appends to it.\\n\\n        `to_sql` can be thought of as a convenience wrapper around\\n        parameterized SQL insert statements.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the 'connect' method of a DBAPI2-compliant package can be used.\\n\\n        table_name : str\\n          The name of the table to append the data in this SFrame.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        use_python_type_specifiers : bool, optional\\n          If the DBAPI2 module's parameter marker style is 'format' or\\n          'pyformat', attempt to use accurate type specifiers for each value\\n          ('s' for string, 'd' for integer, etc.). Many DBAPI2 modules simply\\n          use 's' for all types if they use these parameter markers, so this is\\n          False by default.\\n\\n        use_exact_column_names : bool, optional\\n          Specify the column names of the SFrame when inserting its contents\\n          into the DB. If the specified table does not have the exact same\\n          column names as the SFrame, inserting the data will fail. If False,\\n          the columns in the SFrame are inserted in order without care of the\\n          schema of the DB table. True by default.\\n        \"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    c = conn.cursor()\n    col_info = list(zip(self.column_names(), self.column_types()))\n    if not use_python_type_specifiers:\n        _pytype_to_printf = lambda x: 's'\n    sql_param = {'qmark': lambda name, col_num, col_type: '?', 'numeric': lambda name, col_num, col_type: ':' + str(col_num + 1), 'named': lambda name, col_num, col_type: ':' + str(name), 'format': lambda name, col_num, col_type: '%' + _pytype_to_printf(col_type), 'pyformat': lambda name, col_num, col_type: '%(' + str(name) + ')' + _pytype_to_printf(col_type)}\n    get_sql_param = sql_param[mod_info['paramstyle']]\n    ins_str = 'INSERT INTO ' + str(table_name)\n    value_str = ' VALUES ('\n    col_str = ' ('\n    count = 0\n    for i in col_info:\n        col_str += i[0]\n        value_str += get_sql_param(i[0], count, i[1])\n        if count < len(col_info) - 1:\n            col_str += ','\n            value_str += ','\n        count += 1\n    col_str += ')'\n    value_str += ')'\n    if use_exact_column_names:\n        ins_str += col_str\n    ins_str += value_str\n    if mod_info['paramstyle'] == 'named' or mod_info['paramstyle'] == 'pyformat':\n        prepare_sf_row = lambda x: x\n    else:\n        col_names = self.column_names()\n        prepare_sf_row = lambda x: [x[i] for i in col_names]\n    for i in self:\n        try:\n            c.execute(ins_str, prepare_sf_row(i))\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n    conn.commit()\n    c.close()",
            "def to_sql(self, conn, table_name, dbapi_module=None, use_python_type_specifiers=False, use_exact_column_names=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Convert an SFrame to a single table in a SQL database.\\n\\n        This function does not attempt to create the table or check if a table\\n        named `table_name` exists in the database. It simply assumes that\\n        `table_name` exists in the database and appends to it.\\n\\n        `to_sql` can be thought of as a convenience wrapper around\\n        parameterized SQL insert statements.\\n\\n        Parameters\\n        ----------\\n        conn : dbapi2.Connection\\n          A DBAPI2 connection object. Any connection object originating from\\n          the 'connect' method of a DBAPI2-compliant package can be used.\\n\\n        table_name : str\\n          The name of the table to append the data in this SFrame.\\n\\n        dbapi_module : module | package, optional\\n          The top-level DBAPI2 module/package that constructed the given\\n          connection object. By default, a best guess of which module the\\n          connection came from is made. In the event that this guess is wrong,\\n          this will need to be specified.\\n\\n        use_python_type_specifiers : bool, optional\\n          If the DBAPI2 module's parameter marker style is 'format' or\\n          'pyformat', attempt to use accurate type specifiers for each value\\n          ('s' for string, 'd' for integer, etc.). Many DBAPI2 modules simply\\n          use 's' for all types if they use these parameter markers, so this is\\n          False by default.\\n\\n        use_exact_column_names : bool, optional\\n          Specify the column names of the SFrame when inserting its contents\\n          into the DB. If the specified table does not have the exact same\\n          column names as the SFrame, inserting the data will fail. If False,\\n          the columns in the SFrame are inserted in order without care of the\\n          schema of the DB table. True by default.\\n        \"\n    mod_info = _get_global_dbapi_info(dbapi_module, conn)\n    c = conn.cursor()\n    col_info = list(zip(self.column_names(), self.column_types()))\n    if not use_python_type_specifiers:\n        _pytype_to_printf = lambda x: 's'\n    sql_param = {'qmark': lambda name, col_num, col_type: '?', 'numeric': lambda name, col_num, col_type: ':' + str(col_num + 1), 'named': lambda name, col_num, col_type: ':' + str(name), 'format': lambda name, col_num, col_type: '%' + _pytype_to_printf(col_type), 'pyformat': lambda name, col_num, col_type: '%(' + str(name) + ')' + _pytype_to_printf(col_type)}\n    get_sql_param = sql_param[mod_info['paramstyle']]\n    ins_str = 'INSERT INTO ' + str(table_name)\n    value_str = ' VALUES ('\n    col_str = ' ('\n    count = 0\n    for i in col_info:\n        col_str += i[0]\n        value_str += get_sql_param(i[0], count, i[1])\n        if count < len(col_info) - 1:\n            col_str += ','\n            value_str += ','\n        count += 1\n    col_str += ')'\n    value_str += ')'\n    if use_exact_column_names:\n        ins_str += col_str\n    ins_str += value_str\n    if mod_info['paramstyle'] == 'named' or mod_info['paramstyle'] == 'pyformat':\n        prepare_sf_row = lambda x: x\n    else:\n        col_names = self.column_names()\n        prepare_sf_row = lambda x: [x[i] for i in col_names]\n    for i in self:\n        try:\n            c.execute(ins_str, prepare_sf_row(i))\n        except mod_info['Error'] as e:\n            if hasattr(conn, 'rollback'):\n                conn.rollback()\n            raise e\n    conn.commit()\n    c.close()"
        ]
    },
    {
        "func_name": "__hash__",
        "original": "def __hash__(self):\n    \"\"\"\n        Because we override `__eq__` we need to implement this function in Python 3.\n        Just make it match default behavior in Python 2.\n        \"\"\"\n    return id(self) // 16",
        "mutated": [
            "def __hash__(self):\n    if False:\n        i = 10\n    '\\n        Because we override `__eq__` we need to implement this function in Python 3.\\n        Just make it match default behavior in Python 2.\\n        '\n    return id(self) // 16",
            "def __hash__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Because we override `__eq__` we need to implement this function in Python 3.\\n        Just make it match default behavior in Python 2.\\n        '\n    return id(self) // 16",
            "def __hash__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Because we override `__eq__` we need to implement this function in Python 3.\\n        Just make it match default behavior in Python 2.\\n        '\n    return id(self) // 16",
            "def __hash__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Because we override `__eq__` we need to implement this function in Python 3.\\n        Just make it match default behavior in Python 2.\\n        '\n    return id(self) // 16",
            "def __hash__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Because we override `__eq__` we need to implement this function in Python 3.\\n        Just make it match default behavior in Python 2.\\n        '\n    return id(self) // 16"
        ]
    },
    {
        "func_name": "__add__",
        "original": "def __add__(self, other):\n    \"\"\"\n        Return append one frames to other\n        \"\"\"\n    self = self.append(other)\n    return self",
        "mutated": [
            "def __add__(self, other):\n    if False:\n        i = 10\n    '\\n        Return append one frames to other\\n        '\n    self = self.append(other)\n    return self",
            "def __add__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return append one frames to other\\n        '\n    self = self.append(other)\n    return self",
            "def __add__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return append one frames to other\\n        '\n    self = self.append(other)\n    return self",
            "def __add__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return append one frames to other\\n        '\n    self = self.append(other)\n    return self",
            "def __add__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return append one frames to other\\n        '\n    self = self.append(other)\n    return self"
        ]
    },
    {
        "func_name": "__repr__",
        "original": "def __repr__(self):\n    \"\"\"\n        Returns a string description of the frame\n        \"\"\"\n    ret = self.__get_column_description__()\n    (is_empty, data_str) = self.__str_impl__()\n    if is_empty:\n        data_str = '\\t[]'\n    if self.__has_size__():\n        ret = ret + 'Rows: ' + str(len(self)) + '\\n\\n'\n    else:\n        ret = ret + 'Rows: Unknown' + '\\n\\n'\n    ret = ret + 'Data:\\n'\n    ret = ret + data_str\n    return ret",
        "mutated": [
            "def __repr__(self):\n    if False:\n        i = 10\n    '\\n        Returns a string description of the frame\\n        '\n    ret = self.__get_column_description__()\n    (is_empty, data_str) = self.__str_impl__()\n    if is_empty:\n        data_str = '\\t[]'\n    if self.__has_size__():\n        ret = ret + 'Rows: ' + str(len(self)) + '\\n\\n'\n    else:\n        ret = ret + 'Rows: Unknown' + '\\n\\n'\n    ret = ret + 'Data:\\n'\n    ret = ret + data_str\n    return ret",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a string description of the frame\\n        '\n    ret = self.__get_column_description__()\n    (is_empty, data_str) = self.__str_impl__()\n    if is_empty:\n        data_str = '\\t[]'\n    if self.__has_size__():\n        ret = ret + 'Rows: ' + str(len(self)) + '\\n\\n'\n    else:\n        ret = ret + 'Rows: Unknown' + '\\n\\n'\n    ret = ret + 'Data:\\n'\n    ret = ret + data_str\n    return ret",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a string description of the frame\\n        '\n    ret = self.__get_column_description__()\n    (is_empty, data_str) = self.__str_impl__()\n    if is_empty:\n        data_str = '\\t[]'\n    if self.__has_size__():\n        ret = ret + 'Rows: ' + str(len(self)) + '\\n\\n'\n    else:\n        ret = ret + 'Rows: Unknown' + '\\n\\n'\n    ret = ret + 'Data:\\n'\n    ret = ret + data_str\n    return ret",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a string description of the frame\\n        '\n    ret = self.__get_column_description__()\n    (is_empty, data_str) = self.__str_impl__()\n    if is_empty:\n        data_str = '\\t[]'\n    if self.__has_size__():\n        ret = ret + 'Rows: ' + str(len(self)) + '\\n\\n'\n    else:\n        ret = ret + 'Rows: Unknown' + '\\n\\n'\n    ret = ret + 'Data:\\n'\n    ret = ret + data_str\n    return ret",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a string description of the frame\\n        '\n    ret = self.__get_column_description__()\n    (is_empty, data_str) = self.__str_impl__()\n    if is_empty:\n        data_str = '\\t[]'\n    if self.__has_size__():\n        ret = ret + 'Rows: ' + str(len(self)) + '\\n\\n'\n    else:\n        ret = ret + 'Rows: Unknown' + '\\n\\n'\n    ret = ret + 'Data:\\n'\n    ret = ret + data_str\n    return ret"
        ]
    },
    {
        "func_name": "__get_column_description__",
        "original": "def __get_column_description__(self):\n    colnames = self.column_names()\n    coltypes = self.column_types()\n    ret = 'Columns:\\n'\n    if len(colnames) > 0:\n        for i in range(len(colnames)):\n            ret = ret + '\\t' + colnames[i] + '\\t' + coltypes[i].__name__ + '\\n'\n        ret = ret + '\\n'\n    else:\n        ret = ret + '\\tNone\\n\\n'\n    return ret",
        "mutated": [
            "def __get_column_description__(self):\n    if False:\n        i = 10\n    colnames = self.column_names()\n    coltypes = self.column_types()\n    ret = 'Columns:\\n'\n    if len(colnames) > 0:\n        for i in range(len(colnames)):\n            ret = ret + '\\t' + colnames[i] + '\\t' + coltypes[i].__name__ + '\\n'\n        ret = ret + '\\n'\n    else:\n        ret = ret + '\\tNone\\n\\n'\n    return ret",
            "def __get_column_description__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    colnames = self.column_names()\n    coltypes = self.column_types()\n    ret = 'Columns:\\n'\n    if len(colnames) > 0:\n        for i in range(len(colnames)):\n            ret = ret + '\\t' + colnames[i] + '\\t' + coltypes[i].__name__ + '\\n'\n        ret = ret + '\\n'\n    else:\n        ret = ret + '\\tNone\\n\\n'\n    return ret",
            "def __get_column_description__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    colnames = self.column_names()\n    coltypes = self.column_types()\n    ret = 'Columns:\\n'\n    if len(colnames) > 0:\n        for i in range(len(colnames)):\n            ret = ret + '\\t' + colnames[i] + '\\t' + coltypes[i].__name__ + '\\n'\n        ret = ret + '\\n'\n    else:\n        ret = ret + '\\tNone\\n\\n'\n    return ret",
            "def __get_column_description__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    colnames = self.column_names()\n    coltypes = self.column_types()\n    ret = 'Columns:\\n'\n    if len(colnames) > 0:\n        for i in range(len(colnames)):\n            ret = ret + '\\t' + colnames[i] + '\\t' + coltypes[i].__name__ + '\\n'\n        ret = ret + '\\n'\n    else:\n        ret = ret + '\\tNone\\n\\n'\n    return ret",
            "def __get_column_description__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    colnames = self.column_names()\n    coltypes = self.column_types()\n    ret = 'Columns:\\n'\n    if len(colnames) > 0:\n        for i in range(len(colnames)):\n            ret = ret + '\\t' + colnames[i] + '\\t' + coltypes[i].__name__ + '\\n'\n        ret = ret + '\\n'\n    else:\n        ret = ret + '\\tNone\\n\\n'\n    return ret"
        ]
    },
    {
        "func_name": "_value_to_str",
        "original": "def _value_to_str(value):\n    if type(value) is array.array:\n        return str(list(value))\n    elif type(value) is numpy.ndarray:\n        return str(value).replace('\\n', ' ')\n    elif type(value) is list:\n        return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n    else:\n        return str(value)",
        "mutated": [
            "def _value_to_str(value):\n    if False:\n        i = 10\n    if type(value) is array.array:\n        return str(list(value))\n    elif type(value) is numpy.ndarray:\n        return str(value).replace('\\n', ' ')\n    elif type(value) is list:\n        return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n    else:\n        return str(value)",
            "def _value_to_str(value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if type(value) is array.array:\n        return str(list(value))\n    elif type(value) is numpy.ndarray:\n        return str(value).replace('\\n', ' ')\n    elif type(value) is list:\n        return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n    else:\n        return str(value)",
            "def _value_to_str(value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if type(value) is array.array:\n        return str(list(value))\n    elif type(value) is numpy.ndarray:\n        return str(value).replace('\\n', ' ')\n    elif type(value) is list:\n        return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n    else:\n        return str(value)",
            "def _value_to_str(value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if type(value) is array.array:\n        return str(list(value))\n    elif type(value) is numpy.ndarray:\n        return str(value).replace('\\n', ' ')\n    elif type(value) is list:\n        return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n    else:\n        return str(value)",
            "def _value_to_str(value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if type(value) is array.array:\n        return str(list(value))\n    elif type(value) is numpy.ndarray:\n        return str(value).replace('\\n', ' ')\n    elif type(value) is list:\n        return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n    else:\n        return str(value)"
        ]
    },
    {
        "func_name": "_escape_space",
        "original": "def _escape_space(s):\n    if sys.version_info.major == 3:\n        return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n    return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])",
        "mutated": [
            "def _escape_space(s):\n    if False:\n        i = 10\n    if sys.version_info.major == 3:\n        return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n    return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])",
            "def _escape_space(s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if sys.version_info.major == 3:\n        return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n    return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])",
            "def _escape_space(s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if sys.version_info.major == 3:\n        return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n    return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])",
            "def _escape_space(s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if sys.version_info.major == 3:\n        return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n    return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])",
            "def _escape_space(s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if sys.version_info.major == 3:\n        return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n    return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])"
        ]
    },
    {
        "func_name": "_truncate_respect_unicode",
        "original": "def _truncate_respect_unicode(s, max_length):\n    if len(s) <= max_length:\n        return s\n    elif sys.version_info.major < 3:\n        u = unicode(s, 'utf-8', errors='replace')\n        return u[:max_length].encode('utf-8')\n    else:\n        return s[:max_length]",
        "mutated": [
            "def _truncate_respect_unicode(s, max_length):\n    if False:\n        i = 10\n    if len(s) <= max_length:\n        return s\n    elif sys.version_info.major < 3:\n        u = unicode(s, 'utf-8', errors='replace')\n        return u[:max_length].encode('utf-8')\n    else:\n        return s[:max_length]",
            "def _truncate_respect_unicode(s, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(s) <= max_length:\n        return s\n    elif sys.version_info.major < 3:\n        u = unicode(s, 'utf-8', errors='replace')\n        return u[:max_length].encode('utf-8')\n    else:\n        return s[:max_length]",
            "def _truncate_respect_unicode(s, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(s) <= max_length:\n        return s\n    elif sys.version_info.major < 3:\n        u = unicode(s, 'utf-8', errors='replace')\n        return u[:max_length].encode('utf-8')\n    else:\n        return s[:max_length]",
            "def _truncate_respect_unicode(s, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(s) <= max_length:\n        return s\n    elif sys.version_info.major < 3:\n        u = unicode(s, 'utf-8', errors='replace')\n        return u[:max_length].encode('utf-8')\n    else:\n        return s[:max_length]",
            "def _truncate_respect_unicode(s, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(s) <= max_length:\n        return s\n    elif sys.version_info.major < 3:\n        u = unicode(s, 'utf-8', errors='replace')\n        return u[:max_length].encode('utf-8')\n    else:\n        return s[:max_length]"
        ]
    },
    {
        "func_name": "_truncate_str",
        "original": "def _truncate_str(s, wrap_str=False):\n    \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n    s = _escape_space(s)\n    if len(s) <= max_column_width:\n        if sys.version_info.major < 3:\n            return unicode(s, 'utf-8', errors='replace')\n        else:\n            return s\n    else:\n        ret = ''\n        if wrap_str:\n            wrapped_lines = wrap(s, max_column_width)\n            if len(wrapped_lines) == 1:\n                return wrapped_lines[0]\n            last_line = wrapped_lines[1]\n            if len(last_line) >= max_column_width:\n                last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n            ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n        else:\n            ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n        if sys.version_info.major < 3:\n            return unicode(ret, 'utf-8', errors='replace')\n        else:\n            return ret",
        "mutated": [
            "def _truncate_str(s, wrap_str=False):\n    if False:\n        i = 10\n    '\\n            Truncate and optionally wrap the input string as unicode, replace\\n            unconvertible character with a diamond ?.\\n            '\n    s = _escape_space(s)\n    if len(s) <= max_column_width:\n        if sys.version_info.major < 3:\n            return unicode(s, 'utf-8', errors='replace')\n        else:\n            return s\n    else:\n        ret = ''\n        if wrap_str:\n            wrapped_lines = wrap(s, max_column_width)\n            if len(wrapped_lines) == 1:\n                return wrapped_lines[0]\n            last_line = wrapped_lines[1]\n            if len(last_line) >= max_column_width:\n                last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n            ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n        else:\n            ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n        if sys.version_info.major < 3:\n            return unicode(ret, 'utf-8', errors='replace')\n        else:\n            return ret",
            "def _truncate_str(s, wrap_str=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n            Truncate and optionally wrap the input string as unicode, replace\\n            unconvertible character with a diamond ?.\\n            '\n    s = _escape_space(s)\n    if len(s) <= max_column_width:\n        if sys.version_info.major < 3:\n            return unicode(s, 'utf-8', errors='replace')\n        else:\n            return s\n    else:\n        ret = ''\n        if wrap_str:\n            wrapped_lines = wrap(s, max_column_width)\n            if len(wrapped_lines) == 1:\n                return wrapped_lines[0]\n            last_line = wrapped_lines[1]\n            if len(last_line) >= max_column_width:\n                last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n            ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n        else:\n            ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n        if sys.version_info.major < 3:\n            return unicode(ret, 'utf-8', errors='replace')\n        else:\n            return ret",
            "def _truncate_str(s, wrap_str=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n            Truncate and optionally wrap the input string as unicode, replace\\n            unconvertible character with a diamond ?.\\n            '\n    s = _escape_space(s)\n    if len(s) <= max_column_width:\n        if sys.version_info.major < 3:\n            return unicode(s, 'utf-8', errors='replace')\n        else:\n            return s\n    else:\n        ret = ''\n        if wrap_str:\n            wrapped_lines = wrap(s, max_column_width)\n            if len(wrapped_lines) == 1:\n                return wrapped_lines[0]\n            last_line = wrapped_lines[1]\n            if len(last_line) >= max_column_width:\n                last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n            ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n        else:\n            ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n        if sys.version_info.major < 3:\n            return unicode(ret, 'utf-8', errors='replace')\n        else:\n            return ret",
            "def _truncate_str(s, wrap_str=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n            Truncate and optionally wrap the input string as unicode, replace\\n            unconvertible character with a diamond ?.\\n            '\n    s = _escape_space(s)\n    if len(s) <= max_column_width:\n        if sys.version_info.major < 3:\n            return unicode(s, 'utf-8', errors='replace')\n        else:\n            return s\n    else:\n        ret = ''\n        if wrap_str:\n            wrapped_lines = wrap(s, max_column_width)\n            if len(wrapped_lines) == 1:\n                return wrapped_lines[0]\n            last_line = wrapped_lines[1]\n            if len(last_line) >= max_column_width:\n                last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n            ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n        else:\n            ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n        if sys.version_info.major < 3:\n            return unicode(ret, 'utf-8', errors='replace')\n        else:\n            return ret",
            "def _truncate_str(s, wrap_str=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n            Truncate and optionally wrap the input string as unicode, replace\\n            unconvertible character with a diamond ?.\\n            '\n    s = _escape_space(s)\n    if len(s) <= max_column_width:\n        if sys.version_info.major < 3:\n            return unicode(s, 'utf-8', errors='replace')\n        else:\n            return s\n    else:\n        ret = ''\n        if wrap_str:\n            wrapped_lines = wrap(s, max_column_width)\n            if len(wrapped_lines) == 1:\n                return wrapped_lines[0]\n            last_line = wrapped_lines[1]\n            if len(last_line) >= max_column_width:\n                last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n            ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n        else:\n            ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n        if sys.version_info.major < 3:\n            return unicode(ret, 'utf-8', errors='replace')\n        else:\n            return ret"
        ]
    },
    {
        "func_name": "__get_pretty_tables__",
        "original": "def __get_pretty_tables__(self, wrap_text=False, max_row_width=80, max_column_width=30, max_columns=20, max_rows_to_display=60):\n    \"\"\"\n        Returns a list of pretty print tables representing the current SFrame.\n        If the number of columns is larger than max_columns, the last pretty\n        table will contain an extra column of \"...\".\n        Parameters\n        ----------\n        wrap_text : bool, optional\n        max_row_width : int, optional\n            Max number of characters per table.\n        max_column_width : int, optional\n            Max number of characters per column.\n        max_columns : int, optional\n            Max number of columns per table.\n        max_rows_to_display : int, optional\n            Max number of rows to display.\n        Returns\n        -------\n        out : list[PrettyTable]\n        \"\"\"\n    if len(self) <= max_rows_to_display:\n        headsf = self.__copy__()\n    else:\n        headsf = self.head(max_rows_to_display)\n    if headsf.shape == (0, 0):\n        return [PrettyTable()]\n    for col in headsf.column_names():\n        if headsf[col].dtype is array.array:\n            headsf[col] = headsf[col].astype(list)\n\n    def _value_to_str(value):\n        if type(value) is array.array:\n            return str(list(value))\n        elif type(value) is numpy.ndarray:\n            return str(value).replace('\\n', ' ')\n        elif type(value) is list:\n            return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n        else:\n            return str(value)\n\n    def _escape_space(s):\n        if sys.version_info.major == 3:\n            return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n        return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])\n\n    def _truncate_respect_unicode(s, max_length):\n        if len(s) <= max_length:\n            return s\n        elif sys.version_info.major < 3:\n            u = unicode(s, 'utf-8', errors='replace')\n            return u[:max_length].encode('utf-8')\n        else:\n            return s[:max_length]\n\n    def _truncate_str(s, wrap_str=False):\n        \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n        s = _escape_space(s)\n        if len(s) <= max_column_width:\n            if sys.version_info.major < 3:\n                return unicode(s, 'utf-8', errors='replace')\n            else:\n                return s\n        else:\n            ret = ''\n            if wrap_str:\n                wrapped_lines = wrap(s, max_column_width)\n                if len(wrapped_lines) == 1:\n                    return wrapped_lines[0]\n                last_line = wrapped_lines[1]\n                if len(last_line) >= max_column_width:\n                    last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n                ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n            else:\n                ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n            if sys.version_info.major < 3:\n                return unicode(ret, 'utf-8', errors='replace')\n            else:\n                return ret\n    columns = self.column_names()[:max_columns]\n    columns.reverse()\n    num_column_of_last_table = 0\n    row_of_tables = []\n    while len(columns) > 0:\n        tbl = PrettyTable()\n        table_width = 0\n        num_column_of_last_table = 0\n        while len(columns) > 0:\n            col = columns.pop()\n            if len(headsf) > 0:\n                col_width = min(max_column_width, max((len(str(x)) for x in headsf[col])))\n            else:\n                col_width = max_column_width\n            if table_width + col_width < max_row_width:\n                header = _truncate_str(col, wrap_text)\n                tbl.add_column(header, [_truncate_str(_value_to_str(x), wrap_text) for x in headsf[col]])\n                table_width = str(tbl).find('\\n')\n                num_column_of_last_table += 1\n            else:\n                columns.append(col)\n                break\n        tbl.align = 'c'\n        row_of_tables.append(tbl)\n    if self.num_columns() > max_columns:\n        row_of_tables[-1].add_column('...', ['...'] * len(headsf))\n        num_column_of_last_table += 1\n    if self.__has_size__() and self.num_rows() > headsf.num_rows():\n        row_of_tables[-1].add_row(['...'] * num_column_of_last_table)\n    return row_of_tables",
        "mutated": [
            "def __get_pretty_tables__(self, wrap_text=False, max_row_width=80, max_column_width=30, max_columns=20, max_rows_to_display=60):\n    if False:\n        i = 10\n    '\\n        Returns a list of pretty print tables representing the current SFrame.\\n        If the number of columns is larger than max_columns, the last pretty\\n        table will contain an extra column of \"...\".\\n        Parameters\\n        ----------\\n        wrap_text : bool, optional\\n        max_row_width : int, optional\\n            Max number of characters per table.\\n        max_column_width : int, optional\\n            Max number of characters per column.\\n        max_columns : int, optional\\n            Max number of columns per table.\\n        max_rows_to_display : int, optional\\n            Max number of rows to display.\\n        Returns\\n        -------\\n        out : list[PrettyTable]\\n        '\n    if len(self) <= max_rows_to_display:\n        headsf = self.__copy__()\n    else:\n        headsf = self.head(max_rows_to_display)\n    if headsf.shape == (0, 0):\n        return [PrettyTable()]\n    for col in headsf.column_names():\n        if headsf[col].dtype is array.array:\n            headsf[col] = headsf[col].astype(list)\n\n    def _value_to_str(value):\n        if type(value) is array.array:\n            return str(list(value))\n        elif type(value) is numpy.ndarray:\n            return str(value).replace('\\n', ' ')\n        elif type(value) is list:\n            return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n        else:\n            return str(value)\n\n    def _escape_space(s):\n        if sys.version_info.major == 3:\n            return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n        return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])\n\n    def _truncate_respect_unicode(s, max_length):\n        if len(s) <= max_length:\n            return s\n        elif sys.version_info.major < 3:\n            u = unicode(s, 'utf-8', errors='replace')\n            return u[:max_length].encode('utf-8')\n        else:\n            return s[:max_length]\n\n    def _truncate_str(s, wrap_str=False):\n        \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n        s = _escape_space(s)\n        if len(s) <= max_column_width:\n            if sys.version_info.major < 3:\n                return unicode(s, 'utf-8', errors='replace')\n            else:\n                return s\n        else:\n            ret = ''\n            if wrap_str:\n                wrapped_lines = wrap(s, max_column_width)\n                if len(wrapped_lines) == 1:\n                    return wrapped_lines[0]\n                last_line = wrapped_lines[1]\n                if len(last_line) >= max_column_width:\n                    last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n                ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n            else:\n                ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n            if sys.version_info.major < 3:\n                return unicode(ret, 'utf-8', errors='replace')\n            else:\n                return ret\n    columns = self.column_names()[:max_columns]\n    columns.reverse()\n    num_column_of_last_table = 0\n    row_of_tables = []\n    while len(columns) > 0:\n        tbl = PrettyTable()\n        table_width = 0\n        num_column_of_last_table = 0\n        while len(columns) > 0:\n            col = columns.pop()\n            if len(headsf) > 0:\n                col_width = min(max_column_width, max((len(str(x)) for x in headsf[col])))\n            else:\n                col_width = max_column_width\n            if table_width + col_width < max_row_width:\n                header = _truncate_str(col, wrap_text)\n                tbl.add_column(header, [_truncate_str(_value_to_str(x), wrap_text) for x in headsf[col]])\n                table_width = str(tbl).find('\\n')\n                num_column_of_last_table += 1\n            else:\n                columns.append(col)\n                break\n        tbl.align = 'c'\n        row_of_tables.append(tbl)\n    if self.num_columns() > max_columns:\n        row_of_tables[-1].add_column('...', ['...'] * len(headsf))\n        num_column_of_last_table += 1\n    if self.__has_size__() and self.num_rows() > headsf.num_rows():\n        row_of_tables[-1].add_row(['...'] * num_column_of_last_table)\n    return row_of_tables",
            "def __get_pretty_tables__(self, wrap_text=False, max_row_width=80, max_column_width=30, max_columns=20, max_rows_to_display=60):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a list of pretty print tables representing the current SFrame.\\n        If the number of columns is larger than max_columns, the last pretty\\n        table will contain an extra column of \"...\".\\n        Parameters\\n        ----------\\n        wrap_text : bool, optional\\n        max_row_width : int, optional\\n            Max number of characters per table.\\n        max_column_width : int, optional\\n            Max number of characters per column.\\n        max_columns : int, optional\\n            Max number of columns per table.\\n        max_rows_to_display : int, optional\\n            Max number of rows to display.\\n        Returns\\n        -------\\n        out : list[PrettyTable]\\n        '\n    if len(self) <= max_rows_to_display:\n        headsf = self.__copy__()\n    else:\n        headsf = self.head(max_rows_to_display)\n    if headsf.shape == (0, 0):\n        return [PrettyTable()]\n    for col in headsf.column_names():\n        if headsf[col].dtype is array.array:\n            headsf[col] = headsf[col].astype(list)\n\n    def _value_to_str(value):\n        if type(value) is array.array:\n            return str(list(value))\n        elif type(value) is numpy.ndarray:\n            return str(value).replace('\\n', ' ')\n        elif type(value) is list:\n            return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n        else:\n            return str(value)\n\n    def _escape_space(s):\n        if sys.version_info.major == 3:\n            return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n        return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])\n\n    def _truncate_respect_unicode(s, max_length):\n        if len(s) <= max_length:\n            return s\n        elif sys.version_info.major < 3:\n            u = unicode(s, 'utf-8', errors='replace')\n            return u[:max_length].encode('utf-8')\n        else:\n            return s[:max_length]\n\n    def _truncate_str(s, wrap_str=False):\n        \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n        s = _escape_space(s)\n        if len(s) <= max_column_width:\n            if sys.version_info.major < 3:\n                return unicode(s, 'utf-8', errors='replace')\n            else:\n                return s\n        else:\n            ret = ''\n            if wrap_str:\n                wrapped_lines = wrap(s, max_column_width)\n                if len(wrapped_lines) == 1:\n                    return wrapped_lines[0]\n                last_line = wrapped_lines[1]\n                if len(last_line) >= max_column_width:\n                    last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n                ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n            else:\n                ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n            if sys.version_info.major < 3:\n                return unicode(ret, 'utf-8', errors='replace')\n            else:\n                return ret\n    columns = self.column_names()[:max_columns]\n    columns.reverse()\n    num_column_of_last_table = 0\n    row_of_tables = []\n    while len(columns) > 0:\n        tbl = PrettyTable()\n        table_width = 0\n        num_column_of_last_table = 0\n        while len(columns) > 0:\n            col = columns.pop()\n            if len(headsf) > 0:\n                col_width = min(max_column_width, max((len(str(x)) for x in headsf[col])))\n            else:\n                col_width = max_column_width\n            if table_width + col_width < max_row_width:\n                header = _truncate_str(col, wrap_text)\n                tbl.add_column(header, [_truncate_str(_value_to_str(x), wrap_text) for x in headsf[col]])\n                table_width = str(tbl).find('\\n')\n                num_column_of_last_table += 1\n            else:\n                columns.append(col)\n                break\n        tbl.align = 'c'\n        row_of_tables.append(tbl)\n    if self.num_columns() > max_columns:\n        row_of_tables[-1].add_column('...', ['...'] * len(headsf))\n        num_column_of_last_table += 1\n    if self.__has_size__() and self.num_rows() > headsf.num_rows():\n        row_of_tables[-1].add_row(['...'] * num_column_of_last_table)\n    return row_of_tables",
            "def __get_pretty_tables__(self, wrap_text=False, max_row_width=80, max_column_width=30, max_columns=20, max_rows_to_display=60):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a list of pretty print tables representing the current SFrame.\\n        If the number of columns is larger than max_columns, the last pretty\\n        table will contain an extra column of \"...\".\\n        Parameters\\n        ----------\\n        wrap_text : bool, optional\\n        max_row_width : int, optional\\n            Max number of characters per table.\\n        max_column_width : int, optional\\n            Max number of characters per column.\\n        max_columns : int, optional\\n            Max number of columns per table.\\n        max_rows_to_display : int, optional\\n            Max number of rows to display.\\n        Returns\\n        -------\\n        out : list[PrettyTable]\\n        '\n    if len(self) <= max_rows_to_display:\n        headsf = self.__copy__()\n    else:\n        headsf = self.head(max_rows_to_display)\n    if headsf.shape == (0, 0):\n        return [PrettyTable()]\n    for col in headsf.column_names():\n        if headsf[col].dtype is array.array:\n            headsf[col] = headsf[col].astype(list)\n\n    def _value_to_str(value):\n        if type(value) is array.array:\n            return str(list(value))\n        elif type(value) is numpy.ndarray:\n            return str(value).replace('\\n', ' ')\n        elif type(value) is list:\n            return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n        else:\n            return str(value)\n\n    def _escape_space(s):\n        if sys.version_info.major == 3:\n            return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n        return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])\n\n    def _truncate_respect_unicode(s, max_length):\n        if len(s) <= max_length:\n            return s\n        elif sys.version_info.major < 3:\n            u = unicode(s, 'utf-8', errors='replace')\n            return u[:max_length].encode('utf-8')\n        else:\n            return s[:max_length]\n\n    def _truncate_str(s, wrap_str=False):\n        \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n        s = _escape_space(s)\n        if len(s) <= max_column_width:\n            if sys.version_info.major < 3:\n                return unicode(s, 'utf-8', errors='replace')\n            else:\n                return s\n        else:\n            ret = ''\n            if wrap_str:\n                wrapped_lines = wrap(s, max_column_width)\n                if len(wrapped_lines) == 1:\n                    return wrapped_lines[0]\n                last_line = wrapped_lines[1]\n                if len(last_line) >= max_column_width:\n                    last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n                ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n            else:\n                ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n            if sys.version_info.major < 3:\n                return unicode(ret, 'utf-8', errors='replace')\n            else:\n                return ret\n    columns = self.column_names()[:max_columns]\n    columns.reverse()\n    num_column_of_last_table = 0\n    row_of_tables = []\n    while len(columns) > 0:\n        tbl = PrettyTable()\n        table_width = 0\n        num_column_of_last_table = 0\n        while len(columns) > 0:\n            col = columns.pop()\n            if len(headsf) > 0:\n                col_width = min(max_column_width, max((len(str(x)) for x in headsf[col])))\n            else:\n                col_width = max_column_width\n            if table_width + col_width < max_row_width:\n                header = _truncate_str(col, wrap_text)\n                tbl.add_column(header, [_truncate_str(_value_to_str(x), wrap_text) for x in headsf[col]])\n                table_width = str(tbl).find('\\n')\n                num_column_of_last_table += 1\n            else:\n                columns.append(col)\n                break\n        tbl.align = 'c'\n        row_of_tables.append(tbl)\n    if self.num_columns() > max_columns:\n        row_of_tables[-1].add_column('...', ['...'] * len(headsf))\n        num_column_of_last_table += 1\n    if self.__has_size__() and self.num_rows() > headsf.num_rows():\n        row_of_tables[-1].add_row(['...'] * num_column_of_last_table)\n    return row_of_tables",
            "def __get_pretty_tables__(self, wrap_text=False, max_row_width=80, max_column_width=30, max_columns=20, max_rows_to_display=60):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a list of pretty print tables representing the current SFrame.\\n        If the number of columns is larger than max_columns, the last pretty\\n        table will contain an extra column of \"...\".\\n        Parameters\\n        ----------\\n        wrap_text : bool, optional\\n        max_row_width : int, optional\\n            Max number of characters per table.\\n        max_column_width : int, optional\\n            Max number of characters per column.\\n        max_columns : int, optional\\n            Max number of columns per table.\\n        max_rows_to_display : int, optional\\n            Max number of rows to display.\\n        Returns\\n        -------\\n        out : list[PrettyTable]\\n        '\n    if len(self) <= max_rows_to_display:\n        headsf = self.__copy__()\n    else:\n        headsf = self.head(max_rows_to_display)\n    if headsf.shape == (0, 0):\n        return [PrettyTable()]\n    for col in headsf.column_names():\n        if headsf[col].dtype is array.array:\n            headsf[col] = headsf[col].astype(list)\n\n    def _value_to_str(value):\n        if type(value) is array.array:\n            return str(list(value))\n        elif type(value) is numpy.ndarray:\n            return str(value).replace('\\n', ' ')\n        elif type(value) is list:\n            return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n        else:\n            return str(value)\n\n    def _escape_space(s):\n        if sys.version_info.major == 3:\n            return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n        return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])\n\n    def _truncate_respect_unicode(s, max_length):\n        if len(s) <= max_length:\n            return s\n        elif sys.version_info.major < 3:\n            u = unicode(s, 'utf-8', errors='replace')\n            return u[:max_length].encode('utf-8')\n        else:\n            return s[:max_length]\n\n    def _truncate_str(s, wrap_str=False):\n        \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n        s = _escape_space(s)\n        if len(s) <= max_column_width:\n            if sys.version_info.major < 3:\n                return unicode(s, 'utf-8', errors='replace')\n            else:\n                return s\n        else:\n            ret = ''\n            if wrap_str:\n                wrapped_lines = wrap(s, max_column_width)\n                if len(wrapped_lines) == 1:\n                    return wrapped_lines[0]\n                last_line = wrapped_lines[1]\n                if len(last_line) >= max_column_width:\n                    last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n                ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n            else:\n                ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n            if sys.version_info.major < 3:\n                return unicode(ret, 'utf-8', errors='replace')\n            else:\n                return ret\n    columns = self.column_names()[:max_columns]\n    columns.reverse()\n    num_column_of_last_table = 0\n    row_of_tables = []\n    while len(columns) > 0:\n        tbl = PrettyTable()\n        table_width = 0\n        num_column_of_last_table = 0\n        while len(columns) > 0:\n            col = columns.pop()\n            if len(headsf) > 0:\n                col_width = min(max_column_width, max((len(str(x)) for x in headsf[col])))\n            else:\n                col_width = max_column_width\n            if table_width + col_width < max_row_width:\n                header = _truncate_str(col, wrap_text)\n                tbl.add_column(header, [_truncate_str(_value_to_str(x), wrap_text) for x in headsf[col]])\n                table_width = str(tbl).find('\\n')\n                num_column_of_last_table += 1\n            else:\n                columns.append(col)\n                break\n        tbl.align = 'c'\n        row_of_tables.append(tbl)\n    if self.num_columns() > max_columns:\n        row_of_tables[-1].add_column('...', ['...'] * len(headsf))\n        num_column_of_last_table += 1\n    if self.__has_size__() and self.num_rows() > headsf.num_rows():\n        row_of_tables[-1].add_row(['...'] * num_column_of_last_table)\n    return row_of_tables",
            "def __get_pretty_tables__(self, wrap_text=False, max_row_width=80, max_column_width=30, max_columns=20, max_rows_to_display=60):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a list of pretty print tables representing the current SFrame.\\n        If the number of columns is larger than max_columns, the last pretty\\n        table will contain an extra column of \"...\".\\n        Parameters\\n        ----------\\n        wrap_text : bool, optional\\n        max_row_width : int, optional\\n            Max number of characters per table.\\n        max_column_width : int, optional\\n            Max number of characters per column.\\n        max_columns : int, optional\\n            Max number of columns per table.\\n        max_rows_to_display : int, optional\\n            Max number of rows to display.\\n        Returns\\n        -------\\n        out : list[PrettyTable]\\n        '\n    if len(self) <= max_rows_to_display:\n        headsf = self.__copy__()\n    else:\n        headsf = self.head(max_rows_to_display)\n    if headsf.shape == (0, 0):\n        return [PrettyTable()]\n    for col in headsf.column_names():\n        if headsf[col].dtype is array.array:\n            headsf[col] = headsf[col].astype(list)\n\n    def _value_to_str(value):\n        if type(value) is array.array:\n            return str(list(value))\n        elif type(value) is numpy.ndarray:\n            return str(value).replace('\\n', ' ')\n        elif type(value) is list:\n            return '[' + ', '.join((_value_to_str(x) for x in value)) + ']'\n        else:\n            return str(value)\n\n    def _escape_space(s):\n        if sys.version_info.major == 3:\n            return ''.join([ch.encode('unicode_escape').decode() if ch.isspace() else ch for ch in s])\n        return ''.join([ch.encode('string_escape') if ch.isspace() else ch for ch in s])\n\n    def _truncate_respect_unicode(s, max_length):\n        if len(s) <= max_length:\n            return s\n        elif sys.version_info.major < 3:\n            u = unicode(s, 'utf-8', errors='replace')\n            return u[:max_length].encode('utf-8')\n        else:\n            return s[:max_length]\n\n    def _truncate_str(s, wrap_str=False):\n        \"\"\"\n            Truncate and optionally wrap the input string as unicode, replace\n            unconvertible character with a diamond ?.\n            \"\"\"\n        s = _escape_space(s)\n        if len(s) <= max_column_width:\n            if sys.version_info.major < 3:\n                return unicode(s, 'utf-8', errors='replace')\n            else:\n                return s\n        else:\n            ret = ''\n            if wrap_str:\n                wrapped_lines = wrap(s, max_column_width)\n                if len(wrapped_lines) == 1:\n                    return wrapped_lines[0]\n                last_line = wrapped_lines[1]\n                if len(last_line) >= max_column_width:\n                    last_line = _truncate_respect_unicode(last_line, max_column_width - 4)\n                ret = wrapped_lines[0] + '\\n' + last_line + ' ...'\n            else:\n                ret = _truncate_respect_unicode(s, max_column_width - 4) + '...'\n            if sys.version_info.major < 3:\n                return unicode(ret, 'utf-8', errors='replace')\n            else:\n                return ret\n    columns = self.column_names()[:max_columns]\n    columns.reverse()\n    num_column_of_last_table = 0\n    row_of_tables = []\n    while len(columns) > 0:\n        tbl = PrettyTable()\n        table_width = 0\n        num_column_of_last_table = 0\n        while len(columns) > 0:\n            col = columns.pop()\n            if len(headsf) > 0:\n                col_width = min(max_column_width, max((len(str(x)) for x in headsf[col])))\n            else:\n                col_width = max_column_width\n            if table_width + col_width < max_row_width:\n                header = _truncate_str(col, wrap_text)\n                tbl.add_column(header, [_truncate_str(_value_to_str(x), wrap_text) for x in headsf[col]])\n                table_width = str(tbl).find('\\n')\n                num_column_of_last_table += 1\n            else:\n                columns.append(col)\n                break\n        tbl.align = 'c'\n        row_of_tables.append(tbl)\n    if self.num_columns() > max_columns:\n        row_of_tables[-1].add_column('...', ['...'] * len(headsf))\n        num_column_of_last_table += 1\n    if self.__has_size__() and self.num_rows() > headsf.num_rows():\n        row_of_tables[-1].add_row(['...'] * num_column_of_last_table)\n    return row_of_tables"
        ]
    },
    {
        "func_name": "print_rows",
        "original": "def print_rows(self, num_rows=10, num_columns=40, max_column_width=30, max_row_width=80, output_file=None):\n    \"\"\"\n        Print the first M rows and N columns of the SFrame in human readable\n        format.\n\n        Parameters\n        ----------\n        num_rows : int, optional\n            Number of rows to print.\n\n        num_columns : int, optional\n            Number of columns to print.\n\n        max_column_width : int, optional\n            Maximum width of a column. Columns use fewer characters if possible.\n\n        max_row_width : int, optional\n            Maximum width of a printed row. Columns beyond this width wrap to a\n            new line. `max_row_width` is automatically reset to be the\n            larger of itself and `max_column_width`.\n\n        output_file: file, optional\n            The stream or file that receives the output. By default the output\n            goes to sys.stdout, but it can also be redirected to a file or a\n            string (using an object of type StringIO).\n\n        See Also\n        --------\n        head, tail\n        \"\"\"\n    if output_file is None:\n        output_file = sys.stdout\n    max_row_width = max(max_row_width, max_column_width + 1)\n    printed_sf = self._imagecols_to_stringcols(num_rows)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=num_rows, max_columns=num_columns, max_column_width=max_column_width, max_row_width=max_row_width)\n    footer = '[%d rows x %d columns]\\n' % self.shape\n    print('\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer, file=output_file)",
        "mutated": [
            "def print_rows(self, num_rows=10, num_columns=40, max_column_width=30, max_row_width=80, output_file=None):\n    if False:\n        i = 10\n    '\\n        Print the first M rows and N columns of the SFrame in human readable\\n        format.\\n\\n        Parameters\\n        ----------\\n        num_rows : int, optional\\n            Number of rows to print.\\n\\n        num_columns : int, optional\\n            Number of columns to print.\\n\\n        max_column_width : int, optional\\n            Maximum width of a column. Columns use fewer characters if possible.\\n\\n        max_row_width : int, optional\\n            Maximum width of a printed row. Columns beyond this width wrap to a\\n            new line. `max_row_width` is automatically reset to be the\\n            larger of itself and `max_column_width`.\\n\\n        output_file: file, optional\\n            The stream or file that receives the output. By default the output\\n            goes to sys.stdout, but it can also be redirected to a file or a\\n            string (using an object of type StringIO).\\n\\n        See Also\\n        --------\\n        head, tail\\n        '\n    if output_file is None:\n        output_file = sys.stdout\n    max_row_width = max(max_row_width, max_column_width + 1)\n    printed_sf = self._imagecols_to_stringcols(num_rows)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=num_rows, max_columns=num_columns, max_column_width=max_column_width, max_row_width=max_row_width)\n    footer = '[%d rows x %d columns]\\n' % self.shape\n    print('\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer, file=output_file)",
            "def print_rows(self, num_rows=10, num_columns=40, max_column_width=30, max_row_width=80, output_file=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Print the first M rows and N columns of the SFrame in human readable\\n        format.\\n\\n        Parameters\\n        ----------\\n        num_rows : int, optional\\n            Number of rows to print.\\n\\n        num_columns : int, optional\\n            Number of columns to print.\\n\\n        max_column_width : int, optional\\n            Maximum width of a column. Columns use fewer characters if possible.\\n\\n        max_row_width : int, optional\\n            Maximum width of a printed row. Columns beyond this width wrap to a\\n            new line. `max_row_width` is automatically reset to be the\\n            larger of itself and `max_column_width`.\\n\\n        output_file: file, optional\\n            The stream or file that receives the output. By default the output\\n            goes to sys.stdout, but it can also be redirected to a file or a\\n            string (using an object of type StringIO).\\n\\n        See Also\\n        --------\\n        head, tail\\n        '\n    if output_file is None:\n        output_file = sys.stdout\n    max_row_width = max(max_row_width, max_column_width + 1)\n    printed_sf = self._imagecols_to_stringcols(num_rows)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=num_rows, max_columns=num_columns, max_column_width=max_column_width, max_row_width=max_row_width)\n    footer = '[%d rows x %d columns]\\n' % self.shape\n    print('\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer, file=output_file)",
            "def print_rows(self, num_rows=10, num_columns=40, max_column_width=30, max_row_width=80, output_file=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Print the first M rows and N columns of the SFrame in human readable\\n        format.\\n\\n        Parameters\\n        ----------\\n        num_rows : int, optional\\n            Number of rows to print.\\n\\n        num_columns : int, optional\\n            Number of columns to print.\\n\\n        max_column_width : int, optional\\n            Maximum width of a column. Columns use fewer characters if possible.\\n\\n        max_row_width : int, optional\\n            Maximum width of a printed row. Columns beyond this width wrap to a\\n            new line. `max_row_width` is automatically reset to be the\\n            larger of itself and `max_column_width`.\\n\\n        output_file: file, optional\\n            The stream or file that receives the output. By default the output\\n            goes to sys.stdout, but it can also be redirected to a file or a\\n            string (using an object of type StringIO).\\n\\n        See Also\\n        --------\\n        head, tail\\n        '\n    if output_file is None:\n        output_file = sys.stdout\n    max_row_width = max(max_row_width, max_column_width + 1)\n    printed_sf = self._imagecols_to_stringcols(num_rows)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=num_rows, max_columns=num_columns, max_column_width=max_column_width, max_row_width=max_row_width)\n    footer = '[%d rows x %d columns]\\n' % self.shape\n    print('\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer, file=output_file)",
            "def print_rows(self, num_rows=10, num_columns=40, max_column_width=30, max_row_width=80, output_file=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Print the first M rows and N columns of the SFrame in human readable\\n        format.\\n\\n        Parameters\\n        ----------\\n        num_rows : int, optional\\n            Number of rows to print.\\n\\n        num_columns : int, optional\\n            Number of columns to print.\\n\\n        max_column_width : int, optional\\n            Maximum width of a column. Columns use fewer characters if possible.\\n\\n        max_row_width : int, optional\\n            Maximum width of a printed row. Columns beyond this width wrap to a\\n            new line. `max_row_width` is automatically reset to be the\\n            larger of itself and `max_column_width`.\\n\\n        output_file: file, optional\\n            The stream or file that receives the output. By default the output\\n            goes to sys.stdout, but it can also be redirected to a file or a\\n            string (using an object of type StringIO).\\n\\n        See Also\\n        --------\\n        head, tail\\n        '\n    if output_file is None:\n        output_file = sys.stdout\n    max_row_width = max(max_row_width, max_column_width + 1)\n    printed_sf = self._imagecols_to_stringcols(num_rows)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=num_rows, max_columns=num_columns, max_column_width=max_column_width, max_row_width=max_row_width)\n    footer = '[%d rows x %d columns]\\n' % self.shape\n    print('\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer, file=output_file)",
            "def print_rows(self, num_rows=10, num_columns=40, max_column_width=30, max_row_width=80, output_file=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Print the first M rows and N columns of the SFrame in human readable\\n        format.\\n\\n        Parameters\\n        ----------\\n        num_rows : int, optional\\n            Number of rows to print.\\n\\n        num_columns : int, optional\\n            Number of columns to print.\\n\\n        max_column_width : int, optional\\n            Maximum width of a column. Columns use fewer characters if possible.\\n\\n        max_row_width : int, optional\\n            Maximum width of a printed row. Columns beyond this width wrap to a\\n            new line. `max_row_width` is automatically reset to be the\\n            larger of itself and `max_column_width`.\\n\\n        output_file: file, optional\\n            The stream or file that receives the output. By default the output\\n            goes to sys.stdout, but it can also be redirected to a file or a\\n            string (using an object of type StringIO).\\n\\n        See Also\\n        --------\\n        head, tail\\n        '\n    if output_file is None:\n        output_file = sys.stdout\n    max_row_width = max(max_row_width, max_column_width + 1)\n    printed_sf = self._imagecols_to_stringcols(num_rows)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=num_rows, max_columns=num_columns, max_column_width=max_column_width, max_row_width=max_row_width)\n    footer = '[%d rows x %d columns]\\n' % self.shape\n    print('\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer, file=output_file)"
        ]
    },
    {
        "func_name": "_imagecols_to_stringcols",
        "original": "def _imagecols_to_stringcols(self, num_rows=10):\n    types = self.column_types()\n    names = self.column_names()\n    image_column_names = [names[i] for i in range(len(names)) if types[i] == _Image]\n    printed_sf = self.__copy__()\n    if len(image_column_names) > 0:\n        for t in names:\n            if t in image_column_names:\n                printed_sf[t] = self[t].astype(str)\n    return printed_sf.head(num_rows)",
        "mutated": [
            "def _imagecols_to_stringcols(self, num_rows=10):\n    if False:\n        i = 10\n    types = self.column_types()\n    names = self.column_names()\n    image_column_names = [names[i] for i in range(len(names)) if types[i] == _Image]\n    printed_sf = self.__copy__()\n    if len(image_column_names) > 0:\n        for t in names:\n            if t in image_column_names:\n                printed_sf[t] = self[t].astype(str)\n    return printed_sf.head(num_rows)",
            "def _imagecols_to_stringcols(self, num_rows=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    types = self.column_types()\n    names = self.column_names()\n    image_column_names = [names[i] for i in range(len(names)) if types[i] == _Image]\n    printed_sf = self.__copy__()\n    if len(image_column_names) > 0:\n        for t in names:\n            if t in image_column_names:\n                printed_sf[t] = self[t].astype(str)\n    return printed_sf.head(num_rows)",
            "def _imagecols_to_stringcols(self, num_rows=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    types = self.column_types()\n    names = self.column_names()\n    image_column_names = [names[i] for i in range(len(names)) if types[i] == _Image]\n    printed_sf = self.__copy__()\n    if len(image_column_names) > 0:\n        for t in names:\n            if t in image_column_names:\n                printed_sf[t] = self[t].astype(str)\n    return printed_sf.head(num_rows)",
            "def _imagecols_to_stringcols(self, num_rows=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    types = self.column_types()\n    names = self.column_names()\n    image_column_names = [names[i] for i in range(len(names)) if types[i] == _Image]\n    printed_sf = self.__copy__()\n    if len(image_column_names) > 0:\n        for t in names:\n            if t in image_column_names:\n                printed_sf[t] = self[t].astype(str)\n    return printed_sf.head(num_rows)",
            "def _imagecols_to_stringcols(self, num_rows=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    types = self.column_types()\n    names = self.column_names()\n    image_column_names = [names[i] for i in range(len(names)) if types[i] == _Image]\n    printed_sf = self.__copy__()\n    if len(image_column_names) > 0:\n        for t in names:\n            if t in image_column_names:\n                printed_sf[t] = self[t].astype(str)\n    return printed_sf.head(num_rows)"
        ]
    },
    {
        "func_name": "drop_duplicates",
        "original": "def drop_duplicates(self, subset):\n    \"\"\"\n        Returns an SFrame with duplicate rows removed.\n\n        Parameters\n        ----------\n        subset : column label or sequence of labels\n            Use only these columns for identifying duplicates.\n\n        Examples\n        --------\n        >>> import turicreate as tc\n        >>> sf = tc.SFrame({'A': ['a', 'b', 'a', 'C'], 'B': ['b', 'a', 'b', 'D'], 'C': [1, 2, 1, 8]})\n        >>> sf.drop_duplicates(subset=[\"A\",\"B\"])\n        Columns:\n\t        A\tstr\n\t        B\tstr\n\t        C\tint\n        Rows: 3\n        Data:\n        +---+---+---+\n        | A | B | C |\n        +---+---+---+\n        | b | a | 2 |\n        | C | D | 8 |\n        | a | b | 1 |\n        +---+---+---+\n        [3 rows x 3 columns]\n\n        \"\"\"\n    result = all((elem in self.column_names() for elem in subset))\n    if result:\n        return self.groupby(subset, {col: aggregate.SELECT_ONE(col) for col in self.column_names() if col not in subset})\n    else:\n        raise TypeError('Not all subset columns in SFrame')",
        "mutated": [
            "def drop_duplicates(self, subset):\n    if False:\n        i = 10\n    '\\n        Returns an SFrame with duplicate rows removed.\\n\\n        Parameters\\n        ----------\\n        subset : column label or sequence of labels\\n            Use only these columns for identifying duplicates.\\n\\n        Examples\\n        --------\\n        >>> import turicreate as tc\\n        >>> sf = tc.SFrame({\\'A\\': [\\'a\\', \\'b\\', \\'a\\', \\'C\\'], \\'B\\': [\\'b\\', \\'a\\', \\'b\\', \\'D\\'], \\'C\\': [1, 2, 1, 8]})\\n        >>> sf.drop_duplicates(subset=[\"A\",\"B\"])\\n        Columns:\\n\\t        A\\tstr\\n\\t        B\\tstr\\n\\t        C\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+---+\\n        | A | B | C |\\n        +---+---+---+\\n        | b | a | 2 |\\n        | C | D | 8 |\\n        | a | b | 1 |\\n        +---+---+---+\\n        [3 rows x 3 columns]\\n\\n        '\n    result = all((elem in self.column_names() for elem in subset))\n    if result:\n        return self.groupby(subset, {col: aggregate.SELECT_ONE(col) for col in self.column_names() if col not in subset})\n    else:\n        raise TypeError('Not all subset columns in SFrame')",
            "def drop_duplicates(self, subset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns an SFrame with duplicate rows removed.\\n\\n        Parameters\\n        ----------\\n        subset : column label or sequence of labels\\n            Use only these columns for identifying duplicates.\\n\\n        Examples\\n        --------\\n        >>> import turicreate as tc\\n        >>> sf = tc.SFrame({\\'A\\': [\\'a\\', \\'b\\', \\'a\\', \\'C\\'], \\'B\\': [\\'b\\', \\'a\\', \\'b\\', \\'D\\'], \\'C\\': [1, 2, 1, 8]})\\n        >>> sf.drop_duplicates(subset=[\"A\",\"B\"])\\n        Columns:\\n\\t        A\\tstr\\n\\t        B\\tstr\\n\\t        C\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+---+\\n        | A | B | C |\\n        +---+---+---+\\n        | b | a | 2 |\\n        | C | D | 8 |\\n        | a | b | 1 |\\n        +---+---+---+\\n        [3 rows x 3 columns]\\n\\n        '\n    result = all((elem in self.column_names() for elem in subset))\n    if result:\n        return self.groupby(subset, {col: aggregate.SELECT_ONE(col) for col in self.column_names() if col not in subset})\n    else:\n        raise TypeError('Not all subset columns in SFrame')",
            "def drop_duplicates(self, subset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns an SFrame with duplicate rows removed.\\n\\n        Parameters\\n        ----------\\n        subset : column label or sequence of labels\\n            Use only these columns for identifying duplicates.\\n\\n        Examples\\n        --------\\n        >>> import turicreate as tc\\n        >>> sf = tc.SFrame({\\'A\\': [\\'a\\', \\'b\\', \\'a\\', \\'C\\'], \\'B\\': [\\'b\\', \\'a\\', \\'b\\', \\'D\\'], \\'C\\': [1, 2, 1, 8]})\\n        >>> sf.drop_duplicates(subset=[\"A\",\"B\"])\\n        Columns:\\n\\t        A\\tstr\\n\\t        B\\tstr\\n\\t        C\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+---+\\n        | A | B | C |\\n        +---+---+---+\\n        | b | a | 2 |\\n        | C | D | 8 |\\n        | a | b | 1 |\\n        +---+---+---+\\n        [3 rows x 3 columns]\\n\\n        '\n    result = all((elem in self.column_names() for elem in subset))\n    if result:\n        return self.groupby(subset, {col: aggregate.SELECT_ONE(col) for col in self.column_names() if col not in subset})\n    else:\n        raise TypeError('Not all subset columns in SFrame')",
            "def drop_duplicates(self, subset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns an SFrame with duplicate rows removed.\\n\\n        Parameters\\n        ----------\\n        subset : column label or sequence of labels\\n            Use only these columns for identifying duplicates.\\n\\n        Examples\\n        --------\\n        >>> import turicreate as tc\\n        >>> sf = tc.SFrame({\\'A\\': [\\'a\\', \\'b\\', \\'a\\', \\'C\\'], \\'B\\': [\\'b\\', \\'a\\', \\'b\\', \\'D\\'], \\'C\\': [1, 2, 1, 8]})\\n        >>> sf.drop_duplicates(subset=[\"A\",\"B\"])\\n        Columns:\\n\\t        A\\tstr\\n\\t        B\\tstr\\n\\t        C\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+---+\\n        | A | B | C |\\n        +---+---+---+\\n        | b | a | 2 |\\n        | C | D | 8 |\\n        | a | b | 1 |\\n        +---+---+---+\\n        [3 rows x 3 columns]\\n\\n        '\n    result = all((elem in self.column_names() for elem in subset))\n    if result:\n        return self.groupby(subset, {col: aggregate.SELECT_ONE(col) for col in self.column_names() if col not in subset})\n    else:\n        raise TypeError('Not all subset columns in SFrame')",
            "def drop_duplicates(self, subset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns an SFrame with duplicate rows removed.\\n\\n        Parameters\\n        ----------\\n        subset : column label or sequence of labels\\n            Use only these columns for identifying duplicates.\\n\\n        Examples\\n        --------\\n        >>> import turicreate as tc\\n        >>> sf = tc.SFrame({\\'A\\': [\\'a\\', \\'b\\', \\'a\\', \\'C\\'], \\'B\\': [\\'b\\', \\'a\\', \\'b\\', \\'D\\'], \\'C\\': [1, 2, 1, 8]})\\n        >>> sf.drop_duplicates(subset=[\"A\",\"B\"])\\n        Columns:\\n\\t        A\\tstr\\n\\t        B\\tstr\\n\\t        C\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+---+\\n        | A | B | C |\\n        +---+---+---+\\n        | b | a | 2 |\\n        | C | D | 8 |\\n        | a | b | 1 |\\n        +---+---+---+\\n        [3 rows x 3 columns]\\n\\n        '\n    result = all((elem in self.column_names() for elem in subset))\n    if result:\n        return self.groupby(subset, {col: aggregate.SELECT_ONE(col) for col in self.column_names() if col not in subset})\n    else:\n        raise TypeError('Not all subset columns in SFrame')"
        ]
    },
    {
        "func_name": "__str_impl__",
        "original": "def __str_impl__(self, num_rows=10, footer=True):\n    \"\"\"\n        Returns a string containing the first num_rows elements of the frame, along\n        with a description of the frame.\n        \"\"\"\n    MAX_ROWS_TO_DISPLAY = num_rows\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    is_empty = len(printed_sf) == 0\n    if not footer:\n        return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]))\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]\\n' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '\\n'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]\\n' % self.num_columns()\n        footer += '\\n'.join(LAZY_FOOTER_STRS)\n    return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer)",
        "mutated": [
            "def __str_impl__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n    '\\n        Returns a string containing the first num_rows elements of the frame, along\\n        with a description of the frame.\\n        '\n    MAX_ROWS_TO_DISPLAY = num_rows\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    is_empty = len(printed_sf) == 0\n    if not footer:\n        return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]))\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]\\n' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '\\n'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]\\n' % self.num_columns()\n        footer += '\\n'.join(LAZY_FOOTER_STRS)\n    return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer)",
            "def __str_impl__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a string containing the first num_rows elements of the frame, along\\n        with a description of the frame.\\n        '\n    MAX_ROWS_TO_DISPLAY = num_rows\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    is_empty = len(printed_sf) == 0\n    if not footer:\n        return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]))\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]\\n' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '\\n'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]\\n' % self.num_columns()\n        footer += '\\n'.join(LAZY_FOOTER_STRS)\n    return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer)",
            "def __str_impl__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a string containing the first num_rows elements of the frame, along\\n        with a description of the frame.\\n        '\n    MAX_ROWS_TO_DISPLAY = num_rows\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    is_empty = len(printed_sf) == 0\n    if not footer:\n        return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]))\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]\\n' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '\\n'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]\\n' % self.num_columns()\n        footer += '\\n'.join(LAZY_FOOTER_STRS)\n    return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer)",
            "def __str_impl__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a string containing the first num_rows elements of the frame, along\\n        with a description of the frame.\\n        '\n    MAX_ROWS_TO_DISPLAY = num_rows\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    is_empty = len(printed_sf) == 0\n    if not footer:\n        return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]))\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]\\n' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '\\n'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]\\n' % self.num_columns()\n        footer += '\\n'.join(LAZY_FOOTER_STRS)\n    return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer)",
            "def __str_impl__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a string containing the first num_rows elements of the frame, along\\n        with a description of the frame.\\n        '\n    MAX_ROWS_TO_DISPLAY = num_rows\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=False, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    is_empty = len(printed_sf) == 0\n    if not footer:\n        return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]))\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]\\n' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '\\n'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]\\n' % self.num_columns()\n        footer += '\\n'.join(LAZY_FOOTER_STRS)\n    return (is_empty, '\\n'.join([str(tb) for tb in row_of_tables]) + '\\n' + footer)"
        ]
    },
    {
        "func_name": "__str__",
        "original": "def __str__(self, num_rows=10, footer=True):\n    \"\"\"\n        Returns a string containing the first 10 elements of the frame, along\n        with a description of the frame.\n        \"\"\"\n    return self.__str_impl__(num_rows, footer)[1]",
        "mutated": [
            "def __str__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n    '\\n        Returns a string containing the first 10 elements of the frame, along\\n        with a description of the frame.\\n        '\n    return self.__str_impl__(num_rows, footer)[1]",
            "def __str__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a string containing the first 10 elements of the frame, along\\n        with a description of the frame.\\n        '\n    return self.__str_impl__(num_rows, footer)[1]",
            "def __str__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a string containing the first 10 elements of the frame, along\\n        with a description of the frame.\\n        '\n    return self.__str_impl__(num_rows, footer)[1]",
            "def __str__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a string containing the first 10 elements of the frame, along\\n        with a description of the frame.\\n        '\n    return self.__str_impl__(num_rows, footer)[1]",
            "def __str__(self, num_rows=10, footer=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a string containing the first 10 elements of the frame, along\\n        with a description of the frame.\\n        '\n    return self.__str_impl__(num_rows, footer)[1]"
        ]
    },
    {
        "func_name": "_repr_html_",
        "original": "def _repr_html_(self):\n    MAX_ROWS_TO_DISPLAY = 10\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=True, max_row_width=120, max_columns=40, max_column_width=25, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]<br/>' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '<br/>'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]<br/>' % self.num_columns()\n        footer += '<br/>'.join(LAZY_FOOTER_STRS)\n    begin = '<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">'\n    end = '\\n</div>'\n    return begin + '\\n'.join([tb.get_html_string(format=True) for tb in row_of_tables]) + '\\n' + footer + end",
        "mutated": [
            "def _repr_html_(self):\n    if False:\n        i = 10\n    MAX_ROWS_TO_DISPLAY = 10\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=True, max_row_width=120, max_columns=40, max_column_width=25, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]<br/>' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '<br/>'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]<br/>' % self.num_columns()\n        footer += '<br/>'.join(LAZY_FOOTER_STRS)\n    begin = '<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">'\n    end = '\\n</div>'\n    return begin + '\\n'.join([tb.get_html_string(format=True) for tb in row_of_tables]) + '\\n' + footer + end",
            "def _repr_html_(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    MAX_ROWS_TO_DISPLAY = 10\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=True, max_row_width=120, max_columns=40, max_column_width=25, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]<br/>' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '<br/>'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]<br/>' % self.num_columns()\n        footer += '<br/>'.join(LAZY_FOOTER_STRS)\n    begin = '<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">'\n    end = '\\n</div>'\n    return begin + '\\n'.join([tb.get_html_string(format=True) for tb in row_of_tables]) + '\\n' + footer + end",
            "def _repr_html_(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    MAX_ROWS_TO_DISPLAY = 10\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=True, max_row_width=120, max_columns=40, max_column_width=25, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]<br/>' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '<br/>'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]<br/>' % self.num_columns()\n        footer += '<br/>'.join(LAZY_FOOTER_STRS)\n    begin = '<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">'\n    end = '\\n</div>'\n    return begin + '\\n'.join([tb.get_html_string(format=True) for tb in row_of_tables]) + '\\n' + footer + end",
            "def _repr_html_(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    MAX_ROWS_TO_DISPLAY = 10\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=True, max_row_width=120, max_columns=40, max_column_width=25, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]<br/>' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '<br/>'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]<br/>' % self.num_columns()\n        footer += '<br/>'.join(LAZY_FOOTER_STRS)\n    begin = '<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">'\n    end = '\\n</div>'\n    return begin + '\\n'.join([tb.get_html_string(format=True) for tb in row_of_tables]) + '\\n' + footer + end",
            "def _repr_html_(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    MAX_ROWS_TO_DISPLAY = 10\n    printed_sf = self._imagecols_to_stringcols(MAX_ROWS_TO_DISPLAY)\n    row_of_tables = printed_sf.__get_pretty_tables__(wrap_text=True, max_row_width=120, max_columns=40, max_column_width=25, max_rows_to_display=MAX_ROWS_TO_DISPLAY)\n    if self.__has_size__():\n        footer = '[%d rows x %d columns]<br/>' % self.shape\n        if self.num_rows() > MAX_ROWS_TO_DISPLAY:\n            footer += '<br/>'.join(FOOTER_STRS)\n    else:\n        footer = '[? rows x %d columns]<br/>' % self.num_columns()\n        footer += '<br/>'.join(LAZY_FOOTER_STRS)\n    begin = '<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">'\n    end = '\\n</div>'\n    return begin + '\\n'.join([tb.get_html_string(format=True) for tb in row_of_tables]) + '\\n' + footer + end"
        ]
    },
    {
        "func_name": "__nonzero__",
        "original": "def __nonzero__(self):\n    \"\"\"\n        Returns true if the frame is not empty.\n        \"\"\"\n    return self.num_rows() != 0",
        "mutated": [
            "def __nonzero__(self):\n    if False:\n        i = 10\n    '\\n        Returns true if the frame is not empty.\\n        '\n    return self.num_rows() != 0",
            "def __nonzero__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns true if the frame is not empty.\\n        '\n    return self.num_rows() != 0",
            "def __nonzero__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns true if the frame is not empty.\\n        '\n    return self.num_rows() != 0",
            "def __nonzero__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns true if the frame is not empty.\\n        '\n    return self.num_rows() != 0",
            "def __nonzero__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns true if the frame is not empty.\\n        '\n    return self.num_rows() != 0"
        ]
    },
    {
        "func_name": "__len__",
        "original": "def __len__(self):\n    \"\"\"\n        Returns the number of rows of the sframe.\n        \"\"\"\n    return self.num_rows()",
        "mutated": [
            "def __len__(self):\n    if False:\n        i = 10\n    '\\n        Returns the number of rows of the sframe.\\n        '\n    return self.num_rows()",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the number of rows of the sframe.\\n        '\n    return self.num_rows()",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the number of rows of the sframe.\\n        '\n    return self.num_rows()",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the number of rows of the sframe.\\n        '\n    return self.num_rows()",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the number of rows of the sframe.\\n        '\n    return self.num_rows()"
        ]
    },
    {
        "func_name": "__copy__",
        "original": "def __copy__(self):\n    \"\"\"\n        Returns a shallow copy of the sframe.\n        \"\"\"\n    return self.select_columns(self.column_names())",
        "mutated": [
            "def __copy__(self):\n    if False:\n        i = 10\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.select_columns(self.column_names())",
            "def __copy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.select_columns(self.column_names())",
            "def __copy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.select_columns(self.column_names())",
            "def __copy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.select_columns(self.column_names())",
            "def __copy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.select_columns(self.column_names())"
        ]
    },
    {
        "func_name": "__deepcopy__",
        "original": "def __deepcopy__(self, memo):\n    \"\"\"\n        Returns a deep copy of the sframe. As the data in an SFrame is\n        immutable, this is identical to __copy__.\n        \"\"\"\n    return self.__copy__()",
        "mutated": [
            "def __deepcopy__(self, memo):\n    if False:\n        i = 10\n    '\\n        Returns a deep copy of the sframe. As the data in an SFrame is\\n        immutable, this is identical to __copy__.\\n        '\n    return self.__copy__()",
            "def __deepcopy__(self, memo):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a deep copy of the sframe. As the data in an SFrame is\\n        immutable, this is identical to __copy__.\\n        '\n    return self.__copy__()",
            "def __deepcopy__(self, memo):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a deep copy of the sframe. As the data in an SFrame is\\n        immutable, this is identical to __copy__.\\n        '\n    return self.__copy__()",
            "def __deepcopy__(self, memo):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a deep copy of the sframe. As the data in an SFrame is\\n        immutable, this is identical to __copy__.\\n        '\n    return self.__copy__()",
            "def __deepcopy__(self, memo):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a deep copy of the sframe. As the data in an SFrame is\\n        immutable, this is identical to __copy__.\\n        '\n    return self.__copy__()"
        ]
    },
    {
        "func_name": "copy",
        "original": "def copy(self):\n    \"\"\"\n        Returns a shallow copy of the sframe.\n        \"\"\"\n    return self.__copy__()",
        "mutated": [
            "def copy(self):\n    if False:\n        i = 10\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.__copy__()",
            "def copy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.__copy__()",
            "def copy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.__copy__()",
            "def copy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.__copy__()",
            "def copy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a shallow copy of the sframe.\\n        '\n    return self.__copy__()"
        ]
    },
    {
        "func_name": "__eq__",
        "original": "def __eq__(self, other):\n    raise NotImplementedError",
        "mutated": [
            "def __eq__(self, other):\n    if False:\n        i = 10\n    raise NotImplementedError",
            "def __eq__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    raise NotImplementedError",
            "def __eq__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    raise NotImplementedError",
            "def __eq__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    raise NotImplementedError",
            "def __eq__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    raise NotImplementedError"
        ]
    },
    {
        "func_name": "__ne__",
        "original": "def __ne__(self, other):\n    raise NotImplementedError",
        "mutated": [
            "def __ne__(self, other):\n    if False:\n        i = 10\n    raise NotImplementedError",
            "def __ne__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    raise NotImplementedError",
            "def __ne__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    raise NotImplementedError",
            "def __ne__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    raise NotImplementedError",
            "def __ne__(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    raise NotImplementedError"
        ]
    },
    {
        "func_name": "_row_selector",
        "original": "def _row_selector(self, other):\n    \"\"\"\n        Where other is an SArray of identical length as the current Frame,\n        this returns a selection of a subset of rows in the current SFrame\n        where the corresponding row in the selector is non-zero.\n        \"\"\"\n    if type(other) is SArray:\n        if self.__has_size__() and other.__has_size__() and (len(other) != len(self)):\n            raise IndexError('Cannot perform logical indexing on arrays of different length.')\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.logical_filter(other.__proxy__))",
        "mutated": [
            "def _row_selector(self, other):\n    if False:\n        i = 10\n    '\\n        Where other is an SArray of identical length as the current Frame,\\n        this returns a selection of a subset of rows in the current SFrame\\n        where the corresponding row in the selector is non-zero.\\n        '\n    if type(other) is SArray:\n        if self.__has_size__() and other.__has_size__() and (len(other) != len(self)):\n            raise IndexError('Cannot perform logical indexing on arrays of different length.')\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.logical_filter(other.__proxy__))",
            "def _row_selector(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Where other is an SArray of identical length as the current Frame,\\n        this returns a selection of a subset of rows in the current SFrame\\n        where the corresponding row in the selector is non-zero.\\n        '\n    if type(other) is SArray:\n        if self.__has_size__() and other.__has_size__() and (len(other) != len(self)):\n            raise IndexError('Cannot perform logical indexing on arrays of different length.')\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.logical_filter(other.__proxy__))",
            "def _row_selector(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Where other is an SArray of identical length as the current Frame,\\n        this returns a selection of a subset of rows in the current SFrame\\n        where the corresponding row in the selector is non-zero.\\n        '\n    if type(other) is SArray:\n        if self.__has_size__() and other.__has_size__() and (len(other) != len(self)):\n            raise IndexError('Cannot perform logical indexing on arrays of different length.')\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.logical_filter(other.__proxy__))",
            "def _row_selector(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Where other is an SArray of identical length as the current Frame,\\n        this returns a selection of a subset of rows in the current SFrame\\n        where the corresponding row in the selector is non-zero.\\n        '\n    if type(other) is SArray:\n        if self.__has_size__() and other.__has_size__() and (len(other) != len(self)):\n            raise IndexError('Cannot perform logical indexing on arrays of different length.')\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.logical_filter(other.__proxy__))",
            "def _row_selector(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Where other is an SArray of identical length as the current Frame,\\n        this returns a selection of a subset of rows in the current SFrame\\n        where the corresponding row in the selector is non-zero.\\n        '\n    if type(other) is SArray:\n        if self.__has_size__() and other.__has_size__() and (len(other) != len(self)):\n            raise IndexError('Cannot perform logical indexing on arrays of different length.')\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.logical_filter(other.__proxy__))"
        ]
    },
    {
        "func_name": "dtype",
        "original": "@property\ndef dtype(self):\n    \"\"\"\n        The type of each column.\n\n        Returns\n        -------\n        out : list[type]\n            Column types of the SFrame.\n\n        See Also\n        --------\n        column_types\n        \"\"\"\n    return self.column_types()",
        "mutated": [
            "@property\ndef dtype(self):\n    if False:\n        i = 10\n    '\\n        The type of each column.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        column_types\\n        '\n    return self.column_types()",
            "@property\ndef dtype(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The type of each column.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        column_types\\n        '\n    return self.column_types()",
            "@property\ndef dtype(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The type of each column.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        column_types\\n        '\n    return self.column_types()",
            "@property\ndef dtype(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The type of each column.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        column_types\\n        '\n    return self.column_types()",
            "@property\ndef dtype(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The type of each column.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        column_types\\n        '\n    return self.column_types()"
        ]
    },
    {
        "func_name": "num_rows",
        "original": "def num_rows(self):\n    \"\"\"\n        The number of rows in this SFrame.\n\n        Returns\n        -------\n        out : int\n            Number of rows in the SFrame.\n\n        See Also\n        --------\n        num_columns\n        \"\"\"\n    return self.__proxy__.num_rows()",
        "mutated": [
            "def num_rows(self):\n    if False:\n        i = 10\n    '\\n        The number of rows in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of rows in the SFrame.\\n\\n        See Also\\n        --------\\n        num_columns\\n        '\n    return self.__proxy__.num_rows()",
            "def num_rows(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The number of rows in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of rows in the SFrame.\\n\\n        See Also\\n        --------\\n        num_columns\\n        '\n    return self.__proxy__.num_rows()",
            "def num_rows(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The number of rows in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of rows in the SFrame.\\n\\n        See Also\\n        --------\\n        num_columns\\n        '\n    return self.__proxy__.num_rows()",
            "def num_rows(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The number of rows in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of rows in the SFrame.\\n\\n        See Also\\n        --------\\n        num_columns\\n        '\n    return self.__proxy__.num_rows()",
            "def num_rows(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The number of rows in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of rows in the SFrame.\\n\\n        See Also\\n        --------\\n        num_columns\\n        '\n    return self.__proxy__.num_rows()"
        ]
    },
    {
        "func_name": "num_columns",
        "original": "def num_columns(self):\n    \"\"\"\n        The number of columns in this SFrame.\n\n        Returns\n        -------\n        out : int\n            Number of columns in the SFrame.\n\n        See Also\n        --------\n        num_rows\n        \"\"\"\n    return self.__proxy__.num_columns()",
        "mutated": [
            "def num_columns(self):\n    if False:\n        i = 10\n    '\\n        The number of columns in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of columns in the SFrame.\\n\\n        See Also\\n        --------\\n        num_rows\\n        '\n    return self.__proxy__.num_columns()",
            "def num_columns(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The number of columns in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of columns in the SFrame.\\n\\n        See Also\\n        --------\\n        num_rows\\n        '\n    return self.__proxy__.num_columns()",
            "def num_columns(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The number of columns in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of columns in the SFrame.\\n\\n        See Also\\n        --------\\n        num_rows\\n        '\n    return self.__proxy__.num_columns()",
            "def num_columns(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The number of columns in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of columns in the SFrame.\\n\\n        See Also\\n        --------\\n        num_rows\\n        '\n    return self.__proxy__.num_columns()",
            "def num_columns(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The number of columns in this SFrame.\\n\\n        Returns\\n        -------\\n        out : int\\n            Number of columns in the SFrame.\\n\\n        See Also\\n        --------\\n        num_rows\\n        '\n    return self.__proxy__.num_columns()"
        ]
    },
    {
        "func_name": "column_names",
        "original": "def column_names(self):\n    \"\"\"\n        The name of each column in the SFrame.\n\n        Returns\n        -------\n        out : list[string]\n            Column names of the SFrame.\n\n        See Also\n        --------\n        rename\n        \"\"\"\n    return self.__proxy__.column_names()",
        "mutated": [
            "def column_names(self):\n    if False:\n        i = 10\n    '\\n        The name of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[string]\\n            Column names of the SFrame.\\n\\n        See Also\\n        --------\\n        rename\\n        '\n    return self.__proxy__.column_names()",
            "def column_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The name of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[string]\\n            Column names of the SFrame.\\n\\n        See Also\\n        --------\\n        rename\\n        '\n    return self.__proxy__.column_names()",
            "def column_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The name of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[string]\\n            Column names of the SFrame.\\n\\n        See Also\\n        --------\\n        rename\\n        '\n    return self.__proxy__.column_names()",
            "def column_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The name of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[string]\\n            Column names of the SFrame.\\n\\n        See Also\\n        --------\\n        rename\\n        '\n    return self.__proxy__.column_names()",
            "def column_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The name of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[string]\\n            Column names of the SFrame.\\n\\n        See Also\\n        --------\\n        rename\\n        '\n    return self.__proxy__.column_names()"
        ]
    },
    {
        "func_name": "column_types",
        "original": "def column_types(self):\n    \"\"\"\n        The type of each column in the SFrame.\n\n        Returns\n        -------\n        out : list[type]\n            Column types of the SFrame.\n\n        See Also\n        --------\n        dtype\n        \"\"\"\n    return self.__proxy__.dtype()",
        "mutated": [
            "def column_types(self):\n    if False:\n        i = 10\n    '\\n        The type of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        dtype\\n        '\n    return self.__proxy__.dtype()",
            "def column_types(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The type of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        dtype\\n        '\n    return self.__proxy__.dtype()",
            "def column_types(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The type of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        dtype\\n        '\n    return self.__proxy__.dtype()",
            "def column_types(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The type of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        dtype\\n        '\n    return self.__proxy__.dtype()",
            "def column_types(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The type of each column in the SFrame.\\n\\n        Returns\\n        -------\\n        out : list[type]\\n            Column types of the SFrame.\\n\\n        See Also\\n        --------\\n        dtype\\n        '\n    return self.__proxy__.dtype()"
        ]
    },
    {
        "func_name": "head",
        "original": "def head(self, n=10):\n    \"\"\"\n        The first n rows of the SFrame.\n\n        Parameters\n        ----------\n        n : int, optional\n            The number of rows to fetch.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame which contains the first n rows of the current SFrame\n\n        See Also\n        --------\n        tail, print_rows\n        \"\"\"\n    return SFrame(_proxy=self.__proxy__.head(n))",
        "mutated": [
            "def head(self, n=10):\n    if False:\n        i = 10\n    '\\n        The first n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the first n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        tail, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.head(n))",
            "def head(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The first n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the first n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        tail, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.head(n))",
            "def head(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The first n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the first n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        tail, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.head(n))",
            "def head(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The first n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the first n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        tail, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.head(n))",
            "def head(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The first n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the first n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        tail, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.head(n))"
        ]
    },
    {
        "func_name": "to_dataframe",
        "original": "def to_dataframe(self):\n    \"\"\"\n        Convert this SFrame to pandas.DataFrame.\n\n        This operation will construct a pandas.DataFrame in memory. Care must\n        be taken when size of the returned object is big.\n\n        Returns\n        -------\n        out : pandas.DataFrame\n            The dataframe which contains all rows of SFrame\n        \"\"\"\n    from ..toolkits.image_classifier._evaluation import _image_resize\n    assert HAS_PANDAS, 'pandas is not installed.'\n    df = pandas.DataFrame()\n    for i in range(self.num_columns()):\n        column_name = self.column_names()[i]\n        if self.column_types()[i] == _Image:\n            df[column_name] = [_image_resize(x[column_name])._to_pil_image() for x in self.select_columns([column_name])]\n        else:\n            df[column_name] = list(self[column_name])\n        if len(df[column_name]) == 0:\n            column_type = self.column_types()[i]\n            if column_type in (array.array, type(None)):\n                column_type = 'object'\n            df[column_name] = df[column_name].astype(column_type)\n    return df",
        "mutated": [
            "def to_dataframe(self):\n    if False:\n        i = 10\n    '\\n        Convert this SFrame to pandas.DataFrame.\\n\\n        This operation will construct a pandas.DataFrame in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : pandas.DataFrame\\n            The dataframe which contains all rows of SFrame\\n        '\n    from ..toolkits.image_classifier._evaluation import _image_resize\n    assert HAS_PANDAS, 'pandas is not installed.'\n    df = pandas.DataFrame()\n    for i in range(self.num_columns()):\n        column_name = self.column_names()[i]\n        if self.column_types()[i] == _Image:\n            df[column_name] = [_image_resize(x[column_name])._to_pil_image() for x in self.select_columns([column_name])]\n        else:\n            df[column_name] = list(self[column_name])\n        if len(df[column_name]) == 0:\n            column_type = self.column_types()[i]\n            if column_type in (array.array, type(None)):\n                column_type = 'object'\n            df[column_name] = df[column_name].astype(column_type)\n    return df",
            "def to_dataframe(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Convert this SFrame to pandas.DataFrame.\\n\\n        This operation will construct a pandas.DataFrame in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : pandas.DataFrame\\n            The dataframe which contains all rows of SFrame\\n        '\n    from ..toolkits.image_classifier._evaluation import _image_resize\n    assert HAS_PANDAS, 'pandas is not installed.'\n    df = pandas.DataFrame()\n    for i in range(self.num_columns()):\n        column_name = self.column_names()[i]\n        if self.column_types()[i] == _Image:\n            df[column_name] = [_image_resize(x[column_name])._to_pil_image() for x in self.select_columns([column_name])]\n        else:\n            df[column_name] = list(self[column_name])\n        if len(df[column_name]) == 0:\n            column_type = self.column_types()[i]\n            if column_type in (array.array, type(None)):\n                column_type = 'object'\n            df[column_name] = df[column_name].astype(column_type)\n    return df",
            "def to_dataframe(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Convert this SFrame to pandas.DataFrame.\\n\\n        This operation will construct a pandas.DataFrame in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : pandas.DataFrame\\n            The dataframe which contains all rows of SFrame\\n        '\n    from ..toolkits.image_classifier._evaluation import _image_resize\n    assert HAS_PANDAS, 'pandas is not installed.'\n    df = pandas.DataFrame()\n    for i in range(self.num_columns()):\n        column_name = self.column_names()[i]\n        if self.column_types()[i] == _Image:\n            df[column_name] = [_image_resize(x[column_name])._to_pil_image() for x in self.select_columns([column_name])]\n        else:\n            df[column_name] = list(self[column_name])\n        if len(df[column_name]) == 0:\n            column_type = self.column_types()[i]\n            if column_type in (array.array, type(None)):\n                column_type = 'object'\n            df[column_name] = df[column_name].astype(column_type)\n    return df",
            "def to_dataframe(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Convert this SFrame to pandas.DataFrame.\\n\\n        This operation will construct a pandas.DataFrame in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : pandas.DataFrame\\n            The dataframe which contains all rows of SFrame\\n        '\n    from ..toolkits.image_classifier._evaluation import _image_resize\n    assert HAS_PANDAS, 'pandas is not installed.'\n    df = pandas.DataFrame()\n    for i in range(self.num_columns()):\n        column_name = self.column_names()[i]\n        if self.column_types()[i] == _Image:\n            df[column_name] = [_image_resize(x[column_name])._to_pil_image() for x in self.select_columns([column_name])]\n        else:\n            df[column_name] = list(self[column_name])\n        if len(df[column_name]) == 0:\n            column_type = self.column_types()[i]\n            if column_type in (array.array, type(None)):\n                column_type = 'object'\n            df[column_name] = df[column_name].astype(column_type)\n    return df",
            "def to_dataframe(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Convert this SFrame to pandas.DataFrame.\\n\\n        This operation will construct a pandas.DataFrame in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : pandas.DataFrame\\n            The dataframe which contains all rows of SFrame\\n        '\n    from ..toolkits.image_classifier._evaluation import _image_resize\n    assert HAS_PANDAS, 'pandas is not installed.'\n    df = pandas.DataFrame()\n    for i in range(self.num_columns()):\n        column_name = self.column_names()[i]\n        if self.column_types()[i] == _Image:\n            df[column_name] = [_image_resize(x[column_name])._to_pil_image() for x in self.select_columns([column_name])]\n        else:\n            df[column_name] = list(self[column_name])\n        if len(df[column_name]) == 0:\n            column_type = self.column_types()[i]\n            if column_type in (array.array, type(None)):\n                column_type = 'object'\n            df[column_name] = df[column_name].astype(column_type)\n    return df"
        ]
    },
    {
        "func_name": "to_numpy",
        "original": "def to_numpy(self):\n    \"\"\"\n        Converts this SFrame to a numpy array\n\n        This operation will construct a numpy array in memory. Care must\n        be taken when size of the returned object is big.\n\n        Returns\n        -------\n        out : numpy.ndarray\n            A Numpy Array containing all the values of the SFrame\n\n        \"\"\"\n    assert HAS_NUMPY, 'numpy is not installed.'\n    import numpy\n    return numpy.transpose(numpy.asarray([self[x] for x in self.column_names()]))",
        "mutated": [
            "def to_numpy(self):\n    if False:\n        i = 10\n    '\\n        Converts this SFrame to a numpy array\\n\\n        This operation will construct a numpy array in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : numpy.ndarray\\n            A Numpy Array containing all the values of the SFrame\\n\\n        '\n    assert HAS_NUMPY, 'numpy is not installed.'\n    import numpy\n    return numpy.transpose(numpy.asarray([self[x] for x in self.column_names()]))",
            "def to_numpy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Converts this SFrame to a numpy array\\n\\n        This operation will construct a numpy array in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : numpy.ndarray\\n            A Numpy Array containing all the values of the SFrame\\n\\n        '\n    assert HAS_NUMPY, 'numpy is not installed.'\n    import numpy\n    return numpy.transpose(numpy.asarray([self[x] for x in self.column_names()]))",
            "def to_numpy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Converts this SFrame to a numpy array\\n\\n        This operation will construct a numpy array in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : numpy.ndarray\\n            A Numpy Array containing all the values of the SFrame\\n\\n        '\n    assert HAS_NUMPY, 'numpy is not installed.'\n    import numpy\n    return numpy.transpose(numpy.asarray([self[x] for x in self.column_names()]))",
            "def to_numpy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Converts this SFrame to a numpy array\\n\\n        This operation will construct a numpy array in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : numpy.ndarray\\n            A Numpy Array containing all the values of the SFrame\\n\\n        '\n    assert HAS_NUMPY, 'numpy is not installed.'\n    import numpy\n    return numpy.transpose(numpy.asarray([self[x] for x in self.column_names()]))",
            "def to_numpy(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Converts this SFrame to a numpy array\\n\\n        This operation will construct a numpy array in memory. Care must\\n        be taken when size of the returned object is big.\\n\\n        Returns\\n        -------\\n        out : numpy.ndarray\\n            A Numpy Array containing all the values of the SFrame\\n\\n        '\n    assert HAS_NUMPY, 'numpy is not installed.'\n    import numpy\n    return numpy.transpose(numpy.asarray([self[x] for x in self.column_names()]))"
        ]
    },
    {
        "func_name": "tail",
        "original": "def tail(self, n=10):\n    \"\"\"\n        The last n rows of the SFrame.\n\n        Parameters\n        ----------\n        n : int, optional\n            The number of rows to fetch.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame which contains the last n rows of the current SFrame\n\n        See Also\n        --------\n        head, print_rows\n        \"\"\"\n    return SFrame(_proxy=self.__proxy__.tail(n))",
        "mutated": [
            "def tail(self, n=10):\n    if False:\n        i = 10\n    '\\n        The last n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the last n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        head, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.tail(n))",
            "def tail(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The last n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the last n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        head, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.tail(n))",
            "def tail(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The last n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the last n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        head, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.tail(n))",
            "def tail(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The last n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the last n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        head, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.tail(n))",
            "def tail(self, n=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The last n rows of the SFrame.\\n\\n        Parameters\\n        ----------\\n        n : int, optional\\n            The number of rows to fetch.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame which contains the last n rows of the current SFrame\\n\\n        See Also\\n        --------\\n        head, print_rows\\n        '\n    return SFrame(_proxy=self.__proxy__.tail(n))"
        ]
    },
    {
        "func_name": "apply",
        "original": "def apply(self, fn, dtype=None):\n    \"\"\"\n        Transform each row to an :class:`~turicreate.SArray` according to a\n        specified function. Returns a new SArray of ``dtype`` where each element\n        in this SArray is transformed by `fn(x)` where `x` is a single row in\n        the sframe represented as a dictionary.  The ``fn`` should return\n        exactly one value which can be cast into type ``dtype``. If ``dtype`` is\n        not specified, the first 100 rows of the SFrame are used to make a guess\n        of the target data type.\n\n        Parameters\n        ----------\n        fn : function\n            The function to transform each row of the SFrame. The return\n            type should be convertible to `dtype` if `dtype` is not None.\n            This can also be a toolkit extension function which is compiled\n            as a native shared library using SDK.\n\n        dtype : dtype, optional\n            The dtype of the new SArray. If None, the first 100\n            elements of the array are used to guess the target\n            data type.\n\n        Returns\n        -------\n        out : SArray\n            The SArray transformed by fn.  Each element of the SArray is of\n            type ``dtype``\n\n        Examples\n        --------\n        Concatenate strings from several columns:\n\n        >>> sf = turicreate.SFrame({'user_id': [1, 2, 3], 'movie_id': [3, 3, 6],\n                                  'rating': [4, 5, 1]})\n        >>> sf.apply(lambda x: str(x['user_id']) + str(x['movie_id']) + str(x['rating']))\n        dtype: str\n        Rows: 3\n        ['134', '235', '361']\n        \"\"\"\n    assert callable(fn), 'Input must be callable'\n    test_sf = self[:10]\n    dryrun = [fn(row) for row in test_sf]\n    if dtype is None:\n        dtype = SArray(dryrun).dtype\n    seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    nativefn = None\n    try:\n        from .. import extensions as extensions\n        nativefn = extensions._build_native_function_call(fn)\n    except:\n        pass\n    if nativefn is not None:\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, seed))\n    with cython_context():\n        return SArray(_proxy=self.__proxy__.transform(fn, dtype, seed))",
        "mutated": [
            "def apply(self, fn, dtype=None):\n    if False:\n        i = 10\n    \"\\n        Transform each row to an :class:`~turicreate.SArray` according to a\\n        specified function. Returns a new SArray of ``dtype`` where each element\\n        in this SArray is transformed by `fn(x)` where `x` is a single row in\\n        the sframe represented as a dictionary.  The ``fn`` should return\\n        exactly one value which can be cast into type ``dtype``. If ``dtype`` is\\n        not specified, the first 100 rows of the SFrame are used to make a guess\\n        of the target data type.\\n\\n        Parameters\\n        ----------\\n        fn : function\\n            The function to transform each row of the SFrame. The return\\n            type should be convertible to `dtype` if `dtype` is not None.\\n            This can also be a toolkit extension function which is compiled\\n            as a native shared library using SDK.\\n\\n        dtype : dtype, optional\\n            The dtype of the new SArray. If None, the first 100\\n            elements of the array are used to guess the target\\n            data type.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray transformed by fn.  Each element of the SArray is of\\n            type ``dtype``\\n\\n        Examples\\n        --------\\n        Concatenate strings from several columns:\\n\\n        >>> sf = turicreate.SFrame({'user_id': [1, 2, 3], 'movie_id': [3, 3, 6],\\n                                  'rating': [4, 5, 1]})\\n        >>> sf.apply(lambda x: str(x['user_id']) + str(x['movie_id']) + str(x['rating']))\\n        dtype: str\\n        Rows: 3\\n        ['134', '235', '361']\\n        \"\n    assert callable(fn), 'Input must be callable'\n    test_sf = self[:10]\n    dryrun = [fn(row) for row in test_sf]\n    if dtype is None:\n        dtype = SArray(dryrun).dtype\n    seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    nativefn = None\n    try:\n        from .. import extensions as extensions\n        nativefn = extensions._build_native_function_call(fn)\n    except:\n        pass\n    if nativefn is not None:\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, seed))\n    with cython_context():\n        return SArray(_proxy=self.__proxy__.transform(fn, dtype, seed))",
            "def apply(self, fn, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Transform each row to an :class:`~turicreate.SArray` according to a\\n        specified function. Returns a new SArray of ``dtype`` where each element\\n        in this SArray is transformed by `fn(x)` where `x` is a single row in\\n        the sframe represented as a dictionary.  The ``fn`` should return\\n        exactly one value which can be cast into type ``dtype``. If ``dtype`` is\\n        not specified, the first 100 rows of the SFrame are used to make a guess\\n        of the target data type.\\n\\n        Parameters\\n        ----------\\n        fn : function\\n            The function to transform each row of the SFrame. The return\\n            type should be convertible to `dtype` if `dtype` is not None.\\n            This can also be a toolkit extension function which is compiled\\n            as a native shared library using SDK.\\n\\n        dtype : dtype, optional\\n            The dtype of the new SArray. If None, the first 100\\n            elements of the array are used to guess the target\\n            data type.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray transformed by fn.  Each element of the SArray is of\\n            type ``dtype``\\n\\n        Examples\\n        --------\\n        Concatenate strings from several columns:\\n\\n        >>> sf = turicreate.SFrame({'user_id': [1, 2, 3], 'movie_id': [3, 3, 6],\\n                                  'rating': [4, 5, 1]})\\n        >>> sf.apply(lambda x: str(x['user_id']) + str(x['movie_id']) + str(x['rating']))\\n        dtype: str\\n        Rows: 3\\n        ['134', '235', '361']\\n        \"\n    assert callable(fn), 'Input must be callable'\n    test_sf = self[:10]\n    dryrun = [fn(row) for row in test_sf]\n    if dtype is None:\n        dtype = SArray(dryrun).dtype\n    seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    nativefn = None\n    try:\n        from .. import extensions as extensions\n        nativefn = extensions._build_native_function_call(fn)\n    except:\n        pass\n    if nativefn is not None:\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, seed))\n    with cython_context():\n        return SArray(_proxy=self.__proxy__.transform(fn, dtype, seed))",
            "def apply(self, fn, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Transform each row to an :class:`~turicreate.SArray` according to a\\n        specified function. Returns a new SArray of ``dtype`` where each element\\n        in this SArray is transformed by `fn(x)` where `x` is a single row in\\n        the sframe represented as a dictionary.  The ``fn`` should return\\n        exactly one value which can be cast into type ``dtype``. If ``dtype`` is\\n        not specified, the first 100 rows of the SFrame are used to make a guess\\n        of the target data type.\\n\\n        Parameters\\n        ----------\\n        fn : function\\n            The function to transform each row of the SFrame. The return\\n            type should be convertible to `dtype` if `dtype` is not None.\\n            This can also be a toolkit extension function which is compiled\\n            as a native shared library using SDK.\\n\\n        dtype : dtype, optional\\n            The dtype of the new SArray. If None, the first 100\\n            elements of the array are used to guess the target\\n            data type.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray transformed by fn.  Each element of the SArray is of\\n            type ``dtype``\\n\\n        Examples\\n        --------\\n        Concatenate strings from several columns:\\n\\n        >>> sf = turicreate.SFrame({'user_id': [1, 2, 3], 'movie_id': [3, 3, 6],\\n                                  'rating': [4, 5, 1]})\\n        >>> sf.apply(lambda x: str(x['user_id']) + str(x['movie_id']) + str(x['rating']))\\n        dtype: str\\n        Rows: 3\\n        ['134', '235', '361']\\n        \"\n    assert callable(fn), 'Input must be callable'\n    test_sf = self[:10]\n    dryrun = [fn(row) for row in test_sf]\n    if dtype is None:\n        dtype = SArray(dryrun).dtype\n    seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    nativefn = None\n    try:\n        from .. import extensions as extensions\n        nativefn = extensions._build_native_function_call(fn)\n    except:\n        pass\n    if nativefn is not None:\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, seed))\n    with cython_context():\n        return SArray(_proxy=self.__proxy__.transform(fn, dtype, seed))",
            "def apply(self, fn, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Transform each row to an :class:`~turicreate.SArray` according to a\\n        specified function. Returns a new SArray of ``dtype`` where each element\\n        in this SArray is transformed by `fn(x)` where `x` is a single row in\\n        the sframe represented as a dictionary.  The ``fn`` should return\\n        exactly one value which can be cast into type ``dtype``. If ``dtype`` is\\n        not specified, the first 100 rows of the SFrame are used to make a guess\\n        of the target data type.\\n\\n        Parameters\\n        ----------\\n        fn : function\\n            The function to transform each row of the SFrame. The return\\n            type should be convertible to `dtype` if `dtype` is not None.\\n            This can also be a toolkit extension function which is compiled\\n            as a native shared library using SDK.\\n\\n        dtype : dtype, optional\\n            The dtype of the new SArray. If None, the first 100\\n            elements of the array are used to guess the target\\n            data type.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray transformed by fn.  Each element of the SArray is of\\n            type ``dtype``\\n\\n        Examples\\n        --------\\n        Concatenate strings from several columns:\\n\\n        >>> sf = turicreate.SFrame({'user_id': [1, 2, 3], 'movie_id': [3, 3, 6],\\n                                  'rating': [4, 5, 1]})\\n        >>> sf.apply(lambda x: str(x['user_id']) + str(x['movie_id']) + str(x['rating']))\\n        dtype: str\\n        Rows: 3\\n        ['134', '235', '361']\\n        \"\n    assert callable(fn), 'Input must be callable'\n    test_sf = self[:10]\n    dryrun = [fn(row) for row in test_sf]\n    if dtype is None:\n        dtype = SArray(dryrun).dtype\n    seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    nativefn = None\n    try:\n        from .. import extensions as extensions\n        nativefn = extensions._build_native_function_call(fn)\n    except:\n        pass\n    if nativefn is not None:\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, seed))\n    with cython_context():\n        return SArray(_proxy=self.__proxy__.transform(fn, dtype, seed))",
            "def apply(self, fn, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Transform each row to an :class:`~turicreate.SArray` according to a\\n        specified function. Returns a new SArray of ``dtype`` where each element\\n        in this SArray is transformed by `fn(x)` where `x` is a single row in\\n        the sframe represented as a dictionary.  The ``fn`` should return\\n        exactly one value which can be cast into type ``dtype``. If ``dtype`` is\\n        not specified, the first 100 rows of the SFrame are used to make a guess\\n        of the target data type.\\n\\n        Parameters\\n        ----------\\n        fn : function\\n            The function to transform each row of the SFrame. The return\\n            type should be convertible to `dtype` if `dtype` is not None.\\n            This can also be a toolkit extension function which is compiled\\n            as a native shared library using SDK.\\n\\n        dtype : dtype, optional\\n            The dtype of the new SArray. If None, the first 100\\n            elements of the array are used to guess the target\\n            data type.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray transformed by fn.  Each element of the SArray is of\\n            type ``dtype``\\n\\n        Examples\\n        --------\\n        Concatenate strings from several columns:\\n\\n        >>> sf = turicreate.SFrame({'user_id': [1, 2, 3], 'movie_id': [3, 3, 6],\\n                                  'rating': [4, 5, 1]})\\n        >>> sf.apply(lambda x: str(x['user_id']) + str(x['movie_id']) + str(x['rating']))\\n        dtype: str\\n        Rows: 3\\n        ['134', '235', '361']\\n        \"\n    assert callable(fn), 'Input must be callable'\n    test_sf = self[:10]\n    dryrun = [fn(row) for row in test_sf]\n    if dtype is None:\n        dtype = SArray(dryrun).dtype\n    seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    nativefn = None\n    try:\n        from .. import extensions as extensions\n        nativefn = extensions._build_native_function_call(fn)\n    except:\n        pass\n    if nativefn is not None:\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, seed))\n    with cython_context():\n        return SArray(_proxy=self.__proxy__.transform(fn, dtype, seed))"
        ]
    },
    {
        "func_name": "flat_map",
        "original": "def flat_map(self, column_names, fn, column_types='auto', seed=None):\n    \"\"\"\n        Map each row of the SFrame to multiple rows in a new SFrame via a\n        function.\n\n        The output of `fn` must have type List[List[...]].  Each inner list\n        will be a single row in the new output, and the collection of these\n        rows within the outer list make up the data for the output SFrame.\n        All rows must have the same length and the same order of types to\n        make sure the result columns are homogeneously typed.  For example, if\n        the first element emitted into in the outer list by `fn` is\n        [43, 2.3, 'string'], then all other elements emitted into the outer\n        list must be a list with three elements, where the first is an int,\n        second is a float, and third is a string.  If column_types is not\n        specified, the first 10 rows of the SFrame are used to determine the\n        column types of the returned sframe.\n\n        Parameters\n        ----------\n        column_names : list[str]\n            The column names for the returned SFrame.\n\n        fn : function\n            The function that maps each of the sframe row into multiple rows,\n            returning List[List[...]].  All outputted rows must have the same\n            length and order of types.\n\n        column_types : list[type], optional\n            The column types of the output SFrame. Default value will be\n            automatically inferred by running `fn` on the first 10 rows of the\n            input. If the types cannot be inferred from the first 10 rows, an\n            error is raised.\n\n        seed : int, optional\n            Used as the seed if a random number generator is included in `fn`.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame containing the results of the flat_map of the\n            original SFrame.\n\n        Examples\n        ---------\n        Repeat each row according to the value in the 'number' column.\n\n        >>> sf = turicreate.SFrame({'letter': ['a', 'b', 'c'],\n        ...                       'number': [1, 2, 3]})\n        >>> sf.flat_map(['number', 'letter'],\n        ...             lambda x: [list(x.values()) for i in range(x['number'])])\n        +--------+--------+\n        | number | letter |\n        +--------+--------+\n        |   1    |   a    |\n        |   2    |   b    |\n        |   2    |   b    |\n        |   3    |   c    |\n        |   3    |   c    |\n        |   3    |   c    |\n        +--------+--------+\n        [6 rows x 2 columns]\n        \"\"\"\n    assert callable(fn), 'Input must be callable'\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if column_types == 'auto':\n        types = set()\n        sample = self[0:10]\n        results = [fn(row) for row in sample]\n        for rows in results:\n            if type(rows) is not list:\n                raise TypeError('Output type of the lambda function must be a list of lists')\n            for row in rows:\n                if type(row) is not list:\n                    raise TypeError('Output type of the lambda function must be a list of lists')\n                types.add(tuple([type(v) for v in row]))\n        if len(types) == 0:\n            raise TypeError('Could not infer output column types from the first ten rows ' + \"of the SFrame. Please use the 'column_types' parameter to \" + 'set the types.')\n        if len(types) > 1:\n            raise TypeError('Mapped rows must have the same length and types')\n        column_types = list(types.pop())\n    assert type(column_types) is list, \"'column_types' must be a list.\"\n    assert len(column_types) == len(column_names), 'Number of output columns must match the size of column names'\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.flat_map(fn, column_names, column_types, seed))",
        "mutated": [
            "def flat_map(self, column_names, fn, column_types='auto', seed=None):\n    if False:\n        i = 10\n    \"\\n        Map each row of the SFrame to multiple rows in a new SFrame via a\\n        function.\\n\\n        The output of `fn` must have type List[List[...]].  Each inner list\\n        will be a single row in the new output, and the collection of these\\n        rows within the outer list make up the data for the output SFrame.\\n        All rows must have the same length and the same order of types to\\n        make sure the result columns are homogeneously typed.  For example, if\\n        the first element emitted into in the outer list by `fn` is\\n        [43, 2.3, 'string'], then all other elements emitted into the outer\\n        list must be a list with three elements, where the first is an int,\\n        second is a float, and third is a string.  If column_types is not\\n        specified, the first 10 rows of the SFrame are used to determine the\\n        column types of the returned sframe.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str]\\n            The column names for the returned SFrame.\\n\\n        fn : function\\n            The function that maps each of the sframe row into multiple rows,\\n            returning List[List[...]].  All outputted rows must have the same\\n            length and order of types.\\n\\n        column_types : list[type], optional\\n            The column types of the output SFrame. Default value will be\\n            automatically inferred by running `fn` on the first 10 rows of the\\n            input. If the types cannot be inferred from the first 10 rows, an\\n            error is raised.\\n\\n        seed : int, optional\\n            Used as the seed if a random number generator is included in `fn`.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the results of the flat_map of the\\n            original SFrame.\\n\\n        Examples\\n        ---------\\n        Repeat each row according to the value in the 'number' column.\\n\\n        >>> sf = turicreate.SFrame({'letter': ['a', 'b', 'c'],\\n        ...                       'number': [1, 2, 3]})\\n        >>> sf.flat_map(['number', 'letter'],\\n        ...             lambda x: [list(x.values()) for i in range(x['number'])])\\n        +--------+--------+\\n        | number | letter |\\n        +--------+--------+\\n        |   1    |   a    |\\n        |   2    |   b    |\\n        |   2    |   b    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        +--------+--------+\\n        [6 rows x 2 columns]\\n        \"\n    assert callable(fn), 'Input must be callable'\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if column_types == 'auto':\n        types = set()\n        sample = self[0:10]\n        results = [fn(row) for row in sample]\n        for rows in results:\n            if type(rows) is not list:\n                raise TypeError('Output type of the lambda function must be a list of lists')\n            for row in rows:\n                if type(row) is not list:\n                    raise TypeError('Output type of the lambda function must be a list of lists')\n                types.add(tuple([type(v) for v in row]))\n        if len(types) == 0:\n            raise TypeError('Could not infer output column types from the first ten rows ' + \"of the SFrame. Please use the 'column_types' parameter to \" + 'set the types.')\n        if len(types) > 1:\n            raise TypeError('Mapped rows must have the same length and types')\n        column_types = list(types.pop())\n    assert type(column_types) is list, \"'column_types' must be a list.\"\n    assert len(column_types) == len(column_names), 'Number of output columns must match the size of column names'\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.flat_map(fn, column_names, column_types, seed))",
            "def flat_map(self, column_names, fn, column_types='auto', seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Map each row of the SFrame to multiple rows in a new SFrame via a\\n        function.\\n\\n        The output of `fn` must have type List[List[...]].  Each inner list\\n        will be a single row in the new output, and the collection of these\\n        rows within the outer list make up the data for the output SFrame.\\n        All rows must have the same length and the same order of types to\\n        make sure the result columns are homogeneously typed.  For example, if\\n        the first element emitted into in the outer list by `fn` is\\n        [43, 2.3, 'string'], then all other elements emitted into the outer\\n        list must be a list with three elements, where the first is an int,\\n        second is a float, and third is a string.  If column_types is not\\n        specified, the first 10 rows of the SFrame are used to determine the\\n        column types of the returned sframe.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str]\\n            The column names for the returned SFrame.\\n\\n        fn : function\\n            The function that maps each of the sframe row into multiple rows,\\n            returning List[List[...]].  All outputted rows must have the same\\n            length and order of types.\\n\\n        column_types : list[type], optional\\n            The column types of the output SFrame. Default value will be\\n            automatically inferred by running `fn` on the first 10 rows of the\\n            input. If the types cannot be inferred from the first 10 rows, an\\n            error is raised.\\n\\n        seed : int, optional\\n            Used as the seed if a random number generator is included in `fn`.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the results of the flat_map of the\\n            original SFrame.\\n\\n        Examples\\n        ---------\\n        Repeat each row according to the value in the 'number' column.\\n\\n        >>> sf = turicreate.SFrame({'letter': ['a', 'b', 'c'],\\n        ...                       'number': [1, 2, 3]})\\n        >>> sf.flat_map(['number', 'letter'],\\n        ...             lambda x: [list(x.values()) for i in range(x['number'])])\\n        +--------+--------+\\n        | number | letter |\\n        +--------+--------+\\n        |   1    |   a    |\\n        |   2    |   b    |\\n        |   2    |   b    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        +--------+--------+\\n        [6 rows x 2 columns]\\n        \"\n    assert callable(fn), 'Input must be callable'\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if column_types == 'auto':\n        types = set()\n        sample = self[0:10]\n        results = [fn(row) for row in sample]\n        for rows in results:\n            if type(rows) is not list:\n                raise TypeError('Output type of the lambda function must be a list of lists')\n            for row in rows:\n                if type(row) is not list:\n                    raise TypeError('Output type of the lambda function must be a list of lists')\n                types.add(tuple([type(v) for v in row]))\n        if len(types) == 0:\n            raise TypeError('Could not infer output column types from the first ten rows ' + \"of the SFrame. Please use the 'column_types' parameter to \" + 'set the types.')\n        if len(types) > 1:\n            raise TypeError('Mapped rows must have the same length and types')\n        column_types = list(types.pop())\n    assert type(column_types) is list, \"'column_types' must be a list.\"\n    assert len(column_types) == len(column_names), 'Number of output columns must match the size of column names'\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.flat_map(fn, column_names, column_types, seed))",
            "def flat_map(self, column_names, fn, column_types='auto', seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Map each row of the SFrame to multiple rows in a new SFrame via a\\n        function.\\n\\n        The output of `fn` must have type List[List[...]].  Each inner list\\n        will be a single row in the new output, and the collection of these\\n        rows within the outer list make up the data for the output SFrame.\\n        All rows must have the same length and the same order of types to\\n        make sure the result columns are homogeneously typed.  For example, if\\n        the first element emitted into in the outer list by `fn` is\\n        [43, 2.3, 'string'], then all other elements emitted into the outer\\n        list must be a list with three elements, where the first is an int,\\n        second is a float, and third is a string.  If column_types is not\\n        specified, the first 10 rows of the SFrame are used to determine the\\n        column types of the returned sframe.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str]\\n            The column names for the returned SFrame.\\n\\n        fn : function\\n            The function that maps each of the sframe row into multiple rows,\\n            returning List[List[...]].  All outputted rows must have the same\\n            length and order of types.\\n\\n        column_types : list[type], optional\\n            The column types of the output SFrame. Default value will be\\n            automatically inferred by running `fn` on the first 10 rows of the\\n            input. If the types cannot be inferred from the first 10 rows, an\\n            error is raised.\\n\\n        seed : int, optional\\n            Used as the seed if a random number generator is included in `fn`.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the results of the flat_map of the\\n            original SFrame.\\n\\n        Examples\\n        ---------\\n        Repeat each row according to the value in the 'number' column.\\n\\n        >>> sf = turicreate.SFrame({'letter': ['a', 'b', 'c'],\\n        ...                       'number': [1, 2, 3]})\\n        >>> sf.flat_map(['number', 'letter'],\\n        ...             lambda x: [list(x.values()) for i in range(x['number'])])\\n        +--------+--------+\\n        | number | letter |\\n        +--------+--------+\\n        |   1    |   a    |\\n        |   2    |   b    |\\n        |   2    |   b    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        +--------+--------+\\n        [6 rows x 2 columns]\\n        \"\n    assert callable(fn), 'Input must be callable'\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if column_types == 'auto':\n        types = set()\n        sample = self[0:10]\n        results = [fn(row) for row in sample]\n        for rows in results:\n            if type(rows) is not list:\n                raise TypeError('Output type of the lambda function must be a list of lists')\n            for row in rows:\n                if type(row) is not list:\n                    raise TypeError('Output type of the lambda function must be a list of lists')\n                types.add(tuple([type(v) for v in row]))\n        if len(types) == 0:\n            raise TypeError('Could not infer output column types from the first ten rows ' + \"of the SFrame. Please use the 'column_types' parameter to \" + 'set the types.')\n        if len(types) > 1:\n            raise TypeError('Mapped rows must have the same length and types')\n        column_types = list(types.pop())\n    assert type(column_types) is list, \"'column_types' must be a list.\"\n    assert len(column_types) == len(column_names), 'Number of output columns must match the size of column names'\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.flat_map(fn, column_names, column_types, seed))",
            "def flat_map(self, column_names, fn, column_types='auto', seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Map each row of the SFrame to multiple rows in a new SFrame via a\\n        function.\\n\\n        The output of `fn` must have type List[List[...]].  Each inner list\\n        will be a single row in the new output, and the collection of these\\n        rows within the outer list make up the data for the output SFrame.\\n        All rows must have the same length and the same order of types to\\n        make sure the result columns are homogeneously typed.  For example, if\\n        the first element emitted into in the outer list by `fn` is\\n        [43, 2.3, 'string'], then all other elements emitted into the outer\\n        list must be a list with three elements, where the first is an int,\\n        second is a float, and third is a string.  If column_types is not\\n        specified, the first 10 rows of the SFrame are used to determine the\\n        column types of the returned sframe.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str]\\n            The column names for the returned SFrame.\\n\\n        fn : function\\n            The function that maps each of the sframe row into multiple rows,\\n            returning List[List[...]].  All outputted rows must have the same\\n            length and order of types.\\n\\n        column_types : list[type], optional\\n            The column types of the output SFrame. Default value will be\\n            automatically inferred by running `fn` on the first 10 rows of the\\n            input. If the types cannot be inferred from the first 10 rows, an\\n            error is raised.\\n\\n        seed : int, optional\\n            Used as the seed if a random number generator is included in `fn`.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the results of the flat_map of the\\n            original SFrame.\\n\\n        Examples\\n        ---------\\n        Repeat each row according to the value in the 'number' column.\\n\\n        >>> sf = turicreate.SFrame({'letter': ['a', 'b', 'c'],\\n        ...                       'number': [1, 2, 3]})\\n        >>> sf.flat_map(['number', 'letter'],\\n        ...             lambda x: [list(x.values()) for i in range(x['number'])])\\n        +--------+--------+\\n        | number | letter |\\n        +--------+--------+\\n        |   1    |   a    |\\n        |   2    |   b    |\\n        |   2    |   b    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        +--------+--------+\\n        [6 rows x 2 columns]\\n        \"\n    assert callable(fn), 'Input must be callable'\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if column_types == 'auto':\n        types = set()\n        sample = self[0:10]\n        results = [fn(row) for row in sample]\n        for rows in results:\n            if type(rows) is not list:\n                raise TypeError('Output type of the lambda function must be a list of lists')\n            for row in rows:\n                if type(row) is not list:\n                    raise TypeError('Output type of the lambda function must be a list of lists')\n                types.add(tuple([type(v) for v in row]))\n        if len(types) == 0:\n            raise TypeError('Could not infer output column types from the first ten rows ' + \"of the SFrame. Please use the 'column_types' parameter to \" + 'set the types.')\n        if len(types) > 1:\n            raise TypeError('Mapped rows must have the same length and types')\n        column_types = list(types.pop())\n    assert type(column_types) is list, \"'column_types' must be a list.\"\n    assert len(column_types) == len(column_names), 'Number of output columns must match the size of column names'\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.flat_map(fn, column_names, column_types, seed))",
            "def flat_map(self, column_names, fn, column_types='auto', seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Map each row of the SFrame to multiple rows in a new SFrame via a\\n        function.\\n\\n        The output of `fn` must have type List[List[...]].  Each inner list\\n        will be a single row in the new output, and the collection of these\\n        rows within the outer list make up the data for the output SFrame.\\n        All rows must have the same length and the same order of types to\\n        make sure the result columns are homogeneously typed.  For example, if\\n        the first element emitted into in the outer list by `fn` is\\n        [43, 2.3, 'string'], then all other elements emitted into the outer\\n        list must be a list with three elements, where the first is an int,\\n        second is a float, and third is a string.  If column_types is not\\n        specified, the first 10 rows of the SFrame are used to determine the\\n        column types of the returned sframe.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str]\\n            The column names for the returned SFrame.\\n\\n        fn : function\\n            The function that maps each of the sframe row into multiple rows,\\n            returning List[List[...]].  All outputted rows must have the same\\n            length and order of types.\\n\\n        column_types : list[type], optional\\n            The column types of the output SFrame. Default value will be\\n            automatically inferred by running `fn` on the first 10 rows of the\\n            input. If the types cannot be inferred from the first 10 rows, an\\n            error is raised.\\n\\n        seed : int, optional\\n            Used as the seed if a random number generator is included in `fn`.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the results of the flat_map of the\\n            original SFrame.\\n\\n        Examples\\n        ---------\\n        Repeat each row according to the value in the 'number' column.\\n\\n        >>> sf = turicreate.SFrame({'letter': ['a', 'b', 'c'],\\n        ...                       'number': [1, 2, 3]})\\n        >>> sf.flat_map(['number', 'letter'],\\n        ...             lambda x: [list(x.values()) for i in range(x['number'])])\\n        +--------+--------+\\n        | number | letter |\\n        +--------+--------+\\n        |   1    |   a    |\\n        |   2    |   b    |\\n        |   2    |   b    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        |   3    |   c    |\\n        +--------+--------+\\n        [6 rows x 2 columns]\\n        \"\n    assert callable(fn), 'Input must be callable'\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if column_types == 'auto':\n        types = set()\n        sample = self[0:10]\n        results = [fn(row) for row in sample]\n        for rows in results:\n            if type(rows) is not list:\n                raise TypeError('Output type of the lambda function must be a list of lists')\n            for row in rows:\n                if type(row) is not list:\n                    raise TypeError('Output type of the lambda function must be a list of lists')\n                types.add(tuple([type(v) for v in row]))\n        if len(types) == 0:\n            raise TypeError('Could not infer output column types from the first ten rows ' + \"of the SFrame. Please use the 'column_types' parameter to \" + 'set the types.')\n        if len(types) > 1:\n            raise TypeError('Mapped rows must have the same length and types')\n        column_types = list(types.pop())\n    assert type(column_types) is list, \"'column_types' must be a list.\"\n    assert len(column_types) == len(column_names), 'Number of output columns must match the size of column names'\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.flat_map(fn, column_names, column_types, seed))"
        ]
    },
    {
        "func_name": "sample",
        "original": "def sample(self, fraction, seed=None, exact=False):\n    \"\"\"\n        Sample a fraction of the current SFrame's rows.\n\n        Parameters\n        ----------\n        fraction : float\n            Fraction of the rows to fetch. Must be between 0 and 1.\n            if exact is False (default), the number of rows returned is\n            approximately the fraction times the number of rows.\n\n        seed : int, optional\n            Seed for the random number generator used to sample.\n\n        exact: bool, optional\n            Defaults to False. If exact=True, an exact fraction is returned,\n            but at a performance penalty.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame containing sampled rows of the current SFrame.\n\n        Examples\n        --------\n        Suppose we have an SFrame with 6,145 rows.\n\n        >>> import random\n        >>> sf = SFrame({'id': range(0, 6145)})\n\n        Retrieve about 30% of the SFrame rows with repeatable results by\n        setting the random seed.\n\n        >>> len(sf.sample(.3, seed=5))\n        1783\n        \"\"\"\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return self\n    else:\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.sample(fraction, seed, exact))",
        "mutated": [
            "def sample(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n    \"\\n        Sample a fraction of the current SFrame's rows.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to sample.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing sampled rows of the current SFrame.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 6,145 rows.\\n\\n        >>> import random\\n        >>> sf = SFrame({'id': range(0, 6145)})\\n\\n        Retrieve about 30% of the SFrame rows with repeatable results by\\n        setting the random seed.\\n\\n        >>> len(sf.sample(.3, seed=5))\\n        1783\\n        \"\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return self\n    else:\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.sample(fraction, seed, exact))",
            "def sample(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Sample a fraction of the current SFrame's rows.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to sample.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing sampled rows of the current SFrame.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 6,145 rows.\\n\\n        >>> import random\\n        >>> sf = SFrame({'id': range(0, 6145)})\\n\\n        Retrieve about 30% of the SFrame rows with repeatable results by\\n        setting the random seed.\\n\\n        >>> len(sf.sample(.3, seed=5))\\n        1783\\n        \"\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return self\n    else:\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.sample(fraction, seed, exact))",
            "def sample(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Sample a fraction of the current SFrame's rows.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to sample.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing sampled rows of the current SFrame.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 6,145 rows.\\n\\n        >>> import random\\n        >>> sf = SFrame({'id': range(0, 6145)})\\n\\n        Retrieve about 30% of the SFrame rows with repeatable results by\\n        setting the random seed.\\n\\n        >>> len(sf.sample(.3, seed=5))\\n        1783\\n        \"\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return self\n    else:\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.sample(fraction, seed, exact))",
            "def sample(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Sample a fraction of the current SFrame's rows.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to sample.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing sampled rows of the current SFrame.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 6,145 rows.\\n\\n        >>> import random\\n        >>> sf = SFrame({'id': range(0, 6145)})\\n\\n        Retrieve about 30% of the SFrame rows with repeatable results by\\n        setting the random seed.\\n\\n        >>> len(sf.sample(.3, seed=5))\\n        1783\\n        \"\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return self\n    else:\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.sample(fraction, seed, exact))",
            "def sample(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Sample a fraction of the current SFrame's rows.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to sample.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing sampled rows of the current SFrame.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 6,145 rows.\\n\\n        >>> import random\\n        >>> sf = SFrame({'id': range(0, 6145)})\\n\\n        Retrieve about 30% of the SFrame rows with repeatable results by\\n        setting the random seed.\\n\\n        >>> len(sf.sample(.3, seed=5))\\n        1783\\n        \"\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return self\n    else:\n        with cython_context():\n            return SFrame(_proxy=self.__proxy__.sample(fraction, seed, exact))"
        ]
    },
    {
        "func_name": "shuffle",
        "original": "def shuffle(self):\n    \"\"\"\n        Randomly shuffles the rows of the SFrame.\n\n        Returns\n        -------\n        out : [SFrame]\n            An SFrame with all the same rows but with the rows in a random order.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({\"nums\": [1, 2, 3, 4],\n                                    \"letters\": [\"a\", \"b\", \"c\", \"d\"]})\n        >>> shuffled_sf = sf.shuffle()\n        >>> print(shuffled_sf)\n        +---------+------+\n        | letters | nums |\n        +---------+------+\n        |    d    |  4   |\n        |    c    |  3   |\n        |    a    |  1   |\n        |    b    |  2   |\n        +---------+------+\n        [4 rows x 2 columns]\n        \"\"\"\n    return SFrame(_proxy=self.__proxy__.shuffle())",
        "mutated": [
            "def shuffle(self):\n    if False:\n        i = 10\n    '\\n        Randomly shuffles the rows of the SFrame.\\n\\n        Returns\\n        -------\\n        out : [SFrame]\\n            An SFrame with all the same rows but with the rows in a random order.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({\"nums\": [1, 2, 3, 4],\\n                                    \"letters\": [\"a\", \"b\", \"c\", \"d\"]})\\n        >>> shuffled_sf = sf.shuffle()\\n        >>> print(shuffled_sf)\\n        +---------+------+\\n        | letters | nums |\\n        +---------+------+\\n        |    d    |  4   |\\n        |    c    |  3   |\\n        |    a    |  1   |\\n        |    b    |  2   |\\n        +---------+------+\\n        [4 rows x 2 columns]\\n        '\n    return SFrame(_proxy=self.__proxy__.shuffle())",
            "def shuffle(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Randomly shuffles the rows of the SFrame.\\n\\n        Returns\\n        -------\\n        out : [SFrame]\\n            An SFrame with all the same rows but with the rows in a random order.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({\"nums\": [1, 2, 3, 4],\\n                                    \"letters\": [\"a\", \"b\", \"c\", \"d\"]})\\n        >>> shuffled_sf = sf.shuffle()\\n        >>> print(shuffled_sf)\\n        +---------+------+\\n        | letters | nums |\\n        +---------+------+\\n        |    d    |  4   |\\n        |    c    |  3   |\\n        |    a    |  1   |\\n        |    b    |  2   |\\n        +---------+------+\\n        [4 rows x 2 columns]\\n        '\n    return SFrame(_proxy=self.__proxy__.shuffle())",
            "def shuffle(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Randomly shuffles the rows of the SFrame.\\n\\n        Returns\\n        -------\\n        out : [SFrame]\\n            An SFrame with all the same rows but with the rows in a random order.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({\"nums\": [1, 2, 3, 4],\\n                                    \"letters\": [\"a\", \"b\", \"c\", \"d\"]})\\n        >>> shuffled_sf = sf.shuffle()\\n        >>> print(shuffled_sf)\\n        +---------+------+\\n        | letters | nums |\\n        +---------+------+\\n        |    d    |  4   |\\n        |    c    |  3   |\\n        |    a    |  1   |\\n        |    b    |  2   |\\n        +---------+------+\\n        [4 rows x 2 columns]\\n        '\n    return SFrame(_proxy=self.__proxy__.shuffle())",
            "def shuffle(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Randomly shuffles the rows of the SFrame.\\n\\n        Returns\\n        -------\\n        out : [SFrame]\\n            An SFrame with all the same rows but with the rows in a random order.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({\"nums\": [1, 2, 3, 4],\\n                                    \"letters\": [\"a\", \"b\", \"c\", \"d\"]})\\n        >>> shuffled_sf = sf.shuffle()\\n        >>> print(shuffled_sf)\\n        +---------+------+\\n        | letters | nums |\\n        +---------+------+\\n        |    d    |  4   |\\n        |    c    |  3   |\\n        |    a    |  1   |\\n        |    b    |  2   |\\n        +---------+------+\\n        [4 rows x 2 columns]\\n        '\n    return SFrame(_proxy=self.__proxy__.shuffle())",
            "def shuffle(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Randomly shuffles the rows of the SFrame.\\n\\n        Returns\\n        -------\\n        out : [SFrame]\\n            An SFrame with all the same rows but with the rows in a random order.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({\"nums\": [1, 2, 3, 4],\\n                                    \"letters\": [\"a\", \"b\", \"c\", \"d\"]})\\n        >>> shuffled_sf = sf.shuffle()\\n        >>> print(shuffled_sf)\\n        +---------+------+\\n        | letters | nums |\\n        +---------+------+\\n        |    d    |  4   |\\n        |    c    |  3   |\\n        |    a    |  1   |\\n        |    b    |  2   |\\n        +---------+------+\\n        [4 rows x 2 columns]\\n        '\n    return SFrame(_proxy=self.__proxy__.shuffle())"
        ]
    },
    {
        "func_name": "random_split",
        "original": "def random_split(self, fraction, seed=None, exact=False):\n    \"\"\"\n        Randomly split the rows of an SFrame into two SFrames. The first SFrame\n        contains *M* rows, sampled uniformly (without replacement) from the\n        original SFrame. *M* is approximately the fraction times the original\n        number of rows. The second SFrame contains the remaining rows of the\n        original SFrame.\n\n        An exact fraction partition can be optionally obtained by setting\n        exact=True.\n\n        Parameters\n        ----------\n        fraction : float\n            Fraction of the rows to fetch. Must be between 0 and 1.\n            if exact is False (default), the number of rows returned is\n            approximately the fraction times the number of rows.\n\n        seed : int, optional\n            Seed for the random number generator used to split.\n\n        exact: bool, optional\n            Defaults to False. If exact=True, an exact fraction is returned,\n            but at a performance penalty.\n\n        Returns\n        -------\n        out : tuple [SFrame]\n            Two new SFrames.\n\n        Examples\n        --------\n        Suppose we have an SFrame with 1,024 rows and we want to randomly split\n        it into training and testing datasets with about a 90%/10% split.\n\n        >>> sf = turicreate.SFrame({'id': range(1024)})\n        >>> sf_train, sf_test = sf.random_split(.9, seed=5)\n        >>> print(len(sf_train), len(sf_test))\n        922 102\n        \"\"\"\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return (SFrame(), SFrame())\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    try:\n        seed = int(seed)\n    except ValueError:\n        raise ValueError(\"The 'seed' parameter must be of type int.\")\n    with cython_context():\n        proxy_pair = self.__proxy__.random_split(fraction, seed, exact)\n        return (SFrame(data=[], _proxy=proxy_pair[0]), SFrame(data=[], _proxy=proxy_pair[1]))",
        "mutated": [
            "def random_split(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n    \"\\n        Randomly split the rows of an SFrame into two SFrames. The first SFrame\\n        contains *M* rows, sampled uniformly (without replacement) from the\\n        original SFrame. *M* is approximately the fraction times the original\\n        number of rows. The second SFrame contains the remaining rows of the\\n        original SFrame.\\n\\n        An exact fraction partition can be optionally obtained by setting\\n        exact=True.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to split.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : tuple [SFrame]\\n            Two new SFrames.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 1,024 rows and we want to randomly split\\n        it into training and testing datasets with about a 90%/10% split.\\n\\n        >>> sf = turicreate.SFrame({'id': range(1024)})\\n        >>> sf_train, sf_test = sf.random_split(.9, seed=5)\\n        >>> print(len(sf_train), len(sf_test))\\n        922 102\\n        \"\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return (SFrame(), SFrame())\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    try:\n        seed = int(seed)\n    except ValueError:\n        raise ValueError(\"The 'seed' parameter must be of type int.\")\n    with cython_context():\n        proxy_pair = self.__proxy__.random_split(fraction, seed, exact)\n        return (SFrame(data=[], _proxy=proxy_pair[0]), SFrame(data=[], _proxy=proxy_pair[1]))",
            "def random_split(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Randomly split the rows of an SFrame into two SFrames. The first SFrame\\n        contains *M* rows, sampled uniformly (without replacement) from the\\n        original SFrame. *M* is approximately the fraction times the original\\n        number of rows. The second SFrame contains the remaining rows of the\\n        original SFrame.\\n\\n        An exact fraction partition can be optionally obtained by setting\\n        exact=True.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to split.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : tuple [SFrame]\\n            Two new SFrames.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 1,024 rows and we want to randomly split\\n        it into training and testing datasets with about a 90%/10% split.\\n\\n        >>> sf = turicreate.SFrame({'id': range(1024)})\\n        >>> sf_train, sf_test = sf.random_split(.9, seed=5)\\n        >>> print(len(sf_train), len(sf_test))\\n        922 102\\n        \"\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return (SFrame(), SFrame())\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    try:\n        seed = int(seed)\n    except ValueError:\n        raise ValueError(\"The 'seed' parameter must be of type int.\")\n    with cython_context():\n        proxy_pair = self.__proxy__.random_split(fraction, seed, exact)\n        return (SFrame(data=[], _proxy=proxy_pair[0]), SFrame(data=[], _proxy=proxy_pair[1]))",
            "def random_split(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Randomly split the rows of an SFrame into two SFrames. The first SFrame\\n        contains *M* rows, sampled uniformly (without replacement) from the\\n        original SFrame. *M* is approximately the fraction times the original\\n        number of rows. The second SFrame contains the remaining rows of the\\n        original SFrame.\\n\\n        An exact fraction partition can be optionally obtained by setting\\n        exact=True.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to split.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : tuple [SFrame]\\n            Two new SFrames.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 1,024 rows and we want to randomly split\\n        it into training and testing datasets with about a 90%/10% split.\\n\\n        >>> sf = turicreate.SFrame({'id': range(1024)})\\n        >>> sf_train, sf_test = sf.random_split(.9, seed=5)\\n        >>> print(len(sf_train), len(sf_test))\\n        922 102\\n        \"\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return (SFrame(), SFrame())\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    try:\n        seed = int(seed)\n    except ValueError:\n        raise ValueError(\"The 'seed' parameter must be of type int.\")\n    with cython_context():\n        proxy_pair = self.__proxy__.random_split(fraction, seed, exact)\n        return (SFrame(data=[], _proxy=proxy_pair[0]), SFrame(data=[], _proxy=proxy_pair[1]))",
            "def random_split(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Randomly split the rows of an SFrame into two SFrames. The first SFrame\\n        contains *M* rows, sampled uniformly (without replacement) from the\\n        original SFrame. *M* is approximately the fraction times the original\\n        number of rows. The second SFrame contains the remaining rows of the\\n        original SFrame.\\n\\n        An exact fraction partition can be optionally obtained by setting\\n        exact=True.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to split.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : tuple [SFrame]\\n            Two new SFrames.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 1,024 rows and we want to randomly split\\n        it into training and testing datasets with about a 90%/10% split.\\n\\n        >>> sf = turicreate.SFrame({'id': range(1024)})\\n        >>> sf_train, sf_test = sf.random_split(.9, seed=5)\\n        >>> print(len(sf_train), len(sf_test))\\n        922 102\\n        \"\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return (SFrame(), SFrame())\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    try:\n        seed = int(seed)\n    except ValueError:\n        raise ValueError(\"The 'seed' parameter must be of type int.\")\n    with cython_context():\n        proxy_pair = self.__proxy__.random_split(fraction, seed, exact)\n        return (SFrame(data=[], _proxy=proxy_pair[0]), SFrame(data=[], _proxy=proxy_pair[1]))",
            "def random_split(self, fraction, seed=None, exact=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Randomly split the rows of an SFrame into two SFrames. The first SFrame\\n        contains *M* rows, sampled uniformly (without replacement) from the\\n        original SFrame. *M* is approximately the fraction times the original\\n        number of rows. The second SFrame contains the remaining rows of the\\n        original SFrame.\\n\\n        An exact fraction partition can be optionally obtained by setting\\n        exact=True.\\n\\n        Parameters\\n        ----------\\n        fraction : float\\n            Fraction of the rows to fetch. Must be between 0 and 1.\\n            if exact is False (default), the number of rows returned is\\n            approximately the fraction times the number of rows.\\n\\n        seed : int, optional\\n            Seed for the random number generator used to split.\\n\\n        exact: bool, optional\\n            Defaults to False. If exact=True, an exact fraction is returned,\\n            but at a performance penalty.\\n\\n        Returns\\n        -------\\n        out : tuple [SFrame]\\n            Two new SFrames.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with 1,024 rows and we want to randomly split\\n        it into training and testing datasets with about a 90%/10% split.\\n\\n        >>> sf = turicreate.SFrame({'id': range(1024)})\\n        >>> sf_train, sf_test = sf.random_split(.9, seed=5)\\n        >>> print(len(sf_train), len(sf_test))\\n        922 102\\n        \"\n    if fraction > 1 or fraction < 0:\n        raise ValueError('Invalid sampling rate: ' + str(fraction))\n    if self.num_rows() == 0 or self.num_columns() == 0:\n        return (SFrame(), SFrame())\n    if seed is None:\n        seed = abs(hash('%0.20f' % time.time())) % 2 ** 31\n    try:\n        seed = int(seed)\n    except ValueError:\n        raise ValueError(\"The 'seed' parameter must be of type int.\")\n    with cython_context():\n        proxy_pair = self.__proxy__.random_split(fraction, seed, exact)\n        return (SFrame(data=[], _proxy=proxy_pair[0]), SFrame(data=[], _proxy=proxy_pair[1]))"
        ]
    },
    {
        "func_name": "topk",
        "original": "def topk(self, column_name, k=10, reverse=False):\n    \"\"\"\n        Get top k rows according to the given column. Result is according to and\n        sorted by `column_name` in the given order (default is descending).\n        When `k` is small, `topk` is more efficient than `sort`.\n\n        Parameters\n        ----------\n        column_name : string\n            The column to sort on\n\n        k : int, optional\n            The number of rows to return\n\n        reverse : bool, optional\n            If True, return the top k rows in ascending order, otherwise, in\n            descending order.\n\n        Returns\n        -------\n        out : SFrame\n            an SFrame containing the top k rows sorted by column_name.\n\n        See Also\n        --------\n        sort\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': range(1000)})\n        >>> sf['value'] = -sf['id']\n        >>> sf.topk('id', k=3)\n        +--------+--------+\n        |   id   |  value |\n        +--------+--------+\n        |   999  |  -999  |\n        |   998  |  -998  |\n        |   997  |  -997  |\n        +--------+--------+\n        [3 rows x 2 columns]\n\n        >>> sf.topk('value', k=3)\n        +--------+--------+\n        |   id   |  value |\n        +--------+--------+\n        |   1    |  -1    |\n        |   2    |  -2    |\n        |   3    |  -3    |\n        +--------+--------+\n        [3 rows x 2 columns]\n        \"\"\"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a string')\n    sf = self[self[column_name].is_topk(k, reverse)]\n    return sf.sort(column_name, ascending=reverse)",
        "mutated": [
            "def topk(self, column_name, k=10, reverse=False):\n    if False:\n        i = 10\n    \"\\n        Get top k rows according to the given column. Result is according to and\\n        sorted by `column_name` in the given order (default is descending).\\n        When `k` is small, `topk` is more efficient than `sort`.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The column to sort on\\n\\n        k : int, optional\\n            The number of rows to return\\n\\n        reverse : bool, optional\\n            If True, return the top k rows in ascending order, otherwise, in\\n            descending order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            an SFrame containing the top k rows sorted by column_name.\\n\\n        See Also\\n        --------\\n        sort\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': range(1000)})\\n        >>> sf['value'] = -sf['id']\\n        >>> sf.topk('id', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   999  |  -999  |\\n        |   998  |  -998  |\\n        |   997  |  -997  |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.topk('value', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   1    |  -1    |\\n        |   2    |  -2    |\\n        |   3    |  -3    |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a string')\n    sf = self[self[column_name].is_topk(k, reverse)]\n    return sf.sort(column_name, ascending=reverse)",
            "def topk(self, column_name, k=10, reverse=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Get top k rows according to the given column. Result is according to and\\n        sorted by `column_name` in the given order (default is descending).\\n        When `k` is small, `topk` is more efficient than `sort`.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The column to sort on\\n\\n        k : int, optional\\n            The number of rows to return\\n\\n        reverse : bool, optional\\n            If True, return the top k rows in ascending order, otherwise, in\\n            descending order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            an SFrame containing the top k rows sorted by column_name.\\n\\n        See Also\\n        --------\\n        sort\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': range(1000)})\\n        >>> sf['value'] = -sf['id']\\n        >>> sf.topk('id', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   999  |  -999  |\\n        |   998  |  -998  |\\n        |   997  |  -997  |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.topk('value', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   1    |  -1    |\\n        |   2    |  -2    |\\n        |   3    |  -3    |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a string')\n    sf = self[self[column_name].is_topk(k, reverse)]\n    return sf.sort(column_name, ascending=reverse)",
            "def topk(self, column_name, k=10, reverse=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Get top k rows according to the given column. Result is according to and\\n        sorted by `column_name` in the given order (default is descending).\\n        When `k` is small, `topk` is more efficient than `sort`.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The column to sort on\\n\\n        k : int, optional\\n            The number of rows to return\\n\\n        reverse : bool, optional\\n            If True, return the top k rows in ascending order, otherwise, in\\n            descending order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            an SFrame containing the top k rows sorted by column_name.\\n\\n        See Also\\n        --------\\n        sort\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': range(1000)})\\n        >>> sf['value'] = -sf['id']\\n        >>> sf.topk('id', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   999  |  -999  |\\n        |   998  |  -998  |\\n        |   997  |  -997  |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.topk('value', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   1    |  -1    |\\n        |   2    |  -2    |\\n        |   3    |  -3    |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a string')\n    sf = self[self[column_name].is_topk(k, reverse)]\n    return sf.sort(column_name, ascending=reverse)",
            "def topk(self, column_name, k=10, reverse=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Get top k rows according to the given column. Result is according to and\\n        sorted by `column_name` in the given order (default is descending).\\n        When `k` is small, `topk` is more efficient than `sort`.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The column to sort on\\n\\n        k : int, optional\\n            The number of rows to return\\n\\n        reverse : bool, optional\\n            If True, return the top k rows in ascending order, otherwise, in\\n            descending order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            an SFrame containing the top k rows sorted by column_name.\\n\\n        See Also\\n        --------\\n        sort\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': range(1000)})\\n        >>> sf['value'] = -sf['id']\\n        >>> sf.topk('id', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   999  |  -999  |\\n        |   998  |  -998  |\\n        |   997  |  -997  |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.topk('value', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   1    |  -1    |\\n        |   2    |  -2    |\\n        |   3    |  -3    |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a string')\n    sf = self[self[column_name].is_topk(k, reverse)]\n    return sf.sort(column_name, ascending=reverse)",
            "def topk(self, column_name, k=10, reverse=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Get top k rows according to the given column. Result is according to and\\n        sorted by `column_name` in the given order (default is descending).\\n        When `k` is small, `topk` is more efficient than `sort`.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The column to sort on\\n\\n        k : int, optional\\n            The number of rows to return\\n\\n        reverse : bool, optional\\n            If True, return the top k rows in ascending order, otherwise, in\\n            descending order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            an SFrame containing the top k rows sorted by column_name.\\n\\n        See Also\\n        --------\\n        sort\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': range(1000)})\\n        >>> sf['value'] = -sf['id']\\n        >>> sf.topk('id', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   999  |  -999  |\\n        |   998  |  -998  |\\n        |   997  |  -997  |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.topk('value', k=3)\\n        +--------+--------+\\n        |   id   |  value |\\n        +--------+--------+\\n        |   1    |  -1    |\\n        |   2    |  -2    |\\n        |   3    |  -3    |\\n        +--------+--------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a string')\n    sf = self[self[column_name].is_topk(k, reverse)]\n    return sf.sort(column_name, ascending=reverse)"
        ]
    },
    {
        "func_name": "save",
        "original": "def save(self, filename, format=None):\n    \"\"\"\n        Save the SFrame to a file system for later use.\n\n        Parameters\n        ----------\n        filename : string\n            The location to save the SFrame. Either a local directory or a\n            remote URL. If the format is 'binary', a directory will be created\n            at the location which will contain the sframe.\n\n        format : {'binary', 'csv', 'json'}, optional\n            Format in which to save the SFrame. Binary saved SFrames can be\n            loaded much faster and without any format conversion losses. If not\n            given, will try to infer the format from filename given. If file\n            name ends with 'csv' or '.csv.gz', then save as 'csv' format,\n            otherwise save as 'binary' format.\n            See export_csv for more csv saving options.\n\n        See Also\n        --------\n        load_sframe, SFrame\n\n        Examples\n        --------\n        >>> # Save the sframe into binary format\n        >>> sf.save('data/training_data_sframe')\n\n        >>> # Save the sframe into csv format\n        >>> sf.save('data/training_data.csv', format='csv')\n        \"\"\"\n    if format is None:\n        if filename.endswith(('.csv', '.csv.gz')):\n            format = 'csv'\n        elif filename.endswith('.json'):\n            format = 'json'\n        else:\n            format = 'binary'\n    elif format == 'csv':\n        if not filename.endswith(('.csv', '.csv.gz')):\n            filename = filename + '.csv'\n    elif format != 'binary' and format != 'json':\n        raise ValueError(\"Invalid format: {}. Supported formats are 'csv' and 'binary' and 'json'\".format(format))\n    url = _make_internal_url(filename)\n    with cython_context():\n        if format == 'binary':\n            self.__proxy__.save(url)\n        elif format == 'csv':\n            assert filename.endswith(('.csv', '.csv.gz'))\n            self.__proxy__.save_as_csv(url, {})\n        elif format == 'json':\n            self.export_json(url)\n        else:\n            raise ValueError('Unsupported format: {}'.format(format))",
        "mutated": [
            "def save(self, filename, format=None):\n    if False:\n        i = 10\n    \"\\n        Save the SFrame to a file system for later use.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL. If the format is 'binary', a directory will be created\\n            at the location which will contain the sframe.\\n\\n        format : {'binary', 'csv', 'json'}, optional\\n            Format in which to save the SFrame. Binary saved SFrames can be\\n            loaded much faster and without any format conversion losses. If not\\n            given, will try to infer the format from filename given. If file\\n            name ends with 'csv' or '.csv.gz', then save as 'csv' format,\\n            otherwise save as 'binary' format.\\n            See export_csv for more csv saving options.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save('data/training_data_sframe')\\n\\n        >>> # Save the sframe into csv format\\n        >>> sf.save('data/training_data.csv', format='csv')\\n        \"\n    if format is None:\n        if filename.endswith(('.csv', '.csv.gz')):\n            format = 'csv'\n        elif filename.endswith('.json'):\n            format = 'json'\n        else:\n            format = 'binary'\n    elif format == 'csv':\n        if not filename.endswith(('.csv', '.csv.gz')):\n            filename = filename + '.csv'\n    elif format != 'binary' and format != 'json':\n        raise ValueError(\"Invalid format: {}. Supported formats are 'csv' and 'binary' and 'json'\".format(format))\n    url = _make_internal_url(filename)\n    with cython_context():\n        if format == 'binary':\n            self.__proxy__.save(url)\n        elif format == 'csv':\n            assert filename.endswith(('.csv', '.csv.gz'))\n            self.__proxy__.save_as_csv(url, {})\n        elif format == 'json':\n            self.export_json(url)\n        else:\n            raise ValueError('Unsupported format: {}'.format(format))",
            "def save(self, filename, format=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Save the SFrame to a file system for later use.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL. If the format is 'binary', a directory will be created\\n            at the location which will contain the sframe.\\n\\n        format : {'binary', 'csv', 'json'}, optional\\n            Format in which to save the SFrame. Binary saved SFrames can be\\n            loaded much faster and without any format conversion losses. If not\\n            given, will try to infer the format from filename given. If file\\n            name ends with 'csv' or '.csv.gz', then save as 'csv' format,\\n            otherwise save as 'binary' format.\\n            See export_csv for more csv saving options.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save('data/training_data_sframe')\\n\\n        >>> # Save the sframe into csv format\\n        >>> sf.save('data/training_data.csv', format='csv')\\n        \"\n    if format is None:\n        if filename.endswith(('.csv', '.csv.gz')):\n            format = 'csv'\n        elif filename.endswith('.json'):\n            format = 'json'\n        else:\n            format = 'binary'\n    elif format == 'csv':\n        if not filename.endswith(('.csv', '.csv.gz')):\n            filename = filename + '.csv'\n    elif format != 'binary' and format != 'json':\n        raise ValueError(\"Invalid format: {}. Supported formats are 'csv' and 'binary' and 'json'\".format(format))\n    url = _make_internal_url(filename)\n    with cython_context():\n        if format == 'binary':\n            self.__proxy__.save(url)\n        elif format == 'csv':\n            assert filename.endswith(('.csv', '.csv.gz'))\n            self.__proxy__.save_as_csv(url, {})\n        elif format == 'json':\n            self.export_json(url)\n        else:\n            raise ValueError('Unsupported format: {}'.format(format))",
            "def save(self, filename, format=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Save the SFrame to a file system for later use.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL. If the format is 'binary', a directory will be created\\n            at the location which will contain the sframe.\\n\\n        format : {'binary', 'csv', 'json'}, optional\\n            Format in which to save the SFrame. Binary saved SFrames can be\\n            loaded much faster and without any format conversion losses. If not\\n            given, will try to infer the format from filename given. If file\\n            name ends with 'csv' or '.csv.gz', then save as 'csv' format,\\n            otherwise save as 'binary' format.\\n            See export_csv for more csv saving options.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save('data/training_data_sframe')\\n\\n        >>> # Save the sframe into csv format\\n        >>> sf.save('data/training_data.csv', format='csv')\\n        \"\n    if format is None:\n        if filename.endswith(('.csv', '.csv.gz')):\n            format = 'csv'\n        elif filename.endswith('.json'):\n            format = 'json'\n        else:\n            format = 'binary'\n    elif format == 'csv':\n        if not filename.endswith(('.csv', '.csv.gz')):\n            filename = filename + '.csv'\n    elif format != 'binary' and format != 'json':\n        raise ValueError(\"Invalid format: {}. Supported formats are 'csv' and 'binary' and 'json'\".format(format))\n    url = _make_internal_url(filename)\n    with cython_context():\n        if format == 'binary':\n            self.__proxy__.save(url)\n        elif format == 'csv':\n            assert filename.endswith(('.csv', '.csv.gz'))\n            self.__proxy__.save_as_csv(url, {})\n        elif format == 'json':\n            self.export_json(url)\n        else:\n            raise ValueError('Unsupported format: {}'.format(format))",
            "def save(self, filename, format=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Save the SFrame to a file system for later use.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL. If the format is 'binary', a directory will be created\\n            at the location which will contain the sframe.\\n\\n        format : {'binary', 'csv', 'json'}, optional\\n            Format in which to save the SFrame. Binary saved SFrames can be\\n            loaded much faster and without any format conversion losses. If not\\n            given, will try to infer the format from filename given. If file\\n            name ends with 'csv' or '.csv.gz', then save as 'csv' format,\\n            otherwise save as 'binary' format.\\n            See export_csv for more csv saving options.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save('data/training_data_sframe')\\n\\n        >>> # Save the sframe into csv format\\n        >>> sf.save('data/training_data.csv', format='csv')\\n        \"\n    if format is None:\n        if filename.endswith(('.csv', '.csv.gz')):\n            format = 'csv'\n        elif filename.endswith('.json'):\n            format = 'json'\n        else:\n            format = 'binary'\n    elif format == 'csv':\n        if not filename.endswith(('.csv', '.csv.gz')):\n            filename = filename + '.csv'\n    elif format != 'binary' and format != 'json':\n        raise ValueError(\"Invalid format: {}. Supported formats are 'csv' and 'binary' and 'json'\".format(format))\n    url = _make_internal_url(filename)\n    with cython_context():\n        if format == 'binary':\n            self.__proxy__.save(url)\n        elif format == 'csv':\n            assert filename.endswith(('.csv', '.csv.gz'))\n            self.__proxy__.save_as_csv(url, {})\n        elif format == 'json':\n            self.export_json(url)\n        else:\n            raise ValueError('Unsupported format: {}'.format(format))",
            "def save(self, filename, format=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Save the SFrame to a file system for later use.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL. If the format is 'binary', a directory will be created\\n            at the location which will contain the sframe.\\n\\n        format : {'binary', 'csv', 'json'}, optional\\n            Format in which to save the SFrame. Binary saved SFrames can be\\n            loaded much faster and without any format conversion losses. If not\\n            given, will try to infer the format from filename given. If file\\n            name ends with 'csv' or '.csv.gz', then save as 'csv' format,\\n            otherwise save as 'binary' format.\\n            See export_csv for more csv saving options.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save('data/training_data_sframe')\\n\\n        >>> # Save the sframe into csv format\\n        >>> sf.save('data/training_data.csv', format='csv')\\n        \"\n    if format is None:\n        if filename.endswith(('.csv', '.csv.gz')):\n            format = 'csv'\n        elif filename.endswith('.json'):\n            format = 'json'\n        else:\n            format = 'binary'\n    elif format == 'csv':\n        if not filename.endswith(('.csv', '.csv.gz')):\n            filename = filename + '.csv'\n    elif format != 'binary' and format != 'json':\n        raise ValueError(\"Invalid format: {}. Supported formats are 'csv' and 'binary' and 'json'\".format(format))\n    url = _make_internal_url(filename)\n    with cython_context():\n        if format == 'binary':\n            self.__proxy__.save(url)\n        elif format == 'csv':\n            assert filename.endswith(('.csv', '.csv.gz'))\n            self.__proxy__.save_as_csv(url, {})\n        elif format == 'json':\n            self.export_json(url)\n        else:\n            raise ValueError('Unsupported format: {}'.format(format))"
        ]
    },
    {
        "func_name": "export_csv",
        "original": "def export_csv(self, filename, delimiter=',', line_terminator='\\n', header=True, quote_level=csv.QUOTE_NONNUMERIC, double_quote=True, escape_char='\\\\', quote_char='\"', na_rep='', file_header='', file_footer='', line_prefix='', _no_prefix_on_first_value=False, **kwargs):\n    \"\"\"\n        Writes an SFrame to a CSV file.\n\n        Parameters\n        ----------\n        filename : string\n            The location to save the CSV.\n\n        delimiter : string, optional\n            This describes the delimiter used for writing csv files.\n\n        line_terminator: string, optional\n            The newline character\n\n        header : bool, optional\n            If true, the column names are emitted as a header.\n\n        quote_level: csv.QUOTE_ALL | csv.QUOTE_NONE | csv.QUOTE_NONNUMERIC, optional\n            The quoting level. If csv.QUOTE_ALL, every field is quoted.\n            if csv.quote_NONE, no field is quoted. If csv.QUOTE_NONNUMERIC, only\n            non-numeric fileds are quoted. csv.QUOTE_MINIMAL is interpreted as\n            csv.QUOTE_NONNUMERIC.\n\n        double_quote : bool, optional\n            If True, quotes are escaped as two consecutive quotes\n\n        escape_char : string, optional\n            Character which begins a C escape sequence\n\n        quote_char: string, optional\n            Character used to quote fields\n\n        na_rep: string, optional\n            The value used to denote a missing value.\n\n        file_header: string, optional\n            A string printed to the start of the file\n\n        file_footer: string, optional\n            A string printed to the end of the file\n\n        line_prefix: string, optional\n            A string printed at the start of each value line\n        \"\"\"\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(list(kwargs.keys())))\n    write_csv_options = {}\n    write_csv_options['delimiter'] = delimiter\n    write_csv_options['escape_char'] = escape_char\n    write_csv_options['double_quote'] = double_quote\n    write_csv_options['quote_char'] = quote_char\n    if quote_level == csv.QUOTE_MINIMAL:\n        write_csv_options['quote_level'] = 0\n    elif quote_level == csv.QUOTE_ALL:\n        write_csv_options['quote_level'] = 1\n    elif quote_level == csv.QUOTE_NONNUMERIC:\n        write_csv_options['quote_level'] = 2\n    elif quote_level == csv.QUOTE_NONE:\n        write_csv_options['quote_level'] = 3\n    write_csv_options['header'] = header\n    write_csv_options['line_terminator'] = line_terminator\n    write_csv_options['na_value'] = na_rep\n    write_csv_options['file_header'] = file_header\n    write_csv_options['file_footer'] = file_footer\n    write_csv_options['line_prefix'] = line_prefix\n    write_csv_options['_no_prefix_on_first_value'] = _no_prefix_on_first_value\n    url = _make_internal_url(filename)\n    self.__proxy__.save_as_csv(url, write_csv_options)",
        "mutated": [
            "def export_csv(self, filename, delimiter=',', line_terminator='\\n', header=True, quote_level=csv.QUOTE_NONNUMERIC, double_quote=True, escape_char='\\\\', quote_char='\"', na_rep='', file_header='', file_footer='', line_prefix='', _no_prefix_on_first_value=False, **kwargs):\n    if False:\n        i = 10\n    '\\n        Writes an SFrame to a CSV file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the CSV.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for writing csv files.\\n\\n        line_terminator: string, optional\\n            The newline character\\n\\n        header : bool, optional\\n            If true, the column names are emitted as a header.\\n\\n        quote_level: csv.QUOTE_ALL | csv.QUOTE_NONE | csv.QUOTE_NONNUMERIC, optional\\n            The quoting level. If csv.QUOTE_ALL, every field is quoted.\\n            if csv.quote_NONE, no field is quoted. If csv.QUOTE_NONNUMERIC, only\\n            non-numeric fileds are quoted. csv.QUOTE_MINIMAL is interpreted as\\n            csv.QUOTE_NONNUMERIC.\\n\\n        double_quote : bool, optional\\n            If True, quotes are escaped as two consecutive quotes\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence\\n\\n        quote_char: string, optional\\n            Character used to quote fields\\n\\n        na_rep: string, optional\\n            The value used to denote a missing value.\\n\\n        file_header: string, optional\\n            A string printed to the start of the file\\n\\n        file_footer: string, optional\\n            A string printed to the end of the file\\n\\n        line_prefix: string, optional\\n            A string printed at the start of each value line\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(list(kwargs.keys())))\n    write_csv_options = {}\n    write_csv_options['delimiter'] = delimiter\n    write_csv_options['escape_char'] = escape_char\n    write_csv_options['double_quote'] = double_quote\n    write_csv_options['quote_char'] = quote_char\n    if quote_level == csv.QUOTE_MINIMAL:\n        write_csv_options['quote_level'] = 0\n    elif quote_level == csv.QUOTE_ALL:\n        write_csv_options['quote_level'] = 1\n    elif quote_level == csv.QUOTE_NONNUMERIC:\n        write_csv_options['quote_level'] = 2\n    elif quote_level == csv.QUOTE_NONE:\n        write_csv_options['quote_level'] = 3\n    write_csv_options['header'] = header\n    write_csv_options['line_terminator'] = line_terminator\n    write_csv_options['na_value'] = na_rep\n    write_csv_options['file_header'] = file_header\n    write_csv_options['file_footer'] = file_footer\n    write_csv_options['line_prefix'] = line_prefix\n    write_csv_options['_no_prefix_on_first_value'] = _no_prefix_on_first_value\n    url = _make_internal_url(filename)\n    self.__proxy__.save_as_csv(url, write_csv_options)",
            "def export_csv(self, filename, delimiter=',', line_terminator='\\n', header=True, quote_level=csv.QUOTE_NONNUMERIC, double_quote=True, escape_char='\\\\', quote_char='\"', na_rep='', file_header='', file_footer='', line_prefix='', _no_prefix_on_first_value=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Writes an SFrame to a CSV file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the CSV.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for writing csv files.\\n\\n        line_terminator: string, optional\\n            The newline character\\n\\n        header : bool, optional\\n            If true, the column names are emitted as a header.\\n\\n        quote_level: csv.QUOTE_ALL | csv.QUOTE_NONE | csv.QUOTE_NONNUMERIC, optional\\n            The quoting level. If csv.QUOTE_ALL, every field is quoted.\\n            if csv.quote_NONE, no field is quoted. If csv.QUOTE_NONNUMERIC, only\\n            non-numeric fileds are quoted. csv.QUOTE_MINIMAL is interpreted as\\n            csv.QUOTE_NONNUMERIC.\\n\\n        double_quote : bool, optional\\n            If True, quotes are escaped as two consecutive quotes\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence\\n\\n        quote_char: string, optional\\n            Character used to quote fields\\n\\n        na_rep: string, optional\\n            The value used to denote a missing value.\\n\\n        file_header: string, optional\\n            A string printed to the start of the file\\n\\n        file_footer: string, optional\\n            A string printed to the end of the file\\n\\n        line_prefix: string, optional\\n            A string printed at the start of each value line\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(list(kwargs.keys())))\n    write_csv_options = {}\n    write_csv_options['delimiter'] = delimiter\n    write_csv_options['escape_char'] = escape_char\n    write_csv_options['double_quote'] = double_quote\n    write_csv_options['quote_char'] = quote_char\n    if quote_level == csv.QUOTE_MINIMAL:\n        write_csv_options['quote_level'] = 0\n    elif quote_level == csv.QUOTE_ALL:\n        write_csv_options['quote_level'] = 1\n    elif quote_level == csv.QUOTE_NONNUMERIC:\n        write_csv_options['quote_level'] = 2\n    elif quote_level == csv.QUOTE_NONE:\n        write_csv_options['quote_level'] = 3\n    write_csv_options['header'] = header\n    write_csv_options['line_terminator'] = line_terminator\n    write_csv_options['na_value'] = na_rep\n    write_csv_options['file_header'] = file_header\n    write_csv_options['file_footer'] = file_footer\n    write_csv_options['line_prefix'] = line_prefix\n    write_csv_options['_no_prefix_on_first_value'] = _no_prefix_on_first_value\n    url = _make_internal_url(filename)\n    self.__proxy__.save_as_csv(url, write_csv_options)",
            "def export_csv(self, filename, delimiter=',', line_terminator='\\n', header=True, quote_level=csv.QUOTE_NONNUMERIC, double_quote=True, escape_char='\\\\', quote_char='\"', na_rep='', file_header='', file_footer='', line_prefix='', _no_prefix_on_first_value=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Writes an SFrame to a CSV file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the CSV.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for writing csv files.\\n\\n        line_terminator: string, optional\\n            The newline character\\n\\n        header : bool, optional\\n            If true, the column names are emitted as a header.\\n\\n        quote_level: csv.QUOTE_ALL | csv.QUOTE_NONE | csv.QUOTE_NONNUMERIC, optional\\n            The quoting level. If csv.QUOTE_ALL, every field is quoted.\\n            if csv.quote_NONE, no field is quoted. If csv.QUOTE_NONNUMERIC, only\\n            non-numeric fileds are quoted. csv.QUOTE_MINIMAL is interpreted as\\n            csv.QUOTE_NONNUMERIC.\\n\\n        double_quote : bool, optional\\n            If True, quotes are escaped as two consecutive quotes\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence\\n\\n        quote_char: string, optional\\n            Character used to quote fields\\n\\n        na_rep: string, optional\\n            The value used to denote a missing value.\\n\\n        file_header: string, optional\\n            A string printed to the start of the file\\n\\n        file_footer: string, optional\\n            A string printed to the end of the file\\n\\n        line_prefix: string, optional\\n            A string printed at the start of each value line\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(list(kwargs.keys())))\n    write_csv_options = {}\n    write_csv_options['delimiter'] = delimiter\n    write_csv_options['escape_char'] = escape_char\n    write_csv_options['double_quote'] = double_quote\n    write_csv_options['quote_char'] = quote_char\n    if quote_level == csv.QUOTE_MINIMAL:\n        write_csv_options['quote_level'] = 0\n    elif quote_level == csv.QUOTE_ALL:\n        write_csv_options['quote_level'] = 1\n    elif quote_level == csv.QUOTE_NONNUMERIC:\n        write_csv_options['quote_level'] = 2\n    elif quote_level == csv.QUOTE_NONE:\n        write_csv_options['quote_level'] = 3\n    write_csv_options['header'] = header\n    write_csv_options['line_terminator'] = line_terminator\n    write_csv_options['na_value'] = na_rep\n    write_csv_options['file_header'] = file_header\n    write_csv_options['file_footer'] = file_footer\n    write_csv_options['line_prefix'] = line_prefix\n    write_csv_options['_no_prefix_on_first_value'] = _no_prefix_on_first_value\n    url = _make_internal_url(filename)\n    self.__proxy__.save_as_csv(url, write_csv_options)",
            "def export_csv(self, filename, delimiter=',', line_terminator='\\n', header=True, quote_level=csv.QUOTE_NONNUMERIC, double_quote=True, escape_char='\\\\', quote_char='\"', na_rep='', file_header='', file_footer='', line_prefix='', _no_prefix_on_first_value=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Writes an SFrame to a CSV file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the CSV.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for writing csv files.\\n\\n        line_terminator: string, optional\\n            The newline character\\n\\n        header : bool, optional\\n            If true, the column names are emitted as a header.\\n\\n        quote_level: csv.QUOTE_ALL | csv.QUOTE_NONE | csv.QUOTE_NONNUMERIC, optional\\n            The quoting level. If csv.QUOTE_ALL, every field is quoted.\\n            if csv.quote_NONE, no field is quoted. If csv.QUOTE_NONNUMERIC, only\\n            non-numeric fileds are quoted. csv.QUOTE_MINIMAL is interpreted as\\n            csv.QUOTE_NONNUMERIC.\\n\\n        double_quote : bool, optional\\n            If True, quotes are escaped as two consecutive quotes\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence\\n\\n        quote_char: string, optional\\n            Character used to quote fields\\n\\n        na_rep: string, optional\\n            The value used to denote a missing value.\\n\\n        file_header: string, optional\\n            A string printed to the start of the file\\n\\n        file_footer: string, optional\\n            A string printed to the end of the file\\n\\n        line_prefix: string, optional\\n            A string printed at the start of each value line\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(list(kwargs.keys())))\n    write_csv_options = {}\n    write_csv_options['delimiter'] = delimiter\n    write_csv_options['escape_char'] = escape_char\n    write_csv_options['double_quote'] = double_quote\n    write_csv_options['quote_char'] = quote_char\n    if quote_level == csv.QUOTE_MINIMAL:\n        write_csv_options['quote_level'] = 0\n    elif quote_level == csv.QUOTE_ALL:\n        write_csv_options['quote_level'] = 1\n    elif quote_level == csv.QUOTE_NONNUMERIC:\n        write_csv_options['quote_level'] = 2\n    elif quote_level == csv.QUOTE_NONE:\n        write_csv_options['quote_level'] = 3\n    write_csv_options['header'] = header\n    write_csv_options['line_terminator'] = line_terminator\n    write_csv_options['na_value'] = na_rep\n    write_csv_options['file_header'] = file_header\n    write_csv_options['file_footer'] = file_footer\n    write_csv_options['line_prefix'] = line_prefix\n    write_csv_options['_no_prefix_on_first_value'] = _no_prefix_on_first_value\n    url = _make_internal_url(filename)\n    self.__proxy__.save_as_csv(url, write_csv_options)",
            "def export_csv(self, filename, delimiter=',', line_terminator='\\n', header=True, quote_level=csv.QUOTE_NONNUMERIC, double_quote=True, escape_char='\\\\', quote_char='\"', na_rep='', file_header='', file_footer='', line_prefix='', _no_prefix_on_first_value=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Writes an SFrame to a CSV file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the CSV.\\n\\n        delimiter : string, optional\\n            This describes the delimiter used for writing csv files.\\n\\n        line_terminator: string, optional\\n            The newline character\\n\\n        header : bool, optional\\n            If true, the column names are emitted as a header.\\n\\n        quote_level: csv.QUOTE_ALL | csv.QUOTE_NONE | csv.QUOTE_NONNUMERIC, optional\\n            The quoting level. If csv.QUOTE_ALL, every field is quoted.\\n            if csv.quote_NONE, no field is quoted. If csv.QUOTE_NONNUMERIC, only\\n            non-numeric fileds are quoted. csv.QUOTE_MINIMAL is interpreted as\\n            csv.QUOTE_NONNUMERIC.\\n\\n        double_quote : bool, optional\\n            If True, quotes are escaped as two consecutive quotes\\n\\n        escape_char : string, optional\\n            Character which begins a C escape sequence\\n\\n        quote_char: string, optional\\n            Character used to quote fields\\n\\n        na_rep: string, optional\\n            The value used to denote a missing value.\\n\\n        file_header: string, optional\\n            A string printed to the start of the file\\n\\n        file_footer: string, optional\\n            A string printed to the end of the file\\n\\n        line_prefix: string, optional\\n            A string printed at the start of each value line\\n        '\n    if 'sep' in kwargs:\n        delimiter = kwargs['sep']\n        del kwargs['sep']\n    if 'quotechar' in kwargs:\n        quote_char = kwargs['quotechar']\n        del kwargs['quotechar']\n    if 'doublequote' in kwargs:\n        double_quote = kwargs['doublequote']\n        del kwargs['doublequote']\n    if 'lineterminator' in kwargs:\n        line_terminator = kwargs['lineterminator']\n        del kwargs['lineterminator']\n    if len(kwargs) > 0:\n        raise TypeError('Unexpected keyword arguments ' + str(list(kwargs.keys())))\n    write_csv_options = {}\n    write_csv_options['delimiter'] = delimiter\n    write_csv_options['escape_char'] = escape_char\n    write_csv_options['double_quote'] = double_quote\n    write_csv_options['quote_char'] = quote_char\n    if quote_level == csv.QUOTE_MINIMAL:\n        write_csv_options['quote_level'] = 0\n    elif quote_level == csv.QUOTE_ALL:\n        write_csv_options['quote_level'] = 1\n    elif quote_level == csv.QUOTE_NONNUMERIC:\n        write_csv_options['quote_level'] = 2\n    elif quote_level == csv.QUOTE_NONE:\n        write_csv_options['quote_level'] = 3\n    write_csv_options['header'] = header\n    write_csv_options['line_terminator'] = line_terminator\n    write_csv_options['na_value'] = na_rep\n    write_csv_options['file_header'] = file_header\n    write_csv_options['file_footer'] = file_footer\n    write_csv_options['line_prefix'] = line_prefix\n    write_csv_options['_no_prefix_on_first_value'] = _no_prefix_on_first_value\n    url = _make_internal_url(filename)\n    self.__proxy__.save_as_csv(url, write_csv_options)"
        ]
    },
    {
        "func_name": "export_json",
        "original": "def export_json(self, filename, orient='records'):\n    \"\"\"\n        Writes an SFrame to a JSON file.\n\n        Parameters\n        ----------\n        filename : string\n            The location to save the JSON file.\n\n        orient : string, optional. Either \"records\" or \"lines\"\n            If orient=\"records\" the file is saved as a single JSON array.\n            If orient=\"lines\", the file is saves as a JSON value per line.\n\n        Examples\n        --------\n        The orient parameter describes the expected input format of the JSON\n        file.\n\n        If orient=\"records\", the output will be a single JSON Array where\n        each array element is a dictionary describing the row.\n\n        >>> g\n        Columns:\n                a\tint\n                b\tint\n        Rows: 3\n        Data:\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | 1 |\n        | 2 | 2 |\n        | 3 | 3 |\n        +---+---+\n        >>> g.export('output.json', orient='records')\n        >>> !cat output.json\n        [\n        {'a':1,'b':1},\n        {'a':2,'b':2},\n        {'a':3,'b':3},\n        ]\n\n        If orient=\"rows\", each row will be emitted as a JSON dictionary to\n        each file line.\n\n        >>> g\n        Columns:\n                a\tint\n                b\tint\n        Rows: 3\n        Data:\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | 1 |\n        | 2 | 2 |\n        | 3 | 3 |\n        +---+---+\n        >>> g.export('output.json', orient='rows')\n        >>> !cat output.json\n        {'a':1,'b':1}\n        {'a':2,'b':2}\n        {'a':3,'b':3}\n        \"\"\"\n    if orient == 'records':\n        self.pack_columns(dtype=dict).export_csv(filename, file_header='[', file_footer=']', header=False, double_quote=False, quote_level=csv.QUOTE_NONE, line_prefix=',', _no_prefix_on_first_value=True)\n    elif orient == 'lines':\n        self.pack_columns(dtype=dict).export_csv(filename, header=False, double_quote=False, quote_level=csv.QUOTE_NONE)\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
        "mutated": [
            "def export_json(self, filename, orient='records'):\n    if False:\n        i = 10\n    '\\n        Writes an SFrame to a JSON file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the JSON file.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is saved as a single JSON array.\\n            If orient=\"lines\", the file is saves as a JSON value per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the output will be a single JSON Array where\\n        each array element is a dictionary describing the row.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'records\\')\\n        >>> !cat output.json\\n        [\\n        {\\'a\\':1,\\'b\\':1},\\n        {\\'a\\':2,\\'b\\':2},\\n        {\\'a\\':3,\\'b\\':3},\\n        ]\\n\\n        If orient=\"rows\", each row will be emitted as a JSON dictionary to\\n        each file line.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'rows\\')\\n        >>> !cat output.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        '\n    if orient == 'records':\n        self.pack_columns(dtype=dict).export_csv(filename, file_header='[', file_footer=']', header=False, double_quote=False, quote_level=csv.QUOTE_NONE, line_prefix=',', _no_prefix_on_first_value=True)\n    elif orient == 'lines':\n        self.pack_columns(dtype=dict).export_csv(filename, header=False, double_quote=False, quote_level=csv.QUOTE_NONE)\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "def export_json(self, filename, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Writes an SFrame to a JSON file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the JSON file.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is saved as a single JSON array.\\n            If orient=\"lines\", the file is saves as a JSON value per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the output will be a single JSON Array where\\n        each array element is a dictionary describing the row.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'records\\')\\n        >>> !cat output.json\\n        [\\n        {\\'a\\':1,\\'b\\':1},\\n        {\\'a\\':2,\\'b\\':2},\\n        {\\'a\\':3,\\'b\\':3},\\n        ]\\n\\n        If orient=\"rows\", each row will be emitted as a JSON dictionary to\\n        each file line.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'rows\\')\\n        >>> !cat output.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        '\n    if orient == 'records':\n        self.pack_columns(dtype=dict).export_csv(filename, file_header='[', file_footer=']', header=False, double_quote=False, quote_level=csv.QUOTE_NONE, line_prefix=',', _no_prefix_on_first_value=True)\n    elif orient == 'lines':\n        self.pack_columns(dtype=dict).export_csv(filename, header=False, double_quote=False, quote_level=csv.QUOTE_NONE)\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "def export_json(self, filename, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Writes an SFrame to a JSON file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the JSON file.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is saved as a single JSON array.\\n            If orient=\"lines\", the file is saves as a JSON value per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the output will be a single JSON Array where\\n        each array element is a dictionary describing the row.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'records\\')\\n        >>> !cat output.json\\n        [\\n        {\\'a\\':1,\\'b\\':1},\\n        {\\'a\\':2,\\'b\\':2},\\n        {\\'a\\':3,\\'b\\':3},\\n        ]\\n\\n        If orient=\"rows\", each row will be emitted as a JSON dictionary to\\n        each file line.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'rows\\')\\n        >>> !cat output.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        '\n    if orient == 'records':\n        self.pack_columns(dtype=dict).export_csv(filename, file_header='[', file_footer=']', header=False, double_quote=False, quote_level=csv.QUOTE_NONE, line_prefix=',', _no_prefix_on_first_value=True)\n    elif orient == 'lines':\n        self.pack_columns(dtype=dict).export_csv(filename, header=False, double_quote=False, quote_level=csv.QUOTE_NONE)\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "def export_json(self, filename, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Writes an SFrame to a JSON file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the JSON file.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is saved as a single JSON array.\\n            If orient=\"lines\", the file is saves as a JSON value per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the output will be a single JSON Array where\\n        each array element is a dictionary describing the row.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'records\\')\\n        >>> !cat output.json\\n        [\\n        {\\'a\\':1,\\'b\\':1},\\n        {\\'a\\':2,\\'b\\':2},\\n        {\\'a\\':3,\\'b\\':3},\\n        ]\\n\\n        If orient=\"rows\", each row will be emitted as a JSON dictionary to\\n        each file line.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'rows\\')\\n        >>> !cat output.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        '\n    if orient == 'records':\n        self.pack_columns(dtype=dict).export_csv(filename, file_header='[', file_footer=']', header=False, double_quote=False, quote_level=csv.QUOTE_NONE, line_prefix=',', _no_prefix_on_first_value=True)\n    elif orient == 'lines':\n        self.pack_columns(dtype=dict).export_csv(filename, header=False, double_quote=False, quote_level=csv.QUOTE_NONE)\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')",
            "def export_json(self, filename, orient='records'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Writes an SFrame to a JSON file.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the JSON file.\\n\\n        orient : string, optional. Either \"records\" or \"lines\"\\n            If orient=\"records\" the file is saved as a single JSON array.\\n            If orient=\"lines\", the file is saves as a JSON value per line.\\n\\n        Examples\\n        --------\\n        The orient parameter describes the expected input format of the JSON\\n        file.\\n\\n        If orient=\"records\", the output will be a single JSON Array where\\n        each array element is a dictionary describing the row.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'records\\')\\n        >>> !cat output.json\\n        [\\n        {\\'a\\':1,\\'b\\':1},\\n        {\\'a\\':2,\\'b\\':2},\\n        {\\'a\\':3,\\'b\\':3},\\n        ]\\n\\n        If orient=\"rows\", each row will be emitted as a JSON dictionary to\\n        each file line.\\n\\n        >>> g\\n        Columns:\\n                a\\tint\\n                b\\tint\\n        Rows: 3\\n        Data:\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | 1 |\\n        | 2 | 2 |\\n        | 3 | 3 |\\n        +---+---+\\n        >>> g.export(\\'output.json\\', orient=\\'rows\\')\\n        >>> !cat output.json\\n        {\\'a\\':1,\\'b\\':1}\\n        {\\'a\\':2,\\'b\\':2}\\n        {\\'a\\':3,\\'b\\':3}\\n        '\n    if orient == 'records':\n        self.pack_columns(dtype=dict).export_csv(filename, file_header='[', file_footer=']', header=False, double_quote=False, quote_level=csv.QUOTE_NONE, line_prefix=',', _no_prefix_on_first_value=True)\n    elif orient == 'lines':\n        self.pack_columns(dtype=dict).export_csv(filename, header=False, double_quote=False, quote_level=csv.QUOTE_NONE)\n    else:\n        raise ValueError('Invalid value for orient parameter (' + str(orient) + ')')"
        ]
    },
    {
        "func_name": "_save_reference",
        "original": "def _save_reference(self, filename):\n    \"\"\"\n        Performs an incomplete save of an existing SFrame into a directory.\n        This saved SFrame may reference SFrames in other locations in the same\n        filesystem for certain resources.\n\n        Parameters\n        ----------\n        filename : string\n            The location to save the SFrame. Either a local directory or a\n            remote URL.\n\n        See Also\n        --------\n        load_sframe, SFrame\n\n        Examples\n        --------\n        >>> # Save the sframe into binary format\n        >>> sf.save_reference('data/training_data_sframe')\n        \"\"\"\n    url = _make_internal_url(filename)\n    with cython_context():\n        self.__proxy__.save_reference(url)",
        "mutated": [
            "def _save_reference(self, filename):\n    if False:\n        i = 10\n    \"\\n        Performs an incomplete save of an existing SFrame into a directory.\\n        This saved SFrame may reference SFrames in other locations in the same\\n        filesystem for certain resources.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save_reference('data/training_data_sframe')\\n        \"\n    url = _make_internal_url(filename)\n    with cython_context():\n        self.__proxy__.save_reference(url)",
            "def _save_reference(self, filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Performs an incomplete save of an existing SFrame into a directory.\\n        This saved SFrame may reference SFrames in other locations in the same\\n        filesystem for certain resources.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save_reference('data/training_data_sframe')\\n        \"\n    url = _make_internal_url(filename)\n    with cython_context():\n        self.__proxy__.save_reference(url)",
            "def _save_reference(self, filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Performs an incomplete save of an existing SFrame into a directory.\\n        This saved SFrame may reference SFrames in other locations in the same\\n        filesystem for certain resources.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save_reference('data/training_data_sframe')\\n        \"\n    url = _make_internal_url(filename)\n    with cython_context():\n        self.__proxy__.save_reference(url)",
            "def _save_reference(self, filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Performs an incomplete save of an existing SFrame into a directory.\\n        This saved SFrame may reference SFrames in other locations in the same\\n        filesystem for certain resources.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save_reference('data/training_data_sframe')\\n        \"\n    url = _make_internal_url(filename)\n    with cython_context():\n        self.__proxy__.save_reference(url)",
            "def _save_reference(self, filename):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Performs an incomplete save of an existing SFrame into a directory.\\n        This saved SFrame may reference SFrames in other locations in the same\\n        filesystem for certain resources.\\n\\n        Parameters\\n        ----------\\n        filename : string\\n            The location to save the SFrame. Either a local directory or a\\n            remote URL.\\n\\n        See Also\\n        --------\\n        load_sframe, SFrame\\n\\n        Examples\\n        --------\\n        >>> # Save the sframe into binary format\\n        >>> sf.save_reference('data/training_data_sframe')\\n        \"\n    url = _make_internal_url(filename)\n    with cython_context():\n        self.__proxy__.save_reference(url)"
        ]
    },
    {
        "func_name": "select_column",
        "original": "def select_column(self, column_name):\n    \"\"\"\n        Get a reference to the :class:`~turicreate.SArray` that corresponds with\n        the given column_name. Throws an exception if the column_name is\n        something other than a string or if the column name is not found.\n\n        Parameters\n        ----------\n        column_name: str\n            The column name.\n\n        Returns\n        -------\n        out : SArray\n            The SArray that is referred by ``column_name``.\n\n        See Also\n        --------\n        select_columns\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\n        ...                       'user_name': ['alice', 'bob', 'charlie']})\n        >>> # This line is equivalent to `sa = sf['user_name']`\n        >>> sa = sf.select_column('user_name')\n        >>> sa\n        dtype: str\n        Rows: 3\n        ['alice', 'bob', 'charlie']\n        \"\"\"\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column_nametype: must be str')\n    with cython_context():\n        return SArray(data=[], _proxy=self.__proxy__.select_column(column_name))",
        "mutated": [
            "def select_column(self, column_name):\n    if False:\n        i = 10\n    \"\\n        Get a reference to the :class:`~turicreate.SArray` that corresponds with\\n        the given column_name. Throws an exception if the column_name is\\n        something other than a string or if the column name is not found.\\n\\n        Parameters\\n        ----------\\n        column_name: str\\n            The column name.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray that is referred by ``column_name``.\\n\\n        See Also\\n        --------\\n        select_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie']})\\n        >>> # This line is equivalent to `sa = sf['user_name']`\\n        >>> sa = sf.select_column('user_name')\\n        >>> sa\\n        dtype: str\\n        Rows: 3\\n        ['alice', 'bob', 'charlie']\\n        \"\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column_nametype: must be str')\n    with cython_context():\n        return SArray(data=[], _proxy=self.__proxy__.select_column(column_name))",
            "def select_column(self, column_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Get a reference to the :class:`~turicreate.SArray` that corresponds with\\n        the given column_name. Throws an exception if the column_name is\\n        something other than a string or if the column name is not found.\\n\\n        Parameters\\n        ----------\\n        column_name: str\\n            The column name.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray that is referred by ``column_name``.\\n\\n        See Also\\n        --------\\n        select_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie']})\\n        >>> # This line is equivalent to `sa = sf['user_name']`\\n        >>> sa = sf.select_column('user_name')\\n        >>> sa\\n        dtype: str\\n        Rows: 3\\n        ['alice', 'bob', 'charlie']\\n        \"\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column_nametype: must be str')\n    with cython_context():\n        return SArray(data=[], _proxy=self.__proxy__.select_column(column_name))",
            "def select_column(self, column_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Get a reference to the :class:`~turicreate.SArray` that corresponds with\\n        the given column_name. Throws an exception if the column_name is\\n        something other than a string or if the column name is not found.\\n\\n        Parameters\\n        ----------\\n        column_name: str\\n            The column name.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray that is referred by ``column_name``.\\n\\n        See Also\\n        --------\\n        select_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie']})\\n        >>> # This line is equivalent to `sa = sf['user_name']`\\n        >>> sa = sf.select_column('user_name')\\n        >>> sa\\n        dtype: str\\n        Rows: 3\\n        ['alice', 'bob', 'charlie']\\n        \"\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column_nametype: must be str')\n    with cython_context():\n        return SArray(data=[], _proxy=self.__proxy__.select_column(column_name))",
            "def select_column(self, column_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Get a reference to the :class:`~turicreate.SArray` that corresponds with\\n        the given column_name. Throws an exception if the column_name is\\n        something other than a string or if the column name is not found.\\n\\n        Parameters\\n        ----------\\n        column_name: str\\n            The column name.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray that is referred by ``column_name``.\\n\\n        See Also\\n        --------\\n        select_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie']})\\n        >>> # This line is equivalent to `sa = sf['user_name']`\\n        >>> sa = sf.select_column('user_name')\\n        >>> sa\\n        dtype: str\\n        Rows: 3\\n        ['alice', 'bob', 'charlie']\\n        \"\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column_nametype: must be str')\n    with cython_context():\n        return SArray(data=[], _proxy=self.__proxy__.select_column(column_name))",
            "def select_column(self, column_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Get a reference to the :class:`~turicreate.SArray` that corresponds with\\n        the given column_name. Throws an exception if the column_name is\\n        something other than a string or if the column name is not found.\\n\\n        Parameters\\n        ----------\\n        column_name: str\\n            The column name.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            The SArray that is referred by ``column_name``.\\n\\n        See Also\\n        --------\\n        select_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie']})\\n        >>> # This line is equivalent to `sa = sf['user_name']`\\n        >>> sa = sf.select_column('user_name')\\n        >>> sa\\n        dtype: str\\n        Rows: 3\\n        ['alice', 'bob', 'charlie']\\n        \"\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column_nametype: must be str')\n    with cython_context():\n        return SArray(data=[], _proxy=self.__proxy__.select_column(column_name))"
        ]
    },
    {
        "func_name": "select_columns",
        "original": "def select_columns(self, column_names):\n    \"\"\"\n        Selects all columns where the name of the column or the type of column\n        is included in the column_names. An exception is raised if duplicate columns\n        are selected i.e. sf.select_columns(['a','a']), or non-existent columns\n        are selected.\n\n        Throws an exception for all other input types.\n\n        Parameters\n        ----------\n        column_names: list[str or type]\n            The list of column names or a list of types.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that is made up of the columns referred to in\n            ``column_names`` from the current SFrame.\n\n        See Also\n        --------\n        select_column\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\n        ...                       'user_name': ['alice', 'bob', 'charlie'],\n        ...                       'zipcode': [98101, 98102, 98103]\n        ...                      })\n        >>> # This line is equivalent to `sf2 = sf[['user_id', 'zipcode']]`\n        >>> sf2 = sf.select_columns(['user_id', 'zipcode'])\n        >>> sf2\n        +---------+---------+\n        | user_id | zipcode |\n        +---------+---------+\n        |    1    |  98101  |\n        |    2    |  98102  |\n        |    3    |  98103  |\n        +---------+---------+\n        [3 rows x 2 columns]\n        \"\"\"\n    if not _is_non_string_iterable(column_names):\n        raise TypeError('column_names must be an iterable')\n    if not all([isinstance(x, six.string_types) or isinstance(x, type) or isinstance(x, bytes) for x in column_names]):\n        raise TypeError('Invalid key type: must be str, unicode, bytes or type')\n    requested_str_columns = [s for s in column_names if isinstance(s, six.string_types)]\n    from collections import Counter\n    column_names_counter = Counter(column_names)\n    if len(column_names) != len(column_names_counter):\n        for key in column_names_counter:\n            if column_names_counter[key] > 1:\n                raise ValueError(\"There are duplicate keys in key list: '\" + key + \"'\")\n    colnames_and_types = list(zip(self.column_names(), self.column_types()))\n    selected_columns = requested_str_columns\n    typelist = [s for s in column_names if isinstance(s, type)]\n    for i in colnames_and_types:\n        if i[1] in typelist and i[0] not in selected_columns:\n            selected_columns += [i[0]]\n    selected_columns = selected_columns\n    with cython_context():\n        return SFrame(data=[], _proxy=self.__proxy__.select_columns(selected_columns))",
        "mutated": [
            "def select_columns(self, column_names):\n    if False:\n        i = 10\n    \"\\n        Selects all columns where the name of the column or the type of column\\n        is included in the column_names. An exception is raised if duplicate columns\\n        are selected i.e. sf.select_columns(['a','a']), or non-existent columns\\n        are selected.\\n\\n        Throws an exception for all other input types.\\n\\n        Parameters\\n        ----------\\n        column_names: list[str or type]\\n            The list of column names or a list of types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is made up of the columns referred to in\\n            ``column_names`` from the current SFrame.\\n\\n        See Also\\n        --------\\n        select_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie'],\\n        ...                       'zipcode': [98101, 98102, 98103]\\n        ...                      })\\n        >>> # This line is equivalent to `sf2 = sf[['user_id', 'zipcode']]`\\n        >>> sf2 = sf.select_columns(['user_id', 'zipcode'])\\n        >>> sf2\\n        +---------+---------+\\n        | user_id | zipcode |\\n        +---------+---------+\\n        |    1    |  98101  |\\n        |    2    |  98102  |\\n        |    3    |  98103  |\\n        +---------+---------+\\n        [3 rows x 2 columns]\\n        \"\n    if not _is_non_string_iterable(column_names):\n        raise TypeError('column_names must be an iterable')\n    if not all([isinstance(x, six.string_types) or isinstance(x, type) or isinstance(x, bytes) for x in column_names]):\n        raise TypeError('Invalid key type: must be str, unicode, bytes or type')\n    requested_str_columns = [s for s in column_names if isinstance(s, six.string_types)]\n    from collections import Counter\n    column_names_counter = Counter(column_names)\n    if len(column_names) != len(column_names_counter):\n        for key in column_names_counter:\n            if column_names_counter[key] > 1:\n                raise ValueError(\"There are duplicate keys in key list: '\" + key + \"'\")\n    colnames_and_types = list(zip(self.column_names(), self.column_types()))\n    selected_columns = requested_str_columns\n    typelist = [s for s in column_names if isinstance(s, type)]\n    for i in colnames_and_types:\n        if i[1] in typelist and i[0] not in selected_columns:\n            selected_columns += [i[0]]\n    selected_columns = selected_columns\n    with cython_context():\n        return SFrame(data=[], _proxy=self.__proxy__.select_columns(selected_columns))",
            "def select_columns(self, column_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Selects all columns where the name of the column or the type of column\\n        is included in the column_names. An exception is raised if duplicate columns\\n        are selected i.e. sf.select_columns(['a','a']), or non-existent columns\\n        are selected.\\n\\n        Throws an exception for all other input types.\\n\\n        Parameters\\n        ----------\\n        column_names: list[str or type]\\n            The list of column names or a list of types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is made up of the columns referred to in\\n            ``column_names`` from the current SFrame.\\n\\n        See Also\\n        --------\\n        select_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie'],\\n        ...                       'zipcode': [98101, 98102, 98103]\\n        ...                      })\\n        >>> # This line is equivalent to `sf2 = sf[['user_id', 'zipcode']]`\\n        >>> sf2 = sf.select_columns(['user_id', 'zipcode'])\\n        >>> sf2\\n        +---------+---------+\\n        | user_id | zipcode |\\n        +---------+---------+\\n        |    1    |  98101  |\\n        |    2    |  98102  |\\n        |    3    |  98103  |\\n        +---------+---------+\\n        [3 rows x 2 columns]\\n        \"\n    if not _is_non_string_iterable(column_names):\n        raise TypeError('column_names must be an iterable')\n    if not all([isinstance(x, six.string_types) or isinstance(x, type) or isinstance(x, bytes) for x in column_names]):\n        raise TypeError('Invalid key type: must be str, unicode, bytes or type')\n    requested_str_columns = [s for s in column_names if isinstance(s, six.string_types)]\n    from collections import Counter\n    column_names_counter = Counter(column_names)\n    if len(column_names) != len(column_names_counter):\n        for key in column_names_counter:\n            if column_names_counter[key] > 1:\n                raise ValueError(\"There are duplicate keys in key list: '\" + key + \"'\")\n    colnames_and_types = list(zip(self.column_names(), self.column_types()))\n    selected_columns = requested_str_columns\n    typelist = [s for s in column_names if isinstance(s, type)]\n    for i in colnames_and_types:\n        if i[1] in typelist and i[0] not in selected_columns:\n            selected_columns += [i[0]]\n    selected_columns = selected_columns\n    with cython_context():\n        return SFrame(data=[], _proxy=self.__proxy__.select_columns(selected_columns))",
            "def select_columns(self, column_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Selects all columns where the name of the column or the type of column\\n        is included in the column_names. An exception is raised if duplicate columns\\n        are selected i.e. sf.select_columns(['a','a']), or non-existent columns\\n        are selected.\\n\\n        Throws an exception for all other input types.\\n\\n        Parameters\\n        ----------\\n        column_names: list[str or type]\\n            The list of column names or a list of types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is made up of the columns referred to in\\n            ``column_names`` from the current SFrame.\\n\\n        See Also\\n        --------\\n        select_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie'],\\n        ...                       'zipcode': [98101, 98102, 98103]\\n        ...                      })\\n        >>> # This line is equivalent to `sf2 = sf[['user_id', 'zipcode']]`\\n        >>> sf2 = sf.select_columns(['user_id', 'zipcode'])\\n        >>> sf2\\n        +---------+---------+\\n        | user_id | zipcode |\\n        +---------+---------+\\n        |    1    |  98101  |\\n        |    2    |  98102  |\\n        |    3    |  98103  |\\n        +---------+---------+\\n        [3 rows x 2 columns]\\n        \"\n    if not _is_non_string_iterable(column_names):\n        raise TypeError('column_names must be an iterable')\n    if not all([isinstance(x, six.string_types) or isinstance(x, type) or isinstance(x, bytes) for x in column_names]):\n        raise TypeError('Invalid key type: must be str, unicode, bytes or type')\n    requested_str_columns = [s for s in column_names if isinstance(s, six.string_types)]\n    from collections import Counter\n    column_names_counter = Counter(column_names)\n    if len(column_names) != len(column_names_counter):\n        for key in column_names_counter:\n            if column_names_counter[key] > 1:\n                raise ValueError(\"There are duplicate keys in key list: '\" + key + \"'\")\n    colnames_and_types = list(zip(self.column_names(), self.column_types()))\n    selected_columns = requested_str_columns\n    typelist = [s for s in column_names if isinstance(s, type)]\n    for i in colnames_and_types:\n        if i[1] in typelist and i[0] not in selected_columns:\n            selected_columns += [i[0]]\n    selected_columns = selected_columns\n    with cython_context():\n        return SFrame(data=[], _proxy=self.__proxy__.select_columns(selected_columns))",
            "def select_columns(self, column_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Selects all columns where the name of the column or the type of column\\n        is included in the column_names. An exception is raised if duplicate columns\\n        are selected i.e. sf.select_columns(['a','a']), or non-existent columns\\n        are selected.\\n\\n        Throws an exception for all other input types.\\n\\n        Parameters\\n        ----------\\n        column_names: list[str or type]\\n            The list of column names or a list of types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is made up of the columns referred to in\\n            ``column_names`` from the current SFrame.\\n\\n        See Also\\n        --------\\n        select_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie'],\\n        ...                       'zipcode': [98101, 98102, 98103]\\n        ...                      })\\n        >>> # This line is equivalent to `sf2 = sf[['user_id', 'zipcode']]`\\n        >>> sf2 = sf.select_columns(['user_id', 'zipcode'])\\n        >>> sf2\\n        +---------+---------+\\n        | user_id | zipcode |\\n        +---------+---------+\\n        |    1    |  98101  |\\n        |    2    |  98102  |\\n        |    3    |  98103  |\\n        +---------+---------+\\n        [3 rows x 2 columns]\\n        \"\n    if not _is_non_string_iterable(column_names):\n        raise TypeError('column_names must be an iterable')\n    if not all([isinstance(x, six.string_types) or isinstance(x, type) or isinstance(x, bytes) for x in column_names]):\n        raise TypeError('Invalid key type: must be str, unicode, bytes or type')\n    requested_str_columns = [s for s in column_names if isinstance(s, six.string_types)]\n    from collections import Counter\n    column_names_counter = Counter(column_names)\n    if len(column_names) != len(column_names_counter):\n        for key in column_names_counter:\n            if column_names_counter[key] > 1:\n                raise ValueError(\"There are duplicate keys in key list: '\" + key + \"'\")\n    colnames_and_types = list(zip(self.column_names(), self.column_types()))\n    selected_columns = requested_str_columns\n    typelist = [s for s in column_names if isinstance(s, type)]\n    for i in colnames_and_types:\n        if i[1] in typelist and i[0] not in selected_columns:\n            selected_columns += [i[0]]\n    selected_columns = selected_columns\n    with cython_context():\n        return SFrame(data=[], _proxy=self.__proxy__.select_columns(selected_columns))",
            "def select_columns(self, column_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Selects all columns where the name of the column or the type of column\\n        is included in the column_names. An exception is raised if duplicate columns\\n        are selected i.e. sf.select_columns(['a','a']), or non-existent columns\\n        are selected.\\n\\n        Throws an exception for all other input types.\\n\\n        Parameters\\n        ----------\\n        column_names: list[str or type]\\n            The list of column names or a list of types.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is made up of the columns referred to in\\n            ``column_names`` from the current SFrame.\\n\\n        See Also\\n        --------\\n        select_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'user_id': [1,2,3],\\n        ...                       'user_name': ['alice', 'bob', 'charlie'],\\n        ...                       'zipcode': [98101, 98102, 98103]\\n        ...                      })\\n        >>> # This line is equivalent to `sf2 = sf[['user_id', 'zipcode']]`\\n        >>> sf2 = sf.select_columns(['user_id', 'zipcode'])\\n        >>> sf2\\n        +---------+---------+\\n        | user_id | zipcode |\\n        +---------+---------+\\n        |    1    |  98101  |\\n        |    2    |  98102  |\\n        |    3    |  98103  |\\n        +---------+---------+\\n        [3 rows x 2 columns]\\n        \"\n    if not _is_non_string_iterable(column_names):\n        raise TypeError('column_names must be an iterable')\n    if not all([isinstance(x, six.string_types) or isinstance(x, type) or isinstance(x, bytes) for x in column_names]):\n        raise TypeError('Invalid key type: must be str, unicode, bytes or type')\n    requested_str_columns = [s for s in column_names if isinstance(s, six.string_types)]\n    from collections import Counter\n    column_names_counter = Counter(column_names)\n    if len(column_names) != len(column_names_counter):\n        for key in column_names_counter:\n            if column_names_counter[key] > 1:\n                raise ValueError(\"There are duplicate keys in key list: '\" + key + \"'\")\n    colnames_and_types = list(zip(self.column_names(), self.column_types()))\n    selected_columns = requested_str_columns\n    typelist = [s for s in column_names if isinstance(s, type)]\n    for i in colnames_and_types:\n        if i[1] in typelist and i[0] not in selected_columns:\n            selected_columns += [i[0]]\n    selected_columns = selected_columns\n    with cython_context():\n        return SFrame(data=[], _proxy=self.__proxy__.select_columns(selected_columns))"
        ]
    },
    {
        "func_name": "add_column",
        "original": "def add_column(self, data, column_name='', inplace=False):\n    \"\"\"\n        Returns an SFrame with a new column. The number of elements in the data\n        given must match the length of every other column of the SFrame.\n        If no name is given, a default name is chosen.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        data : SArray\n            The 'column' of data to add.\n\n        column_name : string, optional\n            The name of the column. If no name is given, a default name is\n            chosen.\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The current SFrame.\n\n        See Also\n        --------\n        add_columns\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\n        >>> sa = turicreate.SArray(['cat', 'dog', 'fossa'])\n        >>> # This line is equivalent to `sf['species'] = sa`\n        >>> res = sf.add_column(sa, 'species')\n        >>> res\n        +----+-----+---------+\n        | id | val | species |\n        +----+-----+---------+\n        | 1  |  A  |   cat   |\n        | 2  |  B  |   dog   |\n        | 3  |  C  |  fossa  |\n        +----+-----+---------+\n        [3 rows x 3 columns]\n        \"\"\"\n    if not isinstance(data, SArray):\n        if isinstance(data, _Iterable):\n            data = SArray(data)\n        elif self.num_columns() == 0:\n            data = SArray([data])\n        else:\n            data = SArray.from_const(data, self.num_rows())\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column name: must be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_column(data.__proxy__, column_name)\n    ret._cache = None\n    return ret",
        "mutated": [
            "def add_column(self, data, column_name='', inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with a new column. The number of elements in the data\\n        given must match the length of every other column of the SFrame.\\n        If no name is given, a default name is chosen.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : SArray\\n            The 'column' of data to add.\\n\\n        column_name : string, optional\\n            The name of the column. If no name is given, a default name is\\n            chosen.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sa = turicreate.SArray(['cat', 'dog', 'fossa'])\\n        >>> # This line is equivalent to `sf['species'] = sa`\\n        >>> res = sf.add_column(sa, 'species')\\n        >>> res\\n        +----+-----+---------+\\n        | id | val | species |\\n        +----+-----+---------+\\n        | 1  |  A  |   cat   |\\n        | 2  |  B  |   dog   |\\n        | 3  |  C  |  fossa  |\\n        +----+-----+---------+\\n        [3 rows x 3 columns]\\n        \"\n    if not isinstance(data, SArray):\n        if isinstance(data, _Iterable):\n            data = SArray(data)\n        elif self.num_columns() == 0:\n            data = SArray([data])\n        else:\n            data = SArray.from_const(data, self.num_rows())\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column name: must be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_column(data.__proxy__, column_name)\n    ret._cache = None\n    return ret",
            "def add_column(self, data, column_name='', inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with a new column. The number of elements in the data\\n        given must match the length of every other column of the SFrame.\\n        If no name is given, a default name is chosen.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : SArray\\n            The 'column' of data to add.\\n\\n        column_name : string, optional\\n            The name of the column. If no name is given, a default name is\\n            chosen.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sa = turicreate.SArray(['cat', 'dog', 'fossa'])\\n        >>> # This line is equivalent to `sf['species'] = sa`\\n        >>> res = sf.add_column(sa, 'species')\\n        >>> res\\n        +----+-----+---------+\\n        | id | val | species |\\n        +----+-----+---------+\\n        | 1  |  A  |   cat   |\\n        | 2  |  B  |   dog   |\\n        | 3  |  C  |  fossa  |\\n        +----+-----+---------+\\n        [3 rows x 3 columns]\\n        \"\n    if not isinstance(data, SArray):\n        if isinstance(data, _Iterable):\n            data = SArray(data)\n        elif self.num_columns() == 0:\n            data = SArray([data])\n        else:\n            data = SArray.from_const(data, self.num_rows())\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column name: must be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_column(data.__proxy__, column_name)\n    ret._cache = None\n    return ret",
            "def add_column(self, data, column_name='', inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with a new column. The number of elements in the data\\n        given must match the length of every other column of the SFrame.\\n        If no name is given, a default name is chosen.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : SArray\\n            The 'column' of data to add.\\n\\n        column_name : string, optional\\n            The name of the column. If no name is given, a default name is\\n            chosen.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sa = turicreate.SArray(['cat', 'dog', 'fossa'])\\n        >>> # This line is equivalent to `sf['species'] = sa`\\n        >>> res = sf.add_column(sa, 'species')\\n        >>> res\\n        +----+-----+---------+\\n        | id | val | species |\\n        +----+-----+---------+\\n        | 1  |  A  |   cat   |\\n        | 2  |  B  |   dog   |\\n        | 3  |  C  |  fossa  |\\n        +----+-----+---------+\\n        [3 rows x 3 columns]\\n        \"\n    if not isinstance(data, SArray):\n        if isinstance(data, _Iterable):\n            data = SArray(data)\n        elif self.num_columns() == 0:\n            data = SArray([data])\n        else:\n            data = SArray.from_const(data, self.num_rows())\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column name: must be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_column(data.__proxy__, column_name)\n    ret._cache = None\n    return ret",
            "def add_column(self, data, column_name='', inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with a new column. The number of elements in the data\\n        given must match the length of every other column of the SFrame.\\n        If no name is given, a default name is chosen.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : SArray\\n            The 'column' of data to add.\\n\\n        column_name : string, optional\\n            The name of the column. If no name is given, a default name is\\n            chosen.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sa = turicreate.SArray(['cat', 'dog', 'fossa'])\\n        >>> # This line is equivalent to `sf['species'] = sa`\\n        >>> res = sf.add_column(sa, 'species')\\n        >>> res\\n        +----+-----+---------+\\n        | id | val | species |\\n        +----+-----+---------+\\n        | 1  |  A  |   cat   |\\n        | 2  |  B  |   dog   |\\n        | 3  |  C  |  fossa  |\\n        +----+-----+---------+\\n        [3 rows x 3 columns]\\n        \"\n    if not isinstance(data, SArray):\n        if isinstance(data, _Iterable):\n            data = SArray(data)\n        elif self.num_columns() == 0:\n            data = SArray([data])\n        else:\n            data = SArray.from_const(data, self.num_rows())\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column name: must be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_column(data.__proxy__, column_name)\n    ret._cache = None\n    return ret",
            "def add_column(self, data, column_name='', inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with a new column. The number of elements in the data\\n        given must match the length of every other column of the SFrame.\\n        If no name is given, a default name is chosen.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : SArray\\n            The 'column' of data to add.\\n\\n        column_name : string, optional\\n            The name of the column. If no name is given, a default name is\\n            chosen.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_columns\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sa = turicreate.SArray(['cat', 'dog', 'fossa'])\\n        >>> # This line is equivalent to `sf['species'] = sa`\\n        >>> res = sf.add_column(sa, 'species')\\n        >>> res\\n        +----+-----+---------+\\n        | id | val | species |\\n        +----+-----+---------+\\n        | 1  |  A  |   cat   |\\n        | 2  |  B  |   dog   |\\n        | 3  |  C  |  fossa  |\\n        +----+-----+---------+\\n        [3 rows x 3 columns]\\n        \"\n    if not isinstance(data, SArray):\n        if isinstance(data, _Iterable):\n            data = SArray(data)\n        elif self.num_columns() == 0:\n            data = SArray([data])\n        else:\n            data = SArray.from_const(data, self.num_rows())\n    if not isinstance(column_name, str):\n        raise TypeError('Invalid column name: must be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_column(data.__proxy__, column_name)\n    ret._cache = None\n    return ret"
        ]
    },
    {
        "func_name": "add_columns",
        "original": "def add_columns(self, data, column_names=None, inplace=False):\n    \"\"\"\n        Returns an SFrame with multiple columns added. The number of\n        elements in all columns must match the length of every other column of\n        the SFrame.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        data : list[SArray] or SFrame\n            The columns to add.\n\n        column_names: list of string, optional\n            A list of column names. All names must be specified. ``column_names`` is\n            ignored if data is an SFrame.\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The current SFrame.\n\n        See Also\n        --------\n        add_column\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\n        >>> sf2 = turicreate.SFrame({'species': ['cat', 'dog', 'fossa'],\n        ...                        'age': [3, 5, 9]})\n        >>> res = sf.add_columns(sf2)\n        >>> res\n        +----+-----+-----+---------+\n        | id | val | age | species |\n        +----+-----+-----+---------+\n        | 1  |  A  |  3  |   cat   |\n        | 2  |  B  |  5  |   dog   |\n        | 3  |  C  |  9  |  fossa  |\n        +----+-----+-----+---------+\n        [3 rows x 4 columns]\n        \"\"\"\n    datalist = data\n    if isinstance(data, SFrame):\n        other = data\n        datalist = [other.select_column(name) for name in other.column_names()]\n        column_names = other.column_names()\n        my_columns = set(self.column_names())\n        for name in column_names:\n            if name in my_columns:\n                raise ValueError(\"Column '\" + name + \"' already exists in current SFrame\")\n    else:\n        if not _is_non_string_iterable(datalist):\n            raise TypeError('datalist must be an iterable')\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable')\n        if not all([isinstance(x, SArray) for x in datalist]):\n            raise TypeError('Must give column as SArray')\n        if not all([isinstance(x, str) for x in column_names]):\n            raise TypeError('Invalid column name in list : must all be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_columns([x.__proxy__ for x in datalist], column_names)\n    ret._cache = None\n    return ret",
        "mutated": [
            "def add_columns(self, data, column_names=None, inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with multiple columns added. The number of\\n        elements in all columns must match the length of every other column of\\n        the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : list[SArray] or SFrame\\n            The columns to add.\\n\\n        column_names: list of string, optional\\n            A list of column names. All names must be specified. ``column_names`` is\\n            ignored if data is an SFrame.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf2 = turicreate.SFrame({'species': ['cat', 'dog', 'fossa'],\\n        ...                        'age': [3, 5, 9]})\\n        >>> res = sf.add_columns(sf2)\\n        >>> res\\n        +----+-----+-----+---------+\\n        | id | val | age | species |\\n        +----+-----+-----+---------+\\n        | 1  |  A  |  3  |   cat   |\\n        | 2  |  B  |  5  |   dog   |\\n        | 3  |  C  |  9  |  fossa  |\\n        +----+-----+-----+---------+\\n        [3 rows x 4 columns]\\n        \"\n    datalist = data\n    if isinstance(data, SFrame):\n        other = data\n        datalist = [other.select_column(name) for name in other.column_names()]\n        column_names = other.column_names()\n        my_columns = set(self.column_names())\n        for name in column_names:\n            if name in my_columns:\n                raise ValueError(\"Column '\" + name + \"' already exists in current SFrame\")\n    else:\n        if not _is_non_string_iterable(datalist):\n            raise TypeError('datalist must be an iterable')\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable')\n        if not all([isinstance(x, SArray) for x in datalist]):\n            raise TypeError('Must give column as SArray')\n        if not all([isinstance(x, str) for x in column_names]):\n            raise TypeError('Invalid column name in list : must all be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_columns([x.__proxy__ for x in datalist], column_names)\n    ret._cache = None\n    return ret",
            "def add_columns(self, data, column_names=None, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with multiple columns added. The number of\\n        elements in all columns must match the length of every other column of\\n        the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : list[SArray] or SFrame\\n            The columns to add.\\n\\n        column_names: list of string, optional\\n            A list of column names. All names must be specified. ``column_names`` is\\n            ignored if data is an SFrame.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf2 = turicreate.SFrame({'species': ['cat', 'dog', 'fossa'],\\n        ...                        'age': [3, 5, 9]})\\n        >>> res = sf.add_columns(sf2)\\n        >>> res\\n        +----+-----+-----+---------+\\n        | id | val | age | species |\\n        +----+-----+-----+---------+\\n        | 1  |  A  |  3  |   cat   |\\n        | 2  |  B  |  5  |   dog   |\\n        | 3  |  C  |  9  |  fossa  |\\n        +----+-----+-----+---------+\\n        [3 rows x 4 columns]\\n        \"\n    datalist = data\n    if isinstance(data, SFrame):\n        other = data\n        datalist = [other.select_column(name) for name in other.column_names()]\n        column_names = other.column_names()\n        my_columns = set(self.column_names())\n        for name in column_names:\n            if name in my_columns:\n                raise ValueError(\"Column '\" + name + \"' already exists in current SFrame\")\n    else:\n        if not _is_non_string_iterable(datalist):\n            raise TypeError('datalist must be an iterable')\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable')\n        if not all([isinstance(x, SArray) for x in datalist]):\n            raise TypeError('Must give column as SArray')\n        if not all([isinstance(x, str) for x in column_names]):\n            raise TypeError('Invalid column name in list : must all be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_columns([x.__proxy__ for x in datalist], column_names)\n    ret._cache = None\n    return ret",
            "def add_columns(self, data, column_names=None, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with multiple columns added. The number of\\n        elements in all columns must match the length of every other column of\\n        the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : list[SArray] or SFrame\\n            The columns to add.\\n\\n        column_names: list of string, optional\\n            A list of column names. All names must be specified. ``column_names`` is\\n            ignored if data is an SFrame.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf2 = turicreate.SFrame({'species': ['cat', 'dog', 'fossa'],\\n        ...                        'age': [3, 5, 9]})\\n        >>> res = sf.add_columns(sf2)\\n        >>> res\\n        +----+-----+-----+---------+\\n        | id | val | age | species |\\n        +----+-----+-----+---------+\\n        | 1  |  A  |  3  |   cat   |\\n        | 2  |  B  |  5  |   dog   |\\n        | 3  |  C  |  9  |  fossa  |\\n        +----+-----+-----+---------+\\n        [3 rows x 4 columns]\\n        \"\n    datalist = data\n    if isinstance(data, SFrame):\n        other = data\n        datalist = [other.select_column(name) for name in other.column_names()]\n        column_names = other.column_names()\n        my_columns = set(self.column_names())\n        for name in column_names:\n            if name in my_columns:\n                raise ValueError(\"Column '\" + name + \"' already exists in current SFrame\")\n    else:\n        if not _is_non_string_iterable(datalist):\n            raise TypeError('datalist must be an iterable')\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable')\n        if not all([isinstance(x, SArray) for x in datalist]):\n            raise TypeError('Must give column as SArray')\n        if not all([isinstance(x, str) for x in column_names]):\n            raise TypeError('Invalid column name in list : must all be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_columns([x.__proxy__ for x in datalist], column_names)\n    ret._cache = None\n    return ret",
            "def add_columns(self, data, column_names=None, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with multiple columns added. The number of\\n        elements in all columns must match the length of every other column of\\n        the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : list[SArray] or SFrame\\n            The columns to add.\\n\\n        column_names: list of string, optional\\n            A list of column names. All names must be specified. ``column_names`` is\\n            ignored if data is an SFrame.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf2 = turicreate.SFrame({'species': ['cat', 'dog', 'fossa'],\\n        ...                        'age': [3, 5, 9]})\\n        >>> res = sf.add_columns(sf2)\\n        >>> res\\n        +----+-----+-----+---------+\\n        | id | val | age | species |\\n        +----+-----+-----+---------+\\n        | 1  |  A  |  3  |   cat   |\\n        | 2  |  B  |  5  |   dog   |\\n        | 3  |  C  |  9  |  fossa  |\\n        +----+-----+-----+---------+\\n        [3 rows x 4 columns]\\n        \"\n    datalist = data\n    if isinstance(data, SFrame):\n        other = data\n        datalist = [other.select_column(name) for name in other.column_names()]\n        column_names = other.column_names()\n        my_columns = set(self.column_names())\n        for name in column_names:\n            if name in my_columns:\n                raise ValueError(\"Column '\" + name + \"' already exists in current SFrame\")\n    else:\n        if not _is_non_string_iterable(datalist):\n            raise TypeError('datalist must be an iterable')\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable')\n        if not all([isinstance(x, SArray) for x in datalist]):\n            raise TypeError('Must give column as SArray')\n        if not all([isinstance(x, str) for x in column_names]):\n            raise TypeError('Invalid column name in list : must all be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_columns([x.__proxy__ for x in datalist], column_names)\n    ret._cache = None\n    return ret",
            "def add_columns(self, data, column_names=None, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with multiple columns added. The number of\\n        elements in all columns must match the length of every other column of\\n        the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        data : list[SArray] or SFrame\\n            The columns to add.\\n\\n        column_names: list of string, optional\\n            A list of column names. All names must be specified. ``column_names`` is\\n            ignored if data is an SFrame.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        add_column\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf2 = turicreate.SFrame({'species': ['cat', 'dog', 'fossa'],\\n        ...                        'age': [3, 5, 9]})\\n        >>> res = sf.add_columns(sf2)\\n        >>> res\\n        +----+-----+-----+---------+\\n        | id | val | age | species |\\n        +----+-----+-----+---------+\\n        | 1  |  A  |  3  |   cat   |\\n        | 2  |  B  |  5  |   dog   |\\n        | 3  |  C  |  9  |  fossa  |\\n        +----+-----+-----+---------+\\n        [3 rows x 4 columns]\\n        \"\n    datalist = data\n    if isinstance(data, SFrame):\n        other = data\n        datalist = [other.select_column(name) for name in other.column_names()]\n        column_names = other.column_names()\n        my_columns = set(self.column_names())\n        for name in column_names:\n            if name in my_columns:\n                raise ValueError(\"Column '\" + name + \"' already exists in current SFrame\")\n    else:\n        if not _is_non_string_iterable(datalist):\n            raise TypeError('datalist must be an iterable')\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable')\n        if not all([isinstance(x, SArray) for x in datalist]):\n            raise TypeError('Must give column as SArray')\n        if not all([isinstance(x, str) for x in column_names]):\n            raise TypeError('Invalid column name in list : must all be str')\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.add_columns([x.__proxy__ for x in datalist], column_names)\n    ret._cache = None\n    return ret"
        ]
    },
    {
        "func_name": "remove_column",
        "original": "def remove_column(self, column_name, inplace=False):\n    \"\"\"\n        Returns an SFrame with a column removed.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        column_name : string\n            The name of the column to remove.\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The SFrame with given column removed.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\n        >>> # This is equivalent to `del sf['val']`\n        >>> res = sf.remove_column('val')\n        >>> res\n        +----+\n        | id |\n        +----+\n        | 1  |\n        | 2  |\n        | 3  |\n        +----+\n        [3 rows x 1 columns]\n        \"\"\"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise KeyError('Cannot find column %s' % column_name)\n    colid = self.column_names().index(column_name)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
        "mutated": [
            "def remove_column(self, column_name, inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with a column removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The name of the column to remove.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given column removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> # This is equivalent to `del sf['val']`\\n        >>> res = sf.remove_column('val')\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise KeyError('Cannot find column %s' % column_name)\n    colid = self.column_names().index(column_name)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_column(self, column_name, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with a column removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The name of the column to remove.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given column removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> # This is equivalent to `del sf['val']`\\n        >>> res = sf.remove_column('val')\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise KeyError('Cannot find column %s' % column_name)\n    colid = self.column_names().index(column_name)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_column(self, column_name, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with a column removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The name of the column to remove.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given column removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> # This is equivalent to `del sf['val']`\\n        >>> res = sf.remove_column('val')\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise KeyError('Cannot find column %s' % column_name)\n    colid = self.column_names().index(column_name)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_column(self, column_name, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with a column removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The name of the column to remove.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given column removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> # This is equivalent to `del sf['val']`\\n        >>> res = sf.remove_column('val')\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise KeyError('Cannot find column %s' % column_name)\n    colid = self.column_names().index(column_name)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_column(self, column_name, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with a column removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : string\\n            The name of the column to remove.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given column removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> # This is equivalent to `del sf['val']`\\n        >>> res = sf.remove_column('val')\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise KeyError('Cannot find column %s' % column_name)\n    colid = self.column_names().index(column_name)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret"
        ]
    },
    {
        "func_name": "remove_columns",
        "original": "def remove_columns(self, column_names, inplace=False):\n    \"\"\"\n        Returns an SFrame with one or more columns removed.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        column_names : list or iterable\n            A list or iterable of column names.\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The SFrame with given columns removed.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val1': ['A', 'B', 'C'], 'val2' : [10, 11, 12]})\n        >>> res = sf.remove_columns(['val1', 'val2'])\n        >>> res\n        +----+\n        | id |\n        +----+\n        | 1  |\n        | 2  |\n        | 3  |\n        +----+\n        [3 rows x 1 columns]\n        \"\"\"\n    column_names = list(column_names)\n    existing_columns = dict(((k, i) for (i, k) in enumerate(self.column_names())))\n    for name in column_names:\n        if name not in existing_columns:\n            raise KeyError('Cannot find column %s' % name)\n    deletion_indices = sorted((existing_columns[name] for name in column_names))\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    for colid in reversed(deletion_indices):\n        with cython_context():\n            ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
        "mutated": [
            "def remove_columns(self, column_names, inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with one or more columns removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_names : list or iterable\\n            A list or iterable of column names.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given columns removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val1': ['A', 'B', 'C'], 'val2' : [10, 11, 12]})\\n        >>> res = sf.remove_columns(['val1', 'val2'])\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_names = list(column_names)\n    existing_columns = dict(((k, i) for (i, k) in enumerate(self.column_names())))\n    for name in column_names:\n        if name not in existing_columns:\n            raise KeyError('Cannot find column %s' % name)\n    deletion_indices = sorted((existing_columns[name] for name in column_names))\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    for colid in reversed(deletion_indices):\n        with cython_context():\n            ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_columns(self, column_names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with one or more columns removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_names : list or iterable\\n            A list or iterable of column names.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given columns removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val1': ['A', 'B', 'C'], 'val2' : [10, 11, 12]})\\n        >>> res = sf.remove_columns(['val1', 'val2'])\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_names = list(column_names)\n    existing_columns = dict(((k, i) for (i, k) in enumerate(self.column_names())))\n    for name in column_names:\n        if name not in existing_columns:\n            raise KeyError('Cannot find column %s' % name)\n    deletion_indices = sorted((existing_columns[name] for name in column_names))\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    for colid in reversed(deletion_indices):\n        with cython_context():\n            ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_columns(self, column_names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with one or more columns removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_names : list or iterable\\n            A list or iterable of column names.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given columns removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val1': ['A', 'B', 'C'], 'val2' : [10, 11, 12]})\\n        >>> res = sf.remove_columns(['val1', 'val2'])\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_names = list(column_names)\n    existing_columns = dict(((k, i) for (i, k) in enumerate(self.column_names())))\n    for name in column_names:\n        if name not in existing_columns:\n            raise KeyError('Cannot find column %s' % name)\n    deletion_indices = sorted((existing_columns[name] for name in column_names))\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    for colid in reversed(deletion_indices):\n        with cython_context():\n            ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_columns(self, column_names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with one or more columns removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_names : list or iterable\\n            A list or iterable of column names.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given columns removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val1': ['A', 'B', 'C'], 'val2' : [10, 11, 12]})\\n        >>> res = sf.remove_columns(['val1', 'val2'])\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_names = list(column_names)\n    existing_columns = dict(((k, i) for (i, k) in enumerate(self.column_names())))\n    for name in column_names:\n        if name not in existing_columns:\n            raise KeyError('Cannot find column %s' % name)\n    deletion_indices = sorted((existing_columns[name] for name in column_names))\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    for colid in reversed(deletion_indices):\n        with cython_context():\n            ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret",
            "def remove_columns(self, column_names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with one or more columns removed.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_names : list or iterable\\n            A list or iterable of column names.\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with given columns removed.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val1': ['A', 'B', 'C'], 'val2' : [10, 11, 12]})\\n        >>> res = sf.remove_columns(['val1', 'val2'])\\n        >>> res\\n        +----+\\n        | id |\\n        +----+\\n        | 1  |\\n        | 2  |\\n        | 3  |\\n        +----+\\n        [3 rows x 1 columns]\\n        \"\n    column_names = list(column_names)\n    existing_columns = dict(((k, i) for (i, k) in enumerate(self.column_names())))\n    for name in column_names:\n        if name not in existing_columns:\n            raise KeyError('Cannot find column %s' % name)\n    deletion_indices = sorted((existing_columns[name] for name in column_names))\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    for colid in reversed(deletion_indices):\n        with cython_context():\n            ret.__proxy__.remove_column(colid)\n    ret._cache = None\n    return ret"
        ]
    },
    {
        "func_name": "swap_columns",
        "original": "def swap_columns(self, column_name_1, column_name_2, inplace=False):\n    \"\"\"\n        Returns an SFrame with two column positions swapped.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        column_name_1 : string\n            Name of column to swap\n\n        column_name_2 : string\n            Name of other column to swap\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The SFrame with swapped columns.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\n        >>> res = sf.swap_columns('id', 'val')\n        >>> res\n        +-----+-----+\n        | val | id  |\n        +-----+-----+\n        |  A  |  1  |\n        |  B  |  2  |\n        |  C  |  3  |\n        +----+-----+\n        [3 rows x 2 columns]\n        \"\"\"\n    colnames = self.column_names()\n    colid_1 = colnames.index(column_name_1)\n    colid_2 = colnames.index(column_name_2)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.swap_columns(colid_1, colid_2)\n    ret._cache = None\n    return ret",
        "mutated": [
            "def swap_columns(self, column_name_1, column_name_2, inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with two column positions swapped.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name_1 : string\\n            Name of column to swap\\n\\n        column_name_2 : string\\n            Name of other column to swap\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with swapped columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> res = sf.swap_columns('id', 'val')\\n        >>> res\\n        +-----+-----+\\n        | val | id  |\\n        +-----+-----+\\n        |  A  |  1  |\\n        |  B  |  2  |\\n        |  C  |  3  |\\n        +----+-----+\\n        [3 rows x 2 columns]\\n        \"\n    colnames = self.column_names()\n    colid_1 = colnames.index(column_name_1)\n    colid_2 = colnames.index(column_name_2)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.swap_columns(colid_1, colid_2)\n    ret._cache = None\n    return ret",
            "def swap_columns(self, column_name_1, column_name_2, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with two column positions swapped.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name_1 : string\\n            Name of column to swap\\n\\n        column_name_2 : string\\n            Name of other column to swap\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with swapped columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> res = sf.swap_columns('id', 'val')\\n        >>> res\\n        +-----+-----+\\n        | val | id  |\\n        +-----+-----+\\n        |  A  |  1  |\\n        |  B  |  2  |\\n        |  C  |  3  |\\n        +----+-----+\\n        [3 rows x 2 columns]\\n        \"\n    colnames = self.column_names()\n    colid_1 = colnames.index(column_name_1)\n    colid_2 = colnames.index(column_name_2)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.swap_columns(colid_1, colid_2)\n    ret._cache = None\n    return ret",
            "def swap_columns(self, column_name_1, column_name_2, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with two column positions swapped.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name_1 : string\\n            Name of column to swap\\n\\n        column_name_2 : string\\n            Name of other column to swap\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with swapped columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> res = sf.swap_columns('id', 'val')\\n        >>> res\\n        +-----+-----+\\n        | val | id  |\\n        +-----+-----+\\n        |  A  |  1  |\\n        |  B  |  2  |\\n        |  C  |  3  |\\n        +----+-----+\\n        [3 rows x 2 columns]\\n        \"\n    colnames = self.column_names()\n    colid_1 = colnames.index(column_name_1)\n    colid_2 = colnames.index(column_name_2)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.swap_columns(colid_1, colid_2)\n    ret._cache = None\n    return ret",
            "def swap_columns(self, column_name_1, column_name_2, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with two column positions swapped.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name_1 : string\\n            Name of column to swap\\n\\n        column_name_2 : string\\n            Name of other column to swap\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with swapped columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> res = sf.swap_columns('id', 'val')\\n        >>> res\\n        +-----+-----+\\n        | val | id  |\\n        +-----+-----+\\n        |  A  |  1  |\\n        |  B  |  2  |\\n        |  C  |  3  |\\n        +----+-----+\\n        [3 rows x 2 columns]\\n        \"\n    colnames = self.column_names()\n    colid_1 = colnames.index(column_name_1)\n    colid_2 = colnames.index(column_name_2)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.swap_columns(colid_1, colid_2)\n    ret._cache = None\n    return ret",
            "def swap_columns(self, column_name_1, column_name_2, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with two column positions swapped.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name_1 : string\\n            Name of column to swap\\n\\n        column_name_2 : string\\n            Name of other column to swap\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The SFrame with swapped columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> res = sf.swap_columns('id', 'val')\\n        >>> res\\n        +-----+-----+\\n        | val | id  |\\n        +-----+-----+\\n        |  A  |  1  |\\n        |  B  |  2  |\\n        |  C  |  3  |\\n        +----+-----+\\n        [3 rows x 2 columns]\\n        \"\n    colnames = self.column_names()\n    colid_1 = colnames.index(column_name_1)\n    colid_2 = colnames.index(column_name_2)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        ret.__proxy__.swap_columns(colid_1, colid_2)\n    ret._cache = None\n    return ret"
        ]
    },
    {
        "func_name": "rename",
        "original": "def rename(self, names, inplace=False):\n    \"\"\"\n        Returns an SFrame with columns renamed. ``names`` is expected to be a\n        dict specifying the old and new names. This changes the names of the\n        columns given as the keys and replaces them with the names given as the\n        values.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        names : dict [string, string]\n            Dictionary of [old_name, new_name]\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The current SFrame.\n\n        See Also\n        --------\n        column_names\n\n        Examples\n        --------\n        >>> sf = SFrame({'X1': ['Alice','Bob'],\n        ...              'X2': ['123 Fake Street','456 Fake Street']})\n        >>> res = sf.rename({'X1': 'name', 'X2':'address'})\n        >>> res\n        +-------+-----------------+\n        |  name |     address     |\n        +-------+-----------------+\n        | Alice | 123 Fake Street |\n        |  Bob  | 456 Fake Street |\n        +-------+-----------------+\n        [2 rows x 2 columns]\n        \"\"\"\n    if type(names) is not dict:\n        raise TypeError('names must be a dictionary: oldname -> newname')\n    all_columns = set(self.column_names())\n    for k in names:\n        if not k in all_columns:\n            raise ValueError('Cannot find column %s in the SFrame' % k)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        for k in names:\n            colid = ret.column_names().index(k)\n            ret.__proxy__.set_column_name(colid, names[k])\n    ret._cache = None\n    return ret",
        "mutated": [
            "def rename(self, names, inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with columns renamed. ``names`` is expected to be a\\n        dict specifying the old and new names. This changes the names of the\\n        columns given as the keys and replaces them with the names given as the\\n        values.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        names : dict [string, string]\\n            Dictionary of [old_name, new_name]\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        column_names\\n\\n        Examples\\n        --------\\n        >>> sf = SFrame({'X1': ['Alice','Bob'],\\n        ...              'X2': ['123 Fake Street','456 Fake Street']})\\n        >>> res = sf.rename({'X1': 'name', 'X2':'address'})\\n        >>> res\\n        +-------+-----------------+\\n        |  name |     address     |\\n        +-------+-----------------+\\n        | Alice | 123 Fake Street |\\n        |  Bob  | 456 Fake Street |\\n        +-------+-----------------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(names) is not dict:\n        raise TypeError('names must be a dictionary: oldname -> newname')\n    all_columns = set(self.column_names())\n    for k in names:\n        if not k in all_columns:\n            raise ValueError('Cannot find column %s in the SFrame' % k)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        for k in names:\n            colid = ret.column_names().index(k)\n            ret.__proxy__.set_column_name(colid, names[k])\n    ret._cache = None\n    return ret",
            "def rename(self, names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with columns renamed. ``names`` is expected to be a\\n        dict specifying the old and new names. This changes the names of the\\n        columns given as the keys and replaces them with the names given as the\\n        values.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        names : dict [string, string]\\n            Dictionary of [old_name, new_name]\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        column_names\\n\\n        Examples\\n        --------\\n        >>> sf = SFrame({'X1': ['Alice','Bob'],\\n        ...              'X2': ['123 Fake Street','456 Fake Street']})\\n        >>> res = sf.rename({'X1': 'name', 'X2':'address'})\\n        >>> res\\n        +-------+-----------------+\\n        |  name |     address     |\\n        +-------+-----------------+\\n        | Alice | 123 Fake Street |\\n        |  Bob  | 456 Fake Street |\\n        +-------+-----------------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(names) is not dict:\n        raise TypeError('names must be a dictionary: oldname -> newname')\n    all_columns = set(self.column_names())\n    for k in names:\n        if not k in all_columns:\n            raise ValueError('Cannot find column %s in the SFrame' % k)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        for k in names:\n            colid = ret.column_names().index(k)\n            ret.__proxy__.set_column_name(colid, names[k])\n    ret._cache = None\n    return ret",
            "def rename(self, names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with columns renamed. ``names`` is expected to be a\\n        dict specifying the old and new names. This changes the names of the\\n        columns given as the keys and replaces them with the names given as the\\n        values.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        names : dict [string, string]\\n            Dictionary of [old_name, new_name]\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        column_names\\n\\n        Examples\\n        --------\\n        >>> sf = SFrame({'X1': ['Alice','Bob'],\\n        ...              'X2': ['123 Fake Street','456 Fake Street']})\\n        >>> res = sf.rename({'X1': 'name', 'X2':'address'})\\n        >>> res\\n        +-------+-----------------+\\n        |  name |     address     |\\n        +-------+-----------------+\\n        | Alice | 123 Fake Street |\\n        |  Bob  | 456 Fake Street |\\n        +-------+-----------------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(names) is not dict:\n        raise TypeError('names must be a dictionary: oldname -> newname')\n    all_columns = set(self.column_names())\n    for k in names:\n        if not k in all_columns:\n            raise ValueError('Cannot find column %s in the SFrame' % k)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        for k in names:\n            colid = ret.column_names().index(k)\n            ret.__proxy__.set_column_name(colid, names[k])\n    ret._cache = None\n    return ret",
            "def rename(self, names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with columns renamed. ``names`` is expected to be a\\n        dict specifying the old and new names. This changes the names of the\\n        columns given as the keys and replaces them with the names given as the\\n        values.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        names : dict [string, string]\\n            Dictionary of [old_name, new_name]\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        column_names\\n\\n        Examples\\n        --------\\n        >>> sf = SFrame({'X1': ['Alice','Bob'],\\n        ...              'X2': ['123 Fake Street','456 Fake Street']})\\n        >>> res = sf.rename({'X1': 'name', 'X2':'address'})\\n        >>> res\\n        +-------+-----------------+\\n        |  name |     address     |\\n        +-------+-----------------+\\n        | Alice | 123 Fake Street |\\n        |  Bob  | 456 Fake Street |\\n        +-------+-----------------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(names) is not dict:\n        raise TypeError('names must be a dictionary: oldname -> newname')\n    all_columns = set(self.column_names())\n    for k in names:\n        if not k in all_columns:\n            raise ValueError('Cannot find column %s in the SFrame' % k)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        for k in names:\n            colid = ret.column_names().index(k)\n            ret.__proxy__.set_column_name(colid, names[k])\n    ret._cache = None\n    return ret",
            "def rename(self, names, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with columns renamed. ``names`` is expected to be a\\n        dict specifying the old and new names. This changes the names of the\\n        columns given as the keys and replaces them with the names given as the\\n        values.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        names : dict [string, string]\\n            Dictionary of [old_name, new_name]\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The current SFrame.\\n\\n        See Also\\n        --------\\n        column_names\\n\\n        Examples\\n        --------\\n        >>> sf = SFrame({'X1': ['Alice','Bob'],\\n        ...              'X2': ['123 Fake Street','456 Fake Street']})\\n        >>> res = sf.rename({'X1': 'name', 'X2':'address'})\\n        >>> res\\n        +-------+-----------------+\\n        |  name |     address     |\\n        +-------+-----------------+\\n        | Alice | 123 Fake Street |\\n        |  Bob  | 456 Fake Street |\\n        +-------+-----------------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(names) is not dict:\n        raise TypeError('names must be a dictionary: oldname -> newname')\n    all_columns = set(self.column_names())\n    for k in names:\n        if not k in all_columns:\n            raise ValueError('Cannot find column %s in the SFrame' % k)\n    if inplace:\n        ret = self\n    else:\n        ret = self.copy()\n    with cython_context():\n        for k in names:\n            colid = ret.column_names().index(k)\n            ret.__proxy__.set_column_name(colid, names[k])\n    ret._cache = None\n    return ret"
        ]
    },
    {
        "func_name": "__getitem__",
        "original": "def __getitem__(self, key):\n    \"\"\"\n        This method does things based on the type of `key`.\n\n        If `key` is:\n            * str\n                selects column with name 'key'\n            * type\n                selects all columns with types matching the type\n            * list of str or type\n                selects all columns with names or type in the list\n            * SArray\n                Performs a logical filter.  Expects given SArray to be the same\n                length as all columns in current SFrame.  Every row\n                corresponding with an entry in the given SArray that is\n                equivalent to False is filtered from the result.\n            * int\n                Returns a single row of the SFrame (the `key`th one) as a dictionary.\n            * slice\n                Returns an SFrame including only the sliced rows.\n        \"\"\"\n    if type(key) is SArray:\n        return self._row_selector(key)\n    elif isinstance(key, six.string_types):\n        if six.PY2 and type(key) == unicode:\n            key = key.encode('utf-8')\n        return self.select_column(key)\n    elif type(key) is type:\n        return self.select_columns([key])\n    elif _is_non_string_iterable(key):\n        return self.select_columns(key)\n    elif isinstance(key, numbers.Integral):\n        sf_len = len(self)\n        if key < 0:\n            key = sf_len + key\n        if key >= sf_len:\n            raise IndexError('SFrame index out of range')\n        if not hasattr(self, '_cache') or self._cache is None:\n            self._cache = {}\n        try:\n            (lb, ub, value_list) = self._cache['getitem_cache']\n            if lb <= key < ub:\n                return value_list[int(key - lb)]\n        except KeyError:\n            pass\n        if not 'getitem_cache_blocksize' in self._cache:\n            block_size = 8 * 1024 // sum((2 if dt in [int, long, float] else 8 for dt in self.column_types()))\n            block_size = max(16, block_size)\n            self._cache['getitem_cache_blocksize'] = block_size\n        else:\n            block_size = self._cache['getitem_cache_blocksize']\n        block_num = int(key // block_size)\n        lb = block_num * block_size\n        ub = min(sf_len, lb + block_size)\n        val_list = list(SFrame(_proxy=self.__proxy__.copy_range(lb, 1, ub)))\n        self._cache['getitem_cache'] = (lb, ub, val_list)\n        return val_list[int(key - lb)]\n    elif type(key) is slice:\n        start = key.start\n        stop = key.stop\n        step = key.step\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(self)\n        if step is None:\n            step = 1\n        if start < 0:\n            start = len(self) + start\n        if stop < 0:\n            stop = len(self) + stop\n        return SFrame(_proxy=self.__proxy__.copy_range(start, step, stop))\n    else:\n        raise TypeError('Invalid index type: must be SArray, list, int, or str')",
        "mutated": [
            "def __getitem__(self, key):\n    if False:\n        i = 10\n    \"\\n        This method does things based on the type of `key`.\\n\\n        If `key` is:\\n            * str\\n                selects column with name 'key'\\n            * type\\n                selects all columns with types matching the type\\n            * list of str or type\\n                selects all columns with names or type in the list\\n            * SArray\\n                Performs a logical filter.  Expects given SArray to be the same\\n                length as all columns in current SFrame.  Every row\\n                corresponding with an entry in the given SArray that is\\n                equivalent to False is filtered from the result.\\n            * int\\n                Returns a single row of the SFrame (the `key`th one) as a dictionary.\\n            * slice\\n                Returns an SFrame including only the sliced rows.\\n        \"\n    if type(key) is SArray:\n        return self._row_selector(key)\n    elif isinstance(key, six.string_types):\n        if six.PY2 and type(key) == unicode:\n            key = key.encode('utf-8')\n        return self.select_column(key)\n    elif type(key) is type:\n        return self.select_columns([key])\n    elif _is_non_string_iterable(key):\n        return self.select_columns(key)\n    elif isinstance(key, numbers.Integral):\n        sf_len = len(self)\n        if key < 0:\n            key = sf_len + key\n        if key >= sf_len:\n            raise IndexError('SFrame index out of range')\n        if not hasattr(self, '_cache') or self._cache is None:\n            self._cache = {}\n        try:\n            (lb, ub, value_list) = self._cache['getitem_cache']\n            if lb <= key < ub:\n                return value_list[int(key - lb)]\n        except KeyError:\n            pass\n        if not 'getitem_cache_blocksize' in self._cache:\n            block_size = 8 * 1024 // sum((2 if dt in [int, long, float] else 8 for dt in self.column_types()))\n            block_size = max(16, block_size)\n            self._cache['getitem_cache_blocksize'] = block_size\n        else:\n            block_size = self._cache['getitem_cache_blocksize']\n        block_num = int(key // block_size)\n        lb = block_num * block_size\n        ub = min(sf_len, lb + block_size)\n        val_list = list(SFrame(_proxy=self.__proxy__.copy_range(lb, 1, ub)))\n        self._cache['getitem_cache'] = (lb, ub, val_list)\n        return val_list[int(key - lb)]\n    elif type(key) is slice:\n        start = key.start\n        stop = key.stop\n        step = key.step\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(self)\n        if step is None:\n            step = 1\n        if start < 0:\n            start = len(self) + start\n        if stop < 0:\n            stop = len(self) + stop\n        return SFrame(_proxy=self.__proxy__.copy_range(start, step, stop))\n    else:\n        raise TypeError('Invalid index type: must be SArray, list, int, or str')",
            "def __getitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        This method does things based on the type of `key`.\\n\\n        If `key` is:\\n            * str\\n                selects column with name 'key'\\n            * type\\n                selects all columns with types matching the type\\n            * list of str or type\\n                selects all columns with names or type in the list\\n            * SArray\\n                Performs a logical filter.  Expects given SArray to be the same\\n                length as all columns in current SFrame.  Every row\\n                corresponding with an entry in the given SArray that is\\n                equivalent to False is filtered from the result.\\n            * int\\n                Returns a single row of the SFrame (the `key`th one) as a dictionary.\\n            * slice\\n                Returns an SFrame including only the sliced rows.\\n        \"\n    if type(key) is SArray:\n        return self._row_selector(key)\n    elif isinstance(key, six.string_types):\n        if six.PY2 and type(key) == unicode:\n            key = key.encode('utf-8')\n        return self.select_column(key)\n    elif type(key) is type:\n        return self.select_columns([key])\n    elif _is_non_string_iterable(key):\n        return self.select_columns(key)\n    elif isinstance(key, numbers.Integral):\n        sf_len = len(self)\n        if key < 0:\n            key = sf_len + key\n        if key >= sf_len:\n            raise IndexError('SFrame index out of range')\n        if not hasattr(self, '_cache') or self._cache is None:\n            self._cache = {}\n        try:\n            (lb, ub, value_list) = self._cache['getitem_cache']\n            if lb <= key < ub:\n                return value_list[int(key - lb)]\n        except KeyError:\n            pass\n        if not 'getitem_cache_blocksize' in self._cache:\n            block_size = 8 * 1024 // sum((2 if dt in [int, long, float] else 8 for dt in self.column_types()))\n            block_size = max(16, block_size)\n            self._cache['getitem_cache_blocksize'] = block_size\n        else:\n            block_size = self._cache['getitem_cache_blocksize']\n        block_num = int(key // block_size)\n        lb = block_num * block_size\n        ub = min(sf_len, lb + block_size)\n        val_list = list(SFrame(_proxy=self.__proxy__.copy_range(lb, 1, ub)))\n        self._cache['getitem_cache'] = (lb, ub, val_list)\n        return val_list[int(key - lb)]\n    elif type(key) is slice:\n        start = key.start\n        stop = key.stop\n        step = key.step\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(self)\n        if step is None:\n            step = 1\n        if start < 0:\n            start = len(self) + start\n        if stop < 0:\n            stop = len(self) + stop\n        return SFrame(_proxy=self.__proxy__.copy_range(start, step, stop))\n    else:\n        raise TypeError('Invalid index type: must be SArray, list, int, or str')",
            "def __getitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        This method does things based on the type of `key`.\\n\\n        If `key` is:\\n            * str\\n                selects column with name 'key'\\n            * type\\n                selects all columns with types matching the type\\n            * list of str or type\\n                selects all columns with names or type in the list\\n            * SArray\\n                Performs a logical filter.  Expects given SArray to be the same\\n                length as all columns in current SFrame.  Every row\\n                corresponding with an entry in the given SArray that is\\n                equivalent to False is filtered from the result.\\n            * int\\n                Returns a single row of the SFrame (the `key`th one) as a dictionary.\\n            * slice\\n                Returns an SFrame including only the sliced rows.\\n        \"\n    if type(key) is SArray:\n        return self._row_selector(key)\n    elif isinstance(key, six.string_types):\n        if six.PY2 and type(key) == unicode:\n            key = key.encode('utf-8')\n        return self.select_column(key)\n    elif type(key) is type:\n        return self.select_columns([key])\n    elif _is_non_string_iterable(key):\n        return self.select_columns(key)\n    elif isinstance(key, numbers.Integral):\n        sf_len = len(self)\n        if key < 0:\n            key = sf_len + key\n        if key >= sf_len:\n            raise IndexError('SFrame index out of range')\n        if not hasattr(self, '_cache') or self._cache is None:\n            self._cache = {}\n        try:\n            (lb, ub, value_list) = self._cache['getitem_cache']\n            if lb <= key < ub:\n                return value_list[int(key - lb)]\n        except KeyError:\n            pass\n        if not 'getitem_cache_blocksize' in self._cache:\n            block_size = 8 * 1024 // sum((2 if dt in [int, long, float] else 8 for dt in self.column_types()))\n            block_size = max(16, block_size)\n            self._cache['getitem_cache_blocksize'] = block_size\n        else:\n            block_size = self._cache['getitem_cache_blocksize']\n        block_num = int(key // block_size)\n        lb = block_num * block_size\n        ub = min(sf_len, lb + block_size)\n        val_list = list(SFrame(_proxy=self.__proxy__.copy_range(lb, 1, ub)))\n        self._cache['getitem_cache'] = (lb, ub, val_list)\n        return val_list[int(key - lb)]\n    elif type(key) is slice:\n        start = key.start\n        stop = key.stop\n        step = key.step\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(self)\n        if step is None:\n            step = 1\n        if start < 0:\n            start = len(self) + start\n        if stop < 0:\n            stop = len(self) + stop\n        return SFrame(_proxy=self.__proxy__.copy_range(start, step, stop))\n    else:\n        raise TypeError('Invalid index type: must be SArray, list, int, or str')",
            "def __getitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        This method does things based on the type of `key`.\\n\\n        If `key` is:\\n            * str\\n                selects column with name 'key'\\n            * type\\n                selects all columns with types matching the type\\n            * list of str or type\\n                selects all columns with names or type in the list\\n            * SArray\\n                Performs a logical filter.  Expects given SArray to be the same\\n                length as all columns in current SFrame.  Every row\\n                corresponding with an entry in the given SArray that is\\n                equivalent to False is filtered from the result.\\n            * int\\n                Returns a single row of the SFrame (the `key`th one) as a dictionary.\\n            * slice\\n                Returns an SFrame including only the sliced rows.\\n        \"\n    if type(key) is SArray:\n        return self._row_selector(key)\n    elif isinstance(key, six.string_types):\n        if six.PY2 and type(key) == unicode:\n            key = key.encode('utf-8')\n        return self.select_column(key)\n    elif type(key) is type:\n        return self.select_columns([key])\n    elif _is_non_string_iterable(key):\n        return self.select_columns(key)\n    elif isinstance(key, numbers.Integral):\n        sf_len = len(self)\n        if key < 0:\n            key = sf_len + key\n        if key >= sf_len:\n            raise IndexError('SFrame index out of range')\n        if not hasattr(self, '_cache') or self._cache is None:\n            self._cache = {}\n        try:\n            (lb, ub, value_list) = self._cache['getitem_cache']\n            if lb <= key < ub:\n                return value_list[int(key - lb)]\n        except KeyError:\n            pass\n        if not 'getitem_cache_blocksize' in self._cache:\n            block_size = 8 * 1024 // sum((2 if dt in [int, long, float] else 8 for dt in self.column_types()))\n            block_size = max(16, block_size)\n            self._cache['getitem_cache_blocksize'] = block_size\n        else:\n            block_size = self._cache['getitem_cache_blocksize']\n        block_num = int(key // block_size)\n        lb = block_num * block_size\n        ub = min(sf_len, lb + block_size)\n        val_list = list(SFrame(_proxy=self.__proxy__.copy_range(lb, 1, ub)))\n        self._cache['getitem_cache'] = (lb, ub, val_list)\n        return val_list[int(key - lb)]\n    elif type(key) is slice:\n        start = key.start\n        stop = key.stop\n        step = key.step\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(self)\n        if step is None:\n            step = 1\n        if start < 0:\n            start = len(self) + start\n        if stop < 0:\n            stop = len(self) + stop\n        return SFrame(_proxy=self.__proxy__.copy_range(start, step, stop))\n    else:\n        raise TypeError('Invalid index type: must be SArray, list, int, or str')",
            "def __getitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        This method does things based on the type of `key`.\\n\\n        If `key` is:\\n            * str\\n                selects column with name 'key'\\n            * type\\n                selects all columns with types matching the type\\n            * list of str or type\\n                selects all columns with names or type in the list\\n            * SArray\\n                Performs a logical filter.  Expects given SArray to be the same\\n                length as all columns in current SFrame.  Every row\\n                corresponding with an entry in the given SArray that is\\n                equivalent to False is filtered from the result.\\n            * int\\n                Returns a single row of the SFrame (the `key`th one) as a dictionary.\\n            * slice\\n                Returns an SFrame including only the sliced rows.\\n        \"\n    if type(key) is SArray:\n        return self._row_selector(key)\n    elif isinstance(key, six.string_types):\n        if six.PY2 and type(key) == unicode:\n            key = key.encode('utf-8')\n        return self.select_column(key)\n    elif type(key) is type:\n        return self.select_columns([key])\n    elif _is_non_string_iterable(key):\n        return self.select_columns(key)\n    elif isinstance(key, numbers.Integral):\n        sf_len = len(self)\n        if key < 0:\n            key = sf_len + key\n        if key >= sf_len:\n            raise IndexError('SFrame index out of range')\n        if not hasattr(self, '_cache') or self._cache is None:\n            self._cache = {}\n        try:\n            (lb, ub, value_list) = self._cache['getitem_cache']\n            if lb <= key < ub:\n                return value_list[int(key - lb)]\n        except KeyError:\n            pass\n        if not 'getitem_cache_blocksize' in self._cache:\n            block_size = 8 * 1024 // sum((2 if dt in [int, long, float] else 8 for dt in self.column_types()))\n            block_size = max(16, block_size)\n            self._cache['getitem_cache_blocksize'] = block_size\n        else:\n            block_size = self._cache['getitem_cache_blocksize']\n        block_num = int(key // block_size)\n        lb = block_num * block_size\n        ub = min(sf_len, lb + block_size)\n        val_list = list(SFrame(_proxy=self.__proxy__.copy_range(lb, 1, ub)))\n        self._cache['getitem_cache'] = (lb, ub, val_list)\n        return val_list[int(key - lb)]\n    elif type(key) is slice:\n        start = key.start\n        stop = key.stop\n        step = key.step\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = len(self)\n        if step is None:\n            step = 1\n        if start < 0:\n            start = len(self) + start\n        if stop < 0:\n            stop = len(self) + stop\n        return SFrame(_proxy=self.__proxy__.copy_range(start, step, stop))\n    else:\n        raise TypeError('Invalid index type: must be SArray, list, int, or str')"
        ]
    },
    {
        "func_name": "__setitem__",
        "original": "def __setitem__(self, key, value):\n    \"\"\"\n        A wrapper around add_column(s).  Key can be either a list or a str.  If\n        value is an SArray, it is added to the SFrame as a column.  If it is a\n        constant value (int, str, or float), then a column is created where\n        every entry is equal to the constant value.  Existing columns can also\n        be replaced using this wrapper.\n        \"\"\"\n    if type(key) is list:\n        self.add_columns(value, key, inplace=True)\n    elif type(key) is str:\n        sa_value = None\n        if type(value) is SArray:\n            sa_value = value\n        elif _is_non_string_iterable(value):\n            sa_value = SArray(value)\n        else:\n            sa_value = SArray.from_const(value, self.num_rows())\n        if not key in self.column_names():\n            with cython_context():\n                self.add_column(sa_value, key, inplace=True)\n        else:\n            single_column = self.num_columns() == 1\n            if single_column:\n                tmpname = key\n                saved_column = self.select_column(key)\n                self.remove_column(key, inplace=True)\n            else:\n                tmpname = '__' + '-'.join(self.column_names())\n            try:\n                self.add_column(sa_value, tmpname, inplace=True)\n            except Exception:\n                if single_column:\n                    self.add_column(saved_column, key, inplace=True)\n                raise\n            if not single_column:\n                self.swap_columns(key, tmpname, inplace=True)\n                self.remove_column(key, inplace=True)\n                self.rename({tmpname: key}, inplace=True)\n    else:\n        raise TypeError('Cannot set column with key type ' + str(type(key)))",
        "mutated": [
            "def __setitem__(self, key, value):\n    if False:\n        i = 10\n    '\\n        A wrapper around add_column(s).  Key can be either a list or a str.  If\\n        value is an SArray, it is added to the SFrame as a column.  If it is a\\n        constant value (int, str, or float), then a column is created where\\n        every entry is equal to the constant value.  Existing columns can also\\n        be replaced using this wrapper.\\n        '\n    if type(key) is list:\n        self.add_columns(value, key, inplace=True)\n    elif type(key) is str:\n        sa_value = None\n        if type(value) is SArray:\n            sa_value = value\n        elif _is_non_string_iterable(value):\n            sa_value = SArray(value)\n        else:\n            sa_value = SArray.from_const(value, self.num_rows())\n        if not key in self.column_names():\n            with cython_context():\n                self.add_column(sa_value, key, inplace=True)\n        else:\n            single_column = self.num_columns() == 1\n            if single_column:\n                tmpname = key\n                saved_column = self.select_column(key)\n                self.remove_column(key, inplace=True)\n            else:\n                tmpname = '__' + '-'.join(self.column_names())\n            try:\n                self.add_column(sa_value, tmpname, inplace=True)\n            except Exception:\n                if single_column:\n                    self.add_column(saved_column, key, inplace=True)\n                raise\n            if not single_column:\n                self.swap_columns(key, tmpname, inplace=True)\n                self.remove_column(key, inplace=True)\n                self.rename({tmpname: key}, inplace=True)\n    else:\n        raise TypeError('Cannot set column with key type ' + str(type(key)))",
            "def __setitem__(self, key, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        A wrapper around add_column(s).  Key can be either a list or a str.  If\\n        value is an SArray, it is added to the SFrame as a column.  If it is a\\n        constant value (int, str, or float), then a column is created where\\n        every entry is equal to the constant value.  Existing columns can also\\n        be replaced using this wrapper.\\n        '\n    if type(key) is list:\n        self.add_columns(value, key, inplace=True)\n    elif type(key) is str:\n        sa_value = None\n        if type(value) is SArray:\n            sa_value = value\n        elif _is_non_string_iterable(value):\n            sa_value = SArray(value)\n        else:\n            sa_value = SArray.from_const(value, self.num_rows())\n        if not key in self.column_names():\n            with cython_context():\n                self.add_column(sa_value, key, inplace=True)\n        else:\n            single_column = self.num_columns() == 1\n            if single_column:\n                tmpname = key\n                saved_column = self.select_column(key)\n                self.remove_column(key, inplace=True)\n            else:\n                tmpname = '__' + '-'.join(self.column_names())\n            try:\n                self.add_column(sa_value, tmpname, inplace=True)\n            except Exception:\n                if single_column:\n                    self.add_column(saved_column, key, inplace=True)\n                raise\n            if not single_column:\n                self.swap_columns(key, tmpname, inplace=True)\n                self.remove_column(key, inplace=True)\n                self.rename({tmpname: key}, inplace=True)\n    else:\n        raise TypeError('Cannot set column with key type ' + str(type(key)))",
            "def __setitem__(self, key, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        A wrapper around add_column(s).  Key can be either a list or a str.  If\\n        value is an SArray, it is added to the SFrame as a column.  If it is a\\n        constant value (int, str, or float), then a column is created where\\n        every entry is equal to the constant value.  Existing columns can also\\n        be replaced using this wrapper.\\n        '\n    if type(key) is list:\n        self.add_columns(value, key, inplace=True)\n    elif type(key) is str:\n        sa_value = None\n        if type(value) is SArray:\n            sa_value = value\n        elif _is_non_string_iterable(value):\n            sa_value = SArray(value)\n        else:\n            sa_value = SArray.from_const(value, self.num_rows())\n        if not key in self.column_names():\n            with cython_context():\n                self.add_column(sa_value, key, inplace=True)\n        else:\n            single_column = self.num_columns() == 1\n            if single_column:\n                tmpname = key\n                saved_column = self.select_column(key)\n                self.remove_column(key, inplace=True)\n            else:\n                tmpname = '__' + '-'.join(self.column_names())\n            try:\n                self.add_column(sa_value, tmpname, inplace=True)\n            except Exception:\n                if single_column:\n                    self.add_column(saved_column, key, inplace=True)\n                raise\n            if not single_column:\n                self.swap_columns(key, tmpname, inplace=True)\n                self.remove_column(key, inplace=True)\n                self.rename({tmpname: key}, inplace=True)\n    else:\n        raise TypeError('Cannot set column with key type ' + str(type(key)))",
            "def __setitem__(self, key, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        A wrapper around add_column(s).  Key can be either a list or a str.  If\\n        value is an SArray, it is added to the SFrame as a column.  If it is a\\n        constant value (int, str, or float), then a column is created where\\n        every entry is equal to the constant value.  Existing columns can also\\n        be replaced using this wrapper.\\n        '\n    if type(key) is list:\n        self.add_columns(value, key, inplace=True)\n    elif type(key) is str:\n        sa_value = None\n        if type(value) is SArray:\n            sa_value = value\n        elif _is_non_string_iterable(value):\n            sa_value = SArray(value)\n        else:\n            sa_value = SArray.from_const(value, self.num_rows())\n        if not key in self.column_names():\n            with cython_context():\n                self.add_column(sa_value, key, inplace=True)\n        else:\n            single_column = self.num_columns() == 1\n            if single_column:\n                tmpname = key\n                saved_column = self.select_column(key)\n                self.remove_column(key, inplace=True)\n            else:\n                tmpname = '__' + '-'.join(self.column_names())\n            try:\n                self.add_column(sa_value, tmpname, inplace=True)\n            except Exception:\n                if single_column:\n                    self.add_column(saved_column, key, inplace=True)\n                raise\n            if not single_column:\n                self.swap_columns(key, tmpname, inplace=True)\n                self.remove_column(key, inplace=True)\n                self.rename({tmpname: key}, inplace=True)\n    else:\n        raise TypeError('Cannot set column with key type ' + str(type(key)))",
            "def __setitem__(self, key, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        A wrapper around add_column(s).  Key can be either a list or a str.  If\\n        value is an SArray, it is added to the SFrame as a column.  If it is a\\n        constant value (int, str, or float), then a column is created where\\n        every entry is equal to the constant value.  Existing columns can also\\n        be replaced using this wrapper.\\n        '\n    if type(key) is list:\n        self.add_columns(value, key, inplace=True)\n    elif type(key) is str:\n        sa_value = None\n        if type(value) is SArray:\n            sa_value = value\n        elif _is_non_string_iterable(value):\n            sa_value = SArray(value)\n        else:\n            sa_value = SArray.from_const(value, self.num_rows())\n        if not key in self.column_names():\n            with cython_context():\n                self.add_column(sa_value, key, inplace=True)\n        else:\n            single_column = self.num_columns() == 1\n            if single_column:\n                tmpname = key\n                saved_column = self.select_column(key)\n                self.remove_column(key, inplace=True)\n            else:\n                tmpname = '__' + '-'.join(self.column_names())\n            try:\n                self.add_column(sa_value, tmpname, inplace=True)\n            except Exception:\n                if single_column:\n                    self.add_column(saved_column, key, inplace=True)\n                raise\n            if not single_column:\n                self.swap_columns(key, tmpname, inplace=True)\n                self.remove_column(key, inplace=True)\n                self.rename({tmpname: key}, inplace=True)\n    else:\n        raise TypeError('Cannot set column with key type ' + str(type(key)))"
        ]
    },
    {
        "func_name": "__delitem__",
        "original": "def __delitem__(self, key):\n    \"\"\"\n        Wrapper around remove_column.\n        \"\"\"\n    self.remove_column(key, inplace=True)",
        "mutated": [
            "def __delitem__(self, key):\n    if False:\n        i = 10\n    '\\n        Wrapper around remove_column.\\n        '\n    self.remove_column(key, inplace=True)",
            "def __delitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Wrapper around remove_column.\\n        '\n    self.remove_column(key, inplace=True)",
            "def __delitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Wrapper around remove_column.\\n        '\n    self.remove_column(key, inplace=True)",
            "def __delitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Wrapper around remove_column.\\n        '\n    self.remove_column(key, inplace=True)",
            "def __delitem__(self, key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Wrapper around remove_column.\\n        '\n    self.remove_column(key, inplace=True)"
        ]
    },
    {
        "func_name": "materialize",
        "original": "def materialize(self):\n    \"\"\"\n        For an SFrame that is lazily evaluated, force the persistence of the\n        SFrame to disk, committing all lazy evaluated operations.\n        \"\"\"\n    with cython_context():\n        self.__proxy__.materialize()",
        "mutated": [
            "def materialize(self):\n    if False:\n        i = 10\n    '\\n        For an SFrame that is lazily evaluated, force the persistence of the\\n        SFrame to disk, committing all lazy evaluated operations.\\n        '\n    with cython_context():\n        self.__proxy__.materialize()",
            "def materialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        For an SFrame that is lazily evaluated, force the persistence of the\\n        SFrame to disk, committing all lazy evaluated operations.\\n        '\n    with cython_context():\n        self.__proxy__.materialize()",
            "def materialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        For an SFrame that is lazily evaluated, force the persistence of the\\n        SFrame to disk, committing all lazy evaluated operations.\\n        '\n    with cython_context():\n        self.__proxy__.materialize()",
            "def materialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        For an SFrame that is lazily evaluated, force the persistence of the\\n        SFrame to disk, committing all lazy evaluated operations.\\n        '\n    with cython_context():\n        self.__proxy__.materialize()",
            "def materialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        For an SFrame that is lazily evaluated, force the persistence of the\\n        SFrame to disk, committing all lazy evaluated operations.\\n        '\n    with cython_context():\n        self.__proxy__.materialize()"
        ]
    },
    {
        "func_name": "is_materialized",
        "original": "def is_materialized(self):\n    \"\"\"\n        Returns whether or not the SFrame has been materialized.\n        \"\"\"\n    return self.__is_materialized__()",
        "mutated": [
            "def is_materialized(self):\n    if False:\n        i = 10\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__is_materialized__()",
            "def is_materialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__is_materialized__()",
            "def is_materialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__is_materialized__()",
            "def is_materialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__is_materialized__()",
            "def is_materialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__is_materialized__()"
        ]
    },
    {
        "func_name": "__is_materialized__",
        "original": "def __is_materialized__(self):\n    \"\"\"\n        Returns whether or not the SFrame has been materialized.\n        \"\"\"\n    return self.__proxy__.is_materialized()",
        "mutated": [
            "def __is_materialized__(self):\n    if False:\n        i = 10\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__proxy__.is_materialized()",
            "def __is_materialized__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__proxy__.is_materialized()",
            "def __is_materialized__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__proxy__.is_materialized()",
            "def __is_materialized__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__proxy__.is_materialized()",
            "def __is_materialized__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns whether or not the SFrame has been materialized.\\n        '\n    return self.__proxy__.is_materialized()"
        ]
    },
    {
        "func_name": "__has_size__",
        "original": "def __has_size__(self):\n    \"\"\"\n        Returns whether or not the size of the SFrame is known.\n        \"\"\"\n    return self.__proxy__.has_size()",
        "mutated": [
            "def __has_size__(self):\n    if False:\n        i = 10\n    '\\n        Returns whether or not the size of the SFrame is known.\\n        '\n    return self.__proxy__.has_size()",
            "def __has_size__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns whether or not the size of the SFrame is known.\\n        '\n    return self.__proxy__.has_size()",
            "def __has_size__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns whether or not the size of the SFrame is known.\\n        '\n    return self.__proxy__.has_size()",
            "def __has_size__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns whether or not the size of the SFrame is known.\\n        '\n    return self.__proxy__.has_size()",
            "def __has_size__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns whether or not the size of the SFrame is known.\\n        '\n    return self.__proxy__.has_size()"
        ]
    },
    {
        "func_name": "__query_plan_str__",
        "original": "def __query_plan_str__(self):\n    \"\"\"\n        Returns the query plan as a dot graph string\n        \"\"\"\n    return self.__proxy__.query_plan_string()",
        "mutated": [
            "def __query_plan_str__(self):\n    if False:\n        i = 10\n    '\\n        Returns the query plan as a dot graph string\\n        '\n    return self.__proxy__.query_plan_string()",
            "def __query_plan_str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the query plan as a dot graph string\\n        '\n    return self.__proxy__.query_plan_string()",
            "def __query_plan_str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the query plan as a dot graph string\\n        '\n    return self.__proxy__.query_plan_string()",
            "def __query_plan_str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the query plan as a dot graph string\\n        '\n    return self.__proxy__.query_plan_string()",
            "def __query_plan_str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the query plan as a dot graph string\\n        '\n    return self.__proxy__.query_plan_string()"
        ]
    },
    {
        "func_name": "generator",
        "original": "def generator():\n    elems_at_a_time = 262144\n    self.__proxy__.begin_iterator()\n    ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n    column_names = self.column_names()\n    while True:\n        for j in ret:\n            yield dict(list(zip(column_names, j)))\n        if len(ret) == elems_at_a_time:\n            ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        else:\n            break",
        "mutated": [
            "def generator():\n    if False:\n        i = 10\n    elems_at_a_time = 262144\n    self.__proxy__.begin_iterator()\n    ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n    column_names = self.column_names()\n    while True:\n        for j in ret:\n            yield dict(list(zip(column_names, j)))\n        if len(ret) == elems_at_a_time:\n            ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        else:\n            break",
            "def generator():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    elems_at_a_time = 262144\n    self.__proxy__.begin_iterator()\n    ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n    column_names = self.column_names()\n    while True:\n        for j in ret:\n            yield dict(list(zip(column_names, j)))\n        if len(ret) == elems_at_a_time:\n            ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        else:\n            break",
            "def generator():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    elems_at_a_time = 262144\n    self.__proxy__.begin_iterator()\n    ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n    column_names = self.column_names()\n    while True:\n        for j in ret:\n            yield dict(list(zip(column_names, j)))\n        if len(ret) == elems_at_a_time:\n            ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        else:\n            break",
            "def generator():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    elems_at_a_time = 262144\n    self.__proxy__.begin_iterator()\n    ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n    column_names = self.column_names()\n    while True:\n        for j in ret:\n            yield dict(list(zip(column_names, j)))\n        if len(ret) == elems_at_a_time:\n            ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        else:\n            break",
            "def generator():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    elems_at_a_time = 262144\n    self.__proxy__.begin_iterator()\n    ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n    column_names = self.column_names()\n    while True:\n        for j in ret:\n            yield dict(list(zip(column_names, j)))\n        if len(ret) == elems_at_a_time:\n            ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        else:\n            break"
        ]
    },
    {
        "func_name": "__iter__",
        "original": "def __iter__(self):\n    \"\"\"\n        Provides an iterator to the rows of the SFrame.\n        \"\"\"\n\n    def generator():\n        elems_at_a_time = 262144\n        self.__proxy__.begin_iterator()\n        ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        column_names = self.column_names()\n        while True:\n            for j in ret:\n                yield dict(list(zip(column_names, j)))\n            if len(ret) == elems_at_a_time:\n                ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n            else:\n                break\n    return generator()",
        "mutated": [
            "def __iter__(self):\n    if False:\n        i = 10\n    '\\n        Provides an iterator to the rows of the SFrame.\\n        '\n\n    def generator():\n        elems_at_a_time = 262144\n        self.__proxy__.begin_iterator()\n        ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        column_names = self.column_names()\n        while True:\n            for j in ret:\n                yield dict(list(zip(column_names, j)))\n            if len(ret) == elems_at_a_time:\n                ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n            else:\n                break\n    return generator()",
            "def __iter__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Provides an iterator to the rows of the SFrame.\\n        '\n\n    def generator():\n        elems_at_a_time = 262144\n        self.__proxy__.begin_iterator()\n        ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        column_names = self.column_names()\n        while True:\n            for j in ret:\n                yield dict(list(zip(column_names, j)))\n            if len(ret) == elems_at_a_time:\n                ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n            else:\n                break\n    return generator()",
            "def __iter__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Provides an iterator to the rows of the SFrame.\\n        '\n\n    def generator():\n        elems_at_a_time = 262144\n        self.__proxy__.begin_iterator()\n        ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        column_names = self.column_names()\n        while True:\n            for j in ret:\n                yield dict(list(zip(column_names, j)))\n            if len(ret) == elems_at_a_time:\n                ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n            else:\n                break\n    return generator()",
            "def __iter__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Provides an iterator to the rows of the SFrame.\\n        '\n\n    def generator():\n        elems_at_a_time = 262144\n        self.__proxy__.begin_iterator()\n        ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        column_names = self.column_names()\n        while True:\n            for j in ret:\n                yield dict(list(zip(column_names, j)))\n            if len(ret) == elems_at_a_time:\n                ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n            else:\n                break\n    return generator()",
            "def __iter__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Provides an iterator to the rows of the SFrame.\\n        '\n\n    def generator():\n        elems_at_a_time = 262144\n        self.__proxy__.begin_iterator()\n        ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n        column_names = self.column_names()\n        while True:\n            for j in ret:\n                yield dict(list(zip(column_names, j)))\n            if len(ret) == elems_at_a_time:\n                ret = self.__proxy__.iterator_get_next(elems_at_a_time)\n            else:\n                break\n    return generator()"
        ]
    },
    {
        "func_name": "append",
        "original": "def append(self, other):\n    \"\"\"\n        Add the rows of an SFrame to the end of this SFrame.\n\n        Both SFrames must have the same set of columns with the same column\n        names and column types.\n\n        Parameters\n        ----------\n        other : SFrame\n            Another SFrame whose rows are appended to the current SFrame.\n\n        Returns\n        -------\n        out : SFrame\n            The result SFrame from the append operation.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [4, 6, 8], 'val': ['D', 'F', 'H']})\n        >>> sf2 = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\n        >>> sf = sf.append(sf2)\n        >>> sf\n        +----+-----+\n        | id | val |\n        +----+-----+\n        | 4  |  D  |\n        | 6  |  F  |\n        | 8  |  H  |\n        | 1  |  A  |\n        | 2  |  B  |\n        | 3  |  C  |\n        +----+-----+\n        [6 rows x 2 columns]\n        \"\"\"\n    if type(other) is not SFrame:\n        raise RuntimeError('SFrame append can only work with SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.append(other.__proxy__))",
        "mutated": [
            "def append(self, other):\n    if False:\n        i = 10\n    \"\\n        Add the rows of an SFrame to the end of this SFrame.\\n\\n        Both SFrames must have the same set of columns with the same column\\n        names and column types.\\n\\n        Parameters\\n        ----------\\n        other : SFrame\\n            Another SFrame whose rows are appended to the current SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The result SFrame from the append operation.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [4, 6, 8], 'val': ['D', 'F', 'H']})\\n        >>> sf2 = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf = sf.append(sf2)\\n        >>> sf\\n        +----+-----+\\n        | id | val |\\n        +----+-----+\\n        | 4  |  D  |\\n        | 6  |  F  |\\n        | 8  |  H  |\\n        | 1  |  A  |\\n        | 2  |  B  |\\n        | 3  |  C  |\\n        +----+-----+\\n        [6 rows x 2 columns]\\n        \"\n    if type(other) is not SFrame:\n        raise RuntimeError('SFrame append can only work with SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.append(other.__proxy__))",
            "def append(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Add the rows of an SFrame to the end of this SFrame.\\n\\n        Both SFrames must have the same set of columns with the same column\\n        names and column types.\\n\\n        Parameters\\n        ----------\\n        other : SFrame\\n            Another SFrame whose rows are appended to the current SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The result SFrame from the append operation.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [4, 6, 8], 'val': ['D', 'F', 'H']})\\n        >>> sf2 = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf = sf.append(sf2)\\n        >>> sf\\n        +----+-----+\\n        | id | val |\\n        +----+-----+\\n        | 4  |  D  |\\n        | 6  |  F  |\\n        | 8  |  H  |\\n        | 1  |  A  |\\n        | 2  |  B  |\\n        | 3  |  C  |\\n        +----+-----+\\n        [6 rows x 2 columns]\\n        \"\n    if type(other) is not SFrame:\n        raise RuntimeError('SFrame append can only work with SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.append(other.__proxy__))",
            "def append(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Add the rows of an SFrame to the end of this SFrame.\\n\\n        Both SFrames must have the same set of columns with the same column\\n        names and column types.\\n\\n        Parameters\\n        ----------\\n        other : SFrame\\n            Another SFrame whose rows are appended to the current SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The result SFrame from the append operation.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [4, 6, 8], 'val': ['D', 'F', 'H']})\\n        >>> sf2 = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf = sf.append(sf2)\\n        >>> sf\\n        +----+-----+\\n        | id | val |\\n        +----+-----+\\n        | 4  |  D  |\\n        | 6  |  F  |\\n        | 8  |  H  |\\n        | 1  |  A  |\\n        | 2  |  B  |\\n        | 3  |  C  |\\n        +----+-----+\\n        [6 rows x 2 columns]\\n        \"\n    if type(other) is not SFrame:\n        raise RuntimeError('SFrame append can only work with SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.append(other.__proxy__))",
            "def append(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Add the rows of an SFrame to the end of this SFrame.\\n\\n        Both SFrames must have the same set of columns with the same column\\n        names and column types.\\n\\n        Parameters\\n        ----------\\n        other : SFrame\\n            Another SFrame whose rows are appended to the current SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The result SFrame from the append operation.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [4, 6, 8], 'val': ['D', 'F', 'H']})\\n        >>> sf2 = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf = sf.append(sf2)\\n        >>> sf\\n        +----+-----+\\n        | id | val |\\n        +----+-----+\\n        | 4  |  D  |\\n        | 6  |  F  |\\n        | 8  |  H  |\\n        | 1  |  A  |\\n        | 2  |  B  |\\n        | 3  |  C  |\\n        +----+-----+\\n        [6 rows x 2 columns]\\n        \"\n    if type(other) is not SFrame:\n        raise RuntimeError('SFrame append can only work with SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.append(other.__proxy__))",
            "def append(self, other):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Add the rows of an SFrame to the end of this SFrame.\\n\\n        Both SFrames must have the same set of columns with the same column\\n        names and column types.\\n\\n        Parameters\\n        ----------\\n        other : SFrame\\n            Another SFrame whose rows are appended to the current SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The result SFrame from the append operation.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [4, 6, 8], 'val': ['D', 'F', 'H']})\\n        >>> sf2 = turicreate.SFrame({'id': [1, 2, 3], 'val': ['A', 'B', 'C']})\\n        >>> sf = sf.append(sf2)\\n        >>> sf\\n        +----+-----+\\n        | id | val |\\n        +----+-----+\\n        | 4  |  D  |\\n        | 6  |  F  |\\n        | 8  |  H  |\\n        | 1  |  A  |\\n        | 2  |  B  |\\n        | 3  |  C  |\\n        +----+-----+\\n        [6 rows x 2 columns]\\n        \"\n    if type(other) is not SFrame:\n        raise RuntimeError('SFrame append can only work with SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.append(other.__proxy__))"
        ]
    },
    {
        "func_name": "groupby",
        "original": "def groupby(self, key_column_names, operations, *args):\n    \"\"\"\n        Perform a group on the key_column_names followed by aggregations on the\n        columns listed in operations.\n\n        The operations parameter is a dictionary that indicates which\n        aggregation operators to use and which columns to use them on. The\n        available operators are SUM, MAX, MIN, COUNT, AVG, VAR, STDV, CONCAT,\n        SELECT_ONE, ARGMIN, ARGMAX, and QUANTILE. For convenience, aggregators\n        MEAN, STD, and VARIANCE are available as synonyms for AVG, STDV, and\n        VAR. See :mod:`~turicreate.aggregate` for more detail on the aggregators.\n\n        Parameters\n        ----------\n        key_column_names : string | list[string]\n            Column(s) to group by. Key columns can be of any type other than\n            dictionary.\n\n        operations : dict, list\n            Dictionary of columns and aggregation operations. Each key is a\n            output column name and each value is an aggregator. This can also\n            be a list of aggregators, in which case column names will be\n            automatically assigned.\n\n        *args\n            All other remaining arguments will be interpreted in the same\n            way as the operations argument.\n\n        Returns\n        -------\n        out_sf : SFrame\n            A new SFrame, with a column for each groupby column and each\n            aggregation operation.\n\n        See Also\n        --------\n        aggregate\n\n        Notes\n        -----\n        * Numeric aggregators (such as sum, mean, stdev etc.) follow the skip\n        None policy i.e they will omit all missing values from the aggregation.\n        As an example, `sum([None, 5, 10]) = 15` because the `None` value is\n        skipped.\n        * Aggregators have a default value when no values (after skipping all\n        `None` values) are present. Default values are `None` for ['ARGMAX',\n        'ARGMIN', 'AVG', 'STD', 'MEAN', 'MIN', 'MAX'],  `0` for ['COUNT'\n        'COUNT_DISTINCT', 'DISTINCT'] `[]` for 'CONCAT', 'QUANTILE',\n        'DISTINCT', and `{}` for 'FREQ_COUNT'.\n\n        Examples\n        --------\n        Suppose we have an SFrame with movie ratings by many users.\n\n        >>> import turicreate.aggregate as agg\n        >>> url = 'https://static.turi.com/datasets/rating_data_example.csv'\n        >>> sf = turicreate.SFrame.read_csv(url)\n        >>> sf\n        +---------+----------+--------+\n        | user_id | movie_id | rating |\n        +---------+----------+--------+\n        |  25904  |   1663   |   3    |\n        |  25907  |   1663   |   3    |\n        |  25923  |   1663   |   3    |\n        |  25924  |   1663   |   3    |\n        |  25928  |   1663   |   2    |\n        |  25933  |   1663   |   4    |\n        |  25934  |   1663   |   4    |\n        |  25935  |   1663   |   4    |\n        |  25936  |   1663   |   5    |\n        |  25937  |   1663   |   2    |\n        |   ...   |   ...    |  ...   |\n        +---------+----------+--------+\n        [10000 rows x 3 columns]\n\n        Compute the number of occurrences of each user.\n\n        >>> user_count = sf.groupby(key_column_names='user_id',\n        ...                         operations={'count': agg.COUNT()})\n        >>> user_count\n        +---------+-------+\n        | user_id | count |\n        +---------+-------+\n        |  62361  |   1   |\n        |  30727  |   1   |\n        |  40111  |   1   |\n        |  50513  |   1   |\n        |  35140  |   1   |\n        |  42352  |   1   |\n        |  29667  |   1   |\n        |  46242  |   1   |\n        |  58310  |   1   |\n        |  64614  |   1   |\n        |   ...   |  ...  |\n        +---------+-------+\n        [9852 rows x 2 columns]\n\n        Compute the mean and standard deviation of ratings per user.\n\n        >>> user_rating_stats = sf.groupby(key_column_names='user_id',\n        ...                                operations={\n        ...                                    'mean_rating': agg.MEAN('rating'),\n        ...                                    'std_rating': agg.STD('rating')\n        ...                                })\n        >>> user_rating_stats\n        +---------+-------------+------------+\n        | user_id | mean_rating | std_rating |\n        +---------+-------------+------------+\n        |  62361  |     5.0     |    0.0     |\n        |  30727  |     4.0     |    0.0     |\n        |  40111  |     2.0     |    0.0     |\n        |  50513  |     4.0     |    0.0     |\n        |  35140  |     4.0     |    0.0     |\n        |  42352  |     5.0     |    0.0     |\n        |  29667  |     4.0     |    0.0     |\n        |  46242  |     5.0     |    0.0     |\n        |  58310  |     2.0     |    0.0     |\n        |  64614  |     2.0     |    0.0     |\n        |   ...   |     ...     |    ...     |\n        +---------+-------------+------------+\n        [9852 rows x 3 columns]\n\n        Compute the movie with the minimum rating per user.\n\n        >>> chosen_movies = sf.groupby(key_column_names='user_id',\n        ...                            operations={\n        ...                                'worst_movies': agg.ARGMIN('rating','movie_id')\n        ...                            })\n        >>> chosen_movies\n        +---------+-------------+\n        | user_id | worst_movies |\n        +---------+-------------+\n        |  62361  |     1663    |\n        |  30727  |     1663    |\n        |  40111  |     1663    |\n        |  50513  |     1663    |\n        |  35140  |     1663    |\n        |  42352  |     1663    |\n        |  29667  |     1663    |\n        |  46242  |     1663    |\n        |  58310  |     1663    |\n        |  64614  |     1663    |\n        |   ...   |     ...     |\n        +---------+-------------+\n        [9852 rows x 2 columns]\n\n        Compute the movie with the max rating per user and also the movie with\n        the maximum imdb-ranking per user.\n\n        >>> sf['imdb-ranking'] = sf['rating'] * 10\n        >>> chosen_movies = sf.groupby(key_column_names='user_id',\n        ...         operations={('max_rating_movie','max_imdb_ranking_movie'): agg.ARGMAX(('rating','imdb-ranking'),'movie_id')})\n        >>> chosen_movies\n        +---------+------------------+------------------------+\n        | user_id | max_rating_movie | max_imdb_ranking_movie |\n        +---------+------------------+------------------------+\n        |  62361  |       1663       |          16630         |\n        |  30727  |       1663       |          16630         |\n        |  40111  |       1663       |          16630         |\n        |  50513  |       1663       |          16630         |\n        |  35140  |       1663       |          16630         |\n        |  42352  |       1663       |          16630         |\n        |  29667  |       1663       |          16630         |\n        |  46242  |       1663       |          16630         |\n        |  58310  |       1663       |          16630         |\n        |  64614  |       1663       |          16630         |\n        |   ...   |       ...        |          ...           |\n        +---------+------------------+------------------------+\n        [9852 rows x 3 columns]\n\n        Compute the movie with the max rating per user.\n\n        >>> chosen_movies = sf.groupby(key_column_names='user_id',\n                    operations={'best_movies': agg.ARGMAX('rating','movie')})\n\n        Compute the movie with the max rating per user and also the movie with the maximum imdb-ranking per user.\n\n        >>> chosen_movies = sf.groupby(key_column_names='user_id',\n                   operations={('max_rating_movie','max_imdb_ranking_movie'): agg.ARGMAX(('rating','imdb-ranking'),'movie')})\n\n        Compute the count, mean, and standard deviation of ratings per (user,\n        time), automatically assigning output column names.\n\n        >>> sf['time'] = sf.apply(lambda x: (x['user_id'] + x['movie_id']) % 11 + 2000)\n        >>> user_rating_stats = sf.groupby(['user_id', 'time'],\n        ...                                [agg.COUNT(),\n        ...                                 agg.AVG('rating'),\n        ...                                 agg.STDV('rating')])\n        >>> user_rating_stats\n        +------+---------+-------+---------------+----------------+\n        | time | user_id | Count | Avg of rating | Stdv of rating |\n        +------+---------+-------+---------------+----------------+\n        | 2006 |  61285  |   1   |      4.0      |      0.0       |\n        | 2000 |  36078  |   1   |      4.0      |      0.0       |\n        | 2003 |  47158  |   1   |      3.0      |      0.0       |\n        | 2007 |  34446  |   1   |      3.0      |      0.0       |\n        | 2010 |  47990  |   1   |      3.0      |      0.0       |\n        | 2003 |  42120  |   1   |      5.0      |      0.0       |\n        | 2007 |  44940  |   1   |      4.0      |      0.0       |\n        | 2008 |  58240  |   1   |      4.0      |      0.0       |\n        | 2002 |   102   |   1   |      1.0      |      0.0       |\n        | 2009 |  52708  |   1   |      3.0      |      0.0       |\n        | ...  |   ...   |  ...  |      ...      |      ...       |\n        +------+---------+-------+---------------+----------------+\n        [10000 rows x 5 columns]\n\n\n        The groupby function can take a variable length list of aggregation\n        specifiers so if we want the count and the 0.25 and 0.75 quantiles of\n        ratings:\n\n        >>> user_rating_stats = sf.groupby(['user_id', 'time'], agg.COUNT(),\n        ...                                {'rating_quantiles': agg.QUANTILE('rating',[0.25, 0.75])})\n        >>> user_rating_stats\n        +------+---------+-------+------------------------+\n        | time | user_id | Count |    rating_quantiles    |\n        +------+---------+-------+------------------------+\n        | 2006 |  61285  |   1   | array('d', [4.0, 4.0]) |\n        | 2000 |  36078  |   1   | array('d', [4.0, 4.0]) |\n        | 2003 |  47158  |   1   | array('d', [3.0, 3.0]) |\n        | 2007 |  34446  |   1   | array('d', [3.0, 3.0]) |\n        | 2010 |  47990  |   1   | array('d', [3.0, 3.0]) |\n        | 2003 |  42120  |   1   | array('d', [5.0, 5.0]) |\n        | 2007 |  44940  |   1   | array('d', [4.0, 4.0]) |\n        | 2008 |  58240  |   1   | array('d', [4.0, 4.0]) |\n        | 2002 |   102   |   1   | array('d', [1.0, 1.0]) |\n        | 2009 |  52708  |   1   | array('d', [3.0, 3.0]) |\n        | ...  |   ...   |  ...  |          ...           |\n        +------+---------+-------+------------------------+\n        [10000 rows x 4 columns]\n\n        To put all items a user rated into one list value by their star rating:\n\n        >>> user_rating_stats = sf.groupby([\"user_id\", \"rating\"],\n        ...                                {\"rated_movie_ids\":agg.CONCAT(\"movie_id\")})\n        >>> user_rating_stats\n        +--------+---------+----------------------+\n        | rating | user_id |     rated_movie_ids  |\n        +--------+---------+----------------------+\n        |   3    |  31434  | array('d', [1663.0]) |\n        |   5    |  25944  | array('d', [1663.0]) |\n        |   4    |  38827  | array('d', [1663.0]) |\n        |   4    |  51437  | array('d', [1663.0]) |\n        |   4    |  42549  | array('d', [1663.0]) |\n        |   4    |  49532  | array('d', [1663.0]) |\n        |   3    |  26124  | array('d', [1663.0]) |\n        |   4    |  46336  | array('d', [1663.0]) |\n        |   4    |  52133  | array('d', [1663.0]) |\n        |   5    |  62361  | array('d', [1663.0]) |\n        |  ...   |   ...   |         ...          |\n        +--------+---------+----------------------+\n        [9952 rows x 3 columns]\n\n        To put all items and rating of a given user together into a dictionary\n        value:\n\n        >>> user_rating_stats = sf.groupby(\"user_id\",\n        ...                                {\"movie_rating\":agg.CONCAT(\"movie_id\", \"rating\")})\n        >>> user_rating_stats\n        +---------+--------------+\n        | user_id | movie_rating |\n        +---------+--------------+\n        |  62361  |  {1663: 5}   |\n        |  30727  |  {1663: 4}   |\n        |  40111  |  {1663: 2}   |\n        |  50513  |  {1663: 4}   |\n        |  35140  |  {1663: 4}   |\n        |  42352  |  {1663: 5}   |\n        |  29667  |  {1663: 4}   |\n        |  46242  |  {1663: 5}   |\n        |  58310  |  {1663: 2}   |\n        |  64614  |  {1663: 2}   |\n        |   ...   |     ...      |\n        +---------+--------------+\n        [9852 rows x 2 columns]\n        \"\"\"\n    if isinstance(key_column_names, str):\n        key_column_names = [key_column_names]\n    my_column_names = self.column_names()\n    key_columns_array = []\n    for column in key_column_names:\n        if not isinstance(column, str):\n            raise TypeError('Column name must be a string')\n        if column not in my_column_names:\n            raise KeyError('Column \"' + column + '\" does not exist in SFrame')\n        if self[column].dtype == dict:\n            raise TypeError('Cannot group on a dictionary column.')\n        key_columns_array.append(column)\n    group_output_columns = []\n    group_columns = []\n    group_ops = []\n    all_ops = [operations] + list(args)\n    for op_entry in all_ops:\n        operation = op_entry\n        if not (isinstance(operation, list) or isinstance(operation, dict)):\n            operation = [operation]\n        if isinstance(operation, dict):\n            for key in operation:\n                val = operation[key]\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and (type(column[0]) is tuple) != (type(key) is tuple):\n                        raise TypeError('Output column(s) and aggregate column(s) for aggregate operation should be either all tuple or all string.')\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for (col, output) in zip(column[0], key):\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + [output]\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + [key]\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + [key]\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition of output column: ' + key)\n        elif isinstance(operation, list):\n            for val in operation:\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for col in column[0]:\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + ['']\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + ['']\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + ['']\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition.')\n    for (cols, op) in zip(group_columns, group_ops):\n        for col in cols:\n            if not isinstance(col, str):\n                raise TypeError('Column name must be a string')\n        if not isinstance(op, str):\n            raise TypeError('Operation type not recognized.')\n        if op is not aggregate.COUNT()[0]:\n            for col in cols:\n                if col not in my_column_names:\n                    raise KeyError('Column ' + col + ' does not exist in SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.groupby_aggregate(key_columns_array, group_columns, group_output_columns, group_ops))",
        "mutated": [
            "def groupby(self, key_column_names, operations, *args):\n    if False:\n        i = 10\n    '\\n        Perform a group on the key_column_names followed by aggregations on the\\n        columns listed in operations.\\n\\n        The operations parameter is a dictionary that indicates which\\n        aggregation operators to use and which columns to use them on. The\\n        available operators are SUM, MAX, MIN, COUNT, AVG, VAR, STDV, CONCAT,\\n        SELECT_ONE, ARGMIN, ARGMAX, and QUANTILE. For convenience, aggregators\\n        MEAN, STD, and VARIANCE are available as synonyms for AVG, STDV, and\\n        VAR. See :mod:`~turicreate.aggregate` for more detail on the aggregators.\\n\\n        Parameters\\n        ----------\\n        key_column_names : string | list[string]\\n            Column(s) to group by. Key columns can be of any type other than\\n            dictionary.\\n\\n        operations : dict, list\\n            Dictionary of columns and aggregation operations. Each key is a\\n            output column name and each value is an aggregator. This can also\\n            be a list of aggregators, in which case column names will be\\n            automatically assigned.\\n\\n        *args\\n            All other remaining arguments will be interpreted in the same\\n            way as the operations argument.\\n\\n        Returns\\n        -------\\n        out_sf : SFrame\\n            A new SFrame, with a column for each groupby column and each\\n            aggregation operation.\\n\\n        See Also\\n        --------\\n        aggregate\\n\\n        Notes\\n        -----\\n        * Numeric aggregators (such as sum, mean, stdev etc.) follow the skip\\n        None policy i.e they will omit all missing values from the aggregation.\\n        As an example, `sum([None, 5, 10]) = 15` because the `None` value is\\n        skipped.\\n        * Aggregators have a default value when no values (after skipping all\\n        `None` values) are present. Default values are `None` for [\\'ARGMAX\\',\\n        \\'ARGMIN\\', \\'AVG\\', \\'STD\\', \\'MEAN\\', \\'MIN\\', \\'MAX\\'],  `0` for [\\'COUNT\\'\\n        \\'COUNT_DISTINCT\\', \\'DISTINCT\\'] `[]` for \\'CONCAT\\', \\'QUANTILE\\',\\n        \\'DISTINCT\\', and `{}` for \\'FREQ_COUNT\\'.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with movie ratings by many users.\\n\\n        >>> import turicreate.aggregate as agg\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |  25933  |   1663   |   4    |\\n        |  25934  |   1663   |   4    |\\n        |  25935  |   1663   |   4    |\\n        |  25936  |   1663   |   5    |\\n        |  25937  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Compute the number of occurrences of each user.\\n\\n        >>> user_count = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                         operations={\\'count\\': agg.COUNT()})\\n        >>> user_count\\n        +---------+-------+\\n        | user_id | count |\\n        +---------+-------+\\n        |  62361  |   1   |\\n        |  30727  |   1   |\\n        |  40111  |   1   |\\n        |  50513  |   1   |\\n        |  35140  |   1   |\\n        |  42352  |   1   |\\n        |  29667  |   1   |\\n        |  46242  |   1   |\\n        |  58310  |   1   |\\n        |  64614  |   1   |\\n        |   ...   |  ...  |\\n        +---------+-------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the mean and standard deviation of ratings per user.\\n\\n        >>> user_rating_stats = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                                operations={\\n        ...                                    \\'mean_rating\\': agg.MEAN(\\'rating\\'),\\n        ...                                    \\'std_rating\\': agg.STD(\\'rating\\')\\n        ...                                })\\n        >>> user_rating_stats\\n        +---------+-------------+------------+\\n        | user_id | mean_rating | std_rating |\\n        +---------+-------------+------------+\\n        |  62361  |     5.0     |    0.0     |\\n        |  30727  |     4.0     |    0.0     |\\n        |  40111  |     2.0     |    0.0     |\\n        |  50513  |     4.0     |    0.0     |\\n        |  35140  |     4.0     |    0.0     |\\n        |  42352  |     5.0     |    0.0     |\\n        |  29667  |     4.0     |    0.0     |\\n        |  46242  |     5.0     |    0.0     |\\n        |  58310  |     2.0     |    0.0     |\\n        |  64614  |     2.0     |    0.0     |\\n        |   ...   |     ...     |    ...     |\\n        +---------+-------------+------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the minimum rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                            operations={\\n        ...                                \\'worst_movies\\': agg.ARGMIN(\\'rating\\',\\'movie_id\\')\\n        ...                            })\\n        >>> chosen_movies\\n        +---------+-------------+\\n        | user_id | worst_movies |\\n        +---------+-------------+\\n        |  62361  |     1663    |\\n        |  30727  |     1663    |\\n        |  40111  |     1663    |\\n        |  50513  |     1663    |\\n        |  35140  |     1663    |\\n        |  42352  |     1663    |\\n        |  29667  |     1663    |\\n        |  46242  |     1663    |\\n        |  58310  |     1663    |\\n        |  64614  |     1663    |\\n        |   ...   |     ...     |\\n        +---------+-------------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the movie with the max rating per user and also the movie with\\n        the maximum imdb-ranking per user.\\n\\n        >>> sf[\\'imdb-ranking\\'] = sf[\\'rating\\'] * 10\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...         operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie_id\\')})\\n        >>> chosen_movies\\n        +---------+------------------+------------------------+\\n        | user_id | max_rating_movie | max_imdb_ranking_movie |\\n        +---------+------------------+------------------------+\\n        |  62361  |       1663       |          16630         |\\n        |  30727  |       1663       |          16630         |\\n        |  40111  |       1663       |          16630         |\\n        |  50513  |       1663       |          16630         |\\n        |  35140  |       1663       |          16630         |\\n        |  42352  |       1663       |          16630         |\\n        |  29667  |       1663       |          16630         |\\n        |  46242  |       1663       |          16630         |\\n        |  58310  |       1663       |          16630         |\\n        |  64614  |       1663       |          16630         |\\n        |   ...   |       ...        |          ...           |\\n        +---------+------------------+------------------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the max rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                    operations={\\'best_movies\\': agg.ARGMAX(\\'rating\\',\\'movie\\')})\\n\\n        Compute the movie with the max rating per user and also the movie with the maximum imdb-ranking per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                   operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie\\')})\\n\\n        Compute the count, mean, and standard deviation of ratings per (user,\\n        time), automatically assigning output column names.\\n\\n        >>> sf[\\'time\\'] = sf.apply(lambda x: (x[\\'user_id\\'] + x[\\'movie_id\\']) % 11 + 2000)\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'],\\n        ...                                [agg.COUNT(),\\n        ...                                 agg.AVG(\\'rating\\'),\\n        ...                                 agg.STDV(\\'rating\\')])\\n        >>> user_rating_stats\\n        +------+---------+-------+---------------+----------------+\\n        | time | user_id | Count | Avg of rating | Stdv of rating |\\n        +------+---------+-------+---------------+----------------+\\n        | 2006 |  61285  |   1   |      4.0      |      0.0       |\\n        | 2000 |  36078  |   1   |      4.0      |      0.0       |\\n        | 2003 |  47158  |   1   |      3.0      |      0.0       |\\n        | 2007 |  34446  |   1   |      3.0      |      0.0       |\\n        | 2010 |  47990  |   1   |      3.0      |      0.0       |\\n        | 2003 |  42120  |   1   |      5.0      |      0.0       |\\n        | 2007 |  44940  |   1   |      4.0      |      0.0       |\\n        | 2008 |  58240  |   1   |      4.0      |      0.0       |\\n        | 2002 |   102   |   1   |      1.0      |      0.0       |\\n        | 2009 |  52708  |   1   |      3.0      |      0.0       |\\n        | ...  |   ...   |  ...  |      ...      |      ...       |\\n        +------+---------+-------+---------------+----------------+\\n        [10000 rows x 5 columns]\\n\\n\\n        The groupby function can take a variable length list of aggregation\\n        specifiers so if we want the count and the 0.25 and 0.75 quantiles of\\n        ratings:\\n\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'], agg.COUNT(),\\n        ...                                {\\'rating_quantiles\\': agg.QUANTILE(\\'rating\\',[0.25, 0.75])})\\n        >>> user_rating_stats\\n        +------+---------+-------+------------------------+\\n        | time | user_id | Count |    rating_quantiles    |\\n        +------+---------+-------+------------------------+\\n        | 2006 |  61285  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2000 |  36078  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2003 |  47158  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2007 |  34446  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2010 |  47990  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2003 |  42120  |   1   | array(\\'d\\', [5.0, 5.0]) |\\n        | 2007 |  44940  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2008 |  58240  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2002 |   102   |   1   | array(\\'d\\', [1.0, 1.0]) |\\n        | 2009 |  52708  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | ...  |   ...   |  ...  |          ...           |\\n        +------+---------+-------+------------------------+\\n        [10000 rows x 4 columns]\\n\\n        To put all items a user rated into one list value by their star rating:\\n\\n        >>> user_rating_stats = sf.groupby([\"user_id\", \"rating\"],\\n        ...                                {\"rated_movie_ids\":agg.CONCAT(\"movie_id\")})\\n        >>> user_rating_stats\\n        +--------+---------+----------------------+\\n        | rating | user_id |     rated_movie_ids  |\\n        +--------+---------+----------------------+\\n        |   3    |  31434  | array(\\'d\\', [1663.0]) |\\n        |   5    |  25944  | array(\\'d\\', [1663.0]) |\\n        |   4    |  38827  | array(\\'d\\', [1663.0]) |\\n        |   4    |  51437  | array(\\'d\\', [1663.0]) |\\n        |   4    |  42549  | array(\\'d\\', [1663.0]) |\\n        |   4    |  49532  | array(\\'d\\', [1663.0]) |\\n        |   3    |  26124  | array(\\'d\\', [1663.0]) |\\n        |   4    |  46336  | array(\\'d\\', [1663.0]) |\\n        |   4    |  52133  | array(\\'d\\', [1663.0]) |\\n        |   5    |  62361  | array(\\'d\\', [1663.0]) |\\n        |  ...   |   ...   |         ...          |\\n        +--------+---------+----------------------+\\n        [9952 rows x 3 columns]\\n\\n        To put all items and rating of a given user together into a dictionary\\n        value:\\n\\n        >>> user_rating_stats = sf.groupby(\"user_id\",\\n        ...                                {\"movie_rating\":agg.CONCAT(\"movie_id\", \"rating\")})\\n        >>> user_rating_stats\\n        +---------+--------------+\\n        | user_id | movie_rating |\\n        +---------+--------------+\\n        |  62361  |  {1663: 5}   |\\n        |  30727  |  {1663: 4}   |\\n        |  40111  |  {1663: 2}   |\\n        |  50513  |  {1663: 4}   |\\n        |  35140  |  {1663: 4}   |\\n        |  42352  |  {1663: 5}   |\\n        |  29667  |  {1663: 4}   |\\n        |  46242  |  {1663: 5}   |\\n        |  58310  |  {1663: 2}   |\\n        |  64614  |  {1663: 2}   |\\n        |   ...   |     ...      |\\n        +---------+--------------+\\n        [9852 rows x 2 columns]\\n        '\n    if isinstance(key_column_names, str):\n        key_column_names = [key_column_names]\n    my_column_names = self.column_names()\n    key_columns_array = []\n    for column in key_column_names:\n        if not isinstance(column, str):\n            raise TypeError('Column name must be a string')\n        if column not in my_column_names:\n            raise KeyError('Column \"' + column + '\" does not exist in SFrame')\n        if self[column].dtype == dict:\n            raise TypeError('Cannot group on a dictionary column.')\n        key_columns_array.append(column)\n    group_output_columns = []\n    group_columns = []\n    group_ops = []\n    all_ops = [operations] + list(args)\n    for op_entry in all_ops:\n        operation = op_entry\n        if not (isinstance(operation, list) or isinstance(operation, dict)):\n            operation = [operation]\n        if isinstance(operation, dict):\n            for key in operation:\n                val = operation[key]\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and (type(column[0]) is tuple) != (type(key) is tuple):\n                        raise TypeError('Output column(s) and aggregate column(s) for aggregate operation should be either all tuple or all string.')\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for (col, output) in zip(column[0], key):\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + [output]\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + [key]\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + [key]\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition of output column: ' + key)\n        elif isinstance(operation, list):\n            for val in operation:\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for col in column[0]:\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + ['']\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + ['']\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + ['']\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition.')\n    for (cols, op) in zip(group_columns, group_ops):\n        for col in cols:\n            if not isinstance(col, str):\n                raise TypeError('Column name must be a string')\n        if not isinstance(op, str):\n            raise TypeError('Operation type not recognized.')\n        if op is not aggregate.COUNT()[0]:\n            for col in cols:\n                if col not in my_column_names:\n                    raise KeyError('Column ' + col + ' does not exist in SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.groupby_aggregate(key_columns_array, group_columns, group_output_columns, group_ops))",
            "def groupby(self, key_column_names, operations, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Perform a group on the key_column_names followed by aggregations on the\\n        columns listed in operations.\\n\\n        The operations parameter is a dictionary that indicates which\\n        aggregation operators to use and which columns to use them on. The\\n        available operators are SUM, MAX, MIN, COUNT, AVG, VAR, STDV, CONCAT,\\n        SELECT_ONE, ARGMIN, ARGMAX, and QUANTILE. For convenience, aggregators\\n        MEAN, STD, and VARIANCE are available as synonyms for AVG, STDV, and\\n        VAR. See :mod:`~turicreate.aggregate` for more detail on the aggregators.\\n\\n        Parameters\\n        ----------\\n        key_column_names : string | list[string]\\n            Column(s) to group by. Key columns can be of any type other than\\n            dictionary.\\n\\n        operations : dict, list\\n            Dictionary of columns and aggregation operations. Each key is a\\n            output column name and each value is an aggregator. This can also\\n            be a list of aggregators, in which case column names will be\\n            automatically assigned.\\n\\n        *args\\n            All other remaining arguments will be interpreted in the same\\n            way as the operations argument.\\n\\n        Returns\\n        -------\\n        out_sf : SFrame\\n            A new SFrame, with a column for each groupby column and each\\n            aggregation operation.\\n\\n        See Also\\n        --------\\n        aggregate\\n\\n        Notes\\n        -----\\n        * Numeric aggregators (such as sum, mean, stdev etc.) follow the skip\\n        None policy i.e they will omit all missing values from the aggregation.\\n        As an example, `sum([None, 5, 10]) = 15` because the `None` value is\\n        skipped.\\n        * Aggregators have a default value when no values (after skipping all\\n        `None` values) are present. Default values are `None` for [\\'ARGMAX\\',\\n        \\'ARGMIN\\', \\'AVG\\', \\'STD\\', \\'MEAN\\', \\'MIN\\', \\'MAX\\'],  `0` for [\\'COUNT\\'\\n        \\'COUNT_DISTINCT\\', \\'DISTINCT\\'] `[]` for \\'CONCAT\\', \\'QUANTILE\\',\\n        \\'DISTINCT\\', and `{}` for \\'FREQ_COUNT\\'.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with movie ratings by many users.\\n\\n        >>> import turicreate.aggregate as agg\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |  25933  |   1663   |   4    |\\n        |  25934  |   1663   |   4    |\\n        |  25935  |   1663   |   4    |\\n        |  25936  |   1663   |   5    |\\n        |  25937  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Compute the number of occurrences of each user.\\n\\n        >>> user_count = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                         operations={\\'count\\': agg.COUNT()})\\n        >>> user_count\\n        +---------+-------+\\n        | user_id | count |\\n        +---------+-------+\\n        |  62361  |   1   |\\n        |  30727  |   1   |\\n        |  40111  |   1   |\\n        |  50513  |   1   |\\n        |  35140  |   1   |\\n        |  42352  |   1   |\\n        |  29667  |   1   |\\n        |  46242  |   1   |\\n        |  58310  |   1   |\\n        |  64614  |   1   |\\n        |   ...   |  ...  |\\n        +---------+-------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the mean and standard deviation of ratings per user.\\n\\n        >>> user_rating_stats = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                                operations={\\n        ...                                    \\'mean_rating\\': agg.MEAN(\\'rating\\'),\\n        ...                                    \\'std_rating\\': agg.STD(\\'rating\\')\\n        ...                                })\\n        >>> user_rating_stats\\n        +---------+-------------+------------+\\n        | user_id | mean_rating | std_rating |\\n        +---------+-------------+------------+\\n        |  62361  |     5.0     |    0.0     |\\n        |  30727  |     4.0     |    0.0     |\\n        |  40111  |     2.0     |    0.0     |\\n        |  50513  |     4.0     |    0.0     |\\n        |  35140  |     4.0     |    0.0     |\\n        |  42352  |     5.0     |    0.0     |\\n        |  29667  |     4.0     |    0.0     |\\n        |  46242  |     5.0     |    0.0     |\\n        |  58310  |     2.0     |    0.0     |\\n        |  64614  |     2.0     |    0.0     |\\n        |   ...   |     ...     |    ...     |\\n        +---------+-------------+------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the minimum rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                            operations={\\n        ...                                \\'worst_movies\\': agg.ARGMIN(\\'rating\\',\\'movie_id\\')\\n        ...                            })\\n        >>> chosen_movies\\n        +---------+-------------+\\n        | user_id | worst_movies |\\n        +---------+-------------+\\n        |  62361  |     1663    |\\n        |  30727  |     1663    |\\n        |  40111  |     1663    |\\n        |  50513  |     1663    |\\n        |  35140  |     1663    |\\n        |  42352  |     1663    |\\n        |  29667  |     1663    |\\n        |  46242  |     1663    |\\n        |  58310  |     1663    |\\n        |  64614  |     1663    |\\n        |   ...   |     ...     |\\n        +---------+-------------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the movie with the max rating per user and also the movie with\\n        the maximum imdb-ranking per user.\\n\\n        >>> sf[\\'imdb-ranking\\'] = sf[\\'rating\\'] * 10\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...         operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie_id\\')})\\n        >>> chosen_movies\\n        +---------+------------------+------------------------+\\n        | user_id | max_rating_movie | max_imdb_ranking_movie |\\n        +---------+------------------+------------------------+\\n        |  62361  |       1663       |          16630         |\\n        |  30727  |       1663       |          16630         |\\n        |  40111  |       1663       |          16630         |\\n        |  50513  |       1663       |          16630         |\\n        |  35140  |       1663       |          16630         |\\n        |  42352  |       1663       |          16630         |\\n        |  29667  |       1663       |          16630         |\\n        |  46242  |       1663       |          16630         |\\n        |  58310  |       1663       |          16630         |\\n        |  64614  |       1663       |          16630         |\\n        |   ...   |       ...        |          ...           |\\n        +---------+------------------+------------------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the max rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                    operations={\\'best_movies\\': agg.ARGMAX(\\'rating\\',\\'movie\\')})\\n\\n        Compute the movie with the max rating per user and also the movie with the maximum imdb-ranking per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                   operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie\\')})\\n\\n        Compute the count, mean, and standard deviation of ratings per (user,\\n        time), automatically assigning output column names.\\n\\n        >>> sf[\\'time\\'] = sf.apply(lambda x: (x[\\'user_id\\'] + x[\\'movie_id\\']) % 11 + 2000)\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'],\\n        ...                                [agg.COUNT(),\\n        ...                                 agg.AVG(\\'rating\\'),\\n        ...                                 agg.STDV(\\'rating\\')])\\n        >>> user_rating_stats\\n        +------+---------+-------+---------------+----------------+\\n        | time | user_id | Count | Avg of rating | Stdv of rating |\\n        +------+---------+-------+---------------+----------------+\\n        | 2006 |  61285  |   1   |      4.0      |      0.0       |\\n        | 2000 |  36078  |   1   |      4.0      |      0.0       |\\n        | 2003 |  47158  |   1   |      3.0      |      0.0       |\\n        | 2007 |  34446  |   1   |      3.0      |      0.0       |\\n        | 2010 |  47990  |   1   |      3.0      |      0.0       |\\n        | 2003 |  42120  |   1   |      5.0      |      0.0       |\\n        | 2007 |  44940  |   1   |      4.0      |      0.0       |\\n        | 2008 |  58240  |   1   |      4.0      |      0.0       |\\n        | 2002 |   102   |   1   |      1.0      |      0.0       |\\n        | 2009 |  52708  |   1   |      3.0      |      0.0       |\\n        | ...  |   ...   |  ...  |      ...      |      ...       |\\n        +------+---------+-------+---------------+----------------+\\n        [10000 rows x 5 columns]\\n\\n\\n        The groupby function can take a variable length list of aggregation\\n        specifiers so if we want the count and the 0.25 and 0.75 quantiles of\\n        ratings:\\n\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'], agg.COUNT(),\\n        ...                                {\\'rating_quantiles\\': agg.QUANTILE(\\'rating\\',[0.25, 0.75])})\\n        >>> user_rating_stats\\n        +------+---------+-------+------------------------+\\n        | time | user_id | Count |    rating_quantiles    |\\n        +------+---------+-------+------------------------+\\n        | 2006 |  61285  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2000 |  36078  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2003 |  47158  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2007 |  34446  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2010 |  47990  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2003 |  42120  |   1   | array(\\'d\\', [5.0, 5.0]) |\\n        | 2007 |  44940  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2008 |  58240  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2002 |   102   |   1   | array(\\'d\\', [1.0, 1.0]) |\\n        | 2009 |  52708  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | ...  |   ...   |  ...  |          ...           |\\n        +------+---------+-------+------------------------+\\n        [10000 rows x 4 columns]\\n\\n        To put all items a user rated into one list value by their star rating:\\n\\n        >>> user_rating_stats = sf.groupby([\"user_id\", \"rating\"],\\n        ...                                {\"rated_movie_ids\":agg.CONCAT(\"movie_id\")})\\n        >>> user_rating_stats\\n        +--------+---------+----------------------+\\n        | rating | user_id |     rated_movie_ids  |\\n        +--------+---------+----------------------+\\n        |   3    |  31434  | array(\\'d\\', [1663.0]) |\\n        |   5    |  25944  | array(\\'d\\', [1663.0]) |\\n        |   4    |  38827  | array(\\'d\\', [1663.0]) |\\n        |   4    |  51437  | array(\\'d\\', [1663.0]) |\\n        |   4    |  42549  | array(\\'d\\', [1663.0]) |\\n        |   4    |  49532  | array(\\'d\\', [1663.0]) |\\n        |   3    |  26124  | array(\\'d\\', [1663.0]) |\\n        |   4    |  46336  | array(\\'d\\', [1663.0]) |\\n        |   4    |  52133  | array(\\'d\\', [1663.0]) |\\n        |   5    |  62361  | array(\\'d\\', [1663.0]) |\\n        |  ...   |   ...   |         ...          |\\n        +--------+---------+----------------------+\\n        [9952 rows x 3 columns]\\n\\n        To put all items and rating of a given user together into a dictionary\\n        value:\\n\\n        >>> user_rating_stats = sf.groupby(\"user_id\",\\n        ...                                {\"movie_rating\":agg.CONCAT(\"movie_id\", \"rating\")})\\n        >>> user_rating_stats\\n        +---------+--------------+\\n        | user_id | movie_rating |\\n        +---------+--------------+\\n        |  62361  |  {1663: 5}   |\\n        |  30727  |  {1663: 4}   |\\n        |  40111  |  {1663: 2}   |\\n        |  50513  |  {1663: 4}   |\\n        |  35140  |  {1663: 4}   |\\n        |  42352  |  {1663: 5}   |\\n        |  29667  |  {1663: 4}   |\\n        |  46242  |  {1663: 5}   |\\n        |  58310  |  {1663: 2}   |\\n        |  64614  |  {1663: 2}   |\\n        |   ...   |     ...      |\\n        +---------+--------------+\\n        [9852 rows x 2 columns]\\n        '\n    if isinstance(key_column_names, str):\n        key_column_names = [key_column_names]\n    my_column_names = self.column_names()\n    key_columns_array = []\n    for column in key_column_names:\n        if not isinstance(column, str):\n            raise TypeError('Column name must be a string')\n        if column not in my_column_names:\n            raise KeyError('Column \"' + column + '\" does not exist in SFrame')\n        if self[column].dtype == dict:\n            raise TypeError('Cannot group on a dictionary column.')\n        key_columns_array.append(column)\n    group_output_columns = []\n    group_columns = []\n    group_ops = []\n    all_ops = [operations] + list(args)\n    for op_entry in all_ops:\n        operation = op_entry\n        if not (isinstance(operation, list) or isinstance(operation, dict)):\n            operation = [operation]\n        if isinstance(operation, dict):\n            for key in operation:\n                val = operation[key]\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and (type(column[0]) is tuple) != (type(key) is tuple):\n                        raise TypeError('Output column(s) and aggregate column(s) for aggregate operation should be either all tuple or all string.')\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for (col, output) in zip(column[0], key):\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + [output]\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + [key]\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + [key]\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition of output column: ' + key)\n        elif isinstance(operation, list):\n            for val in operation:\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for col in column[0]:\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + ['']\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + ['']\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + ['']\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition.')\n    for (cols, op) in zip(group_columns, group_ops):\n        for col in cols:\n            if not isinstance(col, str):\n                raise TypeError('Column name must be a string')\n        if not isinstance(op, str):\n            raise TypeError('Operation type not recognized.')\n        if op is not aggregate.COUNT()[0]:\n            for col in cols:\n                if col not in my_column_names:\n                    raise KeyError('Column ' + col + ' does not exist in SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.groupby_aggregate(key_columns_array, group_columns, group_output_columns, group_ops))",
            "def groupby(self, key_column_names, operations, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Perform a group on the key_column_names followed by aggregations on the\\n        columns listed in operations.\\n\\n        The operations parameter is a dictionary that indicates which\\n        aggregation operators to use and which columns to use them on. The\\n        available operators are SUM, MAX, MIN, COUNT, AVG, VAR, STDV, CONCAT,\\n        SELECT_ONE, ARGMIN, ARGMAX, and QUANTILE. For convenience, aggregators\\n        MEAN, STD, and VARIANCE are available as synonyms for AVG, STDV, and\\n        VAR. See :mod:`~turicreate.aggregate` for more detail on the aggregators.\\n\\n        Parameters\\n        ----------\\n        key_column_names : string | list[string]\\n            Column(s) to group by. Key columns can be of any type other than\\n            dictionary.\\n\\n        operations : dict, list\\n            Dictionary of columns and aggregation operations. Each key is a\\n            output column name and each value is an aggregator. This can also\\n            be a list of aggregators, in which case column names will be\\n            automatically assigned.\\n\\n        *args\\n            All other remaining arguments will be interpreted in the same\\n            way as the operations argument.\\n\\n        Returns\\n        -------\\n        out_sf : SFrame\\n            A new SFrame, with a column for each groupby column and each\\n            aggregation operation.\\n\\n        See Also\\n        --------\\n        aggregate\\n\\n        Notes\\n        -----\\n        * Numeric aggregators (such as sum, mean, stdev etc.) follow the skip\\n        None policy i.e they will omit all missing values from the aggregation.\\n        As an example, `sum([None, 5, 10]) = 15` because the `None` value is\\n        skipped.\\n        * Aggregators have a default value when no values (after skipping all\\n        `None` values) are present. Default values are `None` for [\\'ARGMAX\\',\\n        \\'ARGMIN\\', \\'AVG\\', \\'STD\\', \\'MEAN\\', \\'MIN\\', \\'MAX\\'],  `0` for [\\'COUNT\\'\\n        \\'COUNT_DISTINCT\\', \\'DISTINCT\\'] `[]` for \\'CONCAT\\', \\'QUANTILE\\',\\n        \\'DISTINCT\\', and `{}` for \\'FREQ_COUNT\\'.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with movie ratings by many users.\\n\\n        >>> import turicreate.aggregate as agg\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |  25933  |   1663   |   4    |\\n        |  25934  |   1663   |   4    |\\n        |  25935  |   1663   |   4    |\\n        |  25936  |   1663   |   5    |\\n        |  25937  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Compute the number of occurrences of each user.\\n\\n        >>> user_count = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                         operations={\\'count\\': agg.COUNT()})\\n        >>> user_count\\n        +---------+-------+\\n        | user_id | count |\\n        +---------+-------+\\n        |  62361  |   1   |\\n        |  30727  |   1   |\\n        |  40111  |   1   |\\n        |  50513  |   1   |\\n        |  35140  |   1   |\\n        |  42352  |   1   |\\n        |  29667  |   1   |\\n        |  46242  |   1   |\\n        |  58310  |   1   |\\n        |  64614  |   1   |\\n        |   ...   |  ...  |\\n        +---------+-------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the mean and standard deviation of ratings per user.\\n\\n        >>> user_rating_stats = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                                operations={\\n        ...                                    \\'mean_rating\\': agg.MEAN(\\'rating\\'),\\n        ...                                    \\'std_rating\\': agg.STD(\\'rating\\')\\n        ...                                })\\n        >>> user_rating_stats\\n        +---------+-------------+------------+\\n        | user_id | mean_rating | std_rating |\\n        +---------+-------------+------------+\\n        |  62361  |     5.0     |    0.0     |\\n        |  30727  |     4.0     |    0.0     |\\n        |  40111  |     2.0     |    0.0     |\\n        |  50513  |     4.0     |    0.0     |\\n        |  35140  |     4.0     |    0.0     |\\n        |  42352  |     5.0     |    0.0     |\\n        |  29667  |     4.0     |    0.0     |\\n        |  46242  |     5.0     |    0.0     |\\n        |  58310  |     2.0     |    0.0     |\\n        |  64614  |     2.0     |    0.0     |\\n        |   ...   |     ...     |    ...     |\\n        +---------+-------------+------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the minimum rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                            operations={\\n        ...                                \\'worst_movies\\': agg.ARGMIN(\\'rating\\',\\'movie_id\\')\\n        ...                            })\\n        >>> chosen_movies\\n        +---------+-------------+\\n        | user_id | worst_movies |\\n        +---------+-------------+\\n        |  62361  |     1663    |\\n        |  30727  |     1663    |\\n        |  40111  |     1663    |\\n        |  50513  |     1663    |\\n        |  35140  |     1663    |\\n        |  42352  |     1663    |\\n        |  29667  |     1663    |\\n        |  46242  |     1663    |\\n        |  58310  |     1663    |\\n        |  64614  |     1663    |\\n        |   ...   |     ...     |\\n        +---------+-------------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the movie with the max rating per user and also the movie with\\n        the maximum imdb-ranking per user.\\n\\n        >>> sf[\\'imdb-ranking\\'] = sf[\\'rating\\'] * 10\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...         operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie_id\\')})\\n        >>> chosen_movies\\n        +---------+------------------+------------------------+\\n        | user_id | max_rating_movie | max_imdb_ranking_movie |\\n        +---------+------------------+------------------------+\\n        |  62361  |       1663       |          16630         |\\n        |  30727  |       1663       |          16630         |\\n        |  40111  |       1663       |          16630         |\\n        |  50513  |       1663       |          16630         |\\n        |  35140  |       1663       |          16630         |\\n        |  42352  |       1663       |          16630         |\\n        |  29667  |       1663       |          16630         |\\n        |  46242  |       1663       |          16630         |\\n        |  58310  |       1663       |          16630         |\\n        |  64614  |       1663       |          16630         |\\n        |   ...   |       ...        |          ...           |\\n        +---------+------------------+------------------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the max rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                    operations={\\'best_movies\\': agg.ARGMAX(\\'rating\\',\\'movie\\')})\\n\\n        Compute the movie with the max rating per user and also the movie with the maximum imdb-ranking per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                   operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie\\')})\\n\\n        Compute the count, mean, and standard deviation of ratings per (user,\\n        time), automatically assigning output column names.\\n\\n        >>> sf[\\'time\\'] = sf.apply(lambda x: (x[\\'user_id\\'] + x[\\'movie_id\\']) % 11 + 2000)\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'],\\n        ...                                [agg.COUNT(),\\n        ...                                 agg.AVG(\\'rating\\'),\\n        ...                                 agg.STDV(\\'rating\\')])\\n        >>> user_rating_stats\\n        +------+---------+-------+---------------+----------------+\\n        | time | user_id | Count | Avg of rating | Stdv of rating |\\n        +------+---------+-------+---------------+----------------+\\n        | 2006 |  61285  |   1   |      4.0      |      0.0       |\\n        | 2000 |  36078  |   1   |      4.0      |      0.0       |\\n        | 2003 |  47158  |   1   |      3.0      |      0.0       |\\n        | 2007 |  34446  |   1   |      3.0      |      0.0       |\\n        | 2010 |  47990  |   1   |      3.0      |      0.0       |\\n        | 2003 |  42120  |   1   |      5.0      |      0.0       |\\n        | 2007 |  44940  |   1   |      4.0      |      0.0       |\\n        | 2008 |  58240  |   1   |      4.0      |      0.0       |\\n        | 2002 |   102   |   1   |      1.0      |      0.0       |\\n        | 2009 |  52708  |   1   |      3.0      |      0.0       |\\n        | ...  |   ...   |  ...  |      ...      |      ...       |\\n        +------+---------+-------+---------------+----------------+\\n        [10000 rows x 5 columns]\\n\\n\\n        The groupby function can take a variable length list of aggregation\\n        specifiers so if we want the count and the 0.25 and 0.75 quantiles of\\n        ratings:\\n\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'], agg.COUNT(),\\n        ...                                {\\'rating_quantiles\\': agg.QUANTILE(\\'rating\\',[0.25, 0.75])})\\n        >>> user_rating_stats\\n        +------+---------+-------+------------------------+\\n        | time | user_id | Count |    rating_quantiles    |\\n        +------+---------+-------+------------------------+\\n        | 2006 |  61285  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2000 |  36078  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2003 |  47158  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2007 |  34446  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2010 |  47990  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2003 |  42120  |   1   | array(\\'d\\', [5.0, 5.0]) |\\n        | 2007 |  44940  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2008 |  58240  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2002 |   102   |   1   | array(\\'d\\', [1.0, 1.0]) |\\n        | 2009 |  52708  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | ...  |   ...   |  ...  |          ...           |\\n        +------+---------+-------+------------------------+\\n        [10000 rows x 4 columns]\\n\\n        To put all items a user rated into one list value by their star rating:\\n\\n        >>> user_rating_stats = sf.groupby([\"user_id\", \"rating\"],\\n        ...                                {\"rated_movie_ids\":agg.CONCAT(\"movie_id\")})\\n        >>> user_rating_stats\\n        +--------+---------+----------------------+\\n        | rating | user_id |     rated_movie_ids  |\\n        +--------+---------+----------------------+\\n        |   3    |  31434  | array(\\'d\\', [1663.0]) |\\n        |   5    |  25944  | array(\\'d\\', [1663.0]) |\\n        |   4    |  38827  | array(\\'d\\', [1663.0]) |\\n        |   4    |  51437  | array(\\'d\\', [1663.0]) |\\n        |   4    |  42549  | array(\\'d\\', [1663.0]) |\\n        |   4    |  49532  | array(\\'d\\', [1663.0]) |\\n        |   3    |  26124  | array(\\'d\\', [1663.0]) |\\n        |   4    |  46336  | array(\\'d\\', [1663.0]) |\\n        |   4    |  52133  | array(\\'d\\', [1663.0]) |\\n        |   5    |  62361  | array(\\'d\\', [1663.0]) |\\n        |  ...   |   ...   |         ...          |\\n        +--------+---------+----------------------+\\n        [9952 rows x 3 columns]\\n\\n        To put all items and rating of a given user together into a dictionary\\n        value:\\n\\n        >>> user_rating_stats = sf.groupby(\"user_id\",\\n        ...                                {\"movie_rating\":agg.CONCAT(\"movie_id\", \"rating\")})\\n        >>> user_rating_stats\\n        +---------+--------------+\\n        | user_id | movie_rating |\\n        +---------+--------------+\\n        |  62361  |  {1663: 5}   |\\n        |  30727  |  {1663: 4}   |\\n        |  40111  |  {1663: 2}   |\\n        |  50513  |  {1663: 4}   |\\n        |  35140  |  {1663: 4}   |\\n        |  42352  |  {1663: 5}   |\\n        |  29667  |  {1663: 4}   |\\n        |  46242  |  {1663: 5}   |\\n        |  58310  |  {1663: 2}   |\\n        |  64614  |  {1663: 2}   |\\n        |   ...   |     ...      |\\n        +---------+--------------+\\n        [9852 rows x 2 columns]\\n        '\n    if isinstance(key_column_names, str):\n        key_column_names = [key_column_names]\n    my_column_names = self.column_names()\n    key_columns_array = []\n    for column in key_column_names:\n        if not isinstance(column, str):\n            raise TypeError('Column name must be a string')\n        if column not in my_column_names:\n            raise KeyError('Column \"' + column + '\" does not exist in SFrame')\n        if self[column].dtype == dict:\n            raise TypeError('Cannot group on a dictionary column.')\n        key_columns_array.append(column)\n    group_output_columns = []\n    group_columns = []\n    group_ops = []\n    all_ops = [operations] + list(args)\n    for op_entry in all_ops:\n        operation = op_entry\n        if not (isinstance(operation, list) or isinstance(operation, dict)):\n            operation = [operation]\n        if isinstance(operation, dict):\n            for key in operation:\n                val = operation[key]\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and (type(column[0]) is tuple) != (type(key) is tuple):\n                        raise TypeError('Output column(s) and aggregate column(s) for aggregate operation should be either all tuple or all string.')\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for (col, output) in zip(column[0], key):\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + [output]\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + [key]\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + [key]\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition of output column: ' + key)\n        elif isinstance(operation, list):\n            for val in operation:\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for col in column[0]:\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + ['']\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + ['']\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + ['']\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition.')\n    for (cols, op) in zip(group_columns, group_ops):\n        for col in cols:\n            if not isinstance(col, str):\n                raise TypeError('Column name must be a string')\n        if not isinstance(op, str):\n            raise TypeError('Operation type not recognized.')\n        if op is not aggregate.COUNT()[0]:\n            for col in cols:\n                if col not in my_column_names:\n                    raise KeyError('Column ' + col + ' does not exist in SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.groupby_aggregate(key_columns_array, group_columns, group_output_columns, group_ops))",
            "def groupby(self, key_column_names, operations, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Perform a group on the key_column_names followed by aggregations on the\\n        columns listed in operations.\\n\\n        The operations parameter is a dictionary that indicates which\\n        aggregation operators to use and which columns to use them on. The\\n        available operators are SUM, MAX, MIN, COUNT, AVG, VAR, STDV, CONCAT,\\n        SELECT_ONE, ARGMIN, ARGMAX, and QUANTILE. For convenience, aggregators\\n        MEAN, STD, and VARIANCE are available as synonyms for AVG, STDV, and\\n        VAR. See :mod:`~turicreate.aggregate` for more detail on the aggregators.\\n\\n        Parameters\\n        ----------\\n        key_column_names : string | list[string]\\n            Column(s) to group by. Key columns can be of any type other than\\n            dictionary.\\n\\n        operations : dict, list\\n            Dictionary of columns and aggregation operations. Each key is a\\n            output column name and each value is an aggregator. This can also\\n            be a list of aggregators, in which case column names will be\\n            automatically assigned.\\n\\n        *args\\n            All other remaining arguments will be interpreted in the same\\n            way as the operations argument.\\n\\n        Returns\\n        -------\\n        out_sf : SFrame\\n            A new SFrame, with a column for each groupby column and each\\n            aggregation operation.\\n\\n        See Also\\n        --------\\n        aggregate\\n\\n        Notes\\n        -----\\n        * Numeric aggregators (such as sum, mean, stdev etc.) follow the skip\\n        None policy i.e they will omit all missing values from the aggregation.\\n        As an example, `sum([None, 5, 10]) = 15` because the `None` value is\\n        skipped.\\n        * Aggregators have a default value when no values (after skipping all\\n        `None` values) are present. Default values are `None` for [\\'ARGMAX\\',\\n        \\'ARGMIN\\', \\'AVG\\', \\'STD\\', \\'MEAN\\', \\'MIN\\', \\'MAX\\'],  `0` for [\\'COUNT\\'\\n        \\'COUNT_DISTINCT\\', \\'DISTINCT\\'] `[]` for \\'CONCAT\\', \\'QUANTILE\\',\\n        \\'DISTINCT\\', and `{}` for \\'FREQ_COUNT\\'.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with movie ratings by many users.\\n\\n        >>> import turicreate.aggregate as agg\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |  25933  |   1663   |   4    |\\n        |  25934  |   1663   |   4    |\\n        |  25935  |   1663   |   4    |\\n        |  25936  |   1663   |   5    |\\n        |  25937  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Compute the number of occurrences of each user.\\n\\n        >>> user_count = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                         operations={\\'count\\': agg.COUNT()})\\n        >>> user_count\\n        +---------+-------+\\n        | user_id | count |\\n        +---------+-------+\\n        |  62361  |   1   |\\n        |  30727  |   1   |\\n        |  40111  |   1   |\\n        |  50513  |   1   |\\n        |  35140  |   1   |\\n        |  42352  |   1   |\\n        |  29667  |   1   |\\n        |  46242  |   1   |\\n        |  58310  |   1   |\\n        |  64614  |   1   |\\n        |   ...   |  ...  |\\n        +---------+-------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the mean and standard deviation of ratings per user.\\n\\n        >>> user_rating_stats = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                                operations={\\n        ...                                    \\'mean_rating\\': agg.MEAN(\\'rating\\'),\\n        ...                                    \\'std_rating\\': agg.STD(\\'rating\\')\\n        ...                                })\\n        >>> user_rating_stats\\n        +---------+-------------+------------+\\n        | user_id | mean_rating | std_rating |\\n        +---------+-------------+------------+\\n        |  62361  |     5.0     |    0.0     |\\n        |  30727  |     4.0     |    0.0     |\\n        |  40111  |     2.0     |    0.0     |\\n        |  50513  |     4.0     |    0.0     |\\n        |  35140  |     4.0     |    0.0     |\\n        |  42352  |     5.0     |    0.0     |\\n        |  29667  |     4.0     |    0.0     |\\n        |  46242  |     5.0     |    0.0     |\\n        |  58310  |     2.0     |    0.0     |\\n        |  64614  |     2.0     |    0.0     |\\n        |   ...   |     ...     |    ...     |\\n        +---------+-------------+------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the minimum rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                            operations={\\n        ...                                \\'worst_movies\\': agg.ARGMIN(\\'rating\\',\\'movie_id\\')\\n        ...                            })\\n        >>> chosen_movies\\n        +---------+-------------+\\n        | user_id | worst_movies |\\n        +---------+-------------+\\n        |  62361  |     1663    |\\n        |  30727  |     1663    |\\n        |  40111  |     1663    |\\n        |  50513  |     1663    |\\n        |  35140  |     1663    |\\n        |  42352  |     1663    |\\n        |  29667  |     1663    |\\n        |  46242  |     1663    |\\n        |  58310  |     1663    |\\n        |  64614  |     1663    |\\n        |   ...   |     ...     |\\n        +---------+-------------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the movie with the max rating per user and also the movie with\\n        the maximum imdb-ranking per user.\\n\\n        >>> sf[\\'imdb-ranking\\'] = sf[\\'rating\\'] * 10\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...         operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie_id\\')})\\n        >>> chosen_movies\\n        +---------+------------------+------------------------+\\n        | user_id | max_rating_movie | max_imdb_ranking_movie |\\n        +---------+------------------+------------------------+\\n        |  62361  |       1663       |          16630         |\\n        |  30727  |       1663       |          16630         |\\n        |  40111  |       1663       |          16630         |\\n        |  50513  |       1663       |          16630         |\\n        |  35140  |       1663       |          16630         |\\n        |  42352  |       1663       |          16630         |\\n        |  29667  |       1663       |          16630         |\\n        |  46242  |       1663       |          16630         |\\n        |  58310  |       1663       |          16630         |\\n        |  64614  |       1663       |          16630         |\\n        |   ...   |       ...        |          ...           |\\n        +---------+------------------+------------------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the max rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                    operations={\\'best_movies\\': agg.ARGMAX(\\'rating\\',\\'movie\\')})\\n\\n        Compute the movie with the max rating per user and also the movie with the maximum imdb-ranking per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                   operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie\\')})\\n\\n        Compute the count, mean, and standard deviation of ratings per (user,\\n        time), automatically assigning output column names.\\n\\n        >>> sf[\\'time\\'] = sf.apply(lambda x: (x[\\'user_id\\'] + x[\\'movie_id\\']) % 11 + 2000)\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'],\\n        ...                                [agg.COUNT(),\\n        ...                                 agg.AVG(\\'rating\\'),\\n        ...                                 agg.STDV(\\'rating\\')])\\n        >>> user_rating_stats\\n        +------+---------+-------+---------------+----------------+\\n        | time | user_id | Count | Avg of rating | Stdv of rating |\\n        +------+---------+-------+---------------+----------------+\\n        | 2006 |  61285  |   1   |      4.0      |      0.0       |\\n        | 2000 |  36078  |   1   |      4.0      |      0.0       |\\n        | 2003 |  47158  |   1   |      3.0      |      0.0       |\\n        | 2007 |  34446  |   1   |      3.0      |      0.0       |\\n        | 2010 |  47990  |   1   |      3.0      |      0.0       |\\n        | 2003 |  42120  |   1   |      5.0      |      0.0       |\\n        | 2007 |  44940  |   1   |      4.0      |      0.0       |\\n        | 2008 |  58240  |   1   |      4.0      |      0.0       |\\n        | 2002 |   102   |   1   |      1.0      |      0.0       |\\n        | 2009 |  52708  |   1   |      3.0      |      0.0       |\\n        | ...  |   ...   |  ...  |      ...      |      ...       |\\n        +------+---------+-------+---------------+----------------+\\n        [10000 rows x 5 columns]\\n\\n\\n        The groupby function can take a variable length list of aggregation\\n        specifiers so if we want the count and the 0.25 and 0.75 quantiles of\\n        ratings:\\n\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'], agg.COUNT(),\\n        ...                                {\\'rating_quantiles\\': agg.QUANTILE(\\'rating\\',[0.25, 0.75])})\\n        >>> user_rating_stats\\n        +------+---------+-------+------------------------+\\n        | time | user_id | Count |    rating_quantiles    |\\n        +------+---------+-------+------------------------+\\n        | 2006 |  61285  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2000 |  36078  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2003 |  47158  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2007 |  34446  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2010 |  47990  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2003 |  42120  |   1   | array(\\'d\\', [5.0, 5.0]) |\\n        | 2007 |  44940  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2008 |  58240  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2002 |   102   |   1   | array(\\'d\\', [1.0, 1.0]) |\\n        | 2009 |  52708  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | ...  |   ...   |  ...  |          ...           |\\n        +------+---------+-------+------------------------+\\n        [10000 rows x 4 columns]\\n\\n        To put all items a user rated into one list value by their star rating:\\n\\n        >>> user_rating_stats = sf.groupby([\"user_id\", \"rating\"],\\n        ...                                {\"rated_movie_ids\":agg.CONCAT(\"movie_id\")})\\n        >>> user_rating_stats\\n        +--------+---------+----------------------+\\n        | rating | user_id |     rated_movie_ids  |\\n        +--------+---------+----------------------+\\n        |   3    |  31434  | array(\\'d\\', [1663.0]) |\\n        |   5    |  25944  | array(\\'d\\', [1663.0]) |\\n        |   4    |  38827  | array(\\'d\\', [1663.0]) |\\n        |   4    |  51437  | array(\\'d\\', [1663.0]) |\\n        |   4    |  42549  | array(\\'d\\', [1663.0]) |\\n        |   4    |  49532  | array(\\'d\\', [1663.0]) |\\n        |   3    |  26124  | array(\\'d\\', [1663.0]) |\\n        |   4    |  46336  | array(\\'d\\', [1663.0]) |\\n        |   4    |  52133  | array(\\'d\\', [1663.0]) |\\n        |   5    |  62361  | array(\\'d\\', [1663.0]) |\\n        |  ...   |   ...   |         ...          |\\n        +--------+---------+----------------------+\\n        [9952 rows x 3 columns]\\n\\n        To put all items and rating of a given user together into a dictionary\\n        value:\\n\\n        >>> user_rating_stats = sf.groupby(\"user_id\",\\n        ...                                {\"movie_rating\":agg.CONCAT(\"movie_id\", \"rating\")})\\n        >>> user_rating_stats\\n        +---------+--------------+\\n        | user_id | movie_rating |\\n        +---------+--------------+\\n        |  62361  |  {1663: 5}   |\\n        |  30727  |  {1663: 4}   |\\n        |  40111  |  {1663: 2}   |\\n        |  50513  |  {1663: 4}   |\\n        |  35140  |  {1663: 4}   |\\n        |  42352  |  {1663: 5}   |\\n        |  29667  |  {1663: 4}   |\\n        |  46242  |  {1663: 5}   |\\n        |  58310  |  {1663: 2}   |\\n        |  64614  |  {1663: 2}   |\\n        |   ...   |     ...      |\\n        +---------+--------------+\\n        [9852 rows x 2 columns]\\n        '\n    if isinstance(key_column_names, str):\n        key_column_names = [key_column_names]\n    my_column_names = self.column_names()\n    key_columns_array = []\n    for column in key_column_names:\n        if not isinstance(column, str):\n            raise TypeError('Column name must be a string')\n        if column not in my_column_names:\n            raise KeyError('Column \"' + column + '\" does not exist in SFrame')\n        if self[column].dtype == dict:\n            raise TypeError('Cannot group on a dictionary column.')\n        key_columns_array.append(column)\n    group_output_columns = []\n    group_columns = []\n    group_ops = []\n    all_ops = [operations] + list(args)\n    for op_entry in all_ops:\n        operation = op_entry\n        if not (isinstance(operation, list) or isinstance(operation, dict)):\n            operation = [operation]\n        if isinstance(operation, dict):\n            for key in operation:\n                val = operation[key]\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and (type(column[0]) is tuple) != (type(key) is tuple):\n                        raise TypeError('Output column(s) and aggregate column(s) for aggregate operation should be either all tuple or all string.')\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for (col, output) in zip(column[0], key):\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + [output]\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + [key]\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + [key]\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition of output column: ' + key)\n        elif isinstance(operation, list):\n            for val in operation:\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for col in column[0]:\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + ['']\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + ['']\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + ['']\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition.')\n    for (cols, op) in zip(group_columns, group_ops):\n        for col in cols:\n            if not isinstance(col, str):\n                raise TypeError('Column name must be a string')\n        if not isinstance(op, str):\n            raise TypeError('Operation type not recognized.')\n        if op is not aggregate.COUNT()[0]:\n            for col in cols:\n                if col not in my_column_names:\n                    raise KeyError('Column ' + col + ' does not exist in SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.groupby_aggregate(key_columns_array, group_columns, group_output_columns, group_ops))",
            "def groupby(self, key_column_names, operations, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Perform a group on the key_column_names followed by aggregations on the\\n        columns listed in operations.\\n\\n        The operations parameter is a dictionary that indicates which\\n        aggregation operators to use and which columns to use them on. The\\n        available operators are SUM, MAX, MIN, COUNT, AVG, VAR, STDV, CONCAT,\\n        SELECT_ONE, ARGMIN, ARGMAX, and QUANTILE. For convenience, aggregators\\n        MEAN, STD, and VARIANCE are available as synonyms for AVG, STDV, and\\n        VAR. See :mod:`~turicreate.aggregate` for more detail on the aggregators.\\n\\n        Parameters\\n        ----------\\n        key_column_names : string | list[string]\\n            Column(s) to group by. Key columns can be of any type other than\\n            dictionary.\\n\\n        operations : dict, list\\n            Dictionary of columns and aggregation operations. Each key is a\\n            output column name and each value is an aggregator. This can also\\n            be a list of aggregators, in which case column names will be\\n            automatically assigned.\\n\\n        *args\\n            All other remaining arguments will be interpreted in the same\\n            way as the operations argument.\\n\\n        Returns\\n        -------\\n        out_sf : SFrame\\n            A new SFrame, with a column for each groupby column and each\\n            aggregation operation.\\n\\n        See Also\\n        --------\\n        aggregate\\n\\n        Notes\\n        -----\\n        * Numeric aggregators (such as sum, mean, stdev etc.) follow the skip\\n        None policy i.e they will omit all missing values from the aggregation.\\n        As an example, `sum([None, 5, 10]) = 15` because the `None` value is\\n        skipped.\\n        * Aggregators have a default value when no values (after skipping all\\n        `None` values) are present. Default values are `None` for [\\'ARGMAX\\',\\n        \\'ARGMIN\\', \\'AVG\\', \\'STD\\', \\'MEAN\\', \\'MIN\\', \\'MAX\\'],  `0` for [\\'COUNT\\'\\n        \\'COUNT_DISTINCT\\', \\'DISTINCT\\'] `[]` for \\'CONCAT\\', \\'QUANTILE\\',\\n        \\'DISTINCT\\', and `{}` for \\'FREQ_COUNT\\'.\\n\\n        Examples\\n        --------\\n        Suppose we have an SFrame with movie ratings by many users.\\n\\n        >>> import turicreate.aggregate as agg\\n        >>> url = \\'https://static.turi.com/datasets/rating_data_example.csv\\'\\n        >>> sf = turicreate.SFrame.read_csv(url)\\n        >>> sf\\n        +---------+----------+--------+\\n        | user_id | movie_id | rating |\\n        +---------+----------+--------+\\n        |  25904  |   1663   |   3    |\\n        |  25907  |   1663   |   3    |\\n        |  25923  |   1663   |   3    |\\n        |  25924  |   1663   |   3    |\\n        |  25928  |   1663   |   2    |\\n        |  25933  |   1663   |   4    |\\n        |  25934  |   1663   |   4    |\\n        |  25935  |   1663   |   4    |\\n        |  25936  |   1663   |   5    |\\n        |  25937  |   1663   |   2    |\\n        |   ...   |   ...    |  ...   |\\n        +---------+----------+--------+\\n        [10000 rows x 3 columns]\\n\\n        Compute the number of occurrences of each user.\\n\\n        >>> user_count = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                         operations={\\'count\\': agg.COUNT()})\\n        >>> user_count\\n        +---------+-------+\\n        | user_id | count |\\n        +---------+-------+\\n        |  62361  |   1   |\\n        |  30727  |   1   |\\n        |  40111  |   1   |\\n        |  50513  |   1   |\\n        |  35140  |   1   |\\n        |  42352  |   1   |\\n        |  29667  |   1   |\\n        |  46242  |   1   |\\n        |  58310  |   1   |\\n        |  64614  |   1   |\\n        |   ...   |  ...  |\\n        +---------+-------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the mean and standard deviation of ratings per user.\\n\\n        >>> user_rating_stats = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                                operations={\\n        ...                                    \\'mean_rating\\': agg.MEAN(\\'rating\\'),\\n        ...                                    \\'std_rating\\': agg.STD(\\'rating\\')\\n        ...                                })\\n        >>> user_rating_stats\\n        +---------+-------------+------------+\\n        | user_id | mean_rating | std_rating |\\n        +---------+-------------+------------+\\n        |  62361  |     5.0     |    0.0     |\\n        |  30727  |     4.0     |    0.0     |\\n        |  40111  |     2.0     |    0.0     |\\n        |  50513  |     4.0     |    0.0     |\\n        |  35140  |     4.0     |    0.0     |\\n        |  42352  |     5.0     |    0.0     |\\n        |  29667  |     4.0     |    0.0     |\\n        |  46242  |     5.0     |    0.0     |\\n        |  58310  |     2.0     |    0.0     |\\n        |  64614  |     2.0     |    0.0     |\\n        |   ...   |     ...     |    ...     |\\n        +---------+-------------+------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the minimum rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...                            operations={\\n        ...                                \\'worst_movies\\': agg.ARGMIN(\\'rating\\',\\'movie_id\\')\\n        ...                            })\\n        >>> chosen_movies\\n        +---------+-------------+\\n        | user_id | worst_movies |\\n        +---------+-------------+\\n        |  62361  |     1663    |\\n        |  30727  |     1663    |\\n        |  40111  |     1663    |\\n        |  50513  |     1663    |\\n        |  35140  |     1663    |\\n        |  42352  |     1663    |\\n        |  29667  |     1663    |\\n        |  46242  |     1663    |\\n        |  58310  |     1663    |\\n        |  64614  |     1663    |\\n        |   ...   |     ...     |\\n        +---------+-------------+\\n        [9852 rows x 2 columns]\\n\\n        Compute the movie with the max rating per user and also the movie with\\n        the maximum imdb-ranking per user.\\n\\n        >>> sf[\\'imdb-ranking\\'] = sf[\\'rating\\'] * 10\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n        ...         operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie_id\\')})\\n        >>> chosen_movies\\n        +---------+------------------+------------------------+\\n        | user_id | max_rating_movie | max_imdb_ranking_movie |\\n        +---------+------------------+------------------------+\\n        |  62361  |       1663       |          16630         |\\n        |  30727  |       1663       |          16630         |\\n        |  40111  |       1663       |          16630         |\\n        |  50513  |       1663       |          16630         |\\n        |  35140  |       1663       |          16630         |\\n        |  42352  |       1663       |          16630         |\\n        |  29667  |       1663       |          16630         |\\n        |  46242  |       1663       |          16630         |\\n        |  58310  |       1663       |          16630         |\\n        |  64614  |       1663       |          16630         |\\n        |   ...   |       ...        |          ...           |\\n        +---------+------------------+------------------------+\\n        [9852 rows x 3 columns]\\n\\n        Compute the movie with the max rating per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                    operations={\\'best_movies\\': agg.ARGMAX(\\'rating\\',\\'movie\\')})\\n\\n        Compute the movie with the max rating per user and also the movie with the maximum imdb-ranking per user.\\n\\n        >>> chosen_movies = sf.groupby(key_column_names=\\'user_id\\',\\n                   operations={(\\'max_rating_movie\\',\\'max_imdb_ranking_movie\\'): agg.ARGMAX((\\'rating\\',\\'imdb-ranking\\'),\\'movie\\')})\\n\\n        Compute the count, mean, and standard deviation of ratings per (user,\\n        time), automatically assigning output column names.\\n\\n        >>> sf[\\'time\\'] = sf.apply(lambda x: (x[\\'user_id\\'] + x[\\'movie_id\\']) % 11 + 2000)\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'],\\n        ...                                [agg.COUNT(),\\n        ...                                 agg.AVG(\\'rating\\'),\\n        ...                                 agg.STDV(\\'rating\\')])\\n        >>> user_rating_stats\\n        +------+---------+-------+---------------+----------------+\\n        | time | user_id | Count | Avg of rating | Stdv of rating |\\n        +------+---------+-------+---------------+----------------+\\n        | 2006 |  61285  |   1   |      4.0      |      0.0       |\\n        | 2000 |  36078  |   1   |      4.0      |      0.0       |\\n        | 2003 |  47158  |   1   |      3.0      |      0.0       |\\n        | 2007 |  34446  |   1   |      3.0      |      0.0       |\\n        | 2010 |  47990  |   1   |      3.0      |      0.0       |\\n        | 2003 |  42120  |   1   |      5.0      |      0.0       |\\n        | 2007 |  44940  |   1   |      4.0      |      0.0       |\\n        | 2008 |  58240  |   1   |      4.0      |      0.0       |\\n        | 2002 |   102   |   1   |      1.0      |      0.0       |\\n        | 2009 |  52708  |   1   |      3.0      |      0.0       |\\n        | ...  |   ...   |  ...  |      ...      |      ...       |\\n        +------+---------+-------+---------------+----------------+\\n        [10000 rows x 5 columns]\\n\\n\\n        The groupby function can take a variable length list of aggregation\\n        specifiers so if we want the count and the 0.25 and 0.75 quantiles of\\n        ratings:\\n\\n        >>> user_rating_stats = sf.groupby([\\'user_id\\', \\'time\\'], agg.COUNT(),\\n        ...                                {\\'rating_quantiles\\': agg.QUANTILE(\\'rating\\',[0.25, 0.75])})\\n        >>> user_rating_stats\\n        +------+---------+-------+------------------------+\\n        | time | user_id | Count |    rating_quantiles    |\\n        +------+---------+-------+------------------------+\\n        | 2006 |  61285  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2000 |  36078  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2003 |  47158  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2007 |  34446  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2010 |  47990  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | 2003 |  42120  |   1   | array(\\'d\\', [5.0, 5.0]) |\\n        | 2007 |  44940  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2008 |  58240  |   1   | array(\\'d\\', [4.0, 4.0]) |\\n        | 2002 |   102   |   1   | array(\\'d\\', [1.0, 1.0]) |\\n        | 2009 |  52708  |   1   | array(\\'d\\', [3.0, 3.0]) |\\n        | ...  |   ...   |  ...  |          ...           |\\n        +------+---------+-------+------------------------+\\n        [10000 rows x 4 columns]\\n\\n        To put all items a user rated into one list value by their star rating:\\n\\n        >>> user_rating_stats = sf.groupby([\"user_id\", \"rating\"],\\n        ...                                {\"rated_movie_ids\":agg.CONCAT(\"movie_id\")})\\n        >>> user_rating_stats\\n        +--------+---------+----------------------+\\n        | rating | user_id |     rated_movie_ids  |\\n        +--------+---------+----------------------+\\n        |   3    |  31434  | array(\\'d\\', [1663.0]) |\\n        |   5    |  25944  | array(\\'d\\', [1663.0]) |\\n        |   4    |  38827  | array(\\'d\\', [1663.0]) |\\n        |   4    |  51437  | array(\\'d\\', [1663.0]) |\\n        |   4    |  42549  | array(\\'d\\', [1663.0]) |\\n        |   4    |  49532  | array(\\'d\\', [1663.0]) |\\n        |   3    |  26124  | array(\\'d\\', [1663.0]) |\\n        |   4    |  46336  | array(\\'d\\', [1663.0]) |\\n        |   4    |  52133  | array(\\'d\\', [1663.0]) |\\n        |   5    |  62361  | array(\\'d\\', [1663.0]) |\\n        |  ...   |   ...   |         ...          |\\n        +--------+---------+----------------------+\\n        [9952 rows x 3 columns]\\n\\n        To put all items and rating of a given user together into a dictionary\\n        value:\\n\\n        >>> user_rating_stats = sf.groupby(\"user_id\",\\n        ...                                {\"movie_rating\":agg.CONCAT(\"movie_id\", \"rating\")})\\n        >>> user_rating_stats\\n        +---------+--------------+\\n        | user_id | movie_rating |\\n        +---------+--------------+\\n        |  62361  |  {1663: 5}   |\\n        |  30727  |  {1663: 4}   |\\n        |  40111  |  {1663: 2}   |\\n        |  50513  |  {1663: 4}   |\\n        |  35140  |  {1663: 4}   |\\n        |  42352  |  {1663: 5}   |\\n        |  29667  |  {1663: 4}   |\\n        |  46242  |  {1663: 5}   |\\n        |  58310  |  {1663: 2}   |\\n        |  64614  |  {1663: 2}   |\\n        |   ...   |     ...      |\\n        +---------+--------------+\\n        [9852 rows x 2 columns]\\n        '\n    if isinstance(key_column_names, str):\n        key_column_names = [key_column_names]\n    my_column_names = self.column_names()\n    key_columns_array = []\n    for column in key_column_names:\n        if not isinstance(column, str):\n            raise TypeError('Column name must be a string')\n        if column not in my_column_names:\n            raise KeyError('Column \"' + column + '\" does not exist in SFrame')\n        if self[column].dtype == dict:\n            raise TypeError('Cannot group on a dictionary column.')\n        key_columns_array.append(column)\n    group_output_columns = []\n    group_columns = []\n    group_ops = []\n    all_ops = [operations] + list(args)\n    for op_entry in all_ops:\n        operation = op_entry\n        if not (isinstance(operation, list) or isinstance(operation, dict)):\n            operation = [operation]\n        if isinstance(operation, dict):\n            for key in operation:\n                val = operation[key]\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and (type(column[0]) is tuple) != (type(key) is tuple):\n                        raise TypeError('Output column(s) and aggregate column(s) for aggregate operation should be either all tuple or all string.')\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for (col, output) in zip(column[0], key):\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + [output]\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + [key]\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + [key]\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition of output column: ' + key)\n        elif isinstance(operation, list):\n            for val in operation:\n                if type(val) is tuple:\n                    (op, column) = val\n                    if op == '__builtin__avg__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__avg__'\n                    if op == '__builtin__sum__' and self[column[0]].dtype in [array.array, numpy.ndarray]:\n                        op = '__builtin__vector__sum__'\n                    if (op == '__builtin__argmax__' or op == '__builtin__argmin__') and type(column[0]) is tuple:\n                        for col in column[0]:\n                            group_columns = group_columns + [[col, column[1]]]\n                            group_ops = group_ops + [op]\n                            group_output_columns = group_output_columns + ['']\n                    else:\n                        group_columns = group_columns + [column]\n                        group_ops = group_ops + [op]\n                        group_output_columns = group_output_columns + ['']\n                    if op == '__builtin__concat__dict__':\n                        key_column = column[0]\n                        key_column_type = self.select_column(key_column).dtype\n                        if not key_column_type in (int, float, str):\n                            raise TypeError('CONCAT key column must be int, float or str type')\n                elif val == aggregate.COUNT:\n                    group_output_columns = group_output_columns + ['']\n                    val = aggregate.COUNT()\n                    (op, column) = val\n                    group_columns = group_columns + [column]\n                    group_ops = group_ops + [op]\n                else:\n                    raise TypeError('Unexpected type in aggregator definition.')\n    for (cols, op) in zip(group_columns, group_ops):\n        for col in cols:\n            if not isinstance(col, str):\n                raise TypeError('Column name must be a string')\n        if not isinstance(op, str):\n            raise TypeError('Operation type not recognized.')\n        if op is not aggregate.COUNT()[0]:\n            for col in cols:\n                if col not in my_column_names:\n                    raise KeyError('Column ' + col + ' does not exist in SFrame')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.groupby_aggregate(key_columns_array, group_columns, group_output_columns, group_ops))"
        ]
    },
    {
        "func_name": "join",
        "original": "def join(self, right, on=None, how='inner', alter_name=None):\n    \"\"\"\n        Merge two SFrames. Merges the current (left) SFrame with the given\n        (right) SFrame using a SQL-style equi-join operation by columns.\n\n        Parameters\n        ----------\n        right : SFrame\n            The SFrame to join.\n\n        on : None | str | list | dict, optional\n            The column name(s) representing the set of join keys.  Each row that\n            has the same value in this set of columns will be merged together.\n\n            * If 'None' is given, join will use all columns that have the same\n              name as the set of join keys.\n\n            * If a str is given, this is interpreted as a join using one column,\n              where both SFrames have the same column name.\n\n            * If a list is given, this is interpreted as a join using one or\n              more column names, where each column name given exists in both\n              SFrames.\n\n            * If a dict is given, each dict key is taken as a column name in the\n              left SFrame, and each dict value is taken as the column name in\n              right SFrame that will be joined together. e.g.\n              {'left_col_name':'right_col_name'}.\n\n        how : {'left', 'right', 'outer', 'inner'}, optional\n            The type of join to perform.  'inner' is default.\n\n            * inner: Equivalent to a SQL inner join.  Result consists of the\n              rows from the two frames whose join key values match exactly,\n              merged together into one SFrame.\n\n            * left: Equivalent to a SQL left outer join. Result is the union\n              between the result of an inner join and the rest of the rows from\n              the left SFrame, merged with missing values.\n\n            * right: Equivalent to a SQL right outer join.  Result is the union\n              between the result of an inner join and the rest of the rows from\n              the right SFrame, merged with missing values.\n\n            * outer: Equivalent to a SQL full outer join. Result is\n              the union between the result of a left outer join and a right\n              outer join.\n\n        alter_name : None | dict\n            user provided names to resolve column name conflict when merging two sframe.\n\n            * 'None', then default conflict resolution will be used. For example, if 'X' is\n            defined in the sframe on the left side of join, and there's an column also called\n            'X' in the sframe on the right, 'X.1' will be used as the new column name when\n            appending the column 'X' from the right sframe, in order to avoid column name collision.\n\n            * if a dict is given, the dict key should be obtained from column names from the right\n            sframe. The dict value should be user preferred column name to resolve the name collision\n            instead of resolving by the default behavior. In general, dict key should not be any value\n            from the right sframe column names. If dict value will cause potential name confict\n            after an attempt to resolve, exception will be thrown.\n\n        Returns\n        -------\n        out : SFrame\n\n        Examples\n        --------\n        >>> animals = turicreate.SFrame({'id': [1, 2, 3, 4],\n        ...                           'name': ['dog', 'cat', 'sheep', 'cow']})\n        >>> sounds = turicreate.SFrame({'id': [1, 3, 4, 5],\n        ...                          'sound': ['woof', 'baa', 'moo', 'oink']})\n        >>> animals.join(sounds, how='inner')\n        +----+-------+-------+\n        | id |  name | sound |\n        +----+-------+-------+\n        | 1  |  dog  |  woof |\n        | 3  | sheep |  baa  |\n        | 4  |  cow  |  moo  |\n        +----+-------+-------+\n        [3 rows x 3 columns]\n\n        >>> animals.join(sounds, on='id', how='left')\n        +----+-------+-------+\n        | id |  name | sound |\n        +----+-------+-------+\n        | 1  |  dog  |  woof |\n        | 3  | sheep |  baa  |\n        | 4  |  cow  |  moo  |\n        | 2  |  cat  |  None |\n        +----+-------+-------+\n        [4 rows x 3 columns]\n\n        >>> animals.join(sounds, on=['id'], how='right')\n        +----+-------+-------+\n        | id |  name | sound |\n        +----+-------+-------+\n        | 1  |  dog  |  woof |\n        | 3  | sheep |  baa  |\n        | 4  |  cow  |  moo  |\n        | 5  |  None |  oink |\n        +----+-------+-------+\n        [4 rows x 3 columns]\n\n        >>> animals.join(sounds, on={'id':'id'}, how='outer')\n        +----+-------+-------+\n        | id |  name | sound |\n        +----+-------+-------+\n        | 1  |  dog  |  woof |\n        | 3  | sheep |  baa  |\n        | 4  |  cow  |  moo  |\n        | 5  |  None |  oink |\n        | 2  |  cat  |  None |\n        +----+-------+-------+\n        [5 rows x 3 columns]\n        \"\"\"\n    available_join_types = ['left', 'right', 'outer', 'inner']\n    if not isinstance(right, SFrame):\n        raise TypeError('Can only join two SFrames')\n    if how not in available_join_types:\n        raise ValueError('Invalid join type')\n    if self.num_columns() <= 0 or right.num_columns() <= 0:\n        raise ValueError('Cannot join an SFrame with no columns.')\n    join_keys = dict()\n    if on is None:\n        left_names = self.column_names()\n        right_names = right.column_names()\n        common_columns = [name for name in left_names if name in right_names]\n        for name in common_columns:\n            join_keys[name] = name\n    elif type(on) is str:\n        join_keys[on] = on\n    elif type(on) is list:\n        for name in on:\n            if type(name) is not str:\n                raise TypeError('Join keys must each be a str.')\n            join_keys[name] = name\n    elif type(on) is dict:\n        join_keys = on\n    else:\n        raise TypeError('Must pass a str, list, or dict of join keys')\n    with cython_context():\n        if alter_name is None:\n            return SFrame(_proxy=self.__proxy__.join(right.__proxy__, how, join_keys))\n        if type(alter_name) is dict:\n            left_names = self.column_names()\n            right_names = right.column_names()\n            for (k, v) in alter_name.items():\n                if k not in right_names or k in join_keys:\n                    raise KeyError('Redundant key %s for collision resolution' % k)\n                if k == v:\n                    raise ValueError('Key %s should not be equal to value' % k)\n                if v in left_names or v in right_names:\n                    raise ValueError('Value %s will cause further collision' % v)\n            return SFrame(_proxy=self.__proxy__.join_with_custom_name(right.__proxy__, how, join_keys, alter_name))",
        "mutated": [
            "def join(self, right, on=None, how='inner', alter_name=None):\n    if False:\n        i = 10\n    \"\\n        Merge two SFrames. Merges the current (left) SFrame with the given\\n        (right) SFrame using a SQL-style equi-join operation by columns.\\n\\n        Parameters\\n        ----------\\n        right : SFrame\\n            The SFrame to join.\\n\\n        on : None | str | list | dict, optional\\n            The column name(s) representing the set of join keys.  Each row that\\n            has the same value in this set of columns will be merged together.\\n\\n            * If 'None' is given, join will use all columns that have the same\\n              name as the set of join keys.\\n\\n            * If a str is given, this is interpreted as a join using one column,\\n              where both SFrames have the same column name.\\n\\n            * If a list is given, this is interpreted as a join using one or\\n              more column names, where each column name given exists in both\\n              SFrames.\\n\\n            * If a dict is given, each dict key is taken as a column name in the\\n              left SFrame, and each dict value is taken as the column name in\\n              right SFrame that will be joined together. e.g.\\n              {'left_col_name':'right_col_name'}.\\n\\n        how : {'left', 'right', 'outer', 'inner'}, optional\\n            The type of join to perform.  'inner' is default.\\n\\n            * inner: Equivalent to a SQL inner join.  Result consists of the\\n              rows from the two frames whose join key values match exactly,\\n              merged together into one SFrame.\\n\\n            * left: Equivalent to a SQL left outer join. Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the left SFrame, merged with missing values.\\n\\n            * right: Equivalent to a SQL right outer join.  Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the right SFrame, merged with missing values.\\n\\n            * outer: Equivalent to a SQL full outer join. Result is\\n              the union between the result of a left outer join and a right\\n              outer join.\\n\\n        alter_name : None | dict\\n            user provided names to resolve column name conflict when merging two sframe.\\n\\n            * 'None', then default conflict resolution will be used. For example, if 'X' is\\n            defined in the sframe on the left side of join, and there's an column also called\\n            'X' in the sframe on the right, 'X.1' will be used as the new column name when\\n            appending the column 'X' from the right sframe, in order to avoid column name collision.\\n\\n            * if a dict is given, the dict key should be obtained from column names from the right\\n            sframe. The dict value should be user preferred column name to resolve the name collision\\n            instead of resolving by the default behavior. In general, dict key should not be any value\\n            from the right sframe column names. If dict value will cause potential name confict\\n            after an attempt to resolve, exception will be thrown.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> animals = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                           'name': ['dog', 'cat', 'sheep', 'cow']})\\n        >>> sounds = turicreate.SFrame({'id': [1, 3, 4, 5],\\n        ...                          'sound': ['woof', 'baa', 'moo', 'oink']})\\n        >>> animals.join(sounds, how='inner')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        +----+-------+-------+\\n        [3 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on='id', how='left')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on=['id'], how='right')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on={'id':'id'}, how='outer')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [5 rows x 3 columns]\\n        \"\n    available_join_types = ['left', 'right', 'outer', 'inner']\n    if not isinstance(right, SFrame):\n        raise TypeError('Can only join two SFrames')\n    if how not in available_join_types:\n        raise ValueError('Invalid join type')\n    if self.num_columns() <= 0 or right.num_columns() <= 0:\n        raise ValueError('Cannot join an SFrame with no columns.')\n    join_keys = dict()\n    if on is None:\n        left_names = self.column_names()\n        right_names = right.column_names()\n        common_columns = [name for name in left_names if name in right_names]\n        for name in common_columns:\n            join_keys[name] = name\n    elif type(on) is str:\n        join_keys[on] = on\n    elif type(on) is list:\n        for name in on:\n            if type(name) is not str:\n                raise TypeError('Join keys must each be a str.')\n            join_keys[name] = name\n    elif type(on) is dict:\n        join_keys = on\n    else:\n        raise TypeError('Must pass a str, list, or dict of join keys')\n    with cython_context():\n        if alter_name is None:\n            return SFrame(_proxy=self.__proxy__.join(right.__proxy__, how, join_keys))\n        if type(alter_name) is dict:\n            left_names = self.column_names()\n            right_names = right.column_names()\n            for (k, v) in alter_name.items():\n                if k not in right_names or k in join_keys:\n                    raise KeyError('Redundant key %s for collision resolution' % k)\n                if k == v:\n                    raise ValueError('Key %s should not be equal to value' % k)\n                if v in left_names or v in right_names:\n                    raise ValueError('Value %s will cause further collision' % v)\n            return SFrame(_proxy=self.__proxy__.join_with_custom_name(right.__proxy__, how, join_keys, alter_name))",
            "def join(self, right, on=None, how='inner', alter_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Merge two SFrames. Merges the current (left) SFrame with the given\\n        (right) SFrame using a SQL-style equi-join operation by columns.\\n\\n        Parameters\\n        ----------\\n        right : SFrame\\n            The SFrame to join.\\n\\n        on : None | str | list | dict, optional\\n            The column name(s) representing the set of join keys.  Each row that\\n            has the same value in this set of columns will be merged together.\\n\\n            * If 'None' is given, join will use all columns that have the same\\n              name as the set of join keys.\\n\\n            * If a str is given, this is interpreted as a join using one column,\\n              where both SFrames have the same column name.\\n\\n            * If a list is given, this is interpreted as a join using one or\\n              more column names, where each column name given exists in both\\n              SFrames.\\n\\n            * If a dict is given, each dict key is taken as a column name in the\\n              left SFrame, and each dict value is taken as the column name in\\n              right SFrame that will be joined together. e.g.\\n              {'left_col_name':'right_col_name'}.\\n\\n        how : {'left', 'right', 'outer', 'inner'}, optional\\n            The type of join to perform.  'inner' is default.\\n\\n            * inner: Equivalent to a SQL inner join.  Result consists of the\\n              rows from the two frames whose join key values match exactly,\\n              merged together into one SFrame.\\n\\n            * left: Equivalent to a SQL left outer join. Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the left SFrame, merged with missing values.\\n\\n            * right: Equivalent to a SQL right outer join.  Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the right SFrame, merged with missing values.\\n\\n            * outer: Equivalent to a SQL full outer join. Result is\\n              the union between the result of a left outer join and a right\\n              outer join.\\n\\n        alter_name : None | dict\\n            user provided names to resolve column name conflict when merging two sframe.\\n\\n            * 'None', then default conflict resolution will be used. For example, if 'X' is\\n            defined in the sframe on the left side of join, and there's an column also called\\n            'X' in the sframe on the right, 'X.1' will be used as the new column name when\\n            appending the column 'X' from the right sframe, in order to avoid column name collision.\\n\\n            * if a dict is given, the dict key should be obtained from column names from the right\\n            sframe. The dict value should be user preferred column name to resolve the name collision\\n            instead of resolving by the default behavior. In general, dict key should not be any value\\n            from the right sframe column names. If dict value will cause potential name confict\\n            after an attempt to resolve, exception will be thrown.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> animals = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                           'name': ['dog', 'cat', 'sheep', 'cow']})\\n        >>> sounds = turicreate.SFrame({'id': [1, 3, 4, 5],\\n        ...                          'sound': ['woof', 'baa', 'moo', 'oink']})\\n        >>> animals.join(sounds, how='inner')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        +----+-------+-------+\\n        [3 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on='id', how='left')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on=['id'], how='right')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on={'id':'id'}, how='outer')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [5 rows x 3 columns]\\n        \"\n    available_join_types = ['left', 'right', 'outer', 'inner']\n    if not isinstance(right, SFrame):\n        raise TypeError('Can only join two SFrames')\n    if how not in available_join_types:\n        raise ValueError('Invalid join type')\n    if self.num_columns() <= 0 or right.num_columns() <= 0:\n        raise ValueError('Cannot join an SFrame with no columns.')\n    join_keys = dict()\n    if on is None:\n        left_names = self.column_names()\n        right_names = right.column_names()\n        common_columns = [name for name in left_names if name in right_names]\n        for name in common_columns:\n            join_keys[name] = name\n    elif type(on) is str:\n        join_keys[on] = on\n    elif type(on) is list:\n        for name in on:\n            if type(name) is not str:\n                raise TypeError('Join keys must each be a str.')\n            join_keys[name] = name\n    elif type(on) is dict:\n        join_keys = on\n    else:\n        raise TypeError('Must pass a str, list, or dict of join keys')\n    with cython_context():\n        if alter_name is None:\n            return SFrame(_proxy=self.__proxy__.join(right.__proxy__, how, join_keys))\n        if type(alter_name) is dict:\n            left_names = self.column_names()\n            right_names = right.column_names()\n            for (k, v) in alter_name.items():\n                if k not in right_names or k in join_keys:\n                    raise KeyError('Redundant key %s for collision resolution' % k)\n                if k == v:\n                    raise ValueError('Key %s should not be equal to value' % k)\n                if v in left_names or v in right_names:\n                    raise ValueError('Value %s will cause further collision' % v)\n            return SFrame(_proxy=self.__proxy__.join_with_custom_name(right.__proxy__, how, join_keys, alter_name))",
            "def join(self, right, on=None, how='inner', alter_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Merge two SFrames. Merges the current (left) SFrame with the given\\n        (right) SFrame using a SQL-style equi-join operation by columns.\\n\\n        Parameters\\n        ----------\\n        right : SFrame\\n            The SFrame to join.\\n\\n        on : None | str | list | dict, optional\\n            The column name(s) representing the set of join keys.  Each row that\\n            has the same value in this set of columns will be merged together.\\n\\n            * If 'None' is given, join will use all columns that have the same\\n              name as the set of join keys.\\n\\n            * If a str is given, this is interpreted as a join using one column,\\n              where both SFrames have the same column name.\\n\\n            * If a list is given, this is interpreted as a join using one or\\n              more column names, where each column name given exists in both\\n              SFrames.\\n\\n            * If a dict is given, each dict key is taken as a column name in the\\n              left SFrame, and each dict value is taken as the column name in\\n              right SFrame that will be joined together. e.g.\\n              {'left_col_name':'right_col_name'}.\\n\\n        how : {'left', 'right', 'outer', 'inner'}, optional\\n            The type of join to perform.  'inner' is default.\\n\\n            * inner: Equivalent to a SQL inner join.  Result consists of the\\n              rows from the two frames whose join key values match exactly,\\n              merged together into one SFrame.\\n\\n            * left: Equivalent to a SQL left outer join. Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the left SFrame, merged with missing values.\\n\\n            * right: Equivalent to a SQL right outer join.  Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the right SFrame, merged with missing values.\\n\\n            * outer: Equivalent to a SQL full outer join. Result is\\n              the union between the result of a left outer join and a right\\n              outer join.\\n\\n        alter_name : None | dict\\n            user provided names to resolve column name conflict when merging two sframe.\\n\\n            * 'None', then default conflict resolution will be used. For example, if 'X' is\\n            defined in the sframe on the left side of join, and there's an column also called\\n            'X' in the sframe on the right, 'X.1' will be used as the new column name when\\n            appending the column 'X' from the right sframe, in order to avoid column name collision.\\n\\n            * if a dict is given, the dict key should be obtained from column names from the right\\n            sframe. The dict value should be user preferred column name to resolve the name collision\\n            instead of resolving by the default behavior. In general, dict key should not be any value\\n            from the right sframe column names. If dict value will cause potential name confict\\n            after an attempt to resolve, exception will be thrown.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> animals = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                           'name': ['dog', 'cat', 'sheep', 'cow']})\\n        >>> sounds = turicreate.SFrame({'id': [1, 3, 4, 5],\\n        ...                          'sound': ['woof', 'baa', 'moo', 'oink']})\\n        >>> animals.join(sounds, how='inner')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        +----+-------+-------+\\n        [3 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on='id', how='left')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on=['id'], how='right')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on={'id':'id'}, how='outer')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [5 rows x 3 columns]\\n        \"\n    available_join_types = ['left', 'right', 'outer', 'inner']\n    if not isinstance(right, SFrame):\n        raise TypeError('Can only join two SFrames')\n    if how not in available_join_types:\n        raise ValueError('Invalid join type')\n    if self.num_columns() <= 0 or right.num_columns() <= 0:\n        raise ValueError('Cannot join an SFrame with no columns.')\n    join_keys = dict()\n    if on is None:\n        left_names = self.column_names()\n        right_names = right.column_names()\n        common_columns = [name for name in left_names if name in right_names]\n        for name in common_columns:\n            join_keys[name] = name\n    elif type(on) is str:\n        join_keys[on] = on\n    elif type(on) is list:\n        for name in on:\n            if type(name) is not str:\n                raise TypeError('Join keys must each be a str.')\n            join_keys[name] = name\n    elif type(on) is dict:\n        join_keys = on\n    else:\n        raise TypeError('Must pass a str, list, or dict of join keys')\n    with cython_context():\n        if alter_name is None:\n            return SFrame(_proxy=self.__proxy__.join(right.__proxy__, how, join_keys))\n        if type(alter_name) is dict:\n            left_names = self.column_names()\n            right_names = right.column_names()\n            for (k, v) in alter_name.items():\n                if k not in right_names or k in join_keys:\n                    raise KeyError('Redundant key %s for collision resolution' % k)\n                if k == v:\n                    raise ValueError('Key %s should not be equal to value' % k)\n                if v in left_names or v in right_names:\n                    raise ValueError('Value %s will cause further collision' % v)\n            return SFrame(_proxy=self.__proxy__.join_with_custom_name(right.__proxy__, how, join_keys, alter_name))",
            "def join(self, right, on=None, how='inner', alter_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Merge two SFrames. Merges the current (left) SFrame with the given\\n        (right) SFrame using a SQL-style equi-join operation by columns.\\n\\n        Parameters\\n        ----------\\n        right : SFrame\\n            The SFrame to join.\\n\\n        on : None | str | list | dict, optional\\n            The column name(s) representing the set of join keys.  Each row that\\n            has the same value in this set of columns will be merged together.\\n\\n            * If 'None' is given, join will use all columns that have the same\\n              name as the set of join keys.\\n\\n            * If a str is given, this is interpreted as a join using one column,\\n              where both SFrames have the same column name.\\n\\n            * If a list is given, this is interpreted as a join using one or\\n              more column names, where each column name given exists in both\\n              SFrames.\\n\\n            * If a dict is given, each dict key is taken as a column name in the\\n              left SFrame, and each dict value is taken as the column name in\\n              right SFrame that will be joined together. e.g.\\n              {'left_col_name':'right_col_name'}.\\n\\n        how : {'left', 'right', 'outer', 'inner'}, optional\\n            The type of join to perform.  'inner' is default.\\n\\n            * inner: Equivalent to a SQL inner join.  Result consists of the\\n              rows from the two frames whose join key values match exactly,\\n              merged together into one SFrame.\\n\\n            * left: Equivalent to a SQL left outer join. Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the left SFrame, merged with missing values.\\n\\n            * right: Equivalent to a SQL right outer join.  Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the right SFrame, merged with missing values.\\n\\n            * outer: Equivalent to a SQL full outer join. Result is\\n              the union between the result of a left outer join and a right\\n              outer join.\\n\\n        alter_name : None | dict\\n            user provided names to resolve column name conflict when merging two sframe.\\n\\n            * 'None', then default conflict resolution will be used. For example, if 'X' is\\n            defined in the sframe on the left side of join, and there's an column also called\\n            'X' in the sframe on the right, 'X.1' will be used as the new column name when\\n            appending the column 'X' from the right sframe, in order to avoid column name collision.\\n\\n            * if a dict is given, the dict key should be obtained from column names from the right\\n            sframe. The dict value should be user preferred column name to resolve the name collision\\n            instead of resolving by the default behavior. In general, dict key should not be any value\\n            from the right sframe column names. If dict value will cause potential name confict\\n            after an attempt to resolve, exception will be thrown.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> animals = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                           'name': ['dog', 'cat', 'sheep', 'cow']})\\n        >>> sounds = turicreate.SFrame({'id': [1, 3, 4, 5],\\n        ...                          'sound': ['woof', 'baa', 'moo', 'oink']})\\n        >>> animals.join(sounds, how='inner')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        +----+-------+-------+\\n        [3 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on='id', how='left')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on=['id'], how='right')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on={'id':'id'}, how='outer')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [5 rows x 3 columns]\\n        \"\n    available_join_types = ['left', 'right', 'outer', 'inner']\n    if not isinstance(right, SFrame):\n        raise TypeError('Can only join two SFrames')\n    if how not in available_join_types:\n        raise ValueError('Invalid join type')\n    if self.num_columns() <= 0 or right.num_columns() <= 0:\n        raise ValueError('Cannot join an SFrame with no columns.')\n    join_keys = dict()\n    if on is None:\n        left_names = self.column_names()\n        right_names = right.column_names()\n        common_columns = [name for name in left_names if name in right_names]\n        for name in common_columns:\n            join_keys[name] = name\n    elif type(on) is str:\n        join_keys[on] = on\n    elif type(on) is list:\n        for name in on:\n            if type(name) is not str:\n                raise TypeError('Join keys must each be a str.')\n            join_keys[name] = name\n    elif type(on) is dict:\n        join_keys = on\n    else:\n        raise TypeError('Must pass a str, list, or dict of join keys')\n    with cython_context():\n        if alter_name is None:\n            return SFrame(_proxy=self.__proxy__.join(right.__proxy__, how, join_keys))\n        if type(alter_name) is dict:\n            left_names = self.column_names()\n            right_names = right.column_names()\n            for (k, v) in alter_name.items():\n                if k not in right_names or k in join_keys:\n                    raise KeyError('Redundant key %s for collision resolution' % k)\n                if k == v:\n                    raise ValueError('Key %s should not be equal to value' % k)\n                if v in left_names or v in right_names:\n                    raise ValueError('Value %s will cause further collision' % v)\n            return SFrame(_proxy=self.__proxy__.join_with_custom_name(right.__proxy__, how, join_keys, alter_name))",
            "def join(self, right, on=None, how='inner', alter_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Merge two SFrames. Merges the current (left) SFrame with the given\\n        (right) SFrame using a SQL-style equi-join operation by columns.\\n\\n        Parameters\\n        ----------\\n        right : SFrame\\n            The SFrame to join.\\n\\n        on : None | str | list | dict, optional\\n            The column name(s) representing the set of join keys.  Each row that\\n            has the same value in this set of columns will be merged together.\\n\\n            * If 'None' is given, join will use all columns that have the same\\n              name as the set of join keys.\\n\\n            * If a str is given, this is interpreted as a join using one column,\\n              where both SFrames have the same column name.\\n\\n            * If a list is given, this is interpreted as a join using one or\\n              more column names, where each column name given exists in both\\n              SFrames.\\n\\n            * If a dict is given, each dict key is taken as a column name in the\\n              left SFrame, and each dict value is taken as the column name in\\n              right SFrame that will be joined together. e.g.\\n              {'left_col_name':'right_col_name'}.\\n\\n        how : {'left', 'right', 'outer', 'inner'}, optional\\n            The type of join to perform.  'inner' is default.\\n\\n            * inner: Equivalent to a SQL inner join.  Result consists of the\\n              rows from the two frames whose join key values match exactly,\\n              merged together into one SFrame.\\n\\n            * left: Equivalent to a SQL left outer join. Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the left SFrame, merged with missing values.\\n\\n            * right: Equivalent to a SQL right outer join.  Result is the union\\n              between the result of an inner join and the rest of the rows from\\n              the right SFrame, merged with missing values.\\n\\n            * outer: Equivalent to a SQL full outer join. Result is\\n              the union between the result of a left outer join and a right\\n              outer join.\\n\\n        alter_name : None | dict\\n            user provided names to resolve column name conflict when merging two sframe.\\n\\n            * 'None', then default conflict resolution will be used. For example, if 'X' is\\n            defined in the sframe on the left side of join, and there's an column also called\\n            'X' in the sframe on the right, 'X.1' will be used as the new column name when\\n            appending the column 'X' from the right sframe, in order to avoid column name collision.\\n\\n            * if a dict is given, the dict key should be obtained from column names from the right\\n            sframe. The dict value should be user preferred column name to resolve the name collision\\n            instead of resolving by the default behavior. In general, dict key should not be any value\\n            from the right sframe column names. If dict value will cause potential name confict\\n            after an attempt to resolve, exception will be thrown.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        Examples\\n        --------\\n        >>> animals = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                           'name': ['dog', 'cat', 'sheep', 'cow']})\\n        >>> sounds = turicreate.SFrame({'id': [1, 3, 4, 5],\\n        ...                          'sound': ['woof', 'baa', 'moo', 'oink']})\\n        >>> animals.join(sounds, how='inner')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        +----+-------+-------+\\n        [3 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on='id', how='left')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on=['id'], how='right')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        +----+-------+-------+\\n        [4 rows x 3 columns]\\n\\n        >>> animals.join(sounds, on={'id':'id'}, how='outer')\\n        +----+-------+-------+\\n        | id |  name | sound |\\n        +----+-------+-------+\\n        | 1  |  dog  |  woof |\\n        | 3  | sheep |  baa  |\\n        | 4  |  cow  |  moo  |\\n        | 5  |  None |  oink |\\n        | 2  |  cat  |  None |\\n        +----+-------+-------+\\n        [5 rows x 3 columns]\\n        \"\n    available_join_types = ['left', 'right', 'outer', 'inner']\n    if not isinstance(right, SFrame):\n        raise TypeError('Can only join two SFrames')\n    if how not in available_join_types:\n        raise ValueError('Invalid join type')\n    if self.num_columns() <= 0 or right.num_columns() <= 0:\n        raise ValueError('Cannot join an SFrame with no columns.')\n    join_keys = dict()\n    if on is None:\n        left_names = self.column_names()\n        right_names = right.column_names()\n        common_columns = [name for name in left_names if name in right_names]\n        for name in common_columns:\n            join_keys[name] = name\n    elif type(on) is str:\n        join_keys[on] = on\n    elif type(on) is list:\n        for name in on:\n            if type(name) is not str:\n                raise TypeError('Join keys must each be a str.')\n            join_keys[name] = name\n    elif type(on) is dict:\n        join_keys = on\n    else:\n        raise TypeError('Must pass a str, list, or dict of join keys')\n    with cython_context():\n        if alter_name is None:\n            return SFrame(_proxy=self.__proxy__.join(right.__proxy__, how, join_keys))\n        if type(alter_name) is dict:\n            left_names = self.column_names()\n            right_names = right.column_names()\n            for (k, v) in alter_name.items():\n                if k not in right_names or k in join_keys:\n                    raise KeyError('Redundant key %s for collision resolution' % k)\n                if k == v:\n                    raise ValueError('Key %s should not be equal to value' % k)\n                if v in left_names or v in right_names:\n                    raise ValueError('Value %s will cause further collision' % v)\n            return SFrame(_proxy=self.__proxy__.join_with_custom_name(right.__proxy__, how, join_keys, alter_name))"
        ]
    },
    {
        "func_name": "filter_by",
        "original": "def filter_by(self, values, column_name, exclude=False):\n    \"\"\"\n        Filter an SFrame by values inside an iterable object. Result is an\n        SFrame that only includes (or excludes) the rows that have a column\n        with the given ``column_name`` which holds one of the values in the\n        given ``values`` :class:`~turicreate.SArray`. If ``values`` is not an\n        SArray, we attempt to convert it to one before filtering.\n\n        Parameters\n        ----------\n        values : SArray | list | numpy.ndarray | pandas.Series | str | map\n        | generator | filter | None | range\n            The values to use to filter the SFrame.  The resulting SFrame will\n            only include rows that have one of these values in the given\n            column.\n\n        column_name : str\n            The column of the SFrame to match with the given `values`.\n\n        exclude : bool\n            If True, the result SFrame will contain all rows EXCEPT those that\n            have one of ``values`` in ``column_name``.\n\n        Returns\n        -------\n        out : SFrame\n            The filtered SFrame.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3, 4],\n        ...                      'animal_type': ['dog', 'cat', 'cow', 'horse'],\n        ...                      'name': ['bob', 'jim', 'jimbob', 'bobjim']})\n        >>> household_pets = ['cat', 'hamster', 'dog', 'fish', 'bird', 'snake']\n        >>> sf.filter_by(household_pets, 'animal_type')\n        +-------------+----+------+\n        | animal_type | id | name |\n        +-------------+----+------+\n        |     dog     | 1  | bob  |\n        |     cat     | 2  | jim  |\n        +-------------+----+------+\n        [2 rows x 3 columns]\n        >>> sf.filter_by(household_pets, 'animal_type', exclude=True)\n        +-------------+----+--------+\n        | animal_type | id |  name  |\n        +-------------+----+--------+\n        |    horse    | 4  | bobjim |\n        |     cow     | 3  | jimbob |\n        +-------------+----+--------+\n        [2 rows x 3 columns]\n\n        >>> sf.filter_by(None, 'name', exclude=True)\n        +-------------+----+--------+\n        | animal_type | id |  name  |\n        +-------------+----+--------+\n        |     dog     | 1  |  bob   |\n        |     cat     | 2  |  jim   |\n        |     cow     | 3  | jimbob |\n        |    horse    | 4  | bobjim |\n        +-------------+----+--------+\n        [4 rows x 3 columns]\n\n        >>> sf.filter_by(filter(lambda x : len(x) > 3, sf['name']), 'name', exclude=True)\n        +-------------+----+--------+\n        | animal_type | id |  name  |\n        +-------------+----+--------+\n        |     dog     | 1  |  bob   |\n        |     cat     | 2  |  jim   |\n        +-------------+----+--------+\n        [2 rows x 3 columns]\n\n        >>> sf.filter_by(range(3), 'id', exclude=True)\n        +-------------+----+--------+\n        | animal_type | id |  name  |\n        +-------------+----+--------+\n        |     cow     | 3  | jimbob |\n        |    horse    | 4  | bobjim |\n        +-------------+----+--------+\n        [2 rows x 3 columns]\n        \"\"\"\n    if type(column_name) is not str:\n        raise TypeError('Must pass a str as column_name')\n    existing_columns = self.column_names()\n    if column_name not in existing_columns:\n        raise KeyError(\"Column '\" + column_name + \"' not in SFrame.\")\n    existing_type = self[column_name].dtype\n    if type(values) is not SArray:\n        if not _is_non_string_iterable(values):\n            values = [values]\n        elif SArray._is_iterable_required_to_listify(values):\n            values = list(values)\n        if all((val is None for val in values)):\n            values = SArray(values, existing_type)\n        else:\n            values = SArray(values)\n    value_sf = SFrame()\n    value_sf.add_column(values, column_name, inplace=True)\n    given_type = value_sf.column_types()[0]\n    if given_type != existing_type:\n        raise TypeError((\"Type of given values ({0}) does not match type of column '\" + column_name + \"' ({1}) in SFrame.\").format(given_type, existing_type))\n    value_sf = value_sf.groupby(column_name, {})\n    with cython_context():\n        if exclude:\n            id_name = 'id'\n            while id_name in existing_columns:\n                id_name += '1'\n            value_sf = value_sf.add_row_number(id_name)\n            tmp = SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'left', {column_name: column_name}))\n            ret_sf = tmp[tmp[id_name] == None]\n            del ret_sf[id_name]\n            return ret_sf\n        else:\n            return SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'inner', {column_name: column_name}))",
        "mutated": [
            "def filter_by(self, values, column_name, exclude=False):\n    if False:\n        i = 10\n    \"\\n        Filter an SFrame by values inside an iterable object. Result is an\\n        SFrame that only includes (or excludes) the rows that have a column\\n        with the given ``column_name`` which holds one of the values in the\\n        given ``values`` :class:`~turicreate.SArray`. If ``values`` is not an\\n        SArray, we attempt to convert it to one before filtering.\\n\\n        Parameters\\n        ----------\\n        values : SArray | list | numpy.ndarray | pandas.Series | str | map\\n        | generator | filter | None | range\\n            The values to use to filter the SFrame.  The resulting SFrame will\\n            only include rows that have one of these values in the given\\n            column.\\n\\n        column_name : str\\n            The column of the SFrame to match with the given `values`.\\n\\n        exclude : bool\\n            If True, the result SFrame will contain all rows EXCEPT those that\\n            have one of ``values`` in ``column_name``.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The filtered SFrame.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                      'animal_type': ['dog', 'cat', 'cow', 'horse'],\\n        ...                      'name': ['bob', 'jim', 'jimbob', 'bobjim']})\\n        >>> household_pets = ['cat', 'hamster', 'dog', 'fish', 'bird', 'snake']\\n        >>> sf.filter_by(household_pets, 'animal_type')\\n        +-------------+----+------+\\n        | animal_type | id | name |\\n        +-------------+----+------+\\n        |     dog     | 1  | bob  |\\n        |     cat     | 2  | jim  |\\n        +-------------+----+------+\\n        [2 rows x 3 columns]\\n        >>> sf.filter_by(household_pets, 'animal_type', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |    horse    | 4  | bobjim |\\n        |     cow     | 3  | jimbob |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(None, 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.filter_by(filter(lambda x : len(x) > 3, sf['name']), 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(range(3), 'id', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must pass a str as column_name')\n    existing_columns = self.column_names()\n    if column_name not in existing_columns:\n        raise KeyError(\"Column '\" + column_name + \"' not in SFrame.\")\n    existing_type = self[column_name].dtype\n    if type(values) is not SArray:\n        if not _is_non_string_iterable(values):\n            values = [values]\n        elif SArray._is_iterable_required_to_listify(values):\n            values = list(values)\n        if all((val is None for val in values)):\n            values = SArray(values, existing_type)\n        else:\n            values = SArray(values)\n    value_sf = SFrame()\n    value_sf.add_column(values, column_name, inplace=True)\n    given_type = value_sf.column_types()[0]\n    if given_type != existing_type:\n        raise TypeError((\"Type of given values ({0}) does not match type of column '\" + column_name + \"' ({1}) in SFrame.\").format(given_type, existing_type))\n    value_sf = value_sf.groupby(column_name, {})\n    with cython_context():\n        if exclude:\n            id_name = 'id'\n            while id_name in existing_columns:\n                id_name += '1'\n            value_sf = value_sf.add_row_number(id_name)\n            tmp = SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'left', {column_name: column_name}))\n            ret_sf = tmp[tmp[id_name] == None]\n            del ret_sf[id_name]\n            return ret_sf\n        else:\n            return SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'inner', {column_name: column_name}))",
            "def filter_by(self, values, column_name, exclude=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Filter an SFrame by values inside an iterable object. Result is an\\n        SFrame that only includes (or excludes) the rows that have a column\\n        with the given ``column_name`` which holds one of the values in the\\n        given ``values`` :class:`~turicreate.SArray`. If ``values`` is not an\\n        SArray, we attempt to convert it to one before filtering.\\n\\n        Parameters\\n        ----------\\n        values : SArray | list | numpy.ndarray | pandas.Series | str | map\\n        | generator | filter | None | range\\n            The values to use to filter the SFrame.  The resulting SFrame will\\n            only include rows that have one of these values in the given\\n            column.\\n\\n        column_name : str\\n            The column of the SFrame to match with the given `values`.\\n\\n        exclude : bool\\n            If True, the result SFrame will contain all rows EXCEPT those that\\n            have one of ``values`` in ``column_name``.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The filtered SFrame.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                      'animal_type': ['dog', 'cat', 'cow', 'horse'],\\n        ...                      'name': ['bob', 'jim', 'jimbob', 'bobjim']})\\n        >>> household_pets = ['cat', 'hamster', 'dog', 'fish', 'bird', 'snake']\\n        >>> sf.filter_by(household_pets, 'animal_type')\\n        +-------------+----+------+\\n        | animal_type | id | name |\\n        +-------------+----+------+\\n        |     dog     | 1  | bob  |\\n        |     cat     | 2  | jim  |\\n        +-------------+----+------+\\n        [2 rows x 3 columns]\\n        >>> sf.filter_by(household_pets, 'animal_type', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |    horse    | 4  | bobjim |\\n        |     cow     | 3  | jimbob |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(None, 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.filter_by(filter(lambda x : len(x) > 3, sf['name']), 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(range(3), 'id', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must pass a str as column_name')\n    existing_columns = self.column_names()\n    if column_name not in existing_columns:\n        raise KeyError(\"Column '\" + column_name + \"' not in SFrame.\")\n    existing_type = self[column_name].dtype\n    if type(values) is not SArray:\n        if not _is_non_string_iterable(values):\n            values = [values]\n        elif SArray._is_iterable_required_to_listify(values):\n            values = list(values)\n        if all((val is None for val in values)):\n            values = SArray(values, existing_type)\n        else:\n            values = SArray(values)\n    value_sf = SFrame()\n    value_sf.add_column(values, column_name, inplace=True)\n    given_type = value_sf.column_types()[0]\n    if given_type != existing_type:\n        raise TypeError((\"Type of given values ({0}) does not match type of column '\" + column_name + \"' ({1}) in SFrame.\").format(given_type, existing_type))\n    value_sf = value_sf.groupby(column_name, {})\n    with cython_context():\n        if exclude:\n            id_name = 'id'\n            while id_name in existing_columns:\n                id_name += '1'\n            value_sf = value_sf.add_row_number(id_name)\n            tmp = SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'left', {column_name: column_name}))\n            ret_sf = tmp[tmp[id_name] == None]\n            del ret_sf[id_name]\n            return ret_sf\n        else:\n            return SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'inner', {column_name: column_name}))",
            "def filter_by(self, values, column_name, exclude=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Filter an SFrame by values inside an iterable object. Result is an\\n        SFrame that only includes (or excludes) the rows that have a column\\n        with the given ``column_name`` which holds one of the values in the\\n        given ``values`` :class:`~turicreate.SArray`. If ``values`` is not an\\n        SArray, we attempt to convert it to one before filtering.\\n\\n        Parameters\\n        ----------\\n        values : SArray | list | numpy.ndarray | pandas.Series | str | map\\n        | generator | filter | None | range\\n            The values to use to filter the SFrame.  The resulting SFrame will\\n            only include rows that have one of these values in the given\\n            column.\\n\\n        column_name : str\\n            The column of the SFrame to match with the given `values`.\\n\\n        exclude : bool\\n            If True, the result SFrame will contain all rows EXCEPT those that\\n            have one of ``values`` in ``column_name``.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The filtered SFrame.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                      'animal_type': ['dog', 'cat', 'cow', 'horse'],\\n        ...                      'name': ['bob', 'jim', 'jimbob', 'bobjim']})\\n        >>> household_pets = ['cat', 'hamster', 'dog', 'fish', 'bird', 'snake']\\n        >>> sf.filter_by(household_pets, 'animal_type')\\n        +-------------+----+------+\\n        | animal_type | id | name |\\n        +-------------+----+------+\\n        |     dog     | 1  | bob  |\\n        |     cat     | 2  | jim  |\\n        +-------------+----+------+\\n        [2 rows x 3 columns]\\n        >>> sf.filter_by(household_pets, 'animal_type', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |    horse    | 4  | bobjim |\\n        |     cow     | 3  | jimbob |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(None, 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.filter_by(filter(lambda x : len(x) > 3, sf['name']), 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(range(3), 'id', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must pass a str as column_name')\n    existing_columns = self.column_names()\n    if column_name not in existing_columns:\n        raise KeyError(\"Column '\" + column_name + \"' not in SFrame.\")\n    existing_type = self[column_name].dtype\n    if type(values) is not SArray:\n        if not _is_non_string_iterable(values):\n            values = [values]\n        elif SArray._is_iterable_required_to_listify(values):\n            values = list(values)\n        if all((val is None for val in values)):\n            values = SArray(values, existing_type)\n        else:\n            values = SArray(values)\n    value_sf = SFrame()\n    value_sf.add_column(values, column_name, inplace=True)\n    given_type = value_sf.column_types()[0]\n    if given_type != existing_type:\n        raise TypeError((\"Type of given values ({0}) does not match type of column '\" + column_name + \"' ({1}) in SFrame.\").format(given_type, existing_type))\n    value_sf = value_sf.groupby(column_name, {})\n    with cython_context():\n        if exclude:\n            id_name = 'id'\n            while id_name in existing_columns:\n                id_name += '1'\n            value_sf = value_sf.add_row_number(id_name)\n            tmp = SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'left', {column_name: column_name}))\n            ret_sf = tmp[tmp[id_name] == None]\n            del ret_sf[id_name]\n            return ret_sf\n        else:\n            return SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'inner', {column_name: column_name}))",
            "def filter_by(self, values, column_name, exclude=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Filter an SFrame by values inside an iterable object. Result is an\\n        SFrame that only includes (or excludes) the rows that have a column\\n        with the given ``column_name`` which holds one of the values in the\\n        given ``values`` :class:`~turicreate.SArray`. If ``values`` is not an\\n        SArray, we attempt to convert it to one before filtering.\\n\\n        Parameters\\n        ----------\\n        values : SArray | list | numpy.ndarray | pandas.Series | str | map\\n        | generator | filter | None | range\\n            The values to use to filter the SFrame.  The resulting SFrame will\\n            only include rows that have one of these values in the given\\n            column.\\n\\n        column_name : str\\n            The column of the SFrame to match with the given `values`.\\n\\n        exclude : bool\\n            If True, the result SFrame will contain all rows EXCEPT those that\\n            have one of ``values`` in ``column_name``.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The filtered SFrame.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                      'animal_type': ['dog', 'cat', 'cow', 'horse'],\\n        ...                      'name': ['bob', 'jim', 'jimbob', 'bobjim']})\\n        >>> household_pets = ['cat', 'hamster', 'dog', 'fish', 'bird', 'snake']\\n        >>> sf.filter_by(household_pets, 'animal_type')\\n        +-------------+----+------+\\n        | animal_type | id | name |\\n        +-------------+----+------+\\n        |     dog     | 1  | bob  |\\n        |     cat     | 2  | jim  |\\n        +-------------+----+------+\\n        [2 rows x 3 columns]\\n        >>> sf.filter_by(household_pets, 'animal_type', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |    horse    | 4  | bobjim |\\n        |     cow     | 3  | jimbob |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(None, 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.filter_by(filter(lambda x : len(x) > 3, sf['name']), 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(range(3), 'id', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must pass a str as column_name')\n    existing_columns = self.column_names()\n    if column_name not in existing_columns:\n        raise KeyError(\"Column '\" + column_name + \"' not in SFrame.\")\n    existing_type = self[column_name].dtype\n    if type(values) is not SArray:\n        if not _is_non_string_iterable(values):\n            values = [values]\n        elif SArray._is_iterable_required_to_listify(values):\n            values = list(values)\n        if all((val is None for val in values)):\n            values = SArray(values, existing_type)\n        else:\n            values = SArray(values)\n    value_sf = SFrame()\n    value_sf.add_column(values, column_name, inplace=True)\n    given_type = value_sf.column_types()[0]\n    if given_type != existing_type:\n        raise TypeError((\"Type of given values ({0}) does not match type of column '\" + column_name + \"' ({1}) in SFrame.\").format(given_type, existing_type))\n    value_sf = value_sf.groupby(column_name, {})\n    with cython_context():\n        if exclude:\n            id_name = 'id'\n            while id_name in existing_columns:\n                id_name += '1'\n            value_sf = value_sf.add_row_number(id_name)\n            tmp = SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'left', {column_name: column_name}))\n            ret_sf = tmp[tmp[id_name] == None]\n            del ret_sf[id_name]\n            return ret_sf\n        else:\n            return SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'inner', {column_name: column_name}))",
            "def filter_by(self, values, column_name, exclude=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Filter an SFrame by values inside an iterable object. Result is an\\n        SFrame that only includes (or excludes) the rows that have a column\\n        with the given ``column_name`` which holds one of the values in the\\n        given ``values`` :class:`~turicreate.SArray`. If ``values`` is not an\\n        SArray, we attempt to convert it to one before filtering.\\n\\n        Parameters\\n        ----------\\n        values : SArray | list | numpy.ndarray | pandas.Series | str | map\\n        | generator | filter | None | range\\n            The values to use to filter the SFrame.  The resulting SFrame will\\n            only include rows that have one of these values in the given\\n            column.\\n\\n        column_name : str\\n            The column of the SFrame to match with the given `values`.\\n\\n        exclude : bool\\n            If True, the result SFrame will contain all rows EXCEPT those that\\n            have one of ``values`` in ``column_name``.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The filtered SFrame.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id': [1, 2, 3, 4],\\n        ...                      'animal_type': ['dog', 'cat', 'cow', 'horse'],\\n        ...                      'name': ['bob', 'jim', 'jimbob', 'bobjim']})\\n        >>> household_pets = ['cat', 'hamster', 'dog', 'fish', 'bird', 'snake']\\n        >>> sf.filter_by(household_pets, 'animal_type')\\n        +-------------+----+------+\\n        | animal_type | id | name |\\n        +-------------+----+------+\\n        |     dog     | 1  | bob  |\\n        |     cat     | 2  | jim  |\\n        +-------------+----+------+\\n        [2 rows x 3 columns]\\n        >>> sf.filter_by(household_pets, 'animal_type', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |    horse    | 4  | bobjim |\\n        |     cow     | 3  | jimbob |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(None, 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.filter_by(filter(lambda x : len(x) > 3, sf['name']), 'name', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     dog     | 1  |  bob   |\\n        |     cat     | 2  |  jim   |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n\\n        >>> sf.filter_by(range(3), 'id', exclude=True)\\n        +-------------+----+--------+\\n        | animal_type | id |  name  |\\n        +-------------+----+--------+\\n        |     cow     | 3  | jimbob |\\n        |    horse    | 4  | bobjim |\\n        +-------------+----+--------+\\n        [2 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must pass a str as column_name')\n    existing_columns = self.column_names()\n    if column_name not in existing_columns:\n        raise KeyError(\"Column '\" + column_name + \"' not in SFrame.\")\n    existing_type = self[column_name].dtype\n    if type(values) is not SArray:\n        if not _is_non_string_iterable(values):\n            values = [values]\n        elif SArray._is_iterable_required_to_listify(values):\n            values = list(values)\n        if all((val is None for val in values)):\n            values = SArray(values, existing_type)\n        else:\n            values = SArray(values)\n    value_sf = SFrame()\n    value_sf.add_column(values, column_name, inplace=True)\n    given_type = value_sf.column_types()[0]\n    if given_type != existing_type:\n        raise TypeError((\"Type of given values ({0}) does not match type of column '\" + column_name + \"' ({1}) in SFrame.\").format(given_type, existing_type))\n    value_sf = value_sf.groupby(column_name, {})\n    with cython_context():\n        if exclude:\n            id_name = 'id'\n            while id_name in existing_columns:\n                id_name += '1'\n            value_sf = value_sf.add_row_number(id_name)\n            tmp = SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'left', {column_name: column_name}))\n            ret_sf = tmp[tmp[id_name] == None]\n            del ret_sf[id_name]\n            return ret_sf\n        else:\n            return SFrame(_proxy=self.__proxy__.join(value_sf.__proxy__, 'inner', {column_name: column_name}))"
        ]
    },
    {
        "func_name": "explore",
        "original": "def explore(self, title=None):\n    \"\"\"\n        Explore the SFrame in an interactive GUI. Opens a new app window.\n\n        Parameters\n        ----------\n        title : str\n            The plot title to show for the resulting visualization. Defaults to None.\n            If the title is None, a default title will be provided.\n\n        Returns\n        -------\n        None\n\n        Examples\n        --------\n        Suppose 'sf' is an SFrame, we can view it using:\n\n        >>> sf.explore()\n\n        To override the default plot title and axis labels:\n\n        >>> sf.explore(title=\"My Plot Title\")\n        \"\"\"\n    import sys\n    if sys.platform != 'darwin' and sys.platform != 'linux2' and (sys.platform != 'linux'):\n        raise NotImplementedError('Visualization is currently supported only on macOS and Linux.')\n    from ..visualization._plot import _target, display_table_in_notebook, _ensure_web_server\n    if _target == 'none':\n        return\n    if title is None:\n        title = ''\n    if _target == 'browser':\n        _ensure_web_server()\n        import webbrowser\n        import turicreate as tc\n        url = tc.extensions.get_url_for_table(self, title)\n        webbrowser.open_new_tab(url)\n        return\n    try:\n        if _target == 'auto' and (get_ipython().__class__.__name__ == 'ZMQInteractiveShell' or get_ipython().__class__.__name__ == 'Shell'):\n            display_table_in_notebook(self, title)\n            return\n    except NameError:\n        pass\n    path_to_client = _get_client_app_path()\n    self.__proxy__.explore(path_to_client, title)",
        "mutated": [
            "def explore(self, title=None):\n    if False:\n        i = 10\n    '\\n        Explore the SFrame in an interactive GUI. Opens a new app window.\\n\\n        Parameters\\n        ----------\\n        title : str\\n            The plot title to show for the resulting visualization. Defaults to None.\\n            If the title is None, a default title will be provided.\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an SFrame, we can view it using:\\n\\n        >>> sf.explore()\\n\\n        To override the default plot title and axis labels:\\n\\n        >>> sf.explore(title=\"My Plot Title\")\\n        '\n    import sys\n    if sys.platform != 'darwin' and sys.platform != 'linux2' and (sys.platform != 'linux'):\n        raise NotImplementedError('Visualization is currently supported only on macOS and Linux.')\n    from ..visualization._plot import _target, display_table_in_notebook, _ensure_web_server\n    if _target == 'none':\n        return\n    if title is None:\n        title = ''\n    if _target == 'browser':\n        _ensure_web_server()\n        import webbrowser\n        import turicreate as tc\n        url = tc.extensions.get_url_for_table(self, title)\n        webbrowser.open_new_tab(url)\n        return\n    try:\n        if _target == 'auto' and (get_ipython().__class__.__name__ == 'ZMQInteractiveShell' or get_ipython().__class__.__name__ == 'Shell'):\n            display_table_in_notebook(self, title)\n            return\n    except NameError:\n        pass\n    path_to_client = _get_client_app_path()\n    self.__proxy__.explore(path_to_client, title)",
            "def explore(self, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Explore the SFrame in an interactive GUI. Opens a new app window.\\n\\n        Parameters\\n        ----------\\n        title : str\\n            The plot title to show for the resulting visualization. Defaults to None.\\n            If the title is None, a default title will be provided.\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an SFrame, we can view it using:\\n\\n        >>> sf.explore()\\n\\n        To override the default plot title and axis labels:\\n\\n        >>> sf.explore(title=\"My Plot Title\")\\n        '\n    import sys\n    if sys.platform != 'darwin' and sys.platform != 'linux2' and (sys.platform != 'linux'):\n        raise NotImplementedError('Visualization is currently supported only on macOS and Linux.')\n    from ..visualization._plot import _target, display_table_in_notebook, _ensure_web_server\n    if _target == 'none':\n        return\n    if title is None:\n        title = ''\n    if _target == 'browser':\n        _ensure_web_server()\n        import webbrowser\n        import turicreate as tc\n        url = tc.extensions.get_url_for_table(self, title)\n        webbrowser.open_new_tab(url)\n        return\n    try:\n        if _target == 'auto' and (get_ipython().__class__.__name__ == 'ZMQInteractiveShell' or get_ipython().__class__.__name__ == 'Shell'):\n            display_table_in_notebook(self, title)\n            return\n    except NameError:\n        pass\n    path_to_client = _get_client_app_path()\n    self.__proxy__.explore(path_to_client, title)",
            "def explore(self, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Explore the SFrame in an interactive GUI. Opens a new app window.\\n\\n        Parameters\\n        ----------\\n        title : str\\n            The plot title to show for the resulting visualization. Defaults to None.\\n            If the title is None, a default title will be provided.\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an SFrame, we can view it using:\\n\\n        >>> sf.explore()\\n\\n        To override the default plot title and axis labels:\\n\\n        >>> sf.explore(title=\"My Plot Title\")\\n        '\n    import sys\n    if sys.platform != 'darwin' and sys.platform != 'linux2' and (sys.platform != 'linux'):\n        raise NotImplementedError('Visualization is currently supported only on macOS and Linux.')\n    from ..visualization._plot import _target, display_table_in_notebook, _ensure_web_server\n    if _target == 'none':\n        return\n    if title is None:\n        title = ''\n    if _target == 'browser':\n        _ensure_web_server()\n        import webbrowser\n        import turicreate as tc\n        url = tc.extensions.get_url_for_table(self, title)\n        webbrowser.open_new_tab(url)\n        return\n    try:\n        if _target == 'auto' and (get_ipython().__class__.__name__ == 'ZMQInteractiveShell' or get_ipython().__class__.__name__ == 'Shell'):\n            display_table_in_notebook(self, title)\n            return\n    except NameError:\n        pass\n    path_to_client = _get_client_app_path()\n    self.__proxy__.explore(path_to_client, title)",
            "def explore(self, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Explore the SFrame in an interactive GUI. Opens a new app window.\\n\\n        Parameters\\n        ----------\\n        title : str\\n            The plot title to show for the resulting visualization. Defaults to None.\\n            If the title is None, a default title will be provided.\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an SFrame, we can view it using:\\n\\n        >>> sf.explore()\\n\\n        To override the default plot title and axis labels:\\n\\n        >>> sf.explore(title=\"My Plot Title\")\\n        '\n    import sys\n    if sys.platform != 'darwin' and sys.platform != 'linux2' and (sys.platform != 'linux'):\n        raise NotImplementedError('Visualization is currently supported only on macOS and Linux.')\n    from ..visualization._plot import _target, display_table_in_notebook, _ensure_web_server\n    if _target == 'none':\n        return\n    if title is None:\n        title = ''\n    if _target == 'browser':\n        _ensure_web_server()\n        import webbrowser\n        import turicreate as tc\n        url = tc.extensions.get_url_for_table(self, title)\n        webbrowser.open_new_tab(url)\n        return\n    try:\n        if _target == 'auto' and (get_ipython().__class__.__name__ == 'ZMQInteractiveShell' or get_ipython().__class__.__name__ == 'Shell'):\n            display_table_in_notebook(self, title)\n            return\n    except NameError:\n        pass\n    path_to_client = _get_client_app_path()\n    self.__proxy__.explore(path_to_client, title)",
            "def explore(self, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Explore the SFrame in an interactive GUI. Opens a new app window.\\n\\n        Parameters\\n        ----------\\n        title : str\\n            The plot title to show for the resulting visualization. Defaults to None.\\n            If the title is None, a default title will be provided.\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an SFrame, we can view it using:\\n\\n        >>> sf.explore()\\n\\n        To override the default plot title and axis labels:\\n\\n        >>> sf.explore(title=\"My Plot Title\")\\n        '\n    import sys\n    if sys.platform != 'darwin' and sys.platform != 'linux2' and (sys.platform != 'linux'):\n        raise NotImplementedError('Visualization is currently supported only on macOS and Linux.')\n    from ..visualization._plot import _target, display_table_in_notebook, _ensure_web_server\n    if _target == 'none':\n        return\n    if title is None:\n        title = ''\n    if _target == 'browser':\n        _ensure_web_server()\n        import webbrowser\n        import turicreate as tc\n        url = tc.extensions.get_url_for_table(self, title)\n        webbrowser.open_new_tab(url)\n        return\n    try:\n        if _target == 'auto' and (get_ipython().__class__.__name__ == 'ZMQInteractiveShell' or get_ipython().__class__.__name__ == 'Shell'):\n            display_table_in_notebook(self, title)\n            return\n    except NameError:\n        pass\n    path_to_client = _get_client_app_path()\n    self.__proxy__.explore(path_to_client, title)"
        ]
    },
    {
        "func_name": "show",
        "original": "def show(self):\n    \"\"\"\n        Visualize a summary of each column in an SFrame. Opens a new app window.\n\n        Notes\n        -----\n        - The plot will render either inline in a Jupyter Notebook, in a web\n          browser, or in a native GUI window, depending on the value provided in\n          `turicreate.visualization.set_target` (defaults to 'auto').\n\n        Returns\n        -------\n        None\n\n        Examples\n        --------\n        Suppose 'sf' is an SFrame, we can view it using:\n\n        >>> sf.show()\n        \"\"\"\n    returned_plot = self.plot()\n    returned_plot.show()",
        "mutated": [
            "def show(self):\n    if False:\n        i = 10\n    \"\\n        Visualize a summary of each column in an SFrame. Opens a new app window.\\n\\n        Notes\\n        -----\\n        - The plot will render either inline in a Jupyter Notebook, in a web\\n          browser, or in a native GUI window, depending on the value provided in\\n          `turicreate.visualization.set_target` (defaults to 'auto').\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can view it using:\\n\\n        >>> sf.show()\\n        \"\n    returned_plot = self.plot()\n    returned_plot.show()",
            "def show(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Visualize a summary of each column in an SFrame. Opens a new app window.\\n\\n        Notes\\n        -----\\n        - The plot will render either inline in a Jupyter Notebook, in a web\\n          browser, or in a native GUI window, depending on the value provided in\\n          `turicreate.visualization.set_target` (defaults to 'auto').\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can view it using:\\n\\n        >>> sf.show()\\n        \"\n    returned_plot = self.plot()\n    returned_plot.show()",
            "def show(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Visualize a summary of each column in an SFrame. Opens a new app window.\\n\\n        Notes\\n        -----\\n        - The plot will render either inline in a Jupyter Notebook, in a web\\n          browser, or in a native GUI window, depending on the value provided in\\n          `turicreate.visualization.set_target` (defaults to 'auto').\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can view it using:\\n\\n        >>> sf.show()\\n        \"\n    returned_plot = self.plot()\n    returned_plot.show()",
            "def show(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Visualize a summary of each column in an SFrame. Opens a new app window.\\n\\n        Notes\\n        -----\\n        - The plot will render either inline in a Jupyter Notebook, in a web\\n          browser, or in a native GUI window, depending on the value provided in\\n          `turicreate.visualization.set_target` (defaults to 'auto').\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can view it using:\\n\\n        >>> sf.show()\\n        \"\n    returned_plot = self.plot()\n    returned_plot.show()",
            "def show(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Visualize a summary of each column in an SFrame. Opens a new app window.\\n\\n        Notes\\n        -----\\n        - The plot will render either inline in a Jupyter Notebook, in a web\\n          browser, or in a native GUI window, depending on the value provided in\\n          `turicreate.visualization.set_target` (defaults to 'auto').\\n\\n        Returns\\n        -------\\n        None\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can view it using:\\n\\n        >>> sf.show()\\n        \"\n    returned_plot = self.plot()\n    returned_plot.show()"
        ]
    },
    {
        "func_name": "plot",
        "original": "def plot(self):\n    \"\"\"\n        Create a Plot object that contains a summary of each column\n        in an SFrame.\n\n        Returns\n        -------\n        out : Plot\n        A :class: Plot object that is the columnwise summary of the sframe.\n\n        Examples\n        --------\n        Suppose 'sf' is an SFrame, we can make a plot object as:\n\n        >>> plt = sf.plot()\n\n        We can then visualize the plot using:\n\n        >>> plt.show()\n        \"\"\"\n    return Plot(_proxy=self.__proxy__.plot())",
        "mutated": [
            "def plot(self):\n    if False:\n        i = 10\n    \"\\n        Create a Plot object that contains a summary of each column\\n        in an SFrame.\\n\\n        Returns\\n        -------\\n        out : Plot\\n        A :class: Plot object that is the columnwise summary of the sframe.\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can make a plot object as:\\n\\n        >>> plt = sf.plot()\\n\\n        We can then visualize the plot using:\\n\\n        >>> plt.show()\\n        \"\n    return Plot(_proxy=self.__proxy__.plot())",
            "def plot(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Create a Plot object that contains a summary of each column\\n        in an SFrame.\\n\\n        Returns\\n        -------\\n        out : Plot\\n        A :class: Plot object that is the columnwise summary of the sframe.\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can make a plot object as:\\n\\n        >>> plt = sf.plot()\\n\\n        We can then visualize the plot using:\\n\\n        >>> plt.show()\\n        \"\n    return Plot(_proxy=self.__proxy__.plot())",
            "def plot(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Create a Plot object that contains a summary of each column\\n        in an SFrame.\\n\\n        Returns\\n        -------\\n        out : Plot\\n        A :class: Plot object that is the columnwise summary of the sframe.\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can make a plot object as:\\n\\n        >>> plt = sf.plot()\\n\\n        We can then visualize the plot using:\\n\\n        >>> plt.show()\\n        \"\n    return Plot(_proxy=self.__proxy__.plot())",
            "def plot(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Create a Plot object that contains a summary of each column\\n        in an SFrame.\\n\\n        Returns\\n        -------\\n        out : Plot\\n        A :class: Plot object that is the columnwise summary of the sframe.\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can make a plot object as:\\n\\n        >>> plt = sf.plot()\\n\\n        We can then visualize the plot using:\\n\\n        >>> plt.show()\\n        \"\n    return Plot(_proxy=self.__proxy__.plot())",
            "def plot(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Create a Plot object that contains a summary of each column\\n        in an SFrame.\\n\\n        Returns\\n        -------\\n        out : Plot\\n        A :class: Plot object that is the columnwise summary of the sframe.\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an SFrame, we can make a plot object as:\\n\\n        >>> plt = sf.plot()\\n\\n        We can then visualize the plot using:\\n\\n        >>> plt.show()\\n        \"\n    return Plot(_proxy=self.__proxy__.plot())"
        ]
    },
    {
        "func_name": "pack_columns",
        "original": "def pack_columns(self, column_names=None, column_name_prefix=None, dtype=list, fill_na=None, remove_prefix=True, new_column_name=None):\n    \"\"\"\n        Pack columns of the current SFrame into one single column. The result\n        is a new SFrame with the unaffected columns from the original SFrame\n        plus the newly created column.\n\n        The list of columns that are packed is chosen through either the\n        ``column_names`` or ``column_name_prefix`` parameter. Only one of the parameters\n        is allowed to be provided. ``columns_names`` explicitly specifies the list of\n        columns to pack, while ``column_name_prefix`` specifies that all columns that\n        have the given prefix are to be packed.\n\n        The type of the resulting column is decided by the ``dtype`` parameter.\n        Allowed values for ``dtype`` are dict, array.array and list:\n\n         - *dict*: pack to a dictionary SArray where column name becomes\n           dictionary key and column value becomes dictionary value\n\n         - *array.array*: pack all values from the packing columns into an array\n\n         - *list*: pack all values from the packing columns into a list.\n\n        Parameters\n        ----------\n        column_names : list[str], optional\n            A list of column names to be packed.  If omitted and\n            `column_name_prefix` is not specified, all columns from current SFrame\n            are packed.  This parameter is mutually exclusive with the\n            `column_name_prefix` parameter.\n\n        column_name_prefix : str, optional\n            Pack all columns with the given `column_name_prefix`.\n            This parameter is mutually exclusive with the `columns_names` parameter.\n\n        dtype : dict | array.array | list, optional\n            The resulting packed column type. If not provided, dtype is list.\n\n        fill_na : value, optional\n            Value to fill into packed column if missing value is encountered.\n            If packing to dictionary, `fill_na` is only applicable to dictionary\n            values; missing keys are not replaced.\n\n        remove_prefix : bool, optional\n            If True and `column_name_prefix` is specified, the dictionary key will\n            be constructed by removing the prefix from the column name.\n            This option is only applicable when packing to dict type.\n\n        new_column_name : str, optional\n            Packed column name.  If not given and `column_name_prefix` is given,\n            then the prefix will be used as the new column name, otherwise name\n            is generated automatically.\n\n        Returns\n        -------\n        out : SFrame\n            An SFrame that contains columns that are not packed, plus the newly\n            packed column.\n\n        See Also\n        --------\n        unpack\n\n        Notes\n        -----\n        - If packing to dictionary, missing key is always dropped. Missing\n          values are dropped if fill_na is not provided, otherwise, missing\n          value is replaced by 'fill_na'. If packing to list or array, missing\n          values will be kept. If 'fill_na' is provided, the missing value is\n          replaced with 'fill_na' value.\n\n        Examples\n        --------\n        Suppose 'sf' is an an SFrame that maintains business category\n        information:\n\n        >>> sf = turicreate.SFrame({'business': range(1, 5),\n        ...                       'category.retail': [1, None, 1, None],\n        ...                       'category.food': [1, 1, None, None],\n        ...                       'category.service': [None, 1, 1, None],\n        ...                       'category.shop': [1, 1, None, 1]})\n        >>> sf\n        +----------+-----------------+---------------+------------------+---------------+\n        | business | category.retail | category.food | category.service | category.shop |\n        +----------+-----------------+---------------+------------------+---------------+\n        |    1     |        1        |       1       |       None       |       1       |\n        |    2     |       None      |       1       |        1         |       1       |\n        |    3     |        1        |      None     |        1         |      None     |\n        |    4     |       None      |       1       |       None       |       1       |\n        +----------+-----------------+---------------+------------------+---------------+\n        [4 rows x 5 columns]\n\n        To pack all category columns into a list:\n\n        >>> sf.pack_columns(column_name_prefix='category')\n        +----------+-----------------------+\n        | business |        category       |\n        +----------+-----------------------+\n        |    1     |    [1, 1, None, 1]    |\n        |    2     |    [1, None, 1, 1]    |\n        |    3     |   [None, 1, 1, None]  |\n        |    4     | [None, None, None, 1] |\n        +----------+-----------------------+\n        [4 rows x 2 columns]\n\n        To pack all category columns into a dictionary, with new column name:\n\n        >>> sf.pack_columns(column_name_prefix='category', dtype=dict,\n        ...                 new_column_name='new name')\n        +----------+-------------------------------+\n        | business |            new name           |\n        +----------+-------------------------------+\n        |    1     | {'food': 1, 'shop': 1, 're... |\n        |    2     | {'food': 1, 'shop': 1, 'se... |\n        |    3     |  {'retail': 1, 'service': 1}  |\n        |    4     |          {'shop': 1}          |\n        +----------+-------------------------------+\n        [4 rows x 2 columns]\n\n        To keep column prefix in the resulting dict key:\n\n        >>> sf.pack_columns(column_name_prefix='category', dtype=dict,\n                            remove_prefix=False)\n        +----------+-------------------------------+\n        | business |            category           |\n        +----------+-------------------------------+\n        |    1     | {'category.retail': 1, 'ca... |\n        |    2     | {'category.food': 1, 'cate... |\n        |    3     | {'category.retail': 1, 'ca... |\n        |    4     |      {'category.shop': 1}     |\n        +----------+-------------------------------+\n        [4 rows x 2 columns]\n\n        To explicitly pack a set of columns:\n\n        >>> sf.pack_columns(column_names = ['business', 'category.retail',\n                                       'category.food', 'category.service',\n                                       'category.shop'])\n        +-----------------------+\n        |           X1          |\n        +-----------------------+\n        |   [1, 1, 1, None, 1]  |\n        |   [2, None, 1, 1, 1]  |\n        | [3, 1, None, 1, None] |\n        | [4, None, 1, None, 1] |\n        +-----------------------+\n        [4 rows x 1 columns]\n\n        To pack all columns with name starting with 'category' into an array\n        type, and with missing value replaced with 0:\n\n        >>> import array\n        >>> sf.pack_columns(column_name_prefix=\"category\", dtype=array.array,\n        ...                 fill_na=0)\n        +----------+----------------------+\n        | business |       category       |\n        +----------+----------------------+\n        |    1     | [1.0, 1.0, 0.0, 1.0] |\n        |    2     | [1.0, 0.0, 1.0, 1.0] |\n        |    3     | [0.0, 1.0, 1.0, 0.0] |\n        |    4     | [0.0, 0.0, 0.0, 1.0] |\n        +----------+----------------------+\n        [4 rows x 2 columns]\n        \"\"\"\n    if column_names is not None and column_name_prefix is not None:\n        raise ValueError(\"'column_names' and 'column_name_prefix' parameter cannot be given at the same time.\")\n    if new_column_name is None and column_name_prefix is not None:\n        new_column_name = column_name_prefix\n    if column_name_prefix is not None:\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n        column_names = [name for name in self.column_names() if name.startswith(column_name_prefix)]\n        if len(column_names) == 0:\n            raise ValueError(\"There is no column starts with prefix '\" + column_name_prefix + \"'\")\n    elif column_names is None:\n        column_names = self.column_names()\n    else:\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable type')\n        column_name_set = set(self.column_names())\n        for column in column_names:\n            if column not in column_name_set:\n                raise ValueError(\"Current SFrame has no column called '\" + str(column) + \"'.\")\n        if len(set(column_names)) != len(column_names):\n            raise ValueError('There is duplicate column names in column_names parameter')\n    if dtype not in (dict, list, array.array):\n        raise ValueError('Resulting dtype has to be one of dict/array.array/list type')\n    if dtype == array.array:\n        if fill_na is not None and type(fill_na) not in (int, float):\n            raise ValueError('fill_na value for array needs to be numeric type')\n        for column in column_names:\n            if self[column].dtype not in (int, float):\n                raise TypeError(\"Column '\" + column + \"' type is not numeric, cannot pack into array type\")\n    if dtype == dict and column_name_prefix is not None and (remove_prefix == True):\n        size_prefix = len(column_name_prefix)\n        first_char = set([c[size_prefix:size_prefix + 1] for c in column_names])\n        if len(first_char) == 1 and first_char.pop() in ['.', '-', '_']:\n            dict_keys = [name[size_prefix + 1:] for name in column_names]\n        else:\n            dict_keys = [name[size_prefix:] for name in column_names]\n    else:\n        dict_keys = column_names\n    rest_columns = [name for name in self.column_names() if name not in column_names]\n    if new_column_name is not None:\n        if type(new_column_name) != str:\n            raise TypeError(\"'new_column_name' has to be a string\")\n        if new_column_name in rest_columns:\n            raise KeyError('Current SFrame already contains a column name ' + new_column_name)\n    else:\n        new_column_name = ''\n    ret_sa = None\n    with cython_context():\n        ret_sa = SArray(_proxy=self.__proxy__.pack_columns(column_names, dict_keys, dtype, fill_na))\n    new_sf = self.select_columns(rest_columns)\n    new_sf.add_column(ret_sa, new_column_name, inplace=True)\n    return new_sf",
        "mutated": [
            "def pack_columns(self, column_names=None, column_name_prefix=None, dtype=list, fill_na=None, remove_prefix=True, new_column_name=None):\n    if False:\n        i = 10\n    '\\n        Pack columns of the current SFrame into one single column. The result\\n        is a new SFrame with the unaffected columns from the original SFrame\\n        plus the newly created column.\\n\\n        The list of columns that are packed is chosen through either the\\n        ``column_names`` or ``column_name_prefix`` parameter. Only one of the parameters\\n        is allowed to be provided. ``columns_names`` explicitly specifies the list of\\n        columns to pack, while ``column_name_prefix`` specifies that all columns that\\n        have the given prefix are to be packed.\\n\\n        The type of the resulting column is decided by the ``dtype`` parameter.\\n        Allowed values for ``dtype`` are dict, array.array and list:\\n\\n         - *dict*: pack to a dictionary SArray where column name becomes\\n           dictionary key and column value becomes dictionary value\\n\\n         - *array.array*: pack all values from the packing columns into an array\\n\\n         - *list*: pack all values from the packing columns into a list.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str], optional\\n            A list of column names to be packed.  If omitted and\\n            `column_name_prefix` is not specified, all columns from current SFrame\\n            are packed.  This parameter is mutually exclusive with the\\n            `column_name_prefix` parameter.\\n\\n        column_name_prefix : str, optional\\n            Pack all columns with the given `column_name_prefix`.\\n            This parameter is mutually exclusive with the `columns_names` parameter.\\n\\n        dtype : dict | array.array | list, optional\\n            The resulting packed column type. If not provided, dtype is list.\\n\\n        fill_na : value, optional\\n            Value to fill into packed column if missing value is encountered.\\n            If packing to dictionary, `fill_na` is only applicable to dictionary\\n            values; missing keys are not replaced.\\n\\n        remove_prefix : bool, optional\\n            If True and `column_name_prefix` is specified, the dictionary key will\\n            be constructed by removing the prefix from the column name.\\n            This option is only applicable when packing to dict type.\\n\\n        new_column_name : str, optional\\n            Packed column name.  If not given and `column_name_prefix` is given,\\n            then the prefix will be used as the new column name, otherwise name\\n            is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame that contains columns that are not packed, plus the newly\\n            packed column.\\n\\n        See Also\\n        --------\\n        unpack\\n\\n        Notes\\n        -----\\n        - If packing to dictionary, missing key is always dropped. Missing\\n          values are dropped if fill_na is not provided, otherwise, missing\\n          value is replaced by \\'fill_na\\'. If packing to list or array, missing\\n          values will be kept. If \\'fill_na\\' is provided, the missing value is\\n          replaced with \\'fill_na\\' value.\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an an SFrame that maintains business category\\n        information:\\n\\n        >>> sf = turicreate.SFrame({\\'business\\': range(1, 5),\\n        ...                       \\'category.retail\\': [1, None, 1, None],\\n        ...                       \\'category.food\\': [1, 1, None, None],\\n        ...                       \\'category.service\\': [None, 1, 1, None],\\n        ...                       \\'category.shop\\': [1, 1, None, 1]})\\n        >>> sf\\n        +----------+-----------------+---------------+------------------+---------------+\\n        | business | category.retail | category.food | category.service | category.shop |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        |    1     |        1        |       1       |       None       |       1       |\\n        |    2     |       None      |       1       |        1         |       1       |\\n        |    3     |        1        |      None     |        1         |      None     |\\n        |    4     |       None      |       1       |       None       |       1       |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        [4 rows x 5 columns]\\n\\n        To pack all category columns into a list:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\')\\n        +----------+-----------------------+\\n        | business |        category       |\\n        +----------+-----------------------+\\n        |    1     |    [1, 1, None, 1]    |\\n        |    2     |    [1, None, 1, 1]    |\\n        |    3     |   [None, 1, 1, None]  |\\n        |    4     | [None, None, None, 1] |\\n        +----------+-----------------------+\\n        [4 rows x 2 columns]\\n\\n        To pack all category columns into a dictionary, with new column name:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n        ...                 new_column_name=\\'new name\\')\\n        +----------+-------------------------------+\\n        | business |            new name           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'food\\': 1, \\'shop\\': 1, \\'re... |\\n        |    2     | {\\'food\\': 1, \\'shop\\': 1, \\'se... |\\n        |    3     |  {\\'retail\\': 1, \\'service\\': 1}  |\\n        |    4     |          {\\'shop\\': 1}          |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To keep column prefix in the resulting dict key:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n                            remove_prefix=False)\\n        +----------+-------------------------------+\\n        | business |            category           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'category.retail\\': 1, \\'ca... |\\n        |    2     | {\\'category.food\\': 1, \\'cate... |\\n        |    3     | {\\'category.retail\\': 1, \\'ca... |\\n        |    4     |      {\\'category.shop\\': 1}     |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To explicitly pack a set of columns:\\n\\n        >>> sf.pack_columns(column_names = [\\'business\\', \\'category.retail\\',\\n                                       \\'category.food\\', \\'category.service\\',\\n                                       \\'category.shop\\'])\\n        +-----------------------+\\n        |           X1          |\\n        +-----------------------+\\n        |   [1, 1, 1, None, 1]  |\\n        |   [2, None, 1, 1, 1]  |\\n        | [3, 1, None, 1, None] |\\n        | [4, None, 1, None, 1] |\\n        +-----------------------+\\n        [4 rows x 1 columns]\\n\\n        To pack all columns with name starting with \\'category\\' into an array\\n        type, and with missing value replaced with 0:\\n\\n        >>> import array\\n        >>> sf.pack_columns(column_name_prefix=\"category\", dtype=array.array,\\n        ...                 fill_na=0)\\n        +----------+----------------------+\\n        | business |       category       |\\n        +----------+----------------------+\\n        |    1     | [1.0, 1.0, 0.0, 1.0] |\\n        |    2     | [1.0, 0.0, 1.0, 1.0] |\\n        |    3     | [0.0, 1.0, 1.0, 0.0] |\\n        |    4     | [0.0, 0.0, 0.0, 1.0] |\\n        +----------+----------------------+\\n        [4 rows x 2 columns]\\n        '\n    if column_names is not None and column_name_prefix is not None:\n        raise ValueError(\"'column_names' and 'column_name_prefix' parameter cannot be given at the same time.\")\n    if new_column_name is None and column_name_prefix is not None:\n        new_column_name = column_name_prefix\n    if column_name_prefix is not None:\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n        column_names = [name for name in self.column_names() if name.startswith(column_name_prefix)]\n        if len(column_names) == 0:\n            raise ValueError(\"There is no column starts with prefix '\" + column_name_prefix + \"'\")\n    elif column_names is None:\n        column_names = self.column_names()\n    else:\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable type')\n        column_name_set = set(self.column_names())\n        for column in column_names:\n            if column not in column_name_set:\n                raise ValueError(\"Current SFrame has no column called '\" + str(column) + \"'.\")\n        if len(set(column_names)) != len(column_names):\n            raise ValueError('There is duplicate column names in column_names parameter')\n    if dtype not in (dict, list, array.array):\n        raise ValueError('Resulting dtype has to be one of dict/array.array/list type')\n    if dtype == array.array:\n        if fill_na is not None and type(fill_na) not in (int, float):\n            raise ValueError('fill_na value for array needs to be numeric type')\n        for column in column_names:\n            if self[column].dtype not in (int, float):\n                raise TypeError(\"Column '\" + column + \"' type is not numeric, cannot pack into array type\")\n    if dtype == dict and column_name_prefix is not None and (remove_prefix == True):\n        size_prefix = len(column_name_prefix)\n        first_char = set([c[size_prefix:size_prefix + 1] for c in column_names])\n        if len(first_char) == 1 and first_char.pop() in ['.', '-', '_']:\n            dict_keys = [name[size_prefix + 1:] for name in column_names]\n        else:\n            dict_keys = [name[size_prefix:] for name in column_names]\n    else:\n        dict_keys = column_names\n    rest_columns = [name for name in self.column_names() if name not in column_names]\n    if new_column_name is not None:\n        if type(new_column_name) != str:\n            raise TypeError(\"'new_column_name' has to be a string\")\n        if new_column_name in rest_columns:\n            raise KeyError('Current SFrame already contains a column name ' + new_column_name)\n    else:\n        new_column_name = ''\n    ret_sa = None\n    with cython_context():\n        ret_sa = SArray(_proxy=self.__proxy__.pack_columns(column_names, dict_keys, dtype, fill_na))\n    new_sf = self.select_columns(rest_columns)\n    new_sf.add_column(ret_sa, new_column_name, inplace=True)\n    return new_sf",
            "def pack_columns(self, column_names=None, column_name_prefix=None, dtype=list, fill_na=None, remove_prefix=True, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Pack columns of the current SFrame into one single column. The result\\n        is a new SFrame with the unaffected columns from the original SFrame\\n        plus the newly created column.\\n\\n        The list of columns that are packed is chosen through either the\\n        ``column_names`` or ``column_name_prefix`` parameter. Only one of the parameters\\n        is allowed to be provided. ``columns_names`` explicitly specifies the list of\\n        columns to pack, while ``column_name_prefix`` specifies that all columns that\\n        have the given prefix are to be packed.\\n\\n        The type of the resulting column is decided by the ``dtype`` parameter.\\n        Allowed values for ``dtype`` are dict, array.array and list:\\n\\n         - *dict*: pack to a dictionary SArray where column name becomes\\n           dictionary key and column value becomes dictionary value\\n\\n         - *array.array*: pack all values from the packing columns into an array\\n\\n         - *list*: pack all values from the packing columns into a list.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str], optional\\n            A list of column names to be packed.  If omitted and\\n            `column_name_prefix` is not specified, all columns from current SFrame\\n            are packed.  This parameter is mutually exclusive with the\\n            `column_name_prefix` parameter.\\n\\n        column_name_prefix : str, optional\\n            Pack all columns with the given `column_name_prefix`.\\n            This parameter is mutually exclusive with the `columns_names` parameter.\\n\\n        dtype : dict | array.array | list, optional\\n            The resulting packed column type. If not provided, dtype is list.\\n\\n        fill_na : value, optional\\n            Value to fill into packed column if missing value is encountered.\\n            If packing to dictionary, `fill_na` is only applicable to dictionary\\n            values; missing keys are not replaced.\\n\\n        remove_prefix : bool, optional\\n            If True and `column_name_prefix` is specified, the dictionary key will\\n            be constructed by removing the prefix from the column name.\\n            This option is only applicable when packing to dict type.\\n\\n        new_column_name : str, optional\\n            Packed column name.  If not given and `column_name_prefix` is given,\\n            then the prefix will be used as the new column name, otherwise name\\n            is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame that contains columns that are not packed, plus the newly\\n            packed column.\\n\\n        See Also\\n        --------\\n        unpack\\n\\n        Notes\\n        -----\\n        - If packing to dictionary, missing key is always dropped. Missing\\n          values are dropped if fill_na is not provided, otherwise, missing\\n          value is replaced by \\'fill_na\\'. If packing to list or array, missing\\n          values will be kept. If \\'fill_na\\' is provided, the missing value is\\n          replaced with \\'fill_na\\' value.\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an an SFrame that maintains business category\\n        information:\\n\\n        >>> sf = turicreate.SFrame({\\'business\\': range(1, 5),\\n        ...                       \\'category.retail\\': [1, None, 1, None],\\n        ...                       \\'category.food\\': [1, 1, None, None],\\n        ...                       \\'category.service\\': [None, 1, 1, None],\\n        ...                       \\'category.shop\\': [1, 1, None, 1]})\\n        >>> sf\\n        +----------+-----------------+---------------+------------------+---------------+\\n        | business | category.retail | category.food | category.service | category.shop |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        |    1     |        1        |       1       |       None       |       1       |\\n        |    2     |       None      |       1       |        1         |       1       |\\n        |    3     |        1        |      None     |        1         |      None     |\\n        |    4     |       None      |       1       |       None       |       1       |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        [4 rows x 5 columns]\\n\\n        To pack all category columns into a list:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\')\\n        +----------+-----------------------+\\n        | business |        category       |\\n        +----------+-----------------------+\\n        |    1     |    [1, 1, None, 1]    |\\n        |    2     |    [1, None, 1, 1]    |\\n        |    3     |   [None, 1, 1, None]  |\\n        |    4     | [None, None, None, 1] |\\n        +----------+-----------------------+\\n        [4 rows x 2 columns]\\n\\n        To pack all category columns into a dictionary, with new column name:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n        ...                 new_column_name=\\'new name\\')\\n        +----------+-------------------------------+\\n        | business |            new name           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'food\\': 1, \\'shop\\': 1, \\'re... |\\n        |    2     | {\\'food\\': 1, \\'shop\\': 1, \\'se... |\\n        |    3     |  {\\'retail\\': 1, \\'service\\': 1}  |\\n        |    4     |          {\\'shop\\': 1}          |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To keep column prefix in the resulting dict key:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n                            remove_prefix=False)\\n        +----------+-------------------------------+\\n        | business |            category           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'category.retail\\': 1, \\'ca... |\\n        |    2     | {\\'category.food\\': 1, \\'cate... |\\n        |    3     | {\\'category.retail\\': 1, \\'ca... |\\n        |    4     |      {\\'category.shop\\': 1}     |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To explicitly pack a set of columns:\\n\\n        >>> sf.pack_columns(column_names = [\\'business\\', \\'category.retail\\',\\n                                       \\'category.food\\', \\'category.service\\',\\n                                       \\'category.shop\\'])\\n        +-----------------------+\\n        |           X1          |\\n        +-----------------------+\\n        |   [1, 1, 1, None, 1]  |\\n        |   [2, None, 1, 1, 1]  |\\n        | [3, 1, None, 1, None] |\\n        | [4, None, 1, None, 1] |\\n        +-----------------------+\\n        [4 rows x 1 columns]\\n\\n        To pack all columns with name starting with \\'category\\' into an array\\n        type, and with missing value replaced with 0:\\n\\n        >>> import array\\n        >>> sf.pack_columns(column_name_prefix=\"category\", dtype=array.array,\\n        ...                 fill_na=0)\\n        +----------+----------------------+\\n        | business |       category       |\\n        +----------+----------------------+\\n        |    1     | [1.0, 1.0, 0.0, 1.0] |\\n        |    2     | [1.0, 0.0, 1.0, 1.0] |\\n        |    3     | [0.0, 1.0, 1.0, 0.0] |\\n        |    4     | [0.0, 0.0, 0.0, 1.0] |\\n        +----------+----------------------+\\n        [4 rows x 2 columns]\\n        '\n    if column_names is not None and column_name_prefix is not None:\n        raise ValueError(\"'column_names' and 'column_name_prefix' parameter cannot be given at the same time.\")\n    if new_column_name is None and column_name_prefix is not None:\n        new_column_name = column_name_prefix\n    if column_name_prefix is not None:\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n        column_names = [name for name in self.column_names() if name.startswith(column_name_prefix)]\n        if len(column_names) == 0:\n            raise ValueError(\"There is no column starts with prefix '\" + column_name_prefix + \"'\")\n    elif column_names is None:\n        column_names = self.column_names()\n    else:\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable type')\n        column_name_set = set(self.column_names())\n        for column in column_names:\n            if column not in column_name_set:\n                raise ValueError(\"Current SFrame has no column called '\" + str(column) + \"'.\")\n        if len(set(column_names)) != len(column_names):\n            raise ValueError('There is duplicate column names in column_names parameter')\n    if dtype not in (dict, list, array.array):\n        raise ValueError('Resulting dtype has to be one of dict/array.array/list type')\n    if dtype == array.array:\n        if fill_na is not None and type(fill_na) not in (int, float):\n            raise ValueError('fill_na value for array needs to be numeric type')\n        for column in column_names:\n            if self[column].dtype not in (int, float):\n                raise TypeError(\"Column '\" + column + \"' type is not numeric, cannot pack into array type\")\n    if dtype == dict and column_name_prefix is not None and (remove_prefix == True):\n        size_prefix = len(column_name_prefix)\n        first_char = set([c[size_prefix:size_prefix + 1] for c in column_names])\n        if len(first_char) == 1 and first_char.pop() in ['.', '-', '_']:\n            dict_keys = [name[size_prefix + 1:] for name in column_names]\n        else:\n            dict_keys = [name[size_prefix:] for name in column_names]\n    else:\n        dict_keys = column_names\n    rest_columns = [name for name in self.column_names() if name not in column_names]\n    if new_column_name is not None:\n        if type(new_column_name) != str:\n            raise TypeError(\"'new_column_name' has to be a string\")\n        if new_column_name in rest_columns:\n            raise KeyError('Current SFrame already contains a column name ' + new_column_name)\n    else:\n        new_column_name = ''\n    ret_sa = None\n    with cython_context():\n        ret_sa = SArray(_proxy=self.__proxy__.pack_columns(column_names, dict_keys, dtype, fill_na))\n    new_sf = self.select_columns(rest_columns)\n    new_sf.add_column(ret_sa, new_column_name, inplace=True)\n    return new_sf",
            "def pack_columns(self, column_names=None, column_name_prefix=None, dtype=list, fill_na=None, remove_prefix=True, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Pack columns of the current SFrame into one single column. The result\\n        is a new SFrame with the unaffected columns from the original SFrame\\n        plus the newly created column.\\n\\n        The list of columns that are packed is chosen through either the\\n        ``column_names`` or ``column_name_prefix`` parameter. Only one of the parameters\\n        is allowed to be provided. ``columns_names`` explicitly specifies the list of\\n        columns to pack, while ``column_name_prefix`` specifies that all columns that\\n        have the given prefix are to be packed.\\n\\n        The type of the resulting column is decided by the ``dtype`` parameter.\\n        Allowed values for ``dtype`` are dict, array.array and list:\\n\\n         - *dict*: pack to a dictionary SArray where column name becomes\\n           dictionary key and column value becomes dictionary value\\n\\n         - *array.array*: pack all values from the packing columns into an array\\n\\n         - *list*: pack all values from the packing columns into a list.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str], optional\\n            A list of column names to be packed.  If omitted and\\n            `column_name_prefix` is not specified, all columns from current SFrame\\n            are packed.  This parameter is mutually exclusive with the\\n            `column_name_prefix` parameter.\\n\\n        column_name_prefix : str, optional\\n            Pack all columns with the given `column_name_prefix`.\\n            This parameter is mutually exclusive with the `columns_names` parameter.\\n\\n        dtype : dict | array.array | list, optional\\n            The resulting packed column type. If not provided, dtype is list.\\n\\n        fill_na : value, optional\\n            Value to fill into packed column if missing value is encountered.\\n            If packing to dictionary, `fill_na` is only applicable to dictionary\\n            values; missing keys are not replaced.\\n\\n        remove_prefix : bool, optional\\n            If True and `column_name_prefix` is specified, the dictionary key will\\n            be constructed by removing the prefix from the column name.\\n            This option is only applicable when packing to dict type.\\n\\n        new_column_name : str, optional\\n            Packed column name.  If not given and `column_name_prefix` is given,\\n            then the prefix will be used as the new column name, otherwise name\\n            is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame that contains columns that are not packed, plus the newly\\n            packed column.\\n\\n        See Also\\n        --------\\n        unpack\\n\\n        Notes\\n        -----\\n        - If packing to dictionary, missing key is always dropped. Missing\\n          values are dropped if fill_na is not provided, otherwise, missing\\n          value is replaced by \\'fill_na\\'. If packing to list or array, missing\\n          values will be kept. If \\'fill_na\\' is provided, the missing value is\\n          replaced with \\'fill_na\\' value.\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an an SFrame that maintains business category\\n        information:\\n\\n        >>> sf = turicreate.SFrame({\\'business\\': range(1, 5),\\n        ...                       \\'category.retail\\': [1, None, 1, None],\\n        ...                       \\'category.food\\': [1, 1, None, None],\\n        ...                       \\'category.service\\': [None, 1, 1, None],\\n        ...                       \\'category.shop\\': [1, 1, None, 1]})\\n        >>> sf\\n        +----------+-----------------+---------------+------------------+---------------+\\n        | business | category.retail | category.food | category.service | category.shop |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        |    1     |        1        |       1       |       None       |       1       |\\n        |    2     |       None      |       1       |        1         |       1       |\\n        |    3     |        1        |      None     |        1         |      None     |\\n        |    4     |       None      |       1       |       None       |       1       |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        [4 rows x 5 columns]\\n\\n        To pack all category columns into a list:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\')\\n        +----------+-----------------------+\\n        | business |        category       |\\n        +----------+-----------------------+\\n        |    1     |    [1, 1, None, 1]    |\\n        |    2     |    [1, None, 1, 1]    |\\n        |    3     |   [None, 1, 1, None]  |\\n        |    4     | [None, None, None, 1] |\\n        +----------+-----------------------+\\n        [4 rows x 2 columns]\\n\\n        To pack all category columns into a dictionary, with new column name:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n        ...                 new_column_name=\\'new name\\')\\n        +----------+-------------------------------+\\n        | business |            new name           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'food\\': 1, \\'shop\\': 1, \\'re... |\\n        |    2     | {\\'food\\': 1, \\'shop\\': 1, \\'se... |\\n        |    3     |  {\\'retail\\': 1, \\'service\\': 1}  |\\n        |    4     |          {\\'shop\\': 1}          |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To keep column prefix in the resulting dict key:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n                            remove_prefix=False)\\n        +----------+-------------------------------+\\n        | business |            category           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'category.retail\\': 1, \\'ca... |\\n        |    2     | {\\'category.food\\': 1, \\'cate... |\\n        |    3     | {\\'category.retail\\': 1, \\'ca... |\\n        |    4     |      {\\'category.shop\\': 1}     |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To explicitly pack a set of columns:\\n\\n        >>> sf.pack_columns(column_names = [\\'business\\', \\'category.retail\\',\\n                                       \\'category.food\\', \\'category.service\\',\\n                                       \\'category.shop\\'])\\n        +-----------------------+\\n        |           X1          |\\n        +-----------------------+\\n        |   [1, 1, 1, None, 1]  |\\n        |   [2, None, 1, 1, 1]  |\\n        | [3, 1, None, 1, None] |\\n        | [4, None, 1, None, 1] |\\n        +-----------------------+\\n        [4 rows x 1 columns]\\n\\n        To pack all columns with name starting with \\'category\\' into an array\\n        type, and with missing value replaced with 0:\\n\\n        >>> import array\\n        >>> sf.pack_columns(column_name_prefix=\"category\", dtype=array.array,\\n        ...                 fill_na=0)\\n        +----------+----------------------+\\n        | business |       category       |\\n        +----------+----------------------+\\n        |    1     | [1.0, 1.0, 0.0, 1.0] |\\n        |    2     | [1.0, 0.0, 1.0, 1.0] |\\n        |    3     | [0.0, 1.0, 1.0, 0.0] |\\n        |    4     | [0.0, 0.0, 0.0, 1.0] |\\n        +----------+----------------------+\\n        [4 rows x 2 columns]\\n        '\n    if column_names is not None and column_name_prefix is not None:\n        raise ValueError(\"'column_names' and 'column_name_prefix' parameter cannot be given at the same time.\")\n    if new_column_name is None and column_name_prefix is not None:\n        new_column_name = column_name_prefix\n    if column_name_prefix is not None:\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n        column_names = [name for name in self.column_names() if name.startswith(column_name_prefix)]\n        if len(column_names) == 0:\n            raise ValueError(\"There is no column starts with prefix '\" + column_name_prefix + \"'\")\n    elif column_names is None:\n        column_names = self.column_names()\n    else:\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable type')\n        column_name_set = set(self.column_names())\n        for column in column_names:\n            if column not in column_name_set:\n                raise ValueError(\"Current SFrame has no column called '\" + str(column) + \"'.\")\n        if len(set(column_names)) != len(column_names):\n            raise ValueError('There is duplicate column names in column_names parameter')\n    if dtype not in (dict, list, array.array):\n        raise ValueError('Resulting dtype has to be one of dict/array.array/list type')\n    if dtype == array.array:\n        if fill_na is not None and type(fill_na) not in (int, float):\n            raise ValueError('fill_na value for array needs to be numeric type')\n        for column in column_names:\n            if self[column].dtype not in (int, float):\n                raise TypeError(\"Column '\" + column + \"' type is not numeric, cannot pack into array type\")\n    if dtype == dict and column_name_prefix is not None and (remove_prefix == True):\n        size_prefix = len(column_name_prefix)\n        first_char = set([c[size_prefix:size_prefix + 1] for c in column_names])\n        if len(first_char) == 1 and first_char.pop() in ['.', '-', '_']:\n            dict_keys = [name[size_prefix + 1:] for name in column_names]\n        else:\n            dict_keys = [name[size_prefix:] for name in column_names]\n    else:\n        dict_keys = column_names\n    rest_columns = [name for name in self.column_names() if name not in column_names]\n    if new_column_name is not None:\n        if type(new_column_name) != str:\n            raise TypeError(\"'new_column_name' has to be a string\")\n        if new_column_name in rest_columns:\n            raise KeyError('Current SFrame already contains a column name ' + new_column_name)\n    else:\n        new_column_name = ''\n    ret_sa = None\n    with cython_context():\n        ret_sa = SArray(_proxy=self.__proxy__.pack_columns(column_names, dict_keys, dtype, fill_na))\n    new_sf = self.select_columns(rest_columns)\n    new_sf.add_column(ret_sa, new_column_name, inplace=True)\n    return new_sf",
            "def pack_columns(self, column_names=None, column_name_prefix=None, dtype=list, fill_na=None, remove_prefix=True, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Pack columns of the current SFrame into one single column. The result\\n        is a new SFrame with the unaffected columns from the original SFrame\\n        plus the newly created column.\\n\\n        The list of columns that are packed is chosen through either the\\n        ``column_names`` or ``column_name_prefix`` parameter. Only one of the parameters\\n        is allowed to be provided. ``columns_names`` explicitly specifies the list of\\n        columns to pack, while ``column_name_prefix`` specifies that all columns that\\n        have the given prefix are to be packed.\\n\\n        The type of the resulting column is decided by the ``dtype`` parameter.\\n        Allowed values for ``dtype`` are dict, array.array and list:\\n\\n         - *dict*: pack to a dictionary SArray where column name becomes\\n           dictionary key and column value becomes dictionary value\\n\\n         - *array.array*: pack all values from the packing columns into an array\\n\\n         - *list*: pack all values from the packing columns into a list.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str], optional\\n            A list of column names to be packed.  If omitted and\\n            `column_name_prefix` is not specified, all columns from current SFrame\\n            are packed.  This parameter is mutually exclusive with the\\n            `column_name_prefix` parameter.\\n\\n        column_name_prefix : str, optional\\n            Pack all columns with the given `column_name_prefix`.\\n            This parameter is mutually exclusive with the `columns_names` parameter.\\n\\n        dtype : dict | array.array | list, optional\\n            The resulting packed column type. If not provided, dtype is list.\\n\\n        fill_na : value, optional\\n            Value to fill into packed column if missing value is encountered.\\n            If packing to dictionary, `fill_na` is only applicable to dictionary\\n            values; missing keys are not replaced.\\n\\n        remove_prefix : bool, optional\\n            If True and `column_name_prefix` is specified, the dictionary key will\\n            be constructed by removing the prefix from the column name.\\n            This option is only applicable when packing to dict type.\\n\\n        new_column_name : str, optional\\n            Packed column name.  If not given and `column_name_prefix` is given,\\n            then the prefix will be used as the new column name, otherwise name\\n            is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame that contains columns that are not packed, plus the newly\\n            packed column.\\n\\n        See Also\\n        --------\\n        unpack\\n\\n        Notes\\n        -----\\n        - If packing to dictionary, missing key is always dropped. Missing\\n          values are dropped if fill_na is not provided, otherwise, missing\\n          value is replaced by \\'fill_na\\'. If packing to list or array, missing\\n          values will be kept. If \\'fill_na\\' is provided, the missing value is\\n          replaced with \\'fill_na\\' value.\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an an SFrame that maintains business category\\n        information:\\n\\n        >>> sf = turicreate.SFrame({\\'business\\': range(1, 5),\\n        ...                       \\'category.retail\\': [1, None, 1, None],\\n        ...                       \\'category.food\\': [1, 1, None, None],\\n        ...                       \\'category.service\\': [None, 1, 1, None],\\n        ...                       \\'category.shop\\': [1, 1, None, 1]})\\n        >>> sf\\n        +----------+-----------------+---------------+------------------+---------------+\\n        | business | category.retail | category.food | category.service | category.shop |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        |    1     |        1        |       1       |       None       |       1       |\\n        |    2     |       None      |       1       |        1         |       1       |\\n        |    3     |        1        |      None     |        1         |      None     |\\n        |    4     |       None      |       1       |       None       |       1       |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        [4 rows x 5 columns]\\n\\n        To pack all category columns into a list:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\')\\n        +----------+-----------------------+\\n        | business |        category       |\\n        +----------+-----------------------+\\n        |    1     |    [1, 1, None, 1]    |\\n        |    2     |    [1, None, 1, 1]    |\\n        |    3     |   [None, 1, 1, None]  |\\n        |    4     | [None, None, None, 1] |\\n        +----------+-----------------------+\\n        [4 rows x 2 columns]\\n\\n        To pack all category columns into a dictionary, with new column name:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n        ...                 new_column_name=\\'new name\\')\\n        +----------+-------------------------------+\\n        | business |            new name           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'food\\': 1, \\'shop\\': 1, \\'re... |\\n        |    2     | {\\'food\\': 1, \\'shop\\': 1, \\'se... |\\n        |    3     |  {\\'retail\\': 1, \\'service\\': 1}  |\\n        |    4     |          {\\'shop\\': 1}          |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To keep column prefix in the resulting dict key:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n                            remove_prefix=False)\\n        +----------+-------------------------------+\\n        | business |            category           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'category.retail\\': 1, \\'ca... |\\n        |    2     | {\\'category.food\\': 1, \\'cate... |\\n        |    3     | {\\'category.retail\\': 1, \\'ca... |\\n        |    4     |      {\\'category.shop\\': 1}     |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To explicitly pack a set of columns:\\n\\n        >>> sf.pack_columns(column_names = [\\'business\\', \\'category.retail\\',\\n                                       \\'category.food\\', \\'category.service\\',\\n                                       \\'category.shop\\'])\\n        +-----------------------+\\n        |           X1          |\\n        +-----------------------+\\n        |   [1, 1, 1, None, 1]  |\\n        |   [2, None, 1, 1, 1]  |\\n        | [3, 1, None, 1, None] |\\n        | [4, None, 1, None, 1] |\\n        +-----------------------+\\n        [4 rows x 1 columns]\\n\\n        To pack all columns with name starting with \\'category\\' into an array\\n        type, and with missing value replaced with 0:\\n\\n        >>> import array\\n        >>> sf.pack_columns(column_name_prefix=\"category\", dtype=array.array,\\n        ...                 fill_na=0)\\n        +----------+----------------------+\\n        | business |       category       |\\n        +----------+----------------------+\\n        |    1     | [1.0, 1.0, 0.0, 1.0] |\\n        |    2     | [1.0, 0.0, 1.0, 1.0] |\\n        |    3     | [0.0, 1.0, 1.0, 0.0] |\\n        |    4     | [0.0, 0.0, 0.0, 1.0] |\\n        +----------+----------------------+\\n        [4 rows x 2 columns]\\n        '\n    if column_names is not None and column_name_prefix is not None:\n        raise ValueError(\"'column_names' and 'column_name_prefix' parameter cannot be given at the same time.\")\n    if new_column_name is None and column_name_prefix is not None:\n        new_column_name = column_name_prefix\n    if column_name_prefix is not None:\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n        column_names = [name for name in self.column_names() if name.startswith(column_name_prefix)]\n        if len(column_names) == 0:\n            raise ValueError(\"There is no column starts with prefix '\" + column_name_prefix + \"'\")\n    elif column_names is None:\n        column_names = self.column_names()\n    else:\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable type')\n        column_name_set = set(self.column_names())\n        for column in column_names:\n            if column not in column_name_set:\n                raise ValueError(\"Current SFrame has no column called '\" + str(column) + \"'.\")\n        if len(set(column_names)) != len(column_names):\n            raise ValueError('There is duplicate column names in column_names parameter')\n    if dtype not in (dict, list, array.array):\n        raise ValueError('Resulting dtype has to be one of dict/array.array/list type')\n    if dtype == array.array:\n        if fill_na is not None and type(fill_na) not in (int, float):\n            raise ValueError('fill_na value for array needs to be numeric type')\n        for column in column_names:\n            if self[column].dtype not in (int, float):\n                raise TypeError(\"Column '\" + column + \"' type is not numeric, cannot pack into array type\")\n    if dtype == dict and column_name_prefix is not None and (remove_prefix == True):\n        size_prefix = len(column_name_prefix)\n        first_char = set([c[size_prefix:size_prefix + 1] for c in column_names])\n        if len(first_char) == 1 and first_char.pop() in ['.', '-', '_']:\n            dict_keys = [name[size_prefix + 1:] for name in column_names]\n        else:\n            dict_keys = [name[size_prefix:] for name in column_names]\n    else:\n        dict_keys = column_names\n    rest_columns = [name for name in self.column_names() if name not in column_names]\n    if new_column_name is not None:\n        if type(new_column_name) != str:\n            raise TypeError(\"'new_column_name' has to be a string\")\n        if new_column_name in rest_columns:\n            raise KeyError('Current SFrame already contains a column name ' + new_column_name)\n    else:\n        new_column_name = ''\n    ret_sa = None\n    with cython_context():\n        ret_sa = SArray(_proxy=self.__proxy__.pack_columns(column_names, dict_keys, dtype, fill_na))\n    new_sf = self.select_columns(rest_columns)\n    new_sf.add_column(ret_sa, new_column_name, inplace=True)\n    return new_sf",
            "def pack_columns(self, column_names=None, column_name_prefix=None, dtype=list, fill_na=None, remove_prefix=True, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Pack columns of the current SFrame into one single column. The result\\n        is a new SFrame with the unaffected columns from the original SFrame\\n        plus the newly created column.\\n\\n        The list of columns that are packed is chosen through either the\\n        ``column_names`` or ``column_name_prefix`` parameter. Only one of the parameters\\n        is allowed to be provided. ``columns_names`` explicitly specifies the list of\\n        columns to pack, while ``column_name_prefix`` specifies that all columns that\\n        have the given prefix are to be packed.\\n\\n        The type of the resulting column is decided by the ``dtype`` parameter.\\n        Allowed values for ``dtype`` are dict, array.array and list:\\n\\n         - *dict*: pack to a dictionary SArray where column name becomes\\n           dictionary key and column value becomes dictionary value\\n\\n         - *array.array*: pack all values from the packing columns into an array\\n\\n         - *list*: pack all values from the packing columns into a list.\\n\\n        Parameters\\n        ----------\\n        column_names : list[str], optional\\n            A list of column names to be packed.  If omitted and\\n            `column_name_prefix` is not specified, all columns from current SFrame\\n            are packed.  This parameter is mutually exclusive with the\\n            `column_name_prefix` parameter.\\n\\n        column_name_prefix : str, optional\\n            Pack all columns with the given `column_name_prefix`.\\n            This parameter is mutually exclusive with the `columns_names` parameter.\\n\\n        dtype : dict | array.array | list, optional\\n            The resulting packed column type. If not provided, dtype is list.\\n\\n        fill_na : value, optional\\n            Value to fill into packed column if missing value is encountered.\\n            If packing to dictionary, `fill_na` is only applicable to dictionary\\n            values; missing keys are not replaced.\\n\\n        remove_prefix : bool, optional\\n            If True and `column_name_prefix` is specified, the dictionary key will\\n            be constructed by removing the prefix from the column name.\\n            This option is only applicable when packing to dict type.\\n\\n        new_column_name : str, optional\\n            Packed column name.  If not given and `column_name_prefix` is given,\\n            then the prefix will be used as the new column name, otherwise name\\n            is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame that contains columns that are not packed, plus the newly\\n            packed column.\\n\\n        See Also\\n        --------\\n        unpack\\n\\n        Notes\\n        -----\\n        - If packing to dictionary, missing key is always dropped. Missing\\n          values are dropped if fill_na is not provided, otherwise, missing\\n          value is replaced by \\'fill_na\\'. If packing to list or array, missing\\n          values will be kept. If \\'fill_na\\' is provided, the missing value is\\n          replaced with \\'fill_na\\' value.\\n\\n        Examples\\n        --------\\n        Suppose \\'sf\\' is an an SFrame that maintains business category\\n        information:\\n\\n        >>> sf = turicreate.SFrame({\\'business\\': range(1, 5),\\n        ...                       \\'category.retail\\': [1, None, 1, None],\\n        ...                       \\'category.food\\': [1, 1, None, None],\\n        ...                       \\'category.service\\': [None, 1, 1, None],\\n        ...                       \\'category.shop\\': [1, 1, None, 1]})\\n        >>> sf\\n        +----------+-----------------+---------------+------------------+---------------+\\n        | business | category.retail | category.food | category.service | category.shop |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        |    1     |        1        |       1       |       None       |       1       |\\n        |    2     |       None      |       1       |        1         |       1       |\\n        |    3     |        1        |      None     |        1         |      None     |\\n        |    4     |       None      |       1       |       None       |       1       |\\n        +----------+-----------------+---------------+------------------+---------------+\\n        [4 rows x 5 columns]\\n\\n        To pack all category columns into a list:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\')\\n        +----------+-----------------------+\\n        | business |        category       |\\n        +----------+-----------------------+\\n        |    1     |    [1, 1, None, 1]    |\\n        |    2     |    [1, None, 1, 1]    |\\n        |    3     |   [None, 1, 1, None]  |\\n        |    4     | [None, None, None, 1] |\\n        +----------+-----------------------+\\n        [4 rows x 2 columns]\\n\\n        To pack all category columns into a dictionary, with new column name:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n        ...                 new_column_name=\\'new name\\')\\n        +----------+-------------------------------+\\n        | business |            new name           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'food\\': 1, \\'shop\\': 1, \\'re... |\\n        |    2     | {\\'food\\': 1, \\'shop\\': 1, \\'se... |\\n        |    3     |  {\\'retail\\': 1, \\'service\\': 1}  |\\n        |    4     |          {\\'shop\\': 1}          |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To keep column prefix in the resulting dict key:\\n\\n        >>> sf.pack_columns(column_name_prefix=\\'category\\', dtype=dict,\\n                            remove_prefix=False)\\n        +----------+-------------------------------+\\n        | business |            category           |\\n        +----------+-------------------------------+\\n        |    1     | {\\'category.retail\\': 1, \\'ca... |\\n        |    2     | {\\'category.food\\': 1, \\'cate... |\\n        |    3     | {\\'category.retail\\': 1, \\'ca... |\\n        |    4     |      {\\'category.shop\\': 1}     |\\n        +----------+-------------------------------+\\n        [4 rows x 2 columns]\\n\\n        To explicitly pack a set of columns:\\n\\n        >>> sf.pack_columns(column_names = [\\'business\\', \\'category.retail\\',\\n                                       \\'category.food\\', \\'category.service\\',\\n                                       \\'category.shop\\'])\\n        +-----------------------+\\n        |           X1          |\\n        +-----------------------+\\n        |   [1, 1, 1, None, 1]  |\\n        |   [2, None, 1, 1, 1]  |\\n        | [3, 1, None, 1, None] |\\n        | [4, None, 1, None, 1] |\\n        +-----------------------+\\n        [4 rows x 1 columns]\\n\\n        To pack all columns with name starting with \\'category\\' into an array\\n        type, and with missing value replaced with 0:\\n\\n        >>> import array\\n        >>> sf.pack_columns(column_name_prefix=\"category\", dtype=array.array,\\n        ...                 fill_na=0)\\n        +----------+----------------------+\\n        | business |       category       |\\n        +----------+----------------------+\\n        |    1     | [1.0, 1.0, 0.0, 1.0] |\\n        |    2     | [1.0, 0.0, 1.0, 1.0] |\\n        |    3     | [0.0, 1.0, 1.0, 0.0] |\\n        |    4     | [0.0, 0.0, 0.0, 1.0] |\\n        +----------+----------------------+\\n        [4 rows x 2 columns]\\n        '\n    if column_names is not None and column_name_prefix is not None:\n        raise ValueError(\"'column_names' and 'column_name_prefix' parameter cannot be given at the same time.\")\n    if new_column_name is None and column_name_prefix is not None:\n        new_column_name = column_name_prefix\n    if column_name_prefix is not None:\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n        column_names = [name for name in self.column_names() if name.startswith(column_name_prefix)]\n        if len(column_names) == 0:\n            raise ValueError(\"There is no column starts with prefix '\" + column_name_prefix + \"'\")\n    elif column_names is None:\n        column_names = self.column_names()\n    else:\n        if not _is_non_string_iterable(column_names):\n            raise TypeError('column_names must be an iterable type')\n        column_name_set = set(self.column_names())\n        for column in column_names:\n            if column not in column_name_set:\n                raise ValueError(\"Current SFrame has no column called '\" + str(column) + \"'.\")\n        if len(set(column_names)) != len(column_names):\n            raise ValueError('There is duplicate column names in column_names parameter')\n    if dtype not in (dict, list, array.array):\n        raise ValueError('Resulting dtype has to be one of dict/array.array/list type')\n    if dtype == array.array:\n        if fill_na is not None and type(fill_na) not in (int, float):\n            raise ValueError('fill_na value for array needs to be numeric type')\n        for column in column_names:\n            if self[column].dtype not in (int, float):\n                raise TypeError(\"Column '\" + column + \"' type is not numeric, cannot pack into array type\")\n    if dtype == dict and column_name_prefix is not None and (remove_prefix == True):\n        size_prefix = len(column_name_prefix)\n        first_char = set([c[size_prefix:size_prefix + 1] for c in column_names])\n        if len(first_char) == 1 and first_char.pop() in ['.', '-', '_']:\n            dict_keys = [name[size_prefix + 1:] for name in column_names]\n        else:\n            dict_keys = [name[size_prefix:] for name in column_names]\n    else:\n        dict_keys = column_names\n    rest_columns = [name for name in self.column_names() if name not in column_names]\n    if new_column_name is not None:\n        if type(new_column_name) != str:\n            raise TypeError(\"'new_column_name' has to be a string\")\n        if new_column_name in rest_columns:\n            raise KeyError('Current SFrame already contains a column name ' + new_column_name)\n    else:\n        new_column_name = ''\n    ret_sa = None\n    with cython_context():\n        ret_sa = SArray(_proxy=self.__proxy__.pack_columns(column_names, dict_keys, dtype, fill_na))\n    new_sf = self.select_columns(rest_columns)\n    new_sf.add_column(ret_sa, new_column_name, inplace=True)\n    return new_sf"
        ]
    },
    {
        "func_name": "split_datetime",
        "original": "def split_datetime(self, column_name, column_name_prefix=None, limit=None, timezone=False):\n    \"\"\"\n        Splits a datetime column of SFrame to multiple columns, with each value in a\n        separate column. Returns a new SFrame with the expanded column replaced with\n        a list of new columns. The expanded column must be of datetime type.\n\n        For more details regarding name generation and\n        other, refer to :py:func:`turicreate.SArray.split_datetime()`\n\n        Parameters\n        ----------\n        column_name : str\n            Name of the unpacked column.\n\n        column_name_prefix : str, optional\n            If provided, expanded column names would start with the given prefix.\n            If not provided, the default value is the name of the expanded column.\n\n        limit: list[str], optional\n            Limits the set of datetime elements to expand.\n            Possible values are 'year','month','day','hour','minute','second',\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\n            If not provided, only ['year','month','day','hour','minute','second']\n            are expanded.\n\n        timezone : bool, optional\n            A boolean parameter that determines whether to show the timezone\n            column or not. Defaults to False.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains rest of columns from original SFrame with\n            the given column replaced with a collection of expanded columns.\n\n        Examples\n        ---------\n\n        >>> sf\n        Columns:\n            id   int\n            submission  datetime\n        Rows: 2\n        Data:\n            +----+-------------------------------------------------+\n            | id |               submission                        |\n            +----+-------------------------------------------------+\n            | 1  | datetime(2011, 1, 21, 7, 17, 21, tzinfo=GMT(+1))|\n            | 2  | datetime(2011, 1, 21, 5, 43, 21, tzinfo=GMT(+1))|\n            +----+-------------------------------------------------+\n\n        >>> sf.split_datetime('submission',limit=['hour','minute'])\n        Columns:\n            id  int\n            submission.hour int\n            submission.minute int\n        Rows: 2\n        Data:\n        +----+-----------------+-------------------+\n        | id | submission.hour | submission.minute |\n        +----+-----------------+-------------------+\n        | 1  |        7        |        17         |\n        | 2  |        5        |        43         |\n        +----+-----------------+-------------------+\n        \"\"\"\n    if column_name not in self.column_names():\n        raise KeyError(\"column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].split_datetime(column_name_prefix, limit, timezone)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
        "mutated": [
            "def split_datetime(self, column_name, column_name_prefix=None, limit=None, timezone=False):\n    if False:\n        i = 10\n    \"\\n        Splits a datetime column of SFrame to multiple columns, with each value in a\\n        separate column. Returns a new SFrame with the expanded column replaced with\\n        a list of new columns. The expanded column must be of datetime type.\\n\\n        For more details regarding name generation and\\n        other, refer to :py:func:`turicreate.SArray.split_datetime()`\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            Name of the unpacked column.\\n\\n        column_name_prefix : str, optional\\n            If provided, expanded column names would start with the given prefix.\\n            If not provided, the default value is the name of the expanded column.\\n\\n        limit: list[str], optional\\n            Limits the set of datetime elements to expand.\\n            Possible values are 'year','month','day','hour','minute','second',\\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\\n            If not provided, only ['year','month','day','hour','minute','second']\\n            are expanded.\\n\\n        timezone : bool, optional\\n            A boolean parameter that determines whether to show the timezone\\n            column or not. Defaults to False.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of expanded columns.\\n\\n        Examples\\n        ---------\\n\\n        >>> sf\\n        Columns:\\n            id   int\\n            submission  datetime\\n        Rows: 2\\n        Data:\\n            +----+-------------------------------------------------+\\n            | id |               submission                        |\\n            +----+-------------------------------------------------+\\n            | 1  | datetime(2011, 1, 21, 7, 17, 21, tzinfo=GMT(+1))|\\n            | 2  | datetime(2011, 1, 21, 5, 43, 21, tzinfo=GMT(+1))|\\n            +----+-------------------------------------------------+\\n\\n        >>> sf.split_datetime('submission',limit=['hour','minute'])\\n        Columns:\\n            id  int\\n            submission.hour int\\n            submission.minute int\\n        Rows: 2\\n        Data:\\n        +----+-----------------+-------------------+\\n        | id | submission.hour | submission.minute |\\n        +----+-----------------+-------------------+\\n        | 1  |        7        |        17         |\\n        | 2  |        5        |        43         |\\n        +----+-----------------+-------------------+\\n        \"\n    if column_name not in self.column_names():\n        raise KeyError(\"column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].split_datetime(column_name_prefix, limit, timezone)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def split_datetime(self, column_name, column_name_prefix=None, limit=None, timezone=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Splits a datetime column of SFrame to multiple columns, with each value in a\\n        separate column. Returns a new SFrame with the expanded column replaced with\\n        a list of new columns. The expanded column must be of datetime type.\\n\\n        For more details regarding name generation and\\n        other, refer to :py:func:`turicreate.SArray.split_datetime()`\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            Name of the unpacked column.\\n\\n        column_name_prefix : str, optional\\n            If provided, expanded column names would start with the given prefix.\\n            If not provided, the default value is the name of the expanded column.\\n\\n        limit: list[str], optional\\n            Limits the set of datetime elements to expand.\\n            Possible values are 'year','month','day','hour','minute','second',\\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\\n            If not provided, only ['year','month','day','hour','minute','second']\\n            are expanded.\\n\\n        timezone : bool, optional\\n            A boolean parameter that determines whether to show the timezone\\n            column or not. Defaults to False.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of expanded columns.\\n\\n        Examples\\n        ---------\\n\\n        >>> sf\\n        Columns:\\n            id   int\\n            submission  datetime\\n        Rows: 2\\n        Data:\\n            +----+-------------------------------------------------+\\n            | id |               submission                        |\\n            +----+-------------------------------------------------+\\n            | 1  | datetime(2011, 1, 21, 7, 17, 21, tzinfo=GMT(+1))|\\n            | 2  | datetime(2011, 1, 21, 5, 43, 21, tzinfo=GMT(+1))|\\n            +----+-------------------------------------------------+\\n\\n        >>> sf.split_datetime('submission',limit=['hour','minute'])\\n        Columns:\\n            id  int\\n            submission.hour int\\n            submission.minute int\\n        Rows: 2\\n        Data:\\n        +----+-----------------+-------------------+\\n        | id | submission.hour | submission.minute |\\n        +----+-----------------+-------------------+\\n        | 1  |        7        |        17         |\\n        | 2  |        5        |        43         |\\n        +----+-----------------+-------------------+\\n        \"\n    if column_name not in self.column_names():\n        raise KeyError(\"column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].split_datetime(column_name_prefix, limit, timezone)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def split_datetime(self, column_name, column_name_prefix=None, limit=None, timezone=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Splits a datetime column of SFrame to multiple columns, with each value in a\\n        separate column. Returns a new SFrame with the expanded column replaced with\\n        a list of new columns. The expanded column must be of datetime type.\\n\\n        For more details regarding name generation and\\n        other, refer to :py:func:`turicreate.SArray.split_datetime()`\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            Name of the unpacked column.\\n\\n        column_name_prefix : str, optional\\n            If provided, expanded column names would start with the given prefix.\\n            If not provided, the default value is the name of the expanded column.\\n\\n        limit: list[str], optional\\n            Limits the set of datetime elements to expand.\\n            Possible values are 'year','month','day','hour','minute','second',\\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\\n            If not provided, only ['year','month','day','hour','minute','second']\\n            are expanded.\\n\\n        timezone : bool, optional\\n            A boolean parameter that determines whether to show the timezone\\n            column or not. Defaults to False.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of expanded columns.\\n\\n        Examples\\n        ---------\\n\\n        >>> sf\\n        Columns:\\n            id   int\\n            submission  datetime\\n        Rows: 2\\n        Data:\\n            +----+-------------------------------------------------+\\n            | id |               submission                        |\\n            +----+-------------------------------------------------+\\n            | 1  | datetime(2011, 1, 21, 7, 17, 21, tzinfo=GMT(+1))|\\n            | 2  | datetime(2011, 1, 21, 5, 43, 21, tzinfo=GMT(+1))|\\n            +----+-------------------------------------------------+\\n\\n        >>> sf.split_datetime('submission',limit=['hour','minute'])\\n        Columns:\\n            id  int\\n            submission.hour int\\n            submission.minute int\\n        Rows: 2\\n        Data:\\n        +----+-----------------+-------------------+\\n        | id | submission.hour | submission.minute |\\n        +----+-----------------+-------------------+\\n        | 1  |        7        |        17         |\\n        | 2  |        5        |        43         |\\n        +----+-----------------+-------------------+\\n        \"\n    if column_name not in self.column_names():\n        raise KeyError(\"column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].split_datetime(column_name_prefix, limit, timezone)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def split_datetime(self, column_name, column_name_prefix=None, limit=None, timezone=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Splits a datetime column of SFrame to multiple columns, with each value in a\\n        separate column. Returns a new SFrame with the expanded column replaced with\\n        a list of new columns. The expanded column must be of datetime type.\\n\\n        For more details regarding name generation and\\n        other, refer to :py:func:`turicreate.SArray.split_datetime()`\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            Name of the unpacked column.\\n\\n        column_name_prefix : str, optional\\n            If provided, expanded column names would start with the given prefix.\\n            If not provided, the default value is the name of the expanded column.\\n\\n        limit: list[str], optional\\n            Limits the set of datetime elements to expand.\\n            Possible values are 'year','month','day','hour','minute','second',\\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\\n            If not provided, only ['year','month','day','hour','minute','second']\\n            are expanded.\\n\\n        timezone : bool, optional\\n            A boolean parameter that determines whether to show the timezone\\n            column or not. Defaults to False.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of expanded columns.\\n\\n        Examples\\n        ---------\\n\\n        >>> sf\\n        Columns:\\n            id   int\\n            submission  datetime\\n        Rows: 2\\n        Data:\\n            +----+-------------------------------------------------+\\n            | id |               submission                        |\\n            +----+-------------------------------------------------+\\n            | 1  | datetime(2011, 1, 21, 7, 17, 21, tzinfo=GMT(+1))|\\n            | 2  | datetime(2011, 1, 21, 5, 43, 21, tzinfo=GMT(+1))|\\n            +----+-------------------------------------------------+\\n\\n        >>> sf.split_datetime('submission',limit=['hour','minute'])\\n        Columns:\\n            id  int\\n            submission.hour int\\n            submission.minute int\\n        Rows: 2\\n        Data:\\n        +----+-----------------+-------------------+\\n        | id | submission.hour | submission.minute |\\n        +----+-----------------+-------------------+\\n        | 1  |        7        |        17         |\\n        | 2  |        5        |        43         |\\n        +----+-----------------+-------------------+\\n        \"\n    if column_name not in self.column_names():\n        raise KeyError(\"column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].split_datetime(column_name_prefix, limit, timezone)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def split_datetime(self, column_name, column_name_prefix=None, limit=None, timezone=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Splits a datetime column of SFrame to multiple columns, with each value in a\\n        separate column. Returns a new SFrame with the expanded column replaced with\\n        a list of new columns. The expanded column must be of datetime type.\\n\\n        For more details regarding name generation and\\n        other, refer to :py:func:`turicreate.SArray.split_datetime()`\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            Name of the unpacked column.\\n\\n        column_name_prefix : str, optional\\n            If provided, expanded column names would start with the given prefix.\\n            If not provided, the default value is the name of the expanded column.\\n\\n        limit: list[str], optional\\n            Limits the set of datetime elements to expand.\\n            Possible values are 'year','month','day','hour','minute','second',\\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\\n            If not provided, only ['year','month','day','hour','minute','second']\\n            are expanded.\\n\\n        timezone : bool, optional\\n            A boolean parameter that determines whether to show the timezone\\n            column or not. Defaults to False.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of expanded columns.\\n\\n        Examples\\n        ---------\\n\\n        >>> sf\\n        Columns:\\n            id   int\\n            submission  datetime\\n        Rows: 2\\n        Data:\\n            +----+-------------------------------------------------+\\n            | id |               submission                        |\\n            +----+-------------------------------------------------+\\n            | 1  | datetime(2011, 1, 21, 7, 17, 21, tzinfo=GMT(+1))|\\n            | 2  | datetime(2011, 1, 21, 5, 43, 21, tzinfo=GMT(+1))|\\n            +----+-------------------------------------------------+\\n\\n        >>> sf.split_datetime('submission',limit=['hour','minute'])\\n        Columns:\\n            id  int\\n            submission.hour int\\n            submission.minute int\\n        Rows: 2\\n        Data:\\n        +----+-----------------+-------------------+\\n        | id | submission.hour | submission.minute |\\n        +----+-----------------+-------------------+\\n        | 1  |        7        |        17         |\\n        | 2  |        5        |        43         |\\n        +----+-----------------+-------------------+\\n        \"\n    if column_name not in self.column_names():\n        raise KeyError(\"column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].split_datetime(column_name_prefix, limit, timezone)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf"
        ]
    },
    {
        "func_name": "unpack",
        "original": "def unpack(self, column_name=None, column_name_prefix=None, column_types=None, na_value=None, limit=None):\n    \"\"\"\n        Expand one column of this SFrame to multiple columns with each value in\n        a separate column. Returns a new SFrame with the unpacked column\n        replaced with a list of new columns.  The column must be of\n        list/array/dict type.\n\n        For more details regarding name generation, missing value handling and\n        other, refer to the SArray version of\n        :py:func:`~turicreate.SArray.unpack()`.\n\n        Parameters\n        ----------\n        column_name : str, optional\n            Name of the unpacked column, if provided. If not provided\n            and only one column is present then the column is unpacked.\n            In case of multiple columns, name must be provided to know\n            which column to be unpacked.\n\n\n        column_name_prefix : str, optional\n            If provided, unpacked column names would start with the given\n            prefix. If not provided, default value is the name of the unpacked\n            column.\n\n        column_types : [type], optional\n            Column types for the unpacked columns.\n            If not provided, column types are automatically inferred from first\n            100 rows. For array type, default column types are float.  If\n            provided, column_types also restricts how many columns to unpack.\n\n        na_value : flexible_type, optional\n            If provided, convert all values that are equal to \"na_value\" to\n            missing value (None).\n\n        limit : list[str] | list[int], optional\n            Control unpacking only a subset of list/array/dict value. For\n            dictionary SArray, `limit` is a list of dictionary keys to restrict.\n            For list/array SArray, `limit` is a list of integers that are\n            indexes into the list/array value.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains rest of columns from original SFrame with\n            the given column replaced with a collection of unpacked columns.\n\n        See Also\n        --------\n        pack_columns, SArray.unpack\n\n        Examples\n        ---------\n        >>> sf = turicreate.SFrame({'id': [1,2,3],\n        ...                      'wc': [{'a': 1}, {'b': 2}, {'a': 1, 'b': 2}]})\n        +----+------------------+\n        | id |        wc        |\n        +----+------------------+\n        | 1  |     {'a': 1}     |\n        | 2  |     {'b': 2}     |\n        | 3  | {'a': 1, 'b': 2} |\n        +----+------------------+\n        [3 rows x 2 columns]\n\n        >>> sf.unpack('wc')\n        +----+------+------+\n        | id | wc.a | wc.b |\n        +----+------+------+\n        | 1  |  1   | None |\n        | 2  | None |  2   |\n        | 3  |  1   |  2   |\n        +----+------+------+\n        [3 rows x 3 columns]\n\n        To not have prefix in the generated column name:\n\n        >>> sf.unpack('wc', column_name_prefix=\"\")\n        +----+------+------+\n        | id |  a   |  b   |\n        +----+------+------+\n        | 1  |  1   | None |\n        | 2  | None |  2   |\n        | 3  |  1   |  2   |\n        +----+------+------+\n        [3 rows x 3 columns]\n\n        To limit subset of keys to unpack:\n\n        >>> sf.unpack('wc', limit=['b'])\n        +----+------+\n        | id | wc.b |\n        +----+------+\n        | 1  | None |\n        | 2  |  2   |\n        | 3  |  2   |\n        +----+------+\n        [3 rows x 3 columns]\n\n        To unpack an array column:\n\n        >>> import array\n        >>> sf = turicreate.SFrame({'id': [1,2,3],\n        ...                       'friends': [array.array('d', [1.0, 2.0, 3.0]),\n        ...                                   array.array('d', [2.0, 3.0, 4.0]),\n        ...                                   array.array('d', [3.0, 4.0, 5.0])]})\n        >>> sf\n        +-----------------+----+\n        |     friends     | id |\n        +-----------------+----+\n        | [1.0, 2.0, 3.0] | 1  |\n        | [2.0, 3.0, 4.0] | 2  |\n        | [3.0, 4.0, 5.0] | 3  |\n        +-----------------+----+\n        [3 rows x 2 columns]\n\n        >>> sf.unpack('friends')\n        +----+-----------+-----------+-----------+\n        | id | friends.0 | friends.1 | friends.2 |\n        +----+-----------+-----------+-----------+\n        | 1  |    1.0    |    2.0    |    3.0    |\n        | 2  |    2.0    |    3.0    |    4.0    |\n        | 3  |    3.0    |    4.0    |    5.0    |\n        +----+-----------+-----------+-----------+\n        [3 rows x 4 columns]\n\n        >>> sf = turicreate.SFrame([{'a':1,'b':2,'c':3},{'a':4,'b':5,'c':6}])\n        >>> sf.unpack()\n        +---+---+---+\n        | a | b | c |\n        +---+---+---+\n        | 1 | 2 | 3 |\n        | 4 | 5 | 6 |\n        +---+---+---+\n        [2 rows x 3 columns]\n\n\n\n        \"\"\"\n    if column_name is None:\n        if self.num_columns() == 0:\n            raise RuntimeError('No column exists in the current SFrame')\n        for t in range(self.num_columns()):\n            column_type = self.column_types()[t]\n            if column_type == dict or column_type == list or column_type == array.array:\n                if column_name is None:\n                    column_name = self.column_names()[t]\n                else:\n                    raise RuntimeError('Column name needed to unpack')\n        if column_name is None:\n            raise RuntimeError('No columns can be unpacked')\n        elif column_name_prefix is None:\n            column_name_prefix = ''\n    elif column_name not in self.column_names():\n        raise KeyError(\"Column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].unpack(column_name_prefix, column_types, na_value, limit)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
        "mutated": [
            "def unpack(self, column_name=None, column_name_prefix=None, column_types=None, na_value=None, limit=None):\n    if False:\n        i = 10\n    '\\n        Expand one column of this SFrame to multiple columns with each value in\\n        a separate column. Returns a new SFrame with the unpacked column\\n        replaced with a list of new columns.  The column must be of\\n        list/array/dict type.\\n\\n        For more details regarding name generation, missing value handling and\\n        other, refer to the SArray version of\\n        :py:func:`~turicreate.SArray.unpack()`.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            Name of the unpacked column, if provided. If not provided\\n            and only one column is present then the column is unpacked.\\n            In case of multiple columns, name must be provided to know\\n            which column to be unpacked.\\n\\n\\n        column_name_prefix : str, optional\\n            If provided, unpacked column names would start with the given\\n            prefix. If not provided, default value is the name of the unpacked\\n            column.\\n\\n        column_types : [type], optional\\n            Column types for the unpacked columns.\\n            If not provided, column types are automatically inferred from first\\n            100 rows. For array type, default column types are float.  If\\n            provided, column_types also restricts how many columns to unpack.\\n\\n        na_value : flexible_type, optional\\n            If provided, convert all values that are equal to \"na_value\" to\\n            missing value (None).\\n\\n        limit : list[str] | list[int], optional\\n            Control unpacking only a subset of list/array/dict value. For\\n            dictionary SArray, `limit` is a list of dictionary keys to restrict.\\n            For list/array SArray, `limit` is a list of integers that are\\n            indexes into the list/array value.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of unpacked columns.\\n\\n        See Also\\n        --------\\n        pack_columns, SArray.unpack\\n\\n        Examples\\n        ---------\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                      \\'wc\\': [{\\'a\\': 1}, {\\'b\\': 2}, {\\'a\\': 1, \\'b\\': 2}]})\\n        +----+------------------+\\n        | id |        wc        |\\n        +----+------------------+\\n        | 1  |     {\\'a\\': 1}     |\\n        | 2  |     {\\'b\\': 2}     |\\n        | 3  | {\\'a\\': 1, \\'b\\': 2} |\\n        +----+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'wc\\')\\n        +----+------+------+\\n        | id | wc.a | wc.b |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To not have prefix in the generated column name:\\n\\n        >>> sf.unpack(\\'wc\\', column_name_prefix=\"\")\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To limit subset of keys to unpack:\\n\\n        >>> sf.unpack(\\'wc\\', limit=[\\'b\\'])\\n        +----+------+\\n        | id | wc.b |\\n        +----+------+\\n        | 1  | None |\\n        | 2  |  2   |\\n        | 3  |  2   |\\n        +----+------+\\n        [3 rows x 3 columns]\\n\\n        To unpack an array column:\\n\\n        >>> import array\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                       \\'friends\\': [array.array(\\'d\\', [1.0, 2.0, 3.0]),\\n        ...                                   array.array(\\'d\\', [2.0, 3.0, 4.0]),\\n        ...                                   array.array(\\'d\\', [3.0, 4.0, 5.0])]})\\n        >>> sf\\n        +-----------------+----+\\n        |     friends     | id |\\n        +-----------------+----+\\n        | [1.0, 2.0, 3.0] | 1  |\\n        | [2.0, 3.0, 4.0] | 2  |\\n        | [3.0, 4.0, 5.0] | 3  |\\n        +-----------------+----+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'friends\\')\\n        +----+-----------+-----------+-----------+\\n        | id | friends.0 | friends.1 | friends.2 |\\n        +----+-----------+-----------+-----------+\\n        | 1  |    1.0    |    2.0    |    3.0    |\\n        | 2  |    2.0    |    3.0    |    4.0    |\\n        | 3  |    3.0    |    4.0    |    5.0    |\\n        +----+-----------+-----------+-----------+\\n        [3 rows x 4 columns]\\n\\n        >>> sf = turicreate.SFrame([{\\'a\\':1,\\'b\\':2,\\'c\\':3},{\\'a\\':4,\\'b\\':5,\\'c\\':6}])\\n        >>> sf.unpack()\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | 2 | 3 |\\n        | 4 | 5 | 6 |\\n        +---+---+---+\\n        [2 rows x 3 columns]\\n\\n\\n\\n        '\n    if column_name is None:\n        if self.num_columns() == 0:\n            raise RuntimeError('No column exists in the current SFrame')\n        for t in range(self.num_columns()):\n            column_type = self.column_types()[t]\n            if column_type == dict or column_type == list or column_type == array.array:\n                if column_name is None:\n                    column_name = self.column_names()[t]\n                else:\n                    raise RuntimeError('Column name needed to unpack')\n        if column_name is None:\n            raise RuntimeError('No columns can be unpacked')\n        elif column_name_prefix is None:\n            column_name_prefix = ''\n    elif column_name not in self.column_names():\n        raise KeyError(\"Column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].unpack(column_name_prefix, column_types, na_value, limit)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def unpack(self, column_name=None, column_name_prefix=None, column_types=None, na_value=None, limit=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Expand one column of this SFrame to multiple columns with each value in\\n        a separate column. Returns a new SFrame with the unpacked column\\n        replaced with a list of new columns.  The column must be of\\n        list/array/dict type.\\n\\n        For more details regarding name generation, missing value handling and\\n        other, refer to the SArray version of\\n        :py:func:`~turicreate.SArray.unpack()`.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            Name of the unpacked column, if provided. If not provided\\n            and only one column is present then the column is unpacked.\\n            In case of multiple columns, name must be provided to know\\n            which column to be unpacked.\\n\\n\\n        column_name_prefix : str, optional\\n            If provided, unpacked column names would start with the given\\n            prefix. If not provided, default value is the name of the unpacked\\n            column.\\n\\n        column_types : [type], optional\\n            Column types for the unpacked columns.\\n            If not provided, column types are automatically inferred from first\\n            100 rows. For array type, default column types are float.  If\\n            provided, column_types also restricts how many columns to unpack.\\n\\n        na_value : flexible_type, optional\\n            If provided, convert all values that are equal to \"na_value\" to\\n            missing value (None).\\n\\n        limit : list[str] | list[int], optional\\n            Control unpacking only a subset of list/array/dict value. For\\n            dictionary SArray, `limit` is a list of dictionary keys to restrict.\\n            For list/array SArray, `limit` is a list of integers that are\\n            indexes into the list/array value.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of unpacked columns.\\n\\n        See Also\\n        --------\\n        pack_columns, SArray.unpack\\n\\n        Examples\\n        ---------\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                      \\'wc\\': [{\\'a\\': 1}, {\\'b\\': 2}, {\\'a\\': 1, \\'b\\': 2}]})\\n        +----+------------------+\\n        | id |        wc        |\\n        +----+------------------+\\n        | 1  |     {\\'a\\': 1}     |\\n        | 2  |     {\\'b\\': 2}     |\\n        | 3  | {\\'a\\': 1, \\'b\\': 2} |\\n        +----+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'wc\\')\\n        +----+------+------+\\n        | id | wc.a | wc.b |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To not have prefix in the generated column name:\\n\\n        >>> sf.unpack(\\'wc\\', column_name_prefix=\"\")\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To limit subset of keys to unpack:\\n\\n        >>> sf.unpack(\\'wc\\', limit=[\\'b\\'])\\n        +----+------+\\n        | id | wc.b |\\n        +----+------+\\n        | 1  | None |\\n        | 2  |  2   |\\n        | 3  |  2   |\\n        +----+------+\\n        [3 rows x 3 columns]\\n\\n        To unpack an array column:\\n\\n        >>> import array\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                       \\'friends\\': [array.array(\\'d\\', [1.0, 2.0, 3.0]),\\n        ...                                   array.array(\\'d\\', [2.0, 3.0, 4.0]),\\n        ...                                   array.array(\\'d\\', [3.0, 4.0, 5.0])]})\\n        >>> sf\\n        +-----------------+----+\\n        |     friends     | id |\\n        +-----------------+----+\\n        | [1.0, 2.0, 3.0] | 1  |\\n        | [2.0, 3.0, 4.0] | 2  |\\n        | [3.0, 4.0, 5.0] | 3  |\\n        +-----------------+----+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'friends\\')\\n        +----+-----------+-----------+-----------+\\n        | id | friends.0 | friends.1 | friends.2 |\\n        +----+-----------+-----------+-----------+\\n        | 1  |    1.0    |    2.0    |    3.0    |\\n        | 2  |    2.0    |    3.0    |    4.0    |\\n        | 3  |    3.0    |    4.0    |    5.0    |\\n        +----+-----------+-----------+-----------+\\n        [3 rows x 4 columns]\\n\\n        >>> sf = turicreate.SFrame([{\\'a\\':1,\\'b\\':2,\\'c\\':3},{\\'a\\':4,\\'b\\':5,\\'c\\':6}])\\n        >>> sf.unpack()\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | 2 | 3 |\\n        | 4 | 5 | 6 |\\n        +---+---+---+\\n        [2 rows x 3 columns]\\n\\n\\n\\n        '\n    if column_name is None:\n        if self.num_columns() == 0:\n            raise RuntimeError('No column exists in the current SFrame')\n        for t in range(self.num_columns()):\n            column_type = self.column_types()[t]\n            if column_type == dict or column_type == list or column_type == array.array:\n                if column_name is None:\n                    column_name = self.column_names()[t]\n                else:\n                    raise RuntimeError('Column name needed to unpack')\n        if column_name is None:\n            raise RuntimeError('No columns can be unpacked')\n        elif column_name_prefix is None:\n            column_name_prefix = ''\n    elif column_name not in self.column_names():\n        raise KeyError(\"Column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].unpack(column_name_prefix, column_types, na_value, limit)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def unpack(self, column_name=None, column_name_prefix=None, column_types=None, na_value=None, limit=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Expand one column of this SFrame to multiple columns with each value in\\n        a separate column. Returns a new SFrame with the unpacked column\\n        replaced with a list of new columns.  The column must be of\\n        list/array/dict type.\\n\\n        For more details regarding name generation, missing value handling and\\n        other, refer to the SArray version of\\n        :py:func:`~turicreate.SArray.unpack()`.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            Name of the unpacked column, if provided. If not provided\\n            and only one column is present then the column is unpacked.\\n            In case of multiple columns, name must be provided to know\\n            which column to be unpacked.\\n\\n\\n        column_name_prefix : str, optional\\n            If provided, unpacked column names would start with the given\\n            prefix. If not provided, default value is the name of the unpacked\\n            column.\\n\\n        column_types : [type], optional\\n            Column types for the unpacked columns.\\n            If not provided, column types are automatically inferred from first\\n            100 rows. For array type, default column types are float.  If\\n            provided, column_types also restricts how many columns to unpack.\\n\\n        na_value : flexible_type, optional\\n            If provided, convert all values that are equal to \"na_value\" to\\n            missing value (None).\\n\\n        limit : list[str] | list[int], optional\\n            Control unpacking only a subset of list/array/dict value. For\\n            dictionary SArray, `limit` is a list of dictionary keys to restrict.\\n            For list/array SArray, `limit` is a list of integers that are\\n            indexes into the list/array value.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of unpacked columns.\\n\\n        See Also\\n        --------\\n        pack_columns, SArray.unpack\\n\\n        Examples\\n        ---------\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                      \\'wc\\': [{\\'a\\': 1}, {\\'b\\': 2}, {\\'a\\': 1, \\'b\\': 2}]})\\n        +----+------------------+\\n        | id |        wc        |\\n        +----+------------------+\\n        | 1  |     {\\'a\\': 1}     |\\n        | 2  |     {\\'b\\': 2}     |\\n        | 3  | {\\'a\\': 1, \\'b\\': 2} |\\n        +----+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'wc\\')\\n        +----+------+------+\\n        | id | wc.a | wc.b |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To not have prefix in the generated column name:\\n\\n        >>> sf.unpack(\\'wc\\', column_name_prefix=\"\")\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To limit subset of keys to unpack:\\n\\n        >>> sf.unpack(\\'wc\\', limit=[\\'b\\'])\\n        +----+------+\\n        | id | wc.b |\\n        +----+------+\\n        | 1  | None |\\n        | 2  |  2   |\\n        | 3  |  2   |\\n        +----+------+\\n        [3 rows x 3 columns]\\n\\n        To unpack an array column:\\n\\n        >>> import array\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                       \\'friends\\': [array.array(\\'d\\', [1.0, 2.0, 3.0]),\\n        ...                                   array.array(\\'d\\', [2.0, 3.0, 4.0]),\\n        ...                                   array.array(\\'d\\', [3.0, 4.0, 5.0])]})\\n        >>> sf\\n        +-----------------+----+\\n        |     friends     | id |\\n        +-----------------+----+\\n        | [1.0, 2.0, 3.0] | 1  |\\n        | [2.0, 3.0, 4.0] | 2  |\\n        | [3.0, 4.0, 5.0] | 3  |\\n        +-----------------+----+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'friends\\')\\n        +----+-----------+-----------+-----------+\\n        | id | friends.0 | friends.1 | friends.2 |\\n        +----+-----------+-----------+-----------+\\n        | 1  |    1.0    |    2.0    |    3.0    |\\n        | 2  |    2.0    |    3.0    |    4.0    |\\n        | 3  |    3.0    |    4.0    |    5.0    |\\n        +----+-----------+-----------+-----------+\\n        [3 rows x 4 columns]\\n\\n        >>> sf = turicreate.SFrame([{\\'a\\':1,\\'b\\':2,\\'c\\':3},{\\'a\\':4,\\'b\\':5,\\'c\\':6}])\\n        >>> sf.unpack()\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | 2 | 3 |\\n        | 4 | 5 | 6 |\\n        +---+---+---+\\n        [2 rows x 3 columns]\\n\\n\\n\\n        '\n    if column_name is None:\n        if self.num_columns() == 0:\n            raise RuntimeError('No column exists in the current SFrame')\n        for t in range(self.num_columns()):\n            column_type = self.column_types()[t]\n            if column_type == dict or column_type == list or column_type == array.array:\n                if column_name is None:\n                    column_name = self.column_names()[t]\n                else:\n                    raise RuntimeError('Column name needed to unpack')\n        if column_name is None:\n            raise RuntimeError('No columns can be unpacked')\n        elif column_name_prefix is None:\n            column_name_prefix = ''\n    elif column_name not in self.column_names():\n        raise KeyError(\"Column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].unpack(column_name_prefix, column_types, na_value, limit)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def unpack(self, column_name=None, column_name_prefix=None, column_types=None, na_value=None, limit=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Expand one column of this SFrame to multiple columns with each value in\\n        a separate column. Returns a new SFrame with the unpacked column\\n        replaced with a list of new columns.  The column must be of\\n        list/array/dict type.\\n\\n        For more details regarding name generation, missing value handling and\\n        other, refer to the SArray version of\\n        :py:func:`~turicreate.SArray.unpack()`.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            Name of the unpacked column, if provided. If not provided\\n            and only one column is present then the column is unpacked.\\n            In case of multiple columns, name must be provided to know\\n            which column to be unpacked.\\n\\n\\n        column_name_prefix : str, optional\\n            If provided, unpacked column names would start with the given\\n            prefix. If not provided, default value is the name of the unpacked\\n            column.\\n\\n        column_types : [type], optional\\n            Column types for the unpacked columns.\\n            If not provided, column types are automatically inferred from first\\n            100 rows. For array type, default column types are float.  If\\n            provided, column_types also restricts how many columns to unpack.\\n\\n        na_value : flexible_type, optional\\n            If provided, convert all values that are equal to \"na_value\" to\\n            missing value (None).\\n\\n        limit : list[str] | list[int], optional\\n            Control unpacking only a subset of list/array/dict value. For\\n            dictionary SArray, `limit` is a list of dictionary keys to restrict.\\n            For list/array SArray, `limit` is a list of integers that are\\n            indexes into the list/array value.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of unpacked columns.\\n\\n        See Also\\n        --------\\n        pack_columns, SArray.unpack\\n\\n        Examples\\n        ---------\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                      \\'wc\\': [{\\'a\\': 1}, {\\'b\\': 2}, {\\'a\\': 1, \\'b\\': 2}]})\\n        +----+------------------+\\n        | id |        wc        |\\n        +----+------------------+\\n        | 1  |     {\\'a\\': 1}     |\\n        | 2  |     {\\'b\\': 2}     |\\n        | 3  | {\\'a\\': 1, \\'b\\': 2} |\\n        +----+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'wc\\')\\n        +----+------+------+\\n        | id | wc.a | wc.b |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To not have prefix in the generated column name:\\n\\n        >>> sf.unpack(\\'wc\\', column_name_prefix=\"\")\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To limit subset of keys to unpack:\\n\\n        >>> sf.unpack(\\'wc\\', limit=[\\'b\\'])\\n        +----+------+\\n        | id | wc.b |\\n        +----+------+\\n        | 1  | None |\\n        | 2  |  2   |\\n        | 3  |  2   |\\n        +----+------+\\n        [3 rows x 3 columns]\\n\\n        To unpack an array column:\\n\\n        >>> import array\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                       \\'friends\\': [array.array(\\'d\\', [1.0, 2.0, 3.0]),\\n        ...                                   array.array(\\'d\\', [2.0, 3.0, 4.0]),\\n        ...                                   array.array(\\'d\\', [3.0, 4.0, 5.0])]})\\n        >>> sf\\n        +-----------------+----+\\n        |     friends     | id |\\n        +-----------------+----+\\n        | [1.0, 2.0, 3.0] | 1  |\\n        | [2.0, 3.0, 4.0] | 2  |\\n        | [3.0, 4.0, 5.0] | 3  |\\n        +-----------------+----+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'friends\\')\\n        +----+-----------+-----------+-----------+\\n        | id | friends.0 | friends.1 | friends.2 |\\n        +----+-----------+-----------+-----------+\\n        | 1  |    1.0    |    2.0    |    3.0    |\\n        | 2  |    2.0    |    3.0    |    4.0    |\\n        | 3  |    3.0    |    4.0    |    5.0    |\\n        +----+-----------+-----------+-----------+\\n        [3 rows x 4 columns]\\n\\n        >>> sf = turicreate.SFrame([{\\'a\\':1,\\'b\\':2,\\'c\\':3},{\\'a\\':4,\\'b\\':5,\\'c\\':6}])\\n        >>> sf.unpack()\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | 2 | 3 |\\n        | 4 | 5 | 6 |\\n        +---+---+---+\\n        [2 rows x 3 columns]\\n\\n\\n\\n        '\n    if column_name is None:\n        if self.num_columns() == 0:\n            raise RuntimeError('No column exists in the current SFrame')\n        for t in range(self.num_columns()):\n            column_type = self.column_types()[t]\n            if column_type == dict or column_type == list or column_type == array.array:\n                if column_name is None:\n                    column_name = self.column_names()[t]\n                else:\n                    raise RuntimeError('Column name needed to unpack')\n        if column_name is None:\n            raise RuntimeError('No columns can be unpacked')\n        elif column_name_prefix is None:\n            column_name_prefix = ''\n    elif column_name not in self.column_names():\n        raise KeyError(\"Column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].unpack(column_name_prefix, column_types, na_value, limit)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf",
            "def unpack(self, column_name=None, column_name_prefix=None, column_types=None, na_value=None, limit=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Expand one column of this SFrame to multiple columns with each value in\\n        a separate column. Returns a new SFrame with the unpacked column\\n        replaced with a list of new columns.  The column must be of\\n        list/array/dict type.\\n\\n        For more details regarding name generation, missing value handling and\\n        other, refer to the SArray version of\\n        :py:func:`~turicreate.SArray.unpack()`.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            Name of the unpacked column, if provided. If not provided\\n            and only one column is present then the column is unpacked.\\n            In case of multiple columns, name must be provided to know\\n            which column to be unpacked.\\n\\n\\n        column_name_prefix : str, optional\\n            If provided, unpacked column names would start with the given\\n            prefix. If not provided, default value is the name of the unpacked\\n            column.\\n\\n        column_types : [type], optional\\n            Column types for the unpacked columns.\\n            If not provided, column types are automatically inferred from first\\n            100 rows. For array type, default column types are float.  If\\n            provided, column_types also restricts how many columns to unpack.\\n\\n        na_value : flexible_type, optional\\n            If provided, convert all values that are equal to \"na_value\" to\\n            missing value (None).\\n\\n        limit : list[str] | list[int], optional\\n            Control unpacking only a subset of list/array/dict value. For\\n            dictionary SArray, `limit` is a list of dictionary keys to restrict.\\n            For list/array SArray, `limit` is a list of integers that are\\n            indexes into the list/array value.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains rest of columns from original SFrame with\\n            the given column replaced with a collection of unpacked columns.\\n\\n        See Also\\n        --------\\n        pack_columns, SArray.unpack\\n\\n        Examples\\n        ---------\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                      \\'wc\\': [{\\'a\\': 1}, {\\'b\\': 2}, {\\'a\\': 1, \\'b\\': 2}]})\\n        +----+------------------+\\n        | id |        wc        |\\n        +----+------------------+\\n        | 1  |     {\\'a\\': 1}     |\\n        | 2  |     {\\'b\\': 2}     |\\n        | 3  | {\\'a\\': 1, \\'b\\': 2} |\\n        +----+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'wc\\')\\n        +----+------+------+\\n        | id | wc.a | wc.b |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To not have prefix in the generated column name:\\n\\n        >>> sf.unpack(\\'wc\\', column_name_prefix=\"\")\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 1  |  1   | None |\\n        | 2  | None |  2   |\\n        | 3  |  1   |  2   |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n\\n        To limit subset of keys to unpack:\\n\\n        >>> sf.unpack(\\'wc\\', limit=[\\'b\\'])\\n        +----+------+\\n        | id | wc.b |\\n        +----+------+\\n        | 1  | None |\\n        | 2  |  2   |\\n        | 3  |  2   |\\n        +----+------+\\n        [3 rows x 3 columns]\\n\\n        To unpack an array column:\\n\\n        >>> import array\\n        >>> sf = turicreate.SFrame({\\'id\\': [1,2,3],\\n        ...                       \\'friends\\': [array.array(\\'d\\', [1.0, 2.0, 3.0]),\\n        ...                                   array.array(\\'d\\', [2.0, 3.0, 4.0]),\\n        ...                                   array.array(\\'d\\', [3.0, 4.0, 5.0])]})\\n        >>> sf\\n        +-----------------+----+\\n        |     friends     | id |\\n        +-----------------+----+\\n        | [1.0, 2.0, 3.0] | 1  |\\n        | [2.0, 3.0, 4.0] | 2  |\\n        | [3.0, 4.0, 5.0] | 3  |\\n        +-----------------+----+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.unpack(\\'friends\\')\\n        +----+-----------+-----------+-----------+\\n        | id | friends.0 | friends.1 | friends.2 |\\n        +----+-----------+-----------+-----------+\\n        | 1  |    1.0    |    2.0    |    3.0    |\\n        | 2  |    2.0    |    3.0    |    4.0    |\\n        | 3  |    3.0    |    4.0    |    5.0    |\\n        +----+-----------+-----------+-----------+\\n        [3 rows x 4 columns]\\n\\n        >>> sf = turicreate.SFrame([{\\'a\\':1,\\'b\\':2,\\'c\\':3},{\\'a\\':4,\\'b\\':5,\\'c\\':6}])\\n        >>> sf.unpack()\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | 2 | 3 |\\n        | 4 | 5 | 6 |\\n        +---+---+---+\\n        [2 rows x 3 columns]\\n\\n\\n\\n        '\n    if column_name is None:\n        if self.num_columns() == 0:\n            raise RuntimeError('No column exists in the current SFrame')\n        for t in range(self.num_columns()):\n            column_type = self.column_types()[t]\n            if column_type == dict or column_type == list or column_type == array.array:\n                if column_name is None:\n                    column_name = self.column_names()[t]\n                else:\n                    raise RuntimeError('Column name needed to unpack')\n        if column_name is None:\n            raise RuntimeError('No columns can be unpacked')\n        elif column_name_prefix is None:\n            column_name_prefix = ''\n    elif column_name not in self.column_names():\n        raise KeyError(\"Column '\" + column_name + \"' does not exist in current SFrame\")\n    if column_name_prefix is None:\n        column_name_prefix = column_name\n    new_sf = self[column_name].unpack(column_name_prefix, column_types, na_value, limit)\n    rest_columns = [name for name in self.column_names() if name != column_name]\n    new_names = new_sf.column_names()\n    while set(new_names).intersection(rest_columns):\n        new_names = [name + '.1' for name in new_names]\n    new_sf.rename(dict(list(zip(new_sf.column_names(), new_names))), inplace=True)\n    ret_sf = self.select_columns(rest_columns)\n    ret_sf.add_columns(new_sf, inplace=True)\n    return ret_sf"
        ]
    },
    {
        "func_name": "stack",
        "original": "def stack(self, column_name, new_column_name=None, drop_na=False, new_column_type=None):\n    \"\"\"\n        Convert a \"wide\" column of an SFrame to one or two \"tall\" columns by\n        stacking all values.\n\n        The stack works only for columns of dict, list, or array type.  If the\n        column is dict type, two new columns are created as a result of\n        stacking: one column holds the key and another column holds the value.\n        The rest of the columns are repeated for each key/value pair.\n\n        If the column is array or list type, one new column is created as a\n        result of stacking. With each row holds one element of the array or list\n        value, and the rest columns from the same original row repeated.\n\n        The returned SFrame includes the newly created column(s) and all\n        columns other than the one that is stacked.\n\n        Parameters\n        --------------\n        column_name : str\n            The column to stack. This column must be of dict/list/array type\n\n        new_column_name : str | list of str, optional\n            The new column name(s). If original column is list/array type,\n            new_column_name must a string. If original column is dict type,\n            new_column_name must be a list of two strings. If not given, column\n            names are generated automatically.\n\n        drop_na : boolean, optional\n            If True, missing values and empty list/array/dict are all dropped\n            from the resulting column(s). If False, missing values are\n            maintained in stacked column(s).\n\n        new_column_type : type | list of types, optional\n            The new column types. If original column is a list/array type\n            new_column_type must be a single type, or a list of one type. If\n            original column is of dict type, new_column_type must be a list of\n            two types. If not provided, the types are automatically inferred\n            from the first 100 values of the SFrame.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains newly stacked column(s) plus columns in\n            original SFrame other than the stacked column.\n\n        See Also\n        --------\n        unstack\n\n        Examples\n        ---------\n        Suppose 'sf' is an SFrame that contains a column of dict type:\n\n        >>> sf = turicreate.SFrame({'topic':[1,2,3,4],\n        ...                       'words': [{'a':3, 'cat':2},\n        ...                                 {'a':1, 'the':2},\n        ...                                 {'the':1, 'dog':3},\n        ...                                 {}]\n        ...                      })\n        +-------+----------------------+\n        | topic |        words         |\n        +-------+----------------------+\n        |   1   |  {'a': 3, 'cat': 2}  |\n        |   2   |  {'a': 1, 'the': 2}  |\n        |   3   | {'the': 1, 'dog': 3} |\n        |   4   |          {}          |\n        +-------+----------------------+\n        [4 rows x 2 columns]\n\n        Stack would stack all keys in one column and all values in another\n        column:\n\n        >>> sf.stack('words', new_column_name=['word', 'count'])\n        +-------+------+-------+\n        | topic | word | count |\n        +-------+------+-------+\n        |   1   |  a   |   3   |\n        |   1   | cat  |   2   |\n        |   2   |  a   |   1   |\n        |   2   | the  |   2   |\n        |   3   | the  |   1   |\n        |   3   | dog  |   3   |\n        |   4   | None |  None |\n        +-------+------+-------+\n        [7 rows x 3 columns]\n\n        Observe that since topic 4 had no words, an empty row is inserted.\n        To drop that row, set drop_na=True in the parameters to stack.\n\n        Suppose 'sf' is an SFrame that contains a user and his/her friends,\n        where 'friends' columns is an array type. Stack on 'friends' column\n        would create a user/friend list for each user/friend pair:\n\n        >>> sf = turicreate.SFrame({'topic':[1,2,3],\n        ...                       'friends':[[2,3,4], [5,6],\n        ...                                  [4,5,10,None]]\n        ...                      })\n        >>> sf\n        +-------+------------------+\n        | topic |     friends      |\n        +-------+------------------+\n        |  1    |     [2, 3, 4]    |\n        |  2    |      [5, 6]      |\n        |  3    | [4, 5, 10, None] |\n        +----- -+------------------+\n        [3 rows x 2 columns]\n\n        >>> sf.stack('friends', new_column_name='friend')\n        +-------+--------+\n        | topic | friend |\n        +-------+--------+\n        |   1   |   2    |\n        |   1   |   3    |\n        |   1   |   4    |\n        |   2   |   5    |\n        |   2   |   6    |\n        |   3   |   4    |\n        |   3   |   5    |\n        |   3   |   10   |\n        |   3   |  None  |\n        +-------+--------+\n        [9 rows x 2 columns]\n\n        \"\"\"\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise ValueError(\"Cannot find column '\" + str(column_name) + \"' in the SFrame.\")\n    stack_column_type = self[column_name].dtype\n    if stack_column_type not in [dict, array.array, list]:\n        raise TypeError('Stack is only supported for column of dict/list/array type.')\n    if new_column_type is not None:\n        if type(new_column_type) is type:\n            new_column_type = [new_column_type]\n        if stack_column_type in [list, array.array] and len(new_column_type) != 1:\n            raise ValueError('Expecting a single column type to unpack list or array columns')\n        if stack_column_type in [dict] and len(new_column_type) != 2:\n            raise ValueError('Expecting two column types to unpack a dict column')\n    if new_column_name is not None:\n        if stack_column_type == dict:\n            if type(new_column_name) is not list:\n                raise TypeError('new_column_name has to be a list to stack dict type')\n            elif len(new_column_name) != 2:\n                raise TypeError('new_column_name must have length of two')\n        else:\n            if type(new_column_name) != str:\n                raise TypeError('new_column_name has to be a str')\n            new_column_name = [new_column_name]\n        for name in new_column_name:\n            if name in self.column_names() and name != column_name:\n                raise ValueError(\"Column with name '\" + name + \"' already exists, pick a new column name\")\n    elif stack_column_type == dict:\n        new_column_name = ['', '']\n    else:\n        new_column_name = ['']\n    head_row = SArray(self[column_name].head(100)).dropna()\n    if len(head_row) == 0:\n        raise ValueError('Cannot infer column type because there is not enough rows to infer value')\n    if new_column_type is None:\n        if stack_column_type == dict:\n            keys = []\n            values = []\n            for row in head_row:\n                for val in row:\n                    keys.append(val)\n                    if val is not None:\n                        values.append(row[val])\n            new_column_type = [infer_type_of_list(keys), infer_type_of_list(values)]\n        else:\n            values = [v for v in itertools.chain.from_iterable(head_row)]\n            new_column_type = [infer_type_of_list(values)]\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.stack(column_name, new_column_name, new_column_type, drop_na))",
        "mutated": [
            "def stack(self, column_name, new_column_name=None, drop_na=False, new_column_type=None):\n    if False:\n        i = 10\n    '\\n        Convert a \"wide\" column of an SFrame to one or two \"tall\" columns by\\n        stacking all values.\\n\\n        The stack works only for columns of dict, list, or array type.  If the\\n        column is dict type, two new columns are created as a result of\\n        stacking: one column holds the key and another column holds the value.\\n        The rest of the columns are repeated for each key/value pair.\\n\\n        If the column is array or list type, one new column is created as a\\n        result of stacking. With each row holds one element of the array or list\\n        value, and the rest columns from the same original row repeated.\\n\\n        The returned SFrame includes the newly created column(s) and all\\n        columns other than the one that is stacked.\\n\\n        Parameters\\n        --------------\\n        column_name : str\\n            The column to stack. This column must be of dict/list/array type\\n\\n        new_column_name : str | list of str, optional\\n            The new column name(s). If original column is list/array type,\\n            new_column_name must a string. If original column is dict type,\\n            new_column_name must be a list of two strings. If not given, column\\n            names are generated automatically.\\n\\n        drop_na : boolean, optional\\n            If True, missing values and empty list/array/dict are all dropped\\n            from the resulting column(s). If False, missing values are\\n            maintained in stacked column(s).\\n\\n        new_column_type : type | list of types, optional\\n            The new column types. If original column is a list/array type\\n            new_column_type must be a single type, or a list of one type. If\\n            original column is of dict type, new_column_type must be a list of\\n            two types. If not provided, the types are automatically inferred\\n            from the first 100 values of the SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains newly stacked column(s) plus columns in\\n            original SFrame other than the stacked column.\\n\\n        See Also\\n        --------\\n        unstack\\n\\n        Examples\\n        ---------\\n        Suppose \\'sf\\' is an SFrame that contains a column of dict type:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3,4],\\n        ...                       \\'words\\': [{\\'a\\':3, \\'cat\\':2},\\n        ...                                 {\\'a\\':1, \\'the\\':2},\\n        ...                                 {\\'the\\':1, \\'dog\\':3},\\n        ...                                 {}]\\n        ...                      })\\n        +-------+----------------------+\\n        | topic |        words         |\\n        +-------+----------------------+\\n        |   1   |  {\\'a\\': 3, \\'cat\\': 2}  |\\n        |   2   |  {\\'a\\': 1, \\'the\\': 2}  |\\n        |   3   | {\\'the\\': 1, \\'dog\\': 3} |\\n        |   4   |          {}          |\\n        +-------+----------------------+\\n        [4 rows x 2 columns]\\n\\n        Stack would stack all keys in one column and all values in another\\n        column:\\n\\n        >>> sf.stack(\\'words\\', new_column_name=[\\'word\\', \\'count\\'])\\n        +-------+------+-------+\\n        | topic | word | count |\\n        +-------+------+-------+\\n        |   1   |  a   |   3   |\\n        |   1   | cat  |   2   |\\n        |   2   |  a   |   1   |\\n        |   2   | the  |   2   |\\n        |   3   | the  |   1   |\\n        |   3   | dog  |   3   |\\n        |   4   | None |  None |\\n        +-------+------+-------+\\n        [7 rows x 3 columns]\\n\\n        Observe that since topic 4 had no words, an empty row is inserted.\\n        To drop that row, set drop_na=True in the parameters to stack.\\n\\n        Suppose \\'sf\\' is an SFrame that contains a user and his/her friends,\\n        where \\'friends\\' columns is an array type. Stack on \\'friends\\' column\\n        would create a user/friend list for each user/friend pair:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3],\\n        ...                       \\'friends\\':[[2,3,4], [5,6],\\n        ...                                  [4,5,10,None]]\\n        ...                      })\\n        >>> sf\\n        +-------+------------------+\\n        | topic |     friends      |\\n        +-------+------------------+\\n        |  1    |     [2, 3, 4]    |\\n        |  2    |      [5, 6]      |\\n        |  3    | [4, 5, 10, None] |\\n        +----- -+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.stack(\\'friends\\', new_column_name=\\'friend\\')\\n        +-------+--------+\\n        | topic | friend |\\n        +-------+--------+\\n        |   1   |   2    |\\n        |   1   |   3    |\\n        |   1   |   4    |\\n        |   2   |   5    |\\n        |   2   |   6    |\\n        |   3   |   4    |\\n        |   3   |   5    |\\n        |   3   |   10   |\\n        |   3   |  None  |\\n        +-------+--------+\\n        [9 rows x 2 columns]\\n\\n        '\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise ValueError(\"Cannot find column '\" + str(column_name) + \"' in the SFrame.\")\n    stack_column_type = self[column_name].dtype\n    if stack_column_type not in [dict, array.array, list]:\n        raise TypeError('Stack is only supported for column of dict/list/array type.')\n    if new_column_type is not None:\n        if type(new_column_type) is type:\n            new_column_type = [new_column_type]\n        if stack_column_type in [list, array.array] and len(new_column_type) != 1:\n            raise ValueError('Expecting a single column type to unpack list or array columns')\n        if stack_column_type in [dict] and len(new_column_type) != 2:\n            raise ValueError('Expecting two column types to unpack a dict column')\n    if new_column_name is not None:\n        if stack_column_type == dict:\n            if type(new_column_name) is not list:\n                raise TypeError('new_column_name has to be a list to stack dict type')\n            elif len(new_column_name) != 2:\n                raise TypeError('new_column_name must have length of two')\n        else:\n            if type(new_column_name) != str:\n                raise TypeError('new_column_name has to be a str')\n            new_column_name = [new_column_name]\n        for name in new_column_name:\n            if name in self.column_names() and name != column_name:\n                raise ValueError(\"Column with name '\" + name + \"' already exists, pick a new column name\")\n    elif stack_column_type == dict:\n        new_column_name = ['', '']\n    else:\n        new_column_name = ['']\n    head_row = SArray(self[column_name].head(100)).dropna()\n    if len(head_row) == 0:\n        raise ValueError('Cannot infer column type because there is not enough rows to infer value')\n    if new_column_type is None:\n        if stack_column_type == dict:\n            keys = []\n            values = []\n            for row in head_row:\n                for val in row:\n                    keys.append(val)\n                    if val is not None:\n                        values.append(row[val])\n            new_column_type = [infer_type_of_list(keys), infer_type_of_list(values)]\n        else:\n            values = [v for v in itertools.chain.from_iterable(head_row)]\n            new_column_type = [infer_type_of_list(values)]\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.stack(column_name, new_column_name, new_column_type, drop_na))",
            "def stack(self, column_name, new_column_name=None, drop_na=False, new_column_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Convert a \"wide\" column of an SFrame to one or two \"tall\" columns by\\n        stacking all values.\\n\\n        The stack works only for columns of dict, list, or array type.  If the\\n        column is dict type, two new columns are created as a result of\\n        stacking: one column holds the key and another column holds the value.\\n        The rest of the columns are repeated for each key/value pair.\\n\\n        If the column is array or list type, one new column is created as a\\n        result of stacking. With each row holds one element of the array or list\\n        value, and the rest columns from the same original row repeated.\\n\\n        The returned SFrame includes the newly created column(s) and all\\n        columns other than the one that is stacked.\\n\\n        Parameters\\n        --------------\\n        column_name : str\\n            The column to stack. This column must be of dict/list/array type\\n\\n        new_column_name : str | list of str, optional\\n            The new column name(s). If original column is list/array type,\\n            new_column_name must a string. If original column is dict type,\\n            new_column_name must be a list of two strings. If not given, column\\n            names are generated automatically.\\n\\n        drop_na : boolean, optional\\n            If True, missing values and empty list/array/dict are all dropped\\n            from the resulting column(s). If False, missing values are\\n            maintained in stacked column(s).\\n\\n        new_column_type : type | list of types, optional\\n            The new column types. If original column is a list/array type\\n            new_column_type must be a single type, or a list of one type. If\\n            original column is of dict type, new_column_type must be a list of\\n            two types. If not provided, the types are automatically inferred\\n            from the first 100 values of the SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains newly stacked column(s) plus columns in\\n            original SFrame other than the stacked column.\\n\\n        See Also\\n        --------\\n        unstack\\n\\n        Examples\\n        ---------\\n        Suppose \\'sf\\' is an SFrame that contains a column of dict type:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3,4],\\n        ...                       \\'words\\': [{\\'a\\':3, \\'cat\\':2},\\n        ...                                 {\\'a\\':1, \\'the\\':2},\\n        ...                                 {\\'the\\':1, \\'dog\\':3},\\n        ...                                 {}]\\n        ...                      })\\n        +-------+----------------------+\\n        | topic |        words         |\\n        +-------+----------------------+\\n        |   1   |  {\\'a\\': 3, \\'cat\\': 2}  |\\n        |   2   |  {\\'a\\': 1, \\'the\\': 2}  |\\n        |   3   | {\\'the\\': 1, \\'dog\\': 3} |\\n        |   4   |          {}          |\\n        +-------+----------------------+\\n        [4 rows x 2 columns]\\n\\n        Stack would stack all keys in one column and all values in another\\n        column:\\n\\n        >>> sf.stack(\\'words\\', new_column_name=[\\'word\\', \\'count\\'])\\n        +-------+------+-------+\\n        | topic | word | count |\\n        +-------+------+-------+\\n        |   1   |  a   |   3   |\\n        |   1   | cat  |   2   |\\n        |   2   |  a   |   1   |\\n        |   2   | the  |   2   |\\n        |   3   | the  |   1   |\\n        |   3   | dog  |   3   |\\n        |   4   | None |  None |\\n        +-------+------+-------+\\n        [7 rows x 3 columns]\\n\\n        Observe that since topic 4 had no words, an empty row is inserted.\\n        To drop that row, set drop_na=True in the parameters to stack.\\n\\n        Suppose \\'sf\\' is an SFrame that contains a user and his/her friends,\\n        where \\'friends\\' columns is an array type. Stack on \\'friends\\' column\\n        would create a user/friend list for each user/friend pair:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3],\\n        ...                       \\'friends\\':[[2,3,4], [5,6],\\n        ...                                  [4,5,10,None]]\\n        ...                      })\\n        >>> sf\\n        +-------+------------------+\\n        | topic |     friends      |\\n        +-------+------------------+\\n        |  1    |     [2, 3, 4]    |\\n        |  2    |      [5, 6]      |\\n        |  3    | [4, 5, 10, None] |\\n        +----- -+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.stack(\\'friends\\', new_column_name=\\'friend\\')\\n        +-------+--------+\\n        | topic | friend |\\n        +-------+--------+\\n        |   1   |   2    |\\n        |   1   |   3    |\\n        |   1   |   4    |\\n        |   2   |   5    |\\n        |   2   |   6    |\\n        |   3   |   4    |\\n        |   3   |   5    |\\n        |   3   |   10   |\\n        |   3   |  None  |\\n        +-------+--------+\\n        [9 rows x 2 columns]\\n\\n        '\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise ValueError(\"Cannot find column '\" + str(column_name) + \"' in the SFrame.\")\n    stack_column_type = self[column_name].dtype\n    if stack_column_type not in [dict, array.array, list]:\n        raise TypeError('Stack is only supported for column of dict/list/array type.')\n    if new_column_type is not None:\n        if type(new_column_type) is type:\n            new_column_type = [new_column_type]\n        if stack_column_type in [list, array.array] and len(new_column_type) != 1:\n            raise ValueError('Expecting a single column type to unpack list or array columns')\n        if stack_column_type in [dict] and len(new_column_type) != 2:\n            raise ValueError('Expecting two column types to unpack a dict column')\n    if new_column_name is not None:\n        if stack_column_type == dict:\n            if type(new_column_name) is not list:\n                raise TypeError('new_column_name has to be a list to stack dict type')\n            elif len(new_column_name) != 2:\n                raise TypeError('new_column_name must have length of two')\n        else:\n            if type(new_column_name) != str:\n                raise TypeError('new_column_name has to be a str')\n            new_column_name = [new_column_name]\n        for name in new_column_name:\n            if name in self.column_names() and name != column_name:\n                raise ValueError(\"Column with name '\" + name + \"' already exists, pick a new column name\")\n    elif stack_column_type == dict:\n        new_column_name = ['', '']\n    else:\n        new_column_name = ['']\n    head_row = SArray(self[column_name].head(100)).dropna()\n    if len(head_row) == 0:\n        raise ValueError('Cannot infer column type because there is not enough rows to infer value')\n    if new_column_type is None:\n        if stack_column_type == dict:\n            keys = []\n            values = []\n            for row in head_row:\n                for val in row:\n                    keys.append(val)\n                    if val is not None:\n                        values.append(row[val])\n            new_column_type = [infer_type_of_list(keys), infer_type_of_list(values)]\n        else:\n            values = [v for v in itertools.chain.from_iterable(head_row)]\n            new_column_type = [infer_type_of_list(values)]\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.stack(column_name, new_column_name, new_column_type, drop_na))",
            "def stack(self, column_name, new_column_name=None, drop_na=False, new_column_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Convert a \"wide\" column of an SFrame to one or two \"tall\" columns by\\n        stacking all values.\\n\\n        The stack works only for columns of dict, list, or array type.  If the\\n        column is dict type, two new columns are created as a result of\\n        stacking: one column holds the key and another column holds the value.\\n        The rest of the columns are repeated for each key/value pair.\\n\\n        If the column is array or list type, one new column is created as a\\n        result of stacking. With each row holds one element of the array or list\\n        value, and the rest columns from the same original row repeated.\\n\\n        The returned SFrame includes the newly created column(s) and all\\n        columns other than the one that is stacked.\\n\\n        Parameters\\n        --------------\\n        column_name : str\\n            The column to stack. This column must be of dict/list/array type\\n\\n        new_column_name : str | list of str, optional\\n            The new column name(s). If original column is list/array type,\\n            new_column_name must a string. If original column is dict type,\\n            new_column_name must be a list of two strings. If not given, column\\n            names are generated automatically.\\n\\n        drop_na : boolean, optional\\n            If True, missing values and empty list/array/dict are all dropped\\n            from the resulting column(s). If False, missing values are\\n            maintained in stacked column(s).\\n\\n        new_column_type : type | list of types, optional\\n            The new column types. If original column is a list/array type\\n            new_column_type must be a single type, or a list of one type. If\\n            original column is of dict type, new_column_type must be a list of\\n            two types. If not provided, the types are automatically inferred\\n            from the first 100 values of the SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains newly stacked column(s) plus columns in\\n            original SFrame other than the stacked column.\\n\\n        See Also\\n        --------\\n        unstack\\n\\n        Examples\\n        ---------\\n        Suppose \\'sf\\' is an SFrame that contains a column of dict type:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3,4],\\n        ...                       \\'words\\': [{\\'a\\':3, \\'cat\\':2},\\n        ...                                 {\\'a\\':1, \\'the\\':2},\\n        ...                                 {\\'the\\':1, \\'dog\\':3},\\n        ...                                 {}]\\n        ...                      })\\n        +-------+----------------------+\\n        | topic |        words         |\\n        +-------+----------------------+\\n        |   1   |  {\\'a\\': 3, \\'cat\\': 2}  |\\n        |   2   |  {\\'a\\': 1, \\'the\\': 2}  |\\n        |   3   | {\\'the\\': 1, \\'dog\\': 3} |\\n        |   4   |          {}          |\\n        +-------+----------------------+\\n        [4 rows x 2 columns]\\n\\n        Stack would stack all keys in one column and all values in another\\n        column:\\n\\n        >>> sf.stack(\\'words\\', new_column_name=[\\'word\\', \\'count\\'])\\n        +-------+------+-------+\\n        | topic | word | count |\\n        +-------+------+-------+\\n        |   1   |  a   |   3   |\\n        |   1   | cat  |   2   |\\n        |   2   |  a   |   1   |\\n        |   2   | the  |   2   |\\n        |   3   | the  |   1   |\\n        |   3   | dog  |   3   |\\n        |   4   | None |  None |\\n        +-------+------+-------+\\n        [7 rows x 3 columns]\\n\\n        Observe that since topic 4 had no words, an empty row is inserted.\\n        To drop that row, set drop_na=True in the parameters to stack.\\n\\n        Suppose \\'sf\\' is an SFrame that contains a user and his/her friends,\\n        where \\'friends\\' columns is an array type. Stack on \\'friends\\' column\\n        would create a user/friend list for each user/friend pair:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3],\\n        ...                       \\'friends\\':[[2,3,4], [5,6],\\n        ...                                  [4,5,10,None]]\\n        ...                      })\\n        >>> sf\\n        +-------+------------------+\\n        | topic |     friends      |\\n        +-------+------------------+\\n        |  1    |     [2, 3, 4]    |\\n        |  2    |      [5, 6]      |\\n        |  3    | [4, 5, 10, None] |\\n        +----- -+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.stack(\\'friends\\', new_column_name=\\'friend\\')\\n        +-------+--------+\\n        | topic | friend |\\n        +-------+--------+\\n        |   1   |   2    |\\n        |   1   |   3    |\\n        |   1   |   4    |\\n        |   2   |   5    |\\n        |   2   |   6    |\\n        |   3   |   4    |\\n        |   3   |   5    |\\n        |   3   |   10   |\\n        |   3   |  None  |\\n        +-------+--------+\\n        [9 rows x 2 columns]\\n\\n        '\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise ValueError(\"Cannot find column '\" + str(column_name) + \"' in the SFrame.\")\n    stack_column_type = self[column_name].dtype\n    if stack_column_type not in [dict, array.array, list]:\n        raise TypeError('Stack is only supported for column of dict/list/array type.')\n    if new_column_type is not None:\n        if type(new_column_type) is type:\n            new_column_type = [new_column_type]\n        if stack_column_type in [list, array.array] and len(new_column_type) != 1:\n            raise ValueError('Expecting a single column type to unpack list or array columns')\n        if stack_column_type in [dict] and len(new_column_type) != 2:\n            raise ValueError('Expecting two column types to unpack a dict column')\n    if new_column_name is not None:\n        if stack_column_type == dict:\n            if type(new_column_name) is not list:\n                raise TypeError('new_column_name has to be a list to stack dict type')\n            elif len(new_column_name) != 2:\n                raise TypeError('new_column_name must have length of two')\n        else:\n            if type(new_column_name) != str:\n                raise TypeError('new_column_name has to be a str')\n            new_column_name = [new_column_name]\n        for name in new_column_name:\n            if name in self.column_names() and name != column_name:\n                raise ValueError(\"Column with name '\" + name + \"' already exists, pick a new column name\")\n    elif stack_column_type == dict:\n        new_column_name = ['', '']\n    else:\n        new_column_name = ['']\n    head_row = SArray(self[column_name].head(100)).dropna()\n    if len(head_row) == 0:\n        raise ValueError('Cannot infer column type because there is not enough rows to infer value')\n    if new_column_type is None:\n        if stack_column_type == dict:\n            keys = []\n            values = []\n            for row in head_row:\n                for val in row:\n                    keys.append(val)\n                    if val is not None:\n                        values.append(row[val])\n            new_column_type = [infer_type_of_list(keys), infer_type_of_list(values)]\n        else:\n            values = [v for v in itertools.chain.from_iterable(head_row)]\n            new_column_type = [infer_type_of_list(values)]\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.stack(column_name, new_column_name, new_column_type, drop_na))",
            "def stack(self, column_name, new_column_name=None, drop_na=False, new_column_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Convert a \"wide\" column of an SFrame to one or two \"tall\" columns by\\n        stacking all values.\\n\\n        The stack works only for columns of dict, list, or array type.  If the\\n        column is dict type, two new columns are created as a result of\\n        stacking: one column holds the key and another column holds the value.\\n        The rest of the columns are repeated for each key/value pair.\\n\\n        If the column is array or list type, one new column is created as a\\n        result of stacking. With each row holds one element of the array or list\\n        value, and the rest columns from the same original row repeated.\\n\\n        The returned SFrame includes the newly created column(s) and all\\n        columns other than the one that is stacked.\\n\\n        Parameters\\n        --------------\\n        column_name : str\\n            The column to stack. This column must be of dict/list/array type\\n\\n        new_column_name : str | list of str, optional\\n            The new column name(s). If original column is list/array type,\\n            new_column_name must a string. If original column is dict type,\\n            new_column_name must be a list of two strings. If not given, column\\n            names are generated automatically.\\n\\n        drop_na : boolean, optional\\n            If True, missing values and empty list/array/dict are all dropped\\n            from the resulting column(s). If False, missing values are\\n            maintained in stacked column(s).\\n\\n        new_column_type : type | list of types, optional\\n            The new column types. If original column is a list/array type\\n            new_column_type must be a single type, or a list of one type. If\\n            original column is of dict type, new_column_type must be a list of\\n            two types. If not provided, the types are automatically inferred\\n            from the first 100 values of the SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains newly stacked column(s) plus columns in\\n            original SFrame other than the stacked column.\\n\\n        See Also\\n        --------\\n        unstack\\n\\n        Examples\\n        ---------\\n        Suppose \\'sf\\' is an SFrame that contains a column of dict type:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3,4],\\n        ...                       \\'words\\': [{\\'a\\':3, \\'cat\\':2},\\n        ...                                 {\\'a\\':1, \\'the\\':2},\\n        ...                                 {\\'the\\':1, \\'dog\\':3},\\n        ...                                 {}]\\n        ...                      })\\n        +-------+----------------------+\\n        | topic |        words         |\\n        +-------+----------------------+\\n        |   1   |  {\\'a\\': 3, \\'cat\\': 2}  |\\n        |   2   |  {\\'a\\': 1, \\'the\\': 2}  |\\n        |   3   | {\\'the\\': 1, \\'dog\\': 3} |\\n        |   4   |          {}          |\\n        +-------+----------------------+\\n        [4 rows x 2 columns]\\n\\n        Stack would stack all keys in one column and all values in another\\n        column:\\n\\n        >>> sf.stack(\\'words\\', new_column_name=[\\'word\\', \\'count\\'])\\n        +-------+------+-------+\\n        | topic | word | count |\\n        +-------+------+-------+\\n        |   1   |  a   |   3   |\\n        |   1   | cat  |   2   |\\n        |   2   |  a   |   1   |\\n        |   2   | the  |   2   |\\n        |   3   | the  |   1   |\\n        |   3   | dog  |   3   |\\n        |   4   | None |  None |\\n        +-------+------+-------+\\n        [7 rows x 3 columns]\\n\\n        Observe that since topic 4 had no words, an empty row is inserted.\\n        To drop that row, set drop_na=True in the parameters to stack.\\n\\n        Suppose \\'sf\\' is an SFrame that contains a user and his/her friends,\\n        where \\'friends\\' columns is an array type. Stack on \\'friends\\' column\\n        would create a user/friend list for each user/friend pair:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3],\\n        ...                       \\'friends\\':[[2,3,4], [5,6],\\n        ...                                  [4,5,10,None]]\\n        ...                      })\\n        >>> sf\\n        +-------+------------------+\\n        | topic |     friends      |\\n        +-------+------------------+\\n        |  1    |     [2, 3, 4]    |\\n        |  2    |      [5, 6]      |\\n        |  3    | [4, 5, 10, None] |\\n        +----- -+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.stack(\\'friends\\', new_column_name=\\'friend\\')\\n        +-------+--------+\\n        | topic | friend |\\n        +-------+--------+\\n        |   1   |   2    |\\n        |   1   |   3    |\\n        |   1   |   4    |\\n        |   2   |   5    |\\n        |   2   |   6    |\\n        |   3   |   4    |\\n        |   3   |   5    |\\n        |   3   |   10   |\\n        |   3   |  None  |\\n        +-------+--------+\\n        [9 rows x 2 columns]\\n\\n        '\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise ValueError(\"Cannot find column '\" + str(column_name) + \"' in the SFrame.\")\n    stack_column_type = self[column_name].dtype\n    if stack_column_type not in [dict, array.array, list]:\n        raise TypeError('Stack is only supported for column of dict/list/array type.')\n    if new_column_type is not None:\n        if type(new_column_type) is type:\n            new_column_type = [new_column_type]\n        if stack_column_type in [list, array.array] and len(new_column_type) != 1:\n            raise ValueError('Expecting a single column type to unpack list or array columns')\n        if stack_column_type in [dict] and len(new_column_type) != 2:\n            raise ValueError('Expecting two column types to unpack a dict column')\n    if new_column_name is not None:\n        if stack_column_type == dict:\n            if type(new_column_name) is not list:\n                raise TypeError('new_column_name has to be a list to stack dict type')\n            elif len(new_column_name) != 2:\n                raise TypeError('new_column_name must have length of two')\n        else:\n            if type(new_column_name) != str:\n                raise TypeError('new_column_name has to be a str')\n            new_column_name = [new_column_name]\n        for name in new_column_name:\n            if name in self.column_names() and name != column_name:\n                raise ValueError(\"Column with name '\" + name + \"' already exists, pick a new column name\")\n    elif stack_column_type == dict:\n        new_column_name = ['', '']\n    else:\n        new_column_name = ['']\n    head_row = SArray(self[column_name].head(100)).dropna()\n    if len(head_row) == 0:\n        raise ValueError('Cannot infer column type because there is not enough rows to infer value')\n    if new_column_type is None:\n        if stack_column_type == dict:\n            keys = []\n            values = []\n            for row in head_row:\n                for val in row:\n                    keys.append(val)\n                    if val is not None:\n                        values.append(row[val])\n            new_column_type = [infer_type_of_list(keys), infer_type_of_list(values)]\n        else:\n            values = [v for v in itertools.chain.from_iterable(head_row)]\n            new_column_type = [infer_type_of_list(values)]\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.stack(column_name, new_column_name, new_column_type, drop_na))",
            "def stack(self, column_name, new_column_name=None, drop_na=False, new_column_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Convert a \"wide\" column of an SFrame to one or two \"tall\" columns by\\n        stacking all values.\\n\\n        The stack works only for columns of dict, list, or array type.  If the\\n        column is dict type, two new columns are created as a result of\\n        stacking: one column holds the key and another column holds the value.\\n        The rest of the columns are repeated for each key/value pair.\\n\\n        If the column is array or list type, one new column is created as a\\n        result of stacking. With each row holds one element of the array or list\\n        value, and the rest columns from the same original row repeated.\\n\\n        The returned SFrame includes the newly created column(s) and all\\n        columns other than the one that is stacked.\\n\\n        Parameters\\n        --------------\\n        column_name : str\\n            The column to stack. This column must be of dict/list/array type\\n\\n        new_column_name : str | list of str, optional\\n            The new column name(s). If original column is list/array type,\\n            new_column_name must a string. If original column is dict type,\\n            new_column_name must be a list of two strings. If not given, column\\n            names are generated automatically.\\n\\n        drop_na : boolean, optional\\n            If True, missing values and empty list/array/dict are all dropped\\n            from the resulting column(s). If False, missing values are\\n            maintained in stacked column(s).\\n\\n        new_column_type : type | list of types, optional\\n            The new column types. If original column is a list/array type\\n            new_column_type must be a single type, or a list of one type. If\\n            original column is of dict type, new_column_type must be a list of\\n            two types. If not provided, the types are automatically inferred\\n            from the first 100 values of the SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains newly stacked column(s) plus columns in\\n            original SFrame other than the stacked column.\\n\\n        See Also\\n        --------\\n        unstack\\n\\n        Examples\\n        ---------\\n        Suppose \\'sf\\' is an SFrame that contains a column of dict type:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3,4],\\n        ...                       \\'words\\': [{\\'a\\':3, \\'cat\\':2},\\n        ...                                 {\\'a\\':1, \\'the\\':2},\\n        ...                                 {\\'the\\':1, \\'dog\\':3},\\n        ...                                 {}]\\n        ...                      })\\n        +-------+----------------------+\\n        | topic |        words         |\\n        +-------+----------------------+\\n        |   1   |  {\\'a\\': 3, \\'cat\\': 2}  |\\n        |   2   |  {\\'a\\': 1, \\'the\\': 2}  |\\n        |   3   | {\\'the\\': 1, \\'dog\\': 3} |\\n        |   4   |          {}          |\\n        +-------+----------------------+\\n        [4 rows x 2 columns]\\n\\n        Stack would stack all keys in one column and all values in another\\n        column:\\n\\n        >>> sf.stack(\\'words\\', new_column_name=[\\'word\\', \\'count\\'])\\n        +-------+------+-------+\\n        | topic | word | count |\\n        +-------+------+-------+\\n        |   1   |  a   |   3   |\\n        |   1   | cat  |   2   |\\n        |   2   |  a   |   1   |\\n        |   2   | the  |   2   |\\n        |   3   | the  |   1   |\\n        |   3   | dog  |   3   |\\n        |   4   | None |  None |\\n        +-------+------+-------+\\n        [7 rows x 3 columns]\\n\\n        Observe that since topic 4 had no words, an empty row is inserted.\\n        To drop that row, set drop_na=True in the parameters to stack.\\n\\n        Suppose \\'sf\\' is an SFrame that contains a user and his/her friends,\\n        where \\'friends\\' columns is an array type. Stack on \\'friends\\' column\\n        would create a user/friend list for each user/friend pair:\\n\\n        >>> sf = turicreate.SFrame({\\'topic\\':[1,2,3],\\n        ...                       \\'friends\\':[[2,3,4], [5,6],\\n        ...                                  [4,5,10,None]]\\n        ...                      })\\n        >>> sf\\n        +-------+------------------+\\n        | topic |     friends      |\\n        +-------+------------------+\\n        |  1    |     [2, 3, 4]    |\\n        |  2    |      [5, 6]      |\\n        |  3    | [4, 5, 10, None] |\\n        +----- -+------------------+\\n        [3 rows x 2 columns]\\n\\n        >>> sf.stack(\\'friends\\', new_column_name=\\'friend\\')\\n        +-------+--------+\\n        | topic | friend |\\n        +-------+--------+\\n        |   1   |   2    |\\n        |   1   |   3    |\\n        |   1   |   4    |\\n        |   2   |   5    |\\n        |   2   |   6    |\\n        |   3   |   4    |\\n        |   3   |   5    |\\n        |   3   |   10   |\\n        |   3   |  None  |\\n        +-------+--------+\\n        [9 rows x 2 columns]\\n\\n        '\n    column_name = str(column_name)\n    if column_name not in self.column_names():\n        raise ValueError(\"Cannot find column '\" + str(column_name) + \"' in the SFrame.\")\n    stack_column_type = self[column_name].dtype\n    if stack_column_type not in [dict, array.array, list]:\n        raise TypeError('Stack is only supported for column of dict/list/array type.')\n    if new_column_type is not None:\n        if type(new_column_type) is type:\n            new_column_type = [new_column_type]\n        if stack_column_type in [list, array.array] and len(new_column_type) != 1:\n            raise ValueError('Expecting a single column type to unpack list or array columns')\n        if stack_column_type in [dict] and len(new_column_type) != 2:\n            raise ValueError('Expecting two column types to unpack a dict column')\n    if new_column_name is not None:\n        if stack_column_type == dict:\n            if type(new_column_name) is not list:\n                raise TypeError('new_column_name has to be a list to stack dict type')\n            elif len(new_column_name) != 2:\n                raise TypeError('new_column_name must have length of two')\n        else:\n            if type(new_column_name) != str:\n                raise TypeError('new_column_name has to be a str')\n            new_column_name = [new_column_name]\n        for name in new_column_name:\n            if name in self.column_names() and name != column_name:\n                raise ValueError(\"Column with name '\" + name + \"' already exists, pick a new column name\")\n    elif stack_column_type == dict:\n        new_column_name = ['', '']\n    else:\n        new_column_name = ['']\n    head_row = SArray(self[column_name].head(100)).dropna()\n    if len(head_row) == 0:\n        raise ValueError('Cannot infer column type because there is not enough rows to infer value')\n    if new_column_type is None:\n        if stack_column_type == dict:\n            keys = []\n            values = []\n            for row in head_row:\n                for val in row:\n                    keys.append(val)\n                    if val is not None:\n                        values.append(row[val])\n            new_column_type = [infer_type_of_list(keys), infer_type_of_list(values)]\n        else:\n            values = [v for v in itertools.chain.from_iterable(head_row)]\n            new_column_type = [infer_type_of_list(values)]\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.stack(column_name, new_column_name, new_column_type, drop_na))"
        ]
    },
    {
        "func_name": "unstack",
        "original": "def unstack(self, column_names, new_column_name=None):\n    \"\"\"\n        Concatenate values from one or two columns into one column, grouping by\n        all other columns. The resulting column could be of type list, array or\n        dictionary.  If ``column_names`` is a numeric column, the result will be of\n        array.array type.  If ``column_names`` is a non-numeric column, the new column\n        will be of list type. If ``column_names`` is a list of two columns, the new\n        column will be of dict type where the keys are taken from the first\n        column in the list.\n\n        Parameters\n        ----------\n        column_names : str | [str, str]\n            The column(s) that is(are) to be concatenated.\n            If str, then collapsed column type is either array or list.\n            If [str, str], then collapsed column type is dict\n\n        new_column_name : str, optional\n            New column name. If not given, a name is generated automatically.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame containing the grouped columns as well as the new\n            column.\n\n        See Also\n        --------\n        stack : The inverse of unstack.\n\n        groupby : ``unstack`` is a special version of ``groupby`` that uses the\n          :mod:`~turicreate.aggregate.CONCAT` aggregator\n\n        Notes\n        -----\n        - There is no guarantee the resulting SFrame maintains the same order as\n          the original SFrame.\n\n        - Missing values are maintained during unstack.\n\n        - When unstacking into a dictionary, if there is more than one instance\n          of a given key for a particular group, an arbitrary value is selected.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'count':[4, 2, 1, 1, 2, None],\n        ...                       'topic':['cat', 'cat', 'dog', 'elephant', 'elephant', 'fish'],\n        ...                       'word':['a', 'c', 'c', 'a', 'b', None]})\n        >>> sf.unstack(column_names=['word', 'count'], new_column_name='words')\n        +----------+------------------+\n        |  topic   |      words       |\n        +----------+------------------+\n        | elephant | {'a': 1, 'b': 2} |\n        |   dog    |     {'c': 1}     |\n        |   cat    | {'a': 4, 'c': 2} |\n        |   fish   |       None       |\n        +----------+------------------+\n        [4 rows x 2 columns]\n\n        >>> sf = turicreate.SFrame({'friend': [2, 3, 4, 5, 6, 4, 5, 2, 3],\n        ...                      'user': [1, 1, 1, 2, 2, 2, 3, 4, 4]})\n        >>> sf.unstack('friend', new_column_name='new name')\n        +------+-----------+\n        | user |  new name |\n        +------+-----------+\n        |  3   |    [5]    |\n        |  1   | [2, 3, 4] |\n        |  2   | [6, 4, 5] |\n        |  4   |   [2, 3]  |\n        +------+-----------+\n        [4 rows x 2 columns]\n        \"\"\"\n    if type(column_names) != str and len(column_names) != 2:\n        raise TypeError(\"'column_names' parameter has to be either a string or a list of two strings.\")\n    with cython_context():\n        if type(column_names) == str:\n            key_columns = [i for i in self.column_names() if i != column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names)})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names))\n        elif len(column_names) == 2:\n            key_columns = [i for i in self.column_names() if i not in column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names[0], column_names[1])})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names[0], column_names[1]))",
        "mutated": [
            "def unstack(self, column_names, new_column_name=None):\n    if False:\n        i = 10\n    \"\\n        Concatenate values from one or two columns into one column, grouping by\\n        all other columns. The resulting column could be of type list, array or\\n        dictionary.  If ``column_names`` is a numeric column, the result will be of\\n        array.array type.  If ``column_names`` is a non-numeric column, the new column\\n        will be of list type. If ``column_names`` is a list of two columns, the new\\n        column will be of dict type where the keys are taken from the first\\n        column in the list.\\n\\n        Parameters\\n        ----------\\n        column_names : str | [str, str]\\n            The column(s) that is(are) to be concatenated.\\n            If str, then collapsed column type is either array or list.\\n            If [str, str], then collapsed column type is dict\\n\\n        new_column_name : str, optional\\n            New column name. If not given, a name is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the grouped columns as well as the new\\n            column.\\n\\n        See Also\\n        --------\\n        stack : The inverse of unstack.\\n\\n        groupby : ``unstack`` is a special version of ``groupby`` that uses the\\n          :mod:`~turicreate.aggregate.CONCAT` aggregator\\n\\n        Notes\\n        -----\\n        - There is no guarantee the resulting SFrame maintains the same order as\\n          the original SFrame.\\n\\n        - Missing values are maintained during unstack.\\n\\n        - When unstacking into a dictionary, if there is more than one instance\\n          of a given key for a particular group, an arbitrary value is selected.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'count':[4, 2, 1, 1, 2, None],\\n        ...                       'topic':['cat', 'cat', 'dog', 'elephant', 'elephant', 'fish'],\\n        ...                       'word':['a', 'c', 'c', 'a', 'b', None]})\\n        >>> sf.unstack(column_names=['word', 'count'], new_column_name='words')\\n        +----------+------------------+\\n        |  topic   |      words       |\\n        +----------+------------------+\\n        | elephant | {'a': 1, 'b': 2} |\\n        |   dog    |     {'c': 1}     |\\n        |   cat    | {'a': 4, 'c': 2} |\\n        |   fish   |       None       |\\n        +----------+------------------+\\n        [4 rows x 2 columns]\\n\\n        >>> sf = turicreate.SFrame({'friend': [2, 3, 4, 5, 6, 4, 5, 2, 3],\\n        ...                      'user': [1, 1, 1, 2, 2, 2, 3, 4, 4]})\\n        >>> sf.unstack('friend', new_column_name='new name')\\n        +------+-----------+\\n        | user |  new name |\\n        +------+-----------+\\n        |  3   |    [5]    |\\n        |  1   | [2, 3, 4] |\\n        |  2   | [6, 4, 5] |\\n        |  4   |   [2, 3]  |\\n        +------+-----------+\\n        [4 rows x 2 columns]\\n        \"\n    if type(column_names) != str and len(column_names) != 2:\n        raise TypeError(\"'column_names' parameter has to be either a string or a list of two strings.\")\n    with cython_context():\n        if type(column_names) == str:\n            key_columns = [i for i in self.column_names() if i != column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names)})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names))\n        elif len(column_names) == 2:\n            key_columns = [i for i in self.column_names() if i not in column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names[0], column_names[1])})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names[0], column_names[1]))",
            "def unstack(self, column_names, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Concatenate values from one or two columns into one column, grouping by\\n        all other columns. The resulting column could be of type list, array or\\n        dictionary.  If ``column_names`` is a numeric column, the result will be of\\n        array.array type.  If ``column_names`` is a non-numeric column, the new column\\n        will be of list type. If ``column_names`` is a list of two columns, the new\\n        column will be of dict type where the keys are taken from the first\\n        column in the list.\\n\\n        Parameters\\n        ----------\\n        column_names : str | [str, str]\\n            The column(s) that is(are) to be concatenated.\\n            If str, then collapsed column type is either array or list.\\n            If [str, str], then collapsed column type is dict\\n\\n        new_column_name : str, optional\\n            New column name. If not given, a name is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the grouped columns as well as the new\\n            column.\\n\\n        See Also\\n        --------\\n        stack : The inverse of unstack.\\n\\n        groupby : ``unstack`` is a special version of ``groupby`` that uses the\\n          :mod:`~turicreate.aggregate.CONCAT` aggregator\\n\\n        Notes\\n        -----\\n        - There is no guarantee the resulting SFrame maintains the same order as\\n          the original SFrame.\\n\\n        - Missing values are maintained during unstack.\\n\\n        - When unstacking into a dictionary, if there is more than one instance\\n          of a given key for a particular group, an arbitrary value is selected.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'count':[4, 2, 1, 1, 2, None],\\n        ...                       'topic':['cat', 'cat', 'dog', 'elephant', 'elephant', 'fish'],\\n        ...                       'word':['a', 'c', 'c', 'a', 'b', None]})\\n        >>> sf.unstack(column_names=['word', 'count'], new_column_name='words')\\n        +----------+------------------+\\n        |  topic   |      words       |\\n        +----------+------------------+\\n        | elephant | {'a': 1, 'b': 2} |\\n        |   dog    |     {'c': 1}     |\\n        |   cat    | {'a': 4, 'c': 2} |\\n        |   fish   |       None       |\\n        +----------+------------------+\\n        [4 rows x 2 columns]\\n\\n        >>> sf = turicreate.SFrame({'friend': [2, 3, 4, 5, 6, 4, 5, 2, 3],\\n        ...                      'user': [1, 1, 1, 2, 2, 2, 3, 4, 4]})\\n        >>> sf.unstack('friend', new_column_name='new name')\\n        +------+-----------+\\n        | user |  new name |\\n        +------+-----------+\\n        |  3   |    [5]    |\\n        |  1   | [2, 3, 4] |\\n        |  2   | [6, 4, 5] |\\n        |  4   |   [2, 3]  |\\n        +------+-----------+\\n        [4 rows x 2 columns]\\n        \"\n    if type(column_names) != str and len(column_names) != 2:\n        raise TypeError(\"'column_names' parameter has to be either a string or a list of two strings.\")\n    with cython_context():\n        if type(column_names) == str:\n            key_columns = [i for i in self.column_names() if i != column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names)})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names))\n        elif len(column_names) == 2:\n            key_columns = [i for i in self.column_names() if i not in column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names[0], column_names[1])})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names[0], column_names[1]))",
            "def unstack(self, column_names, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Concatenate values from one or two columns into one column, grouping by\\n        all other columns. The resulting column could be of type list, array or\\n        dictionary.  If ``column_names`` is a numeric column, the result will be of\\n        array.array type.  If ``column_names`` is a non-numeric column, the new column\\n        will be of list type. If ``column_names`` is a list of two columns, the new\\n        column will be of dict type where the keys are taken from the first\\n        column in the list.\\n\\n        Parameters\\n        ----------\\n        column_names : str | [str, str]\\n            The column(s) that is(are) to be concatenated.\\n            If str, then collapsed column type is either array or list.\\n            If [str, str], then collapsed column type is dict\\n\\n        new_column_name : str, optional\\n            New column name. If not given, a name is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the grouped columns as well as the new\\n            column.\\n\\n        See Also\\n        --------\\n        stack : The inverse of unstack.\\n\\n        groupby : ``unstack`` is a special version of ``groupby`` that uses the\\n          :mod:`~turicreate.aggregate.CONCAT` aggregator\\n\\n        Notes\\n        -----\\n        - There is no guarantee the resulting SFrame maintains the same order as\\n          the original SFrame.\\n\\n        - Missing values are maintained during unstack.\\n\\n        - When unstacking into a dictionary, if there is more than one instance\\n          of a given key for a particular group, an arbitrary value is selected.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'count':[4, 2, 1, 1, 2, None],\\n        ...                       'topic':['cat', 'cat', 'dog', 'elephant', 'elephant', 'fish'],\\n        ...                       'word':['a', 'c', 'c', 'a', 'b', None]})\\n        >>> sf.unstack(column_names=['word', 'count'], new_column_name='words')\\n        +----------+------------------+\\n        |  topic   |      words       |\\n        +----------+------------------+\\n        | elephant | {'a': 1, 'b': 2} |\\n        |   dog    |     {'c': 1}     |\\n        |   cat    | {'a': 4, 'c': 2} |\\n        |   fish   |       None       |\\n        +----------+------------------+\\n        [4 rows x 2 columns]\\n\\n        >>> sf = turicreate.SFrame({'friend': [2, 3, 4, 5, 6, 4, 5, 2, 3],\\n        ...                      'user': [1, 1, 1, 2, 2, 2, 3, 4, 4]})\\n        >>> sf.unstack('friend', new_column_name='new name')\\n        +------+-----------+\\n        | user |  new name |\\n        +------+-----------+\\n        |  3   |    [5]    |\\n        |  1   | [2, 3, 4] |\\n        |  2   | [6, 4, 5] |\\n        |  4   |   [2, 3]  |\\n        +------+-----------+\\n        [4 rows x 2 columns]\\n        \"\n    if type(column_names) != str and len(column_names) != 2:\n        raise TypeError(\"'column_names' parameter has to be either a string or a list of two strings.\")\n    with cython_context():\n        if type(column_names) == str:\n            key_columns = [i for i in self.column_names() if i != column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names)})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names))\n        elif len(column_names) == 2:\n            key_columns = [i for i in self.column_names() if i not in column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names[0], column_names[1])})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names[0], column_names[1]))",
            "def unstack(self, column_names, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Concatenate values from one or two columns into one column, grouping by\\n        all other columns. The resulting column could be of type list, array or\\n        dictionary.  If ``column_names`` is a numeric column, the result will be of\\n        array.array type.  If ``column_names`` is a non-numeric column, the new column\\n        will be of list type. If ``column_names`` is a list of two columns, the new\\n        column will be of dict type where the keys are taken from the first\\n        column in the list.\\n\\n        Parameters\\n        ----------\\n        column_names : str | [str, str]\\n            The column(s) that is(are) to be concatenated.\\n            If str, then collapsed column type is either array or list.\\n            If [str, str], then collapsed column type is dict\\n\\n        new_column_name : str, optional\\n            New column name. If not given, a name is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the grouped columns as well as the new\\n            column.\\n\\n        See Also\\n        --------\\n        stack : The inverse of unstack.\\n\\n        groupby : ``unstack`` is a special version of ``groupby`` that uses the\\n          :mod:`~turicreate.aggregate.CONCAT` aggregator\\n\\n        Notes\\n        -----\\n        - There is no guarantee the resulting SFrame maintains the same order as\\n          the original SFrame.\\n\\n        - Missing values are maintained during unstack.\\n\\n        - When unstacking into a dictionary, if there is more than one instance\\n          of a given key for a particular group, an arbitrary value is selected.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'count':[4, 2, 1, 1, 2, None],\\n        ...                       'topic':['cat', 'cat', 'dog', 'elephant', 'elephant', 'fish'],\\n        ...                       'word':['a', 'c', 'c', 'a', 'b', None]})\\n        >>> sf.unstack(column_names=['word', 'count'], new_column_name='words')\\n        +----------+------------------+\\n        |  topic   |      words       |\\n        +----------+------------------+\\n        | elephant | {'a': 1, 'b': 2} |\\n        |   dog    |     {'c': 1}     |\\n        |   cat    | {'a': 4, 'c': 2} |\\n        |   fish   |       None       |\\n        +----------+------------------+\\n        [4 rows x 2 columns]\\n\\n        >>> sf = turicreate.SFrame({'friend': [2, 3, 4, 5, 6, 4, 5, 2, 3],\\n        ...                      'user': [1, 1, 1, 2, 2, 2, 3, 4, 4]})\\n        >>> sf.unstack('friend', new_column_name='new name')\\n        +------+-----------+\\n        | user |  new name |\\n        +------+-----------+\\n        |  3   |    [5]    |\\n        |  1   | [2, 3, 4] |\\n        |  2   | [6, 4, 5] |\\n        |  4   |   [2, 3]  |\\n        +------+-----------+\\n        [4 rows x 2 columns]\\n        \"\n    if type(column_names) != str and len(column_names) != 2:\n        raise TypeError(\"'column_names' parameter has to be either a string or a list of two strings.\")\n    with cython_context():\n        if type(column_names) == str:\n            key_columns = [i for i in self.column_names() if i != column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names)})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names))\n        elif len(column_names) == 2:\n            key_columns = [i for i in self.column_names() if i not in column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names[0], column_names[1])})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names[0], column_names[1]))",
            "def unstack(self, column_names, new_column_name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Concatenate values from one or two columns into one column, grouping by\\n        all other columns. The resulting column could be of type list, array or\\n        dictionary.  If ``column_names`` is a numeric column, the result will be of\\n        array.array type.  If ``column_names`` is a non-numeric column, the new column\\n        will be of list type. If ``column_names`` is a list of two columns, the new\\n        column will be of dict type where the keys are taken from the first\\n        column in the list.\\n\\n        Parameters\\n        ----------\\n        column_names : str | [str, str]\\n            The column(s) that is(are) to be concatenated.\\n            If str, then collapsed column type is either array or list.\\n            If [str, str], then collapsed column type is dict\\n\\n        new_column_name : str, optional\\n            New column name. If not given, a name is generated automatically.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame containing the grouped columns as well as the new\\n            column.\\n\\n        See Also\\n        --------\\n        stack : The inverse of unstack.\\n\\n        groupby : ``unstack`` is a special version of ``groupby`` that uses the\\n          :mod:`~turicreate.aggregate.CONCAT` aggregator\\n\\n        Notes\\n        -----\\n        - There is no guarantee the resulting SFrame maintains the same order as\\n          the original SFrame.\\n\\n        - Missing values are maintained during unstack.\\n\\n        - When unstacking into a dictionary, if there is more than one instance\\n          of a given key for a particular group, an arbitrary value is selected.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'count':[4, 2, 1, 1, 2, None],\\n        ...                       'topic':['cat', 'cat', 'dog', 'elephant', 'elephant', 'fish'],\\n        ...                       'word':['a', 'c', 'c', 'a', 'b', None]})\\n        >>> sf.unstack(column_names=['word', 'count'], new_column_name='words')\\n        +----------+------------------+\\n        |  topic   |      words       |\\n        +----------+------------------+\\n        | elephant | {'a': 1, 'b': 2} |\\n        |   dog    |     {'c': 1}     |\\n        |   cat    | {'a': 4, 'c': 2} |\\n        |   fish   |       None       |\\n        +----------+------------------+\\n        [4 rows x 2 columns]\\n\\n        >>> sf = turicreate.SFrame({'friend': [2, 3, 4, 5, 6, 4, 5, 2, 3],\\n        ...                      'user': [1, 1, 1, 2, 2, 2, 3, 4, 4]})\\n        >>> sf.unstack('friend', new_column_name='new name')\\n        +------+-----------+\\n        | user |  new name |\\n        +------+-----------+\\n        |  3   |    [5]    |\\n        |  1   | [2, 3, 4] |\\n        |  2   | [6, 4, 5] |\\n        |  4   |   [2, 3]  |\\n        +------+-----------+\\n        [4 rows x 2 columns]\\n        \"\n    if type(column_names) != str and len(column_names) != 2:\n        raise TypeError(\"'column_names' parameter has to be either a string or a list of two strings.\")\n    with cython_context():\n        if type(column_names) == str:\n            key_columns = [i for i in self.column_names() if i != column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names)})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names))\n        elif len(column_names) == 2:\n            key_columns = [i for i in self.column_names() if i not in column_names]\n            if new_column_name is not None:\n                return self.groupby(key_columns, {new_column_name: aggregate.CONCAT(column_names[0], column_names[1])})\n            else:\n                return self.groupby(key_columns, aggregate.CONCAT(column_names[0], column_names[1]))"
        ]
    },
    {
        "func_name": "unique",
        "original": "def unique(self):\n    \"\"\"\n        Remove duplicate rows of the SFrame. Will not necessarily preserve the\n        order of the given SFrame in the new SFrame.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains the unique rows of the current SFrame.\n\n        Raises\n        ------\n        TypeError\n          If any column in the SFrame is a dictionary type.\n\n        See Also\n        --------\n        SArray.unique\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id':[1,2,3,3,4], 'value':[1,2,3,3,4]})\n        >>> sf\n        +----+-------+\n        | id | value |\n        +----+-------+\n        | 1  |   1   |\n        | 2  |   2   |\n        | 3  |   3   |\n        | 3  |   3   |\n        | 4  |   4   |\n        +----+-------+\n        [5 rows x 2 columns]\n\n        >>> sf.unique()\n        +----+-------+\n        | id | value |\n        +----+-------+\n        | 2  |   2   |\n        | 4  |   4   |\n        | 3  |   3   |\n        | 1  |   1   |\n        +----+-------+\n        [4 rows x 2 columns]\n        \"\"\"\n    return self.groupby(self.column_names(), {})",
        "mutated": [
            "def unique(self):\n    if False:\n        i = 10\n    \"\\n        Remove duplicate rows of the SFrame. Will not necessarily preserve the\\n        order of the given SFrame in the new SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains the unique rows of the current SFrame.\\n\\n        Raises\\n        ------\\n        TypeError\\n          If any column in the SFrame is a dictionary type.\\n\\n        See Also\\n        --------\\n        SArray.unique\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3,3,4], 'value':[1,2,3,3,4]})\\n        >>> sf\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 1  |   1   |\\n        | 2  |   2   |\\n        | 3  |   3   |\\n        | 3  |   3   |\\n        | 4  |   4   |\\n        +----+-------+\\n        [5 rows x 2 columns]\\n\\n        >>> sf.unique()\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 2  |   2   |\\n        | 4  |   4   |\\n        | 3  |   3   |\\n        | 1  |   1   |\\n        +----+-------+\\n        [4 rows x 2 columns]\\n        \"\n    return self.groupby(self.column_names(), {})",
            "def unique(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Remove duplicate rows of the SFrame. Will not necessarily preserve the\\n        order of the given SFrame in the new SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains the unique rows of the current SFrame.\\n\\n        Raises\\n        ------\\n        TypeError\\n          If any column in the SFrame is a dictionary type.\\n\\n        See Also\\n        --------\\n        SArray.unique\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3,3,4], 'value':[1,2,3,3,4]})\\n        >>> sf\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 1  |   1   |\\n        | 2  |   2   |\\n        | 3  |   3   |\\n        | 3  |   3   |\\n        | 4  |   4   |\\n        +----+-------+\\n        [5 rows x 2 columns]\\n\\n        >>> sf.unique()\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 2  |   2   |\\n        | 4  |   4   |\\n        | 3  |   3   |\\n        | 1  |   1   |\\n        +----+-------+\\n        [4 rows x 2 columns]\\n        \"\n    return self.groupby(self.column_names(), {})",
            "def unique(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Remove duplicate rows of the SFrame. Will not necessarily preserve the\\n        order of the given SFrame in the new SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains the unique rows of the current SFrame.\\n\\n        Raises\\n        ------\\n        TypeError\\n          If any column in the SFrame is a dictionary type.\\n\\n        See Also\\n        --------\\n        SArray.unique\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3,3,4], 'value':[1,2,3,3,4]})\\n        >>> sf\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 1  |   1   |\\n        | 2  |   2   |\\n        | 3  |   3   |\\n        | 3  |   3   |\\n        | 4  |   4   |\\n        +----+-------+\\n        [5 rows x 2 columns]\\n\\n        >>> sf.unique()\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 2  |   2   |\\n        | 4  |   4   |\\n        | 3  |   3   |\\n        | 1  |   1   |\\n        +----+-------+\\n        [4 rows x 2 columns]\\n        \"\n    return self.groupby(self.column_names(), {})",
            "def unique(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Remove duplicate rows of the SFrame. Will not necessarily preserve the\\n        order of the given SFrame in the new SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains the unique rows of the current SFrame.\\n\\n        Raises\\n        ------\\n        TypeError\\n          If any column in the SFrame is a dictionary type.\\n\\n        See Also\\n        --------\\n        SArray.unique\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3,3,4], 'value':[1,2,3,3,4]})\\n        >>> sf\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 1  |   1   |\\n        | 2  |   2   |\\n        | 3  |   3   |\\n        | 3  |   3   |\\n        | 4  |   4   |\\n        +----+-------+\\n        [5 rows x 2 columns]\\n\\n        >>> sf.unique()\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 2  |   2   |\\n        | 4  |   4   |\\n        | 3  |   3   |\\n        | 1  |   1   |\\n        +----+-------+\\n        [4 rows x 2 columns]\\n        \"\n    return self.groupby(self.column_names(), {})",
            "def unique(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Remove duplicate rows of the SFrame. Will not necessarily preserve the\\n        order of the given SFrame in the new SFrame.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that contains the unique rows of the current SFrame.\\n\\n        Raises\\n        ------\\n        TypeError\\n          If any column in the SFrame is a dictionary type.\\n\\n        See Also\\n        --------\\n        SArray.unique\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3,3,4], 'value':[1,2,3,3,4]})\\n        >>> sf\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 1  |   1   |\\n        | 2  |   2   |\\n        | 3  |   3   |\\n        | 3  |   3   |\\n        | 4  |   4   |\\n        +----+-------+\\n        [5 rows x 2 columns]\\n\\n        >>> sf.unique()\\n        +----+-------+\\n        | id | value |\\n        +----+-------+\\n        | 2  |   2   |\\n        | 4  |   4   |\\n        | 3  |   3   |\\n        | 1  |   1   |\\n        +----+-------+\\n        [4 rows x 2 columns]\\n        \"\n    return self.groupby(self.column_names(), {})"
        ]
    },
    {
        "func_name": "sort",
        "original": "def sort(self, key_column_names, ascending=True):\n    \"\"\"\n        Sort current SFrame by the given columns, using the given sort order.\n        Only columns that are type of str, int and float can be sorted.\n\n        Parameters\n        ----------\n        key_column_names : str | list of str | list of (str, bool) pairs\n            Names of columns to be sorted.  The result will be sorted first by\n            first column, followed by second column, and so on. All columns will\n            be sorted in the same order as governed by the `ascending`\n            parameter. To control the sort ordering for each column\n            individually, `key_column_names` must be a list of (str, bool) pairs.\n            Given this case, the first value is the column name and the second\n            value is a boolean indicating whether the sort order is ascending.\n\n        ascending : bool, optional\n            Sort all columns in the given order.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that is sorted according to given sort criteria\n\n        See Also\n        --------\n        topk\n\n        Examples\n        --------\n        Suppose 'sf' is an sframe that has three columns 'a', 'b', 'c'.\n        To sort by column 'a', ascending\n\n        >>> sf = turicreate.SFrame({'a':[1,3,2,1],\n        ...                       'b':['a','c','b','b'],\n        ...                       'c':['x','y','z','y']})\n        >>> sf\n        +---+---+---+\n        | a | b | c |\n        +---+---+---+\n        | 1 | a | x |\n        | 3 | c | y |\n        | 2 | b | z |\n        | 1 | b | y |\n        +---+---+---+\n        [4 rows x 3 columns]\n\n        >>> sf.sort('a')\n        +---+---+---+\n        | a | b | c |\n        +---+---+---+\n        | 1 | a | x |\n        | 1 | b | y |\n        | 2 | b | z |\n        | 3 | c | y |\n        +---+---+---+\n        [4 rows x 3 columns]\n\n        To sort by column 'a', descending\n\n        >>> sf.sort('a', ascending = False)\n        +---+---+---+\n        | a | b | c |\n        +---+---+---+\n        | 3 | c | y |\n        | 2 | b | z |\n        | 1 | a | x |\n        | 1 | b | y |\n        +---+---+---+\n        [4 rows x 3 columns]\n\n        To sort by column 'a' and 'b', all ascending\n\n        >>> sf.sort(['a', 'b'])\n        +---+---+---+\n        | a | b | c |\n        +---+---+---+\n        | 1 | a | x |\n        | 1 | b | y |\n        | 2 | b | z |\n        | 3 | c | y |\n        +---+---+---+\n        [4 rows x 3 columns]\n\n        To sort by column 'a' ascending, and then by column 'c' descending\n\n        >>> sf.sort([('a', True), ('c', False)])\n        +---+---+---+\n        | a | b | c |\n        +---+---+---+\n        | 1 | b | y |\n        | 1 | a | x |\n        | 2 | b | z |\n        | 3 | c | y |\n        +---+---+---+\n        [4 rows x 3 columns]\n        \"\"\"\n    sort_column_names = []\n    sort_column_orders = []\n    if type(key_column_names) == str:\n        sort_column_names = [key_column_names]\n    elif type(key_column_names) == list:\n        if len(key_column_names) == 0:\n            raise ValueError('Please provide at least one column to sort')\n        first_param_types = set([type(i) for i in key_column_names])\n        if len(first_param_types) != 1:\n            raise ValueError('key_column_names element are not of the same type')\n        first_param_type = first_param_types.pop()\n        if first_param_type == tuple:\n            sort_column_names = [i[0] for i in key_column_names]\n            sort_column_orders = [i[1] for i in key_column_names]\n        elif first_param_type == str:\n            sort_column_names = key_column_names\n        else:\n            raise TypeError('key_column_names type is not supported')\n    else:\n        raise TypeError('key_column_names type is not correct. Supported types are str, list of str or list of (str,bool) pair.')\n    if len(sort_column_orders) == 0:\n        sort_column_orders = [ascending for i in sort_column_names]\n    my_column_names = set(self.column_names())\n    for column in sort_column_names:\n        if type(column) != str:\n            raise TypeError('Only string parameter can be passed in as column names')\n        if column not in my_column_names:\n            raise ValueError(\"SFrame has no column named: '\" + str(column) + \"'\")\n        if self[column].dtype not in (str, int, float, datetime.datetime):\n            raise TypeError('Only columns of type (str, int, float) can be sorted')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.sort(sort_column_names, sort_column_orders))",
        "mutated": [
            "def sort(self, key_column_names, ascending=True):\n    if False:\n        i = 10\n    \"\\n        Sort current SFrame by the given columns, using the given sort order.\\n        Only columns that are type of str, int and float can be sorted.\\n\\n        Parameters\\n        ----------\\n        key_column_names : str | list of str | list of (str, bool) pairs\\n            Names of columns to be sorted.  The result will be sorted first by\\n            first column, followed by second column, and so on. All columns will\\n            be sorted in the same order as governed by the `ascending`\\n            parameter. To control the sort ordering for each column\\n            individually, `key_column_names` must be a list of (str, bool) pairs.\\n            Given this case, the first value is the column name and the second\\n            value is a boolean indicating whether the sort order is ascending.\\n\\n        ascending : bool, optional\\n            Sort all columns in the given order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is sorted according to given sort criteria\\n\\n        See Also\\n        --------\\n        topk\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an sframe that has three columns 'a', 'b', 'c'.\\n        To sort by column 'a', ascending\\n\\n        >>> sf = turicreate.SFrame({'a':[1,3,2,1],\\n        ...                       'b':['a','c','b','b'],\\n        ...                       'c':['x','y','z','y']})\\n        >>> sf\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.sort('a')\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a', descending\\n\\n        >>> sf.sort('a', ascending = False)\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' and 'b', all ascending\\n\\n        >>> sf.sort(['a', 'b'])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' ascending, and then by column 'c' descending\\n\\n        >>> sf.sort([('a', True), ('c', False)])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | b | y |\\n        | 1 | a | x |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n        \"\n    sort_column_names = []\n    sort_column_orders = []\n    if type(key_column_names) == str:\n        sort_column_names = [key_column_names]\n    elif type(key_column_names) == list:\n        if len(key_column_names) == 0:\n            raise ValueError('Please provide at least one column to sort')\n        first_param_types = set([type(i) for i in key_column_names])\n        if len(first_param_types) != 1:\n            raise ValueError('key_column_names element are not of the same type')\n        first_param_type = first_param_types.pop()\n        if first_param_type == tuple:\n            sort_column_names = [i[0] for i in key_column_names]\n            sort_column_orders = [i[1] for i in key_column_names]\n        elif first_param_type == str:\n            sort_column_names = key_column_names\n        else:\n            raise TypeError('key_column_names type is not supported')\n    else:\n        raise TypeError('key_column_names type is not correct. Supported types are str, list of str or list of (str,bool) pair.')\n    if len(sort_column_orders) == 0:\n        sort_column_orders = [ascending for i in sort_column_names]\n    my_column_names = set(self.column_names())\n    for column in sort_column_names:\n        if type(column) != str:\n            raise TypeError('Only string parameter can be passed in as column names')\n        if column not in my_column_names:\n            raise ValueError(\"SFrame has no column named: '\" + str(column) + \"'\")\n        if self[column].dtype not in (str, int, float, datetime.datetime):\n            raise TypeError('Only columns of type (str, int, float) can be sorted')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.sort(sort_column_names, sort_column_orders))",
            "def sort(self, key_column_names, ascending=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Sort current SFrame by the given columns, using the given sort order.\\n        Only columns that are type of str, int and float can be sorted.\\n\\n        Parameters\\n        ----------\\n        key_column_names : str | list of str | list of (str, bool) pairs\\n            Names of columns to be sorted.  The result will be sorted first by\\n            first column, followed by second column, and so on. All columns will\\n            be sorted in the same order as governed by the `ascending`\\n            parameter. To control the sort ordering for each column\\n            individually, `key_column_names` must be a list of (str, bool) pairs.\\n            Given this case, the first value is the column name and the second\\n            value is a boolean indicating whether the sort order is ascending.\\n\\n        ascending : bool, optional\\n            Sort all columns in the given order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is sorted according to given sort criteria\\n\\n        See Also\\n        --------\\n        topk\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an sframe that has three columns 'a', 'b', 'c'.\\n        To sort by column 'a', ascending\\n\\n        >>> sf = turicreate.SFrame({'a':[1,3,2,1],\\n        ...                       'b':['a','c','b','b'],\\n        ...                       'c':['x','y','z','y']})\\n        >>> sf\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.sort('a')\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a', descending\\n\\n        >>> sf.sort('a', ascending = False)\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' and 'b', all ascending\\n\\n        >>> sf.sort(['a', 'b'])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' ascending, and then by column 'c' descending\\n\\n        >>> sf.sort([('a', True), ('c', False)])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | b | y |\\n        | 1 | a | x |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n        \"\n    sort_column_names = []\n    sort_column_orders = []\n    if type(key_column_names) == str:\n        sort_column_names = [key_column_names]\n    elif type(key_column_names) == list:\n        if len(key_column_names) == 0:\n            raise ValueError('Please provide at least one column to sort')\n        first_param_types = set([type(i) for i in key_column_names])\n        if len(first_param_types) != 1:\n            raise ValueError('key_column_names element are not of the same type')\n        first_param_type = first_param_types.pop()\n        if first_param_type == tuple:\n            sort_column_names = [i[0] for i in key_column_names]\n            sort_column_orders = [i[1] for i in key_column_names]\n        elif first_param_type == str:\n            sort_column_names = key_column_names\n        else:\n            raise TypeError('key_column_names type is not supported')\n    else:\n        raise TypeError('key_column_names type is not correct. Supported types are str, list of str or list of (str,bool) pair.')\n    if len(sort_column_orders) == 0:\n        sort_column_orders = [ascending for i in sort_column_names]\n    my_column_names = set(self.column_names())\n    for column in sort_column_names:\n        if type(column) != str:\n            raise TypeError('Only string parameter can be passed in as column names')\n        if column not in my_column_names:\n            raise ValueError(\"SFrame has no column named: '\" + str(column) + \"'\")\n        if self[column].dtype not in (str, int, float, datetime.datetime):\n            raise TypeError('Only columns of type (str, int, float) can be sorted')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.sort(sort_column_names, sort_column_orders))",
            "def sort(self, key_column_names, ascending=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Sort current SFrame by the given columns, using the given sort order.\\n        Only columns that are type of str, int and float can be sorted.\\n\\n        Parameters\\n        ----------\\n        key_column_names : str | list of str | list of (str, bool) pairs\\n            Names of columns to be sorted.  The result will be sorted first by\\n            first column, followed by second column, and so on. All columns will\\n            be sorted in the same order as governed by the `ascending`\\n            parameter. To control the sort ordering for each column\\n            individually, `key_column_names` must be a list of (str, bool) pairs.\\n            Given this case, the first value is the column name and the second\\n            value is a boolean indicating whether the sort order is ascending.\\n\\n        ascending : bool, optional\\n            Sort all columns in the given order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is sorted according to given sort criteria\\n\\n        See Also\\n        --------\\n        topk\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an sframe that has three columns 'a', 'b', 'c'.\\n        To sort by column 'a', ascending\\n\\n        >>> sf = turicreate.SFrame({'a':[1,3,2,1],\\n        ...                       'b':['a','c','b','b'],\\n        ...                       'c':['x','y','z','y']})\\n        >>> sf\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.sort('a')\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a', descending\\n\\n        >>> sf.sort('a', ascending = False)\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' and 'b', all ascending\\n\\n        >>> sf.sort(['a', 'b'])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' ascending, and then by column 'c' descending\\n\\n        >>> sf.sort([('a', True), ('c', False)])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | b | y |\\n        | 1 | a | x |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n        \"\n    sort_column_names = []\n    sort_column_orders = []\n    if type(key_column_names) == str:\n        sort_column_names = [key_column_names]\n    elif type(key_column_names) == list:\n        if len(key_column_names) == 0:\n            raise ValueError('Please provide at least one column to sort')\n        first_param_types = set([type(i) for i in key_column_names])\n        if len(first_param_types) != 1:\n            raise ValueError('key_column_names element are not of the same type')\n        first_param_type = first_param_types.pop()\n        if first_param_type == tuple:\n            sort_column_names = [i[0] for i in key_column_names]\n            sort_column_orders = [i[1] for i in key_column_names]\n        elif first_param_type == str:\n            sort_column_names = key_column_names\n        else:\n            raise TypeError('key_column_names type is not supported')\n    else:\n        raise TypeError('key_column_names type is not correct. Supported types are str, list of str or list of (str,bool) pair.')\n    if len(sort_column_orders) == 0:\n        sort_column_orders = [ascending for i in sort_column_names]\n    my_column_names = set(self.column_names())\n    for column in sort_column_names:\n        if type(column) != str:\n            raise TypeError('Only string parameter can be passed in as column names')\n        if column not in my_column_names:\n            raise ValueError(\"SFrame has no column named: '\" + str(column) + \"'\")\n        if self[column].dtype not in (str, int, float, datetime.datetime):\n            raise TypeError('Only columns of type (str, int, float) can be sorted')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.sort(sort_column_names, sort_column_orders))",
            "def sort(self, key_column_names, ascending=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Sort current SFrame by the given columns, using the given sort order.\\n        Only columns that are type of str, int and float can be sorted.\\n\\n        Parameters\\n        ----------\\n        key_column_names : str | list of str | list of (str, bool) pairs\\n            Names of columns to be sorted.  The result will be sorted first by\\n            first column, followed by second column, and so on. All columns will\\n            be sorted in the same order as governed by the `ascending`\\n            parameter. To control the sort ordering for each column\\n            individually, `key_column_names` must be a list of (str, bool) pairs.\\n            Given this case, the first value is the column name and the second\\n            value is a boolean indicating whether the sort order is ascending.\\n\\n        ascending : bool, optional\\n            Sort all columns in the given order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is sorted according to given sort criteria\\n\\n        See Also\\n        --------\\n        topk\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an sframe that has three columns 'a', 'b', 'c'.\\n        To sort by column 'a', ascending\\n\\n        >>> sf = turicreate.SFrame({'a':[1,3,2,1],\\n        ...                       'b':['a','c','b','b'],\\n        ...                       'c':['x','y','z','y']})\\n        >>> sf\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.sort('a')\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a', descending\\n\\n        >>> sf.sort('a', ascending = False)\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' and 'b', all ascending\\n\\n        >>> sf.sort(['a', 'b'])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' ascending, and then by column 'c' descending\\n\\n        >>> sf.sort([('a', True), ('c', False)])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | b | y |\\n        | 1 | a | x |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n        \"\n    sort_column_names = []\n    sort_column_orders = []\n    if type(key_column_names) == str:\n        sort_column_names = [key_column_names]\n    elif type(key_column_names) == list:\n        if len(key_column_names) == 0:\n            raise ValueError('Please provide at least one column to sort')\n        first_param_types = set([type(i) for i in key_column_names])\n        if len(first_param_types) != 1:\n            raise ValueError('key_column_names element are not of the same type')\n        first_param_type = first_param_types.pop()\n        if first_param_type == tuple:\n            sort_column_names = [i[0] for i in key_column_names]\n            sort_column_orders = [i[1] for i in key_column_names]\n        elif first_param_type == str:\n            sort_column_names = key_column_names\n        else:\n            raise TypeError('key_column_names type is not supported')\n    else:\n        raise TypeError('key_column_names type is not correct. Supported types are str, list of str or list of (str,bool) pair.')\n    if len(sort_column_orders) == 0:\n        sort_column_orders = [ascending for i in sort_column_names]\n    my_column_names = set(self.column_names())\n    for column in sort_column_names:\n        if type(column) != str:\n            raise TypeError('Only string parameter can be passed in as column names')\n        if column not in my_column_names:\n            raise ValueError(\"SFrame has no column named: '\" + str(column) + \"'\")\n        if self[column].dtype not in (str, int, float, datetime.datetime):\n            raise TypeError('Only columns of type (str, int, float) can be sorted')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.sort(sort_column_names, sort_column_orders))",
            "def sort(self, key_column_names, ascending=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Sort current SFrame by the given columns, using the given sort order.\\n        Only columns that are type of str, int and float can be sorted.\\n\\n        Parameters\\n        ----------\\n        key_column_names : str | list of str | list of (str, bool) pairs\\n            Names of columns to be sorted.  The result will be sorted first by\\n            first column, followed by second column, and so on. All columns will\\n            be sorted in the same order as governed by the `ascending`\\n            parameter. To control the sort ordering for each column\\n            individually, `key_column_names` must be a list of (str, bool) pairs.\\n            Given this case, the first value is the column name and the second\\n            value is a boolean indicating whether the sort order is ascending.\\n\\n        ascending : bool, optional\\n            Sort all columns in the given order.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame that is sorted according to given sort criteria\\n\\n        See Also\\n        --------\\n        topk\\n\\n        Examples\\n        --------\\n        Suppose 'sf' is an sframe that has three columns 'a', 'b', 'c'.\\n        To sort by column 'a', ascending\\n\\n        >>> sf = turicreate.SFrame({'a':[1,3,2,1],\\n        ...                       'b':['a','c','b','b'],\\n        ...                       'c':['x','y','z','y']})\\n        >>> sf\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        >>> sf.sort('a')\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a', descending\\n\\n        >>> sf.sort('a', ascending = False)\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 3 | c | y |\\n        | 2 | b | z |\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' and 'b', all ascending\\n\\n        >>> sf.sort(['a', 'b'])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | a | x |\\n        | 1 | b | y |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n\\n        To sort by column 'a' ascending, and then by column 'c' descending\\n\\n        >>> sf.sort([('a', True), ('c', False)])\\n        +---+---+---+\\n        | a | b | c |\\n        +---+---+---+\\n        | 1 | b | y |\\n        | 1 | a | x |\\n        | 2 | b | z |\\n        | 3 | c | y |\\n        +---+---+---+\\n        [4 rows x 3 columns]\\n        \"\n    sort_column_names = []\n    sort_column_orders = []\n    if type(key_column_names) == str:\n        sort_column_names = [key_column_names]\n    elif type(key_column_names) == list:\n        if len(key_column_names) == 0:\n            raise ValueError('Please provide at least one column to sort')\n        first_param_types = set([type(i) for i in key_column_names])\n        if len(first_param_types) != 1:\n            raise ValueError('key_column_names element are not of the same type')\n        first_param_type = first_param_types.pop()\n        if first_param_type == tuple:\n            sort_column_names = [i[0] for i in key_column_names]\n            sort_column_orders = [i[1] for i in key_column_names]\n        elif first_param_type == str:\n            sort_column_names = key_column_names\n        else:\n            raise TypeError('key_column_names type is not supported')\n    else:\n        raise TypeError('key_column_names type is not correct. Supported types are str, list of str or list of (str,bool) pair.')\n    if len(sort_column_orders) == 0:\n        sort_column_orders = [ascending for i in sort_column_names]\n    my_column_names = set(self.column_names())\n    for column in sort_column_names:\n        if type(column) != str:\n            raise TypeError('Only string parameter can be passed in as column names')\n        if column not in my_column_names:\n            raise ValueError(\"SFrame has no column named: '\" + str(column) + \"'\")\n        if self[column].dtype not in (str, int, float, datetime.datetime):\n            raise TypeError('Only columns of type (str, int, float) can be sorted')\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.sort(sort_column_names, sort_column_orders))"
        ]
    },
    {
        "func_name": "dropna",
        "original": "def dropna(self, columns=None, how='any', recursive=False):\n    \"\"\"\n        Remove missing values from an SFrame. A missing value is either ``None``\n        or ``NaN``.  If ``how`` is 'any', a row will be removed if any of the\n        columns in the ``columns`` parameter contains at least one missing\n        value.  If ``how`` is 'all', a row will be removed if all of the columns\n        in the ``columns`` parameter are missing values.\n\n        If the ``columns`` parameter is not specified, the default is to\n        consider all columns when searching for missing values.\n\n        Parameters\n        ----------\n        columns : list or str, optional\n            The columns to use when looking for missing values. By default, all\n            columns are used.\n\n        how : {'any', 'all'}, optional\n            Specifies whether a row should be dropped if at least one column\n            has missing values, or if all columns have missing values.  'any' is\n            default.\n\n        recursive: bool\n            By default is False. If this flag is set to True, then `nan` check will\n            be performed on each element of a sframe cell in a DFS manner if the cell\n            has a nested structure, such as dict, list.\n\n        Returns\n        -------\n        out : SFrame\n            SFrame with missing values removed (according to the given rules).\n\n        See Also\n        --------\n        dropna_split :  Drops missing rows from the SFrame and returns them.\n\n        Examples\n        --------\n        Drop all missing values.\n\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\n        >>> sf.dropna()\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | a |\n        +---+---+\n        [1 rows x 2 columns]\n\n        Drop rows where every value is missing.\n\n        >>> sf.dropna(any=\"all\")\n        +------+---+\n        |  a   | b |\n        +------+---+\n        |  1   | a |\n        | None | b |\n        +------+---+\n        [2 rows x 2 columns]\n\n        Drop rows where column 'a' has a missing value.\n\n        >>> sf.dropna('a', any=\"all\")\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | a |\n        +---+---+\n        [1 rows x 2 columns]\n        \"\"\"\n    if type(columns) is list and len(columns) == 0:\n        return SFrame(_proxy=self.__proxy__)\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.drop_missing_values(columns, all_behavior, False, recursive))",
        "mutated": [
            "def dropna(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n    '\\n        Remove missing values from an SFrame. A missing value is either ``None``\\n        or ``NaN``.  If ``how`` is \\'any\\', a row will be removed if any of the\\n        columns in the ``columns`` parameter contains at least one missing\\n        value.  If ``how`` is \\'all\\', a row will be removed if all of the columns\\n        in the ``columns`` parameter are missing values.\\n\\n        If the ``columns`` parameter is not specified, the default is to\\n        consider all columns when searching for missing values.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {\\'any\\', \\'all\\'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  \\'any\\' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a DFS manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            SFrame with missing values removed (according to the given rules).\\n\\n        See Also\\n        --------\\n        dropna_split :  Drops missing rows from the SFrame and returns them.\\n\\n        Examples\\n        --------\\n        Drop all missing values.\\n\\n        >>> sf = turicreate.SFrame({\\'a\\': [1, None, None], \\'b\\': [\\'a\\', \\'b\\', None]})\\n        >>> sf.dropna()\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        Drop rows where every value is missing.\\n\\n        >>> sf.dropna(any=\"all\")\\n        +------+---+\\n        |  a   | b |\\n        +------+---+\\n        |  1   | a |\\n        | None | b |\\n        +------+---+\\n        [2 rows x 2 columns]\\n\\n        Drop rows where column \\'a\\' has a missing value.\\n\\n        >>> sf.dropna(\\'a\\', any=\"all\")\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    if type(columns) is list and len(columns) == 0:\n        return SFrame(_proxy=self.__proxy__)\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.drop_missing_values(columns, all_behavior, False, recursive))",
            "def dropna(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Remove missing values from an SFrame. A missing value is either ``None``\\n        or ``NaN``.  If ``how`` is \\'any\\', a row will be removed if any of the\\n        columns in the ``columns`` parameter contains at least one missing\\n        value.  If ``how`` is \\'all\\', a row will be removed if all of the columns\\n        in the ``columns`` parameter are missing values.\\n\\n        If the ``columns`` parameter is not specified, the default is to\\n        consider all columns when searching for missing values.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {\\'any\\', \\'all\\'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  \\'any\\' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a DFS manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            SFrame with missing values removed (according to the given rules).\\n\\n        See Also\\n        --------\\n        dropna_split :  Drops missing rows from the SFrame and returns them.\\n\\n        Examples\\n        --------\\n        Drop all missing values.\\n\\n        >>> sf = turicreate.SFrame({\\'a\\': [1, None, None], \\'b\\': [\\'a\\', \\'b\\', None]})\\n        >>> sf.dropna()\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        Drop rows where every value is missing.\\n\\n        >>> sf.dropna(any=\"all\")\\n        +------+---+\\n        |  a   | b |\\n        +------+---+\\n        |  1   | a |\\n        | None | b |\\n        +------+---+\\n        [2 rows x 2 columns]\\n\\n        Drop rows where column \\'a\\' has a missing value.\\n\\n        >>> sf.dropna(\\'a\\', any=\"all\")\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    if type(columns) is list and len(columns) == 0:\n        return SFrame(_proxy=self.__proxy__)\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.drop_missing_values(columns, all_behavior, False, recursive))",
            "def dropna(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Remove missing values from an SFrame. A missing value is either ``None``\\n        or ``NaN``.  If ``how`` is \\'any\\', a row will be removed if any of the\\n        columns in the ``columns`` parameter contains at least one missing\\n        value.  If ``how`` is \\'all\\', a row will be removed if all of the columns\\n        in the ``columns`` parameter are missing values.\\n\\n        If the ``columns`` parameter is not specified, the default is to\\n        consider all columns when searching for missing values.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {\\'any\\', \\'all\\'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  \\'any\\' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a DFS manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            SFrame with missing values removed (according to the given rules).\\n\\n        See Also\\n        --------\\n        dropna_split :  Drops missing rows from the SFrame and returns them.\\n\\n        Examples\\n        --------\\n        Drop all missing values.\\n\\n        >>> sf = turicreate.SFrame({\\'a\\': [1, None, None], \\'b\\': [\\'a\\', \\'b\\', None]})\\n        >>> sf.dropna()\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        Drop rows where every value is missing.\\n\\n        >>> sf.dropna(any=\"all\")\\n        +------+---+\\n        |  a   | b |\\n        +------+---+\\n        |  1   | a |\\n        | None | b |\\n        +------+---+\\n        [2 rows x 2 columns]\\n\\n        Drop rows where column \\'a\\' has a missing value.\\n\\n        >>> sf.dropna(\\'a\\', any=\"all\")\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    if type(columns) is list and len(columns) == 0:\n        return SFrame(_proxy=self.__proxy__)\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.drop_missing_values(columns, all_behavior, False, recursive))",
            "def dropna(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Remove missing values from an SFrame. A missing value is either ``None``\\n        or ``NaN``.  If ``how`` is \\'any\\', a row will be removed if any of the\\n        columns in the ``columns`` parameter contains at least one missing\\n        value.  If ``how`` is \\'all\\', a row will be removed if all of the columns\\n        in the ``columns`` parameter are missing values.\\n\\n        If the ``columns`` parameter is not specified, the default is to\\n        consider all columns when searching for missing values.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {\\'any\\', \\'all\\'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  \\'any\\' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a DFS manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            SFrame with missing values removed (according to the given rules).\\n\\n        See Also\\n        --------\\n        dropna_split :  Drops missing rows from the SFrame and returns them.\\n\\n        Examples\\n        --------\\n        Drop all missing values.\\n\\n        >>> sf = turicreate.SFrame({\\'a\\': [1, None, None], \\'b\\': [\\'a\\', \\'b\\', None]})\\n        >>> sf.dropna()\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        Drop rows where every value is missing.\\n\\n        >>> sf.dropna(any=\"all\")\\n        +------+---+\\n        |  a   | b |\\n        +------+---+\\n        |  1   | a |\\n        | None | b |\\n        +------+---+\\n        [2 rows x 2 columns]\\n\\n        Drop rows where column \\'a\\' has a missing value.\\n\\n        >>> sf.dropna(\\'a\\', any=\"all\")\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    if type(columns) is list and len(columns) == 0:\n        return SFrame(_proxy=self.__proxy__)\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.drop_missing_values(columns, all_behavior, False, recursive))",
            "def dropna(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Remove missing values from an SFrame. A missing value is either ``None``\\n        or ``NaN``.  If ``how`` is \\'any\\', a row will be removed if any of the\\n        columns in the ``columns`` parameter contains at least one missing\\n        value.  If ``how`` is \\'all\\', a row will be removed if all of the columns\\n        in the ``columns`` parameter are missing values.\\n\\n        If the ``columns`` parameter is not specified, the default is to\\n        consider all columns when searching for missing values.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {\\'any\\', \\'all\\'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  \\'any\\' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a DFS manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            SFrame with missing values removed (according to the given rules).\\n\\n        See Also\\n        --------\\n        dropna_split :  Drops missing rows from the SFrame and returns them.\\n\\n        Examples\\n        --------\\n        Drop all missing values.\\n\\n        >>> sf = turicreate.SFrame({\\'a\\': [1, None, None], \\'b\\': [\\'a\\', \\'b\\', None]})\\n        >>> sf.dropna()\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        Drop rows where every value is missing.\\n\\n        >>> sf.dropna(any=\"all\")\\n        +------+---+\\n        |  a   | b |\\n        +------+---+\\n        |  1   | a |\\n        | None | b |\\n        +------+---+\\n        [2 rows x 2 columns]\\n\\n        Drop rows where column \\'a\\' has a missing value.\\n\\n        >>> sf.dropna(\\'a\\', any=\"all\")\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n        '\n    if type(columns) is list and len(columns) == 0:\n        return SFrame(_proxy=self.__proxy__)\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    with cython_context():\n        return SFrame(_proxy=self.__proxy__.drop_missing_values(columns, all_behavior, False, recursive))"
        ]
    },
    {
        "func_name": "dropna_split",
        "original": "def dropna_split(self, columns=None, how='any', recursive=False):\n    \"\"\"\n        Split rows with missing values from this SFrame. This function has the\n        same functionality as :py:func:`~turicreate.SFrame.dropna`, but returns a\n        tuple of two SFrames.  The first item is the expected output from\n        :py:func:`~turicreate.SFrame.dropna`, and the second item contains all the\n        rows filtered out by the `dropna` algorithm.\n\n        Parameters\n        ----------\n        columns : list or str, optional\n            The columns to use when looking for missing values. By default, all\n            columns are used.\n\n        how : {'any', 'all'}, optional\n            Specifies whether a row should be dropped if at least one column\n            has missing values, or if all columns have missing values.  'any' is\n            default.\n\n        recursive: bool\n            By default is False. If this flag is set to True, then `nan` check will\n            be performed on each element of a sframe cell in a recursive manner if the cell\n            has a nested structure, such as dict, list.\n\n\n        Returns\n        -------\n        out : (SFrame, SFrame)\n            (SFrame with missing values removed,\n             SFrame with the removed missing values)\n\n        See Also\n        --------\n        dropna\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\n        >>> good, bad = sf.dropna_split()\n        >>> good\n        +---+---+\n        | a | b |\n        +---+---+\n        | 1 | a |\n        +---+---+\n        [1 rows x 2 columns]\n\n        >>> bad\n        +------+------+\n        |  a   |  b   |\n        +------+------+\n        | None |  b   |\n        | None | None |\n        +------+------+\n        [2 rows x 2 columns]\n        \"\"\"\n    if type(columns) is list and len(columns) == 0:\n        return (SFrame(_proxy=self.__proxy__), SFrame())\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    sframe_tuple = self.__proxy__.drop_missing_values(columns, all_behavior, True, recursive)\n    if len(sframe_tuple) != 2:\n        raise RuntimeError('Did not return two SFrames!')\n    with cython_context():\n        return (SFrame(_proxy=sframe_tuple[0]), SFrame(_proxy=sframe_tuple[1]))",
        "mutated": [
            "def dropna_split(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n    \"\\n        Split rows with missing values from this SFrame. This function has the\\n        same functionality as :py:func:`~turicreate.SFrame.dropna`, but returns a\\n        tuple of two SFrames.  The first item is the expected output from\\n        :py:func:`~turicreate.SFrame.dropna`, and the second item contains all the\\n        rows filtered out by the `dropna` algorithm.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {'any', 'all'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  'any' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a recursive manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n\\n        Returns\\n        -------\\n        out : (SFrame, SFrame)\\n            (SFrame with missing values removed,\\n             SFrame with the removed missing values)\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> good, bad = sf.dropna_split()\\n        >>> good\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        >>> bad\\n        +------+------+\\n        |  a   |  b   |\\n        +------+------+\\n        | None |  b   |\\n        | None | None |\\n        +------+------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(columns) is list and len(columns) == 0:\n        return (SFrame(_proxy=self.__proxy__), SFrame())\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    sframe_tuple = self.__proxy__.drop_missing_values(columns, all_behavior, True, recursive)\n    if len(sframe_tuple) != 2:\n        raise RuntimeError('Did not return two SFrames!')\n    with cython_context():\n        return (SFrame(_proxy=sframe_tuple[0]), SFrame(_proxy=sframe_tuple[1]))",
            "def dropna_split(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Split rows with missing values from this SFrame. This function has the\\n        same functionality as :py:func:`~turicreate.SFrame.dropna`, but returns a\\n        tuple of two SFrames.  The first item is the expected output from\\n        :py:func:`~turicreate.SFrame.dropna`, and the second item contains all the\\n        rows filtered out by the `dropna` algorithm.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {'any', 'all'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  'any' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a recursive manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n\\n        Returns\\n        -------\\n        out : (SFrame, SFrame)\\n            (SFrame with missing values removed,\\n             SFrame with the removed missing values)\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> good, bad = sf.dropna_split()\\n        >>> good\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        >>> bad\\n        +------+------+\\n        |  a   |  b   |\\n        +------+------+\\n        | None |  b   |\\n        | None | None |\\n        +------+------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(columns) is list and len(columns) == 0:\n        return (SFrame(_proxy=self.__proxy__), SFrame())\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    sframe_tuple = self.__proxy__.drop_missing_values(columns, all_behavior, True, recursive)\n    if len(sframe_tuple) != 2:\n        raise RuntimeError('Did not return two SFrames!')\n    with cython_context():\n        return (SFrame(_proxy=sframe_tuple[0]), SFrame(_proxy=sframe_tuple[1]))",
            "def dropna_split(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Split rows with missing values from this SFrame. This function has the\\n        same functionality as :py:func:`~turicreate.SFrame.dropna`, but returns a\\n        tuple of two SFrames.  The first item is the expected output from\\n        :py:func:`~turicreate.SFrame.dropna`, and the second item contains all the\\n        rows filtered out by the `dropna` algorithm.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {'any', 'all'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  'any' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a recursive manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n\\n        Returns\\n        -------\\n        out : (SFrame, SFrame)\\n            (SFrame with missing values removed,\\n             SFrame with the removed missing values)\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> good, bad = sf.dropna_split()\\n        >>> good\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        >>> bad\\n        +------+------+\\n        |  a   |  b   |\\n        +------+------+\\n        | None |  b   |\\n        | None | None |\\n        +------+------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(columns) is list and len(columns) == 0:\n        return (SFrame(_proxy=self.__proxy__), SFrame())\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    sframe_tuple = self.__proxy__.drop_missing_values(columns, all_behavior, True, recursive)\n    if len(sframe_tuple) != 2:\n        raise RuntimeError('Did not return two SFrames!')\n    with cython_context():\n        return (SFrame(_proxy=sframe_tuple[0]), SFrame(_proxy=sframe_tuple[1]))",
            "def dropna_split(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Split rows with missing values from this SFrame. This function has the\\n        same functionality as :py:func:`~turicreate.SFrame.dropna`, but returns a\\n        tuple of two SFrames.  The first item is the expected output from\\n        :py:func:`~turicreate.SFrame.dropna`, and the second item contains all the\\n        rows filtered out by the `dropna` algorithm.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {'any', 'all'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  'any' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a recursive manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n\\n        Returns\\n        -------\\n        out : (SFrame, SFrame)\\n            (SFrame with missing values removed,\\n             SFrame with the removed missing values)\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> good, bad = sf.dropna_split()\\n        >>> good\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        >>> bad\\n        +------+------+\\n        |  a   |  b   |\\n        +------+------+\\n        | None |  b   |\\n        | None | None |\\n        +------+------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(columns) is list and len(columns) == 0:\n        return (SFrame(_proxy=self.__proxy__), SFrame())\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    sframe_tuple = self.__proxy__.drop_missing_values(columns, all_behavior, True, recursive)\n    if len(sframe_tuple) != 2:\n        raise RuntimeError('Did not return two SFrames!')\n    with cython_context():\n        return (SFrame(_proxy=sframe_tuple[0]), SFrame(_proxy=sframe_tuple[1]))",
            "def dropna_split(self, columns=None, how='any', recursive=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Split rows with missing values from this SFrame. This function has the\\n        same functionality as :py:func:`~turicreate.SFrame.dropna`, but returns a\\n        tuple of two SFrames.  The first item is the expected output from\\n        :py:func:`~turicreate.SFrame.dropna`, and the second item contains all the\\n        rows filtered out by the `dropna` algorithm.\\n\\n        Parameters\\n        ----------\\n        columns : list or str, optional\\n            The columns to use when looking for missing values. By default, all\\n            columns are used.\\n\\n        how : {'any', 'all'}, optional\\n            Specifies whether a row should be dropped if at least one column\\n            has missing values, or if all columns have missing values.  'any' is\\n            default.\\n\\n        recursive: bool\\n            By default is False. If this flag is set to True, then `nan` check will\\n            be performed on each element of a sframe cell in a recursive manner if the cell\\n            has a nested structure, such as dict, list.\\n\\n\\n        Returns\\n        -------\\n        out : (SFrame, SFrame)\\n            (SFrame with missing values removed,\\n             SFrame with the removed missing values)\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> good, bad = sf.dropna_split()\\n        >>> good\\n        +---+---+\\n        | a | b |\\n        +---+---+\\n        | 1 | a |\\n        +---+---+\\n        [1 rows x 2 columns]\\n\\n        >>> bad\\n        +------+------+\\n        |  a   |  b   |\\n        +------+------+\\n        | None |  b   |\\n        | None | None |\\n        +------+------+\\n        [2 rows x 2 columns]\\n        \"\n    if type(columns) is list and len(columns) == 0:\n        return (SFrame(_proxy=self.__proxy__), SFrame())\n    (columns, all_behavior) = self.__dropna_errchk(columns, how)\n    sframe_tuple = self.__proxy__.drop_missing_values(columns, all_behavior, True, recursive)\n    if len(sframe_tuple) != 2:\n        raise RuntimeError('Did not return two SFrames!')\n    with cython_context():\n        return (SFrame(_proxy=sframe_tuple[0]), SFrame(_proxy=sframe_tuple[1]))"
        ]
    },
    {
        "func_name": "__dropna_errchk",
        "original": "def __dropna_errchk(self, columns, how):\n    if columns is None:\n        columns = list()\n    elif type(columns) is str:\n        columns = [columns]\n    elif type(columns) is not list:\n        raise TypeError(\"Must give columns as a list, str, or 'None'\")\n    else:\n        list_types = set([type(i) for i in columns])\n        if str not in list_types or len(list_types) > 1:\n            raise TypeError(\"All columns must be of 'str' type\")\n    if how not in ['any', 'all']:\n        raise ValueError(\"Must specify 'any' or 'all'\")\n    if how == 'all':\n        all_behavior = True\n    else:\n        all_behavior = False\n    return (columns, all_behavior)",
        "mutated": [
            "def __dropna_errchk(self, columns, how):\n    if False:\n        i = 10\n    if columns is None:\n        columns = list()\n    elif type(columns) is str:\n        columns = [columns]\n    elif type(columns) is not list:\n        raise TypeError(\"Must give columns as a list, str, or 'None'\")\n    else:\n        list_types = set([type(i) for i in columns])\n        if str not in list_types or len(list_types) > 1:\n            raise TypeError(\"All columns must be of 'str' type\")\n    if how not in ['any', 'all']:\n        raise ValueError(\"Must specify 'any' or 'all'\")\n    if how == 'all':\n        all_behavior = True\n    else:\n        all_behavior = False\n    return (columns, all_behavior)",
            "def __dropna_errchk(self, columns, how):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if columns is None:\n        columns = list()\n    elif type(columns) is str:\n        columns = [columns]\n    elif type(columns) is not list:\n        raise TypeError(\"Must give columns as a list, str, or 'None'\")\n    else:\n        list_types = set([type(i) for i in columns])\n        if str not in list_types or len(list_types) > 1:\n            raise TypeError(\"All columns must be of 'str' type\")\n    if how not in ['any', 'all']:\n        raise ValueError(\"Must specify 'any' or 'all'\")\n    if how == 'all':\n        all_behavior = True\n    else:\n        all_behavior = False\n    return (columns, all_behavior)",
            "def __dropna_errchk(self, columns, how):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if columns is None:\n        columns = list()\n    elif type(columns) is str:\n        columns = [columns]\n    elif type(columns) is not list:\n        raise TypeError(\"Must give columns as a list, str, or 'None'\")\n    else:\n        list_types = set([type(i) for i in columns])\n        if str not in list_types or len(list_types) > 1:\n            raise TypeError(\"All columns must be of 'str' type\")\n    if how not in ['any', 'all']:\n        raise ValueError(\"Must specify 'any' or 'all'\")\n    if how == 'all':\n        all_behavior = True\n    else:\n        all_behavior = False\n    return (columns, all_behavior)",
            "def __dropna_errchk(self, columns, how):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if columns is None:\n        columns = list()\n    elif type(columns) is str:\n        columns = [columns]\n    elif type(columns) is not list:\n        raise TypeError(\"Must give columns as a list, str, or 'None'\")\n    else:\n        list_types = set([type(i) for i in columns])\n        if str not in list_types or len(list_types) > 1:\n            raise TypeError(\"All columns must be of 'str' type\")\n    if how not in ['any', 'all']:\n        raise ValueError(\"Must specify 'any' or 'all'\")\n    if how == 'all':\n        all_behavior = True\n    else:\n        all_behavior = False\n    return (columns, all_behavior)",
            "def __dropna_errchk(self, columns, how):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if columns is None:\n        columns = list()\n    elif type(columns) is str:\n        columns = [columns]\n    elif type(columns) is not list:\n        raise TypeError(\"Must give columns as a list, str, or 'None'\")\n    else:\n        list_types = set([type(i) for i in columns])\n        if str not in list_types or len(list_types) > 1:\n            raise TypeError(\"All columns must be of 'str' type\")\n    if how not in ['any', 'all']:\n        raise ValueError(\"Must specify 'any' or 'all'\")\n    if how == 'all':\n        all_behavior = True\n    else:\n        all_behavior = False\n    return (columns, all_behavior)"
        ]
    },
    {
        "func_name": "fillna",
        "original": "def fillna(self, column_name, value):\n    \"\"\"\n        Fill all missing values with a given value in a given column. If the\n        ``value`` is not the same type as the values in ``column_name``, this method\n        attempts to convert the value to the original column's type. If this\n        fails, an error is raised.\n\n        Parameters\n        ----------\n        column_name : str\n            The name of the column to modify.\n\n        value : type convertible to SArray's type\n            The value used to replace all missing values.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame with the specified value in place of missing values.\n\n        See Also\n        --------\n        dropna\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'a':[1, None, None],\n        ...                       'b':['13.1', '17.2', None]})\n        >>> sf = sf.fillna('a', 0)\n        >>> sf\n        +---+------+\n        | a |  b   |\n        +---+------+\n        | 1 | 13.1 |\n        | 0 | 17.2 |\n        | 0 | None |\n        +---+------+\n        [3 rows x 2 columns]\n        \"\"\"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a str')\n    ret = self[self.column_names()]\n    ret[column_name] = ret[column_name].fillna(value)\n    return ret",
        "mutated": [
            "def fillna(self, column_name, value):\n    if False:\n        i = 10\n    \"\\n        Fill all missing values with a given value in a given column. If the\\n        ``value`` is not the same type as the values in ``column_name``, this method\\n        attempts to convert the value to the original column's type. If this\\n        fails, an error is raised.\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            The name of the column to modify.\\n\\n        value : type convertible to SArray's type\\n            The value used to replace all missing values.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame with the specified value in place of missing values.\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a':[1, None, None],\\n        ...                       'b':['13.1', '17.2', None]})\\n        >>> sf = sf.fillna('a', 0)\\n        >>> sf\\n        +---+------+\\n        | a |  b   |\\n        +---+------+\\n        | 1 | 13.1 |\\n        | 0 | 17.2 |\\n        | 0 | None |\\n        +---+------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a str')\n    ret = self[self.column_names()]\n    ret[column_name] = ret[column_name].fillna(value)\n    return ret",
            "def fillna(self, column_name, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Fill all missing values with a given value in a given column. If the\\n        ``value`` is not the same type as the values in ``column_name``, this method\\n        attempts to convert the value to the original column's type. If this\\n        fails, an error is raised.\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            The name of the column to modify.\\n\\n        value : type convertible to SArray's type\\n            The value used to replace all missing values.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame with the specified value in place of missing values.\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a':[1, None, None],\\n        ...                       'b':['13.1', '17.2', None]})\\n        >>> sf = sf.fillna('a', 0)\\n        >>> sf\\n        +---+------+\\n        | a |  b   |\\n        +---+------+\\n        | 1 | 13.1 |\\n        | 0 | 17.2 |\\n        | 0 | None |\\n        +---+------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a str')\n    ret = self[self.column_names()]\n    ret[column_name] = ret[column_name].fillna(value)\n    return ret",
            "def fillna(self, column_name, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Fill all missing values with a given value in a given column. If the\\n        ``value`` is not the same type as the values in ``column_name``, this method\\n        attempts to convert the value to the original column's type. If this\\n        fails, an error is raised.\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            The name of the column to modify.\\n\\n        value : type convertible to SArray's type\\n            The value used to replace all missing values.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame with the specified value in place of missing values.\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a':[1, None, None],\\n        ...                       'b':['13.1', '17.2', None]})\\n        >>> sf = sf.fillna('a', 0)\\n        >>> sf\\n        +---+------+\\n        | a |  b   |\\n        +---+------+\\n        | 1 | 13.1 |\\n        | 0 | 17.2 |\\n        | 0 | None |\\n        +---+------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a str')\n    ret = self[self.column_names()]\n    ret[column_name] = ret[column_name].fillna(value)\n    return ret",
            "def fillna(self, column_name, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Fill all missing values with a given value in a given column. If the\\n        ``value`` is not the same type as the values in ``column_name``, this method\\n        attempts to convert the value to the original column's type. If this\\n        fails, an error is raised.\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            The name of the column to modify.\\n\\n        value : type convertible to SArray's type\\n            The value used to replace all missing values.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame with the specified value in place of missing values.\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a':[1, None, None],\\n        ...                       'b':['13.1', '17.2', None]})\\n        >>> sf = sf.fillna('a', 0)\\n        >>> sf\\n        +---+------+\\n        | a |  b   |\\n        +---+------+\\n        | 1 | 13.1 |\\n        | 0 | 17.2 |\\n        | 0 | None |\\n        +---+------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a str')\n    ret = self[self.column_names()]\n    ret[column_name] = ret[column_name].fillna(value)\n    return ret",
            "def fillna(self, column_name, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Fill all missing values with a given value in a given column. If the\\n        ``value`` is not the same type as the values in ``column_name``, this method\\n        attempts to convert the value to the original column's type. If this\\n        fails, an error is raised.\\n\\n        Parameters\\n        ----------\\n        column_name : str\\n            The name of the column to modify.\\n\\n        value : type convertible to SArray's type\\n            The value used to replace all missing values.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            A new SFrame with the specified value in place of missing values.\\n\\n        See Also\\n        --------\\n        dropna\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a':[1, None, None],\\n        ...                       'b':['13.1', '17.2', None]})\\n        >>> sf = sf.fillna('a', 0)\\n        >>> sf\\n        +---+------+\\n        | a |  b   |\\n        +---+------+\\n        | 1 | 13.1 |\\n        | 0 | 17.2 |\\n        | 0 | None |\\n        +---+------+\\n        [3 rows x 2 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('column_name must be a str')\n    ret = self[self.column_names()]\n    ret[column_name] = ret[column_name].fillna(value)\n    return ret"
        ]
    },
    {
        "func_name": "add_row_number",
        "original": "def add_row_number(self, column_name='id', start=0, inplace=False):\n    \"\"\"\n        Returns an SFrame with a new column that numbers each row\n        sequentially. By default the count starts at 0, but this can be changed\n        to a positive or negative number.  The new column will be named with\n        the given column name.  An error will be raised if the given column\n        name already exists in the SFrame.\n\n        If inplace == False (default) this operation does not modify the\n        current SFrame, returning a new SFrame.\n\n        If inplace == True, this operation modifies the current\n        SFrame, returning self.\n\n        Parameters\n        ----------\n        column_name : str, optional\n            The name of the new column that will hold the row numbers.\n\n        start : int, optional\n            The number used to start the row number count.\n\n\n        inplace : bool, optional. Defaults to False.\n            Whether the SFrame is modified in place.\n\n        Returns\n        -------\n        out : SFrame\n            The new SFrame with a column name\n\n        Notes\n        -----\n        The range of numbers is constrained by a signed 64-bit integer, so\n        beware of overflow if you think the results in the row number column\n        will be greater than 9 quintillion.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\n        >>> sf.add_row_number()\n        +----+------+------+\n        | id |  a   |  b   |\n        +----+------+------+\n        | 0  |  1   |  a   |\n        | 1  | None |  b   |\n        | 2  | None | None |\n        +----+------+------+\n        [3 rows x 3 columns]\n        \"\"\"\n    if type(column_name) is not str:\n        raise TypeError('Must give column_name as strs')\n    if type(start) is not int:\n        raise TypeError('Must give start as int')\n    if column_name in self.column_names():\n        raise RuntimeError(\"Column '\" + column_name + \"' already exists in the current SFrame\")\n    the_col = _create_sequential_sarray(self.num_rows(), start)\n    new_sf = SFrame()\n    new_sf.add_column(the_col, column_name, inplace=True)\n    new_sf.add_columns(self, inplace=True)\n    if inplace:\n        self.__proxy__ = new_sf.__proxy__\n        return self\n    else:\n        return new_sf",
        "mutated": [
            "def add_row_number(self, column_name='id', start=0, inplace=False):\n    if False:\n        i = 10\n    \"\\n        Returns an SFrame with a new column that numbers each row\\n        sequentially. By default the count starts at 0, but this can be changed\\n        to a positive or negative number.  The new column will be named with\\n        the given column name.  An error will be raised if the given column\\n        name already exists in the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            The name of the new column that will hold the row numbers.\\n\\n        start : int, optional\\n            The number used to start the row number count.\\n\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The new SFrame with a column name\\n\\n        Notes\\n        -----\\n        The range of numbers is constrained by a signed 64-bit integer, so\\n        beware of overflow if you think the results in the row number column\\n        will be greater than 9 quintillion.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> sf.add_row_number()\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 0  |  1   |  a   |\\n        | 1  | None |  b   |\\n        | 2  | None | None |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must give column_name as strs')\n    if type(start) is not int:\n        raise TypeError('Must give start as int')\n    if column_name in self.column_names():\n        raise RuntimeError(\"Column '\" + column_name + \"' already exists in the current SFrame\")\n    the_col = _create_sequential_sarray(self.num_rows(), start)\n    new_sf = SFrame()\n    new_sf.add_column(the_col, column_name, inplace=True)\n    new_sf.add_columns(self, inplace=True)\n    if inplace:\n        self.__proxy__ = new_sf.__proxy__\n        return self\n    else:\n        return new_sf",
            "def add_row_number(self, column_name='id', start=0, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns an SFrame with a new column that numbers each row\\n        sequentially. By default the count starts at 0, but this can be changed\\n        to a positive or negative number.  The new column will be named with\\n        the given column name.  An error will be raised if the given column\\n        name already exists in the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            The name of the new column that will hold the row numbers.\\n\\n        start : int, optional\\n            The number used to start the row number count.\\n\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The new SFrame with a column name\\n\\n        Notes\\n        -----\\n        The range of numbers is constrained by a signed 64-bit integer, so\\n        beware of overflow if you think the results in the row number column\\n        will be greater than 9 quintillion.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> sf.add_row_number()\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 0  |  1   |  a   |\\n        | 1  | None |  b   |\\n        | 2  | None | None |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must give column_name as strs')\n    if type(start) is not int:\n        raise TypeError('Must give start as int')\n    if column_name in self.column_names():\n        raise RuntimeError(\"Column '\" + column_name + \"' already exists in the current SFrame\")\n    the_col = _create_sequential_sarray(self.num_rows(), start)\n    new_sf = SFrame()\n    new_sf.add_column(the_col, column_name, inplace=True)\n    new_sf.add_columns(self, inplace=True)\n    if inplace:\n        self.__proxy__ = new_sf.__proxy__\n        return self\n    else:\n        return new_sf",
            "def add_row_number(self, column_name='id', start=0, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns an SFrame with a new column that numbers each row\\n        sequentially. By default the count starts at 0, but this can be changed\\n        to a positive or negative number.  The new column will be named with\\n        the given column name.  An error will be raised if the given column\\n        name already exists in the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            The name of the new column that will hold the row numbers.\\n\\n        start : int, optional\\n            The number used to start the row number count.\\n\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The new SFrame with a column name\\n\\n        Notes\\n        -----\\n        The range of numbers is constrained by a signed 64-bit integer, so\\n        beware of overflow if you think the results in the row number column\\n        will be greater than 9 quintillion.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> sf.add_row_number()\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 0  |  1   |  a   |\\n        | 1  | None |  b   |\\n        | 2  | None | None |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must give column_name as strs')\n    if type(start) is not int:\n        raise TypeError('Must give start as int')\n    if column_name in self.column_names():\n        raise RuntimeError(\"Column '\" + column_name + \"' already exists in the current SFrame\")\n    the_col = _create_sequential_sarray(self.num_rows(), start)\n    new_sf = SFrame()\n    new_sf.add_column(the_col, column_name, inplace=True)\n    new_sf.add_columns(self, inplace=True)\n    if inplace:\n        self.__proxy__ = new_sf.__proxy__\n        return self\n    else:\n        return new_sf",
            "def add_row_number(self, column_name='id', start=0, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns an SFrame with a new column that numbers each row\\n        sequentially. By default the count starts at 0, but this can be changed\\n        to a positive or negative number.  The new column will be named with\\n        the given column name.  An error will be raised if the given column\\n        name already exists in the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            The name of the new column that will hold the row numbers.\\n\\n        start : int, optional\\n            The number used to start the row number count.\\n\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The new SFrame with a column name\\n\\n        Notes\\n        -----\\n        The range of numbers is constrained by a signed 64-bit integer, so\\n        beware of overflow if you think the results in the row number column\\n        will be greater than 9 quintillion.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> sf.add_row_number()\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 0  |  1   |  a   |\\n        | 1  | None |  b   |\\n        | 2  | None | None |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must give column_name as strs')\n    if type(start) is not int:\n        raise TypeError('Must give start as int')\n    if column_name in self.column_names():\n        raise RuntimeError(\"Column '\" + column_name + \"' already exists in the current SFrame\")\n    the_col = _create_sequential_sarray(self.num_rows(), start)\n    new_sf = SFrame()\n    new_sf.add_column(the_col, column_name, inplace=True)\n    new_sf.add_columns(self, inplace=True)\n    if inplace:\n        self.__proxy__ = new_sf.__proxy__\n        return self\n    else:\n        return new_sf",
            "def add_row_number(self, column_name='id', start=0, inplace=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns an SFrame with a new column that numbers each row\\n        sequentially. By default the count starts at 0, but this can be changed\\n        to a positive or negative number.  The new column will be named with\\n        the given column name.  An error will be raised if the given column\\n        name already exists in the SFrame.\\n\\n        If inplace == False (default) this operation does not modify the\\n        current SFrame, returning a new SFrame.\\n\\n        If inplace == True, this operation modifies the current\\n        SFrame, returning self.\\n\\n        Parameters\\n        ----------\\n        column_name : str, optional\\n            The name of the new column that will hold the row numbers.\\n\\n        start : int, optional\\n            The number used to start the row number count.\\n\\n\\n        inplace : bool, optional. Defaults to False.\\n            Whether the SFrame is modified in place.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            The new SFrame with a column name\\n\\n        Notes\\n        -----\\n        The range of numbers is constrained by a signed 64-bit integer, so\\n        beware of overflow if you think the results in the row number column\\n        will be greater than 9 quintillion.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'a': [1, None, None], 'b': ['a', 'b', None]})\\n        >>> sf.add_row_number()\\n        +----+------+------+\\n        | id |  a   |  b   |\\n        +----+------+------+\\n        | 0  |  1   |  a   |\\n        | 1  | None |  b   |\\n        | 2  | None | None |\\n        +----+------+------+\\n        [3 rows x 3 columns]\\n        \"\n    if type(column_name) is not str:\n        raise TypeError('Must give column_name as strs')\n    if type(start) is not int:\n        raise TypeError('Must give start as int')\n    if column_name in self.column_names():\n        raise RuntimeError(\"Column '\" + column_name + \"' already exists in the current SFrame\")\n    the_col = _create_sequential_sarray(self.num_rows(), start)\n    new_sf = SFrame()\n    new_sf.add_column(the_col, column_name, inplace=True)\n    new_sf.add_columns(self, inplace=True)\n    if inplace:\n        self.__proxy__ = new_sf.__proxy__\n        return self\n    else:\n        return new_sf"
        ]
    },
    {
        "func_name": "shape",
        "original": "@property\ndef shape(self):\n    \"\"\"\n        The shape of the SFrame, in a tuple. The first entry is the number of\n        rows, the second is the number of columns.\n\n        Examples\n        --------\n        >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\n        >>> sf.shape\n        (3, 2)\n        \"\"\"\n    return (self.num_rows(), self.num_columns())",
        "mutated": [
            "@property\ndef shape(self):\n    if False:\n        i = 10\n    \"\\n        The shape of the SFrame, in a tuple. The first entry is the number of\\n        rows, the second is the number of columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n        >>> sf.shape\\n        (3, 2)\\n        \"\n    return (self.num_rows(), self.num_columns())",
            "@property\ndef shape(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        The shape of the SFrame, in a tuple. The first entry is the number of\\n        rows, the second is the number of columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n        >>> sf.shape\\n        (3, 2)\\n        \"\n    return (self.num_rows(), self.num_columns())",
            "@property\ndef shape(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        The shape of the SFrame, in a tuple. The first entry is the number of\\n        rows, the second is the number of columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n        >>> sf.shape\\n        (3, 2)\\n        \"\n    return (self.num_rows(), self.num_columns())",
            "@property\ndef shape(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        The shape of the SFrame, in a tuple. The first entry is the number of\\n        rows, the second is the number of columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n        >>> sf.shape\\n        (3, 2)\\n        \"\n    return (self.num_rows(), self.num_columns())",
            "@property\ndef shape(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        The shape of the SFrame, in a tuple. The first entry is the number of\\n        rows, the second is the number of columns.\\n\\n        Examples\\n        --------\\n        >>> sf = turicreate.SFrame({'id':[1,2,3], 'val':['A','B','C']})\\n        >>> sf.shape\\n        (3, 2)\\n        \"\n    return (self.num_rows(), self.num_columns())"
        ]
    },
    {
        "func_name": "__proxy__",
        "original": "@property\ndef __proxy__(self):\n    return self._proxy",
        "mutated": [
            "@property\ndef __proxy__(self):\n    if False:\n        i = 10\n    return self._proxy",
            "@property\ndef __proxy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self._proxy",
            "@property\ndef __proxy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self._proxy",
            "@property\ndef __proxy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self._proxy",
            "@property\ndef __proxy__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self._proxy"
        ]
    },
    {
        "func_name": "__proxy__",
        "original": "@__proxy__.setter\ndef __proxy__(self, value):\n    assert type(value) is UnitySFrameProxy\n    self._cache = None\n    self._proxy = value\n    self._cache = None",
        "mutated": [
            "@__proxy__.setter\ndef __proxy__(self, value):\n    if False:\n        i = 10\n    assert type(value) is UnitySFrameProxy\n    self._cache = None\n    self._proxy = value\n    self._cache = None",
            "@__proxy__.setter\ndef __proxy__(self, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert type(value) is UnitySFrameProxy\n    self._cache = None\n    self._proxy = value\n    self._cache = None",
            "@__proxy__.setter\ndef __proxy__(self, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert type(value) is UnitySFrameProxy\n    self._cache = None\n    self._proxy = value\n    self._cache = None",
            "@__proxy__.setter\ndef __proxy__(self, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert type(value) is UnitySFrameProxy\n    self._cache = None\n    self._proxy = value\n    self._cache = None",
            "@__proxy__.setter\ndef __proxy__(self, value):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert type(value) is UnitySFrameProxy\n    self._cache = None\n    self._proxy = value\n    self._cache = None"
        ]
    }
]