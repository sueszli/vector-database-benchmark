[
    {
        "func_name": "get_edge_indices",
        "original": "def get_edge_indices(img_metas, downsample_ratio, step=1, pad_mode='default', dtype=np.float32, device='cpu'):\n    \"\"\"Function to filter the objects label outside the image.\n    The edge_indices are generated using numpy on cpu rather\n    than on CUDA due to the latency issue. When batch size = 8,\n    this function with numpy array is ~8 times faster than that\n    with CUDA tensor (0.09s and 0.72s in 100 runs).\n\n    Args:\n        img_metas (list[dict]): Meta information of each image, e.g.,\n            image size, scaling factor, etc.\n        downsample_ratio (int): Downsample ratio of output feature,\n        step (int, optional): Step size used for generateing\n            edge indices. Default: 1.\n        pad_mode (str, optional): Padding mode during data pipeline.\n            Default: 'default'.\n        dtype (torch.dtype, optional): Dtype of edge indices tensor.\n            Default: np.float32.\n        device (str, optional): Device of edge indices tensor.\n            Default: 'cpu'.\n\n    Returns:\n        list[Tensor]: Edge indices for each image in batch data.\n    \"\"\"\n    edge_indices_list = []\n    for i in range(len(img_metas)):\n        img_shape = img_metas[i]['img_shape']\n        pad_shape = img_metas[i]['pad_shape']\n        (h, w) = img_shape[:2]\n        (pad_h, pad_w) = pad_shape\n        edge_indices = []\n        if pad_mode == 'default':\n            x_min = 0\n            y_min = 0\n            x_max = (w - 1) // downsample_ratio\n            y_max = (h - 1) // downsample_ratio\n        elif pad_mode == 'center':\n            x_min = np.ceil((pad_w - w) / 2 * downsample_ratio)\n            y_min = np.ceil((pad_h - h) / 2 * downsample_ratio)\n            x_max = x_min + w // downsample_ratio\n            y_max = y_min + h // downsample_ratio\n        else:\n            raise NotImplementedError\n        y = np.arange(y_min, y_max, step, dtype=dtype)\n        x = np.ones(len(y)) * x_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_min, x_max, step, dtype=dtype)\n        y = np.ones(len(x)) * y_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        y = np.arange(y_max, y_min, -step, dtype=dtype)\n        x = np.ones(len(y)) * x_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_max, x_min, -step, dtype=dtype)\n        y = np.ones(len(x)) * y_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        edge_indices = np.concatenate([index for index in edge_indices], axis=0)\n        edge_indices = torch.from_numpy(edge_indices).to(device).long()\n        edge_indices_list.append(edge_indices)\n    return edge_indices_list",
        "mutated": [
            "def get_edge_indices(img_metas, downsample_ratio, step=1, pad_mode='default', dtype=np.float32, device='cpu'):\n    if False:\n        i = 10\n    \"Function to filter the objects label outside the image.\\n    The edge_indices are generated using numpy on cpu rather\\n    than on CUDA due to the latency issue. When batch size = 8,\\n    this function with numpy array is ~8 times faster than that\\n    with CUDA tensor (0.09s and 0.72s in 100 runs).\\n\\n    Args:\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n        downsample_ratio (int): Downsample ratio of output feature,\\n        step (int, optional): Step size used for generateing\\n            edge indices. Default: 1.\\n        pad_mode (str, optional): Padding mode during data pipeline.\\n            Default: 'default'.\\n        dtype (torch.dtype, optional): Dtype of edge indices tensor.\\n            Default: np.float32.\\n        device (str, optional): Device of edge indices tensor.\\n            Default: 'cpu'.\\n\\n    Returns:\\n        list[Tensor]: Edge indices for each image in batch data.\\n    \"\n    edge_indices_list = []\n    for i in range(len(img_metas)):\n        img_shape = img_metas[i]['img_shape']\n        pad_shape = img_metas[i]['pad_shape']\n        (h, w) = img_shape[:2]\n        (pad_h, pad_w) = pad_shape\n        edge_indices = []\n        if pad_mode == 'default':\n            x_min = 0\n            y_min = 0\n            x_max = (w - 1) // downsample_ratio\n            y_max = (h - 1) // downsample_ratio\n        elif pad_mode == 'center':\n            x_min = np.ceil((pad_w - w) / 2 * downsample_ratio)\n            y_min = np.ceil((pad_h - h) / 2 * downsample_ratio)\n            x_max = x_min + w // downsample_ratio\n            y_max = y_min + h // downsample_ratio\n        else:\n            raise NotImplementedError\n        y = np.arange(y_min, y_max, step, dtype=dtype)\n        x = np.ones(len(y)) * x_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_min, x_max, step, dtype=dtype)\n        y = np.ones(len(x)) * y_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        y = np.arange(y_max, y_min, -step, dtype=dtype)\n        x = np.ones(len(y)) * x_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_max, x_min, -step, dtype=dtype)\n        y = np.ones(len(x)) * y_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        edge_indices = np.concatenate([index for index in edge_indices], axis=0)\n        edge_indices = torch.from_numpy(edge_indices).to(device).long()\n        edge_indices_list.append(edge_indices)\n    return edge_indices_list",
            "def get_edge_indices(img_metas, downsample_ratio, step=1, pad_mode='default', dtype=np.float32, device='cpu'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Function to filter the objects label outside the image.\\n    The edge_indices are generated using numpy on cpu rather\\n    than on CUDA due to the latency issue. When batch size = 8,\\n    this function with numpy array is ~8 times faster than that\\n    with CUDA tensor (0.09s and 0.72s in 100 runs).\\n\\n    Args:\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n        downsample_ratio (int): Downsample ratio of output feature,\\n        step (int, optional): Step size used for generateing\\n            edge indices. Default: 1.\\n        pad_mode (str, optional): Padding mode during data pipeline.\\n            Default: 'default'.\\n        dtype (torch.dtype, optional): Dtype of edge indices tensor.\\n            Default: np.float32.\\n        device (str, optional): Device of edge indices tensor.\\n            Default: 'cpu'.\\n\\n    Returns:\\n        list[Tensor]: Edge indices for each image in batch data.\\n    \"\n    edge_indices_list = []\n    for i in range(len(img_metas)):\n        img_shape = img_metas[i]['img_shape']\n        pad_shape = img_metas[i]['pad_shape']\n        (h, w) = img_shape[:2]\n        (pad_h, pad_w) = pad_shape\n        edge_indices = []\n        if pad_mode == 'default':\n            x_min = 0\n            y_min = 0\n            x_max = (w - 1) // downsample_ratio\n            y_max = (h - 1) // downsample_ratio\n        elif pad_mode == 'center':\n            x_min = np.ceil((pad_w - w) / 2 * downsample_ratio)\n            y_min = np.ceil((pad_h - h) / 2 * downsample_ratio)\n            x_max = x_min + w // downsample_ratio\n            y_max = y_min + h // downsample_ratio\n        else:\n            raise NotImplementedError\n        y = np.arange(y_min, y_max, step, dtype=dtype)\n        x = np.ones(len(y)) * x_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_min, x_max, step, dtype=dtype)\n        y = np.ones(len(x)) * y_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        y = np.arange(y_max, y_min, -step, dtype=dtype)\n        x = np.ones(len(y)) * x_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_max, x_min, -step, dtype=dtype)\n        y = np.ones(len(x)) * y_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        edge_indices = np.concatenate([index for index in edge_indices], axis=0)\n        edge_indices = torch.from_numpy(edge_indices).to(device).long()\n        edge_indices_list.append(edge_indices)\n    return edge_indices_list",
            "def get_edge_indices(img_metas, downsample_ratio, step=1, pad_mode='default', dtype=np.float32, device='cpu'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Function to filter the objects label outside the image.\\n    The edge_indices are generated using numpy on cpu rather\\n    than on CUDA due to the latency issue. When batch size = 8,\\n    this function with numpy array is ~8 times faster than that\\n    with CUDA tensor (0.09s and 0.72s in 100 runs).\\n\\n    Args:\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n        downsample_ratio (int): Downsample ratio of output feature,\\n        step (int, optional): Step size used for generateing\\n            edge indices. Default: 1.\\n        pad_mode (str, optional): Padding mode during data pipeline.\\n            Default: 'default'.\\n        dtype (torch.dtype, optional): Dtype of edge indices tensor.\\n            Default: np.float32.\\n        device (str, optional): Device of edge indices tensor.\\n            Default: 'cpu'.\\n\\n    Returns:\\n        list[Tensor]: Edge indices for each image in batch data.\\n    \"\n    edge_indices_list = []\n    for i in range(len(img_metas)):\n        img_shape = img_metas[i]['img_shape']\n        pad_shape = img_metas[i]['pad_shape']\n        (h, w) = img_shape[:2]\n        (pad_h, pad_w) = pad_shape\n        edge_indices = []\n        if pad_mode == 'default':\n            x_min = 0\n            y_min = 0\n            x_max = (w - 1) // downsample_ratio\n            y_max = (h - 1) // downsample_ratio\n        elif pad_mode == 'center':\n            x_min = np.ceil((pad_w - w) / 2 * downsample_ratio)\n            y_min = np.ceil((pad_h - h) / 2 * downsample_ratio)\n            x_max = x_min + w // downsample_ratio\n            y_max = y_min + h // downsample_ratio\n        else:\n            raise NotImplementedError\n        y = np.arange(y_min, y_max, step, dtype=dtype)\n        x = np.ones(len(y)) * x_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_min, x_max, step, dtype=dtype)\n        y = np.ones(len(x)) * y_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        y = np.arange(y_max, y_min, -step, dtype=dtype)\n        x = np.ones(len(y)) * x_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_max, x_min, -step, dtype=dtype)\n        y = np.ones(len(x)) * y_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        edge_indices = np.concatenate([index for index in edge_indices], axis=0)\n        edge_indices = torch.from_numpy(edge_indices).to(device).long()\n        edge_indices_list.append(edge_indices)\n    return edge_indices_list",
            "def get_edge_indices(img_metas, downsample_ratio, step=1, pad_mode='default', dtype=np.float32, device='cpu'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Function to filter the objects label outside the image.\\n    The edge_indices are generated using numpy on cpu rather\\n    than on CUDA due to the latency issue. When batch size = 8,\\n    this function with numpy array is ~8 times faster than that\\n    with CUDA tensor (0.09s and 0.72s in 100 runs).\\n\\n    Args:\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n        downsample_ratio (int): Downsample ratio of output feature,\\n        step (int, optional): Step size used for generateing\\n            edge indices. Default: 1.\\n        pad_mode (str, optional): Padding mode during data pipeline.\\n            Default: 'default'.\\n        dtype (torch.dtype, optional): Dtype of edge indices tensor.\\n            Default: np.float32.\\n        device (str, optional): Device of edge indices tensor.\\n            Default: 'cpu'.\\n\\n    Returns:\\n        list[Tensor]: Edge indices for each image in batch data.\\n    \"\n    edge_indices_list = []\n    for i in range(len(img_metas)):\n        img_shape = img_metas[i]['img_shape']\n        pad_shape = img_metas[i]['pad_shape']\n        (h, w) = img_shape[:2]\n        (pad_h, pad_w) = pad_shape\n        edge_indices = []\n        if pad_mode == 'default':\n            x_min = 0\n            y_min = 0\n            x_max = (w - 1) // downsample_ratio\n            y_max = (h - 1) // downsample_ratio\n        elif pad_mode == 'center':\n            x_min = np.ceil((pad_w - w) / 2 * downsample_ratio)\n            y_min = np.ceil((pad_h - h) / 2 * downsample_ratio)\n            x_max = x_min + w // downsample_ratio\n            y_max = y_min + h // downsample_ratio\n        else:\n            raise NotImplementedError\n        y = np.arange(y_min, y_max, step, dtype=dtype)\n        x = np.ones(len(y)) * x_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_min, x_max, step, dtype=dtype)\n        y = np.ones(len(x)) * y_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        y = np.arange(y_max, y_min, -step, dtype=dtype)\n        x = np.ones(len(y)) * x_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_max, x_min, -step, dtype=dtype)\n        y = np.ones(len(x)) * y_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        edge_indices = np.concatenate([index for index in edge_indices], axis=0)\n        edge_indices = torch.from_numpy(edge_indices).to(device).long()\n        edge_indices_list.append(edge_indices)\n    return edge_indices_list",
            "def get_edge_indices(img_metas, downsample_ratio, step=1, pad_mode='default', dtype=np.float32, device='cpu'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Function to filter the objects label outside the image.\\n    The edge_indices are generated using numpy on cpu rather\\n    than on CUDA due to the latency issue. When batch size = 8,\\n    this function with numpy array is ~8 times faster than that\\n    with CUDA tensor (0.09s and 0.72s in 100 runs).\\n\\n    Args:\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n        downsample_ratio (int): Downsample ratio of output feature,\\n        step (int, optional): Step size used for generateing\\n            edge indices. Default: 1.\\n        pad_mode (str, optional): Padding mode during data pipeline.\\n            Default: 'default'.\\n        dtype (torch.dtype, optional): Dtype of edge indices tensor.\\n            Default: np.float32.\\n        device (str, optional): Device of edge indices tensor.\\n            Default: 'cpu'.\\n\\n    Returns:\\n        list[Tensor]: Edge indices for each image in batch data.\\n    \"\n    edge_indices_list = []\n    for i in range(len(img_metas)):\n        img_shape = img_metas[i]['img_shape']\n        pad_shape = img_metas[i]['pad_shape']\n        (h, w) = img_shape[:2]\n        (pad_h, pad_w) = pad_shape\n        edge_indices = []\n        if pad_mode == 'default':\n            x_min = 0\n            y_min = 0\n            x_max = (w - 1) // downsample_ratio\n            y_max = (h - 1) // downsample_ratio\n        elif pad_mode == 'center':\n            x_min = np.ceil((pad_w - w) / 2 * downsample_ratio)\n            y_min = np.ceil((pad_h - h) / 2 * downsample_ratio)\n            x_max = x_min + w // downsample_ratio\n            y_max = y_min + h // downsample_ratio\n        else:\n            raise NotImplementedError\n        y = np.arange(y_min, y_max, step, dtype=dtype)\n        x = np.ones(len(y)) * x_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_min, x_max, step, dtype=dtype)\n        y = np.ones(len(x)) * y_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        y = np.arange(y_max, y_min, -step, dtype=dtype)\n        x = np.ones(len(y)) * x_max\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        x = np.arange(x_max, x_min, -step, dtype=dtype)\n        y = np.ones(len(x)) * y_min\n        edge_indices_edge = np.stack((x, y), axis=1)\n        edge_indices.append(edge_indices_edge)\n        edge_indices = np.concatenate([index for index in edge_indices], axis=0)\n        edge_indices = torch.from_numpy(edge_indices).to(device).long()\n        edge_indices_list.append(edge_indices)\n    return edge_indices_list"
        ]
    }
]