[
    {
        "func_name": "_build_seq_graph",
        "original": "def _build_seq_graph(self):\n    \"\"\"The main function to create sli_rec model.\n\n        Returns:\n            object: the output of sli_rec section.\n        \"\"\"\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('sli_rec'):\n        hist_input = tf.concat([self.item_history_embedding, self.cate_history_embedding], 2)\n        self.mask = self.iterator.mask\n        self.sequence_length = tf.reduce_sum(input_tensor=self.mask, axis=1)\n        with tf.compat.v1.variable_scope('long_term_asvd'):\n            att_outputs1 = self._attention(hist_input, hparams.attention_size)\n            att_fea1 = tf.reduce_sum(input_tensor=att_outputs1, axis=1)\n            tf.compat.v1.summary.histogram('att_fea1', att_fea1)\n        item_history_embedding_new = tf.concat([self.item_history_embedding, tf.expand_dims(self.iterator.time_from_first_action, -1)], -1)\n        item_history_embedding_new = tf.concat([item_history_embedding_new, tf.expand_dims(self.iterator.time_to_now, -1)], -1)\n        with tf.compat.v1.variable_scope('rnn'):\n            (rnn_outputs, _) = dynamic_rnn(Time4LSTMCell(hparams.hidden_size), inputs=item_history_embedding_new, sequence_length=self.sequence_length, dtype=tf.float32, scope='time4lstm')\n            tf.compat.v1.summary.histogram('LSTM_outputs', rnn_outputs)\n        with tf.compat.v1.variable_scope('attention_fcn'):\n            att_outputs2 = self._attention_fcn(self.target_item_embedding, rnn_outputs)\n            att_fea2 = tf.reduce_sum(input_tensor=att_outputs2, axis=1)\n            tf.compat.v1.summary.histogram('att_fea2', att_fea2)\n        with tf.compat.v1.name_scope('alpha'):\n            concat_all = tf.concat([self.target_item_embedding, att_fea1, att_fea2, tf.expand_dims(self.iterator.time_to_now[:, -1], -1)], 1)\n            last_hidden_nn_layer = concat_all\n            alpha_logit = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='fcn_alpha')\n            alpha_output = tf.sigmoid(alpha_logit)\n            user_embed = att_fea1 * alpha_output + att_fea2 * (1.0 - alpha_output)\n        model_output = tf.concat([user_embed, self.target_item_embedding], 1)\n        tf.compat.v1.summary.histogram('model_output', model_output)\n        return model_output",
        "mutated": [
            "def _build_seq_graph(self):\n    if False:\n        i = 10\n    'The main function to create sli_rec model.\\n\\n        Returns:\\n            object: the output of sli_rec section.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('sli_rec'):\n        hist_input = tf.concat([self.item_history_embedding, self.cate_history_embedding], 2)\n        self.mask = self.iterator.mask\n        self.sequence_length = tf.reduce_sum(input_tensor=self.mask, axis=1)\n        with tf.compat.v1.variable_scope('long_term_asvd'):\n            att_outputs1 = self._attention(hist_input, hparams.attention_size)\n            att_fea1 = tf.reduce_sum(input_tensor=att_outputs1, axis=1)\n            tf.compat.v1.summary.histogram('att_fea1', att_fea1)\n        item_history_embedding_new = tf.concat([self.item_history_embedding, tf.expand_dims(self.iterator.time_from_first_action, -1)], -1)\n        item_history_embedding_new = tf.concat([item_history_embedding_new, tf.expand_dims(self.iterator.time_to_now, -1)], -1)\n        with tf.compat.v1.variable_scope('rnn'):\n            (rnn_outputs, _) = dynamic_rnn(Time4LSTMCell(hparams.hidden_size), inputs=item_history_embedding_new, sequence_length=self.sequence_length, dtype=tf.float32, scope='time4lstm')\n            tf.compat.v1.summary.histogram('LSTM_outputs', rnn_outputs)\n        with tf.compat.v1.variable_scope('attention_fcn'):\n            att_outputs2 = self._attention_fcn(self.target_item_embedding, rnn_outputs)\n            att_fea2 = tf.reduce_sum(input_tensor=att_outputs2, axis=1)\n            tf.compat.v1.summary.histogram('att_fea2', att_fea2)\n        with tf.compat.v1.name_scope('alpha'):\n            concat_all = tf.concat([self.target_item_embedding, att_fea1, att_fea2, tf.expand_dims(self.iterator.time_to_now[:, -1], -1)], 1)\n            last_hidden_nn_layer = concat_all\n            alpha_logit = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='fcn_alpha')\n            alpha_output = tf.sigmoid(alpha_logit)\n            user_embed = att_fea1 * alpha_output + att_fea2 * (1.0 - alpha_output)\n        model_output = tf.concat([user_embed, self.target_item_embedding], 1)\n        tf.compat.v1.summary.histogram('model_output', model_output)\n        return model_output",
            "def _build_seq_graph(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'The main function to create sli_rec model.\\n\\n        Returns:\\n            object: the output of sli_rec section.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('sli_rec'):\n        hist_input = tf.concat([self.item_history_embedding, self.cate_history_embedding], 2)\n        self.mask = self.iterator.mask\n        self.sequence_length = tf.reduce_sum(input_tensor=self.mask, axis=1)\n        with tf.compat.v1.variable_scope('long_term_asvd'):\n            att_outputs1 = self._attention(hist_input, hparams.attention_size)\n            att_fea1 = tf.reduce_sum(input_tensor=att_outputs1, axis=1)\n            tf.compat.v1.summary.histogram('att_fea1', att_fea1)\n        item_history_embedding_new = tf.concat([self.item_history_embedding, tf.expand_dims(self.iterator.time_from_first_action, -1)], -1)\n        item_history_embedding_new = tf.concat([item_history_embedding_new, tf.expand_dims(self.iterator.time_to_now, -1)], -1)\n        with tf.compat.v1.variable_scope('rnn'):\n            (rnn_outputs, _) = dynamic_rnn(Time4LSTMCell(hparams.hidden_size), inputs=item_history_embedding_new, sequence_length=self.sequence_length, dtype=tf.float32, scope='time4lstm')\n            tf.compat.v1.summary.histogram('LSTM_outputs', rnn_outputs)\n        with tf.compat.v1.variable_scope('attention_fcn'):\n            att_outputs2 = self._attention_fcn(self.target_item_embedding, rnn_outputs)\n            att_fea2 = tf.reduce_sum(input_tensor=att_outputs2, axis=1)\n            tf.compat.v1.summary.histogram('att_fea2', att_fea2)\n        with tf.compat.v1.name_scope('alpha'):\n            concat_all = tf.concat([self.target_item_embedding, att_fea1, att_fea2, tf.expand_dims(self.iterator.time_to_now[:, -1], -1)], 1)\n            last_hidden_nn_layer = concat_all\n            alpha_logit = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='fcn_alpha')\n            alpha_output = tf.sigmoid(alpha_logit)\n            user_embed = att_fea1 * alpha_output + att_fea2 * (1.0 - alpha_output)\n        model_output = tf.concat([user_embed, self.target_item_embedding], 1)\n        tf.compat.v1.summary.histogram('model_output', model_output)\n        return model_output",
            "def _build_seq_graph(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'The main function to create sli_rec model.\\n\\n        Returns:\\n            object: the output of sli_rec section.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('sli_rec'):\n        hist_input = tf.concat([self.item_history_embedding, self.cate_history_embedding], 2)\n        self.mask = self.iterator.mask\n        self.sequence_length = tf.reduce_sum(input_tensor=self.mask, axis=1)\n        with tf.compat.v1.variable_scope('long_term_asvd'):\n            att_outputs1 = self._attention(hist_input, hparams.attention_size)\n            att_fea1 = tf.reduce_sum(input_tensor=att_outputs1, axis=1)\n            tf.compat.v1.summary.histogram('att_fea1', att_fea1)\n        item_history_embedding_new = tf.concat([self.item_history_embedding, tf.expand_dims(self.iterator.time_from_first_action, -1)], -1)\n        item_history_embedding_new = tf.concat([item_history_embedding_new, tf.expand_dims(self.iterator.time_to_now, -1)], -1)\n        with tf.compat.v1.variable_scope('rnn'):\n            (rnn_outputs, _) = dynamic_rnn(Time4LSTMCell(hparams.hidden_size), inputs=item_history_embedding_new, sequence_length=self.sequence_length, dtype=tf.float32, scope='time4lstm')\n            tf.compat.v1.summary.histogram('LSTM_outputs', rnn_outputs)\n        with tf.compat.v1.variable_scope('attention_fcn'):\n            att_outputs2 = self._attention_fcn(self.target_item_embedding, rnn_outputs)\n            att_fea2 = tf.reduce_sum(input_tensor=att_outputs2, axis=1)\n            tf.compat.v1.summary.histogram('att_fea2', att_fea2)\n        with tf.compat.v1.name_scope('alpha'):\n            concat_all = tf.concat([self.target_item_embedding, att_fea1, att_fea2, tf.expand_dims(self.iterator.time_to_now[:, -1], -1)], 1)\n            last_hidden_nn_layer = concat_all\n            alpha_logit = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='fcn_alpha')\n            alpha_output = tf.sigmoid(alpha_logit)\n            user_embed = att_fea1 * alpha_output + att_fea2 * (1.0 - alpha_output)\n        model_output = tf.concat([user_embed, self.target_item_embedding], 1)\n        tf.compat.v1.summary.histogram('model_output', model_output)\n        return model_output",
            "def _build_seq_graph(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'The main function to create sli_rec model.\\n\\n        Returns:\\n            object: the output of sli_rec section.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('sli_rec'):\n        hist_input = tf.concat([self.item_history_embedding, self.cate_history_embedding], 2)\n        self.mask = self.iterator.mask\n        self.sequence_length = tf.reduce_sum(input_tensor=self.mask, axis=1)\n        with tf.compat.v1.variable_scope('long_term_asvd'):\n            att_outputs1 = self._attention(hist_input, hparams.attention_size)\n            att_fea1 = tf.reduce_sum(input_tensor=att_outputs1, axis=1)\n            tf.compat.v1.summary.histogram('att_fea1', att_fea1)\n        item_history_embedding_new = tf.concat([self.item_history_embedding, tf.expand_dims(self.iterator.time_from_first_action, -1)], -1)\n        item_history_embedding_new = tf.concat([item_history_embedding_new, tf.expand_dims(self.iterator.time_to_now, -1)], -1)\n        with tf.compat.v1.variable_scope('rnn'):\n            (rnn_outputs, _) = dynamic_rnn(Time4LSTMCell(hparams.hidden_size), inputs=item_history_embedding_new, sequence_length=self.sequence_length, dtype=tf.float32, scope='time4lstm')\n            tf.compat.v1.summary.histogram('LSTM_outputs', rnn_outputs)\n        with tf.compat.v1.variable_scope('attention_fcn'):\n            att_outputs2 = self._attention_fcn(self.target_item_embedding, rnn_outputs)\n            att_fea2 = tf.reduce_sum(input_tensor=att_outputs2, axis=1)\n            tf.compat.v1.summary.histogram('att_fea2', att_fea2)\n        with tf.compat.v1.name_scope('alpha'):\n            concat_all = tf.concat([self.target_item_embedding, att_fea1, att_fea2, tf.expand_dims(self.iterator.time_to_now[:, -1], -1)], 1)\n            last_hidden_nn_layer = concat_all\n            alpha_logit = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='fcn_alpha')\n            alpha_output = tf.sigmoid(alpha_logit)\n            user_embed = att_fea1 * alpha_output + att_fea2 * (1.0 - alpha_output)\n        model_output = tf.concat([user_embed, self.target_item_embedding], 1)\n        tf.compat.v1.summary.histogram('model_output', model_output)\n        return model_output",
            "def _build_seq_graph(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'The main function to create sli_rec model.\\n\\n        Returns:\\n            object: the output of sli_rec section.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('sli_rec'):\n        hist_input = tf.concat([self.item_history_embedding, self.cate_history_embedding], 2)\n        self.mask = self.iterator.mask\n        self.sequence_length = tf.reduce_sum(input_tensor=self.mask, axis=1)\n        with tf.compat.v1.variable_scope('long_term_asvd'):\n            att_outputs1 = self._attention(hist_input, hparams.attention_size)\n            att_fea1 = tf.reduce_sum(input_tensor=att_outputs1, axis=1)\n            tf.compat.v1.summary.histogram('att_fea1', att_fea1)\n        item_history_embedding_new = tf.concat([self.item_history_embedding, tf.expand_dims(self.iterator.time_from_first_action, -1)], -1)\n        item_history_embedding_new = tf.concat([item_history_embedding_new, tf.expand_dims(self.iterator.time_to_now, -1)], -1)\n        with tf.compat.v1.variable_scope('rnn'):\n            (rnn_outputs, _) = dynamic_rnn(Time4LSTMCell(hparams.hidden_size), inputs=item_history_embedding_new, sequence_length=self.sequence_length, dtype=tf.float32, scope='time4lstm')\n            tf.compat.v1.summary.histogram('LSTM_outputs', rnn_outputs)\n        with tf.compat.v1.variable_scope('attention_fcn'):\n            att_outputs2 = self._attention_fcn(self.target_item_embedding, rnn_outputs)\n            att_fea2 = tf.reduce_sum(input_tensor=att_outputs2, axis=1)\n            tf.compat.v1.summary.histogram('att_fea2', att_fea2)\n        with tf.compat.v1.name_scope('alpha'):\n            concat_all = tf.concat([self.target_item_embedding, att_fea1, att_fea2, tf.expand_dims(self.iterator.time_to_now[:, -1], -1)], 1)\n            last_hidden_nn_layer = concat_all\n            alpha_logit = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='fcn_alpha')\n            alpha_output = tf.sigmoid(alpha_logit)\n            user_embed = att_fea1 * alpha_output + att_fea2 * (1.0 - alpha_output)\n        model_output = tf.concat([user_embed, self.target_item_embedding], 1)\n        tf.compat.v1.summary.histogram('model_output', model_output)\n        return model_output"
        ]
    },
    {
        "func_name": "_attention_fcn",
        "original": "def _attention_fcn(self, query, user_embedding):\n    \"\"\"Apply attention by fully connected layers.\n\n        Args:\n            query (object): The embedding of target item which is regarded as a query in attention operations.\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\n\n        Returns:\n            object: Weighted sum of user modeling.\n        \"\"\"\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('attention_fcn'):\n        query_size = query.shape[1]\n        boolean_mask = tf.equal(self.mask, tf.ones_like(self.mask))\n        attention_mat = tf.compat.v1.get_variable(name='attention_mat', shape=[user_embedding.shape.as_list()[-1], query_size], initializer=self.initializer)\n        att_inputs = tf.tensordot(user_embedding, attention_mat, [[2], [0]])\n        queries = tf.reshape(tf.tile(query, [1, att_inputs.shape[1]]), tf.shape(input=att_inputs))\n        last_hidden_nn_layer = tf.concat([att_inputs, queries, att_inputs - queries, att_inputs * queries], -1)\n        att_fnc_output = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='att_fcn')\n        att_fnc_output = tf.squeeze(att_fnc_output, -1)\n        mask_paddings = tf.ones_like(att_fnc_output) * (-2 ** 32 + 1)\n        att_weights = tf.nn.softmax(tf.compat.v1.where(boolean_mask, att_fnc_output, mask_paddings), name='att_weights')\n        output = user_embedding * tf.expand_dims(att_weights, -1)\n        return output",
        "mutated": [
            "def _attention_fcn(self, query, user_embedding):\n    if False:\n        i = 10\n    'Apply attention by fully connected layers.\\n\\n        Args:\\n            query (object): The embedding of target item which is regarded as a query in attention operations.\\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\\n\\n        Returns:\\n            object: Weighted sum of user modeling.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('attention_fcn'):\n        query_size = query.shape[1]\n        boolean_mask = tf.equal(self.mask, tf.ones_like(self.mask))\n        attention_mat = tf.compat.v1.get_variable(name='attention_mat', shape=[user_embedding.shape.as_list()[-1], query_size], initializer=self.initializer)\n        att_inputs = tf.tensordot(user_embedding, attention_mat, [[2], [0]])\n        queries = tf.reshape(tf.tile(query, [1, att_inputs.shape[1]]), tf.shape(input=att_inputs))\n        last_hidden_nn_layer = tf.concat([att_inputs, queries, att_inputs - queries, att_inputs * queries], -1)\n        att_fnc_output = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='att_fcn')\n        att_fnc_output = tf.squeeze(att_fnc_output, -1)\n        mask_paddings = tf.ones_like(att_fnc_output) * (-2 ** 32 + 1)\n        att_weights = tf.nn.softmax(tf.compat.v1.where(boolean_mask, att_fnc_output, mask_paddings), name='att_weights')\n        output = user_embedding * tf.expand_dims(att_weights, -1)\n        return output",
            "def _attention_fcn(self, query, user_embedding):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Apply attention by fully connected layers.\\n\\n        Args:\\n            query (object): The embedding of target item which is regarded as a query in attention operations.\\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\\n\\n        Returns:\\n            object: Weighted sum of user modeling.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('attention_fcn'):\n        query_size = query.shape[1]\n        boolean_mask = tf.equal(self.mask, tf.ones_like(self.mask))\n        attention_mat = tf.compat.v1.get_variable(name='attention_mat', shape=[user_embedding.shape.as_list()[-1], query_size], initializer=self.initializer)\n        att_inputs = tf.tensordot(user_embedding, attention_mat, [[2], [0]])\n        queries = tf.reshape(tf.tile(query, [1, att_inputs.shape[1]]), tf.shape(input=att_inputs))\n        last_hidden_nn_layer = tf.concat([att_inputs, queries, att_inputs - queries, att_inputs * queries], -1)\n        att_fnc_output = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='att_fcn')\n        att_fnc_output = tf.squeeze(att_fnc_output, -1)\n        mask_paddings = tf.ones_like(att_fnc_output) * (-2 ** 32 + 1)\n        att_weights = tf.nn.softmax(tf.compat.v1.where(boolean_mask, att_fnc_output, mask_paddings), name='att_weights')\n        output = user_embedding * tf.expand_dims(att_weights, -1)\n        return output",
            "def _attention_fcn(self, query, user_embedding):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Apply attention by fully connected layers.\\n\\n        Args:\\n            query (object): The embedding of target item which is regarded as a query in attention operations.\\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\\n\\n        Returns:\\n            object: Weighted sum of user modeling.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('attention_fcn'):\n        query_size = query.shape[1]\n        boolean_mask = tf.equal(self.mask, tf.ones_like(self.mask))\n        attention_mat = tf.compat.v1.get_variable(name='attention_mat', shape=[user_embedding.shape.as_list()[-1], query_size], initializer=self.initializer)\n        att_inputs = tf.tensordot(user_embedding, attention_mat, [[2], [0]])\n        queries = tf.reshape(tf.tile(query, [1, att_inputs.shape[1]]), tf.shape(input=att_inputs))\n        last_hidden_nn_layer = tf.concat([att_inputs, queries, att_inputs - queries, att_inputs * queries], -1)\n        att_fnc_output = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='att_fcn')\n        att_fnc_output = tf.squeeze(att_fnc_output, -1)\n        mask_paddings = tf.ones_like(att_fnc_output) * (-2 ** 32 + 1)\n        att_weights = tf.nn.softmax(tf.compat.v1.where(boolean_mask, att_fnc_output, mask_paddings), name='att_weights')\n        output = user_embedding * tf.expand_dims(att_weights, -1)\n        return output",
            "def _attention_fcn(self, query, user_embedding):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Apply attention by fully connected layers.\\n\\n        Args:\\n            query (object): The embedding of target item which is regarded as a query in attention operations.\\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\\n\\n        Returns:\\n            object: Weighted sum of user modeling.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('attention_fcn'):\n        query_size = query.shape[1]\n        boolean_mask = tf.equal(self.mask, tf.ones_like(self.mask))\n        attention_mat = tf.compat.v1.get_variable(name='attention_mat', shape=[user_embedding.shape.as_list()[-1], query_size], initializer=self.initializer)\n        att_inputs = tf.tensordot(user_embedding, attention_mat, [[2], [0]])\n        queries = tf.reshape(tf.tile(query, [1, att_inputs.shape[1]]), tf.shape(input=att_inputs))\n        last_hidden_nn_layer = tf.concat([att_inputs, queries, att_inputs - queries, att_inputs * queries], -1)\n        att_fnc_output = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='att_fcn')\n        att_fnc_output = tf.squeeze(att_fnc_output, -1)\n        mask_paddings = tf.ones_like(att_fnc_output) * (-2 ** 32 + 1)\n        att_weights = tf.nn.softmax(tf.compat.v1.where(boolean_mask, att_fnc_output, mask_paddings), name='att_weights')\n        output = user_embedding * tf.expand_dims(att_weights, -1)\n        return output",
            "def _attention_fcn(self, query, user_embedding):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Apply attention by fully connected layers.\\n\\n        Args:\\n            query (object): The embedding of target item which is regarded as a query in attention operations.\\n            user_embedding (object): The output of RNN layers which is regarded as user modeling.\\n\\n        Returns:\\n            object: Weighted sum of user modeling.\\n        '\n    hparams = self.hparams\n    with tf.compat.v1.variable_scope('attention_fcn'):\n        query_size = query.shape[1]\n        boolean_mask = tf.equal(self.mask, tf.ones_like(self.mask))\n        attention_mat = tf.compat.v1.get_variable(name='attention_mat', shape=[user_embedding.shape.as_list()[-1], query_size], initializer=self.initializer)\n        att_inputs = tf.tensordot(user_embedding, attention_mat, [[2], [0]])\n        queries = tf.reshape(tf.tile(query, [1, att_inputs.shape[1]]), tf.shape(input=att_inputs))\n        last_hidden_nn_layer = tf.concat([att_inputs, queries, att_inputs - queries, att_inputs * queries], -1)\n        att_fnc_output = self._fcn_net(last_hidden_nn_layer, hparams.att_fcn_layer_sizes, scope='att_fcn')\n        att_fnc_output = tf.squeeze(att_fnc_output, -1)\n        mask_paddings = tf.ones_like(att_fnc_output) * (-2 ** 32 + 1)\n        att_weights = tf.nn.softmax(tf.compat.v1.where(boolean_mask, att_fnc_output, mask_paddings), name='att_weights')\n        output = user_embedding * tf.expand_dims(att_weights, -1)\n        return output"
        ]
    }
]