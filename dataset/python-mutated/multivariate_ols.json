[
    {
        "func_name": "_multivariate_ols_fit",
        "original": "def _multivariate_ols_fit(endog, exog, method='svd', tolerance=1e-08):\n    \"\"\"\n    Solve multivariate linear model y = x * params\n    where y is dependent variables, x is independent variables\n\n    Parameters\n    ----------\n    endog : array_like\n        each column is a dependent variable\n    exog : array_like\n        each column is a independent variable\n    method : str\n        'svd' - Singular value decomposition\n        'pinv' - Moore-Penrose pseudoinverse\n    tolerance : float, a small positive number\n        Tolerance for eigenvalue. Values smaller than tolerance is considered\n        zero.\n    Returns\n    -------\n    a tuple of matrices or values necessary for hypotheses testing\n\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\n    Notes\n    -----\n    Status: experimental and incomplete\n    \"\"\"\n    y = endog\n    x = exog\n    (nobs, k_endog) = y.shape\n    (nobs1, k_exog) = x.shape\n    if nobs != nobs1:\n        raise ValueError('x(n=%d) and y(n=%d) should have the same number of rows!' % (nobs1, nobs))\n    df_resid = nobs - k_exog\n    if method == 'pinv':\n        pinv_x = pinv(x)\n        params = pinv_x.dot(y)\n        inv_cov = pinv_x.dot(pinv_x.T)\n        if matrix_rank(inv_cov, tol=tolerance) < k_exog:\n            raise ValueError('Covariance of x singular!')\n        t = x.dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    elif method == 'svd':\n        (u, s, v) = svd(x, 0)\n        if (s > tolerance).sum() < len(s):\n            raise ValueError('Covariance of x singular!')\n        invs = 1.0 / s\n        params = v.T.dot(np.diag(invs)).dot(u.T).dot(y)\n        inv_cov = v.T.dot(np.diag(np.power(invs, 2))).dot(v)\n        t = np.diag(s).dot(v).dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    else:\n        raise ValueError('%s is not a supported method!' % method)",
        "mutated": [
            "def _multivariate_ols_fit(endog, exog, method='svd', tolerance=1e-08):\n    if False:\n        i = 10\n    \"\\n    Solve multivariate linear model y = x * params\\n    where y is dependent variables, x is independent variables\\n\\n    Parameters\\n    ----------\\n    endog : array_like\\n        each column is a dependent variable\\n    exog : array_like\\n        each column is a independent variable\\n    method : str\\n        'svd' - Singular value decomposition\\n        'pinv' - Moore-Penrose pseudoinverse\\n    tolerance : float, a small positive number\\n        Tolerance for eigenvalue. Values smaller than tolerance is considered\\n        zero.\\n    Returns\\n    -------\\n    a tuple of matrices or values necessary for hypotheses testing\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    Notes\\n    -----\\n    Status: experimental and incomplete\\n    \"\n    y = endog\n    x = exog\n    (nobs, k_endog) = y.shape\n    (nobs1, k_exog) = x.shape\n    if nobs != nobs1:\n        raise ValueError('x(n=%d) and y(n=%d) should have the same number of rows!' % (nobs1, nobs))\n    df_resid = nobs - k_exog\n    if method == 'pinv':\n        pinv_x = pinv(x)\n        params = pinv_x.dot(y)\n        inv_cov = pinv_x.dot(pinv_x.T)\n        if matrix_rank(inv_cov, tol=tolerance) < k_exog:\n            raise ValueError('Covariance of x singular!')\n        t = x.dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    elif method == 'svd':\n        (u, s, v) = svd(x, 0)\n        if (s > tolerance).sum() < len(s):\n            raise ValueError('Covariance of x singular!')\n        invs = 1.0 / s\n        params = v.T.dot(np.diag(invs)).dot(u.T).dot(y)\n        inv_cov = v.T.dot(np.diag(np.power(invs, 2))).dot(v)\n        t = np.diag(s).dot(v).dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    else:\n        raise ValueError('%s is not a supported method!' % method)",
            "def _multivariate_ols_fit(endog, exog, method='svd', tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Solve multivariate linear model y = x * params\\n    where y is dependent variables, x is independent variables\\n\\n    Parameters\\n    ----------\\n    endog : array_like\\n        each column is a dependent variable\\n    exog : array_like\\n        each column is a independent variable\\n    method : str\\n        'svd' - Singular value decomposition\\n        'pinv' - Moore-Penrose pseudoinverse\\n    tolerance : float, a small positive number\\n        Tolerance for eigenvalue. Values smaller than tolerance is considered\\n        zero.\\n    Returns\\n    -------\\n    a tuple of matrices or values necessary for hypotheses testing\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    Notes\\n    -----\\n    Status: experimental and incomplete\\n    \"\n    y = endog\n    x = exog\n    (nobs, k_endog) = y.shape\n    (nobs1, k_exog) = x.shape\n    if nobs != nobs1:\n        raise ValueError('x(n=%d) and y(n=%d) should have the same number of rows!' % (nobs1, nobs))\n    df_resid = nobs - k_exog\n    if method == 'pinv':\n        pinv_x = pinv(x)\n        params = pinv_x.dot(y)\n        inv_cov = pinv_x.dot(pinv_x.T)\n        if matrix_rank(inv_cov, tol=tolerance) < k_exog:\n            raise ValueError('Covariance of x singular!')\n        t = x.dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    elif method == 'svd':\n        (u, s, v) = svd(x, 0)\n        if (s > tolerance).sum() < len(s):\n            raise ValueError('Covariance of x singular!')\n        invs = 1.0 / s\n        params = v.T.dot(np.diag(invs)).dot(u.T).dot(y)\n        inv_cov = v.T.dot(np.diag(np.power(invs, 2))).dot(v)\n        t = np.diag(s).dot(v).dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    else:\n        raise ValueError('%s is not a supported method!' % method)",
            "def _multivariate_ols_fit(endog, exog, method='svd', tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Solve multivariate linear model y = x * params\\n    where y is dependent variables, x is independent variables\\n\\n    Parameters\\n    ----------\\n    endog : array_like\\n        each column is a dependent variable\\n    exog : array_like\\n        each column is a independent variable\\n    method : str\\n        'svd' - Singular value decomposition\\n        'pinv' - Moore-Penrose pseudoinverse\\n    tolerance : float, a small positive number\\n        Tolerance for eigenvalue. Values smaller than tolerance is considered\\n        zero.\\n    Returns\\n    -------\\n    a tuple of matrices or values necessary for hypotheses testing\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    Notes\\n    -----\\n    Status: experimental and incomplete\\n    \"\n    y = endog\n    x = exog\n    (nobs, k_endog) = y.shape\n    (nobs1, k_exog) = x.shape\n    if nobs != nobs1:\n        raise ValueError('x(n=%d) and y(n=%d) should have the same number of rows!' % (nobs1, nobs))\n    df_resid = nobs - k_exog\n    if method == 'pinv':\n        pinv_x = pinv(x)\n        params = pinv_x.dot(y)\n        inv_cov = pinv_x.dot(pinv_x.T)\n        if matrix_rank(inv_cov, tol=tolerance) < k_exog:\n            raise ValueError('Covariance of x singular!')\n        t = x.dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    elif method == 'svd':\n        (u, s, v) = svd(x, 0)\n        if (s > tolerance).sum() < len(s):\n            raise ValueError('Covariance of x singular!')\n        invs = 1.0 / s\n        params = v.T.dot(np.diag(invs)).dot(u.T).dot(y)\n        inv_cov = v.T.dot(np.diag(np.power(invs, 2))).dot(v)\n        t = np.diag(s).dot(v).dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    else:\n        raise ValueError('%s is not a supported method!' % method)",
            "def _multivariate_ols_fit(endog, exog, method='svd', tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Solve multivariate linear model y = x * params\\n    where y is dependent variables, x is independent variables\\n\\n    Parameters\\n    ----------\\n    endog : array_like\\n        each column is a dependent variable\\n    exog : array_like\\n        each column is a independent variable\\n    method : str\\n        'svd' - Singular value decomposition\\n        'pinv' - Moore-Penrose pseudoinverse\\n    tolerance : float, a small positive number\\n        Tolerance for eigenvalue. Values smaller than tolerance is considered\\n        zero.\\n    Returns\\n    -------\\n    a tuple of matrices or values necessary for hypotheses testing\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    Notes\\n    -----\\n    Status: experimental and incomplete\\n    \"\n    y = endog\n    x = exog\n    (nobs, k_endog) = y.shape\n    (nobs1, k_exog) = x.shape\n    if nobs != nobs1:\n        raise ValueError('x(n=%d) and y(n=%d) should have the same number of rows!' % (nobs1, nobs))\n    df_resid = nobs - k_exog\n    if method == 'pinv':\n        pinv_x = pinv(x)\n        params = pinv_x.dot(y)\n        inv_cov = pinv_x.dot(pinv_x.T)\n        if matrix_rank(inv_cov, tol=tolerance) < k_exog:\n            raise ValueError('Covariance of x singular!')\n        t = x.dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    elif method == 'svd':\n        (u, s, v) = svd(x, 0)\n        if (s > tolerance).sum() < len(s):\n            raise ValueError('Covariance of x singular!')\n        invs = 1.0 / s\n        params = v.T.dot(np.diag(invs)).dot(u.T).dot(y)\n        inv_cov = v.T.dot(np.diag(np.power(invs, 2))).dot(v)\n        t = np.diag(s).dot(v).dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    else:\n        raise ValueError('%s is not a supported method!' % method)",
            "def _multivariate_ols_fit(endog, exog, method='svd', tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Solve multivariate linear model y = x * params\\n    where y is dependent variables, x is independent variables\\n\\n    Parameters\\n    ----------\\n    endog : array_like\\n        each column is a dependent variable\\n    exog : array_like\\n        each column is a independent variable\\n    method : str\\n        'svd' - Singular value decomposition\\n        'pinv' - Moore-Penrose pseudoinverse\\n    tolerance : float, a small positive number\\n        Tolerance for eigenvalue. Values smaller than tolerance is considered\\n        zero.\\n    Returns\\n    -------\\n    a tuple of matrices or values necessary for hypotheses testing\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    Notes\\n    -----\\n    Status: experimental and incomplete\\n    \"\n    y = endog\n    x = exog\n    (nobs, k_endog) = y.shape\n    (nobs1, k_exog) = x.shape\n    if nobs != nobs1:\n        raise ValueError('x(n=%d) and y(n=%d) should have the same number of rows!' % (nobs1, nobs))\n    df_resid = nobs - k_exog\n    if method == 'pinv':\n        pinv_x = pinv(x)\n        params = pinv_x.dot(y)\n        inv_cov = pinv_x.dot(pinv_x.T)\n        if matrix_rank(inv_cov, tol=tolerance) < k_exog:\n            raise ValueError('Covariance of x singular!')\n        t = x.dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    elif method == 'svd':\n        (u, s, v) = svd(x, 0)\n        if (s > tolerance).sum() < len(s):\n            raise ValueError('Covariance of x singular!')\n        invs = 1.0 / s\n        params = v.T.dot(np.diag(invs)).dot(u.T).dot(y)\n        inv_cov = v.T.dot(np.diag(np.power(invs, 2))).dot(v)\n        t = np.diag(s).dot(v).dot(params)\n        sscpr = np.subtract(y.T.dot(y), t.T.dot(t))\n        return (params, df_resid, inv_cov, sscpr)\n    else:\n        raise ValueError('%s is not a supported method!' % method)"
        ]
    },
    {
        "func_name": "fn",
        "original": "def fn(x):\n    return np.real([x])[0]",
        "mutated": [
            "def fn(x):\n    if False:\n        i = 10\n    return np.real([x])[0]",
            "def fn(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return np.real([x])[0]",
            "def fn(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return np.real([x])[0]",
            "def fn(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return np.real([x])[0]",
            "def fn(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return np.real([x])[0]"
        ]
    },
    {
        "func_name": "multivariate_stats",
        "original": "def multivariate_stats(eigenvals, r_err_sscp, r_contrast, df_resid, tolerance=1e-08):\n    \"\"\"\n    For multivariate linear model Y = X * B\n    Testing hypotheses\n        L*B*M = 0\n    where L is contrast matrix, B is the parameters of the\n    multivariate linear model and M is dependent variable transform matrix.\n        T = L*inv(X'X)*L'\n        H = M'B'L'*inv(T)*LBM\n        E =  M'(Y'Y - B'X'XB)M\n\n    Parameters\n    ----------\n    eigenvals : ndarray\n        The eigenvalues of inv(E + H)*H\n    r_err_sscp : int\n        Rank of E + H\n    r_contrast : int\n        Rank of T matrix\n    df_resid : int\n        Residual degree of freedom (n_samples minus n_variables of X)\n    tolerance : float\n        smaller than which eigenvalue is considered 0\n\n    Returns\n    -------\n    A DataFrame\n\n    References\n    ----------\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\n    \"\"\"\n    v = df_resid\n    p = r_err_sscp\n    q = r_contrast\n    s = np.min([p, q])\n    ind = eigenvals > tolerance\n    n_e = ind.sum()\n    eigv2 = eigenvals[ind]\n    eigv1 = np.array([i / (1 - i) for i in eigv2])\n    m = (np.abs(p - q) - 1) / 2\n    n = (v - p - 1) / 2\n    cols = ['Value', 'Num DF', 'Den DF', 'F Value', 'Pr > F']\n    index = [\"Wilks' lambda\", \"Pillai's trace\", 'Hotelling-Lawley trace', \"Roy's greatest root\"]\n    results = pd.DataFrame(columns=cols, index=index)\n\n    def fn(x):\n        return np.real([x])[0]\n    results.loc[\"Wilks' lambda\", 'Value'] = fn(np.prod(1 - eigv2))\n    results.loc[\"Pillai's trace\", 'Value'] = fn(eigv2.sum())\n    results.loc['Hotelling-Lawley trace', 'Value'] = fn(eigv1.sum())\n    results.loc[\"Roy's greatest root\", 'Value'] = fn(eigv1.max())\n    r = v - (p - q + 1) / 2\n    u = (p * q - 2) / 4\n    df1 = p * q\n    if p * p + q * q - 5 > 0:\n        t = np.sqrt((p * p * q * q - 4) / (p * p + q * q - 5))\n    else:\n        t = 1\n    df2 = r * t - 2 * u\n    lmd = results.loc[\"Wilks' lambda\", 'Value']\n    lmd = np.power(lmd, 1 / t)\n    F = (1 - lmd) / lmd * df2 / df1\n    results.loc[\"Wilks' lambda\", 'Num DF'] = df1\n    results.loc[\"Wilks' lambda\", 'Den DF'] = df2\n    results.loc[\"Wilks' lambda\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Wilks' lambda\", 'Pr > F'] = pval\n    V = results.loc[\"Pillai's trace\", 'Value']\n    df1 = s * (2 * m + s + 1)\n    df2 = s * (2 * n + s + 1)\n    F = df2 / df1 * V / (s - V)\n    results.loc[\"Pillai's trace\", 'Num DF'] = df1\n    results.loc[\"Pillai's trace\", 'Den DF'] = df2\n    results.loc[\"Pillai's trace\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Pillai's trace\", 'Pr > F'] = pval\n    U = results.loc['Hotelling-Lawley trace', 'Value']\n    if n > 0:\n        b = (p + 2 * n) * (q + 2 * n) / 2 / (2 * n + 1) / (n - 1)\n        df1 = p * q\n        df2 = 4 + (p * q + 2) / (b - 1)\n        c = (df2 - 2) / 2 / n\n        F = df2 / df1 * U / c\n    else:\n        df1 = s * (2 * m + s + 1)\n        df2 = s * (s * n + 1)\n        F = df2 / df1 / s * U\n    results.loc['Hotelling-Lawley trace', 'Num DF'] = df1\n    results.loc['Hotelling-Lawley trace', 'Den DF'] = df2\n    results.loc['Hotelling-Lawley trace', 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc['Hotelling-Lawley trace', 'Pr > F'] = pval\n    sigma = results.loc[\"Roy's greatest root\", 'Value']\n    r = np.max([p, q])\n    df1 = r\n    df2 = v - r + q\n    F = df2 / df1 * sigma\n    results.loc[\"Roy's greatest root\", 'Num DF'] = df1\n    results.loc[\"Roy's greatest root\", 'Den DF'] = df2\n    results.loc[\"Roy's greatest root\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Roy's greatest root\", 'Pr > F'] = pval\n    return results",
        "mutated": [
            "def multivariate_stats(eigenvals, r_err_sscp, r_contrast, df_resid, tolerance=1e-08):\n    if False:\n        i = 10\n    \"\\n    For multivariate linear model Y = X * B\\n    Testing hypotheses\\n        L*B*M = 0\\n    where L is contrast matrix, B is the parameters of the\\n    multivariate linear model and M is dependent variable transform matrix.\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n\\n    Parameters\\n    ----------\\n    eigenvals : ndarray\\n        The eigenvalues of inv(E + H)*H\\n    r_err_sscp : int\\n        Rank of E + H\\n    r_contrast : int\\n        Rank of T matrix\\n    df_resid : int\\n        Residual degree of freedom (n_samples minus n_variables of X)\\n    tolerance : float\\n        smaller than which eigenvalue is considered 0\\n\\n    Returns\\n    -------\\n    A DataFrame\\n\\n    References\\n    ----------\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    \"\n    v = df_resid\n    p = r_err_sscp\n    q = r_contrast\n    s = np.min([p, q])\n    ind = eigenvals > tolerance\n    n_e = ind.sum()\n    eigv2 = eigenvals[ind]\n    eigv1 = np.array([i / (1 - i) for i in eigv2])\n    m = (np.abs(p - q) - 1) / 2\n    n = (v - p - 1) / 2\n    cols = ['Value', 'Num DF', 'Den DF', 'F Value', 'Pr > F']\n    index = [\"Wilks' lambda\", \"Pillai's trace\", 'Hotelling-Lawley trace', \"Roy's greatest root\"]\n    results = pd.DataFrame(columns=cols, index=index)\n\n    def fn(x):\n        return np.real([x])[0]\n    results.loc[\"Wilks' lambda\", 'Value'] = fn(np.prod(1 - eigv2))\n    results.loc[\"Pillai's trace\", 'Value'] = fn(eigv2.sum())\n    results.loc['Hotelling-Lawley trace', 'Value'] = fn(eigv1.sum())\n    results.loc[\"Roy's greatest root\", 'Value'] = fn(eigv1.max())\n    r = v - (p - q + 1) / 2\n    u = (p * q - 2) / 4\n    df1 = p * q\n    if p * p + q * q - 5 > 0:\n        t = np.sqrt((p * p * q * q - 4) / (p * p + q * q - 5))\n    else:\n        t = 1\n    df2 = r * t - 2 * u\n    lmd = results.loc[\"Wilks' lambda\", 'Value']\n    lmd = np.power(lmd, 1 / t)\n    F = (1 - lmd) / lmd * df2 / df1\n    results.loc[\"Wilks' lambda\", 'Num DF'] = df1\n    results.loc[\"Wilks' lambda\", 'Den DF'] = df2\n    results.loc[\"Wilks' lambda\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Wilks' lambda\", 'Pr > F'] = pval\n    V = results.loc[\"Pillai's trace\", 'Value']\n    df1 = s * (2 * m + s + 1)\n    df2 = s * (2 * n + s + 1)\n    F = df2 / df1 * V / (s - V)\n    results.loc[\"Pillai's trace\", 'Num DF'] = df1\n    results.loc[\"Pillai's trace\", 'Den DF'] = df2\n    results.loc[\"Pillai's trace\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Pillai's trace\", 'Pr > F'] = pval\n    U = results.loc['Hotelling-Lawley trace', 'Value']\n    if n > 0:\n        b = (p + 2 * n) * (q + 2 * n) / 2 / (2 * n + 1) / (n - 1)\n        df1 = p * q\n        df2 = 4 + (p * q + 2) / (b - 1)\n        c = (df2 - 2) / 2 / n\n        F = df2 / df1 * U / c\n    else:\n        df1 = s * (2 * m + s + 1)\n        df2 = s * (s * n + 1)\n        F = df2 / df1 / s * U\n    results.loc['Hotelling-Lawley trace', 'Num DF'] = df1\n    results.loc['Hotelling-Lawley trace', 'Den DF'] = df2\n    results.loc['Hotelling-Lawley trace', 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc['Hotelling-Lawley trace', 'Pr > F'] = pval\n    sigma = results.loc[\"Roy's greatest root\", 'Value']\n    r = np.max([p, q])\n    df1 = r\n    df2 = v - r + q\n    F = df2 / df1 * sigma\n    results.loc[\"Roy's greatest root\", 'Num DF'] = df1\n    results.loc[\"Roy's greatest root\", 'Den DF'] = df2\n    results.loc[\"Roy's greatest root\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Roy's greatest root\", 'Pr > F'] = pval\n    return results",
            "def multivariate_stats(eigenvals, r_err_sscp, r_contrast, df_resid, tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    For multivariate linear model Y = X * B\\n    Testing hypotheses\\n        L*B*M = 0\\n    where L is contrast matrix, B is the parameters of the\\n    multivariate linear model and M is dependent variable transform matrix.\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n\\n    Parameters\\n    ----------\\n    eigenvals : ndarray\\n        The eigenvalues of inv(E + H)*H\\n    r_err_sscp : int\\n        Rank of E + H\\n    r_contrast : int\\n        Rank of T matrix\\n    df_resid : int\\n        Residual degree of freedom (n_samples minus n_variables of X)\\n    tolerance : float\\n        smaller than which eigenvalue is considered 0\\n\\n    Returns\\n    -------\\n    A DataFrame\\n\\n    References\\n    ----------\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    \"\n    v = df_resid\n    p = r_err_sscp\n    q = r_contrast\n    s = np.min([p, q])\n    ind = eigenvals > tolerance\n    n_e = ind.sum()\n    eigv2 = eigenvals[ind]\n    eigv1 = np.array([i / (1 - i) for i in eigv2])\n    m = (np.abs(p - q) - 1) / 2\n    n = (v - p - 1) / 2\n    cols = ['Value', 'Num DF', 'Den DF', 'F Value', 'Pr > F']\n    index = [\"Wilks' lambda\", \"Pillai's trace\", 'Hotelling-Lawley trace', \"Roy's greatest root\"]\n    results = pd.DataFrame(columns=cols, index=index)\n\n    def fn(x):\n        return np.real([x])[0]\n    results.loc[\"Wilks' lambda\", 'Value'] = fn(np.prod(1 - eigv2))\n    results.loc[\"Pillai's trace\", 'Value'] = fn(eigv2.sum())\n    results.loc['Hotelling-Lawley trace', 'Value'] = fn(eigv1.sum())\n    results.loc[\"Roy's greatest root\", 'Value'] = fn(eigv1.max())\n    r = v - (p - q + 1) / 2\n    u = (p * q - 2) / 4\n    df1 = p * q\n    if p * p + q * q - 5 > 0:\n        t = np.sqrt((p * p * q * q - 4) / (p * p + q * q - 5))\n    else:\n        t = 1\n    df2 = r * t - 2 * u\n    lmd = results.loc[\"Wilks' lambda\", 'Value']\n    lmd = np.power(lmd, 1 / t)\n    F = (1 - lmd) / lmd * df2 / df1\n    results.loc[\"Wilks' lambda\", 'Num DF'] = df1\n    results.loc[\"Wilks' lambda\", 'Den DF'] = df2\n    results.loc[\"Wilks' lambda\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Wilks' lambda\", 'Pr > F'] = pval\n    V = results.loc[\"Pillai's trace\", 'Value']\n    df1 = s * (2 * m + s + 1)\n    df2 = s * (2 * n + s + 1)\n    F = df2 / df1 * V / (s - V)\n    results.loc[\"Pillai's trace\", 'Num DF'] = df1\n    results.loc[\"Pillai's trace\", 'Den DF'] = df2\n    results.loc[\"Pillai's trace\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Pillai's trace\", 'Pr > F'] = pval\n    U = results.loc['Hotelling-Lawley trace', 'Value']\n    if n > 0:\n        b = (p + 2 * n) * (q + 2 * n) / 2 / (2 * n + 1) / (n - 1)\n        df1 = p * q\n        df2 = 4 + (p * q + 2) / (b - 1)\n        c = (df2 - 2) / 2 / n\n        F = df2 / df1 * U / c\n    else:\n        df1 = s * (2 * m + s + 1)\n        df2 = s * (s * n + 1)\n        F = df2 / df1 / s * U\n    results.loc['Hotelling-Lawley trace', 'Num DF'] = df1\n    results.loc['Hotelling-Lawley trace', 'Den DF'] = df2\n    results.loc['Hotelling-Lawley trace', 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc['Hotelling-Lawley trace', 'Pr > F'] = pval\n    sigma = results.loc[\"Roy's greatest root\", 'Value']\n    r = np.max([p, q])\n    df1 = r\n    df2 = v - r + q\n    F = df2 / df1 * sigma\n    results.loc[\"Roy's greatest root\", 'Num DF'] = df1\n    results.loc[\"Roy's greatest root\", 'Den DF'] = df2\n    results.loc[\"Roy's greatest root\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Roy's greatest root\", 'Pr > F'] = pval\n    return results",
            "def multivariate_stats(eigenvals, r_err_sscp, r_contrast, df_resid, tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    For multivariate linear model Y = X * B\\n    Testing hypotheses\\n        L*B*M = 0\\n    where L is contrast matrix, B is the parameters of the\\n    multivariate linear model and M is dependent variable transform matrix.\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n\\n    Parameters\\n    ----------\\n    eigenvals : ndarray\\n        The eigenvalues of inv(E + H)*H\\n    r_err_sscp : int\\n        Rank of E + H\\n    r_contrast : int\\n        Rank of T matrix\\n    df_resid : int\\n        Residual degree of freedom (n_samples minus n_variables of X)\\n    tolerance : float\\n        smaller than which eigenvalue is considered 0\\n\\n    Returns\\n    -------\\n    A DataFrame\\n\\n    References\\n    ----------\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    \"\n    v = df_resid\n    p = r_err_sscp\n    q = r_contrast\n    s = np.min([p, q])\n    ind = eigenvals > tolerance\n    n_e = ind.sum()\n    eigv2 = eigenvals[ind]\n    eigv1 = np.array([i / (1 - i) for i in eigv2])\n    m = (np.abs(p - q) - 1) / 2\n    n = (v - p - 1) / 2\n    cols = ['Value', 'Num DF', 'Den DF', 'F Value', 'Pr > F']\n    index = [\"Wilks' lambda\", \"Pillai's trace\", 'Hotelling-Lawley trace', \"Roy's greatest root\"]\n    results = pd.DataFrame(columns=cols, index=index)\n\n    def fn(x):\n        return np.real([x])[0]\n    results.loc[\"Wilks' lambda\", 'Value'] = fn(np.prod(1 - eigv2))\n    results.loc[\"Pillai's trace\", 'Value'] = fn(eigv2.sum())\n    results.loc['Hotelling-Lawley trace', 'Value'] = fn(eigv1.sum())\n    results.loc[\"Roy's greatest root\", 'Value'] = fn(eigv1.max())\n    r = v - (p - q + 1) / 2\n    u = (p * q - 2) / 4\n    df1 = p * q\n    if p * p + q * q - 5 > 0:\n        t = np.sqrt((p * p * q * q - 4) / (p * p + q * q - 5))\n    else:\n        t = 1\n    df2 = r * t - 2 * u\n    lmd = results.loc[\"Wilks' lambda\", 'Value']\n    lmd = np.power(lmd, 1 / t)\n    F = (1 - lmd) / lmd * df2 / df1\n    results.loc[\"Wilks' lambda\", 'Num DF'] = df1\n    results.loc[\"Wilks' lambda\", 'Den DF'] = df2\n    results.loc[\"Wilks' lambda\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Wilks' lambda\", 'Pr > F'] = pval\n    V = results.loc[\"Pillai's trace\", 'Value']\n    df1 = s * (2 * m + s + 1)\n    df2 = s * (2 * n + s + 1)\n    F = df2 / df1 * V / (s - V)\n    results.loc[\"Pillai's trace\", 'Num DF'] = df1\n    results.loc[\"Pillai's trace\", 'Den DF'] = df2\n    results.loc[\"Pillai's trace\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Pillai's trace\", 'Pr > F'] = pval\n    U = results.loc['Hotelling-Lawley trace', 'Value']\n    if n > 0:\n        b = (p + 2 * n) * (q + 2 * n) / 2 / (2 * n + 1) / (n - 1)\n        df1 = p * q\n        df2 = 4 + (p * q + 2) / (b - 1)\n        c = (df2 - 2) / 2 / n\n        F = df2 / df1 * U / c\n    else:\n        df1 = s * (2 * m + s + 1)\n        df2 = s * (s * n + 1)\n        F = df2 / df1 / s * U\n    results.loc['Hotelling-Lawley trace', 'Num DF'] = df1\n    results.loc['Hotelling-Lawley trace', 'Den DF'] = df2\n    results.loc['Hotelling-Lawley trace', 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc['Hotelling-Lawley trace', 'Pr > F'] = pval\n    sigma = results.loc[\"Roy's greatest root\", 'Value']\n    r = np.max([p, q])\n    df1 = r\n    df2 = v - r + q\n    F = df2 / df1 * sigma\n    results.loc[\"Roy's greatest root\", 'Num DF'] = df1\n    results.loc[\"Roy's greatest root\", 'Den DF'] = df2\n    results.loc[\"Roy's greatest root\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Roy's greatest root\", 'Pr > F'] = pval\n    return results",
            "def multivariate_stats(eigenvals, r_err_sscp, r_contrast, df_resid, tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    For multivariate linear model Y = X * B\\n    Testing hypotheses\\n        L*B*M = 0\\n    where L is contrast matrix, B is the parameters of the\\n    multivariate linear model and M is dependent variable transform matrix.\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n\\n    Parameters\\n    ----------\\n    eigenvals : ndarray\\n        The eigenvalues of inv(E + H)*H\\n    r_err_sscp : int\\n        Rank of E + H\\n    r_contrast : int\\n        Rank of T matrix\\n    df_resid : int\\n        Residual degree of freedom (n_samples minus n_variables of X)\\n    tolerance : float\\n        smaller than which eigenvalue is considered 0\\n\\n    Returns\\n    -------\\n    A DataFrame\\n\\n    References\\n    ----------\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    \"\n    v = df_resid\n    p = r_err_sscp\n    q = r_contrast\n    s = np.min([p, q])\n    ind = eigenvals > tolerance\n    n_e = ind.sum()\n    eigv2 = eigenvals[ind]\n    eigv1 = np.array([i / (1 - i) for i in eigv2])\n    m = (np.abs(p - q) - 1) / 2\n    n = (v - p - 1) / 2\n    cols = ['Value', 'Num DF', 'Den DF', 'F Value', 'Pr > F']\n    index = [\"Wilks' lambda\", \"Pillai's trace\", 'Hotelling-Lawley trace', \"Roy's greatest root\"]\n    results = pd.DataFrame(columns=cols, index=index)\n\n    def fn(x):\n        return np.real([x])[0]\n    results.loc[\"Wilks' lambda\", 'Value'] = fn(np.prod(1 - eigv2))\n    results.loc[\"Pillai's trace\", 'Value'] = fn(eigv2.sum())\n    results.loc['Hotelling-Lawley trace', 'Value'] = fn(eigv1.sum())\n    results.loc[\"Roy's greatest root\", 'Value'] = fn(eigv1.max())\n    r = v - (p - q + 1) / 2\n    u = (p * q - 2) / 4\n    df1 = p * q\n    if p * p + q * q - 5 > 0:\n        t = np.sqrt((p * p * q * q - 4) / (p * p + q * q - 5))\n    else:\n        t = 1\n    df2 = r * t - 2 * u\n    lmd = results.loc[\"Wilks' lambda\", 'Value']\n    lmd = np.power(lmd, 1 / t)\n    F = (1 - lmd) / lmd * df2 / df1\n    results.loc[\"Wilks' lambda\", 'Num DF'] = df1\n    results.loc[\"Wilks' lambda\", 'Den DF'] = df2\n    results.loc[\"Wilks' lambda\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Wilks' lambda\", 'Pr > F'] = pval\n    V = results.loc[\"Pillai's trace\", 'Value']\n    df1 = s * (2 * m + s + 1)\n    df2 = s * (2 * n + s + 1)\n    F = df2 / df1 * V / (s - V)\n    results.loc[\"Pillai's trace\", 'Num DF'] = df1\n    results.loc[\"Pillai's trace\", 'Den DF'] = df2\n    results.loc[\"Pillai's trace\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Pillai's trace\", 'Pr > F'] = pval\n    U = results.loc['Hotelling-Lawley trace', 'Value']\n    if n > 0:\n        b = (p + 2 * n) * (q + 2 * n) / 2 / (2 * n + 1) / (n - 1)\n        df1 = p * q\n        df2 = 4 + (p * q + 2) / (b - 1)\n        c = (df2 - 2) / 2 / n\n        F = df2 / df1 * U / c\n    else:\n        df1 = s * (2 * m + s + 1)\n        df2 = s * (s * n + 1)\n        F = df2 / df1 / s * U\n    results.loc['Hotelling-Lawley trace', 'Num DF'] = df1\n    results.loc['Hotelling-Lawley trace', 'Den DF'] = df2\n    results.loc['Hotelling-Lawley trace', 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc['Hotelling-Lawley trace', 'Pr > F'] = pval\n    sigma = results.loc[\"Roy's greatest root\", 'Value']\n    r = np.max([p, q])\n    df1 = r\n    df2 = v - r + q\n    F = df2 / df1 * sigma\n    results.loc[\"Roy's greatest root\", 'Num DF'] = df1\n    results.loc[\"Roy's greatest root\", 'Den DF'] = df2\n    results.loc[\"Roy's greatest root\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Roy's greatest root\", 'Pr > F'] = pval\n    return results",
            "def multivariate_stats(eigenvals, r_err_sscp, r_contrast, df_resid, tolerance=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    For multivariate linear model Y = X * B\\n    Testing hypotheses\\n        L*B*M = 0\\n    where L is contrast matrix, B is the parameters of the\\n    multivariate linear model and M is dependent variable transform matrix.\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n\\n    Parameters\\n    ----------\\n    eigenvals : ndarray\\n        The eigenvalues of inv(E + H)*H\\n    r_err_sscp : int\\n        Rank of E + H\\n    r_contrast : int\\n        Rank of T matrix\\n    df_resid : int\\n        Residual degree of freedom (n_samples minus n_variables of X)\\n    tolerance : float\\n        smaller than which eigenvalue is considered 0\\n\\n    Returns\\n    -------\\n    A DataFrame\\n\\n    References\\n    ----------\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introreg_sect012.htm\\n    \"\n    v = df_resid\n    p = r_err_sscp\n    q = r_contrast\n    s = np.min([p, q])\n    ind = eigenvals > tolerance\n    n_e = ind.sum()\n    eigv2 = eigenvals[ind]\n    eigv1 = np.array([i / (1 - i) for i in eigv2])\n    m = (np.abs(p - q) - 1) / 2\n    n = (v - p - 1) / 2\n    cols = ['Value', 'Num DF', 'Den DF', 'F Value', 'Pr > F']\n    index = [\"Wilks' lambda\", \"Pillai's trace\", 'Hotelling-Lawley trace', \"Roy's greatest root\"]\n    results = pd.DataFrame(columns=cols, index=index)\n\n    def fn(x):\n        return np.real([x])[0]\n    results.loc[\"Wilks' lambda\", 'Value'] = fn(np.prod(1 - eigv2))\n    results.loc[\"Pillai's trace\", 'Value'] = fn(eigv2.sum())\n    results.loc['Hotelling-Lawley trace', 'Value'] = fn(eigv1.sum())\n    results.loc[\"Roy's greatest root\", 'Value'] = fn(eigv1.max())\n    r = v - (p - q + 1) / 2\n    u = (p * q - 2) / 4\n    df1 = p * q\n    if p * p + q * q - 5 > 0:\n        t = np.sqrt((p * p * q * q - 4) / (p * p + q * q - 5))\n    else:\n        t = 1\n    df2 = r * t - 2 * u\n    lmd = results.loc[\"Wilks' lambda\", 'Value']\n    lmd = np.power(lmd, 1 / t)\n    F = (1 - lmd) / lmd * df2 / df1\n    results.loc[\"Wilks' lambda\", 'Num DF'] = df1\n    results.loc[\"Wilks' lambda\", 'Den DF'] = df2\n    results.loc[\"Wilks' lambda\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Wilks' lambda\", 'Pr > F'] = pval\n    V = results.loc[\"Pillai's trace\", 'Value']\n    df1 = s * (2 * m + s + 1)\n    df2 = s * (2 * n + s + 1)\n    F = df2 / df1 * V / (s - V)\n    results.loc[\"Pillai's trace\", 'Num DF'] = df1\n    results.loc[\"Pillai's trace\", 'Den DF'] = df2\n    results.loc[\"Pillai's trace\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Pillai's trace\", 'Pr > F'] = pval\n    U = results.loc['Hotelling-Lawley trace', 'Value']\n    if n > 0:\n        b = (p + 2 * n) * (q + 2 * n) / 2 / (2 * n + 1) / (n - 1)\n        df1 = p * q\n        df2 = 4 + (p * q + 2) / (b - 1)\n        c = (df2 - 2) / 2 / n\n        F = df2 / df1 * U / c\n    else:\n        df1 = s * (2 * m + s + 1)\n        df2 = s * (s * n + 1)\n        F = df2 / df1 / s * U\n    results.loc['Hotelling-Lawley trace', 'Num DF'] = df1\n    results.loc['Hotelling-Lawley trace', 'Den DF'] = df2\n    results.loc['Hotelling-Lawley trace', 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc['Hotelling-Lawley trace', 'Pr > F'] = pval\n    sigma = results.loc[\"Roy's greatest root\", 'Value']\n    r = np.max([p, q])\n    df1 = r\n    df2 = v - r + q\n    F = df2 / df1 * sigma\n    results.loc[\"Roy's greatest root\", 'Num DF'] = df1\n    results.loc[\"Roy's greatest root\", 'Den DF'] = df2\n    results.loc[\"Roy's greatest root\", 'F Value'] = F\n    pval = stats.f.sf(F, df1, df2)\n    results.loc[\"Roy's greatest root\", 'Pr > F'] = pval\n    return results"
        ]
    },
    {
        "func_name": "fn",
        "original": "def fn(L, M, C):\n    (params, df_resid, inv_cov, sscpr) = fit_results\n    t1 = L.dot(params).dot(M) - C\n    t2 = L.dot(inv_cov).dot(L.T)\n    q = matrix_rank(t2)\n    H = t1.T.dot(inv(t2)).dot(t1)\n    E = M.T.dot(sscpr).dot(M)\n    return (E, H, q, df_resid)",
        "mutated": [
            "def fn(L, M, C):\n    if False:\n        i = 10\n    (params, df_resid, inv_cov, sscpr) = fit_results\n    t1 = L.dot(params).dot(M) - C\n    t2 = L.dot(inv_cov).dot(L.T)\n    q = matrix_rank(t2)\n    H = t1.T.dot(inv(t2)).dot(t1)\n    E = M.T.dot(sscpr).dot(M)\n    return (E, H, q, df_resid)",
            "def fn(L, M, C):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (params, df_resid, inv_cov, sscpr) = fit_results\n    t1 = L.dot(params).dot(M) - C\n    t2 = L.dot(inv_cov).dot(L.T)\n    q = matrix_rank(t2)\n    H = t1.T.dot(inv(t2)).dot(t1)\n    E = M.T.dot(sscpr).dot(M)\n    return (E, H, q, df_resid)",
            "def fn(L, M, C):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (params, df_resid, inv_cov, sscpr) = fit_results\n    t1 = L.dot(params).dot(M) - C\n    t2 = L.dot(inv_cov).dot(L.T)\n    q = matrix_rank(t2)\n    H = t1.T.dot(inv(t2)).dot(t1)\n    E = M.T.dot(sscpr).dot(M)\n    return (E, H, q, df_resid)",
            "def fn(L, M, C):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (params, df_resid, inv_cov, sscpr) = fit_results\n    t1 = L.dot(params).dot(M) - C\n    t2 = L.dot(inv_cov).dot(L.T)\n    q = matrix_rank(t2)\n    H = t1.T.dot(inv(t2)).dot(t1)\n    E = M.T.dot(sscpr).dot(M)\n    return (E, H, q, df_resid)",
            "def fn(L, M, C):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (params, df_resid, inv_cov, sscpr) = fit_results\n    t1 = L.dot(params).dot(M) - C\n    t2 = L.dot(inv_cov).dot(L.T)\n    q = matrix_rank(t2)\n    H = t1.T.dot(inv(t2)).dot(t1)\n    E = M.T.dot(sscpr).dot(M)\n    return (E, H, q, df_resid)"
        ]
    },
    {
        "func_name": "_multivariate_ols_test",
        "original": "def _multivariate_ols_test(hypotheses, fit_results, exog_names, endog_names):\n\n    def fn(L, M, C):\n        (params, df_resid, inv_cov, sscpr) = fit_results\n        t1 = L.dot(params).dot(M) - C\n        t2 = L.dot(inv_cov).dot(L.T)\n        q = matrix_rank(t2)\n        H = t1.T.dot(inv(t2)).dot(t1)\n        E = M.T.dot(sscpr).dot(M)\n        return (E, H, q, df_resid)\n    return _multivariate_test(hypotheses, exog_names, endog_names, fn)",
        "mutated": [
            "def _multivariate_ols_test(hypotheses, fit_results, exog_names, endog_names):\n    if False:\n        i = 10\n\n    def fn(L, M, C):\n        (params, df_resid, inv_cov, sscpr) = fit_results\n        t1 = L.dot(params).dot(M) - C\n        t2 = L.dot(inv_cov).dot(L.T)\n        q = matrix_rank(t2)\n        H = t1.T.dot(inv(t2)).dot(t1)\n        E = M.T.dot(sscpr).dot(M)\n        return (E, H, q, df_resid)\n    return _multivariate_test(hypotheses, exog_names, endog_names, fn)",
            "def _multivariate_ols_test(hypotheses, fit_results, exog_names, endog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def fn(L, M, C):\n        (params, df_resid, inv_cov, sscpr) = fit_results\n        t1 = L.dot(params).dot(M) - C\n        t2 = L.dot(inv_cov).dot(L.T)\n        q = matrix_rank(t2)\n        H = t1.T.dot(inv(t2)).dot(t1)\n        E = M.T.dot(sscpr).dot(M)\n        return (E, H, q, df_resid)\n    return _multivariate_test(hypotheses, exog_names, endog_names, fn)",
            "def _multivariate_ols_test(hypotheses, fit_results, exog_names, endog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def fn(L, M, C):\n        (params, df_resid, inv_cov, sscpr) = fit_results\n        t1 = L.dot(params).dot(M) - C\n        t2 = L.dot(inv_cov).dot(L.T)\n        q = matrix_rank(t2)\n        H = t1.T.dot(inv(t2)).dot(t1)\n        E = M.T.dot(sscpr).dot(M)\n        return (E, H, q, df_resid)\n    return _multivariate_test(hypotheses, exog_names, endog_names, fn)",
            "def _multivariate_ols_test(hypotheses, fit_results, exog_names, endog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def fn(L, M, C):\n        (params, df_resid, inv_cov, sscpr) = fit_results\n        t1 = L.dot(params).dot(M) - C\n        t2 = L.dot(inv_cov).dot(L.T)\n        q = matrix_rank(t2)\n        H = t1.T.dot(inv(t2)).dot(t1)\n        E = M.T.dot(sscpr).dot(M)\n        return (E, H, q, df_resid)\n    return _multivariate_test(hypotheses, exog_names, endog_names, fn)",
            "def _multivariate_ols_test(hypotheses, fit_results, exog_names, endog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def fn(L, M, C):\n        (params, df_resid, inv_cov, sscpr) = fit_results\n        t1 = L.dot(params).dot(M) - C\n        t2 = L.dot(inv_cov).dot(L.T)\n        q = matrix_rank(t2)\n        H = t1.T.dot(inv(t2)).dot(t1)\n        E = M.T.dot(sscpr).dot(M)\n        return (E, H, q, df_resid)\n    return _multivariate_test(hypotheses, exog_names, endog_names, fn)"
        ]
    },
    {
        "func_name": "_multivariate_test",
        "original": "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef _multivariate_test(hypotheses, exog_names, endog_names, fn):\n    \"\"\"\n    Multivariate linear model hypotheses testing\n\n    For y = x * params, where y are the dependent variables and x are the\n    independent variables, testing L * params * M = 0 where L is the contrast\n    matrix for hypotheses testing and M is the transformation matrix for\n    transforming the dependent variables in y.\n\n    Algorithm:\n        T = L*inv(X'X)*L'\n        H = M'B'L'*inv(T)*LBM\n        E =  M'(Y'Y - B'X'XB)M\n    where H and E correspond to the numerator and denominator of a univariate\n    F-test. Then find the eigenvalues of inv(H + E)*H from which the\n    multivariate test statistics are calculated.\n\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML\n           /default/viewer.htm#statug_introreg_sect012.htm\n\n    Parameters\n    ----------\n    %(hypotheses_doc)s\n    k_xvar : int\n        The number of independent variables\n    k_yvar : int\n        The number of dependent variables\n    fn : function\n        a function fn(contrast_L, transform_M) that returns E, H, q, df_resid\n        where q is the rank of T matrix\n\n    Returns\n    -------\n    results : MANOVAResults\n    \"\"\"\n    k_xvar = len(exog_names)\n    k_yvar = len(endog_names)\n    results = {}\n    for hypo in hypotheses:\n        if len(hypo) == 2:\n            (name, L) = hypo\n            M = None\n            C = None\n        elif len(hypo) == 3:\n            (name, L, M) = hypo\n            C = None\n        elif len(hypo) == 4:\n            (name, L, M, C) = hypo\n        else:\n            raise ValueError('hypotheses must be a tuple of length 2, 3 or 4. len(hypotheses)=%d' % len(hypo))\n        if any((isinstance(j, str) for j in L)):\n            L = DesignInfo(exog_names).linear_constraint(L).coefs\n        else:\n            if not isinstance(L, np.ndarray) or len(L.shape) != 2:\n                raise ValueError('Contrast matrix L must be a 2-d array!')\n            if L.shape[1] != k_xvar:\n                raise ValueError('Contrast matrix L should have the same number of columns as exog! %d != %d' % (L.shape[1], k_xvar))\n        if M is None:\n            M = np.eye(k_yvar)\n        elif any((isinstance(j, str) for j in M)):\n            M = DesignInfo(endog_names).linear_constraint(M).coefs.T\n        elif M is not None:\n            if not isinstance(M, np.ndarray) or len(M.shape) != 2:\n                raise ValueError('Transform matrix M must be a 2-d array!')\n            if M.shape[0] != k_yvar:\n                raise ValueError('Transform matrix M should have the same number of rows as the number of columns of endog! %d != %d' % (M.shape[0], k_yvar))\n        if C is None:\n            C = np.zeros([L.shape[0], M.shape[1]])\n        elif not isinstance(C, np.ndarray):\n            raise ValueError('Constant matrix C must be a 2-d array!')\n        if C.shape[0] != L.shape[0]:\n            raise ValueError('contrast L and constant C must have the same number of rows! %d!=%d' % (L.shape[0], C.shape[0]))\n        if C.shape[1] != M.shape[1]:\n            raise ValueError('transform M and constant C must have the same number of columns! %d!=%d' % (M.shape[1], C.shape[1]))\n        (E, H, q, df_resid) = fn(L, M, C)\n        EH = np.add(E, H)\n        p = matrix_rank(EH)\n        eigv2 = np.sort(eigvals(solve(EH, H)))\n        stat_table = multivariate_stats(eigv2, p, q, df_resid)\n        results[name] = {'stat': stat_table, 'contrast_L': L, 'transform_M': M, 'constant_C': C, 'E': E, 'H': H}\n    return results",
        "mutated": [
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef _multivariate_test(hypotheses, exog_names, endog_names, fn):\n    if False:\n        i = 10\n    \"\\n    Multivariate linear model hypotheses testing\\n\\n    For y = x * params, where y are the dependent variables and x are the\\n    independent variables, testing L * params * M = 0 where L is the contrast\\n    matrix for hypotheses testing and M is the transformation matrix for\\n    transforming the dependent variables in y.\\n\\n    Algorithm:\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n    where H and E correspond to the numerator and denominator of a univariate\\n    F-test. Then find the eigenvalues of inv(H + E)*H from which the\\n    multivariate test statistics are calculated.\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML\\n           /default/viewer.htm#statug_introreg_sect012.htm\\n\\n    Parameters\\n    ----------\\n    %(hypotheses_doc)s\\n    k_xvar : int\\n        The number of independent variables\\n    k_yvar : int\\n        The number of dependent variables\\n    fn : function\\n        a function fn(contrast_L, transform_M) that returns E, H, q, df_resid\\n        where q is the rank of T matrix\\n\\n    Returns\\n    -------\\n    results : MANOVAResults\\n    \"\n    k_xvar = len(exog_names)\n    k_yvar = len(endog_names)\n    results = {}\n    for hypo in hypotheses:\n        if len(hypo) == 2:\n            (name, L) = hypo\n            M = None\n            C = None\n        elif len(hypo) == 3:\n            (name, L, M) = hypo\n            C = None\n        elif len(hypo) == 4:\n            (name, L, M, C) = hypo\n        else:\n            raise ValueError('hypotheses must be a tuple of length 2, 3 or 4. len(hypotheses)=%d' % len(hypo))\n        if any((isinstance(j, str) for j in L)):\n            L = DesignInfo(exog_names).linear_constraint(L).coefs\n        else:\n            if not isinstance(L, np.ndarray) or len(L.shape) != 2:\n                raise ValueError('Contrast matrix L must be a 2-d array!')\n            if L.shape[1] != k_xvar:\n                raise ValueError('Contrast matrix L should have the same number of columns as exog! %d != %d' % (L.shape[1], k_xvar))\n        if M is None:\n            M = np.eye(k_yvar)\n        elif any((isinstance(j, str) for j in M)):\n            M = DesignInfo(endog_names).linear_constraint(M).coefs.T\n        elif M is not None:\n            if not isinstance(M, np.ndarray) or len(M.shape) != 2:\n                raise ValueError('Transform matrix M must be a 2-d array!')\n            if M.shape[0] != k_yvar:\n                raise ValueError('Transform matrix M should have the same number of rows as the number of columns of endog! %d != %d' % (M.shape[0], k_yvar))\n        if C is None:\n            C = np.zeros([L.shape[0], M.shape[1]])\n        elif not isinstance(C, np.ndarray):\n            raise ValueError('Constant matrix C must be a 2-d array!')\n        if C.shape[0] != L.shape[0]:\n            raise ValueError('contrast L and constant C must have the same number of rows! %d!=%d' % (L.shape[0], C.shape[0]))\n        if C.shape[1] != M.shape[1]:\n            raise ValueError('transform M and constant C must have the same number of columns! %d!=%d' % (M.shape[1], C.shape[1]))\n        (E, H, q, df_resid) = fn(L, M, C)\n        EH = np.add(E, H)\n        p = matrix_rank(EH)\n        eigv2 = np.sort(eigvals(solve(EH, H)))\n        stat_table = multivariate_stats(eigv2, p, q, df_resid)\n        results[name] = {'stat': stat_table, 'contrast_L': L, 'transform_M': M, 'constant_C': C, 'E': E, 'H': H}\n    return results",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef _multivariate_test(hypotheses, exog_names, endog_names, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Multivariate linear model hypotheses testing\\n\\n    For y = x * params, where y are the dependent variables and x are the\\n    independent variables, testing L * params * M = 0 where L is the contrast\\n    matrix for hypotheses testing and M is the transformation matrix for\\n    transforming the dependent variables in y.\\n\\n    Algorithm:\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n    where H and E correspond to the numerator and denominator of a univariate\\n    F-test. Then find the eigenvalues of inv(H + E)*H from which the\\n    multivariate test statistics are calculated.\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML\\n           /default/viewer.htm#statug_introreg_sect012.htm\\n\\n    Parameters\\n    ----------\\n    %(hypotheses_doc)s\\n    k_xvar : int\\n        The number of independent variables\\n    k_yvar : int\\n        The number of dependent variables\\n    fn : function\\n        a function fn(contrast_L, transform_M) that returns E, H, q, df_resid\\n        where q is the rank of T matrix\\n\\n    Returns\\n    -------\\n    results : MANOVAResults\\n    \"\n    k_xvar = len(exog_names)\n    k_yvar = len(endog_names)\n    results = {}\n    for hypo in hypotheses:\n        if len(hypo) == 2:\n            (name, L) = hypo\n            M = None\n            C = None\n        elif len(hypo) == 3:\n            (name, L, M) = hypo\n            C = None\n        elif len(hypo) == 4:\n            (name, L, M, C) = hypo\n        else:\n            raise ValueError('hypotheses must be a tuple of length 2, 3 or 4. len(hypotheses)=%d' % len(hypo))\n        if any((isinstance(j, str) for j in L)):\n            L = DesignInfo(exog_names).linear_constraint(L).coefs\n        else:\n            if not isinstance(L, np.ndarray) or len(L.shape) != 2:\n                raise ValueError('Contrast matrix L must be a 2-d array!')\n            if L.shape[1] != k_xvar:\n                raise ValueError('Contrast matrix L should have the same number of columns as exog! %d != %d' % (L.shape[1], k_xvar))\n        if M is None:\n            M = np.eye(k_yvar)\n        elif any((isinstance(j, str) for j in M)):\n            M = DesignInfo(endog_names).linear_constraint(M).coefs.T\n        elif M is not None:\n            if not isinstance(M, np.ndarray) or len(M.shape) != 2:\n                raise ValueError('Transform matrix M must be a 2-d array!')\n            if M.shape[0] != k_yvar:\n                raise ValueError('Transform matrix M should have the same number of rows as the number of columns of endog! %d != %d' % (M.shape[0], k_yvar))\n        if C is None:\n            C = np.zeros([L.shape[0], M.shape[1]])\n        elif not isinstance(C, np.ndarray):\n            raise ValueError('Constant matrix C must be a 2-d array!')\n        if C.shape[0] != L.shape[0]:\n            raise ValueError('contrast L and constant C must have the same number of rows! %d!=%d' % (L.shape[0], C.shape[0]))\n        if C.shape[1] != M.shape[1]:\n            raise ValueError('transform M and constant C must have the same number of columns! %d!=%d' % (M.shape[1], C.shape[1]))\n        (E, H, q, df_resid) = fn(L, M, C)\n        EH = np.add(E, H)\n        p = matrix_rank(EH)\n        eigv2 = np.sort(eigvals(solve(EH, H)))\n        stat_table = multivariate_stats(eigv2, p, q, df_resid)\n        results[name] = {'stat': stat_table, 'contrast_L': L, 'transform_M': M, 'constant_C': C, 'E': E, 'H': H}\n    return results",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef _multivariate_test(hypotheses, exog_names, endog_names, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Multivariate linear model hypotheses testing\\n\\n    For y = x * params, where y are the dependent variables and x are the\\n    independent variables, testing L * params * M = 0 where L is the contrast\\n    matrix for hypotheses testing and M is the transformation matrix for\\n    transforming the dependent variables in y.\\n\\n    Algorithm:\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n    where H and E correspond to the numerator and denominator of a univariate\\n    F-test. Then find the eigenvalues of inv(H + E)*H from which the\\n    multivariate test statistics are calculated.\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML\\n           /default/viewer.htm#statug_introreg_sect012.htm\\n\\n    Parameters\\n    ----------\\n    %(hypotheses_doc)s\\n    k_xvar : int\\n        The number of independent variables\\n    k_yvar : int\\n        The number of dependent variables\\n    fn : function\\n        a function fn(contrast_L, transform_M) that returns E, H, q, df_resid\\n        where q is the rank of T matrix\\n\\n    Returns\\n    -------\\n    results : MANOVAResults\\n    \"\n    k_xvar = len(exog_names)\n    k_yvar = len(endog_names)\n    results = {}\n    for hypo in hypotheses:\n        if len(hypo) == 2:\n            (name, L) = hypo\n            M = None\n            C = None\n        elif len(hypo) == 3:\n            (name, L, M) = hypo\n            C = None\n        elif len(hypo) == 4:\n            (name, L, M, C) = hypo\n        else:\n            raise ValueError('hypotheses must be a tuple of length 2, 3 or 4. len(hypotheses)=%d' % len(hypo))\n        if any((isinstance(j, str) for j in L)):\n            L = DesignInfo(exog_names).linear_constraint(L).coefs\n        else:\n            if not isinstance(L, np.ndarray) or len(L.shape) != 2:\n                raise ValueError('Contrast matrix L must be a 2-d array!')\n            if L.shape[1] != k_xvar:\n                raise ValueError('Contrast matrix L should have the same number of columns as exog! %d != %d' % (L.shape[1], k_xvar))\n        if M is None:\n            M = np.eye(k_yvar)\n        elif any((isinstance(j, str) for j in M)):\n            M = DesignInfo(endog_names).linear_constraint(M).coefs.T\n        elif M is not None:\n            if not isinstance(M, np.ndarray) or len(M.shape) != 2:\n                raise ValueError('Transform matrix M must be a 2-d array!')\n            if M.shape[0] != k_yvar:\n                raise ValueError('Transform matrix M should have the same number of rows as the number of columns of endog! %d != %d' % (M.shape[0], k_yvar))\n        if C is None:\n            C = np.zeros([L.shape[0], M.shape[1]])\n        elif not isinstance(C, np.ndarray):\n            raise ValueError('Constant matrix C must be a 2-d array!')\n        if C.shape[0] != L.shape[0]:\n            raise ValueError('contrast L and constant C must have the same number of rows! %d!=%d' % (L.shape[0], C.shape[0]))\n        if C.shape[1] != M.shape[1]:\n            raise ValueError('transform M and constant C must have the same number of columns! %d!=%d' % (M.shape[1], C.shape[1]))\n        (E, H, q, df_resid) = fn(L, M, C)\n        EH = np.add(E, H)\n        p = matrix_rank(EH)\n        eigv2 = np.sort(eigvals(solve(EH, H)))\n        stat_table = multivariate_stats(eigv2, p, q, df_resid)\n        results[name] = {'stat': stat_table, 'contrast_L': L, 'transform_M': M, 'constant_C': C, 'E': E, 'H': H}\n    return results",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef _multivariate_test(hypotheses, exog_names, endog_names, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Multivariate linear model hypotheses testing\\n\\n    For y = x * params, where y are the dependent variables and x are the\\n    independent variables, testing L * params * M = 0 where L is the contrast\\n    matrix for hypotheses testing and M is the transformation matrix for\\n    transforming the dependent variables in y.\\n\\n    Algorithm:\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n    where H and E correspond to the numerator and denominator of a univariate\\n    F-test. Then find the eigenvalues of inv(H + E)*H from which the\\n    multivariate test statistics are calculated.\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML\\n           /default/viewer.htm#statug_introreg_sect012.htm\\n\\n    Parameters\\n    ----------\\n    %(hypotheses_doc)s\\n    k_xvar : int\\n        The number of independent variables\\n    k_yvar : int\\n        The number of dependent variables\\n    fn : function\\n        a function fn(contrast_L, transform_M) that returns E, H, q, df_resid\\n        where q is the rank of T matrix\\n\\n    Returns\\n    -------\\n    results : MANOVAResults\\n    \"\n    k_xvar = len(exog_names)\n    k_yvar = len(endog_names)\n    results = {}\n    for hypo in hypotheses:\n        if len(hypo) == 2:\n            (name, L) = hypo\n            M = None\n            C = None\n        elif len(hypo) == 3:\n            (name, L, M) = hypo\n            C = None\n        elif len(hypo) == 4:\n            (name, L, M, C) = hypo\n        else:\n            raise ValueError('hypotheses must be a tuple of length 2, 3 or 4. len(hypotheses)=%d' % len(hypo))\n        if any((isinstance(j, str) for j in L)):\n            L = DesignInfo(exog_names).linear_constraint(L).coefs\n        else:\n            if not isinstance(L, np.ndarray) or len(L.shape) != 2:\n                raise ValueError('Contrast matrix L must be a 2-d array!')\n            if L.shape[1] != k_xvar:\n                raise ValueError('Contrast matrix L should have the same number of columns as exog! %d != %d' % (L.shape[1], k_xvar))\n        if M is None:\n            M = np.eye(k_yvar)\n        elif any((isinstance(j, str) for j in M)):\n            M = DesignInfo(endog_names).linear_constraint(M).coefs.T\n        elif M is not None:\n            if not isinstance(M, np.ndarray) or len(M.shape) != 2:\n                raise ValueError('Transform matrix M must be a 2-d array!')\n            if M.shape[0] != k_yvar:\n                raise ValueError('Transform matrix M should have the same number of rows as the number of columns of endog! %d != %d' % (M.shape[0], k_yvar))\n        if C is None:\n            C = np.zeros([L.shape[0], M.shape[1]])\n        elif not isinstance(C, np.ndarray):\n            raise ValueError('Constant matrix C must be a 2-d array!')\n        if C.shape[0] != L.shape[0]:\n            raise ValueError('contrast L and constant C must have the same number of rows! %d!=%d' % (L.shape[0], C.shape[0]))\n        if C.shape[1] != M.shape[1]:\n            raise ValueError('transform M and constant C must have the same number of columns! %d!=%d' % (M.shape[1], C.shape[1]))\n        (E, H, q, df_resid) = fn(L, M, C)\n        EH = np.add(E, H)\n        p = matrix_rank(EH)\n        eigv2 = np.sort(eigvals(solve(EH, H)))\n        stat_table = multivariate_stats(eigv2, p, q, df_resid)\n        results[name] = {'stat': stat_table, 'contrast_L': L, 'transform_M': M, 'constant_C': C, 'E': E, 'H': H}\n    return results",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef _multivariate_test(hypotheses, exog_names, endog_names, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Multivariate linear model hypotheses testing\\n\\n    For y = x * params, where y are the dependent variables and x are the\\n    independent variables, testing L * params * M = 0 where L is the contrast\\n    matrix for hypotheses testing and M is the transformation matrix for\\n    transforming the dependent variables in y.\\n\\n    Algorithm:\\n        T = L*inv(X'X)*L'\\n        H = M'B'L'*inv(T)*LBM\\n        E =  M'(Y'Y - B'X'XB)M\\n    where H and E correspond to the numerator and denominator of a univariate\\n    F-test. Then find the eigenvalues of inv(H + E)*H from which the\\n    multivariate test statistics are calculated.\\n\\n    .. [*] https://support.sas.com/documentation/cdl/en/statug/63033/HTML\\n           /default/viewer.htm#statug_introreg_sect012.htm\\n\\n    Parameters\\n    ----------\\n    %(hypotheses_doc)s\\n    k_xvar : int\\n        The number of independent variables\\n    k_yvar : int\\n        The number of dependent variables\\n    fn : function\\n        a function fn(contrast_L, transform_M) that returns E, H, q, df_resid\\n        where q is the rank of T matrix\\n\\n    Returns\\n    -------\\n    results : MANOVAResults\\n    \"\n    k_xvar = len(exog_names)\n    k_yvar = len(endog_names)\n    results = {}\n    for hypo in hypotheses:\n        if len(hypo) == 2:\n            (name, L) = hypo\n            M = None\n            C = None\n        elif len(hypo) == 3:\n            (name, L, M) = hypo\n            C = None\n        elif len(hypo) == 4:\n            (name, L, M, C) = hypo\n        else:\n            raise ValueError('hypotheses must be a tuple of length 2, 3 or 4. len(hypotheses)=%d' % len(hypo))\n        if any((isinstance(j, str) for j in L)):\n            L = DesignInfo(exog_names).linear_constraint(L).coefs\n        else:\n            if not isinstance(L, np.ndarray) or len(L.shape) != 2:\n                raise ValueError('Contrast matrix L must be a 2-d array!')\n            if L.shape[1] != k_xvar:\n                raise ValueError('Contrast matrix L should have the same number of columns as exog! %d != %d' % (L.shape[1], k_xvar))\n        if M is None:\n            M = np.eye(k_yvar)\n        elif any((isinstance(j, str) for j in M)):\n            M = DesignInfo(endog_names).linear_constraint(M).coefs.T\n        elif M is not None:\n            if not isinstance(M, np.ndarray) or len(M.shape) != 2:\n                raise ValueError('Transform matrix M must be a 2-d array!')\n            if M.shape[0] != k_yvar:\n                raise ValueError('Transform matrix M should have the same number of rows as the number of columns of endog! %d != %d' % (M.shape[0], k_yvar))\n        if C is None:\n            C = np.zeros([L.shape[0], M.shape[1]])\n        elif not isinstance(C, np.ndarray):\n            raise ValueError('Constant matrix C must be a 2-d array!')\n        if C.shape[0] != L.shape[0]:\n            raise ValueError('contrast L and constant C must have the same number of rows! %d!=%d' % (L.shape[0], C.shape[0]))\n        if C.shape[1] != M.shape[1]:\n            raise ValueError('transform M and constant C must have the same number of columns! %d!=%d' % (M.shape[1], C.shape[1]))\n        (E, H, q, df_resid) = fn(L, M, C)\n        EH = np.add(E, H)\n        p = matrix_rank(EH)\n        eigv2 = np.sort(eigvals(solve(EH, H)))\n        stat_table = multivariate_stats(eigv2, p, q, df_resid)\n        results[name] = {'stat': stat_table, 'contrast_L': L, 'transform_M': M, 'constant_C': C, 'E': E, 'H': H}\n    return results"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, missing='none', hasconst=None, **kwargs):\n    if len(endog.shape) == 1 or endog.shape[1] == 1:\n        raise ValueError('There must be more than one dependent variable to fit multivariate OLS!')\n    super(_MultivariateOLS, self).__init__(endog, exog, missing=missing, hasconst=hasconst, **kwargs)",
        "mutated": [
            "def __init__(self, endog, exog, missing='none', hasconst=None, **kwargs):\n    if False:\n        i = 10\n    if len(endog.shape) == 1 or endog.shape[1] == 1:\n        raise ValueError('There must be more than one dependent variable to fit multivariate OLS!')\n    super(_MultivariateOLS, self).__init__(endog, exog, missing=missing, hasconst=hasconst, **kwargs)",
            "def __init__(self, endog, exog, missing='none', hasconst=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(endog.shape) == 1 or endog.shape[1] == 1:\n        raise ValueError('There must be more than one dependent variable to fit multivariate OLS!')\n    super(_MultivariateOLS, self).__init__(endog, exog, missing=missing, hasconst=hasconst, **kwargs)",
            "def __init__(self, endog, exog, missing='none', hasconst=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(endog.shape) == 1 or endog.shape[1] == 1:\n        raise ValueError('There must be more than one dependent variable to fit multivariate OLS!')\n    super(_MultivariateOLS, self).__init__(endog, exog, missing=missing, hasconst=hasconst, **kwargs)",
            "def __init__(self, endog, exog, missing='none', hasconst=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(endog.shape) == 1 or endog.shape[1] == 1:\n        raise ValueError('There must be more than one dependent variable to fit multivariate OLS!')\n    super(_MultivariateOLS, self).__init__(endog, exog, missing=missing, hasconst=hasconst, **kwargs)",
            "def __init__(self, endog, exog, missing='none', hasconst=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(endog.shape) == 1 or endog.shape[1] == 1:\n        raise ValueError('There must be more than one dependent variable to fit multivariate OLS!')\n    super(_MultivariateOLS, self).__init__(endog, exog, missing=missing, hasconst=hasconst, **kwargs)"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, method='svd'):\n    self._fittedmod = _multivariate_ols_fit(self.endog, self.exog, method=method)\n    return _MultivariateOLSResults(self)",
        "mutated": [
            "def fit(self, method='svd'):\n    if False:\n        i = 10\n    self._fittedmod = _multivariate_ols_fit(self.endog, self.exog, method=method)\n    return _MultivariateOLSResults(self)",
            "def fit(self, method='svd'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._fittedmod = _multivariate_ols_fit(self.endog, self.exog, method=method)\n    return _MultivariateOLSResults(self)",
            "def fit(self, method='svd'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._fittedmod = _multivariate_ols_fit(self.endog, self.exog, method=method)\n    return _MultivariateOLSResults(self)",
            "def fit(self, method='svd'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._fittedmod = _multivariate_ols_fit(self.endog, self.exog, method=method)\n    return _MultivariateOLSResults(self)",
            "def fit(self, method='svd'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._fittedmod = _multivariate_ols_fit(self.endog, self.exog, method=method)\n    return _MultivariateOLSResults(self)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, fitted_mv_ols):\n    if hasattr(fitted_mv_ols, 'data') and hasattr(fitted_mv_ols.data, 'design_info'):\n        self.design_info = fitted_mv_ols.data.design_info\n    else:\n        self.design_info = None\n    self.exog_names = fitted_mv_ols.exog_names\n    self.endog_names = fitted_mv_ols.endog_names\n    self._fittedmod = fitted_mv_ols._fittedmod",
        "mutated": [
            "def __init__(self, fitted_mv_ols):\n    if False:\n        i = 10\n    if hasattr(fitted_mv_ols, 'data') and hasattr(fitted_mv_ols.data, 'design_info'):\n        self.design_info = fitted_mv_ols.data.design_info\n    else:\n        self.design_info = None\n    self.exog_names = fitted_mv_ols.exog_names\n    self.endog_names = fitted_mv_ols.endog_names\n    self._fittedmod = fitted_mv_ols._fittedmod",
            "def __init__(self, fitted_mv_ols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if hasattr(fitted_mv_ols, 'data') and hasattr(fitted_mv_ols.data, 'design_info'):\n        self.design_info = fitted_mv_ols.data.design_info\n    else:\n        self.design_info = None\n    self.exog_names = fitted_mv_ols.exog_names\n    self.endog_names = fitted_mv_ols.endog_names\n    self._fittedmod = fitted_mv_ols._fittedmod",
            "def __init__(self, fitted_mv_ols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if hasattr(fitted_mv_ols, 'data') and hasattr(fitted_mv_ols.data, 'design_info'):\n        self.design_info = fitted_mv_ols.data.design_info\n    else:\n        self.design_info = None\n    self.exog_names = fitted_mv_ols.exog_names\n    self.endog_names = fitted_mv_ols.endog_names\n    self._fittedmod = fitted_mv_ols._fittedmod",
            "def __init__(self, fitted_mv_ols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if hasattr(fitted_mv_ols, 'data') and hasattr(fitted_mv_ols.data, 'design_info'):\n        self.design_info = fitted_mv_ols.data.design_info\n    else:\n        self.design_info = None\n    self.exog_names = fitted_mv_ols.exog_names\n    self.endog_names = fitted_mv_ols.endog_names\n    self._fittedmod = fitted_mv_ols._fittedmod",
            "def __init__(self, fitted_mv_ols):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if hasattr(fitted_mv_ols, 'data') and hasattr(fitted_mv_ols.data, 'design_info'):\n        self.design_info = fitted_mv_ols.data.design_info\n    else:\n        self.design_info = None\n    self.exog_names = fitted_mv_ols.exog_names\n    self.endog_names = fitted_mv_ols.endog_names\n    self._fittedmod = fitted_mv_ols._fittedmod"
        ]
    },
    {
        "func_name": "__str__",
        "original": "def __str__(self):\n    return self.summary().__str__()",
        "mutated": [
            "def __str__(self):\n    if False:\n        i = 10\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.summary().__str__()"
        ]
    },
    {
        "func_name": "mv_test",
        "original": "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef mv_test(self, hypotheses=None, skip_intercept_test=False):\n    \"\"\"\n        Linear hypotheses testing\n\n        Parameters\n        ----------\n        %(hypotheses_doc)s\n        skip_intercept_test : bool\n            If true, then testing the intercept is skipped, the model is not\n            changed.\n            Note: If a term has a numerically insignificant effect, then\n            an exception because of emtpy arrays may be raised. This can\n            happen for the intercept if the data has been demeaned.\n\n        Returns\n        -------\n        results: _MultivariateOLSResults\n\n        Notes\n        -----\n        Tests hypotheses of the form\n\n            L * params * M = C\n\n        where `params` is the regression coefficient matrix for the\n        linear model y = x * params, `L` is the contrast matrix, `M` is the\n        dependent variable transform matrix and C is the constant matrix.\n        \"\"\"\n    k_xvar = len(self.exog_names)\n    if hypotheses is None:\n        if self.design_info is not None:\n            terms = self.design_info.term_name_slices\n            hypotheses = []\n            for key in terms:\n                if skip_intercept_test and key == 'Intercept':\n                    continue\n                L_contrast = np.eye(k_xvar)[terms[key], :]\n                hypotheses.append([key, L_contrast, None])\n        else:\n            hypotheses = []\n            for i in range(k_xvar):\n                name = 'x%d' % i\n                L = np.zeros([1, k_xvar])\n                L[i] = 1\n                hypotheses.append([name, L, None])\n    results = _multivariate_ols_test(hypotheses, self._fittedmod, self.exog_names, self.endog_names)\n    return MultivariateTestResults(results, self.endog_names, self.exog_names)",
        "mutated": [
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef mv_test(self, hypotheses=None, skip_intercept_test=False):\n    if False:\n        i = 10\n    '\\n        Linear hypotheses testing\\n\\n        Parameters\\n        ----------\\n        %(hypotheses_doc)s\\n        skip_intercept_test : bool\\n            If true, then testing the intercept is skipped, the model is not\\n            changed.\\n            Note: If a term has a numerically insignificant effect, then\\n            an exception because of emtpy arrays may be raised. This can\\n            happen for the intercept if the data has been demeaned.\\n\\n        Returns\\n        -------\\n        results: _MultivariateOLSResults\\n\\n        Notes\\n        -----\\n        Tests hypotheses of the form\\n\\n            L * params * M = C\\n\\n        where `params` is the regression coefficient matrix for the\\n        linear model y = x * params, `L` is the contrast matrix, `M` is the\\n        dependent variable transform matrix and C is the constant matrix.\\n        '\n    k_xvar = len(self.exog_names)\n    if hypotheses is None:\n        if self.design_info is not None:\n            terms = self.design_info.term_name_slices\n            hypotheses = []\n            for key in terms:\n                if skip_intercept_test and key == 'Intercept':\n                    continue\n                L_contrast = np.eye(k_xvar)[terms[key], :]\n                hypotheses.append([key, L_contrast, None])\n        else:\n            hypotheses = []\n            for i in range(k_xvar):\n                name = 'x%d' % i\n                L = np.zeros([1, k_xvar])\n                L[i] = 1\n                hypotheses.append([name, L, None])\n    results = _multivariate_ols_test(hypotheses, self._fittedmod, self.exog_names, self.endog_names)\n    return MultivariateTestResults(results, self.endog_names, self.exog_names)",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef mv_test(self, hypotheses=None, skip_intercept_test=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Linear hypotheses testing\\n\\n        Parameters\\n        ----------\\n        %(hypotheses_doc)s\\n        skip_intercept_test : bool\\n            If true, then testing the intercept is skipped, the model is not\\n            changed.\\n            Note: If a term has a numerically insignificant effect, then\\n            an exception because of emtpy arrays may be raised. This can\\n            happen for the intercept if the data has been demeaned.\\n\\n        Returns\\n        -------\\n        results: _MultivariateOLSResults\\n\\n        Notes\\n        -----\\n        Tests hypotheses of the form\\n\\n            L * params * M = C\\n\\n        where `params` is the regression coefficient matrix for the\\n        linear model y = x * params, `L` is the contrast matrix, `M` is the\\n        dependent variable transform matrix and C is the constant matrix.\\n        '\n    k_xvar = len(self.exog_names)\n    if hypotheses is None:\n        if self.design_info is not None:\n            terms = self.design_info.term_name_slices\n            hypotheses = []\n            for key in terms:\n                if skip_intercept_test and key == 'Intercept':\n                    continue\n                L_contrast = np.eye(k_xvar)[terms[key], :]\n                hypotheses.append([key, L_contrast, None])\n        else:\n            hypotheses = []\n            for i in range(k_xvar):\n                name = 'x%d' % i\n                L = np.zeros([1, k_xvar])\n                L[i] = 1\n                hypotheses.append([name, L, None])\n    results = _multivariate_ols_test(hypotheses, self._fittedmod, self.exog_names, self.endog_names)\n    return MultivariateTestResults(results, self.endog_names, self.exog_names)",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef mv_test(self, hypotheses=None, skip_intercept_test=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Linear hypotheses testing\\n\\n        Parameters\\n        ----------\\n        %(hypotheses_doc)s\\n        skip_intercept_test : bool\\n            If true, then testing the intercept is skipped, the model is not\\n            changed.\\n            Note: If a term has a numerically insignificant effect, then\\n            an exception because of emtpy arrays may be raised. This can\\n            happen for the intercept if the data has been demeaned.\\n\\n        Returns\\n        -------\\n        results: _MultivariateOLSResults\\n\\n        Notes\\n        -----\\n        Tests hypotheses of the form\\n\\n            L * params * M = C\\n\\n        where `params` is the regression coefficient matrix for the\\n        linear model y = x * params, `L` is the contrast matrix, `M` is the\\n        dependent variable transform matrix and C is the constant matrix.\\n        '\n    k_xvar = len(self.exog_names)\n    if hypotheses is None:\n        if self.design_info is not None:\n            terms = self.design_info.term_name_slices\n            hypotheses = []\n            for key in terms:\n                if skip_intercept_test and key == 'Intercept':\n                    continue\n                L_contrast = np.eye(k_xvar)[terms[key], :]\n                hypotheses.append([key, L_contrast, None])\n        else:\n            hypotheses = []\n            for i in range(k_xvar):\n                name = 'x%d' % i\n                L = np.zeros([1, k_xvar])\n                L[i] = 1\n                hypotheses.append([name, L, None])\n    results = _multivariate_ols_test(hypotheses, self._fittedmod, self.exog_names, self.endog_names)\n    return MultivariateTestResults(results, self.endog_names, self.exog_names)",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef mv_test(self, hypotheses=None, skip_intercept_test=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Linear hypotheses testing\\n\\n        Parameters\\n        ----------\\n        %(hypotheses_doc)s\\n        skip_intercept_test : bool\\n            If true, then testing the intercept is skipped, the model is not\\n            changed.\\n            Note: If a term has a numerically insignificant effect, then\\n            an exception because of emtpy arrays may be raised. This can\\n            happen for the intercept if the data has been demeaned.\\n\\n        Returns\\n        -------\\n        results: _MultivariateOLSResults\\n\\n        Notes\\n        -----\\n        Tests hypotheses of the form\\n\\n            L * params * M = C\\n\\n        where `params` is the regression coefficient matrix for the\\n        linear model y = x * params, `L` is the contrast matrix, `M` is the\\n        dependent variable transform matrix and C is the constant matrix.\\n        '\n    k_xvar = len(self.exog_names)\n    if hypotheses is None:\n        if self.design_info is not None:\n            terms = self.design_info.term_name_slices\n            hypotheses = []\n            for key in terms:\n                if skip_intercept_test and key == 'Intercept':\n                    continue\n                L_contrast = np.eye(k_xvar)[terms[key], :]\n                hypotheses.append([key, L_contrast, None])\n        else:\n            hypotheses = []\n            for i in range(k_xvar):\n                name = 'x%d' % i\n                L = np.zeros([1, k_xvar])\n                L[i] = 1\n                hypotheses.append([name, L, None])\n    results = _multivariate_ols_test(hypotheses, self._fittedmod, self.exog_names, self.endog_names)\n    return MultivariateTestResults(results, self.endog_names, self.exog_names)",
            "@Substitution(hypotheses_doc=_hypotheses_doc)\ndef mv_test(self, hypotheses=None, skip_intercept_test=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Linear hypotheses testing\\n\\n        Parameters\\n        ----------\\n        %(hypotheses_doc)s\\n        skip_intercept_test : bool\\n            If true, then testing the intercept is skipped, the model is not\\n            changed.\\n            Note: If a term has a numerically insignificant effect, then\\n            an exception because of emtpy arrays may be raised. This can\\n            happen for the intercept if the data has been demeaned.\\n\\n        Returns\\n        -------\\n        results: _MultivariateOLSResults\\n\\n        Notes\\n        -----\\n        Tests hypotheses of the form\\n\\n            L * params * M = C\\n\\n        where `params` is the regression coefficient matrix for the\\n        linear model y = x * params, `L` is the contrast matrix, `M` is the\\n        dependent variable transform matrix and C is the constant matrix.\\n        '\n    k_xvar = len(self.exog_names)\n    if hypotheses is None:\n        if self.design_info is not None:\n            terms = self.design_info.term_name_slices\n            hypotheses = []\n            for key in terms:\n                if skip_intercept_test and key == 'Intercept':\n                    continue\n                L_contrast = np.eye(k_xvar)[terms[key], :]\n                hypotheses.append([key, L_contrast, None])\n        else:\n            hypotheses = []\n            for i in range(k_xvar):\n                name = 'x%d' % i\n                L = np.zeros([1, k_xvar])\n                L[i] = 1\n                hypotheses.append([name, L, None])\n    results = _multivariate_ols_test(hypotheses, self._fittedmod, self.exog_names, self.endog_names)\n    return MultivariateTestResults(results, self.endog_names, self.exog_names)"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self):\n    raise NotImplementedError",
        "mutated": [
            "def summary(self):\n    if False:\n        i = 10\n    raise NotImplementedError",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    raise NotImplementedError",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    raise NotImplementedError",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    raise NotImplementedError",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    raise NotImplementedError"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, results, endog_names, exog_names):\n    self.results = results\n    self.endog_names = list(endog_names)\n    self.exog_names = list(exog_names)",
        "mutated": [
            "def __init__(self, results, endog_names, exog_names):\n    if False:\n        i = 10\n    self.results = results\n    self.endog_names = list(endog_names)\n    self.exog_names = list(exog_names)",
            "def __init__(self, results, endog_names, exog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.results = results\n    self.endog_names = list(endog_names)\n    self.exog_names = list(exog_names)",
            "def __init__(self, results, endog_names, exog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.results = results\n    self.endog_names = list(endog_names)\n    self.exog_names = list(exog_names)",
            "def __init__(self, results, endog_names, exog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.results = results\n    self.endog_names = list(endog_names)\n    self.exog_names = list(exog_names)",
            "def __init__(self, results, endog_names, exog_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.results = results\n    self.endog_names = list(endog_names)\n    self.exog_names = list(exog_names)"
        ]
    },
    {
        "func_name": "__str__",
        "original": "def __str__(self):\n    return self.summary().__str__()",
        "mutated": [
            "def __str__(self):\n    if False:\n        i = 10\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.summary().__str__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.summary().__str__()"
        ]
    },
    {
        "func_name": "__getitem__",
        "original": "def __getitem__(self, item):\n    return self.results[item]",
        "mutated": [
            "def __getitem__(self, item):\n    if False:\n        i = 10\n    return self.results[item]",
            "def __getitem__(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.results[item]",
            "def __getitem__(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.results[item]",
            "def __getitem__(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.results[item]",
            "def __getitem__(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.results[item]"
        ]
    },
    {
        "func_name": "summary_frame",
        "original": "@property\ndef summary_frame(self):\n    \"\"\"\n        Return results as a multiindex dataframe\n        \"\"\"\n    df = []\n    for key in self.results:\n        tmp = self.results[key]['stat'].copy()\n        tmp.loc[:, 'Effect'] = key\n        df.append(tmp.reset_index())\n    df = pd.concat(df, axis=0)\n    df = df.set_index(['Effect', 'index'])\n    df.index.set_names(['Effect', 'Statistic'], inplace=True)\n    return df",
        "mutated": [
            "@property\ndef summary_frame(self):\n    if False:\n        i = 10\n    '\\n        Return results as a multiindex dataframe\\n        '\n    df = []\n    for key in self.results:\n        tmp = self.results[key]['stat'].copy()\n        tmp.loc[:, 'Effect'] = key\n        df.append(tmp.reset_index())\n    df = pd.concat(df, axis=0)\n    df = df.set_index(['Effect', 'index'])\n    df.index.set_names(['Effect', 'Statistic'], inplace=True)\n    return df",
            "@property\ndef summary_frame(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return results as a multiindex dataframe\\n        '\n    df = []\n    for key in self.results:\n        tmp = self.results[key]['stat'].copy()\n        tmp.loc[:, 'Effect'] = key\n        df.append(tmp.reset_index())\n    df = pd.concat(df, axis=0)\n    df = df.set_index(['Effect', 'index'])\n    df.index.set_names(['Effect', 'Statistic'], inplace=True)\n    return df",
            "@property\ndef summary_frame(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return results as a multiindex dataframe\\n        '\n    df = []\n    for key in self.results:\n        tmp = self.results[key]['stat'].copy()\n        tmp.loc[:, 'Effect'] = key\n        df.append(tmp.reset_index())\n    df = pd.concat(df, axis=0)\n    df = df.set_index(['Effect', 'index'])\n    df.index.set_names(['Effect', 'Statistic'], inplace=True)\n    return df",
            "@property\ndef summary_frame(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return results as a multiindex dataframe\\n        '\n    df = []\n    for key in self.results:\n        tmp = self.results[key]['stat'].copy()\n        tmp.loc[:, 'Effect'] = key\n        df.append(tmp.reset_index())\n    df = pd.concat(df, axis=0)\n    df = df.set_index(['Effect', 'index'])\n    df.index.set_names(['Effect', 'Statistic'], inplace=True)\n    return df",
            "@property\ndef summary_frame(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return results as a multiindex dataframe\\n        '\n    df = []\n    for key in self.results:\n        tmp = self.results[key]['stat'].copy()\n        tmp.loc[:, 'Effect'] = key\n        df.append(tmp.reset_index())\n    df = pd.concat(df, axis=0)\n    df = df.set_index(['Effect', 'index'])\n    df.index.set_names(['Effect', 'Statistic'], inplace=True)\n    return df"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, show_contrast_L=False, show_transform_M=False, show_constant_C=False):\n    \"\"\"\n        Summary of test results\n\n        Parameters\n        ----------\n        show_contrast_L : bool\n            Whether to show contrast_L matrix\n        show_transform_M : bool\n            Whether to show transform_M matrix\n        show_constant_C : bool\n            Whether to show the constant_C\n        \"\"\"\n    summ = summary2.Summary()\n    summ.add_title('Multivariate linear model')\n    for key in self.results:\n        summ.add_dict({'': ''})\n        df = self.results[key]['stat'].copy()\n        df = df.reset_index()\n        c = list(df.columns)\n        c[0] = key\n        df.columns = c\n        df.index = ['', '', '', '']\n        summ.add_df(df)\n        if show_contrast_L:\n            summ.add_dict({key: ' contrast L='})\n            df = pd.DataFrame(self.results[key]['contrast_L'], columns=self.exog_names)\n            summ.add_df(df)\n        if show_transform_M:\n            summ.add_dict({key: ' transform M='})\n            df = pd.DataFrame(self.results[key]['transform_M'], index=self.endog_names)\n            summ.add_df(df)\n        if show_constant_C:\n            summ.add_dict({key: ' constant C='})\n            df = pd.DataFrame(self.results[key]['constant_C'])\n            summ.add_df(df)\n    return summ",
        "mutated": [
            "def summary(self, show_contrast_L=False, show_transform_M=False, show_constant_C=False):\n    if False:\n        i = 10\n    '\\n        Summary of test results\\n\\n        Parameters\\n        ----------\\n        show_contrast_L : bool\\n            Whether to show contrast_L matrix\\n        show_transform_M : bool\\n            Whether to show transform_M matrix\\n        show_constant_C : bool\\n            Whether to show the constant_C\\n        '\n    summ = summary2.Summary()\n    summ.add_title('Multivariate linear model')\n    for key in self.results:\n        summ.add_dict({'': ''})\n        df = self.results[key]['stat'].copy()\n        df = df.reset_index()\n        c = list(df.columns)\n        c[0] = key\n        df.columns = c\n        df.index = ['', '', '', '']\n        summ.add_df(df)\n        if show_contrast_L:\n            summ.add_dict({key: ' contrast L='})\n            df = pd.DataFrame(self.results[key]['contrast_L'], columns=self.exog_names)\n            summ.add_df(df)\n        if show_transform_M:\n            summ.add_dict({key: ' transform M='})\n            df = pd.DataFrame(self.results[key]['transform_M'], index=self.endog_names)\n            summ.add_df(df)\n        if show_constant_C:\n            summ.add_dict({key: ' constant C='})\n            df = pd.DataFrame(self.results[key]['constant_C'])\n            summ.add_df(df)\n    return summ",
            "def summary(self, show_contrast_L=False, show_transform_M=False, show_constant_C=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Summary of test results\\n\\n        Parameters\\n        ----------\\n        show_contrast_L : bool\\n            Whether to show contrast_L matrix\\n        show_transform_M : bool\\n            Whether to show transform_M matrix\\n        show_constant_C : bool\\n            Whether to show the constant_C\\n        '\n    summ = summary2.Summary()\n    summ.add_title('Multivariate linear model')\n    for key in self.results:\n        summ.add_dict({'': ''})\n        df = self.results[key]['stat'].copy()\n        df = df.reset_index()\n        c = list(df.columns)\n        c[0] = key\n        df.columns = c\n        df.index = ['', '', '', '']\n        summ.add_df(df)\n        if show_contrast_L:\n            summ.add_dict({key: ' contrast L='})\n            df = pd.DataFrame(self.results[key]['contrast_L'], columns=self.exog_names)\n            summ.add_df(df)\n        if show_transform_M:\n            summ.add_dict({key: ' transform M='})\n            df = pd.DataFrame(self.results[key]['transform_M'], index=self.endog_names)\n            summ.add_df(df)\n        if show_constant_C:\n            summ.add_dict({key: ' constant C='})\n            df = pd.DataFrame(self.results[key]['constant_C'])\n            summ.add_df(df)\n    return summ",
            "def summary(self, show_contrast_L=False, show_transform_M=False, show_constant_C=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Summary of test results\\n\\n        Parameters\\n        ----------\\n        show_contrast_L : bool\\n            Whether to show contrast_L matrix\\n        show_transform_M : bool\\n            Whether to show transform_M matrix\\n        show_constant_C : bool\\n            Whether to show the constant_C\\n        '\n    summ = summary2.Summary()\n    summ.add_title('Multivariate linear model')\n    for key in self.results:\n        summ.add_dict({'': ''})\n        df = self.results[key]['stat'].copy()\n        df = df.reset_index()\n        c = list(df.columns)\n        c[0] = key\n        df.columns = c\n        df.index = ['', '', '', '']\n        summ.add_df(df)\n        if show_contrast_L:\n            summ.add_dict({key: ' contrast L='})\n            df = pd.DataFrame(self.results[key]['contrast_L'], columns=self.exog_names)\n            summ.add_df(df)\n        if show_transform_M:\n            summ.add_dict({key: ' transform M='})\n            df = pd.DataFrame(self.results[key]['transform_M'], index=self.endog_names)\n            summ.add_df(df)\n        if show_constant_C:\n            summ.add_dict({key: ' constant C='})\n            df = pd.DataFrame(self.results[key]['constant_C'])\n            summ.add_df(df)\n    return summ",
            "def summary(self, show_contrast_L=False, show_transform_M=False, show_constant_C=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Summary of test results\\n\\n        Parameters\\n        ----------\\n        show_contrast_L : bool\\n            Whether to show contrast_L matrix\\n        show_transform_M : bool\\n            Whether to show transform_M matrix\\n        show_constant_C : bool\\n            Whether to show the constant_C\\n        '\n    summ = summary2.Summary()\n    summ.add_title('Multivariate linear model')\n    for key in self.results:\n        summ.add_dict({'': ''})\n        df = self.results[key]['stat'].copy()\n        df = df.reset_index()\n        c = list(df.columns)\n        c[0] = key\n        df.columns = c\n        df.index = ['', '', '', '']\n        summ.add_df(df)\n        if show_contrast_L:\n            summ.add_dict({key: ' contrast L='})\n            df = pd.DataFrame(self.results[key]['contrast_L'], columns=self.exog_names)\n            summ.add_df(df)\n        if show_transform_M:\n            summ.add_dict({key: ' transform M='})\n            df = pd.DataFrame(self.results[key]['transform_M'], index=self.endog_names)\n            summ.add_df(df)\n        if show_constant_C:\n            summ.add_dict({key: ' constant C='})\n            df = pd.DataFrame(self.results[key]['constant_C'])\n            summ.add_df(df)\n    return summ",
            "def summary(self, show_contrast_L=False, show_transform_M=False, show_constant_C=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Summary of test results\\n\\n        Parameters\\n        ----------\\n        show_contrast_L : bool\\n            Whether to show contrast_L matrix\\n        show_transform_M : bool\\n            Whether to show transform_M matrix\\n        show_constant_C : bool\\n            Whether to show the constant_C\\n        '\n    summ = summary2.Summary()\n    summ.add_title('Multivariate linear model')\n    for key in self.results:\n        summ.add_dict({'': ''})\n        df = self.results[key]['stat'].copy()\n        df = df.reset_index()\n        c = list(df.columns)\n        c[0] = key\n        df.columns = c\n        df.index = ['', '', '', '']\n        summ.add_df(df)\n        if show_contrast_L:\n            summ.add_dict({key: ' contrast L='})\n            df = pd.DataFrame(self.results[key]['contrast_L'], columns=self.exog_names)\n            summ.add_df(df)\n        if show_transform_M:\n            summ.add_dict({key: ' transform M='})\n            df = pd.DataFrame(self.results[key]['transform_M'], index=self.endog_names)\n            summ.add_df(df)\n        if show_constant_C:\n            summ.add_dict({key: ' constant C='})\n            df = pd.DataFrame(self.results[key]['constant_C'])\n            summ.add_df(df)\n    return summ"
        ]
    }
]