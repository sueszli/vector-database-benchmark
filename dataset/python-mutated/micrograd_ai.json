[
    {
        "func_name": "run_all_micrograd_demo",
        "original": "def run_all_micrograd_demo(*args, **kwargs):\n    result = micrograd_demo()\n    pyscript.write('micrograd-run-all-fig2-div', result)",
        "mutated": [
            "def run_all_micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n    result = micrograd_demo()\n    pyscript.write('micrograd-run-all-fig2-div', result)",
            "def run_all_micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    result = micrograd_demo()\n    pyscript.write('micrograd-run-all-fig2-div', result)",
            "def run_all_micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    result = micrograd_demo()\n    pyscript.write('micrograd-run-all-fig2-div', result)",
            "def run_all_micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    result = micrograd_demo()\n    pyscript.write('micrograd-run-all-fig2-div', result)",
            "def run_all_micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    result = micrograd_demo()\n    pyscript.write('micrograd-run-all-fig2-div', result)"
        ]
    },
    {
        "func_name": "print_div",
        "original": "def print_div(o):\n    o = str(o)\n    print_statements.append(o + ' \\n<br>')\n    pyscript.write('micrograd-run-all-print-div', ''.join(print_statements))",
        "mutated": [
            "def print_div(o):\n    if False:\n        i = 10\n    o = str(o)\n    print_statements.append(o + ' \\n<br>')\n    pyscript.write('micrograd-run-all-print-div', ''.join(print_statements))",
            "def print_div(o):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    o = str(o)\n    print_statements.append(o + ' \\n<br>')\n    pyscript.write('micrograd-run-all-print-div', ''.join(print_statements))",
            "def print_div(o):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    o = str(o)\n    print_statements.append(o + ' \\n<br>')\n    pyscript.write('micrograd-run-all-print-div', ''.join(print_statements))",
            "def print_div(o):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    o = str(o)\n    print_statements.append(o + ' \\n<br>')\n    pyscript.write('micrograd-run-all-print-div', ''.join(print_statements))",
            "def print_div(o):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    o = str(o)\n    print_statements.append(o + ' \\n<br>')\n    pyscript.write('micrograd-run-all-print-div', ''.join(print_statements))"
        ]
    },
    {
        "func_name": "make_moons",
        "original": "def make_moons(n_samples=100, noise=None):\n    (n_samples_out, n_samples_in) = (n_samples, n_samples)\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n    if noise is not None:\n        X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n    return (X, y)",
        "mutated": [
            "def make_moons(n_samples=100, noise=None):\n    if False:\n        i = 10\n    (n_samples_out, n_samples_in) = (n_samples, n_samples)\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n    if noise is not None:\n        X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n    return (X, y)",
            "def make_moons(n_samples=100, noise=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (n_samples_out, n_samples_in) = (n_samples, n_samples)\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n    if noise is not None:\n        X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n    return (X, y)",
            "def make_moons(n_samples=100, noise=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (n_samples_out, n_samples_in) = (n_samples, n_samples)\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n    if noise is not None:\n        X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n    return (X, y)",
            "def make_moons(n_samples=100, noise=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (n_samples_out, n_samples_in) = (n_samples, n_samples)\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n    if noise is not None:\n        X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n    return (X, y)",
            "def make_moons(n_samples=100, noise=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (n_samples_out, n_samples_in) = (n_samples, n_samples)\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n    X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n    y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n    if noise is not None:\n        X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n    return (X, y)"
        ]
    },
    {
        "func_name": "loss",
        "original": "def loss(batch_size=None):\n    if batch_size is None:\n        (Xb, yb) = (X, y)\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        (Xb, yb) = (X[ri], y[ri])\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    scores = list(map(model, inputs))\n    losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    alpha = 0.0001\n    reg_loss = alpha * sum((p * p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n    return (total_loss, sum(accuracy) / len(accuracy))",
        "mutated": [
            "def loss(batch_size=None):\n    if False:\n        i = 10\n    if batch_size is None:\n        (Xb, yb) = (X, y)\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        (Xb, yb) = (X[ri], y[ri])\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    scores = list(map(model, inputs))\n    losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    alpha = 0.0001\n    reg_loss = alpha * sum((p * p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n    return (total_loss, sum(accuracy) / len(accuracy))",
            "def loss(batch_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if batch_size is None:\n        (Xb, yb) = (X, y)\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        (Xb, yb) = (X[ri], y[ri])\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    scores = list(map(model, inputs))\n    losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    alpha = 0.0001\n    reg_loss = alpha * sum((p * p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n    return (total_loss, sum(accuracy) / len(accuracy))",
            "def loss(batch_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if batch_size is None:\n        (Xb, yb) = (X, y)\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        (Xb, yb) = (X[ri], y[ri])\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    scores = list(map(model, inputs))\n    losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    alpha = 0.0001\n    reg_loss = alpha * sum((p * p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n    return (total_loss, sum(accuracy) / len(accuracy))",
            "def loss(batch_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if batch_size is None:\n        (Xb, yb) = (X, y)\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        (Xb, yb) = (X[ri], y[ri])\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    scores = list(map(model, inputs))\n    losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    alpha = 0.0001\n    reg_loss = alpha * sum((p * p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n    return (total_loss, sum(accuracy) / len(accuracy))",
            "def loss(batch_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if batch_size is None:\n        (Xb, yb) = (X, y)\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        (Xb, yb) = (X[ri], y[ri])\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    scores = list(map(model, inputs))\n    losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    alpha = 0.0001\n    reg_loss = alpha * sum((p * p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n    return (total_loss, sum(accuracy) / len(accuracy))"
        ]
    },
    {
        "func_name": "micrograd_demo",
        "original": "def micrograd_demo(*args, **kwargs):\n    \"\"\"\n    Runs the micrograd demo.\n\n    *args and **kwargs do nothing and are only there to capture any parameters passed\n    from pyscript when this function is called when a button is clicked.\n    \"\"\"\n    start = datetime.datetime.now()\n    print_div('Starting...')\n    np.random.seed(1337)\n    random.seed(1337)\n\n    def make_moons(n_samples=100, noise=None):\n        (n_samples_out, n_samples_in) = (n_samples, n_samples)\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n        if noise is not None:\n            X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n        return (X, y)\n    (X, y) = make_moons(n_samples=100, noise=0.1)\n    y = y * 2 - 1\n    plt.figure(figsize=(5, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='jet')\n    plt\n    pyscript.write('micrograd-run-all-fig1-div', plt)\n    model = MLP(2, [16, 16, 1])\n    print_div(model)\n    print_div(('number of parameters', len(model.parameters())))\n\n    def loss(batch_size=None):\n        if batch_size is None:\n            (Xb, yb) = (X, y)\n        else:\n            ri = np.random.permutation(X.shape[0])[:batch_size]\n            (Xb, yb) = (X[ri], y[ri])\n        inputs = [list(map(Value, xrow)) for xrow in Xb]\n        scores = list(map(model, inputs))\n        losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n        data_loss = sum(losses) * (1.0 / len(losses))\n        alpha = 0.0001\n        reg_loss = alpha * sum((p * p for p in model.parameters()))\n        total_loss = data_loss + reg_loss\n        accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n        return (total_loss, sum(accuracy) / len(accuracy))\n    (total_loss, acc) = loss()\n    print((total_loss, acc))\n    for k in range(20):\n        (total_loss, _) = loss()\n        model.zero_grad()\n        total_loss.backward()\n        learning_rate = 1.0 - 0.9 * k / 100\n        for p in model.parameters():\n            p.data -= learning_rate * p.grad\n        if k % 1 == 0:\n            print_div(f'step {k} loss {total_loss.data}, accuracy {acc * 100}%')\n    h = 0.25\n    (x_min, x_max) = (X[:, 0].min() - 1, X[:, 0].max() + 1)\n    (y_min, y_max) = (X[:, 1].min() - 1, X[:, 1].max() + 1)\n    (xx, yy) = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n    scores = list(map(model, inputs))\n    Z = np.array([s.data.__gt__(0) for s in scores])\n    Z = Z.reshape(xx.shape)\n    _ = plt.figure()\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    finish = datetime.datetime.now()\n    print_div(f'It took {(finish - start).seconds} seconds to run this code.')\n    plt\n    return plt",
        "mutated": [
            "def micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n    '\\n    Runs the micrograd demo.\\n\\n    *args and **kwargs do nothing and are only there to capture any parameters passed\\n    from pyscript when this function is called when a button is clicked.\\n    '\n    start = datetime.datetime.now()\n    print_div('Starting...')\n    np.random.seed(1337)\n    random.seed(1337)\n\n    def make_moons(n_samples=100, noise=None):\n        (n_samples_out, n_samples_in) = (n_samples, n_samples)\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n        if noise is not None:\n            X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n        return (X, y)\n    (X, y) = make_moons(n_samples=100, noise=0.1)\n    y = y * 2 - 1\n    plt.figure(figsize=(5, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='jet')\n    plt\n    pyscript.write('micrograd-run-all-fig1-div', plt)\n    model = MLP(2, [16, 16, 1])\n    print_div(model)\n    print_div(('number of parameters', len(model.parameters())))\n\n    def loss(batch_size=None):\n        if batch_size is None:\n            (Xb, yb) = (X, y)\n        else:\n            ri = np.random.permutation(X.shape[0])[:batch_size]\n            (Xb, yb) = (X[ri], y[ri])\n        inputs = [list(map(Value, xrow)) for xrow in Xb]\n        scores = list(map(model, inputs))\n        losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n        data_loss = sum(losses) * (1.0 / len(losses))\n        alpha = 0.0001\n        reg_loss = alpha * sum((p * p for p in model.parameters()))\n        total_loss = data_loss + reg_loss\n        accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n        return (total_loss, sum(accuracy) / len(accuracy))\n    (total_loss, acc) = loss()\n    print((total_loss, acc))\n    for k in range(20):\n        (total_loss, _) = loss()\n        model.zero_grad()\n        total_loss.backward()\n        learning_rate = 1.0 - 0.9 * k / 100\n        for p in model.parameters():\n            p.data -= learning_rate * p.grad\n        if k % 1 == 0:\n            print_div(f'step {k} loss {total_loss.data}, accuracy {acc * 100}%')\n    h = 0.25\n    (x_min, x_max) = (X[:, 0].min() - 1, X[:, 0].max() + 1)\n    (y_min, y_max) = (X[:, 1].min() - 1, X[:, 1].max() + 1)\n    (xx, yy) = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n    scores = list(map(model, inputs))\n    Z = np.array([s.data.__gt__(0) for s in scores])\n    Z = Z.reshape(xx.shape)\n    _ = plt.figure()\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    finish = datetime.datetime.now()\n    print_div(f'It took {(finish - start).seconds} seconds to run this code.')\n    plt\n    return plt",
            "def micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Runs the micrograd demo.\\n\\n    *args and **kwargs do nothing and are only there to capture any parameters passed\\n    from pyscript when this function is called when a button is clicked.\\n    '\n    start = datetime.datetime.now()\n    print_div('Starting...')\n    np.random.seed(1337)\n    random.seed(1337)\n\n    def make_moons(n_samples=100, noise=None):\n        (n_samples_out, n_samples_in) = (n_samples, n_samples)\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n        if noise is not None:\n            X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n        return (X, y)\n    (X, y) = make_moons(n_samples=100, noise=0.1)\n    y = y * 2 - 1\n    plt.figure(figsize=(5, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='jet')\n    plt\n    pyscript.write('micrograd-run-all-fig1-div', plt)\n    model = MLP(2, [16, 16, 1])\n    print_div(model)\n    print_div(('number of parameters', len(model.parameters())))\n\n    def loss(batch_size=None):\n        if batch_size is None:\n            (Xb, yb) = (X, y)\n        else:\n            ri = np.random.permutation(X.shape[0])[:batch_size]\n            (Xb, yb) = (X[ri], y[ri])\n        inputs = [list(map(Value, xrow)) for xrow in Xb]\n        scores = list(map(model, inputs))\n        losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n        data_loss = sum(losses) * (1.0 / len(losses))\n        alpha = 0.0001\n        reg_loss = alpha * sum((p * p for p in model.parameters()))\n        total_loss = data_loss + reg_loss\n        accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n        return (total_loss, sum(accuracy) / len(accuracy))\n    (total_loss, acc) = loss()\n    print((total_loss, acc))\n    for k in range(20):\n        (total_loss, _) = loss()\n        model.zero_grad()\n        total_loss.backward()\n        learning_rate = 1.0 - 0.9 * k / 100\n        for p in model.parameters():\n            p.data -= learning_rate * p.grad\n        if k % 1 == 0:\n            print_div(f'step {k} loss {total_loss.data}, accuracy {acc * 100}%')\n    h = 0.25\n    (x_min, x_max) = (X[:, 0].min() - 1, X[:, 0].max() + 1)\n    (y_min, y_max) = (X[:, 1].min() - 1, X[:, 1].max() + 1)\n    (xx, yy) = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n    scores = list(map(model, inputs))\n    Z = np.array([s.data.__gt__(0) for s in scores])\n    Z = Z.reshape(xx.shape)\n    _ = plt.figure()\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    finish = datetime.datetime.now()\n    print_div(f'It took {(finish - start).seconds} seconds to run this code.')\n    plt\n    return plt",
            "def micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Runs the micrograd demo.\\n\\n    *args and **kwargs do nothing and are only there to capture any parameters passed\\n    from pyscript when this function is called when a button is clicked.\\n    '\n    start = datetime.datetime.now()\n    print_div('Starting...')\n    np.random.seed(1337)\n    random.seed(1337)\n\n    def make_moons(n_samples=100, noise=None):\n        (n_samples_out, n_samples_in) = (n_samples, n_samples)\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n        if noise is not None:\n            X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n        return (X, y)\n    (X, y) = make_moons(n_samples=100, noise=0.1)\n    y = y * 2 - 1\n    plt.figure(figsize=(5, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='jet')\n    plt\n    pyscript.write('micrograd-run-all-fig1-div', plt)\n    model = MLP(2, [16, 16, 1])\n    print_div(model)\n    print_div(('number of parameters', len(model.parameters())))\n\n    def loss(batch_size=None):\n        if batch_size is None:\n            (Xb, yb) = (X, y)\n        else:\n            ri = np.random.permutation(X.shape[0])[:batch_size]\n            (Xb, yb) = (X[ri], y[ri])\n        inputs = [list(map(Value, xrow)) for xrow in Xb]\n        scores = list(map(model, inputs))\n        losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n        data_loss = sum(losses) * (1.0 / len(losses))\n        alpha = 0.0001\n        reg_loss = alpha * sum((p * p for p in model.parameters()))\n        total_loss = data_loss + reg_loss\n        accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n        return (total_loss, sum(accuracy) / len(accuracy))\n    (total_loss, acc) = loss()\n    print((total_loss, acc))\n    for k in range(20):\n        (total_loss, _) = loss()\n        model.zero_grad()\n        total_loss.backward()\n        learning_rate = 1.0 - 0.9 * k / 100\n        for p in model.parameters():\n            p.data -= learning_rate * p.grad\n        if k % 1 == 0:\n            print_div(f'step {k} loss {total_loss.data}, accuracy {acc * 100}%')\n    h = 0.25\n    (x_min, x_max) = (X[:, 0].min() - 1, X[:, 0].max() + 1)\n    (y_min, y_max) = (X[:, 1].min() - 1, X[:, 1].max() + 1)\n    (xx, yy) = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n    scores = list(map(model, inputs))\n    Z = np.array([s.data.__gt__(0) for s in scores])\n    Z = Z.reshape(xx.shape)\n    _ = plt.figure()\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    finish = datetime.datetime.now()\n    print_div(f'It took {(finish - start).seconds} seconds to run this code.')\n    plt\n    return plt",
            "def micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Runs the micrograd demo.\\n\\n    *args and **kwargs do nothing and are only there to capture any parameters passed\\n    from pyscript when this function is called when a button is clicked.\\n    '\n    start = datetime.datetime.now()\n    print_div('Starting...')\n    np.random.seed(1337)\n    random.seed(1337)\n\n    def make_moons(n_samples=100, noise=None):\n        (n_samples_out, n_samples_in) = (n_samples, n_samples)\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n        if noise is not None:\n            X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n        return (X, y)\n    (X, y) = make_moons(n_samples=100, noise=0.1)\n    y = y * 2 - 1\n    plt.figure(figsize=(5, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='jet')\n    plt\n    pyscript.write('micrograd-run-all-fig1-div', plt)\n    model = MLP(2, [16, 16, 1])\n    print_div(model)\n    print_div(('number of parameters', len(model.parameters())))\n\n    def loss(batch_size=None):\n        if batch_size is None:\n            (Xb, yb) = (X, y)\n        else:\n            ri = np.random.permutation(X.shape[0])[:batch_size]\n            (Xb, yb) = (X[ri], y[ri])\n        inputs = [list(map(Value, xrow)) for xrow in Xb]\n        scores = list(map(model, inputs))\n        losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n        data_loss = sum(losses) * (1.0 / len(losses))\n        alpha = 0.0001\n        reg_loss = alpha * sum((p * p for p in model.parameters()))\n        total_loss = data_loss + reg_loss\n        accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n        return (total_loss, sum(accuracy) / len(accuracy))\n    (total_loss, acc) = loss()\n    print((total_loss, acc))\n    for k in range(20):\n        (total_loss, _) = loss()\n        model.zero_grad()\n        total_loss.backward()\n        learning_rate = 1.0 - 0.9 * k / 100\n        for p in model.parameters():\n            p.data -= learning_rate * p.grad\n        if k % 1 == 0:\n            print_div(f'step {k} loss {total_loss.data}, accuracy {acc * 100}%')\n    h = 0.25\n    (x_min, x_max) = (X[:, 0].min() - 1, X[:, 0].max() + 1)\n    (y_min, y_max) = (X[:, 1].min() - 1, X[:, 1].max() + 1)\n    (xx, yy) = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n    scores = list(map(model, inputs))\n    Z = np.array([s.data.__gt__(0) for s in scores])\n    Z = Z.reshape(xx.shape)\n    _ = plt.figure()\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    finish = datetime.datetime.now()\n    print_div(f'It took {(finish - start).seconds} seconds to run this code.')\n    plt\n    return plt",
            "def micrograd_demo(*args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Runs the micrograd demo.\\n\\n    *args and **kwargs do nothing and are only there to capture any parameters passed\\n    from pyscript when this function is called when a button is clicked.\\n    '\n    start = datetime.datetime.now()\n    print_div('Starting...')\n    np.random.seed(1337)\n    random.seed(1337)\n\n    def make_moons(n_samples=100, noise=None):\n        (n_samples_out, n_samples_in) = (n_samples, n_samples)\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)])\n        if noise is not None:\n            X += np.random.normal(loc=0.0, scale=noise, size=X.shape)\n        return (X, y)\n    (X, y) = make_moons(n_samples=100, noise=0.1)\n    y = y * 2 - 1\n    plt.figure(figsize=(5, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='jet')\n    plt\n    pyscript.write('micrograd-run-all-fig1-div', plt)\n    model = MLP(2, [16, 16, 1])\n    print_div(model)\n    print_div(('number of parameters', len(model.parameters())))\n\n    def loss(batch_size=None):\n        if batch_size is None:\n            (Xb, yb) = (X, y)\n        else:\n            ri = np.random.permutation(X.shape[0])[:batch_size]\n            (Xb, yb) = (X[ri], y[ri])\n        inputs = [list(map(Value, xrow)) for xrow in Xb]\n        scores = list(map(model, inputs))\n        losses = [(1 + -yi * scorei).relu() for (yi, scorei) in zip(yb, scores, strict=True)]\n        data_loss = sum(losses) * (1.0 / len(losses))\n        alpha = 0.0001\n        reg_loss = alpha * sum((p * p for p in model.parameters()))\n        total_loss = data_loss + reg_loss\n        accuracy = [yi.__gt__(0) == scorei.data.__gt__(0) for (yi, scorei) in zip(yb, scores, strict=True)]\n        return (total_loss, sum(accuracy) / len(accuracy))\n    (total_loss, acc) = loss()\n    print((total_loss, acc))\n    for k in range(20):\n        (total_loss, _) = loss()\n        model.zero_grad()\n        total_loss.backward()\n        learning_rate = 1.0 - 0.9 * k / 100\n        for p in model.parameters():\n            p.data -= learning_rate * p.grad\n        if k % 1 == 0:\n            print_div(f'step {k} loss {total_loss.data}, accuracy {acc * 100}%')\n    h = 0.25\n    (x_min, x_max) = (X[:, 0].min() - 1, X[:, 0].max() + 1)\n    (y_min, y_max) = (X[:, 1].min() - 1, X[:, 1].max() + 1)\n    (xx, yy) = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n    scores = list(map(model, inputs))\n    Z = np.array([s.data.__gt__(0) for s in scores])\n    Z = Z.reshape(xx.shape)\n    _ = plt.figure()\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    finish = datetime.datetime.now()\n    print_div(f'It took {(finish - start).seconds} seconds to run this code.')\n    plt\n    return plt"
        ]
    }
]