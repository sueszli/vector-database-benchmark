[
    {
        "func_name": "sampling_analysis",
        "original": "def sampling_analysis(Run_name, Model_list, m_Mmax, b_sample, a_s_model, mega_mfd_cummulative, catalog_cum_rate, xmin, xmax, ymin, ymax, total_list_model, bining_in_mag, total_list_MFD_type, total_list_scenario_name, file_faults_data, total_list_sample, total_list_BG_hyp):\n    if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis'):\n        os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis')\n    file_LT_metrics = open(str(Run_name) + '/analysis/txt_files/LT_metrics.txt', 'w')\n    file_LT_metrics.write('ScL\\tModel\\tBG\\tbvalue\\tMFD\\tSc\\tsample\\tmean_sr\\tchi_score\\tMmax_score\\tNMS_score\\tpaleo_score\\n')\n    \"\\n    #read the catalog cumulative rates for all sampling \\n        and compare each branch to the catalog using the chi-squared test\\n    \\n    methodology:\\n        for each branch i of the logic tree\\n        30 random MFD calculated from the catalog are extracted for the comaprison\\n        the modeled rate of the branch i are compared the each on of these random samples\\n        the comparison is done using the following formula:\\n        we calculate the absolute value of the difference between the logs of the model minus the log of catalog rate\\n        we had 10 to this asolute value to make it accepatble or the chi-squarred test\\n        we run the chisquared test for an array of ten value corresponding to one unit of magnitude (ten bins of 0.1)\\n        bins of magnitude where one of the two rates are not defined are deleted\\n        the value are conpared to an array of value equal ten (the expected value is the model fits the data)\\n        we save the pvalue calculated \\n        \\n        In order to get the p value for the whole MFD, we do the mean of the pvalue for each unit of magnitude \\n        weighted by the number of filled bins in the range of magnitude.\\n        \\n        If the p value is close to 1, the two MFD are similar. \\n        \\n        personal opinion: \\n        p values superior to 0.9 seam like a good match\\n        p values superior to 0.8 seam like an acceptable match in most cases\\n        p values less than 0.7 make the match difficult to accept\\n        \\n        Warning! this method doesn't care if the two maximum magnitude are different,\\n        it will only take the bin where both MFDs are defined. \\n        The fit in terms of Mmax need to rely on some other test. (hopefully I managed to provide one...)\\n        \\n    \"\n    plot_fig = False\n    index_Mmin = np.where(np.array(np.linspace(4.0, 7.0, num=31).round(1)) == xmin)[0][0]\n    index_Mmax = np.where(np.array(np.linspace(4.0, 10.0, num=61).round(1)) == xmax)[0][0] + 1\n    file = open(str(Run_name) + '/analysis/txt_files/model_performance.txt', 'w')\n    file.write('Model\\tMFD type\\tBG\\tScenario Set\\tsample\\tFit to catalog\\tFit to Paleo\\tNMS score\\n')\n    index_model = 0\n    for model in Model_list:\n        if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis/' + model):\n            os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis/' + model)\n        catfile_all = str(Run_name) + '/analysis/figures/catalogue/catalog_rates_all_' + model + '.txt'\n        with open(catfile_all) as f:\n            lines_cat = f.readlines()\n        ranges_mag = [[4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], [5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9], [6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9], [7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9], [8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9], [9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]]\n        p_chi_branch = []\n        indexes_model = []\n        index_branch = 0\n        for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n            if model_name_i == model:\n                indexes_model.append(index_branch)\n                indexes_catalogs_to_test = np.random.choice(range(len(lines_cat))[1:], size=40)\n                pvalues = [[], [], [], [], [], []]\n                weights_pvalues = [[], [], [], [], [], []]\n                if plot_fig == True:\n                    (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                for i_cat in indexes_catalogs_to_test:\n                    cat_rates_i = lines_cat[i_cat].split('\\t')\n                    cat_rates_i = [float(i) for i in cat_rates_i]\n                    if plot_fig == True:\n                        ax1.scatter(bining_in_mag, cat_rates_i, c='k', alpha=0.1, s=0.5)\n                    index_range = 0\n                    for range_i in ranges_mag:\n                        diff_rate = []\n                        target_value = []\n                        bining_i = []\n                        for (model_rate_i, data_rate_i, mag_i) in zip(mfd[index_Mmin:index_Mmax], cat_rates_i, bining_in_mag):\n                            if model_rate_i != 0 and data_rate_i != 0 and (mag_i in range_i):\n                                diff_rate.append(abs(np.log10(model_rate_i) - np.log10(data_rate_i)) * 10.0 + 10.0)\n                                target_value.append(10.0)\n                                bining_i.append(mag_i)\n                        if len(diff_rate) >= 2:\n                            pvalues[index_range].append(chisquare(diff_rate, f_exp=target_value)[1])\n                            weights_pvalues[index_range].append(len(diff_rate))\n                            if plot_fig == True:\n                                ax2.scatter(bining_i, diff_rate, c='r', alpha=0.2, s=2)\n                                ax2.scatter(bining_i, target_value, c='k', alpha=0.1, s=2)\n                        index_range += 1\n                if plot_fig == True:\n                    ax1.scatter(bining_in_mag, mfd[index_Mmin:index_Mmax], c='r', s=0.5)\n                    ax1.set_yscale('log')\n                    ax1.set_xlim([xmin, xmax])\n                    ax1.set_ylim([ymin, ymax])\n                p_total = []\n                weight_p = []\n                for (range_i, p_i, w_i) in zip(ranges_mag, pvalues, weights_pvalues):\n                    if len(p_i) != 0:\n                        weight_p.append(np.mean(w_i))\n                        p_total.append(round(np.mean(p_i), 4))\n                        if plot_fig == True:\n                            if round(np.mean(p_i), 3) >= 0.9:\n                                color = 'g'\n                            elif round(np.mean(p_i), 3) >= 0.8:\n                                color = 'orange'\n                            else:\n                                color = 'r'\n                            ax2.text(np.mean(range_i), 25, str(round(np.mean(p_i), 3)), fontsize=8, color=color)\n                p_chi_branch.append(round(np.average(p_total, weights=weight_p), 3))\n                if plot_fig == True:\n                    if round(np.average(p_total, weights=weight_p), 3) >= 0.9:\n                        color = 'g'\n                    elif round(np.average(p_total, weights=weight_p), 3) >= 0.8:\n                        color = 'orange'\n                    else:\n                        color = 'r'\n                    ax1.set_title(str(round(np.average(p_total, weights=weight_p), 3)), color=color)\n                    ax2.set_xlim([xmin - 0.1, xmax])\n                    ax2.set_ylim([9, 30])\n                    plt.show()\n                    plt.close()\n            index_branch += 1\n        '\\n        #   Mmax fit to the Mmax in the catalog\\n        \\n        The rule is: The Mmax in the model should be at least the one in the catalog \\n        but the catalog has some uncertainties on the magnitude of large historical EQs\\n        \\n        methodology:\\n            we calculate the cumulative density distribution of the Mmax in the catalog\\n            we associate the given density to each Mmax of the models\\n        \\n        '\n        Mmax_cat = []\n        bining_cat = lines_cat[0].split('\\t')\n        bining_cat = [float(i) for i in bining_cat]\n        for i_cat in range(len(lines_cat) - 1):\n            cat_rates_i = lines_cat[i_cat + 1].split('\\t')\n            cat_rates_i = [float(i) for i in cat_rates_i]\n            i_test = 0\n            try:\n                while cat_rates_i[i_test] != 0:\n                    i_test += 1\n            except:\n                i_test = len(cat_rates_i) - 1\n            Mmax_cat.append(bining_cat[i_test])\n        distribution_Mmax_cat = []\n        for mag_i in bining_cat:\n            d_i = sum((i <= mag_i + 0.1 for i in Mmax_cat)) / len(Mmax_cat)\n            distribution_Mmax_cat.append(d_i)\n        plt.plot(bining_cat, distribution_Mmax_cat)\n        plt.xlim([xmax - 1.5, xmax])\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/Mmax_distrib_in_the_cat.png', dpi=180)\n        plt.close()\n        weight_model_Mmax = []\n        for (Mmax_i, model_name_i) in zip(m_Mmax, total_list_model):\n            if model_name_i == model:\n                index = np.where(np.array(bining_cat) == Mmax_i)[0][0]\n                weight_model_Mmax.append(distribution_Mmax_cat[index])\n        '\\n        The NMS on a set of faults as a metric for judging the quality of a model\\n        '\n        fault_set = ['F1', 'F2', 'F3']\n        NMS_set = []\n        for fault in fault_set:\n            NMS_set.append([])\n        if len(NMS_set) != 0:\n            sr_sample = []\n            for fault in fault_set:\n                sr_sample.append([])\n            score_nms = []\n            srate_sample_file = str(Run_name) + '/analysis/txt_files/slip_rate_sampling.txt'\n            with open(srate_sample_file) as f:\n                lines_sr = f.readlines()\n            srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n            try:\n                with open(srep_file) as f:\n                    lines = f.readlines()\n                line_number = 0\n                for line in lines:\n                    if line.split('\\t')[7] in fault_set and line.split('\\t')[1] == model:\n                        index_fault = np.where(np.array(fault_set) == line.split('\\t')[7])[0][0]\n                        NMS_set[index_fault].append(float(line.split('\\t')[-1]))\n                        sr_sample[index_fault].append(float(lines_sr[line_number].split('\\t')[-1]))\n                    line_number += 1\n                if np.sum(NMS_set) != 0.0:\n                    for i in range(len(p_chi_branch)):\n                        '\\n                      the score is 1 is MSN is less than 20%\\n                      the score is 0 if:\\n                          at least one of the NMS of the test faults if more than 50%\\n                          the mean is more the 40%\\n                      between 20 and 40 the score evolves linearily between 1 and 0\\n                      (this is very much open to discussion!)\\n                      '\n                        if np.mean(NMS_set, axis=0)[i] > 40.0:\n                            score_nms_i = 0.0\n                        elif np.mean(NMS_set, axis=0)[i] < 20.0:\n                            score_nms_i = 1.0\n                        else:\n                            score_nms_i = 2 - 1.0 / 20.0 * np.mean(NMS_set, axis=0)[i]\n                        'hard limit on acceptability'\n                        for nms_row in NMS_set:\n                            if nms_row[i] > 50.0:\n                                score_nms_i = 0.0\n                        score_nms.append(score_nms_i)\n            except FileNotFoundError:\n                print('!!! you need to run the plot_sr_use if you want the NMS metric !!!')\n                print('Default value = 1. ')\n                for i in range(len(p_chi_branch)):\n                    score_nms.append(1.0)\n        else:\n            print('modify Sampling_analysis.py for the NMS metric')\n            print('Default value = 1. ')\n            for i in range(len(p_chi_branch)):\n                score_nms.append(1.0)\n        mean_sr_branch = np.mean(sr_sample, axis=0)\n        '#############################\\n        Weight based on the fit to the paleo rates\\n        \\n        and the RSQSim rates if they exist\\n        #######################################'\n        plot_paleo = False\n        plot_rsqsim_pr = True\n        faults_data = np.genfromtxt(file_faults_data, dtype=[('model', 'U100000'), ('fault_name', 'U100000'), ('type', 'U100000'), ('M', 'f8'), ('sig_M', 'f8'), ('rate', 'f8'), ('sig_rate', 'f8')], delimiter='\\t', skip_header=1)\n        try:\n            len_faults_data = len(faults_data)\n        except TypeError:\n            faults_data = faults_data.reshape((1,))\n        rsqsim_pr = False\n        RSQSim_pr_file = str(Run_name) + '/file_pr_rsqsim.txt'\n        try:\n            with open(RSQSim_pr_file) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            rqsim_pr_faults = []\n            faults_name_rsqsim = []\n            for line in lines[1:]:\n                faults_name_rsqsim.append(line.split('\\t')[0])\n                rqsim_pr_faults.append([float(i) for i in line.split('\\t')[1:-1]])\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n        except:\n            rsqsim_pr = False\n        data_model = list(map(lambda i: faults_data[i][0], range(len(faults_data))))\n        data_fault_name = list(map(lambda i: faults_data[i][1], range(len(faults_data))))\n        data_type = list(map(lambda i: faults_data[i][2], range(len(faults_data))))\n        data_M = list(map(lambda i: float(faults_data[i][3]), range(len(faults_data))))\n        data_sig_M = list(map(lambda i: float(faults_data[i][4]), range(len(faults_data))))\n        data_rate = list(map(lambda i: float(faults_data[i][5]), range(len(faults_data))))\n        data_sig_rate = list(map(lambda i: float(faults_data[i][6]), range(len(faults_data))))\n        score_paleo = []\n        score_paleo_faults = []\n        faults_data = []\n        score_pr_rsqsim = []\n        faults_rsqsim = []\n        for (fault, data_model_i) in zip(data_fault_name, data_model):\n            if data_model_i == model and fault not in faults_data:\n                score_paleo_faults.append([])\n                faults_data.append(fault)\n                if rsqsim_pr == True:\n                    if fault in faults_name_rsqsim and fault not in faults_rsqsim:\n                        score_pr_rsqsim.append([])\n                        faults_rsqsim.append(fault)\n        participation_rate_file = str(Run_name) + '/analysis/figures/rupture_rate_for_each_fault_cum/' + model + '/file_for_comparison.txt'\n        with open(participation_rate_file) as f:\n            lines_pr = f.readlines()\n        paleo_list_mfd = []\n        paleo_list_bvalue = []\n        paleo_list_bg = []\n        paleo_list_scl = []\n        paleo_list_scenario = []\n        paleo_list_sample = []\n        index_branch = 0\n        for line in lines_pr:\n            index_fault = 0\n            for fault_name in faults_data:\n                if line.split('\\t')[0] == model and line.split('\\t')[7] == fault_name:\n                    if index_fault == 0:\n                        paleo_list_mfd.append(line.split('\\t')[1])\n                        paleo_list_scenario.append(line.split('\\t')[2])\n                        paleo_list_bg.append(line.split('\\t')[3])\n                        paleo_list_scl.append(line.split('\\t')[4])\n                        paleo_list_bvalue.append(line.split('\\t')[5])\n                        paleo_list_sample.append(line.split('\\t')[6])\n                    mfd_i = [float(i) for i in list(line.split('\\t')[8 + index_Mmin:8 + index_Mmax])]\n                    self_data_M = []\n                    self_data_sig_M = []\n                    self_data_rate = []\n                    self_data_sig_rate = []\n                    index_fault_in_data = np.where(np.array(data_fault_name) == fault_name)[0]\n                    for index_i in index_fault_in_data:\n                        if data_model[index_i] == model and data_type[index_i] == 'pal':\n                            self_data_M.append(data_M[index_i])\n                            self_data_sig_M.append(data_sig_M[index_i])\n                            self_data_rate.append(data_rate[index_i])\n                            self_data_sig_rate.append(data_sig_rate[index_i])\n                    paleo_score_i = []\n                    for (m_i, sm_i, r_i, sr_i) in zip(self_data_M, self_data_sig_M, self_data_rate, self_data_sig_rate):\n                        (x, y) = np.mgrid[4.5:7.5:0.01, -5.0:0.0:0.01]\n                        pos = np.empty(x.shape + (2,))\n                        pos[:, :, 0] = x\n                        pos[:, :, 1] = y\n                        rv = multivariate_normal([m_i, np.log10(r_i)], [sm_i + 0.001, sr_i + 1e-07])\n                        detailed_bin_mag = np.linspace(bining_in_mag[0], bining_in_mag[-1], 1000)\n                        detailed_mfd_i = np.interp(detailed_bin_mag, bining_in_mag, np.log10(mfd_i))\n                        if plot_paleo == True:\n                            plt.contourf(x, y, rv.pdf(pos), alpha=0.5)\n                            plt.scatter(bining_in_mag, np.log10(mfd_i), c='k', marker='s', s=10, linewidths=0.01, alpha=0.7)\n                            plt.scatter(detailed_bin_mag, detailed_mfd_i, c='k', marker='s', s=3, linewidths=0.01, alpha=0.7)\n                            plt.xlim([5.0, 7.0])\n                            plt.ylim([-3, -1.0])\n                            plt.grid()\n                            plt.show()\n                        paleo_score_i.append(max([rv.pdf([i, j]) / rv.pdf([m_i, np.log10(r_i)]) for (i, j) in zip(detailed_bin_mag, detailed_mfd_i)]))\n                    score_paleo_faults[index_fault].append(np.mean(paleo_score_i))\n                    if rsqsim_pr == True and line.split('\\t')[6] == '1':\n                        pvalues = []\n                        pshape = []\n                        if fault_name in faults_rsqsim:\n                            index_fault_rsqsim = np.where(np.array(faults_name_rsqsim) == fault_name)[0][0]\n                            fault_pr_rsqsim = rqsim_pr_faults[index_fault_rsqsim]\n                            if plot_rsqsim_pr == True:\n                                (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bin_mag_rsqsim[:-2], fault_pr_rsqsim[:-2], c='k', alpha=0.9, s=3)\n                                ax1.scatter(bin_mag_rsqsim[-2:], fault_pr_rsqsim[-2:], c='k', alpha=0.5, s=3)\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], fault_pr_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pvalues.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='b', alpha=0.8, s=2)\n                                index_range += 1\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], c='r', s=0.5)\n                                ax1.scatter(bining_in_mag[-2:], mfd_i[-2:], c='r', alpha=0.4, s=0.5)\n                                ax1.set_yscale('log')\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax1.set_ylim([ymin, ymax / 100.0])\n                            p_total = np.mean(diff_rate)\n                            n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                            n_mfd_rsqsim = [i / sum(fault_pr_rsqsim[:-2]) for i in fault_pr_rsqsim[:-2]]\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pshape.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=2)\n                            if plot_rsqsim_pr == True:\n                                if round(p_total, 3) >= 1.3:\n                                    color = 'r'\n                                elif round(p_total, 3) >= 1.2:\n                                    color = 'orange'\n                                else:\n                                    color = 'g'\n                                if round(np.mean(diff_rate), 3) >= 1.3:\n                                    color_shape = 'r'\n                                elif round(np.mean(diff_rate), 3) >= 1.2:\n                                    color_shape = 'orange'\n                                else:\n                                    color_shape = 'g'\n                                ax1.set_title(model + ' ' + fault_name + ' ' + str(round(p_total, 2)), color=color)\n                                ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_ylim([0.9, 3.0])\n                                plt.show()\n                                plt.close()\n                index_fault += 1\n        score_paleo = np.mean(score_paleo_faults, axis=0)\n        '###################\"\"\\n        Compare with some other MFD at the system level (physics based for example)\\n        #####################\"'\n        plot_fig_rsqsim = False\n        RSQSim_MFD = str(Run_name) + '/mfd_RSQSim.txt'\n        try:\n            with open(RSQSim_MFD) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            mfd_rsqsim = [float(i) for i in lines[1].split('\\t')[1:-1]]\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n            index_branch = 0\n            for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n                if model_name_i == model:\n                    if plot_fig_rsqsim == True:\n                        (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bin_mag_rsqsim, mfd_rsqsim, c='k', alpha=0.9, s=3)\n                    pvalues = []\n                    diff_rate = []\n                    bining_i = []\n                    mfd_i = mfd[index_Mmin:index_Mmax]\n                    for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pvalues.append(np.mean(diff_rate))\n                    p_total = np.mean(diff_rate)\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='r', alpha=0.9, s=3)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim], c='r', s=0.5)\n                    n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                    n_mfd_rsqsim = [i / sum(mfd_rsqsim[:-2]) for i in mfd_rsqsim[:-2]]\n                    diff_rate = []\n                    bining_i = []\n                    for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pshape.append(np.mean(diff_rate))\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=3)\n                    if plot_fig_rsqsim == True:\n                        if round(p_total, 3) >= 1.3:\n                            color = 'r'\n                        elif round(p_total, 3) >= 1.2:\n                            color = 'orange'\n                        else:\n                            color = 'g'\n                        if round(np.mean(diff_rate), 3) >= 1.4:\n                            color_shape = 'r'\n                        elif round(np.mean(diff_rate), 3) >= 1.3:\n                            color_shape = 'orange'\n                        else:\n                            color_shape = 'g'\n                        ax1.set_title(model + ' ' + str(round(p_total, 2)), color=color)\n                        ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                        ax1.set_ylim([ymin / 10.0, ymax])\n                        ax1.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_ylim([0.9, 3.0])\n                        ax1.set_yscale('log')\n                        plt.show()\n                        plt.close()\n                index_branch += 1\n        except:\n            pass\n        '\\n        Setting the weight for each score\\n        '\n        weight_chi = 0.35\n        weight_Mmax = 0.05\n        weight_NMS_faults_test = 0.3\n        weight_paleo = 0.3\n        if len(score_nms) == 0.0:\n            print('!!! no selected faults for the NMS metric !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_NMS_faults_test = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_paleo = weight_paleo / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_nms.append(0.0)\n        if len(score_paleo) == 0.0:\n            print('!!! no paleo data on the faults !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_paleo = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_NMS_faults_test = weight_NMS_faults_test / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_paleo.append(0.0)\n        ' \\n        Builbing the text file\\n        '\n        lt_branch = []\n        lt_i_before = 'truc'\n        srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n        try:\n            with open(srep_file) as f:\n                lines = f.readlines()\n            ordered_score_paleo = []\n            i_lt = 0\n            for line in lines:\n                if line.split('\\t')[1] == model:\n                    lt_i = []\n                    for i in range(7):\n                        lt_i.append(line.split('\\t')[i])\n                    if str(lt_i) != lt_i_before:\n                        lt_i_before = str(lt_i)\n                        lt_i.append(round(mean_sr_branch[i_lt], 3))\n                        lt_i.append(round(p_chi_branch[i_lt], 3))\n                        lt_i.append(round(weight_model_Mmax[i_lt], 3))\n                        lt_i.append(round(score_nms[i_lt], 3))\n                        i1 = np.where(np.array(paleo_list_mfd) == line.split('\\t')[4][4:])[0]\n                        i2 = np.where(np.array(paleo_list_scenario) == line.split('\\t')[5])[0]\n                        i3 = np.where(np.array(paleo_list_sample) == line.split('\\t')[6].split('_')[1])[0]\n                        i4 = np.where(np.array(paleo_list_bvalue) == line.split('\\t')[3])[0]\n                        i5 = np.where(np.array(paleo_list_bg) == line.split('\\t')[2][3:])[0]\n                        i6 = np.where(np.array(paleo_list_scl) == line.split('\\t')[0])[0]\n                        i1 = np.intersect1d(i1, i2)\n                        i1 = np.intersect1d(i1, i3)\n                        i1 = np.intersect1d(i1, i4)\n                        i1 = np.intersect1d(i1, i5)\n                        i1 = np.intersect1d(i1, i6)\n                        lt_i.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        ordered_score_paleo.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        lt_branch.append(lt_i)\n                        i_lt += 1\n            for lt_i in lt_branch:\n                line = ''\n                for i in lt_i:\n                    line += str(i) + '\\t'\n                line = line[:-1]\n                file_LT_metrics.write(line + '\\n')\n        except (FileNotFoundError, IndexError) as e:\n            print('!!! you need to run the plot_sr_use if you want the file with the metrics  and modify Sampling_analysis.py!!!')\n        '\\n        Calculataing the weighted score for each branch\\n        '\n        if ordered_score_paleo == []:\n            ordered_score_paleo = [0 for i in range(len(p_chi_branch))]\n        final_weigth = []\n        for i in range(len(p_chi_branch)):\n            final_weigth.append(p_chi_branch[i] * weight_chi + weight_model_Mmax[i] * weight_Mmax + score_nms[i] * weight_NMS_faults_test + ordered_score_paleo[i] * weight_paleo)\n        '\\n        Plotting section\\n        \\n        Weighted average of the different metric\\n        \\n        user defined weight for each metric. the figure give the weighted average as a final p value\\n        '\n        color_mfd = []\n        for (MFD_type_i, model_name_i) in zip(total_list_MFD_type, total_list_model):\n            if model_name_i == model:\n                if MFD_type_i == 'GR':\n                    color_mfd.append('darkblue')\n                else:\n                    color_mfd.append('darkgreen')\n        (f, (ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, sharey=True)\n        ax1.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax1.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax1.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax2.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax2.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax2.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax3.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax3.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax3.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax4.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax4.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax4.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax5.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax5.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax5.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax1.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax1.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            if total_list_scenario_name[j] == total_list_scenario_name[0]:\n                if weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                else:\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n            elif weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n            else:\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n        ax1.set_xlabel('Mmax')\n        ax1.set_ylabel('test value   ' + str(model))\n        ax1.set_ylim([-0.05, 1.05])\n        ax1.set_xlim([xmax - 1.5, xmax])\n        ax2.set_xlim([xmax - 1.5, xmax])\n        ax3.set_xlim([xmax - 1.5, xmax])\n        ax4.set_xlim([xmax - 1.5, xmax])\n        ax5.set_xlim([xmax - 1.5, xmax])\n        ax1.set_title('chi test')\n        ax2.set_title('Mmax test')\n        ax3.set_title('NMS test')\n        ax4.set_title('Paleo test')\n        ax5.set_title('weitghted total')\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/model_performance.png', dpi=180)\n        plt.close()\n        index_model += 1\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            file.write(str(model) + '\\t' + str(total_list_MFD_type[j]) + '\\t' + str(total_list_BG_hyp[j]) + '\\t' + str(total_list_scenario_name[j]) + '\\t' + str(total_list_sample[j]) + '\\t' + str(round(p_chi_branch[i], 2)) + '\\t' + str(round(ordered_score_paleo[i], 2)) + '\\t' + str(round(score_nms[i], 2)) + '\\n')\n    file.close()\n    file_LT_metrics.close()",
        "mutated": [
            "def sampling_analysis(Run_name, Model_list, m_Mmax, b_sample, a_s_model, mega_mfd_cummulative, catalog_cum_rate, xmin, xmax, ymin, ymax, total_list_model, bining_in_mag, total_list_MFD_type, total_list_scenario_name, file_faults_data, total_list_sample, total_list_BG_hyp):\n    if False:\n        i = 10\n    if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis'):\n        os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis')\n    file_LT_metrics = open(str(Run_name) + '/analysis/txt_files/LT_metrics.txt', 'w')\n    file_LT_metrics.write('ScL\\tModel\\tBG\\tbvalue\\tMFD\\tSc\\tsample\\tmean_sr\\tchi_score\\tMmax_score\\tNMS_score\\tpaleo_score\\n')\n    \"\\n    #read the catalog cumulative rates for all sampling \\n        and compare each branch to the catalog using the chi-squared test\\n    \\n    methodology:\\n        for each branch i of the logic tree\\n        30 random MFD calculated from the catalog are extracted for the comaprison\\n        the modeled rate of the branch i are compared the each on of these random samples\\n        the comparison is done using the following formula:\\n        we calculate the absolute value of the difference between the logs of the model minus the log of catalog rate\\n        we had 10 to this asolute value to make it accepatble or the chi-squarred test\\n        we run the chisquared test for an array of ten value corresponding to one unit of magnitude (ten bins of 0.1)\\n        bins of magnitude where one of the two rates are not defined are deleted\\n        the value are conpared to an array of value equal ten (the expected value is the model fits the data)\\n        we save the pvalue calculated \\n        \\n        In order to get the p value for the whole MFD, we do the mean of the pvalue for each unit of magnitude \\n        weighted by the number of filled bins in the range of magnitude.\\n        \\n        If the p value is close to 1, the two MFD are similar. \\n        \\n        personal opinion: \\n        p values superior to 0.9 seam like a good match\\n        p values superior to 0.8 seam like an acceptable match in most cases\\n        p values less than 0.7 make the match difficult to accept\\n        \\n        Warning! this method doesn't care if the two maximum magnitude are different,\\n        it will only take the bin where both MFDs are defined. \\n        The fit in terms of Mmax need to rely on some other test. (hopefully I managed to provide one...)\\n        \\n    \"\n    plot_fig = False\n    index_Mmin = np.where(np.array(np.linspace(4.0, 7.0, num=31).round(1)) == xmin)[0][0]\n    index_Mmax = np.where(np.array(np.linspace(4.0, 10.0, num=61).round(1)) == xmax)[0][0] + 1\n    file = open(str(Run_name) + '/analysis/txt_files/model_performance.txt', 'w')\n    file.write('Model\\tMFD type\\tBG\\tScenario Set\\tsample\\tFit to catalog\\tFit to Paleo\\tNMS score\\n')\n    index_model = 0\n    for model in Model_list:\n        if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis/' + model):\n            os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis/' + model)\n        catfile_all = str(Run_name) + '/analysis/figures/catalogue/catalog_rates_all_' + model + '.txt'\n        with open(catfile_all) as f:\n            lines_cat = f.readlines()\n        ranges_mag = [[4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], [5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9], [6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9], [7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9], [8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9], [9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]]\n        p_chi_branch = []\n        indexes_model = []\n        index_branch = 0\n        for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n            if model_name_i == model:\n                indexes_model.append(index_branch)\n                indexes_catalogs_to_test = np.random.choice(range(len(lines_cat))[1:], size=40)\n                pvalues = [[], [], [], [], [], []]\n                weights_pvalues = [[], [], [], [], [], []]\n                if plot_fig == True:\n                    (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                for i_cat in indexes_catalogs_to_test:\n                    cat_rates_i = lines_cat[i_cat].split('\\t')\n                    cat_rates_i = [float(i) for i in cat_rates_i]\n                    if plot_fig == True:\n                        ax1.scatter(bining_in_mag, cat_rates_i, c='k', alpha=0.1, s=0.5)\n                    index_range = 0\n                    for range_i in ranges_mag:\n                        diff_rate = []\n                        target_value = []\n                        bining_i = []\n                        for (model_rate_i, data_rate_i, mag_i) in zip(mfd[index_Mmin:index_Mmax], cat_rates_i, bining_in_mag):\n                            if model_rate_i != 0 and data_rate_i != 0 and (mag_i in range_i):\n                                diff_rate.append(abs(np.log10(model_rate_i) - np.log10(data_rate_i)) * 10.0 + 10.0)\n                                target_value.append(10.0)\n                                bining_i.append(mag_i)\n                        if len(diff_rate) >= 2:\n                            pvalues[index_range].append(chisquare(diff_rate, f_exp=target_value)[1])\n                            weights_pvalues[index_range].append(len(diff_rate))\n                            if plot_fig == True:\n                                ax2.scatter(bining_i, diff_rate, c='r', alpha=0.2, s=2)\n                                ax2.scatter(bining_i, target_value, c='k', alpha=0.1, s=2)\n                        index_range += 1\n                if plot_fig == True:\n                    ax1.scatter(bining_in_mag, mfd[index_Mmin:index_Mmax], c='r', s=0.5)\n                    ax1.set_yscale('log')\n                    ax1.set_xlim([xmin, xmax])\n                    ax1.set_ylim([ymin, ymax])\n                p_total = []\n                weight_p = []\n                for (range_i, p_i, w_i) in zip(ranges_mag, pvalues, weights_pvalues):\n                    if len(p_i) != 0:\n                        weight_p.append(np.mean(w_i))\n                        p_total.append(round(np.mean(p_i), 4))\n                        if plot_fig == True:\n                            if round(np.mean(p_i), 3) >= 0.9:\n                                color = 'g'\n                            elif round(np.mean(p_i), 3) >= 0.8:\n                                color = 'orange'\n                            else:\n                                color = 'r'\n                            ax2.text(np.mean(range_i), 25, str(round(np.mean(p_i), 3)), fontsize=8, color=color)\n                p_chi_branch.append(round(np.average(p_total, weights=weight_p), 3))\n                if plot_fig == True:\n                    if round(np.average(p_total, weights=weight_p), 3) >= 0.9:\n                        color = 'g'\n                    elif round(np.average(p_total, weights=weight_p), 3) >= 0.8:\n                        color = 'orange'\n                    else:\n                        color = 'r'\n                    ax1.set_title(str(round(np.average(p_total, weights=weight_p), 3)), color=color)\n                    ax2.set_xlim([xmin - 0.1, xmax])\n                    ax2.set_ylim([9, 30])\n                    plt.show()\n                    plt.close()\n            index_branch += 1\n        '\\n        #   Mmax fit to the Mmax in the catalog\\n        \\n        The rule is: The Mmax in the model should be at least the one in the catalog \\n        but the catalog has some uncertainties on the magnitude of large historical EQs\\n        \\n        methodology:\\n            we calculate the cumulative density distribution of the Mmax in the catalog\\n            we associate the given density to each Mmax of the models\\n        \\n        '\n        Mmax_cat = []\n        bining_cat = lines_cat[0].split('\\t')\n        bining_cat = [float(i) for i in bining_cat]\n        for i_cat in range(len(lines_cat) - 1):\n            cat_rates_i = lines_cat[i_cat + 1].split('\\t')\n            cat_rates_i = [float(i) for i in cat_rates_i]\n            i_test = 0\n            try:\n                while cat_rates_i[i_test] != 0:\n                    i_test += 1\n            except:\n                i_test = len(cat_rates_i) - 1\n            Mmax_cat.append(bining_cat[i_test])\n        distribution_Mmax_cat = []\n        for mag_i in bining_cat:\n            d_i = sum((i <= mag_i + 0.1 for i in Mmax_cat)) / len(Mmax_cat)\n            distribution_Mmax_cat.append(d_i)\n        plt.plot(bining_cat, distribution_Mmax_cat)\n        plt.xlim([xmax - 1.5, xmax])\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/Mmax_distrib_in_the_cat.png', dpi=180)\n        plt.close()\n        weight_model_Mmax = []\n        for (Mmax_i, model_name_i) in zip(m_Mmax, total_list_model):\n            if model_name_i == model:\n                index = np.where(np.array(bining_cat) == Mmax_i)[0][0]\n                weight_model_Mmax.append(distribution_Mmax_cat[index])\n        '\\n        The NMS on a set of faults as a metric for judging the quality of a model\\n        '\n        fault_set = ['F1', 'F2', 'F3']\n        NMS_set = []\n        for fault in fault_set:\n            NMS_set.append([])\n        if len(NMS_set) != 0:\n            sr_sample = []\n            for fault in fault_set:\n                sr_sample.append([])\n            score_nms = []\n            srate_sample_file = str(Run_name) + '/analysis/txt_files/slip_rate_sampling.txt'\n            with open(srate_sample_file) as f:\n                lines_sr = f.readlines()\n            srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n            try:\n                with open(srep_file) as f:\n                    lines = f.readlines()\n                line_number = 0\n                for line in lines:\n                    if line.split('\\t')[7] in fault_set and line.split('\\t')[1] == model:\n                        index_fault = np.where(np.array(fault_set) == line.split('\\t')[7])[0][0]\n                        NMS_set[index_fault].append(float(line.split('\\t')[-1]))\n                        sr_sample[index_fault].append(float(lines_sr[line_number].split('\\t')[-1]))\n                    line_number += 1\n                if np.sum(NMS_set) != 0.0:\n                    for i in range(len(p_chi_branch)):\n                        '\\n                      the score is 1 is MSN is less than 20%\\n                      the score is 0 if:\\n                          at least one of the NMS of the test faults if more than 50%\\n                          the mean is more the 40%\\n                      between 20 and 40 the score evolves linearily between 1 and 0\\n                      (this is very much open to discussion!)\\n                      '\n                        if np.mean(NMS_set, axis=0)[i] > 40.0:\n                            score_nms_i = 0.0\n                        elif np.mean(NMS_set, axis=0)[i] < 20.0:\n                            score_nms_i = 1.0\n                        else:\n                            score_nms_i = 2 - 1.0 / 20.0 * np.mean(NMS_set, axis=0)[i]\n                        'hard limit on acceptability'\n                        for nms_row in NMS_set:\n                            if nms_row[i] > 50.0:\n                                score_nms_i = 0.0\n                        score_nms.append(score_nms_i)\n            except FileNotFoundError:\n                print('!!! you need to run the plot_sr_use if you want the NMS metric !!!')\n                print('Default value = 1. ')\n                for i in range(len(p_chi_branch)):\n                    score_nms.append(1.0)\n        else:\n            print('modify Sampling_analysis.py for the NMS metric')\n            print('Default value = 1. ')\n            for i in range(len(p_chi_branch)):\n                score_nms.append(1.0)\n        mean_sr_branch = np.mean(sr_sample, axis=0)\n        '#############################\\n        Weight based on the fit to the paleo rates\\n        \\n        and the RSQSim rates if they exist\\n        #######################################'\n        plot_paleo = False\n        plot_rsqsim_pr = True\n        faults_data = np.genfromtxt(file_faults_data, dtype=[('model', 'U100000'), ('fault_name', 'U100000'), ('type', 'U100000'), ('M', 'f8'), ('sig_M', 'f8'), ('rate', 'f8'), ('sig_rate', 'f8')], delimiter='\\t', skip_header=1)\n        try:\n            len_faults_data = len(faults_data)\n        except TypeError:\n            faults_data = faults_data.reshape((1,))\n        rsqsim_pr = False\n        RSQSim_pr_file = str(Run_name) + '/file_pr_rsqsim.txt'\n        try:\n            with open(RSQSim_pr_file) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            rqsim_pr_faults = []\n            faults_name_rsqsim = []\n            for line in lines[1:]:\n                faults_name_rsqsim.append(line.split('\\t')[0])\n                rqsim_pr_faults.append([float(i) for i in line.split('\\t')[1:-1]])\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n        except:\n            rsqsim_pr = False\n        data_model = list(map(lambda i: faults_data[i][0], range(len(faults_data))))\n        data_fault_name = list(map(lambda i: faults_data[i][1], range(len(faults_data))))\n        data_type = list(map(lambda i: faults_data[i][2], range(len(faults_data))))\n        data_M = list(map(lambda i: float(faults_data[i][3]), range(len(faults_data))))\n        data_sig_M = list(map(lambda i: float(faults_data[i][4]), range(len(faults_data))))\n        data_rate = list(map(lambda i: float(faults_data[i][5]), range(len(faults_data))))\n        data_sig_rate = list(map(lambda i: float(faults_data[i][6]), range(len(faults_data))))\n        score_paleo = []\n        score_paleo_faults = []\n        faults_data = []\n        score_pr_rsqsim = []\n        faults_rsqsim = []\n        for (fault, data_model_i) in zip(data_fault_name, data_model):\n            if data_model_i == model and fault not in faults_data:\n                score_paleo_faults.append([])\n                faults_data.append(fault)\n                if rsqsim_pr == True:\n                    if fault in faults_name_rsqsim and fault not in faults_rsqsim:\n                        score_pr_rsqsim.append([])\n                        faults_rsqsim.append(fault)\n        participation_rate_file = str(Run_name) + '/analysis/figures/rupture_rate_for_each_fault_cum/' + model + '/file_for_comparison.txt'\n        with open(participation_rate_file) as f:\n            lines_pr = f.readlines()\n        paleo_list_mfd = []\n        paleo_list_bvalue = []\n        paleo_list_bg = []\n        paleo_list_scl = []\n        paleo_list_scenario = []\n        paleo_list_sample = []\n        index_branch = 0\n        for line in lines_pr:\n            index_fault = 0\n            for fault_name in faults_data:\n                if line.split('\\t')[0] == model and line.split('\\t')[7] == fault_name:\n                    if index_fault == 0:\n                        paleo_list_mfd.append(line.split('\\t')[1])\n                        paleo_list_scenario.append(line.split('\\t')[2])\n                        paleo_list_bg.append(line.split('\\t')[3])\n                        paleo_list_scl.append(line.split('\\t')[4])\n                        paleo_list_bvalue.append(line.split('\\t')[5])\n                        paleo_list_sample.append(line.split('\\t')[6])\n                    mfd_i = [float(i) for i in list(line.split('\\t')[8 + index_Mmin:8 + index_Mmax])]\n                    self_data_M = []\n                    self_data_sig_M = []\n                    self_data_rate = []\n                    self_data_sig_rate = []\n                    index_fault_in_data = np.where(np.array(data_fault_name) == fault_name)[0]\n                    for index_i in index_fault_in_data:\n                        if data_model[index_i] == model and data_type[index_i] == 'pal':\n                            self_data_M.append(data_M[index_i])\n                            self_data_sig_M.append(data_sig_M[index_i])\n                            self_data_rate.append(data_rate[index_i])\n                            self_data_sig_rate.append(data_sig_rate[index_i])\n                    paleo_score_i = []\n                    for (m_i, sm_i, r_i, sr_i) in zip(self_data_M, self_data_sig_M, self_data_rate, self_data_sig_rate):\n                        (x, y) = np.mgrid[4.5:7.5:0.01, -5.0:0.0:0.01]\n                        pos = np.empty(x.shape + (2,))\n                        pos[:, :, 0] = x\n                        pos[:, :, 1] = y\n                        rv = multivariate_normal([m_i, np.log10(r_i)], [sm_i + 0.001, sr_i + 1e-07])\n                        detailed_bin_mag = np.linspace(bining_in_mag[0], bining_in_mag[-1], 1000)\n                        detailed_mfd_i = np.interp(detailed_bin_mag, bining_in_mag, np.log10(mfd_i))\n                        if plot_paleo == True:\n                            plt.contourf(x, y, rv.pdf(pos), alpha=0.5)\n                            plt.scatter(bining_in_mag, np.log10(mfd_i), c='k', marker='s', s=10, linewidths=0.01, alpha=0.7)\n                            plt.scatter(detailed_bin_mag, detailed_mfd_i, c='k', marker='s', s=3, linewidths=0.01, alpha=0.7)\n                            plt.xlim([5.0, 7.0])\n                            plt.ylim([-3, -1.0])\n                            plt.grid()\n                            plt.show()\n                        paleo_score_i.append(max([rv.pdf([i, j]) / rv.pdf([m_i, np.log10(r_i)]) for (i, j) in zip(detailed_bin_mag, detailed_mfd_i)]))\n                    score_paleo_faults[index_fault].append(np.mean(paleo_score_i))\n                    if rsqsim_pr == True and line.split('\\t')[6] == '1':\n                        pvalues = []\n                        pshape = []\n                        if fault_name in faults_rsqsim:\n                            index_fault_rsqsim = np.where(np.array(faults_name_rsqsim) == fault_name)[0][0]\n                            fault_pr_rsqsim = rqsim_pr_faults[index_fault_rsqsim]\n                            if plot_rsqsim_pr == True:\n                                (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bin_mag_rsqsim[:-2], fault_pr_rsqsim[:-2], c='k', alpha=0.9, s=3)\n                                ax1.scatter(bin_mag_rsqsim[-2:], fault_pr_rsqsim[-2:], c='k', alpha=0.5, s=3)\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], fault_pr_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pvalues.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='b', alpha=0.8, s=2)\n                                index_range += 1\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], c='r', s=0.5)\n                                ax1.scatter(bining_in_mag[-2:], mfd_i[-2:], c='r', alpha=0.4, s=0.5)\n                                ax1.set_yscale('log')\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax1.set_ylim([ymin, ymax / 100.0])\n                            p_total = np.mean(diff_rate)\n                            n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                            n_mfd_rsqsim = [i / sum(fault_pr_rsqsim[:-2]) for i in fault_pr_rsqsim[:-2]]\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pshape.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=2)\n                            if plot_rsqsim_pr == True:\n                                if round(p_total, 3) >= 1.3:\n                                    color = 'r'\n                                elif round(p_total, 3) >= 1.2:\n                                    color = 'orange'\n                                else:\n                                    color = 'g'\n                                if round(np.mean(diff_rate), 3) >= 1.3:\n                                    color_shape = 'r'\n                                elif round(np.mean(diff_rate), 3) >= 1.2:\n                                    color_shape = 'orange'\n                                else:\n                                    color_shape = 'g'\n                                ax1.set_title(model + ' ' + fault_name + ' ' + str(round(p_total, 2)), color=color)\n                                ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_ylim([0.9, 3.0])\n                                plt.show()\n                                plt.close()\n                index_fault += 1\n        score_paleo = np.mean(score_paleo_faults, axis=0)\n        '###################\"\"\\n        Compare with some other MFD at the system level (physics based for example)\\n        #####################\"'\n        plot_fig_rsqsim = False\n        RSQSim_MFD = str(Run_name) + '/mfd_RSQSim.txt'\n        try:\n            with open(RSQSim_MFD) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            mfd_rsqsim = [float(i) for i in lines[1].split('\\t')[1:-1]]\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n            index_branch = 0\n            for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n                if model_name_i == model:\n                    if plot_fig_rsqsim == True:\n                        (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bin_mag_rsqsim, mfd_rsqsim, c='k', alpha=0.9, s=3)\n                    pvalues = []\n                    diff_rate = []\n                    bining_i = []\n                    mfd_i = mfd[index_Mmin:index_Mmax]\n                    for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pvalues.append(np.mean(diff_rate))\n                    p_total = np.mean(diff_rate)\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='r', alpha=0.9, s=3)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim], c='r', s=0.5)\n                    n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                    n_mfd_rsqsim = [i / sum(mfd_rsqsim[:-2]) for i in mfd_rsqsim[:-2]]\n                    diff_rate = []\n                    bining_i = []\n                    for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pshape.append(np.mean(diff_rate))\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=3)\n                    if plot_fig_rsqsim == True:\n                        if round(p_total, 3) >= 1.3:\n                            color = 'r'\n                        elif round(p_total, 3) >= 1.2:\n                            color = 'orange'\n                        else:\n                            color = 'g'\n                        if round(np.mean(diff_rate), 3) >= 1.4:\n                            color_shape = 'r'\n                        elif round(np.mean(diff_rate), 3) >= 1.3:\n                            color_shape = 'orange'\n                        else:\n                            color_shape = 'g'\n                        ax1.set_title(model + ' ' + str(round(p_total, 2)), color=color)\n                        ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                        ax1.set_ylim([ymin / 10.0, ymax])\n                        ax1.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_ylim([0.9, 3.0])\n                        ax1.set_yscale('log')\n                        plt.show()\n                        plt.close()\n                index_branch += 1\n        except:\n            pass\n        '\\n        Setting the weight for each score\\n        '\n        weight_chi = 0.35\n        weight_Mmax = 0.05\n        weight_NMS_faults_test = 0.3\n        weight_paleo = 0.3\n        if len(score_nms) == 0.0:\n            print('!!! no selected faults for the NMS metric !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_NMS_faults_test = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_paleo = weight_paleo / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_nms.append(0.0)\n        if len(score_paleo) == 0.0:\n            print('!!! no paleo data on the faults !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_paleo = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_NMS_faults_test = weight_NMS_faults_test / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_paleo.append(0.0)\n        ' \\n        Builbing the text file\\n        '\n        lt_branch = []\n        lt_i_before = 'truc'\n        srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n        try:\n            with open(srep_file) as f:\n                lines = f.readlines()\n            ordered_score_paleo = []\n            i_lt = 0\n            for line in lines:\n                if line.split('\\t')[1] == model:\n                    lt_i = []\n                    for i in range(7):\n                        lt_i.append(line.split('\\t')[i])\n                    if str(lt_i) != lt_i_before:\n                        lt_i_before = str(lt_i)\n                        lt_i.append(round(mean_sr_branch[i_lt], 3))\n                        lt_i.append(round(p_chi_branch[i_lt], 3))\n                        lt_i.append(round(weight_model_Mmax[i_lt], 3))\n                        lt_i.append(round(score_nms[i_lt], 3))\n                        i1 = np.where(np.array(paleo_list_mfd) == line.split('\\t')[4][4:])[0]\n                        i2 = np.where(np.array(paleo_list_scenario) == line.split('\\t')[5])[0]\n                        i3 = np.where(np.array(paleo_list_sample) == line.split('\\t')[6].split('_')[1])[0]\n                        i4 = np.where(np.array(paleo_list_bvalue) == line.split('\\t')[3])[0]\n                        i5 = np.where(np.array(paleo_list_bg) == line.split('\\t')[2][3:])[0]\n                        i6 = np.where(np.array(paleo_list_scl) == line.split('\\t')[0])[0]\n                        i1 = np.intersect1d(i1, i2)\n                        i1 = np.intersect1d(i1, i3)\n                        i1 = np.intersect1d(i1, i4)\n                        i1 = np.intersect1d(i1, i5)\n                        i1 = np.intersect1d(i1, i6)\n                        lt_i.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        ordered_score_paleo.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        lt_branch.append(lt_i)\n                        i_lt += 1\n            for lt_i in lt_branch:\n                line = ''\n                for i in lt_i:\n                    line += str(i) + '\\t'\n                line = line[:-1]\n                file_LT_metrics.write(line + '\\n')\n        except (FileNotFoundError, IndexError) as e:\n            print('!!! you need to run the plot_sr_use if you want the file with the metrics  and modify Sampling_analysis.py!!!')\n        '\\n        Calculataing the weighted score for each branch\\n        '\n        if ordered_score_paleo == []:\n            ordered_score_paleo = [0 for i in range(len(p_chi_branch))]\n        final_weigth = []\n        for i in range(len(p_chi_branch)):\n            final_weigth.append(p_chi_branch[i] * weight_chi + weight_model_Mmax[i] * weight_Mmax + score_nms[i] * weight_NMS_faults_test + ordered_score_paleo[i] * weight_paleo)\n        '\\n        Plotting section\\n        \\n        Weighted average of the different metric\\n        \\n        user defined weight for each metric. the figure give the weighted average as a final p value\\n        '\n        color_mfd = []\n        for (MFD_type_i, model_name_i) in zip(total_list_MFD_type, total_list_model):\n            if model_name_i == model:\n                if MFD_type_i == 'GR':\n                    color_mfd.append('darkblue')\n                else:\n                    color_mfd.append('darkgreen')\n        (f, (ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, sharey=True)\n        ax1.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax1.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax1.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax2.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax2.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax2.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax3.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax3.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax3.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax4.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax4.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax4.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax5.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax5.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax5.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax1.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax1.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            if total_list_scenario_name[j] == total_list_scenario_name[0]:\n                if weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                else:\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n            elif weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n            else:\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n        ax1.set_xlabel('Mmax')\n        ax1.set_ylabel('test value   ' + str(model))\n        ax1.set_ylim([-0.05, 1.05])\n        ax1.set_xlim([xmax - 1.5, xmax])\n        ax2.set_xlim([xmax - 1.5, xmax])\n        ax3.set_xlim([xmax - 1.5, xmax])\n        ax4.set_xlim([xmax - 1.5, xmax])\n        ax5.set_xlim([xmax - 1.5, xmax])\n        ax1.set_title('chi test')\n        ax2.set_title('Mmax test')\n        ax3.set_title('NMS test')\n        ax4.set_title('Paleo test')\n        ax5.set_title('weitghted total')\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/model_performance.png', dpi=180)\n        plt.close()\n        index_model += 1\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            file.write(str(model) + '\\t' + str(total_list_MFD_type[j]) + '\\t' + str(total_list_BG_hyp[j]) + '\\t' + str(total_list_scenario_name[j]) + '\\t' + str(total_list_sample[j]) + '\\t' + str(round(p_chi_branch[i], 2)) + '\\t' + str(round(ordered_score_paleo[i], 2)) + '\\t' + str(round(score_nms[i], 2)) + '\\n')\n    file.close()\n    file_LT_metrics.close()",
            "def sampling_analysis(Run_name, Model_list, m_Mmax, b_sample, a_s_model, mega_mfd_cummulative, catalog_cum_rate, xmin, xmax, ymin, ymax, total_list_model, bining_in_mag, total_list_MFD_type, total_list_scenario_name, file_faults_data, total_list_sample, total_list_BG_hyp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis'):\n        os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis')\n    file_LT_metrics = open(str(Run_name) + '/analysis/txt_files/LT_metrics.txt', 'w')\n    file_LT_metrics.write('ScL\\tModel\\tBG\\tbvalue\\tMFD\\tSc\\tsample\\tmean_sr\\tchi_score\\tMmax_score\\tNMS_score\\tpaleo_score\\n')\n    \"\\n    #read the catalog cumulative rates for all sampling \\n        and compare each branch to the catalog using the chi-squared test\\n    \\n    methodology:\\n        for each branch i of the logic tree\\n        30 random MFD calculated from the catalog are extracted for the comaprison\\n        the modeled rate of the branch i are compared the each on of these random samples\\n        the comparison is done using the following formula:\\n        we calculate the absolute value of the difference between the logs of the model minus the log of catalog rate\\n        we had 10 to this asolute value to make it accepatble or the chi-squarred test\\n        we run the chisquared test for an array of ten value corresponding to one unit of magnitude (ten bins of 0.1)\\n        bins of magnitude where one of the two rates are not defined are deleted\\n        the value are conpared to an array of value equal ten (the expected value is the model fits the data)\\n        we save the pvalue calculated \\n        \\n        In order to get the p value for the whole MFD, we do the mean of the pvalue for each unit of magnitude \\n        weighted by the number of filled bins in the range of magnitude.\\n        \\n        If the p value is close to 1, the two MFD are similar. \\n        \\n        personal opinion: \\n        p values superior to 0.9 seam like a good match\\n        p values superior to 0.8 seam like an acceptable match in most cases\\n        p values less than 0.7 make the match difficult to accept\\n        \\n        Warning! this method doesn't care if the two maximum magnitude are different,\\n        it will only take the bin where both MFDs are defined. \\n        The fit in terms of Mmax need to rely on some other test. (hopefully I managed to provide one...)\\n        \\n    \"\n    plot_fig = False\n    index_Mmin = np.where(np.array(np.linspace(4.0, 7.0, num=31).round(1)) == xmin)[0][0]\n    index_Mmax = np.where(np.array(np.linspace(4.0, 10.0, num=61).round(1)) == xmax)[0][0] + 1\n    file = open(str(Run_name) + '/analysis/txt_files/model_performance.txt', 'w')\n    file.write('Model\\tMFD type\\tBG\\tScenario Set\\tsample\\tFit to catalog\\tFit to Paleo\\tNMS score\\n')\n    index_model = 0\n    for model in Model_list:\n        if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis/' + model):\n            os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis/' + model)\n        catfile_all = str(Run_name) + '/analysis/figures/catalogue/catalog_rates_all_' + model + '.txt'\n        with open(catfile_all) as f:\n            lines_cat = f.readlines()\n        ranges_mag = [[4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], [5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9], [6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9], [7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9], [8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9], [9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]]\n        p_chi_branch = []\n        indexes_model = []\n        index_branch = 0\n        for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n            if model_name_i == model:\n                indexes_model.append(index_branch)\n                indexes_catalogs_to_test = np.random.choice(range(len(lines_cat))[1:], size=40)\n                pvalues = [[], [], [], [], [], []]\n                weights_pvalues = [[], [], [], [], [], []]\n                if plot_fig == True:\n                    (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                for i_cat in indexes_catalogs_to_test:\n                    cat_rates_i = lines_cat[i_cat].split('\\t')\n                    cat_rates_i = [float(i) for i in cat_rates_i]\n                    if plot_fig == True:\n                        ax1.scatter(bining_in_mag, cat_rates_i, c='k', alpha=0.1, s=0.5)\n                    index_range = 0\n                    for range_i in ranges_mag:\n                        diff_rate = []\n                        target_value = []\n                        bining_i = []\n                        for (model_rate_i, data_rate_i, mag_i) in zip(mfd[index_Mmin:index_Mmax], cat_rates_i, bining_in_mag):\n                            if model_rate_i != 0 and data_rate_i != 0 and (mag_i in range_i):\n                                diff_rate.append(abs(np.log10(model_rate_i) - np.log10(data_rate_i)) * 10.0 + 10.0)\n                                target_value.append(10.0)\n                                bining_i.append(mag_i)\n                        if len(diff_rate) >= 2:\n                            pvalues[index_range].append(chisquare(diff_rate, f_exp=target_value)[1])\n                            weights_pvalues[index_range].append(len(diff_rate))\n                            if plot_fig == True:\n                                ax2.scatter(bining_i, diff_rate, c='r', alpha=0.2, s=2)\n                                ax2.scatter(bining_i, target_value, c='k', alpha=0.1, s=2)\n                        index_range += 1\n                if plot_fig == True:\n                    ax1.scatter(bining_in_mag, mfd[index_Mmin:index_Mmax], c='r', s=0.5)\n                    ax1.set_yscale('log')\n                    ax1.set_xlim([xmin, xmax])\n                    ax1.set_ylim([ymin, ymax])\n                p_total = []\n                weight_p = []\n                for (range_i, p_i, w_i) in zip(ranges_mag, pvalues, weights_pvalues):\n                    if len(p_i) != 0:\n                        weight_p.append(np.mean(w_i))\n                        p_total.append(round(np.mean(p_i), 4))\n                        if plot_fig == True:\n                            if round(np.mean(p_i), 3) >= 0.9:\n                                color = 'g'\n                            elif round(np.mean(p_i), 3) >= 0.8:\n                                color = 'orange'\n                            else:\n                                color = 'r'\n                            ax2.text(np.mean(range_i), 25, str(round(np.mean(p_i), 3)), fontsize=8, color=color)\n                p_chi_branch.append(round(np.average(p_total, weights=weight_p), 3))\n                if plot_fig == True:\n                    if round(np.average(p_total, weights=weight_p), 3) >= 0.9:\n                        color = 'g'\n                    elif round(np.average(p_total, weights=weight_p), 3) >= 0.8:\n                        color = 'orange'\n                    else:\n                        color = 'r'\n                    ax1.set_title(str(round(np.average(p_total, weights=weight_p), 3)), color=color)\n                    ax2.set_xlim([xmin - 0.1, xmax])\n                    ax2.set_ylim([9, 30])\n                    plt.show()\n                    plt.close()\n            index_branch += 1\n        '\\n        #   Mmax fit to the Mmax in the catalog\\n        \\n        The rule is: The Mmax in the model should be at least the one in the catalog \\n        but the catalog has some uncertainties on the magnitude of large historical EQs\\n        \\n        methodology:\\n            we calculate the cumulative density distribution of the Mmax in the catalog\\n            we associate the given density to each Mmax of the models\\n        \\n        '\n        Mmax_cat = []\n        bining_cat = lines_cat[0].split('\\t')\n        bining_cat = [float(i) for i in bining_cat]\n        for i_cat in range(len(lines_cat) - 1):\n            cat_rates_i = lines_cat[i_cat + 1].split('\\t')\n            cat_rates_i = [float(i) for i in cat_rates_i]\n            i_test = 0\n            try:\n                while cat_rates_i[i_test] != 0:\n                    i_test += 1\n            except:\n                i_test = len(cat_rates_i) - 1\n            Mmax_cat.append(bining_cat[i_test])\n        distribution_Mmax_cat = []\n        for mag_i in bining_cat:\n            d_i = sum((i <= mag_i + 0.1 for i in Mmax_cat)) / len(Mmax_cat)\n            distribution_Mmax_cat.append(d_i)\n        plt.plot(bining_cat, distribution_Mmax_cat)\n        plt.xlim([xmax - 1.5, xmax])\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/Mmax_distrib_in_the_cat.png', dpi=180)\n        plt.close()\n        weight_model_Mmax = []\n        for (Mmax_i, model_name_i) in zip(m_Mmax, total_list_model):\n            if model_name_i == model:\n                index = np.where(np.array(bining_cat) == Mmax_i)[0][0]\n                weight_model_Mmax.append(distribution_Mmax_cat[index])\n        '\\n        The NMS on a set of faults as a metric for judging the quality of a model\\n        '\n        fault_set = ['F1', 'F2', 'F3']\n        NMS_set = []\n        for fault in fault_set:\n            NMS_set.append([])\n        if len(NMS_set) != 0:\n            sr_sample = []\n            for fault in fault_set:\n                sr_sample.append([])\n            score_nms = []\n            srate_sample_file = str(Run_name) + '/analysis/txt_files/slip_rate_sampling.txt'\n            with open(srate_sample_file) as f:\n                lines_sr = f.readlines()\n            srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n            try:\n                with open(srep_file) as f:\n                    lines = f.readlines()\n                line_number = 0\n                for line in lines:\n                    if line.split('\\t')[7] in fault_set and line.split('\\t')[1] == model:\n                        index_fault = np.where(np.array(fault_set) == line.split('\\t')[7])[0][0]\n                        NMS_set[index_fault].append(float(line.split('\\t')[-1]))\n                        sr_sample[index_fault].append(float(lines_sr[line_number].split('\\t')[-1]))\n                    line_number += 1\n                if np.sum(NMS_set) != 0.0:\n                    for i in range(len(p_chi_branch)):\n                        '\\n                      the score is 1 is MSN is less than 20%\\n                      the score is 0 if:\\n                          at least one of the NMS of the test faults if more than 50%\\n                          the mean is more the 40%\\n                      between 20 and 40 the score evolves linearily between 1 and 0\\n                      (this is very much open to discussion!)\\n                      '\n                        if np.mean(NMS_set, axis=0)[i] > 40.0:\n                            score_nms_i = 0.0\n                        elif np.mean(NMS_set, axis=0)[i] < 20.0:\n                            score_nms_i = 1.0\n                        else:\n                            score_nms_i = 2 - 1.0 / 20.0 * np.mean(NMS_set, axis=0)[i]\n                        'hard limit on acceptability'\n                        for nms_row in NMS_set:\n                            if nms_row[i] > 50.0:\n                                score_nms_i = 0.0\n                        score_nms.append(score_nms_i)\n            except FileNotFoundError:\n                print('!!! you need to run the plot_sr_use if you want the NMS metric !!!')\n                print('Default value = 1. ')\n                for i in range(len(p_chi_branch)):\n                    score_nms.append(1.0)\n        else:\n            print('modify Sampling_analysis.py for the NMS metric')\n            print('Default value = 1. ')\n            for i in range(len(p_chi_branch)):\n                score_nms.append(1.0)\n        mean_sr_branch = np.mean(sr_sample, axis=0)\n        '#############################\\n        Weight based on the fit to the paleo rates\\n        \\n        and the RSQSim rates if they exist\\n        #######################################'\n        plot_paleo = False\n        plot_rsqsim_pr = True\n        faults_data = np.genfromtxt(file_faults_data, dtype=[('model', 'U100000'), ('fault_name', 'U100000'), ('type', 'U100000'), ('M', 'f8'), ('sig_M', 'f8'), ('rate', 'f8'), ('sig_rate', 'f8')], delimiter='\\t', skip_header=1)\n        try:\n            len_faults_data = len(faults_data)\n        except TypeError:\n            faults_data = faults_data.reshape((1,))\n        rsqsim_pr = False\n        RSQSim_pr_file = str(Run_name) + '/file_pr_rsqsim.txt'\n        try:\n            with open(RSQSim_pr_file) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            rqsim_pr_faults = []\n            faults_name_rsqsim = []\n            for line in lines[1:]:\n                faults_name_rsqsim.append(line.split('\\t')[0])\n                rqsim_pr_faults.append([float(i) for i in line.split('\\t')[1:-1]])\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n        except:\n            rsqsim_pr = False\n        data_model = list(map(lambda i: faults_data[i][0], range(len(faults_data))))\n        data_fault_name = list(map(lambda i: faults_data[i][1], range(len(faults_data))))\n        data_type = list(map(lambda i: faults_data[i][2], range(len(faults_data))))\n        data_M = list(map(lambda i: float(faults_data[i][3]), range(len(faults_data))))\n        data_sig_M = list(map(lambda i: float(faults_data[i][4]), range(len(faults_data))))\n        data_rate = list(map(lambda i: float(faults_data[i][5]), range(len(faults_data))))\n        data_sig_rate = list(map(lambda i: float(faults_data[i][6]), range(len(faults_data))))\n        score_paleo = []\n        score_paleo_faults = []\n        faults_data = []\n        score_pr_rsqsim = []\n        faults_rsqsim = []\n        for (fault, data_model_i) in zip(data_fault_name, data_model):\n            if data_model_i == model and fault not in faults_data:\n                score_paleo_faults.append([])\n                faults_data.append(fault)\n                if rsqsim_pr == True:\n                    if fault in faults_name_rsqsim and fault not in faults_rsqsim:\n                        score_pr_rsqsim.append([])\n                        faults_rsqsim.append(fault)\n        participation_rate_file = str(Run_name) + '/analysis/figures/rupture_rate_for_each_fault_cum/' + model + '/file_for_comparison.txt'\n        with open(participation_rate_file) as f:\n            lines_pr = f.readlines()\n        paleo_list_mfd = []\n        paleo_list_bvalue = []\n        paleo_list_bg = []\n        paleo_list_scl = []\n        paleo_list_scenario = []\n        paleo_list_sample = []\n        index_branch = 0\n        for line in lines_pr:\n            index_fault = 0\n            for fault_name in faults_data:\n                if line.split('\\t')[0] == model and line.split('\\t')[7] == fault_name:\n                    if index_fault == 0:\n                        paleo_list_mfd.append(line.split('\\t')[1])\n                        paleo_list_scenario.append(line.split('\\t')[2])\n                        paleo_list_bg.append(line.split('\\t')[3])\n                        paleo_list_scl.append(line.split('\\t')[4])\n                        paleo_list_bvalue.append(line.split('\\t')[5])\n                        paleo_list_sample.append(line.split('\\t')[6])\n                    mfd_i = [float(i) for i in list(line.split('\\t')[8 + index_Mmin:8 + index_Mmax])]\n                    self_data_M = []\n                    self_data_sig_M = []\n                    self_data_rate = []\n                    self_data_sig_rate = []\n                    index_fault_in_data = np.where(np.array(data_fault_name) == fault_name)[0]\n                    for index_i in index_fault_in_data:\n                        if data_model[index_i] == model and data_type[index_i] == 'pal':\n                            self_data_M.append(data_M[index_i])\n                            self_data_sig_M.append(data_sig_M[index_i])\n                            self_data_rate.append(data_rate[index_i])\n                            self_data_sig_rate.append(data_sig_rate[index_i])\n                    paleo_score_i = []\n                    for (m_i, sm_i, r_i, sr_i) in zip(self_data_M, self_data_sig_M, self_data_rate, self_data_sig_rate):\n                        (x, y) = np.mgrid[4.5:7.5:0.01, -5.0:0.0:0.01]\n                        pos = np.empty(x.shape + (2,))\n                        pos[:, :, 0] = x\n                        pos[:, :, 1] = y\n                        rv = multivariate_normal([m_i, np.log10(r_i)], [sm_i + 0.001, sr_i + 1e-07])\n                        detailed_bin_mag = np.linspace(bining_in_mag[0], bining_in_mag[-1], 1000)\n                        detailed_mfd_i = np.interp(detailed_bin_mag, bining_in_mag, np.log10(mfd_i))\n                        if plot_paleo == True:\n                            plt.contourf(x, y, rv.pdf(pos), alpha=0.5)\n                            plt.scatter(bining_in_mag, np.log10(mfd_i), c='k', marker='s', s=10, linewidths=0.01, alpha=0.7)\n                            plt.scatter(detailed_bin_mag, detailed_mfd_i, c='k', marker='s', s=3, linewidths=0.01, alpha=0.7)\n                            plt.xlim([5.0, 7.0])\n                            plt.ylim([-3, -1.0])\n                            plt.grid()\n                            plt.show()\n                        paleo_score_i.append(max([rv.pdf([i, j]) / rv.pdf([m_i, np.log10(r_i)]) for (i, j) in zip(detailed_bin_mag, detailed_mfd_i)]))\n                    score_paleo_faults[index_fault].append(np.mean(paleo_score_i))\n                    if rsqsim_pr == True and line.split('\\t')[6] == '1':\n                        pvalues = []\n                        pshape = []\n                        if fault_name in faults_rsqsim:\n                            index_fault_rsqsim = np.where(np.array(faults_name_rsqsim) == fault_name)[0][0]\n                            fault_pr_rsqsim = rqsim_pr_faults[index_fault_rsqsim]\n                            if plot_rsqsim_pr == True:\n                                (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bin_mag_rsqsim[:-2], fault_pr_rsqsim[:-2], c='k', alpha=0.9, s=3)\n                                ax1.scatter(bin_mag_rsqsim[-2:], fault_pr_rsqsim[-2:], c='k', alpha=0.5, s=3)\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], fault_pr_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pvalues.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='b', alpha=0.8, s=2)\n                                index_range += 1\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], c='r', s=0.5)\n                                ax1.scatter(bining_in_mag[-2:], mfd_i[-2:], c='r', alpha=0.4, s=0.5)\n                                ax1.set_yscale('log')\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax1.set_ylim([ymin, ymax / 100.0])\n                            p_total = np.mean(diff_rate)\n                            n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                            n_mfd_rsqsim = [i / sum(fault_pr_rsqsim[:-2]) for i in fault_pr_rsqsim[:-2]]\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pshape.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=2)\n                            if plot_rsqsim_pr == True:\n                                if round(p_total, 3) >= 1.3:\n                                    color = 'r'\n                                elif round(p_total, 3) >= 1.2:\n                                    color = 'orange'\n                                else:\n                                    color = 'g'\n                                if round(np.mean(diff_rate), 3) >= 1.3:\n                                    color_shape = 'r'\n                                elif round(np.mean(diff_rate), 3) >= 1.2:\n                                    color_shape = 'orange'\n                                else:\n                                    color_shape = 'g'\n                                ax1.set_title(model + ' ' + fault_name + ' ' + str(round(p_total, 2)), color=color)\n                                ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_ylim([0.9, 3.0])\n                                plt.show()\n                                plt.close()\n                index_fault += 1\n        score_paleo = np.mean(score_paleo_faults, axis=0)\n        '###################\"\"\\n        Compare with some other MFD at the system level (physics based for example)\\n        #####################\"'\n        plot_fig_rsqsim = False\n        RSQSim_MFD = str(Run_name) + '/mfd_RSQSim.txt'\n        try:\n            with open(RSQSim_MFD) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            mfd_rsqsim = [float(i) for i in lines[1].split('\\t')[1:-1]]\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n            index_branch = 0\n            for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n                if model_name_i == model:\n                    if plot_fig_rsqsim == True:\n                        (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bin_mag_rsqsim, mfd_rsqsim, c='k', alpha=0.9, s=3)\n                    pvalues = []\n                    diff_rate = []\n                    bining_i = []\n                    mfd_i = mfd[index_Mmin:index_Mmax]\n                    for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pvalues.append(np.mean(diff_rate))\n                    p_total = np.mean(diff_rate)\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='r', alpha=0.9, s=3)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim], c='r', s=0.5)\n                    n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                    n_mfd_rsqsim = [i / sum(mfd_rsqsim[:-2]) for i in mfd_rsqsim[:-2]]\n                    diff_rate = []\n                    bining_i = []\n                    for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pshape.append(np.mean(diff_rate))\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=3)\n                    if plot_fig_rsqsim == True:\n                        if round(p_total, 3) >= 1.3:\n                            color = 'r'\n                        elif round(p_total, 3) >= 1.2:\n                            color = 'orange'\n                        else:\n                            color = 'g'\n                        if round(np.mean(diff_rate), 3) >= 1.4:\n                            color_shape = 'r'\n                        elif round(np.mean(diff_rate), 3) >= 1.3:\n                            color_shape = 'orange'\n                        else:\n                            color_shape = 'g'\n                        ax1.set_title(model + ' ' + str(round(p_total, 2)), color=color)\n                        ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                        ax1.set_ylim([ymin / 10.0, ymax])\n                        ax1.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_ylim([0.9, 3.0])\n                        ax1.set_yscale('log')\n                        plt.show()\n                        plt.close()\n                index_branch += 1\n        except:\n            pass\n        '\\n        Setting the weight for each score\\n        '\n        weight_chi = 0.35\n        weight_Mmax = 0.05\n        weight_NMS_faults_test = 0.3\n        weight_paleo = 0.3\n        if len(score_nms) == 0.0:\n            print('!!! no selected faults for the NMS metric !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_NMS_faults_test = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_paleo = weight_paleo / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_nms.append(0.0)\n        if len(score_paleo) == 0.0:\n            print('!!! no paleo data on the faults !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_paleo = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_NMS_faults_test = weight_NMS_faults_test / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_paleo.append(0.0)\n        ' \\n        Builbing the text file\\n        '\n        lt_branch = []\n        lt_i_before = 'truc'\n        srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n        try:\n            with open(srep_file) as f:\n                lines = f.readlines()\n            ordered_score_paleo = []\n            i_lt = 0\n            for line in lines:\n                if line.split('\\t')[1] == model:\n                    lt_i = []\n                    for i in range(7):\n                        lt_i.append(line.split('\\t')[i])\n                    if str(lt_i) != lt_i_before:\n                        lt_i_before = str(lt_i)\n                        lt_i.append(round(mean_sr_branch[i_lt], 3))\n                        lt_i.append(round(p_chi_branch[i_lt], 3))\n                        lt_i.append(round(weight_model_Mmax[i_lt], 3))\n                        lt_i.append(round(score_nms[i_lt], 3))\n                        i1 = np.where(np.array(paleo_list_mfd) == line.split('\\t')[4][4:])[0]\n                        i2 = np.where(np.array(paleo_list_scenario) == line.split('\\t')[5])[0]\n                        i3 = np.where(np.array(paleo_list_sample) == line.split('\\t')[6].split('_')[1])[0]\n                        i4 = np.where(np.array(paleo_list_bvalue) == line.split('\\t')[3])[0]\n                        i5 = np.where(np.array(paleo_list_bg) == line.split('\\t')[2][3:])[0]\n                        i6 = np.where(np.array(paleo_list_scl) == line.split('\\t')[0])[0]\n                        i1 = np.intersect1d(i1, i2)\n                        i1 = np.intersect1d(i1, i3)\n                        i1 = np.intersect1d(i1, i4)\n                        i1 = np.intersect1d(i1, i5)\n                        i1 = np.intersect1d(i1, i6)\n                        lt_i.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        ordered_score_paleo.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        lt_branch.append(lt_i)\n                        i_lt += 1\n            for lt_i in lt_branch:\n                line = ''\n                for i in lt_i:\n                    line += str(i) + '\\t'\n                line = line[:-1]\n                file_LT_metrics.write(line + '\\n')\n        except (FileNotFoundError, IndexError) as e:\n            print('!!! you need to run the plot_sr_use if you want the file with the metrics  and modify Sampling_analysis.py!!!')\n        '\\n        Calculataing the weighted score for each branch\\n        '\n        if ordered_score_paleo == []:\n            ordered_score_paleo = [0 for i in range(len(p_chi_branch))]\n        final_weigth = []\n        for i in range(len(p_chi_branch)):\n            final_weigth.append(p_chi_branch[i] * weight_chi + weight_model_Mmax[i] * weight_Mmax + score_nms[i] * weight_NMS_faults_test + ordered_score_paleo[i] * weight_paleo)\n        '\\n        Plotting section\\n        \\n        Weighted average of the different metric\\n        \\n        user defined weight for each metric. the figure give the weighted average as a final p value\\n        '\n        color_mfd = []\n        for (MFD_type_i, model_name_i) in zip(total_list_MFD_type, total_list_model):\n            if model_name_i == model:\n                if MFD_type_i == 'GR':\n                    color_mfd.append('darkblue')\n                else:\n                    color_mfd.append('darkgreen')\n        (f, (ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, sharey=True)\n        ax1.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax1.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax1.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax2.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax2.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax2.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax3.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax3.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax3.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax4.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax4.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax4.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax5.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax5.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax5.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax1.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax1.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            if total_list_scenario_name[j] == total_list_scenario_name[0]:\n                if weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                else:\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n            elif weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n            else:\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n        ax1.set_xlabel('Mmax')\n        ax1.set_ylabel('test value   ' + str(model))\n        ax1.set_ylim([-0.05, 1.05])\n        ax1.set_xlim([xmax - 1.5, xmax])\n        ax2.set_xlim([xmax - 1.5, xmax])\n        ax3.set_xlim([xmax - 1.5, xmax])\n        ax4.set_xlim([xmax - 1.5, xmax])\n        ax5.set_xlim([xmax - 1.5, xmax])\n        ax1.set_title('chi test')\n        ax2.set_title('Mmax test')\n        ax3.set_title('NMS test')\n        ax4.set_title('Paleo test')\n        ax5.set_title('weitghted total')\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/model_performance.png', dpi=180)\n        plt.close()\n        index_model += 1\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            file.write(str(model) + '\\t' + str(total_list_MFD_type[j]) + '\\t' + str(total_list_BG_hyp[j]) + '\\t' + str(total_list_scenario_name[j]) + '\\t' + str(total_list_sample[j]) + '\\t' + str(round(p_chi_branch[i], 2)) + '\\t' + str(round(ordered_score_paleo[i], 2)) + '\\t' + str(round(score_nms[i], 2)) + '\\n')\n    file.close()\n    file_LT_metrics.close()",
            "def sampling_analysis(Run_name, Model_list, m_Mmax, b_sample, a_s_model, mega_mfd_cummulative, catalog_cum_rate, xmin, xmax, ymin, ymax, total_list_model, bining_in_mag, total_list_MFD_type, total_list_scenario_name, file_faults_data, total_list_sample, total_list_BG_hyp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis'):\n        os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis')\n    file_LT_metrics = open(str(Run_name) + '/analysis/txt_files/LT_metrics.txt', 'w')\n    file_LT_metrics.write('ScL\\tModel\\tBG\\tbvalue\\tMFD\\tSc\\tsample\\tmean_sr\\tchi_score\\tMmax_score\\tNMS_score\\tpaleo_score\\n')\n    \"\\n    #read the catalog cumulative rates for all sampling \\n        and compare each branch to the catalog using the chi-squared test\\n    \\n    methodology:\\n        for each branch i of the logic tree\\n        30 random MFD calculated from the catalog are extracted for the comaprison\\n        the modeled rate of the branch i are compared the each on of these random samples\\n        the comparison is done using the following formula:\\n        we calculate the absolute value of the difference between the logs of the model minus the log of catalog rate\\n        we had 10 to this asolute value to make it accepatble or the chi-squarred test\\n        we run the chisquared test for an array of ten value corresponding to one unit of magnitude (ten bins of 0.1)\\n        bins of magnitude where one of the two rates are not defined are deleted\\n        the value are conpared to an array of value equal ten (the expected value is the model fits the data)\\n        we save the pvalue calculated \\n        \\n        In order to get the p value for the whole MFD, we do the mean of the pvalue for each unit of magnitude \\n        weighted by the number of filled bins in the range of magnitude.\\n        \\n        If the p value is close to 1, the two MFD are similar. \\n        \\n        personal opinion: \\n        p values superior to 0.9 seam like a good match\\n        p values superior to 0.8 seam like an acceptable match in most cases\\n        p values less than 0.7 make the match difficult to accept\\n        \\n        Warning! this method doesn't care if the two maximum magnitude are different,\\n        it will only take the bin where both MFDs are defined. \\n        The fit in terms of Mmax need to rely on some other test. (hopefully I managed to provide one...)\\n        \\n    \"\n    plot_fig = False\n    index_Mmin = np.where(np.array(np.linspace(4.0, 7.0, num=31).round(1)) == xmin)[0][0]\n    index_Mmax = np.where(np.array(np.linspace(4.0, 10.0, num=61).round(1)) == xmax)[0][0] + 1\n    file = open(str(Run_name) + '/analysis/txt_files/model_performance.txt', 'w')\n    file.write('Model\\tMFD type\\tBG\\tScenario Set\\tsample\\tFit to catalog\\tFit to Paleo\\tNMS score\\n')\n    index_model = 0\n    for model in Model_list:\n        if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis/' + model):\n            os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis/' + model)\n        catfile_all = str(Run_name) + '/analysis/figures/catalogue/catalog_rates_all_' + model + '.txt'\n        with open(catfile_all) as f:\n            lines_cat = f.readlines()\n        ranges_mag = [[4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], [5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9], [6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9], [7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9], [8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9], [9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]]\n        p_chi_branch = []\n        indexes_model = []\n        index_branch = 0\n        for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n            if model_name_i == model:\n                indexes_model.append(index_branch)\n                indexes_catalogs_to_test = np.random.choice(range(len(lines_cat))[1:], size=40)\n                pvalues = [[], [], [], [], [], []]\n                weights_pvalues = [[], [], [], [], [], []]\n                if plot_fig == True:\n                    (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                for i_cat in indexes_catalogs_to_test:\n                    cat_rates_i = lines_cat[i_cat].split('\\t')\n                    cat_rates_i = [float(i) for i in cat_rates_i]\n                    if plot_fig == True:\n                        ax1.scatter(bining_in_mag, cat_rates_i, c='k', alpha=0.1, s=0.5)\n                    index_range = 0\n                    for range_i in ranges_mag:\n                        diff_rate = []\n                        target_value = []\n                        bining_i = []\n                        for (model_rate_i, data_rate_i, mag_i) in zip(mfd[index_Mmin:index_Mmax], cat_rates_i, bining_in_mag):\n                            if model_rate_i != 0 and data_rate_i != 0 and (mag_i in range_i):\n                                diff_rate.append(abs(np.log10(model_rate_i) - np.log10(data_rate_i)) * 10.0 + 10.0)\n                                target_value.append(10.0)\n                                bining_i.append(mag_i)\n                        if len(diff_rate) >= 2:\n                            pvalues[index_range].append(chisquare(diff_rate, f_exp=target_value)[1])\n                            weights_pvalues[index_range].append(len(diff_rate))\n                            if plot_fig == True:\n                                ax2.scatter(bining_i, diff_rate, c='r', alpha=0.2, s=2)\n                                ax2.scatter(bining_i, target_value, c='k', alpha=0.1, s=2)\n                        index_range += 1\n                if plot_fig == True:\n                    ax1.scatter(bining_in_mag, mfd[index_Mmin:index_Mmax], c='r', s=0.5)\n                    ax1.set_yscale('log')\n                    ax1.set_xlim([xmin, xmax])\n                    ax1.set_ylim([ymin, ymax])\n                p_total = []\n                weight_p = []\n                for (range_i, p_i, w_i) in zip(ranges_mag, pvalues, weights_pvalues):\n                    if len(p_i) != 0:\n                        weight_p.append(np.mean(w_i))\n                        p_total.append(round(np.mean(p_i), 4))\n                        if plot_fig == True:\n                            if round(np.mean(p_i), 3) >= 0.9:\n                                color = 'g'\n                            elif round(np.mean(p_i), 3) >= 0.8:\n                                color = 'orange'\n                            else:\n                                color = 'r'\n                            ax2.text(np.mean(range_i), 25, str(round(np.mean(p_i), 3)), fontsize=8, color=color)\n                p_chi_branch.append(round(np.average(p_total, weights=weight_p), 3))\n                if plot_fig == True:\n                    if round(np.average(p_total, weights=weight_p), 3) >= 0.9:\n                        color = 'g'\n                    elif round(np.average(p_total, weights=weight_p), 3) >= 0.8:\n                        color = 'orange'\n                    else:\n                        color = 'r'\n                    ax1.set_title(str(round(np.average(p_total, weights=weight_p), 3)), color=color)\n                    ax2.set_xlim([xmin - 0.1, xmax])\n                    ax2.set_ylim([9, 30])\n                    plt.show()\n                    plt.close()\n            index_branch += 1\n        '\\n        #   Mmax fit to the Mmax in the catalog\\n        \\n        The rule is: The Mmax in the model should be at least the one in the catalog \\n        but the catalog has some uncertainties on the magnitude of large historical EQs\\n        \\n        methodology:\\n            we calculate the cumulative density distribution of the Mmax in the catalog\\n            we associate the given density to each Mmax of the models\\n        \\n        '\n        Mmax_cat = []\n        bining_cat = lines_cat[0].split('\\t')\n        bining_cat = [float(i) for i in bining_cat]\n        for i_cat in range(len(lines_cat) - 1):\n            cat_rates_i = lines_cat[i_cat + 1].split('\\t')\n            cat_rates_i = [float(i) for i in cat_rates_i]\n            i_test = 0\n            try:\n                while cat_rates_i[i_test] != 0:\n                    i_test += 1\n            except:\n                i_test = len(cat_rates_i) - 1\n            Mmax_cat.append(bining_cat[i_test])\n        distribution_Mmax_cat = []\n        for mag_i in bining_cat:\n            d_i = sum((i <= mag_i + 0.1 for i in Mmax_cat)) / len(Mmax_cat)\n            distribution_Mmax_cat.append(d_i)\n        plt.plot(bining_cat, distribution_Mmax_cat)\n        plt.xlim([xmax - 1.5, xmax])\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/Mmax_distrib_in_the_cat.png', dpi=180)\n        plt.close()\n        weight_model_Mmax = []\n        for (Mmax_i, model_name_i) in zip(m_Mmax, total_list_model):\n            if model_name_i == model:\n                index = np.where(np.array(bining_cat) == Mmax_i)[0][0]\n                weight_model_Mmax.append(distribution_Mmax_cat[index])\n        '\\n        The NMS on a set of faults as a metric for judging the quality of a model\\n        '\n        fault_set = ['F1', 'F2', 'F3']\n        NMS_set = []\n        for fault in fault_set:\n            NMS_set.append([])\n        if len(NMS_set) != 0:\n            sr_sample = []\n            for fault in fault_set:\n                sr_sample.append([])\n            score_nms = []\n            srate_sample_file = str(Run_name) + '/analysis/txt_files/slip_rate_sampling.txt'\n            with open(srate_sample_file) as f:\n                lines_sr = f.readlines()\n            srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n            try:\n                with open(srep_file) as f:\n                    lines = f.readlines()\n                line_number = 0\n                for line in lines:\n                    if line.split('\\t')[7] in fault_set and line.split('\\t')[1] == model:\n                        index_fault = np.where(np.array(fault_set) == line.split('\\t')[7])[0][0]\n                        NMS_set[index_fault].append(float(line.split('\\t')[-1]))\n                        sr_sample[index_fault].append(float(lines_sr[line_number].split('\\t')[-1]))\n                    line_number += 1\n                if np.sum(NMS_set) != 0.0:\n                    for i in range(len(p_chi_branch)):\n                        '\\n                      the score is 1 is MSN is less than 20%\\n                      the score is 0 if:\\n                          at least one of the NMS of the test faults if more than 50%\\n                          the mean is more the 40%\\n                      between 20 and 40 the score evolves linearily between 1 and 0\\n                      (this is very much open to discussion!)\\n                      '\n                        if np.mean(NMS_set, axis=0)[i] > 40.0:\n                            score_nms_i = 0.0\n                        elif np.mean(NMS_set, axis=0)[i] < 20.0:\n                            score_nms_i = 1.0\n                        else:\n                            score_nms_i = 2 - 1.0 / 20.0 * np.mean(NMS_set, axis=0)[i]\n                        'hard limit on acceptability'\n                        for nms_row in NMS_set:\n                            if nms_row[i] > 50.0:\n                                score_nms_i = 0.0\n                        score_nms.append(score_nms_i)\n            except FileNotFoundError:\n                print('!!! you need to run the plot_sr_use if you want the NMS metric !!!')\n                print('Default value = 1. ')\n                for i in range(len(p_chi_branch)):\n                    score_nms.append(1.0)\n        else:\n            print('modify Sampling_analysis.py for the NMS metric')\n            print('Default value = 1. ')\n            for i in range(len(p_chi_branch)):\n                score_nms.append(1.0)\n        mean_sr_branch = np.mean(sr_sample, axis=0)\n        '#############################\\n        Weight based on the fit to the paleo rates\\n        \\n        and the RSQSim rates if they exist\\n        #######################################'\n        plot_paleo = False\n        plot_rsqsim_pr = True\n        faults_data = np.genfromtxt(file_faults_data, dtype=[('model', 'U100000'), ('fault_name', 'U100000'), ('type', 'U100000'), ('M', 'f8'), ('sig_M', 'f8'), ('rate', 'f8'), ('sig_rate', 'f8')], delimiter='\\t', skip_header=1)\n        try:\n            len_faults_data = len(faults_data)\n        except TypeError:\n            faults_data = faults_data.reshape((1,))\n        rsqsim_pr = False\n        RSQSim_pr_file = str(Run_name) + '/file_pr_rsqsim.txt'\n        try:\n            with open(RSQSim_pr_file) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            rqsim_pr_faults = []\n            faults_name_rsqsim = []\n            for line in lines[1:]:\n                faults_name_rsqsim.append(line.split('\\t')[0])\n                rqsim_pr_faults.append([float(i) for i in line.split('\\t')[1:-1]])\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n        except:\n            rsqsim_pr = False\n        data_model = list(map(lambda i: faults_data[i][0], range(len(faults_data))))\n        data_fault_name = list(map(lambda i: faults_data[i][1], range(len(faults_data))))\n        data_type = list(map(lambda i: faults_data[i][2], range(len(faults_data))))\n        data_M = list(map(lambda i: float(faults_data[i][3]), range(len(faults_data))))\n        data_sig_M = list(map(lambda i: float(faults_data[i][4]), range(len(faults_data))))\n        data_rate = list(map(lambda i: float(faults_data[i][5]), range(len(faults_data))))\n        data_sig_rate = list(map(lambda i: float(faults_data[i][6]), range(len(faults_data))))\n        score_paleo = []\n        score_paleo_faults = []\n        faults_data = []\n        score_pr_rsqsim = []\n        faults_rsqsim = []\n        for (fault, data_model_i) in zip(data_fault_name, data_model):\n            if data_model_i == model and fault not in faults_data:\n                score_paleo_faults.append([])\n                faults_data.append(fault)\n                if rsqsim_pr == True:\n                    if fault in faults_name_rsqsim and fault not in faults_rsqsim:\n                        score_pr_rsqsim.append([])\n                        faults_rsqsim.append(fault)\n        participation_rate_file = str(Run_name) + '/analysis/figures/rupture_rate_for_each_fault_cum/' + model + '/file_for_comparison.txt'\n        with open(participation_rate_file) as f:\n            lines_pr = f.readlines()\n        paleo_list_mfd = []\n        paleo_list_bvalue = []\n        paleo_list_bg = []\n        paleo_list_scl = []\n        paleo_list_scenario = []\n        paleo_list_sample = []\n        index_branch = 0\n        for line in lines_pr:\n            index_fault = 0\n            for fault_name in faults_data:\n                if line.split('\\t')[0] == model and line.split('\\t')[7] == fault_name:\n                    if index_fault == 0:\n                        paleo_list_mfd.append(line.split('\\t')[1])\n                        paleo_list_scenario.append(line.split('\\t')[2])\n                        paleo_list_bg.append(line.split('\\t')[3])\n                        paleo_list_scl.append(line.split('\\t')[4])\n                        paleo_list_bvalue.append(line.split('\\t')[5])\n                        paleo_list_sample.append(line.split('\\t')[6])\n                    mfd_i = [float(i) for i in list(line.split('\\t')[8 + index_Mmin:8 + index_Mmax])]\n                    self_data_M = []\n                    self_data_sig_M = []\n                    self_data_rate = []\n                    self_data_sig_rate = []\n                    index_fault_in_data = np.where(np.array(data_fault_name) == fault_name)[0]\n                    for index_i in index_fault_in_data:\n                        if data_model[index_i] == model and data_type[index_i] == 'pal':\n                            self_data_M.append(data_M[index_i])\n                            self_data_sig_M.append(data_sig_M[index_i])\n                            self_data_rate.append(data_rate[index_i])\n                            self_data_sig_rate.append(data_sig_rate[index_i])\n                    paleo_score_i = []\n                    for (m_i, sm_i, r_i, sr_i) in zip(self_data_M, self_data_sig_M, self_data_rate, self_data_sig_rate):\n                        (x, y) = np.mgrid[4.5:7.5:0.01, -5.0:0.0:0.01]\n                        pos = np.empty(x.shape + (2,))\n                        pos[:, :, 0] = x\n                        pos[:, :, 1] = y\n                        rv = multivariate_normal([m_i, np.log10(r_i)], [sm_i + 0.001, sr_i + 1e-07])\n                        detailed_bin_mag = np.linspace(bining_in_mag[0], bining_in_mag[-1], 1000)\n                        detailed_mfd_i = np.interp(detailed_bin_mag, bining_in_mag, np.log10(mfd_i))\n                        if plot_paleo == True:\n                            plt.contourf(x, y, rv.pdf(pos), alpha=0.5)\n                            plt.scatter(bining_in_mag, np.log10(mfd_i), c='k', marker='s', s=10, linewidths=0.01, alpha=0.7)\n                            plt.scatter(detailed_bin_mag, detailed_mfd_i, c='k', marker='s', s=3, linewidths=0.01, alpha=0.7)\n                            plt.xlim([5.0, 7.0])\n                            plt.ylim([-3, -1.0])\n                            plt.grid()\n                            plt.show()\n                        paleo_score_i.append(max([rv.pdf([i, j]) / rv.pdf([m_i, np.log10(r_i)]) for (i, j) in zip(detailed_bin_mag, detailed_mfd_i)]))\n                    score_paleo_faults[index_fault].append(np.mean(paleo_score_i))\n                    if rsqsim_pr == True and line.split('\\t')[6] == '1':\n                        pvalues = []\n                        pshape = []\n                        if fault_name in faults_rsqsim:\n                            index_fault_rsqsim = np.where(np.array(faults_name_rsqsim) == fault_name)[0][0]\n                            fault_pr_rsqsim = rqsim_pr_faults[index_fault_rsqsim]\n                            if plot_rsqsim_pr == True:\n                                (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bin_mag_rsqsim[:-2], fault_pr_rsqsim[:-2], c='k', alpha=0.9, s=3)\n                                ax1.scatter(bin_mag_rsqsim[-2:], fault_pr_rsqsim[-2:], c='k', alpha=0.5, s=3)\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], fault_pr_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pvalues.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='b', alpha=0.8, s=2)\n                                index_range += 1\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], c='r', s=0.5)\n                                ax1.scatter(bining_in_mag[-2:], mfd_i[-2:], c='r', alpha=0.4, s=0.5)\n                                ax1.set_yscale('log')\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax1.set_ylim([ymin, ymax / 100.0])\n                            p_total = np.mean(diff_rate)\n                            n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                            n_mfd_rsqsim = [i / sum(fault_pr_rsqsim[:-2]) for i in fault_pr_rsqsim[:-2]]\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pshape.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=2)\n                            if plot_rsqsim_pr == True:\n                                if round(p_total, 3) >= 1.3:\n                                    color = 'r'\n                                elif round(p_total, 3) >= 1.2:\n                                    color = 'orange'\n                                else:\n                                    color = 'g'\n                                if round(np.mean(diff_rate), 3) >= 1.3:\n                                    color_shape = 'r'\n                                elif round(np.mean(diff_rate), 3) >= 1.2:\n                                    color_shape = 'orange'\n                                else:\n                                    color_shape = 'g'\n                                ax1.set_title(model + ' ' + fault_name + ' ' + str(round(p_total, 2)), color=color)\n                                ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_ylim([0.9, 3.0])\n                                plt.show()\n                                plt.close()\n                index_fault += 1\n        score_paleo = np.mean(score_paleo_faults, axis=0)\n        '###################\"\"\\n        Compare with some other MFD at the system level (physics based for example)\\n        #####################\"'\n        plot_fig_rsqsim = False\n        RSQSim_MFD = str(Run_name) + '/mfd_RSQSim.txt'\n        try:\n            with open(RSQSim_MFD) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            mfd_rsqsim = [float(i) for i in lines[1].split('\\t')[1:-1]]\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n            index_branch = 0\n            for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n                if model_name_i == model:\n                    if plot_fig_rsqsim == True:\n                        (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bin_mag_rsqsim, mfd_rsqsim, c='k', alpha=0.9, s=3)\n                    pvalues = []\n                    diff_rate = []\n                    bining_i = []\n                    mfd_i = mfd[index_Mmin:index_Mmax]\n                    for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pvalues.append(np.mean(diff_rate))\n                    p_total = np.mean(diff_rate)\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='r', alpha=0.9, s=3)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim], c='r', s=0.5)\n                    n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                    n_mfd_rsqsim = [i / sum(mfd_rsqsim[:-2]) for i in mfd_rsqsim[:-2]]\n                    diff_rate = []\n                    bining_i = []\n                    for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pshape.append(np.mean(diff_rate))\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=3)\n                    if plot_fig_rsqsim == True:\n                        if round(p_total, 3) >= 1.3:\n                            color = 'r'\n                        elif round(p_total, 3) >= 1.2:\n                            color = 'orange'\n                        else:\n                            color = 'g'\n                        if round(np.mean(diff_rate), 3) >= 1.4:\n                            color_shape = 'r'\n                        elif round(np.mean(diff_rate), 3) >= 1.3:\n                            color_shape = 'orange'\n                        else:\n                            color_shape = 'g'\n                        ax1.set_title(model + ' ' + str(round(p_total, 2)), color=color)\n                        ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                        ax1.set_ylim([ymin / 10.0, ymax])\n                        ax1.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_ylim([0.9, 3.0])\n                        ax1.set_yscale('log')\n                        plt.show()\n                        plt.close()\n                index_branch += 1\n        except:\n            pass\n        '\\n        Setting the weight for each score\\n        '\n        weight_chi = 0.35\n        weight_Mmax = 0.05\n        weight_NMS_faults_test = 0.3\n        weight_paleo = 0.3\n        if len(score_nms) == 0.0:\n            print('!!! no selected faults for the NMS metric !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_NMS_faults_test = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_paleo = weight_paleo / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_nms.append(0.0)\n        if len(score_paleo) == 0.0:\n            print('!!! no paleo data on the faults !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_paleo = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_NMS_faults_test = weight_NMS_faults_test / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_paleo.append(0.0)\n        ' \\n        Builbing the text file\\n        '\n        lt_branch = []\n        lt_i_before = 'truc'\n        srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n        try:\n            with open(srep_file) as f:\n                lines = f.readlines()\n            ordered_score_paleo = []\n            i_lt = 0\n            for line in lines:\n                if line.split('\\t')[1] == model:\n                    lt_i = []\n                    for i in range(7):\n                        lt_i.append(line.split('\\t')[i])\n                    if str(lt_i) != lt_i_before:\n                        lt_i_before = str(lt_i)\n                        lt_i.append(round(mean_sr_branch[i_lt], 3))\n                        lt_i.append(round(p_chi_branch[i_lt], 3))\n                        lt_i.append(round(weight_model_Mmax[i_lt], 3))\n                        lt_i.append(round(score_nms[i_lt], 3))\n                        i1 = np.where(np.array(paleo_list_mfd) == line.split('\\t')[4][4:])[0]\n                        i2 = np.where(np.array(paleo_list_scenario) == line.split('\\t')[5])[0]\n                        i3 = np.where(np.array(paleo_list_sample) == line.split('\\t')[6].split('_')[1])[0]\n                        i4 = np.where(np.array(paleo_list_bvalue) == line.split('\\t')[3])[0]\n                        i5 = np.where(np.array(paleo_list_bg) == line.split('\\t')[2][3:])[0]\n                        i6 = np.where(np.array(paleo_list_scl) == line.split('\\t')[0])[0]\n                        i1 = np.intersect1d(i1, i2)\n                        i1 = np.intersect1d(i1, i3)\n                        i1 = np.intersect1d(i1, i4)\n                        i1 = np.intersect1d(i1, i5)\n                        i1 = np.intersect1d(i1, i6)\n                        lt_i.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        ordered_score_paleo.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        lt_branch.append(lt_i)\n                        i_lt += 1\n            for lt_i in lt_branch:\n                line = ''\n                for i in lt_i:\n                    line += str(i) + '\\t'\n                line = line[:-1]\n                file_LT_metrics.write(line + '\\n')\n        except (FileNotFoundError, IndexError) as e:\n            print('!!! you need to run the plot_sr_use if you want the file with the metrics  and modify Sampling_analysis.py!!!')\n        '\\n        Calculataing the weighted score for each branch\\n        '\n        if ordered_score_paleo == []:\n            ordered_score_paleo = [0 for i in range(len(p_chi_branch))]\n        final_weigth = []\n        for i in range(len(p_chi_branch)):\n            final_weigth.append(p_chi_branch[i] * weight_chi + weight_model_Mmax[i] * weight_Mmax + score_nms[i] * weight_NMS_faults_test + ordered_score_paleo[i] * weight_paleo)\n        '\\n        Plotting section\\n        \\n        Weighted average of the different metric\\n        \\n        user defined weight for each metric. the figure give the weighted average as a final p value\\n        '\n        color_mfd = []\n        for (MFD_type_i, model_name_i) in zip(total_list_MFD_type, total_list_model):\n            if model_name_i == model:\n                if MFD_type_i == 'GR':\n                    color_mfd.append('darkblue')\n                else:\n                    color_mfd.append('darkgreen')\n        (f, (ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, sharey=True)\n        ax1.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax1.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax1.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax2.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax2.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax2.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax3.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax3.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax3.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax4.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax4.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax4.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax5.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax5.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax5.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax1.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax1.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            if total_list_scenario_name[j] == total_list_scenario_name[0]:\n                if weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                else:\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n            elif weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n            else:\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n        ax1.set_xlabel('Mmax')\n        ax1.set_ylabel('test value   ' + str(model))\n        ax1.set_ylim([-0.05, 1.05])\n        ax1.set_xlim([xmax - 1.5, xmax])\n        ax2.set_xlim([xmax - 1.5, xmax])\n        ax3.set_xlim([xmax - 1.5, xmax])\n        ax4.set_xlim([xmax - 1.5, xmax])\n        ax5.set_xlim([xmax - 1.5, xmax])\n        ax1.set_title('chi test')\n        ax2.set_title('Mmax test')\n        ax3.set_title('NMS test')\n        ax4.set_title('Paleo test')\n        ax5.set_title('weitghted total')\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/model_performance.png', dpi=180)\n        plt.close()\n        index_model += 1\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            file.write(str(model) + '\\t' + str(total_list_MFD_type[j]) + '\\t' + str(total_list_BG_hyp[j]) + '\\t' + str(total_list_scenario_name[j]) + '\\t' + str(total_list_sample[j]) + '\\t' + str(round(p_chi_branch[i], 2)) + '\\t' + str(round(ordered_score_paleo[i], 2)) + '\\t' + str(round(score_nms[i], 2)) + '\\n')\n    file.close()\n    file_LT_metrics.close()",
            "def sampling_analysis(Run_name, Model_list, m_Mmax, b_sample, a_s_model, mega_mfd_cummulative, catalog_cum_rate, xmin, xmax, ymin, ymax, total_list_model, bining_in_mag, total_list_MFD_type, total_list_scenario_name, file_faults_data, total_list_sample, total_list_BG_hyp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis'):\n        os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis')\n    file_LT_metrics = open(str(Run_name) + '/analysis/txt_files/LT_metrics.txt', 'w')\n    file_LT_metrics.write('ScL\\tModel\\tBG\\tbvalue\\tMFD\\tSc\\tsample\\tmean_sr\\tchi_score\\tMmax_score\\tNMS_score\\tpaleo_score\\n')\n    \"\\n    #read the catalog cumulative rates for all sampling \\n        and compare each branch to the catalog using the chi-squared test\\n    \\n    methodology:\\n        for each branch i of the logic tree\\n        30 random MFD calculated from the catalog are extracted for the comaprison\\n        the modeled rate of the branch i are compared the each on of these random samples\\n        the comparison is done using the following formula:\\n        we calculate the absolute value of the difference between the logs of the model minus the log of catalog rate\\n        we had 10 to this asolute value to make it accepatble or the chi-squarred test\\n        we run the chisquared test for an array of ten value corresponding to one unit of magnitude (ten bins of 0.1)\\n        bins of magnitude where one of the two rates are not defined are deleted\\n        the value are conpared to an array of value equal ten (the expected value is the model fits the data)\\n        we save the pvalue calculated \\n        \\n        In order to get the p value for the whole MFD, we do the mean of the pvalue for each unit of magnitude \\n        weighted by the number of filled bins in the range of magnitude.\\n        \\n        If the p value is close to 1, the two MFD are similar. \\n        \\n        personal opinion: \\n        p values superior to 0.9 seam like a good match\\n        p values superior to 0.8 seam like an acceptable match in most cases\\n        p values less than 0.7 make the match difficult to accept\\n        \\n        Warning! this method doesn't care if the two maximum magnitude are different,\\n        it will only take the bin where both MFDs are defined. \\n        The fit in terms of Mmax need to rely on some other test. (hopefully I managed to provide one...)\\n        \\n    \"\n    plot_fig = False\n    index_Mmin = np.where(np.array(np.linspace(4.0, 7.0, num=31).round(1)) == xmin)[0][0]\n    index_Mmax = np.where(np.array(np.linspace(4.0, 10.0, num=61).round(1)) == xmax)[0][0] + 1\n    file = open(str(Run_name) + '/analysis/txt_files/model_performance.txt', 'w')\n    file.write('Model\\tMFD type\\tBG\\tScenario Set\\tsample\\tFit to catalog\\tFit to Paleo\\tNMS score\\n')\n    index_model = 0\n    for model in Model_list:\n        if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis/' + model):\n            os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis/' + model)\n        catfile_all = str(Run_name) + '/analysis/figures/catalogue/catalog_rates_all_' + model + '.txt'\n        with open(catfile_all) as f:\n            lines_cat = f.readlines()\n        ranges_mag = [[4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], [5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9], [6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9], [7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9], [8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9], [9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]]\n        p_chi_branch = []\n        indexes_model = []\n        index_branch = 0\n        for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n            if model_name_i == model:\n                indexes_model.append(index_branch)\n                indexes_catalogs_to_test = np.random.choice(range(len(lines_cat))[1:], size=40)\n                pvalues = [[], [], [], [], [], []]\n                weights_pvalues = [[], [], [], [], [], []]\n                if plot_fig == True:\n                    (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                for i_cat in indexes_catalogs_to_test:\n                    cat_rates_i = lines_cat[i_cat].split('\\t')\n                    cat_rates_i = [float(i) for i in cat_rates_i]\n                    if plot_fig == True:\n                        ax1.scatter(bining_in_mag, cat_rates_i, c='k', alpha=0.1, s=0.5)\n                    index_range = 0\n                    for range_i in ranges_mag:\n                        diff_rate = []\n                        target_value = []\n                        bining_i = []\n                        for (model_rate_i, data_rate_i, mag_i) in zip(mfd[index_Mmin:index_Mmax], cat_rates_i, bining_in_mag):\n                            if model_rate_i != 0 and data_rate_i != 0 and (mag_i in range_i):\n                                diff_rate.append(abs(np.log10(model_rate_i) - np.log10(data_rate_i)) * 10.0 + 10.0)\n                                target_value.append(10.0)\n                                bining_i.append(mag_i)\n                        if len(diff_rate) >= 2:\n                            pvalues[index_range].append(chisquare(diff_rate, f_exp=target_value)[1])\n                            weights_pvalues[index_range].append(len(diff_rate))\n                            if plot_fig == True:\n                                ax2.scatter(bining_i, diff_rate, c='r', alpha=0.2, s=2)\n                                ax2.scatter(bining_i, target_value, c='k', alpha=0.1, s=2)\n                        index_range += 1\n                if plot_fig == True:\n                    ax1.scatter(bining_in_mag, mfd[index_Mmin:index_Mmax], c='r', s=0.5)\n                    ax1.set_yscale('log')\n                    ax1.set_xlim([xmin, xmax])\n                    ax1.set_ylim([ymin, ymax])\n                p_total = []\n                weight_p = []\n                for (range_i, p_i, w_i) in zip(ranges_mag, pvalues, weights_pvalues):\n                    if len(p_i) != 0:\n                        weight_p.append(np.mean(w_i))\n                        p_total.append(round(np.mean(p_i), 4))\n                        if plot_fig == True:\n                            if round(np.mean(p_i), 3) >= 0.9:\n                                color = 'g'\n                            elif round(np.mean(p_i), 3) >= 0.8:\n                                color = 'orange'\n                            else:\n                                color = 'r'\n                            ax2.text(np.mean(range_i), 25, str(round(np.mean(p_i), 3)), fontsize=8, color=color)\n                p_chi_branch.append(round(np.average(p_total, weights=weight_p), 3))\n                if plot_fig == True:\n                    if round(np.average(p_total, weights=weight_p), 3) >= 0.9:\n                        color = 'g'\n                    elif round(np.average(p_total, weights=weight_p), 3) >= 0.8:\n                        color = 'orange'\n                    else:\n                        color = 'r'\n                    ax1.set_title(str(round(np.average(p_total, weights=weight_p), 3)), color=color)\n                    ax2.set_xlim([xmin - 0.1, xmax])\n                    ax2.set_ylim([9, 30])\n                    plt.show()\n                    plt.close()\n            index_branch += 1\n        '\\n        #   Mmax fit to the Mmax in the catalog\\n        \\n        The rule is: The Mmax in the model should be at least the one in the catalog \\n        but the catalog has some uncertainties on the magnitude of large historical EQs\\n        \\n        methodology:\\n            we calculate the cumulative density distribution of the Mmax in the catalog\\n            we associate the given density to each Mmax of the models\\n        \\n        '\n        Mmax_cat = []\n        bining_cat = lines_cat[0].split('\\t')\n        bining_cat = [float(i) for i in bining_cat]\n        for i_cat in range(len(lines_cat) - 1):\n            cat_rates_i = lines_cat[i_cat + 1].split('\\t')\n            cat_rates_i = [float(i) for i in cat_rates_i]\n            i_test = 0\n            try:\n                while cat_rates_i[i_test] != 0:\n                    i_test += 1\n            except:\n                i_test = len(cat_rates_i) - 1\n            Mmax_cat.append(bining_cat[i_test])\n        distribution_Mmax_cat = []\n        for mag_i in bining_cat:\n            d_i = sum((i <= mag_i + 0.1 for i in Mmax_cat)) / len(Mmax_cat)\n            distribution_Mmax_cat.append(d_i)\n        plt.plot(bining_cat, distribution_Mmax_cat)\n        plt.xlim([xmax - 1.5, xmax])\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/Mmax_distrib_in_the_cat.png', dpi=180)\n        plt.close()\n        weight_model_Mmax = []\n        for (Mmax_i, model_name_i) in zip(m_Mmax, total_list_model):\n            if model_name_i == model:\n                index = np.where(np.array(bining_cat) == Mmax_i)[0][0]\n                weight_model_Mmax.append(distribution_Mmax_cat[index])\n        '\\n        The NMS on a set of faults as a metric for judging the quality of a model\\n        '\n        fault_set = ['F1', 'F2', 'F3']\n        NMS_set = []\n        for fault in fault_set:\n            NMS_set.append([])\n        if len(NMS_set) != 0:\n            sr_sample = []\n            for fault in fault_set:\n                sr_sample.append([])\n            score_nms = []\n            srate_sample_file = str(Run_name) + '/analysis/txt_files/slip_rate_sampling.txt'\n            with open(srate_sample_file) as f:\n                lines_sr = f.readlines()\n            srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n            try:\n                with open(srep_file) as f:\n                    lines = f.readlines()\n                line_number = 0\n                for line in lines:\n                    if line.split('\\t')[7] in fault_set and line.split('\\t')[1] == model:\n                        index_fault = np.where(np.array(fault_set) == line.split('\\t')[7])[0][0]\n                        NMS_set[index_fault].append(float(line.split('\\t')[-1]))\n                        sr_sample[index_fault].append(float(lines_sr[line_number].split('\\t')[-1]))\n                    line_number += 1\n                if np.sum(NMS_set) != 0.0:\n                    for i in range(len(p_chi_branch)):\n                        '\\n                      the score is 1 is MSN is less than 20%\\n                      the score is 0 if:\\n                          at least one of the NMS of the test faults if more than 50%\\n                          the mean is more the 40%\\n                      between 20 and 40 the score evolves linearily between 1 and 0\\n                      (this is very much open to discussion!)\\n                      '\n                        if np.mean(NMS_set, axis=0)[i] > 40.0:\n                            score_nms_i = 0.0\n                        elif np.mean(NMS_set, axis=0)[i] < 20.0:\n                            score_nms_i = 1.0\n                        else:\n                            score_nms_i = 2 - 1.0 / 20.0 * np.mean(NMS_set, axis=0)[i]\n                        'hard limit on acceptability'\n                        for nms_row in NMS_set:\n                            if nms_row[i] > 50.0:\n                                score_nms_i = 0.0\n                        score_nms.append(score_nms_i)\n            except FileNotFoundError:\n                print('!!! you need to run the plot_sr_use if you want the NMS metric !!!')\n                print('Default value = 1. ')\n                for i in range(len(p_chi_branch)):\n                    score_nms.append(1.0)\n        else:\n            print('modify Sampling_analysis.py for the NMS metric')\n            print('Default value = 1. ')\n            for i in range(len(p_chi_branch)):\n                score_nms.append(1.0)\n        mean_sr_branch = np.mean(sr_sample, axis=0)\n        '#############################\\n        Weight based on the fit to the paleo rates\\n        \\n        and the RSQSim rates if they exist\\n        #######################################'\n        plot_paleo = False\n        plot_rsqsim_pr = True\n        faults_data = np.genfromtxt(file_faults_data, dtype=[('model', 'U100000'), ('fault_name', 'U100000'), ('type', 'U100000'), ('M', 'f8'), ('sig_M', 'f8'), ('rate', 'f8'), ('sig_rate', 'f8')], delimiter='\\t', skip_header=1)\n        try:\n            len_faults_data = len(faults_data)\n        except TypeError:\n            faults_data = faults_data.reshape((1,))\n        rsqsim_pr = False\n        RSQSim_pr_file = str(Run_name) + '/file_pr_rsqsim.txt'\n        try:\n            with open(RSQSim_pr_file) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            rqsim_pr_faults = []\n            faults_name_rsqsim = []\n            for line in lines[1:]:\n                faults_name_rsqsim.append(line.split('\\t')[0])\n                rqsim_pr_faults.append([float(i) for i in line.split('\\t')[1:-1]])\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n        except:\n            rsqsim_pr = False\n        data_model = list(map(lambda i: faults_data[i][0], range(len(faults_data))))\n        data_fault_name = list(map(lambda i: faults_data[i][1], range(len(faults_data))))\n        data_type = list(map(lambda i: faults_data[i][2], range(len(faults_data))))\n        data_M = list(map(lambda i: float(faults_data[i][3]), range(len(faults_data))))\n        data_sig_M = list(map(lambda i: float(faults_data[i][4]), range(len(faults_data))))\n        data_rate = list(map(lambda i: float(faults_data[i][5]), range(len(faults_data))))\n        data_sig_rate = list(map(lambda i: float(faults_data[i][6]), range(len(faults_data))))\n        score_paleo = []\n        score_paleo_faults = []\n        faults_data = []\n        score_pr_rsqsim = []\n        faults_rsqsim = []\n        for (fault, data_model_i) in zip(data_fault_name, data_model):\n            if data_model_i == model and fault not in faults_data:\n                score_paleo_faults.append([])\n                faults_data.append(fault)\n                if rsqsim_pr == True:\n                    if fault in faults_name_rsqsim and fault not in faults_rsqsim:\n                        score_pr_rsqsim.append([])\n                        faults_rsqsim.append(fault)\n        participation_rate_file = str(Run_name) + '/analysis/figures/rupture_rate_for_each_fault_cum/' + model + '/file_for_comparison.txt'\n        with open(participation_rate_file) as f:\n            lines_pr = f.readlines()\n        paleo_list_mfd = []\n        paleo_list_bvalue = []\n        paleo_list_bg = []\n        paleo_list_scl = []\n        paleo_list_scenario = []\n        paleo_list_sample = []\n        index_branch = 0\n        for line in lines_pr:\n            index_fault = 0\n            for fault_name in faults_data:\n                if line.split('\\t')[0] == model and line.split('\\t')[7] == fault_name:\n                    if index_fault == 0:\n                        paleo_list_mfd.append(line.split('\\t')[1])\n                        paleo_list_scenario.append(line.split('\\t')[2])\n                        paleo_list_bg.append(line.split('\\t')[3])\n                        paleo_list_scl.append(line.split('\\t')[4])\n                        paleo_list_bvalue.append(line.split('\\t')[5])\n                        paleo_list_sample.append(line.split('\\t')[6])\n                    mfd_i = [float(i) for i in list(line.split('\\t')[8 + index_Mmin:8 + index_Mmax])]\n                    self_data_M = []\n                    self_data_sig_M = []\n                    self_data_rate = []\n                    self_data_sig_rate = []\n                    index_fault_in_data = np.where(np.array(data_fault_name) == fault_name)[0]\n                    for index_i in index_fault_in_data:\n                        if data_model[index_i] == model and data_type[index_i] == 'pal':\n                            self_data_M.append(data_M[index_i])\n                            self_data_sig_M.append(data_sig_M[index_i])\n                            self_data_rate.append(data_rate[index_i])\n                            self_data_sig_rate.append(data_sig_rate[index_i])\n                    paleo_score_i = []\n                    for (m_i, sm_i, r_i, sr_i) in zip(self_data_M, self_data_sig_M, self_data_rate, self_data_sig_rate):\n                        (x, y) = np.mgrid[4.5:7.5:0.01, -5.0:0.0:0.01]\n                        pos = np.empty(x.shape + (2,))\n                        pos[:, :, 0] = x\n                        pos[:, :, 1] = y\n                        rv = multivariate_normal([m_i, np.log10(r_i)], [sm_i + 0.001, sr_i + 1e-07])\n                        detailed_bin_mag = np.linspace(bining_in_mag[0], bining_in_mag[-1], 1000)\n                        detailed_mfd_i = np.interp(detailed_bin_mag, bining_in_mag, np.log10(mfd_i))\n                        if plot_paleo == True:\n                            plt.contourf(x, y, rv.pdf(pos), alpha=0.5)\n                            plt.scatter(bining_in_mag, np.log10(mfd_i), c='k', marker='s', s=10, linewidths=0.01, alpha=0.7)\n                            plt.scatter(detailed_bin_mag, detailed_mfd_i, c='k', marker='s', s=3, linewidths=0.01, alpha=0.7)\n                            plt.xlim([5.0, 7.0])\n                            plt.ylim([-3, -1.0])\n                            plt.grid()\n                            plt.show()\n                        paleo_score_i.append(max([rv.pdf([i, j]) / rv.pdf([m_i, np.log10(r_i)]) for (i, j) in zip(detailed_bin_mag, detailed_mfd_i)]))\n                    score_paleo_faults[index_fault].append(np.mean(paleo_score_i))\n                    if rsqsim_pr == True and line.split('\\t')[6] == '1':\n                        pvalues = []\n                        pshape = []\n                        if fault_name in faults_rsqsim:\n                            index_fault_rsqsim = np.where(np.array(faults_name_rsqsim) == fault_name)[0][0]\n                            fault_pr_rsqsim = rqsim_pr_faults[index_fault_rsqsim]\n                            if plot_rsqsim_pr == True:\n                                (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bin_mag_rsqsim[:-2], fault_pr_rsqsim[:-2], c='k', alpha=0.9, s=3)\n                                ax1.scatter(bin_mag_rsqsim[-2:], fault_pr_rsqsim[-2:], c='k', alpha=0.5, s=3)\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], fault_pr_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pvalues.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='b', alpha=0.8, s=2)\n                                index_range += 1\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], c='r', s=0.5)\n                                ax1.scatter(bining_in_mag[-2:], mfd_i[-2:], c='r', alpha=0.4, s=0.5)\n                                ax1.set_yscale('log')\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax1.set_ylim([ymin, ymax / 100.0])\n                            p_total = np.mean(diff_rate)\n                            n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                            n_mfd_rsqsim = [i / sum(fault_pr_rsqsim[:-2]) for i in fault_pr_rsqsim[:-2]]\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pshape.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=2)\n                            if plot_rsqsim_pr == True:\n                                if round(p_total, 3) >= 1.3:\n                                    color = 'r'\n                                elif round(p_total, 3) >= 1.2:\n                                    color = 'orange'\n                                else:\n                                    color = 'g'\n                                if round(np.mean(diff_rate), 3) >= 1.3:\n                                    color_shape = 'r'\n                                elif round(np.mean(diff_rate), 3) >= 1.2:\n                                    color_shape = 'orange'\n                                else:\n                                    color_shape = 'g'\n                                ax1.set_title(model + ' ' + fault_name + ' ' + str(round(p_total, 2)), color=color)\n                                ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_ylim([0.9, 3.0])\n                                plt.show()\n                                plt.close()\n                index_fault += 1\n        score_paleo = np.mean(score_paleo_faults, axis=0)\n        '###################\"\"\\n        Compare with some other MFD at the system level (physics based for example)\\n        #####################\"'\n        plot_fig_rsqsim = False\n        RSQSim_MFD = str(Run_name) + '/mfd_RSQSim.txt'\n        try:\n            with open(RSQSim_MFD) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            mfd_rsqsim = [float(i) for i in lines[1].split('\\t')[1:-1]]\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n            index_branch = 0\n            for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n                if model_name_i == model:\n                    if plot_fig_rsqsim == True:\n                        (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bin_mag_rsqsim, mfd_rsqsim, c='k', alpha=0.9, s=3)\n                    pvalues = []\n                    diff_rate = []\n                    bining_i = []\n                    mfd_i = mfd[index_Mmin:index_Mmax]\n                    for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pvalues.append(np.mean(diff_rate))\n                    p_total = np.mean(diff_rate)\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='r', alpha=0.9, s=3)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim], c='r', s=0.5)\n                    n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                    n_mfd_rsqsim = [i / sum(mfd_rsqsim[:-2]) for i in mfd_rsqsim[:-2]]\n                    diff_rate = []\n                    bining_i = []\n                    for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pshape.append(np.mean(diff_rate))\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=3)\n                    if plot_fig_rsqsim == True:\n                        if round(p_total, 3) >= 1.3:\n                            color = 'r'\n                        elif round(p_total, 3) >= 1.2:\n                            color = 'orange'\n                        else:\n                            color = 'g'\n                        if round(np.mean(diff_rate), 3) >= 1.4:\n                            color_shape = 'r'\n                        elif round(np.mean(diff_rate), 3) >= 1.3:\n                            color_shape = 'orange'\n                        else:\n                            color_shape = 'g'\n                        ax1.set_title(model + ' ' + str(round(p_total, 2)), color=color)\n                        ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                        ax1.set_ylim([ymin / 10.0, ymax])\n                        ax1.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_ylim([0.9, 3.0])\n                        ax1.set_yscale('log')\n                        plt.show()\n                        plt.close()\n                index_branch += 1\n        except:\n            pass\n        '\\n        Setting the weight for each score\\n        '\n        weight_chi = 0.35\n        weight_Mmax = 0.05\n        weight_NMS_faults_test = 0.3\n        weight_paleo = 0.3\n        if len(score_nms) == 0.0:\n            print('!!! no selected faults for the NMS metric !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_NMS_faults_test = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_paleo = weight_paleo / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_nms.append(0.0)\n        if len(score_paleo) == 0.0:\n            print('!!! no paleo data on the faults !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_paleo = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_NMS_faults_test = weight_NMS_faults_test / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_paleo.append(0.0)\n        ' \\n        Builbing the text file\\n        '\n        lt_branch = []\n        lt_i_before = 'truc'\n        srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n        try:\n            with open(srep_file) as f:\n                lines = f.readlines()\n            ordered_score_paleo = []\n            i_lt = 0\n            for line in lines:\n                if line.split('\\t')[1] == model:\n                    lt_i = []\n                    for i in range(7):\n                        lt_i.append(line.split('\\t')[i])\n                    if str(lt_i) != lt_i_before:\n                        lt_i_before = str(lt_i)\n                        lt_i.append(round(mean_sr_branch[i_lt], 3))\n                        lt_i.append(round(p_chi_branch[i_lt], 3))\n                        lt_i.append(round(weight_model_Mmax[i_lt], 3))\n                        lt_i.append(round(score_nms[i_lt], 3))\n                        i1 = np.where(np.array(paleo_list_mfd) == line.split('\\t')[4][4:])[0]\n                        i2 = np.where(np.array(paleo_list_scenario) == line.split('\\t')[5])[0]\n                        i3 = np.where(np.array(paleo_list_sample) == line.split('\\t')[6].split('_')[1])[0]\n                        i4 = np.where(np.array(paleo_list_bvalue) == line.split('\\t')[3])[0]\n                        i5 = np.where(np.array(paleo_list_bg) == line.split('\\t')[2][3:])[0]\n                        i6 = np.where(np.array(paleo_list_scl) == line.split('\\t')[0])[0]\n                        i1 = np.intersect1d(i1, i2)\n                        i1 = np.intersect1d(i1, i3)\n                        i1 = np.intersect1d(i1, i4)\n                        i1 = np.intersect1d(i1, i5)\n                        i1 = np.intersect1d(i1, i6)\n                        lt_i.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        ordered_score_paleo.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        lt_branch.append(lt_i)\n                        i_lt += 1\n            for lt_i in lt_branch:\n                line = ''\n                for i in lt_i:\n                    line += str(i) + '\\t'\n                line = line[:-1]\n                file_LT_metrics.write(line + '\\n')\n        except (FileNotFoundError, IndexError) as e:\n            print('!!! you need to run the plot_sr_use if you want the file with the metrics  and modify Sampling_analysis.py!!!')\n        '\\n        Calculataing the weighted score for each branch\\n        '\n        if ordered_score_paleo == []:\n            ordered_score_paleo = [0 for i in range(len(p_chi_branch))]\n        final_weigth = []\n        for i in range(len(p_chi_branch)):\n            final_weigth.append(p_chi_branch[i] * weight_chi + weight_model_Mmax[i] * weight_Mmax + score_nms[i] * weight_NMS_faults_test + ordered_score_paleo[i] * weight_paleo)\n        '\\n        Plotting section\\n        \\n        Weighted average of the different metric\\n        \\n        user defined weight for each metric. the figure give the weighted average as a final p value\\n        '\n        color_mfd = []\n        for (MFD_type_i, model_name_i) in zip(total_list_MFD_type, total_list_model):\n            if model_name_i == model:\n                if MFD_type_i == 'GR':\n                    color_mfd.append('darkblue')\n                else:\n                    color_mfd.append('darkgreen')\n        (f, (ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, sharey=True)\n        ax1.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax1.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax1.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax2.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax2.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax2.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax3.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax3.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax3.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax4.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax4.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax4.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax5.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax5.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax5.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax1.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax1.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            if total_list_scenario_name[j] == total_list_scenario_name[0]:\n                if weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                else:\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n            elif weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n            else:\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n        ax1.set_xlabel('Mmax')\n        ax1.set_ylabel('test value   ' + str(model))\n        ax1.set_ylim([-0.05, 1.05])\n        ax1.set_xlim([xmax - 1.5, xmax])\n        ax2.set_xlim([xmax - 1.5, xmax])\n        ax3.set_xlim([xmax - 1.5, xmax])\n        ax4.set_xlim([xmax - 1.5, xmax])\n        ax5.set_xlim([xmax - 1.5, xmax])\n        ax1.set_title('chi test')\n        ax2.set_title('Mmax test')\n        ax3.set_title('NMS test')\n        ax4.set_title('Paleo test')\n        ax5.set_title('weitghted total')\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/model_performance.png', dpi=180)\n        plt.close()\n        index_model += 1\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            file.write(str(model) + '\\t' + str(total_list_MFD_type[j]) + '\\t' + str(total_list_BG_hyp[j]) + '\\t' + str(total_list_scenario_name[j]) + '\\t' + str(total_list_sample[j]) + '\\t' + str(round(p_chi_branch[i], 2)) + '\\t' + str(round(ordered_score_paleo[i], 2)) + '\\t' + str(round(score_nms[i], 2)) + '\\n')\n    file.close()\n    file_LT_metrics.close()",
            "def sampling_analysis(Run_name, Model_list, m_Mmax, b_sample, a_s_model, mega_mfd_cummulative, catalog_cum_rate, xmin, xmax, ymin, ymax, total_list_model, bining_in_mag, total_list_MFD_type, total_list_scenario_name, file_faults_data, total_list_sample, total_list_BG_hyp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis'):\n        os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis')\n    file_LT_metrics = open(str(Run_name) + '/analysis/txt_files/LT_metrics.txt', 'w')\n    file_LT_metrics.write('ScL\\tModel\\tBG\\tbvalue\\tMFD\\tSc\\tsample\\tmean_sr\\tchi_score\\tMmax_score\\tNMS_score\\tpaleo_score\\n')\n    \"\\n    #read the catalog cumulative rates for all sampling \\n        and compare each branch to the catalog using the chi-squared test\\n    \\n    methodology:\\n        for each branch i of the logic tree\\n        30 random MFD calculated from the catalog are extracted for the comaprison\\n        the modeled rate of the branch i are compared the each on of these random samples\\n        the comparison is done using the following formula:\\n        we calculate the absolute value of the difference between the logs of the model minus the log of catalog rate\\n        we had 10 to this asolute value to make it accepatble or the chi-squarred test\\n        we run the chisquared test for an array of ten value corresponding to one unit of magnitude (ten bins of 0.1)\\n        bins of magnitude where one of the two rates are not defined are deleted\\n        the value are conpared to an array of value equal ten (the expected value is the model fits the data)\\n        we save the pvalue calculated \\n        \\n        In order to get the p value for the whole MFD, we do the mean of the pvalue for each unit of magnitude \\n        weighted by the number of filled bins in the range of magnitude.\\n        \\n        If the p value is close to 1, the two MFD are similar. \\n        \\n        personal opinion: \\n        p values superior to 0.9 seam like a good match\\n        p values superior to 0.8 seam like an acceptable match in most cases\\n        p values less than 0.7 make the match difficult to accept\\n        \\n        Warning! this method doesn't care if the two maximum magnitude are different,\\n        it will only take the bin where both MFDs are defined. \\n        The fit in terms of Mmax need to rely on some other test. (hopefully I managed to provide one...)\\n        \\n    \"\n    plot_fig = False\n    index_Mmin = np.where(np.array(np.linspace(4.0, 7.0, num=31).round(1)) == xmin)[0][0]\n    index_Mmax = np.where(np.array(np.linspace(4.0, 10.0, num=61).round(1)) == xmax)[0][0] + 1\n    file = open(str(Run_name) + '/analysis/txt_files/model_performance.txt', 'w')\n    file.write('Model\\tMFD type\\tBG\\tScenario Set\\tsample\\tFit to catalog\\tFit to Paleo\\tNMS score\\n')\n    index_model = 0\n    for model in Model_list:\n        if not os.path.exists(str(Run_name) + '/analysis/figures/sampling_analysis/' + model):\n            os.makedirs(str(Run_name) + '/analysis/figures/sampling_analysis/' + model)\n        catfile_all = str(Run_name) + '/analysis/figures/catalogue/catalog_rates_all_' + model + '.txt'\n        with open(catfile_all) as f:\n            lines_cat = f.readlines()\n        ranges_mag = [[4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], [5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9], [6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9], [7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9], [8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9], [9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]]\n        p_chi_branch = []\n        indexes_model = []\n        index_branch = 0\n        for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n            if model_name_i == model:\n                indexes_model.append(index_branch)\n                indexes_catalogs_to_test = np.random.choice(range(len(lines_cat))[1:], size=40)\n                pvalues = [[], [], [], [], [], []]\n                weights_pvalues = [[], [], [], [], [], []]\n                if plot_fig == True:\n                    (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                for i_cat in indexes_catalogs_to_test:\n                    cat_rates_i = lines_cat[i_cat].split('\\t')\n                    cat_rates_i = [float(i) for i in cat_rates_i]\n                    if plot_fig == True:\n                        ax1.scatter(bining_in_mag, cat_rates_i, c='k', alpha=0.1, s=0.5)\n                    index_range = 0\n                    for range_i in ranges_mag:\n                        diff_rate = []\n                        target_value = []\n                        bining_i = []\n                        for (model_rate_i, data_rate_i, mag_i) in zip(mfd[index_Mmin:index_Mmax], cat_rates_i, bining_in_mag):\n                            if model_rate_i != 0 and data_rate_i != 0 and (mag_i in range_i):\n                                diff_rate.append(abs(np.log10(model_rate_i) - np.log10(data_rate_i)) * 10.0 + 10.0)\n                                target_value.append(10.0)\n                                bining_i.append(mag_i)\n                        if len(diff_rate) >= 2:\n                            pvalues[index_range].append(chisquare(diff_rate, f_exp=target_value)[1])\n                            weights_pvalues[index_range].append(len(diff_rate))\n                            if plot_fig == True:\n                                ax2.scatter(bining_i, diff_rate, c='r', alpha=0.2, s=2)\n                                ax2.scatter(bining_i, target_value, c='k', alpha=0.1, s=2)\n                        index_range += 1\n                if plot_fig == True:\n                    ax1.scatter(bining_in_mag, mfd[index_Mmin:index_Mmax], c='r', s=0.5)\n                    ax1.set_yscale('log')\n                    ax1.set_xlim([xmin, xmax])\n                    ax1.set_ylim([ymin, ymax])\n                p_total = []\n                weight_p = []\n                for (range_i, p_i, w_i) in zip(ranges_mag, pvalues, weights_pvalues):\n                    if len(p_i) != 0:\n                        weight_p.append(np.mean(w_i))\n                        p_total.append(round(np.mean(p_i), 4))\n                        if plot_fig == True:\n                            if round(np.mean(p_i), 3) >= 0.9:\n                                color = 'g'\n                            elif round(np.mean(p_i), 3) >= 0.8:\n                                color = 'orange'\n                            else:\n                                color = 'r'\n                            ax2.text(np.mean(range_i), 25, str(round(np.mean(p_i), 3)), fontsize=8, color=color)\n                p_chi_branch.append(round(np.average(p_total, weights=weight_p), 3))\n                if plot_fig == True:\n                    if round(np.average(p_total, weights=weight_p), 3) >= 0.9:\n                        color = 'g'\n                    elif round(np.average(p_total, weights=weight_p), 3) >= 0.8:\n                        color = 'orange'\n                    else:\n                        color = 'r'\n                    ax1.set_title(str(round(np.average(p_total, weights=weight_p), 3)), color=color)\n                    ax2.set_xlim([xmin - 0.1, xmax])\n                    ax2.set_ylim([9, 30])\n                    plt.show()\n                    plt.close()\n            index_branch += 1\n        '\\n        #   Mmax fit to the Mmax in the catalog\\n        \\n        The rule is: The Mmax in the model should be at least the one in the catalog \\n        but the catalog has some uncertainties on the magnitude of large historical EQs\\n        \\n        methodology:\\n            we calculate the cumulative density distribution of the Mmax in the catalog\\n            we associate the given density to each Mmax of the models\\n        \\n        '\n        Mmax_cat = []\n        bining_cat = lines_cat[0].split('\\t')\n        bining_cat = [float(i) for i in bining_cat]\n        for i_cat in range(len(lines_cat) - 1):\n            cat_rates_i = lines_cat[i_cat + 1].split('\\t')\n            cat_rates_i = [float(i) for i in cat_rates_i]\n            i_test = 0\n            try:\n                while cat_rates_i[i_test] != 0:\n                    i_test += 1\n            except:\n                i_test = len(cat_rates_i) - 1\n            Mmax_cat.append(bining_cat[i_test])\n        distribution_Mmax_cat = []\n        for mag_i in bining_cat:\n            d_i = sum((i <= mag_i + 0.1 for i in Mmax_cat)) / len(Mmax_cat)\n            distribution_Mmax_cat.append(d_i)\n        plt.plot(bining_cat, distribution_Mmax_cat)\n        plt.xlim([xmax - 1.5, xmax])\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/Mmax_distrib_in_the_cat.png', dpi=180)\n        plt.close()\n        weight_model_Mmax = []\n        for (Mmax_i, model_name_i) in zip(m_Mmax, total_list_model):\n            if model_name_i == model:\n                index = np.where(np.array(bining_cat) == Mmax_i)[0][0]\n                weight_model_Mmax.append(distribution_Mmax_cat[index])\n        '\\n        The NMS on a set of faults as a metric for judging the quality of a model\\n        '\n        fault_set = ['F1', 'F2', 'F3']\n        NMS_set = []\n        for fault in fault_set:\n            NMS_set.append([])\n        if len(NMS_set) != 0:\n            sr_sample = []\n            for fault in fault_set:\n                sr_sample.append([])\n            score_nms = []\n            srate_sample_file = str(Run_name) + '/analysis/txt_files/slip_rate_sampling.txt'\n            with open(srate_sample_file) as f:\n                lines_sr = f.readlines()\n            srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n            try:\n                with open(srep_file) as f:\n                    lines = f.readlines()\n                line_number = 0\n                for line in lines:\n                    if line.split('\\t')[7] in fault_set and line.split('\\t')[1] == model:\n                        index_fault = np.where(np.array(fault_set) == line.split('\\t')[7])[0][0]\n                        NMS_set[index_fault].append(float(line.split('\\t')[-1]))\n                        sr_sample[index_fault].append(float(lines_sr[line_number].split('\\t')[-1]))\n                    line_number += 1\n                if np.sum(NMS_set) != 0.0:\n                    for i in range(len(p_chi_branch)):\n                        '\\n                      the score is 1 is MSN is less than 20%\\n                      the score is 0 if:\\n                          at least one of the NMS of the test faults if more than 50%\\n                          the mean is more the 40%\\n                      between 20 and 40 the score evolves linearily between 1 and 0\\n                      (this is very much open to discussion!)\\n                      '\n                        if np.mean(NMS_set, axis=0)[i] > 40.0:\n                            score_nms_i = 0.0\n                        elif np.mean(NMS_set, axis=0)[i] < 20.0:\n                            score_nms_i = 1.0\n                        else:\n                            score_nms_i = 2 - 1.0 / 20.0 * np.mean(NMS_set, axis=0)[i]\n                        'hard limit on acceptability'\n                        for nms_row in NMS_set:\n                            if nms_row[i] > 50.0:\n                                score_nms_i = 0.0\n                        score_nms.append(score_nms_i)\n            except FileNotFoundError:\n                print('!!! you need to run the plot_sr_use if you want the NMS metric !!!')\n                print('Default value = 1. ')\n                for i in range(len(p_chi_branch)):\n                    score_nms.append(1.0)\n        else:\n            print('modify Sampling_analysis.py for the NMS metric')\n            print('Default value = 1. ')\n            for i in range(len(p_chi_branch)):\n                score_nms.append(1.0)\n        mean_sr_branch = np.mean(sr_sample, axis=0)\n        '#############################\\n        Weight based on the fit to the paleo rates\\n        \\n        and the RSQSim rates if they exist\\n        #######################################'\n        plot_paleo = False\n        plot_rsqsim_pr = True\n        faults_data = np.genfromtxt(file_faults_data, dtype=[('model', 'U100000'), ('fault_name', 'U100000'), ('type', 'U100000'), ('M', 'f8'), ('sig_M', 'f8'), ('rate', 'f8'), ('sig_rate', 'f8')], delimiter='\\t', skip_header=1)\n        try:\n            len_faults_data = len(faults_data)\n        except TypeError:\n            faults_data = faults_data.reshape((1,))\n        rsqsim_pr = False\n        RSQSim_pr_file = str(Run_name) + '/file_pr_rsqsim.txt'\n        try:\n            with open(RSQSim_pr_file) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            rqsim_pr_faults = []\n            faults_name_rsqsim = []\n            for line in lines[1:]:\n                faults_name_rsqsim.append(line.split('\\t')[0])\n                rqsim_pr_faults.append([float(i) for i in line.split('\\t')[1:-1]])\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n        except:\n            rsqsim_pr = False\n        data_model = list(map(lambda i: faults_data[i][0], range(len(faults_data))))\n        data_fault_name = list(map(lambda i: faults_data[i][1], range(len(faults_data))))\n        data_type = list(map(lambda i: faults_data[i][2], range(len(faults_data))))\n        data_M = list(map(lambda i: float(faults_data[i][3]), range(len(faults_data))))\n        data_sig_M = list(map(lambda i: float(faults_data[i][4]), range(len(faults_data))))\n        data_rate = list(map(lambda i: float(faults_data[i][5]), range(len(faults_data))))\n        data_sig_rate = list(map(lambda i: float(faults_data[i][6]), range(len(faults_data))))\n        score_paleo = []\n        score_paleo_faults = []\n        faults_data = []\n        score_pr_rsqsim = []\n        faults_rsqsim = []\n        for (fault, data_model_i) in zip(data_fault_name, data_model):\n            if data_model_i == model and fault not in faults_data:\n                score_paleo_faults.append([])\n                faults_data.append(fault)\n                if rsqsim_pr == True:\n                    if fault in faults_name_rsqsim and fault not in faults_rsqsim:\n                        score_pr_rsqsim.append([])\n                        faults_rsqsim.append(fault)\n        participation_rate_file = str(Run_name) + '/analysis/figures/rupture_rate_for_each_fault_cum/' + model + '/file_for_comparison.txt'\n        with open(participation_rate_file) as f:\n            lines_pr = f.readlines()\n        paleo_list_mfd = []\n        paleo_list_bvalue = []\n        paleo_list_bg = []\n        paleo_list_scl = []\n        paleo_list_scenario = []\n        paleo_list_sample = []\n        index_branch = 0\n        for line in lines_pr:\n            index_fault = 0\n            for fault_name in faults_data:\n                if line.split('\\t')[0] == model and line.split('\\t')[7] == fault_name:\n                    if index_fault == 0:\n                        paleo_list_mfd.append(line.split('\\t')[1])\n                        paleo_list_scenario.append(line.split('\\t')[2])\n                        paleo_list_bg.append(line.split('\\t')[3])\n                        paleo_list_scl.append(line.split('\\t')[4])\n                        paleo_list_bvalue.append(line.split('\\t')[5])\n                        paleo_list_sample.append(line.split('\\t')[6])\n                    mfd_i = [float(i) for i in list(line.split('\\t')[8 + index_Mmin:8 + index_Mmax])]\n                    self_data_M = []\n                    self_data_sig_M = []\n                    self_data_rate = []\n                    self_data_sig_rate = []\n                    index_fault_in_data = np.where(np.array(data_fault_name) == fault_name)[0]\n                    for index_i in index_fault_in_data:\n                        if data_model[index_i] == model and data_type[index_i] == 'pal':\n                            self_data_M.append(data_M[index_i])\n                            self_data_sig_M.append(data_sig_M[index_i])\n                            self_data_rate.append(data_rate[index_i])\n                            self_data_sig_rate.append(data_sig_rate[index_i])\n                    paleo_score_i = []\n                    for (m_i, sm_i, r_i, sr_i) in zip(self_data_M, self_data_sig_M, self_data_rate, self_data_sig_rate):\n                        (x, y) = np.mgrid[4.5:7.5:0.01, -5.0:0.0:0.01]\n                        pos = np.empty(x.shape + (2,))\n                        pos[:, :, 0] = x\n                        pos[:, :, 1] = y\n                        rv = multivariate_normal([m_i, np.log10(r_i)], [sm_i + 0.001, sr_i + 1e-07])\n                        detailed_bin_mag = np.linspace(bining_in_mag[0], bining_in_mag[-1], 1000)\n                        detailed_mfd_i = np.interp(detailed_bin_mag, bining_in_mag, np.log10(mfd_i))\n                        if plot_paleo == True:\n                            plt.contourf(x, y, rv.pdf(pos), alpha=0.5)\n                            plt.scatter(bining_in_mag, np.log10(mfd_i), c='k', marker='s', s=10, linewidths=0.01, alpha=0.7)\n                            plt.scatter(detailed_bin_mag, detailed_mfd_i, c='k', marker='s', s=3, linewidths=0.01, alpha=0.7)\n                            plt.xlim([5.0, 7.0])\n                            plt.ylim([-3, -1.0])\n                            plt.grid()\n                            plt.show()\n                        paleo_score_i.append(max([rv.pdf([i, j]) / rv.pdf([m_i, np.log10(r_i)]) for (i, j) in zip(detailed_bin_mag, detailed_mfd_i)]))\n                    score_paleo_faults[index_fault].append(np.mean(paleo_score_i))\n                    if rsqsim_pr == True and line.split('\\t')[6] == '1':\n                        pvalues = []\n                        pshape = []\n                        if fault_name in faults_rsqsim:\n                            index_fault_rsqsim = np.where(np.array(faults_name_rsqsim) == fault_name)[0][0]\n                            fault_pr_rsqsim = rqsim_pr_faults[index_fault_rsqsim]\n                            if plot_rsqsim_pr == True:\n                                (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bin_mag_rsqsim[:-2], fault_pr_rsqsim[:-2], c='k', alpha=0.9, s=3)\n                                ax1.scatter(bin_mag_rsqsim[-2:], fault_pr_rsqsim[-2:], c='k', alpha=0.5, s=3)\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], fault_pr_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pvalues.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='b', alpha=0.8, s=2)\n                                index_range += 1\n                            if plot_rsqsim_pr == True:\n                                ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], c='r', s=0.5)\n                                ax1.scatter(bining_in_mag[-2:], mfd_i[-2:], c='r', alpha=0.4, s=0.5)\n                                ax1.set_yscale('log')\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax1.set_ylim([ymin, ymax / 100.0])\n                            p_total = np.mean(diff_rate)\n                            n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                            n_mfd_rsqsim = [i / sum(fault_pr_rsqsim[:-2]) for i in fault_pr_rsqsim[:-2]]\n                            diff_rate = []\n                            bining_i = []\n                            for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                                if model_rate_i != 0 and data_rate_i != 0:\n                                    if model_rate_i >= data_rate_i:\n                                        diff_rate.append(model_rate_i / data_rate_i)\n                                    else:\n                                        diff_rate.append(data_rate_i / model_rate_i)\n                                    bining_i.append(mag_i)\n                            pshape.append(np.mean(diff_rate))\n                            if plot_rsqsim_pr == True:\n                                ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=2)\n                            if plot_rsqsim_pr == True:\n                                if round(p_total, 3) >= 1.3:\n                                    color = 'r'\n                                elif round(p_total, 3) >= 1.2:\n                                    color = 'orange'\n                                else:\n                                    color = 'g'\n                                if round(np.mean(diff_rate), 3) >= 1.3:\n                                    color_shape = 'r'\n                                elif round(np.mean(diff_rate), 3) >= 1.2:\n                                    color_shape = 'orange'\n                                else:\n                                    color_shape = 'g'\n                                ax1.set_title(model + ' ' + fault_name + ' ' + str(round(p_total, 2)), color=color)\n                                ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                                ax1.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_xlim([xmin + 1.0, xmax])\n                                ax2.set_ylim([0.9, 3.0])\n                                plt.show()\n                                plt.close()\n                index_fault += 1\n        score_paleo = np.mean(score_paleo_faults, axis=0)\n        '###################\"\"\\n        Compare with some other MFD at the system level (physics based for example)\\n        #####################\"'\n        plot_fig_rsqsim = False\n        RSQSim_MFD = str(Run_name) + '/mfd_RSQSim.txt'\n        try:\n            with open(RSQSim_MFD) as f:\n                lines = f.readlines()\n            bin_mag_rsqsim = [round(float(i), 1) for i in lines[0].split('\\t')[1:-1]]\n            mfd_rsqsim = [float(i) for i in lines[1].split('\\t')[1:-1]]\n            index_Mmin_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[0])[0][0]\n            index_Mmax_rsqsim = np.where(np.array(bining_in_mag) == bin_mag_rsqsim[-1])[0][0] + 1\n            index_branch = 0\n            for (mfd, model_name_i) in zip(mega_mfd_cummulative, total_list_model):\n                if model_name_i == model:\n                    if plot_fig_rsqsim == True:\n                        (f, (ax1, ax2)) = plt.subplots(1, 2, sharey=False)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bin_mag_rsqsim, mfd_rsqsim, c='k', alpha=0.9, s=3)\n                    pvalues = []\n                    diff_rate = []\n                    bining_i = []\n                    mfd_i = mfd[index_Mmin:index_Mmax]\n                    for (model_rate_i, data_rate_i, mag_i) in zip(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2], mfd_rsqsim[:-2], bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pvalues.append(np.mean(diff_rate))\n                    p_total = np.mean(diff_rate)\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='r', alpha=0.9, s=3)\n                    if plot_fig_rsqsim == True:\n                        ax1.scatter(bining_in_mag[index_Mmin_rsqsim:index_Mmax_rsqsim], mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim], c='r', s=0.5)\n                    n_mfdi = [i / sum(mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]) for i in mfd_i[index_Mmin_rsqsim:index_Mmax_rsqsim - 2]]\n                    n_mfd_rsqsim = [i / sum(mfd_rsqsim[:-2]) for i in mfd_rsqsim[:-2]]\n                    diff_rate = []\n                    bining_i = []\n                    for (model_rate_i, data_rate_i, mag_i) in zip(n_mfdi, n_mfd_rsqsim, bin_mag_rsqsim[:-2]):\n                        if model_rate_i != 0 and data_rate_i != 0:\n                            if model_rate_i >= data_rate_i:\n                                diff_rate.append(model_rate_i / data_rate_i)\n                            else:\n                                diff_rate.append(data_rate_i / model_rate_i)\n                            bining_i.append(mag_i)\n                    pshape.append(np.mean(diff_rate))\n                    if plot_fig_rsqsim == True:\n                        ax2.scatter(bining_i, diff_rate, c='g', alpha=0.8, s=3)\n                    if plot_fig_rsqsim == True:\n                        if round(p_total, 3) >= 1.3:\n                            color = 'r'\n                        elif round(p_total, 3) >= 1.2:\n                            color = 'orange'\n                        else:\n                            color = 'g'\n                        if round(np.mean(diff_rate), 3) >= 1.4:\n                            color_shape = 'r'\n                        elif round(np.mean(diff_rate), 3) >= 1.3:\n                            color_shape = 'orange'\n                        else:\n                            color_shape = 'g'\n                        ax1.set_title(model + ' ' + str(round(p_total, 2)), color=color)\n                        ax2.set_title(str(round(np.mean(diff_rate), 2)), color=color_shape)\n                        ax1.set_ylim([ymin / 10.0, ymax])\n                        ax1.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_xlim([xmin + 1.0, xmax])\n                        ax2.set_ylim([0.9, 3.0])\n                        ax1.set_yscale('log')\n                        plt.show()\n                        plt.close()\n                index_branch += 1\n        except:\n            pass\n        '\\n        Setting the weight for each score\\n        '\n        weight_chi = 0.35\n        weight_Mmax = 0.05\n        weight_NMS_faults_test = 0.3\n        weight_paleo = 0.3\n        if len(score_nms) == 0.0:\n            print('!!! no selected faults for the NMS metric !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_NMS_faults_test = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_paleo = weight_paleo / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_nms.append(0.0)\n        if len(score_paleo) == 0.0:\n            print('!!! no paleo data on the faults !!!')\n            print('Default value = 0.  Weight is set to 0.')\n            weight_paleo = 0.0\n            weight_chi = weight_chi / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_Mmax = weight_Mmax / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            weight_NMS_faults_test = weight_NMS_faults_test / (weight_chi + weight_Mmax + weight_NMS_faults_test + weight_paleo)\n            for i in range(len(p_chi_branch)):\n                score_paleo.append(0.0)\n        ' \\n        Builbing the text file\\n        '\n        lt_branch = []\n        lt_i_before = 'truc'\n        srep_file = str(Run_name) + '/analysis/txt_files/slip_rep_on_faults_all_data.txt'\n        try:\n            with open(srep_file) as f:\n                lines = f.readlines()\n            ordered_score_paleo = []\n            i_lt = 0\n            for line in lines:\n                if line.split('\\t')[1] == model:\n                    lt_i = []\n                    for i in range(7):\n                        lt_i.append(line.split('\\t')[i])\n                    if str(lt_i) != lt_i_before:\n                        lt_i_before = str(lt_i)\n                        lt_i.append(round(mean_sr_branch[i_lt], 3))\n                        lt_i.append(round(p_chi_branch[i_lt], 3))\n                        lt_i.append(round(weight_model_Mmax[i_lt], 3))\n                        lt_i.append(round(score_nms[i_lt], 3))\n                        i1 = np.where(np.array(paleo_list_mfd) == line.split('\\t')[4][4:])[0]\n                        i2 = np.where(np.array(paleo_list_scenario) == line.split('\\t')[5])[0]\n                        i3 = np.where(np.array(paleo_list_sample) == line.split('\\t')[6].split('_')[1])[0]\n                        i4 = np.where(np.array(paleo_list_bvalue) == line.split('\\t')[3])[0]\n                        i5 = np.where(np.array(paleo_list_bg) == line.split('\\t')[2][3:])[0]\n                        i6 = np.where(np.array(paleo_list_scl) == line.split('\\t')[0])[0]\n                        i1 = np.intersect1d(i1, i2)\n                        i1 = np.intersect1d(i1, i3)\n                        i1 = np.intersect1d(i1, i4)\n                        i1 = np.intersect1d(i1, i5)\n                        i1 = np.intersect1d(i1, i6)\n                        lt_i.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        ordered_score_paleo.append(round(np.mean(np.take(score_paleo, i1)), 3))\n                        lt_branch.append(lt_i)\n                        i_lt += 1\n            for lt_i in lt_branch:\n                line = ''\n                for i in lt_i:\n                    line += str(i) + '\\t'\n                line = line[:-1]\n                file_LT_metrics.write(line + '\\n')\n        except (FileNotFoundError, IndexError) as e:\n            print('!!! you need to run the plot_sr_use if you want the file with the metrics  and modify Sampling_analysis.py!!!')\n        '\\n        Calculataing the weighted score for each branch\\n        '\n        if ordered_score_paleo == []:\n            ordered_score_paleo = [0 for i in range(len(p_chi_branch))]\n        final_weigth = []\n        for i in range(len(p_chi_branch)):\n            final_weigth.append(p_chi_branch[i] * weight_chi + weight_model_Mmax[i] * weight_Mmax + score_nms[i] * weight_NMS_faults_test + ordered_score_paleo[i] * weight_paleo)\n        '\\n        Plotting section\\n        \\n        Weighted average of the different metric\\n        \\n        user defined weight for each metric. the figure give the weighted average as a final p value\\n        '\n        color_mfd = []\n        for (MFD_type_i, model_name_i) in zip(total_list_MFD_type, total_list_model):\n            if model_name_i == model:\n                if MFD_type_i == 'GR':\n                    color_mfd.append('darkblue')\n                else:\n                    color_mfd.append('darkgreen')\n        (f, (ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, sharey=True)\n        ax1.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax1.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax1.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax2.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax2.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax2.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax3.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax3.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax3.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax4.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax4.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax4.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax5.axhspan(0.8, 1.1, facecolor='g', alpha=0.1)\n        ax5.axhspan(0.6, 0.8, facecolor='orange', alpha=0.1)\n        ax5.axhspan(-0.1, 0.6, facecolor='r', alpha=0.1)\n        ax1.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax1.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax2.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax3.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax4.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(0.0, linestyle=':', linewidth=0.2, color='k')\n        ax5.axhline(1.0, linestyle=':', linewidth=0.2, color='k')\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            if total_list_scenario_name[j] == total_list_scenario_name[0]:\n                if weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='_', s=15, alpha=0.2, linewidth=1)\n                else:\n                    ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n                    ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='_', s=15, alpha=0.9, linewidth=1)\n            elif weight_model_Mmax[i] == 0 or score_nms[i] == 0 or ordered_score_paleo[i] < 0.25 or (p_chi_branch[i] < 0.3):\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c='darkred', marker='|', s=15, alpha=0.2, linewidth=1)\n            else:\n                ax1.scatter(m_Mmax[j], p_chi_branch[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax2.scatter(m_Mmax[j], weight_model_Mmax[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax3.scatter(m_Mmax[j], score_nms[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax4.scatter(m_Mmax[j], ordered_score_paleo[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n                ax5.scatter(m_Mmax[j], final_weigth[i], c=color_mfd[i], marker='|', s=15, alpha=0.9, linewidth=1)\n        ax1.set_xlabel('Mmax')\n        ax1.set_ylabel('test value   ' + str(model))\n        ax1.set_ylim([-0.05, 1.05])\n        ax1.set_xlim([xmax - 1.5, xmax])\n        ax2.set_xlim([xmax - 1.5, xmax])\n        ax3.set_xlim([xmax - 1.5, xmax])\n        ax4.set_xlim([xmax - 1.5, xmax])\n        ax5.set_xlim([xmax - 1.5, xmax])\n        ax1.set_title('chi test')\n        ax2.set_title('Mmax test')\n        ax3.set_title('NMS test')\n        ax4.set_title('Paleo test')\n        ax5.set_title('weitghted total')\n        plt.savefig(str(Run_name) + '/analysis/figures/sampling_analysis/' + model + '/model_performance.png', dpi=180)\n        plt.close()\n        index_model += 1\n        for (i, j) in zip(range(len(p_chi_branch)), indexes_model):\n            file.write(str(model) + '\\t' + str(total_list_MFD_type[j]) + '\\t' + str(total_list_BG_hyp[j]) + '\\t' + str(total_list_scenario_name[j]) + '\\t' + str(total_list_sample[j]) + '\\t' + str(round(p_chi_branch[i], 2)) + '\\t' + str(round(ordered_score_paleo[i], 2)) + '\\t' + str(round(score_nms[i], 2)) + '\\n')\n    file.close()\n    file_LT_metrics.close()"
        ]
    }
]