[
    {
        "func_name": "_sort_topk_votes",
        "original": "def _sort_topk_votes(x, k):\n    \"\"\"\n    Sort a dictionary of classes and corresponding vote totals according to the\n    votes, then truncate to the highest 'k' classes.\n    \"\"\"\n    y = sorted(x.items(), key=lambda x: x[1], reverse=True)[:k]\n    return [{'class': i[0], 'votes': i[1]} for i in y]",
        "mutated": [
            "def _sort_topk_votes(x, k):\n    if False:\n        i = 10\n    \"\\n    Sort a dictionary of classes and corresponding vote totals according to the\\n    votes, then truncate to the highest 'k' classes.\\n    \"\n    y = sorted(x.items(), key=lambda x: x[1], reverse=True)[:k]\n    return [{'class': i[0], 'votes': i[1]} for i in y]",
            "def _sort_topk_votes(x, k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Sort a dictionary of classes and corresponding vote totals according to the\\n    votes, then truncate to the highest 'k' classes.\\n    \"\n    y = sorted(x.items(), key=lambda x: x[1], reverse=True)[:k]\n    return [{'class': i[0], 'votes': i[1]} for i in y]",
            "def _sort_topk_votes(x, k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Sort a dictionary of classes and corresponding vote totals according to the\\n    votes, then truncate to the highest 'k' classes.\\n    \"\n    y = sorted(x.items(), key=lambda x: x[1], reverse=True)[:k]\n    return [{'class': i[0], 'votes': i[1]} for i in y]",
            "def _sort_topk_votes(x, k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Sort a dictionary of classes and corresponding vote totals according to the\\n    votes, then truncate to the highest 'k' classes.\\n    \"\n    y = sorted(x.items(), key=lambda x: x[1], reverse=True)[:k]\n    return [{'class': i[0], 'votes': i[1]} for i in y]",
            "def _sort_topk_votes(x, k):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Sort a dictionary of classes and corresponding vote totals according to the\\n    votes, then truncate to the highest 'k' classes.\\n    \"\n    y = sorted(x.items(), key=lambda x: x[1], reverse=True)[:k]\n    return [{'class': i[0], 'votes': i[1]} for i in y]"
        ]
    },
    {
        "func_name": "_construct_auto_distance",
        "original": "def _construct_auto_distance(features, column_types):\n    \"\"\"\n    Construct a composite distance function for a set of features, based on the\n    types of those features.\n\n    NOTE: This function is very similar to\n    `:func:_nearest_neighbors.choose_auto_distance`. The function is separate\n    because the auto-distance logic different than for each nearest\n    neighbors-based toolkit.\n\n    Parameters\n    ----------\n    features : list[str]\n        Names of for which to construct a distance function.\n\n    column_types : dict(string, type)\n        Names and types of all columns.\n\n    Returns\n    -------\n    dist : list[list]\n        A composite distance function. Each element of the inner list has three\n        elements: a list of feature names (strings), a distance function name\n        (string), and a weight (float).\n    \"\"\"\n    numeric_ftrs = []\n    string_ftrs = []\n    dict_ftrs = []\n    for ftr in features:\n        try:\n            ftr_type = column_types[ftr]\n        except:\n            raise ValueError('The specified feature does not exist in the ' + 'input data.')\n        if ftr_type == str:\n            string_ftrs.append(ftr)\n        elif ftr_type == dict:\n            dict_ftrs.append(ftr)\n        elif ftr_type in [int, float, _array.array]:\n            numeric_ftrs.append(ftr)\n        else:\n            raise TypeError('Unable to automatically construct a distance ' + \"function for feature '{}'. \".format(ftr) + 'For the nearest neighbor classifier, features ' + 'must be of type integer, float, string, dictionary, ' + 'or array.array.')\n    dist = []\n    for ftr in string_ftrs:\n        dist.append([[ftr], 'levenshtein', 1])\n    if len(dict_ftrs) > 0:\n        dist.append([dict_ftrs, 'weighted_jaccard', len(dict_ftrs)])\n    if len(numeric_ftrs) > 0:\n        dist.append([numeric_ftrs, 'euclidean', len(numeric_ftrs)])\n    return dist",
        "mutated": [
            "def _construct_auto_distance(features, column_types):\n    if False:\n        i = 10\n    '\\n    Construct a composite distance function for a set of features, based on the\\n    types of those features.\\n\\n    NOTE: This function is very similar to\\n    `:func:_nearest_neighbors.choose_auto_distance`. The function is separate\\n    because the auto-distance logic different than for each nearest\\n    neighbors-based toolkit.\\n\\n    Parameters\\n    ----------\\n    features : list[str]\\n        Names of for which to construct a distance function.\\n\\n    column_types : dict(string, type)\\n        Names and types of all columns.\\n\\n    Returns\\n    -------\\n    dist : list[list]\\n        A composite distance function. Each element of the inner list has three\\n        elements: a list of feature names (strings), a distance function name\\n        (string), and a weight (float).\\n    '\n    numeric_ftrs = []\n    string_ftrs = []\n    dict_ftrs = []\n    for ftr in features:\n        try:\n            ftr_type = column_types[ftr]\n        except:\n            raise ValueError('The specified feature does not exist in the ' + 'input data.')\n        if ftr_type == str:\n            string_ftrs.append(ftr)\n        elif ftr_type == dict:\n            dict_ftrs.append(ftr)\n        elif ftr_type in [int, float, _array.array]:\n            numeric_ftrs.append(ftr)\n        else:\n            raise TypeError('Unable to automatically construct a distance ' + \"function for feature '{}'. \".format(ftr) + 'For the nearest neighbor classifier, features ' + 'must be of type integer, float, string, dictionary, ' + 'or array.array.')\n    dist = []\n    for ftr in string_ftrs:\n        dist.append([[ftr], 'levenshtein', 1])\n    if len(dict_ftrs) > 0:\n        dist.append([dict_ftrs, 'weighted_jaccard', len(dict_ftrs)])\n    if len(numeric_ftrs) > 0:\n        dist.append([numeric_ftrs, 'euclidean', len(numeric_ftrs)])\n    return dist",
            "def _construct_auto_distance(features, column_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Construct a composite distance function for a set of features, based on the\\n    types of those features.\\n\\n    NOTE: This function is very similar to\\n    `:func:_nearest_neighbors.choose_auto_distance`. The function is separate\\n    because the auto-distance logic different than for each nearest\\n    neighbors-based toolkit.\\n\\n    Parameters\\n    ----------\\n    features : list[str]\\n        Names of for which to construct a distance function.\\n\\n    column_types : dict(string, type)\\n        Names and types of all columns.\\n\\n    Returns\\n    -------\\n    dist : list[list]\\n        A composite distance function. Each element of the inner list has three\\n        elements: a list of feature names (strings), a distance function name\\n        (string), and a weight (float).\\n    '\n    numeric_ftrs = []\n    string_ftrs = []\n    dict_ftrs = []\n    for ftr in features:\n        try:\n            ftr_type = column_types[ftr]\n        except:\n            raise ValueError('The specified feature does not exist in the ' + 'input data.')\n        if ftr_type == str:\n            string_ftrs.append(ftr)\n        elif ftr_type == dict:\n            dict_ftrs.append(ftr)\n        elif ftr_type in [int, float, _array.array]:\n            numeric_ftrs.append(ftr)\n        else:\n            raise TypeError('Unable to automatically construct a distance ' + \"function for feature '{}'. \".format(ftr) + 'For the nearest neighbor classifier, features ' + 'must be of type integer, float, string, dictionary, ' + 'or array.array.')\n    dist = []\n    for ftr in string_ftrs:\n        dist.append([[ftr], 'levenshtein', 1])\n    if len(dict_ftrs) > 0:\n        dist.append([dict_ftrs, 'weighted_jaccard', len(dict_ftrs)])\n    if len(numeric_ftrs) > 0:\n        dist.append([numeric_ftrs, 'euclidean', len(numeric_ftrs)])\n    return dist",
            "def _construct_auto_distance(features, column_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Construct a composite distance function for a set of features, based on the\\n    types of those features.\\n\\n    NOTE: This function is very similar to\\n    `:func:_nearest_neighbors.choose_auto_distance`. The function is separate\\n    because the auto-distance logic different than for each nearest\\n    neighbors-based toolkit.\\n\\n    Parameters\\n    ----------\\n    features : list[str]\\n        Names of for which to construct a distance function.\\n\\n    column_types : dict(string, type)\\n        Names and types of all columns.\\n\\n    Returns\\n    -------\\n    dist : list[list]\\n        A composite distance function. Each element of the inner list has three\\n        elements: a list of feature names (strings), a distance function name\\n        (string), and a weight (float).\\n    '\n    numeric_ftrs = []\n    string_ftrs = []\n    dict_ftrs = []\n    for ftr in features:\n        try:\n            ftr_type = column_types[ftr]\n        except:\n            raise ValueError('The specified feature does not exist in the ' + 'input data.')\n        if ftr_type == str:\n            string_ftrs.append(ftr)\n        elif ftr_type == dict:\n            dict_ftrs.append(ftr)\n        elif ftr_type in [int, float, _array.array]:\n            numeric_ftrs.append(ftr)\n        else:\n            raise TypeError('Unable to automatically construct a distance ' + \"function for feature '{}'. \".format(ftr) + 'For the nearest neighbor classifier, features ' + 'must be of type integer, float, string, dictionary, ' + 'or array.array.')\n    dist = []\n    for ftr in string_ftrs:\n        dist.append([[ftr], 'levenshtein', 1])\n    if len(dict_ftrs) > 0:\n        dist.append([dict_ftrs, 'weighted_jaccard', len(dict_ftrs)])\n    if len(numeric_ftrs) > 0:\n        dist.append([numeric_ftrs, 'euclidean', len(numeric_ftrs)])\n    return dist",
            "def _construct_auto_distance(features, column_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Construct a composite distance function for a set of features, based on the\\n    types of those features.\\n\\n    NOTE: This function is very similar to\\n    `:func:_nearest_neighbors.choose_auto_distance`. The function is separate\\n    because the auto-distance logic different than for each nearest\\n    neighbors-based toolkit.\\n\\n    Parameters\\n    ----------\\n    features : list[str]\\n        Names of for which to construct a distance function.\\n\\n    column_types : dict(string, type)\\n        Names and types of all columns.\\n\\n    Returns\\n    -------\\n    dist : list[list]\\n        A composite distance function. Each element of the inner list has three\\n        elements: a list of feature names (strings), a distance function name\\n        (string), and a weight (float).\\n    '\n    numeric_ftrs = []\n    string_ftrs = []\n    dict_ftrs = []\n    for ftr in features:\n        try:\n            ftr_type = column_types[ftr]\n        except:\n            raise ValueError('The specified feature does not exist in the ' + 'input data.')\n        if ftr_type == str:\n            string_ftrs.append(ftr)\n        elif ftr_type == dict:\n            dict_ftrs.append(ftr)\n        elif ftr_type in [int, float, _array.array]:\n            numeric_ftrs.append(ftr)\n        else:\n            raise TypeError('Unable to automatically construct a distance ' + \"function for feature '{}'. \".format(ftr) + 'For the nearest neighbor classifier, features ' + 'must be of type integer, float, string, dictionary, ' + 'or array.array.')\n    dist = []\n    for ftr in string_ftrs:\n        dist.append([[ftr], 'levenshtein', 1])\n    if len(dict_ftrs) > 0:\n        dist.append([dict_ftrs, 'weighted_jaccard', len(dict_ftrs)])\n    if len(numeric_ftrs) > 0:\n        dist.append([numeric_ftrs, 'euclidean', len(numeric_ftrs)])\n    return dist",
            "def _construct_auto_distance(features, column_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Construct a composite distance function for a set of features, based on the\\n    types of those features.\\n\\n    NOTE: This function is very similar to\\n    `:func:_nearest_neighbors.choose_auto_distance`. The function is separate\\n    because the auto-distance logic different than for each nearest\\n    neighbors-based toolkit.\\n\\n    Parameters\\n    ----------\\n    features : list[str]\\n        Names of for which to construct a distance function.\\n\\n    column_types : dict(string, type)\\n        Names and types of all columns.\\n\\n    Returns\\n    -------\\n    dist : list[list]\\n        A composite distance function. Each element of the inner list has three\\n        elements: a list of feature names (strings), a distance function name\\n        (string), and a weight (float).\\n    '\n    numeric_ftrs = []\n    string_ftrs = []\n    dict_ftrs = []\n    for ftr in features:\n        try:\n            ftr_type = column_types[ftr]\n        except:\n            raise ValueError('The specified feature does not exist in the ' + 'input data.')\n        if ftr_type == str:\n            string_ftrs.append(ftr)\n        elif ftr_type == dict:\n            dict_ftrs.append(ftr)\n        elif ftr_type in [int, float, _array.array]:\n            numeric_ftrs.append(ftr)\n        else:\n            raise TypeError('Unable to automatically construct a distance ' + \"function for feature '{}'. \".format(ftr) + 'For the nearest neighbor classifier, features ' + 'must be of type integer, float, string, dictionary, ' + 'or array.array.')\n    dist = []\n    for ftr in string_ftrs:\n        dist.append([[ftr], 'levenshtein', 1])\n    if len(dict_ftrs) > 0:\n        dist.append([dict_ftrs, 'weighted_jaccard', len(dict_ftrs)])\n    if len(numeric_ftrs) > 0:\n        dist.append([numeric_ftrs, 'euclidean', len(numeric_ftrs)])\n    return dist"
        ]
    },
    {
        "func_name": "create",
        "original": "def create(dataset, target, features=None, distance=None, verbose=True):\n    \"\"\"\n    Create a\n    :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`\n    model. This model predicts the class of a query instance by finding the most\n    common class among the query's nearest neighbors.\n\n    Parameters\n    ----------\n    dataset : SFrame\n        Dataset for training the model.\n\n    target : str\n        Name of the column containing the target variable. The values in this\n        column must be of string or integer type.\n\n    features : list[str], optional\n        Name of the columns with features to use in comparing records. 'None'\n        (the default) indicates that all columns except the target variable\n        should be used. Please note: if `distance` is specified as a composite\n        distance, then that parameter controls which features are used in the\n        model. Each column can be one of the following types:\n\n        - *Numeric*: values of numeric type integer or float.\n\n        - *Array*: array of numeric (integer or float) values. Each array\n          element is treated as a separate variable in the model.\n\n        - *Dictionary*: key-value pairs with numeric (integer or float) values.\n          Each key indicates a separate variable in the model.\n\n        - *String*: string values.\n\n        Please note: if `distance` is specified as a composite distance, then\n        that parameter controls which features are used in the model.\n\n    distance : str, function, or list[list], optional\n        Function to measure the distance between any two input data rows. This\n        may be one of three types:\n\n        - *String*: the name of a standard distance function. One of\n          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',\n          'jaccard', 'weighted_jaccard', 'cosine' or 'transformed_dot_product'.\n\n        - *Function*: a function handle from the\n          :mod:`~turicreate.toolkits.distances` module.\n\n        - *Composite distance*: the weighted sum of several standard distance\n          functions applied to various features. This is specified as a list of\n          distance components, each of which is itself a list containing three\n          items:\n\n          1. list or tuple of feature names (str)\n\n          2. standard distance name (str)\n\n          3. scaling factor (int or float)\n\n        For more information about Turi Create distance functions, please\n        see the :py:mod:`~turicreate.toolkits.distances` module.\n\n        For sparse vectors, missing keys are assumed to have value 0.0.\n\n        If 'distance' is left unspecified or set to 'auto', a composite distance\n        is constructed automatically based on feature types.\n\n    verbose : bool, optional\n        If True, print progress updates and model details.\n\n    Returns\n    -------\n    out : NearestNeighborClassifier\n        A trained model of type\n        :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`.\n\n    See Also\n    --------\n    NearestNeighborClassifier\n    turicreate.toolkits.nearest_neighbors\n    turicreate.toolkits.distances\n\n    References\n    ----------\n    - `Wikipedia - nearest neighbors classifier\n      <http://en.wikipedia.org/wiki/Nearest_neighbour_classifiers>`_\n\n    - Hastie, T., Tibshirani, R., Friedman, J. (2009). `The Elements of\n      Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_.\n      Vol. 2. New York. Springer. pp. 463-481.\n\n    Examples\n    --------\n    >>> sf = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\n    ...                       'height': [9, 25, 20, 23],\n    ...                       'weight': [13, 28, 33, 22]})\n    ...\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species')\n\n    As with the nearest neighbors toolkit, the nearest neighbor classifier\n    accepts composite distance functions.\n\n    >>> my_dist = [[('height', 'weight'), 'euclidean', 2.7],\n    ...            [('height', 'weight'), 'manhattan', 1.6]]\n    ...\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species',\n    ...                                                     distance=my_dist)\n    \"\"\"\n    start_time = _time.time()\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if not isinstance(target, str) or target not in dataset.column_names():\n        raise _ToolkitError(\"The 'target' parameter must be the name of a column in the input dataset.\")\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column must contain integers or strings.')\n    if dataset[target].countna() > 0:\n        _logging.warning('Missing values detected in the target column. This ' + \"may lead to ambiguous 'None' predictions, if the \" + \"'radius' parameter is set too small in the prediction, \" + 'classification, or evaluation methods.')\n    if features is None:\n        _features = [x for x in dataset.column_names() if x != target]\n    else:\n        _features = [x for x in features if x != target]\n    if isinstance(distance, list):\n        distance = _copy.deepcopy(distance)\n    elif hasattr(distance, '__call__') or (isinstance(distance, str) and (not distance == 'auto')):\n        distance = [[_features, distance, 1]]\n    elif distance is None or distance == 'auto':\n        col_types = {k: v for (k, v) in zip(dataset.column_names(), dataset.column_types())}\n        distance = _construct_auto_distance(_features, col_types)\n    else:\n        raise TypeError(\"Input 'distance' not understood. The 'distance' \" + 'parameter must be a string or a composite distance, ' + ' or left unspecified.')\n    knn_model = _tc.nearest_neighbors.create(dataset, label=target, distance=distance, verbose=verbose)\n    state = {'verbose': verbose, 'distance': knn_model.distance, 'num_distance_components': knn_model.num_distance_components, 'num_examples': dataset.num_rows(), 'features': knn_model.features, 'target': target, 'num_classes': len(dataset[target].unique()), 'num_features': knn_model.num_features, 'num_unpacked_features': knn_model.num_unpacked_features, 'training_time': _time.time() - start_time, '_target_type': dataset[target].dtype}\n    model = NearestNeighborClassifier(knn_model, state)\n    return model",
        "mutated": [
            "def create(dataset, target, features=None, distance=None, verbose=True):\n    if False:\n        i = 10\n    \"\\n    Create a\\n    :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`\\n    model. This model predicts the class of a query instance by finding the most\\n    common class among the query's nearest neighbors.\\n\\n    Parameters\\n    ----------\\n    dataset : SFrame\\n        Dataset for training the model.\\n\\n    target : str\\n        Name of the column containing the target variable. The values in this\\n        column must be of string or integer type.\\n\\n    features : list[str], optional\\n        Name of the columns with features to use in comparing records. 'None'\\n        (the default) indicates that all columns except the target variable\\n        should be used. Please note: if `distance` is specified as a composite\\n        distance, then that parameter controls which features are used in the\\n        model. Each column can be one of the following types:\\n\\n        - *Numeric*: values of numeric type integer or float.\\n\\n        - *Array*: array of numeric (integer or float) values. Each array\\n          element is treated as a separate variable in the model.\\n\\n        - *Dictionary*: key-value pairs with numeric (integer or float) values.\\n          Each key indicates a separate variable in the model.\\n\\n        - *String*: string values.\\n\\n        Please note: if `distance` is specified as a composite distance, then\\n        that parameter controls which features are used in the model.\\n\\n    distance : str, function, or list[list], optional\\n        Function to measure the distance between any two input data rows. This\\n        may be one of three types:\\n\\n        - *String*: the name of a standard distance function. One of\\n          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',\\n          'jaccard', 'weighted_jaccard', 'cosine' or 'transformed_dot_product'.\\n\\n        - *Function*: a function handle from the\\n          :mod:`~turicreate.toolkits.distances` module.\\n\\n        - *Composite distance*: the weighted sum of several standard distance\\n          functions applied to various features. This is specified as a list of\\n          distance components, each of which is itself a list containing three\\n          items:\\n\\n          1. list or tuple of feature names (str)\\n\\n          2. standard distance name (str)\\n\\n          3. scaling factor (int or float)\\n\\n        For more information about Turi Create distance functions, please\\n        see the :py:mod:`~turicreate.toolkits.distances` module.\\n\\n        For sparse vectors, missing keys are assumed to have value 0.0.\\n\\n        If 'distance' is left unspecified or set to 'auto', a composite distance\\n        is constructed automatically based on feature types.\\n\\n    verbose : bool, optional\\n        If True, print progress updates and model details.\\n\\n    Returns\\n    -------\\n    out : NearestNeighborClassifier\\n        A trained model of type\\n        :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`.\\n\\n    See Also\\n    --------\\n    NearestNeighborClassifier\\n    turicreate.toolkits.nearest_neighbors\\n    turicreate.toolkits.distances\\n\\n    References\\n    ----------\\n    - `Wikipedia - nearest neighbors classifier\\n      <http://en.wikipedia.org/wiki/Nearest_neighbour_classifiers>`_\\n\\n    - Hastie, T., Tibshirani, R., Friedman, J. (2009). `The Elements of\\n      Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_.\\n      Vol. 2. New York. Springer. pp. 463-481.\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n    ...                       'height': [9, 25, 20, 23],\\n    ...                       'weight': [13, 28, 33, 22]})\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n\\n    As with the nearest neighbors toolkit, the nearest neighbor classifier\\n    accepts composite distance functions.\\n\\n    >>> my_dist = [[('height', 'weight'), 'euclidean', 2.7],\\n    ...            [('height', 'weight'), 'manhattan', 1.6]]\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species',\\n    ...                                                     distance=my_dist)\\n    \"\n    start_time = _time.time()\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if not isinstance(target, str) or target not in dataset.column_names():\n        raise _ToolkitError(\"The 'target' parameter must be the name of a column in the input dataset.\")\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column must contain integers or strings.')\n    if dataset[target].countna() > 0:\n        _logging.warning('Missing values detected in the target column. This ' + \"may lead to ambiguous 'None' predictions, if the \" + \"'radius' parameter is set too small in the prediction, \" + 'classification, or evaluation methods.')\n    if features is None:\n        _features = [x for x in dataset.column_names() if x != target]\n    else:\n        _features = [x for x in features if x != target]\n    if isinstance(distance, list):\n        distance = _copy.deepcopy(distance)\n    elif hasattr(distance, '__call__') or (isinstance(distance, str) and (not distance == 'auto')):\n        distance = [[_features, distance, 1]]\n    elif distance is None or distance == 'auto':\n        col_types = {k: v for (k, v) in zip(dataset.column_names(), dataset.column_types())}\n        distance = _construct_auto_distance(_features, col_types)\n    else:\n        raise TypeError(\"Input 'distance' not understood. The 'distance' \" + 'parameter must be a string or a composite distance, ' + ' or left unspecified.')\n    knn_model = _tc.nearest_neighbors.create(dataset, label=target, distance=distance, verbose=verbose)\n    state = {'verbose': verbose, 'distance': knn_model.distance, 'num_distance_components': knn_model.num_distance_components, 'num_examples': dataset.num_rows(), 'features': knn_model.features, 'target': target, 'num_classes': len(dataset[target].unique()), 'num_features': knn_model.num_features, 'num_unpacked_features': knn_model.num_unpacked_features, 'training_time': _time.time() - start_time, '_target_type': dataset[target].dtype}\n    model = NearestNeighborClassifier(knn_model, state)\n    return model",
            "def create(dataset, target, features=None, distance=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Create a\\n    :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`\\n    model. This model predicts the class of a query instance by finding the most\\n    common class among the query's nearest neighbors.\\n\\n    Parameters\\n    ----------\\n    dataset : SFrame\\n        Dataset for training the model.\\n\\n    target : str\\n        Name of the column containing the target variable. The values in this\\n        column must be of string or integer type.\\n\\n    features : list[str], optional\\n        Name of the columns with features to use in comparing records. 'None'\\n        (the default) indicates that all columns except the target variable\\n        should be used. Please note: if `distance` is specified as a composite\\n        distance, then that parameter controls which features are used in the\\n        model. Each column can be one of the following types:\\n\\n        - *Numeric*: values of numeric type integer or float.\\n\\n        - *Array*: array of numeric (integer or float) values. Each array\\n          element is treated as a separate variable in the model.\\n\\n        - *Dictionary*: key-value pairs with numeric (integer or float) values.\\n          Each key indicates a separate variable in the model.\\n\\n        - *String*: string values.\\n\\n        Please note: if `distance` is specified as a composite distance, then\\n        that parameter controls which features are used in the model.\\n\\n    distance : str, function, or list[list], optional\\n        Function to measure the distance between any two input data rows. This\\n        may be one of three types:\\n\\n        - *String*: the name of a standard distance function. One of\\n          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',\\n          'jaccard', 'weighted_jaccard', 'cosine' or 'transformed_dot_product'.\\n\\n        - *Function*: a function handle from the\\n          :mod:`~turicreate.toolkits.distances` module.\\n\\n        - *Composite distance*: the weighted sum of several standard distance\\n          functions applied to various features. This is specified as a list of\\n          distance components, each of which is itself a list containing three\\n          items:\\n\\n          1. list or tuple of feature names (str)\\n\\n          2. standard distance name (str)\\n\\n          3. scaling factor (int or float)\\n\\n        For more information about Turi Create distance functions, please\\n        see the :py:mod:`~turicreate.toolkits.distances` module.\\n\\n        For sparse vectors, missing keys are assumed to have value 0.0.\\n\\n        If 'distance' is left unspecified or set to 'auto', a composite distance\\n        is constructed automatically based on feature types.\\n\\n    verbose : bool, optional\\n        If True, print progress updates and model details.\\n\\n    Returns\\n    -------\\n    out : NearestNeighborClassifier\\n        A trained model of type\\n        :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`.\\n\\n    See Also\\n    --------\\n    NearestNeighborClassifier\\n    turicreate.toolkits.nearest_neighbors\\n    turicreate.toolkits.distances\\n\\n    References\\n    ----------\\n    - `Wikipedia - nearest neighbors classifier\\n      <http://en.wikipedia.org/wiki/Nearest_neighbour_classifiers>`_\\n\\n    - Hastie, T., Tibshirani, R., Friedman, J. (2009). `The Elements of\\n      Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_.\\n      Vol. 2. New York. Springer. pp. 463-481.\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n    ...                       'height': [9, 25, 20, 23],\\n    ...                       'weight': [13, 28, 33, 22]})\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n\\n    As with the nearest neighbors toolkit, the nearest neighbor classifier\\n    accepts composite distance functions.\\n\\n    >>> my_dist = [[('height', 'weight'), 'euclidean', 2.7],\\n    ...            [('height', 'weight'), 'manhattan', 1.6]]\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species',\\n    ...                                                     distance=my_dist)\\n    \"\n    start_time = _time.time()\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if not isinstance(target, str) or target not in dataset.column_names():\n        raise _ToolkitError(\"The 'target' parameter must be the name of a column in the input dataset.\")\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column must contain integers or strings.')\n    if dataset[target].countna() > 0:\n        _logging.warning('Missing values detected in the target column. This ' + \"may lead to ambiguous 'None' predictions, if the \" + \"'radius' parameter is set too small in the prediction, \" + 'classification, or evaluation methods.')\n    if features is None:\n        _features = [x for x in dataset.column_names() if x != target]\n    else:\n        _features = [x for x in features if x != target]\n    if isinstance(distance, list):\n        distance = _copy.deepcopy(distance)\n    elif hasattr(distance, '__call__') or (isinstance(distance, str) and (not distance == 'auto')):\n        distance = [[_features, distance, 1]]\n    elif distance is None or distance == 'auto':\n        col_types = {k: v for (k, v) in zip(dataset.column_names(), dataset.column_types())}\n        distance = _construct_auto_distance(_features, col_types)\n    else:\n        raise TypeError(\"Input 'distance' not understood. The 'distance' \" + 'parameter must be a string or a composite distance, ' + ' or left unspecified.')\n    knn_model = _tc.nearest_neighbors.create(dataset, label=target, distance=distance, verbose=verbose)\n    state = {'verbose': verbose, 'distance': knn_model.distance, 'num_distance_components': knn_model.num_distance_components, 'num_examples': dataset.num_rows(), 'features': knn_model.features, 'target': target, 'num_classes': len(dataset[target].unique()), 'num_features': knn_model.num_features, 'num_unpacked_features': knn_model.num_unpacked_features, 'training_time': _time.time() - start_time, '_target_type': dataset[target].dtype}\n    model = NearestNeighborClassifier(knn_model, state)\n    return model",
            "def create(dataset, target, features=None, distance=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Create a\\n    :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`\\n    model. This model predicts the class of a query instance by finding the most\\n    common class among the query's nearest neighbors.\\n\\n    Parameters\\n    ----------\\n    dataset : SFrame\\n        Dataset for training the model.\\n\\n    target : str\\n        Name of the column containing the target variable. The values in this\\n        column must be of string or integer type.\\n\\n    features : list[str], optional\\n        Name of the columns with features to use in comparing records. 'None'\\n        (the default) indicates that all columns except the target variable\\n        should be used. Please note: if `distance` is specified as a composite\\n        distance, then that parameter controls which features are used in the\\n        model. Each column can be one of the following types:\\n\\n        - *Numeric*: values of numeric type integer or float.\\n\\n        - *Array*: array of numeric (integer or float) values. Each array\\n          element is treated as a separate variable in the model.\\n\\n        - *Dictionary*: key-value pairs with numeric (integer or float) values.\\n          Each key indicates a separate variable in the model.\\n\\n        - *String*: string values.\\n\\n        Please note: if `distance` is specified as a composite distance, then\\n        that parameter controls which features are used in the model.\\n\\n    distance : str, function, or list[list], optional\\n        Function to measure the distance between any two input data rows. This\\n        may be one of three types:\\n\\n        - *String*: the name of a standard distance function. One of\\n          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',\\n          'jaccard', 'weighted_jaccard', 'cosine' or 'transformed_dot_product'.\\n\\n        - *Function*: a function handle from the\\n          :mod:`~turicreate.toolkits.distances` module.\\n\\n        - *Composite distance*: the weighted sum of several standard distance\\n          functions applied to various features. This is specified as a list of\\n          distance components, each of which is itself a list containing three\\n          items:\\n\\n          1. list or tuple of feature names (str)\\n\\n          2. standard distance name (str)\\n\\n          3. scaling factor (int or float)\\n\\n        For more information about Turi Create distance functions, please\\n        see the :py:mod:`~turicreate.toolkits.distances` module.\\n\\n        For sparse vectors, missing keys are assumed to have value 0.0.\\n\\n        If 'distance' is left unspecified or set to 'auto', a composite distance\\n        is constructed automatically based on feature types.\\n\\n    verbose : bool, optional\\n        If True, print progress updates and model details.\\n\\n    Returns\\n    -------\\n    out : NearestNeighborClassifier\\n        A trained model of type\\n        :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`.\\n\\n    See Also\\n    --------\\n    NearestNeighborClassifier\\n    turicreate.toolkits.nearest_neighbors\\n    turicreate.toolkits.distances\\n\\n    References\\n    ----------\\n    - `Wikipedia - nearest neighbors classifier\\n      <http://en.wikipedia.org/wiki/Nearest_neighbour_classifiers>`_\\n\\n    - Hastie, T., Tibshirani, R., Friedman, J. (2009). `The Elements of\\n      Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_.\\n      Vol. 2. New York. Springer. pp. 463-481.\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n    ...                       'height': [9, 25, 20, 23],\\n    ...                       'weight': [13, 28, 33, 22]})\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n\\n    As with the nearest neighbors toolkit, the nearest neighbor classifier\\n    accepts composite distance functions.\\n\\n    >>> my_dist = [[('height', 'weight'), 'euclidean', 2.7],\\n    ...            [('height', 'weight'), 'manhattan', 1.6]]\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species',\\n    ...                                                     distance=my_dist)\\n    \"\n    start_time = _time.time()\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if not isinstance(target, str) or target not in dataset.column_names():\n        raise _ToolkitError(\"The 'target' parameter must be the name of a column in the input dataset.\")\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column must contain integers or strings.')\n    if dataset[target].countna() > 0:\n        _logging.warning('Missing values detected in the target column. This ' + \"may lead to ambiguous 'None' predictions, if the \" + \"'radius' parameter is set too small in the prediction, \" + 'classification, or evaluation methods.')\n    if features is None:\n        _features = [x for x in dataset.column_names() if x != target]\n    else:\n        _features = [x for x in features if x != target]\n    if isinstance(distance, list):\n        distance = _copy.deepcopy(distance)\n    elif hasattr(distance, '__call__') or (isinstance(distance, str) and (not distance == 'auto')):\n        distance = [[_features, distance, 1]]\n    elif distance is None or distance == 'auto':\n        col_types = {k: v for (k, v) in zip(dataset.column_names(), dataset.column_types())}\n        distance = _construct_auto_distance(_features, col_types)\n    else:\n        raise TypeError(\"Input 'distance' not understood. The 'distance' \" + 'parameter must be a string or a composite distance, ' + ' or left unspecified.')\n    knn_model = _tc.nearest_neighbors.create(dataset, label=target, distance=distance, verbose=verbose)\n    state = {'verbose': verbose, 'distance': knn_model.distance, 'num_distance_components': knn_model.num_distance_components, 'num_examples': dataset.num_rows(), 'features': knn_model.features, 'target': target, 'num_classes': len(dataset[target].unique()), 'num_features': knn_model.num_features, 'num_unpacked_features': knn_model.num_unpacked_features, 'training_time': _time.time() - start_time, '_target_type': dataset[target].dtype}\n    model = NearestNeighborClassifier(knn_model, state)\n    return model",
            "def create(dataset, target, features=None, distance=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Create a\\n    :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`\\n    model. This model predicts the class of a query instance by finding the most\\n    common class among the query's nearest neighbors.\\n\\n    Parameters\\n    ----------\\n    dataset : SFrame\\n        Dataset for training the model.\\n\\n    target : str\\n        Name of the column containing the target variable. The values in this\\n        column must be of string or integer type.\\n\\n    features : list[str], optional\\n        Name of the columns with features to use in comparing records. 'None'\\n        (the default) indicates that all columns except the target variable\\n        should be used. Please note: if `distance` is specified as a composite\\n        distance, then that parameter controls which features are used in the\\n        model. Each column can be one of the following types:\\n\\n        - *Numeric*: values of numeric type integer or float.\\n\\n        - *Array*: array of numeric (integer or float) values. Each array\\n          element is treated as a separate variable in the model.\\n\\n        - *Dictionary*: key-value pairs with numeric (integer or float) values.\\n          Each key indicates a separate variable in the model.\\n\\n        - *String*: string values.\\n\\n        Please note: if `distance` is specified as a composite distance, then\\n        that parameter controls which features are used in the model.\\n\\n    distance : str, function, or list[list], optional\\n        Function to measure the distance between any two input data rows. This\\n        may be one of three types:\\n\\n        - *String*: the name of a standard distance function. One of\\n          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',\\n          'jaccard', 'weighted_jaccard', 'cosine' or 'transformed_dot_product'.\\n\\n        - *Function*: a function handle from the\\n          :mod:`~turicreate.toolkits.distances` module.\\n\\n        - *Composite distance*: the weighted sum of several standard distance\\n          functions applied to various features. This is specified as a list of\\n          distance components, each of which is itself a list containing three\\n          items:\\n\\n          1. list or tuple of feature names (str)\\n\\n          2. standard distance name (str)\\n\\n          3. scaling factor (int or float)\\n\\n        For more information about Turi Create distance functions, please\\n        see the :py:mod:`~turicreate.toolkits.distances` module.\\n\\n        For sparse vectors, missing keys are assumed to have value 0.0.\\n\\n        If 'distance' is left unspecified or set to 'auto', a composite distance\\n        is constructed automatically based on feature types.\\n\\n    verbose : bool, optional\\n        If True, print progress updates and model details.\\n\\n    Returns\\n    -------\\n    out : NearestNeighborClassifier\\n        A trained model of type\\n        :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`.\\n\\n    See Also\\n    --------\\n    NearestNeighborClassifier\\n    turicreate.toolkits.nearest_neighbors\\n    turicreate.toolkits.distances\\n\\n    References\\n    ----------\\n    - `Wikipedia - nearest neighbors classifier\\n      <http://en.wikipedia.org/wiki/Nearest_neighbour_classifiers>`_\\n\\n    - Hastie, T., Tibshirani, R., Friedman, J. (2009). `The Elements of\\n      Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_.\\n      Vol. 2. New York. Springer. pp. 463-481.\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n    ...                       'height': [9, 25, 20, 23],\\n    ...                       'weight': [13, 28, 33, 22]})\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n\\n    As with the nearest neighbors toolkit, the nearest neighbor classifier\\n    accepts composite distance functions.\\n\\n    >>> my_dist = [[('height', 'weight'), 'euclidean', 2.7],\\n    ...            [('height', 'weight'), 'manhattan', 1.6]]\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species',\\n    ...                                                     distance=my_dist)\\n    \"\n    start_time = _time.time()\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if not isinstance(target, str) or target not in dataset.column_names():\n        raise _ToolkitError(\"The 'target' parameter must be the name of a column in the input dataset.\")\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column must contain integers or strings.')\n    if dataset[target].countna() > 0:\n        _logging.warning('Missing values detected in the target column. This ' + \"may lead to ambiguous 'None' predictions, if the \" + \"'radius' parameter is set too small in the prediction, \" + 'classification, or evaluation methods.')\n    if features is None:\n        _features = [x for x in dataset.column_names() if x != target]\n    else:\n        _features = [x for x in features if x != target]\n    if isinstance(distance, list):\n        distance = _copy.deepcopy(distance)\n    elif hasattr(distance, '__call__') or (isinstance(distance, str) and (not distance == 'auto')):\n        distance = [[_features, distance, 1]]\n    elif distance is None or distance == 'auto':\n        col_types = {k: v for (k, v) in zip(dataset.column_names(), dataset.column_types())}\n        distance = _construct_auto_distance(_features, col_types)\n    else:\n        raise TypeError(\"Input 'distance' not understood. The 'distance' \" + 'parameter must be a string or a composite distance, ' + ' or left unspecified.')\n    knn_model = _tc.nearest_neighbors.create(dataset, label=target, distance=distance, verbose=verbose)\n    state = {'verbose': verbose, 'distance': knn_model.distance, 'num_distance_components': knn_model.num_distance_components, 'num_examples': dataset.num_rows(), 'features': knn_model.features, 'target': target, 'num_classes': len(dataset[target].unique()), 'num_features': knn_model.num_features, 'num_unpacked_features': knn_model.num_unpacked_features, 'training_time': _time.time() - start_time, '_target_type': dataset[target].dtype}\n    model = NearestNeighborClassifier(knn_model, state)\n    return model",
            "def create(dataset, target, features=None, distance=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Create a\\n    :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`\\n    model. This model predicts the class of a query instance by finding the most\\n    common class among the query's nearest neighbors.\\n\\n    Parameters\\n    ----------\\n    dataset : SFrame\\n        Dataset for training the model.\\n\\n    target : str\\n        Name of the column containing the target variable. The values in this\\n        column must be of string or integer type.\\n\\n    features : list[str], optional\\n        Name of the columns with features to use in comparing records. 'None'\\n        (the default) indicates that all columns except the target variable\\n        should be used. Please note: if `distance` is specified as a composite\\n        distance, then that parameter controls which features are used in the\\n        model. Each column can be one of the following types:\\n\\n        - *Numeric*: values of numeric type integer or float.\\n\\n        - *Array*: array of numeric (integer or float) values. Each array\\n          element is treated as a separate variable in the model.\\n\\n        - *Dictionary*: key-value pairs with numeric (integer or float) values.\\n          Each key indicates a separate variable in the model.\\n\\n        - *String*: string values.\\n\\n        Please note: if `distance` is specified as a composite distance, then\\n        that parameter controls which features are used in the model.\\n\\n    distance : str, function, or list[list], optional\\n        Function to measure the distance between any two input data rows. This\\n        may be one of three types:\\n\\n        - *String*: the name of a standard distance function. One of\\n          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',\\n          'jaccard', 'weighted_jaccard', 'cosine' or 'transformed_dot_product'.\\n\\n        - *Function*: a function handle from the\\n          :mod:`~turicreate.toolkits.distances` module.\\n\\n        - *Composite distance*: the weighted sum of several standard distance\\n          functions applied to various features. This is specified as a list of\\n          distance components, each of which is itself a list containing three\\n          items:\\n\\n          1. list or tuple of feature names (str)\\n\\n          2. standard distance name (str)\\n\\n          3. scaling factor (int or float)\\n\\n        For more information about Turi Create distance functions, please\\n        see the :py:mod:`~turicreate.toolkits.distances` module.\\n\\n        For sparse vectors, missing keys are assumed to have value 0.0.\\n\\n        If 'distance' is left unspecified or set to 'auto', a composite distance\\n        is constructed automatically based on feature types.\\n\\n    verbose : bool, optional\\n        If True, print progress updates and model details.\\n\\n    Returns\\n    -------\\n    out : NearestNeighborClassifier\\n        A trained model of type\\n        :class:`~turicreate.nearest_neighbor_classifier.NearestNeighborClassifier`.\\n\\n    See Also\\n    --------\\n    NearestNeighborClassifier\\n    turicreate.toolkits.nearest_neighbors\\n    turicreate.toolkits.distances\\n\\n    References\\n    ----------\\n    - `Wikipedia - nearest neighbors classifier\\n      <http://en.wikipedia.org/wiki/Nearest_neighbour_classifiers>`_\\n\\n    - Hastie, T., Tibshirani, R., Friedman, J. (2009). `The Elements of\\n      Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_.\\n      Vol. 2. New York. Springer. pp. 463-481.\\n\\n    Examples\\n    --------\\n    >>> sf = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n    ...                       'height': [9, 25, 20, 23],\\n    ...                       'weight': [13, 28, 33, 22]})\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n\\n    As with the nearest neighbors toolkit, the nearest neighbor classifier\\n    accepts composite distance functions.\\n\\n    >>> my_dist = [[('height', 'weight'), 'euclidean', 2.7],\\n    ...            [('height', 'weight'), 'manhattan', 1.6]]\\n    ...\\n    >>> model = turicreate.nearest_neighbor_classifier.create(sf, target='species',\\n    ...                                                     distance=my_dist)\\n    \"\n    start_time = _time.time()\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if not isinstance(target, str) or target not in dataset.column_names():\n        raise _ToolkitError(\"The 'target' parameter must be the name of a column in the input dataset.\")\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column must contain integers or strings.')\n    if dataset[target].countna() > 0:\n        _logging.warning('Missing values detected in the target column. This ' + \"may lead to ambiguous 'None' predictions, if the \" + \"'radius' parameter is set too small in the prediction, \" + 'classification, or evaluation methods.')\n    if features is None:\n        _features = [x for x in dataset.column_names() if x != target]\n    else:\n        _features = [x for x in features if x != target]\n    if isinstance(distance, list):\n        distance = _copy.deepcopy(distance)\n    elif hasattr(distance, '__call__') or (isinstance(distance, str) and (not distance == 'auto')):\n        distance = [[_features, distance, 1]]\n    elif distance is None or distance == 'auto':\n        col_types = {k: v for (k, v) in zip(dataset.column_names(), dataset.column_types())}\n        distance = _construct_auto_distance(_features, col_types)\n    else:\n        raise TypeError(\"Input 'distance' not understood. The 'distance' \" + 'parameter must be a string or a composite distance, ' + ' or left unspecified.')\n    knn_model = _tc.nearest_neighbors.create(dataset, label=target, distance=distance, verbose=verbose)\n    state = {'verbose': verbose, 'distance': knn_model.distance, 'num_distance_components': knn_model.num_distance_components, 'num_examples': dataset.num_rows(), 'features': knn_model.features, 'target': target, 'num_classes': len(dataset[target].unique()), 'num_features': knn_model.num_features, 'num_unpacked_features': knn_model.num_unpacked_features, 'training_time': _time.time() - start_time, '_target_type': dataset[target].dtype}\n    model = NearestNeighborClassifier(knn_model, state)\n    return model"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, knn_model, state=None):\n    self.__proxy__ = _PythonProxy(state)\n    assert isinstance(knn_model, _tc.nearest_neighbors.NearestNeighborsModel)\n    self._knn_model = knn_model",
        "mutated": [
            "def __init__(self, knn_model, state=None):\n    if False:\n        i = 10\n    self.__proxy__ = _PythonProxy(state)\n    assert isinstance(knn_model, _tc.nearest_neighbors.NearestNeighborsModel)\n    self._knn_model = knn_model",
            "def __init__(self, knn_model, state=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.__proxy__ = _PythonProxy(state)\n    assert isinstance(knn_model, _tc.nearest_neighbors.NearestNeighborsModel)\n    self._knn_model = knn_model",
            "def __init__(self, knn_model, state=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.__proxy__ = _PythonProxy(state)\n    assert isinstance(knn_model, _tc.nearest_neighbors.NearestNeighborsModel)\n    self._knn_model = knn_model",
            "def __init__(self, knn_model, state=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.__proxy__ = _PythonProxy(state)\n    assert isinstance(knn_model, _tc.nearest_neighbors.NearestNeighborsModel)\n    self._knn_model = knn_model",
            "def __init__(self, knn_model, state=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.__proxy__ = _PythonProxy(state)\n    assert isinstance(knn_model, _tc.nearest_neighbors.NearestNeighborsModel)\n    self._knn_model = knn_model"
        ]
    },
    {
        "func_name": "_native_name",
        "original": "@classmethod\ndef _native_name(cls):\n    return 'nearest_neighbor_classifier'",
        "mutated": [
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n    return 'nearest_neighbor_classifier'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return 'nearest_neighbor_classifier'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return 'nearest_neighbor_classifier'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return 'nearest_neighbor_classifier'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return 'nearest_neighbor_classifier'"
        ]
    },
    {
        "func_name": "_get_version",
        "original": "def _get_version(self):\n    return self._PYTHON_NN_CLASSIFIER_MODEL_VERSION",
        "mutated": [
            "def _get_version(self):\n    if False:\n        i = 10\n    return self._PYTHON_NN_CLASSIFIER_MODEL_VERSION",
            "def _get_version(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self._PYTHON_NN_CLASSIFIER_MODEL_VERSION",
            "def _get_version(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self._PYTHON_NN_CLASSIFIER_MODEL_VERSION",
            "def _get_version(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self._PYTHON_NN_CLASSIFIER_MODEL_VERSION",
            "def _get_version(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self._PYTHON_NN_CLASSIFIER_MODEL_VERSION"
        ]
    },
    {
        "func_name": "_get_native_state",
        "original": "def _get_native_state(self):\n    retstate = self.__proxy__.get_state()\n    retstate['knn_model'] = self._knn_model.__proxy__\n    retstate['_target_type'] = self._target_type.__name__\n    return retstate",
        "mutated": [
            "def _get_native_state(self):\n    if False:\n        i = 10\n    retstate = self.__proxy__.get_state()\n    retstate['knn_model'] = self._knn_model.__proxy__\n    retstate['_target_type'] = self._target_type.__name__\n    return retstate",
            "def _get_native_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    retstate = self.__proxy__.get_state()\n    retstate['knn_model'] = self._knn_model.__proxy__\n    retstate['_target_type'] = self._target_type.__name__\n    return retstate",
            "def _get_native_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    retstate = self.__proxy__.get_state()\n    retstate['knn_model'] = self._knn_model.__proxy__\n    retstate['_target_type'] = self._target_type.__name__\n    return retstate",
            "def _get_native_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    retstate = self.__proxy__.get_state()\n    retstate['knn_model'] = self._knn_model.__proxy__\n    retstate['_target_type'] = self._target_type.__name__\n    return retstate",
            "def _get_native_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    retstate = self.__proxy__.get_state()\n    retstate['knn_model'] = self._knn_model.__proxy__\n    retstate['_target_type'] = self._target_type.__name__\n    return retstate"
        ]
    },
    {
        "func_name": "_load_version",
        "original": "@classmethod\ndef _load_version(cls, state, version):\n    \"\"\"\n        A function to load a previously saved NearestNeighborClassifier model.\n\n        Parameters\n        ----------\n        unpickler : GLUnpickler\n            A GLUnpickler file handler.\n\n        version : int\n            Version number maintained by the class writer.\n        \"\"\"\n    assert version == cls._PYTHON_NN_CLASSIFIER_MODEL_VERSION\n    knn_model = _tc.nearest_neighbors.NearestNeighborsModel(state['knn_model'])\n    del state['knn_model']\n    state['_target_type'] = eval(state['_target_type'])\n    return cls(knn_model, state)",
        "mutated": [
            "@classmethod\ndef _load_version(cls, state, version):\n    if False:\n        i = 10\n    '\\n        A function to load a previously saved NearestNeighborClassifier model.\\n\\n        Parameters\\n        ----------\\n        unpickler : GLUnpickler\\n            A GLUnpickler file handler.\\n\\n        version : int\\n            Version number maintained by the class writer.\\n        '\n    assert version == cls._PYTHON_NN_CLASSIFIER_MODEL_VERSION\n    knn_model = _tc.nearest_neighbors.NearestNeighborsModel(state['knn_model'])\n    del state['knn_model']\n    state['_target_type'] = eval(state['_target_type'])\n    return cls(knn_model, state)",
            "@classmethod\ndef _load_version(cls, state, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        A function to load a previously saved NearestNeighborClassifier model.\\n\\n        Parameters\\n        ----------\\n        unpickler : GLUnpickler\\n            A GLUnpickler file handler.\\n\\n        version : int\\n            Version number maintained by the class writer.\\n        '\n    assert version == cls._PYTHON_NN_CLASSIFIER_MODEL_VERSION\n    knn_model = _tc.nearest_neighbors.NearestNeighborsModel(state['knn_model'])\n    del state['knn_model']\n    state['_target_type'] = eval(state['_target_type'])\n    return cls(knn_model, state)",
            "@classmethod\ndef _load_version(cls, state, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        A function to load a previously saved NearestNeighborClassifier model.\\n\\n        Parameters\\n        ----------\\n        unpickler : GLUnpickler\\n            A GLUnpickler file handler.\\n\\n        version : int\\n            Version number maintained by the class writer.\\n        '\n    assert version == cls._PYTHON_NN_CLASSIFIER_MODEL_VERSION\n    knn_model = _tc.nearest_neighbors.NearestNeighborsModel(state['knn_model'])\n    del state['knn_model']\n    state['_target_type'] = eval(state['_target_type'])\n    return cls(knn_model, state)",
            "@classmethod\ndef _load_version(cls, state, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        A function to load a previously saved NearestNeighborClassifier model.\\n\\n        Parameters\\n        ----------\\n        unpickler : GLUnpickler\\n            A GLUnpickler file handler.\\n\\n        version : int\\n            Version number maintained by the class writer.\\n        '\n    assert version == cls._PYTHON_NN_CLASSIFIER_MODEL_VERSION\n    knn_model = _tc.nearest_neighbors.NearestNeighborsModel(state['knn_model'])\n    del state['knn_model']\n    state['_target_type'] = eval(state['_target_type'])\n    return cls(knn_model, state)",
            "@classmethod\ndef _load_version(cls, state, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        A function to load a previously saved NearestNeighborClassifier model.\\n\\n        Parameters\\n        ----------\\n        unpickler : GLUnpickler\\n            A GLUnpickler file handler.\\n\\n        version : int\\n            Version number maintained by the class writer.\\n        '\n    assert version == cls._PYTHON_NN_CLASSIFIER_MODEL_VERSION\n    knn_model = _tc.nearest_neighbors.NearestNeighborsModel(state['knn_model'])\n    del state['knn_model']\n    state['_target_type'] = eval(state['_target_type'])\n    return cls(knn_model, state)"
        ]
    },
    {
        "func_name": "__repr__",
        "original": "def __repr__(self):\n    \"\"\"\n        Print a string description of the model when the model name is entered\n        in the terminal.\n        \"\"\"\n    (sections, section_titles) = self._get_summary_struct()\n    out = _toolkit_repr_print(self, sections, section_titles, width=36)\n    return out",
        "mutated": [
            "def __repr__(self):\n    if False:\n        i = 10\n    '\\n        Print a string description of the model when the model name is entered\\n        in the terminal.\\n        '\n    (sections, section_titles) = self._get_summary_struct()\n    out = _toolkit_repr_print(self, sections, section_titles, width=36)\n    return out",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Print a string description of the model when the model name is entered\\n        in the terminal.\\n        '\n    (sections, section_titles) = self._get_summary_struct()\n    out = _toolkit_repr_print(self, sections, section_titles, width=36)\n    return out",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Print a string description of the model when the model name is entered\\n        in the terminal.\\n        '\n    (sections, section_titles) = self._get_summary_struct()\n    out = _toolkit_repr_print(self, sections, section_titles, width=36)\n    return out",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Print a string description of the model when the model name is entered\\n        in the terminal.\\n        '\n    (sections, section_titles) = self._get_summary_struct()\n    out = _toolkit_repr_print(self, sections, section_titles, width=36)\n    return out",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Print a string description of the model when the model name is entered\\n        in the terminal.\\n        '\n    (sections, section_titles) = self._get_summary_struct()\n    out = _toolkit_repr_print(self, sections, section_titles, width=36)\n    return out"
        ]
    },
    {
        "func_name": "__str__",
        "original": "def __str__(self):\n    \"\"\"\n        Return a string description of the model to the ``print`` method.\n\n        Returns\n        -------\n        out : str\n            A description of the NearestNeighborClassifier model.\n        \"\"\"\n    return self.__repr__()",
        "mutated": [
            "def __str__(self):\n    if False:\n        i = 10\n    '\\n        Return a string description of the model to the ``print`` method.\\n\\n        Returns\\n        -------\\n        out : str\\n            A description of the NearestNeighborClassifier model.\\n        '\n    return self.__repr__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return a string description of the model to the ``print`` method.\\n\\n        Returns\\n        -------\\n        out : str\\n            A description of the NearestNeighborClassifier model.\\n        '\n    return self.__repr__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return a string description of the model to the ``print`` method.\\n\\n        Returns\\n        -------\\n        out : str\\n            A description of the NearestNeighborClassifier model.\\n        '\n    return self.__repr__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return a string description of the model to the ``print`` method.\\n\\n        Returns\\n        -------\\n        out : str\\n            A description of the NearestNeighborClassifier model.\\n        '\n    return self.__repr__()",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return a string description of the model to the ``print`` method.\\n\\n        Returns\\n        -------\\n        out : str\\n            A description of the NearestNeighborClassifier model.\\n        '\n    return self.__repr__()"
        ]
    },
    {
        "func_name": "_get_summary_struct",
        "original": "def _get_summary_struct(self):\n    \"\"\"\n        Returns a structured description of the model, including (where relevant)\n        the schema of the training data, description of the training data,\n        training statistics, and model hyperparameters.\n\n        Returns\n        -------\n        sections : list (of list of tuples)\n            A list of summary sections.\n              Each section is a list.\n                Each item in a section list is a tuple of the form:\n                  ('<label>','<field>')\n        section_titles: list\n            A list of section titles.\n              The order matches that of the 'sections' object.\n        \"\"\"\n    model_fields = [('Number of examples', 'num_examples'), ('Number of feature columns', 'num_features'), ('Number of unpacked features', 'num_unpacked_features'), ('Number of distance components', 'num_distance_components'), ('Number of classes', 'num_classes')]\n    training_fields = [('Training time (seconds)', 'training_time')]\n    section_titles = ['Schema', 'Training Summary']\n    return ([model_fields, training_fields], section_titles)",
        "mutated": [
            "def _get_summary_struct(self):\n    if False:\n        i = 10\n    \"\\n        Returns a structured description of the model, including (where relevant)\\n        the schema of the training data, description of the training data,\\n        training statistics, and model hyperparameters.\\n\\n        Returns\\n        -------\\n        sections : list (of list of tuples)\\n            A list of summary sections.\\n              Each section is a list.\\n                Each item in a section list is a tuple of the form:\\n                  ('<label>','<field>')\\n        section_titles: list\\n            A list of section titles.\\n              The order matches that of the 'sections' object.\\n        \"\n    model_fields = [('Number of examples', 'num_examples'), ('Number of feature columns', 'num_features'), ('Number of unpacked features', 'num_unpacked_features'), ('Number of distance components', 'num_distance_components'), ('Number of classes', 'num_classes')]\n    training_fields = [('Training time (seconds)', 'training_time')]\n    section_titles = ['Schema', 'Training Summary']\n    return ([model_fields, training_fields], section_titles)",
            "def _get_summary_struct(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns a structured description of the model, including (where relevant)\\n        the schema of the training data, description of the training data,\\n        training statistics, and model hyperparameters.\\n\\n        Returns\\n        -------\\n        sections : list (of list of tuples)\\n            A list of summary sections.\\n              Each section is a list.\\n                Each item in a section list is a tuple of the form:\\n                  ('<label>','<field>')\\n        section_titles: list\\n            A list of section titles.\\n              The order matches that of the 'sections' object.\\n        \"\n    model_fields = [('Number of examples', 'num_examples'), ('Number of feature columns', 'num_features'), ('Number of unpacked features', 'num_unpacked_features'), ('Number of distance components', 'num_distance_components'), ('Number of classes', 'num_classes')]\n    training_fields = [('Training time (seconds)', 'training_time')]\n    section_titles = ['Schema', 'Training Summary']\n    return ([model_fields, training_fields], section_titles)",
            "def _get_summary_struct(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns a structured description of the model, including (where relevant)\\n        the schema of the training data, description of the training data,\\n        training statistics, and model hyperparameters.\\n\\n        Returns\\n        -------\\n        sections : list (of list of tuples)\\n            A list of summary sections.\\n              Each section is a list.\\n                Each item in a section list is a tuple of the form:\\n                  ('<label>','<field>')\\n        section_titles: list\\n            A list of section titles.\\n              The order matches that of the 'sections' object.\\n        \"\n    model_fields = [('Number of examples', 'num_examples'), ('Number of feature columns', 'num_features'), ('Number of unpacked features', 'num_unpacked_features'), ('Number of distance components', 'num_distance_components'), ('Number of classes', 'num_classes')]\n    training_fields = [('Training time (seconds)', 'training_time')]\n    section_titles = ['Schema', 'Training Summary']\n    return ([model_fields, training_fields], section_titles)",
            "def _get_summary_struct(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns a structured description of the model, including (where relevant)\\n        the schema of the training data, description of the training data,\\n        training statistics, and model hyperparameters.\\n\\n        Returns\\n        -------\\n        sections : list (of list of tuples)\\n            A list of summary sections.\\n              Each section is a list.\\n                Each item in a section list is a tuple of the form:\\n                  ('<label>','<field>')\\n        section_titles: list\\n            A list of section titles.\\n              The order matches that of the 'sections' object.\\n        \"\n    model_fields = [('Number of examples', 'num_examples'), ('Number of feature columns', 'num_features'), ('Number of unpacked features', 'num_unpacked_features'), ('Number of distance components', 'num_distance_components'), ('Number of classes', 'num_classes')]\n    training_fields = [('Training time (seconds)', 'training_time')]\n    section_titles = ['Schema', 'Training Summary']\n    return ([model_fields, training_fields], section_titles)",
            "def _get_summary_struct(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns a structured description of the model, including (where relevant)\\n        the schema of the training data, description of the training data,\\n        training statistics, and model hyperparameters.\\n\\n        Returns\\n        -------\\n        sections : list (of list of tuples)\\n            A list of summary sections.\\n              Each section is a list.\\n                Each item in a section list is a tuple of the form:\\n                  ('<label>','<field>')\\n        section_titles: list\\n            A list of section titles.\\n              The order matches that of the 'sections' object.\\n        \"\n    model_fields = [('Number of examples', 'num_examples'), ('Number of feature columns', 'num_features'), ('Number of unpacked features', 'num_unpacked_features'), ('Number of distance components', 'num_distance_components'), ('Number of classes', 'num_classes')]\n    training_fields = [('Training time (seconds)', 'training_time')]\n    section_titles = ['Schema', 'Training Summary']\n    return ([model_fields, training_fields], section_titles)"
        ]
    },
    {
        "func_name": "classify",
        "original": "def classify(self, dataset, max_neighbors=10, radius=None, verbose=True):\n    \"\"\"\n        Return the predicted class for each observation in *dataset*. This\n        prediction is made based on the closest neighbors stored in the nearest\n        neighbors classifier model.\n\n        Parameters\n        ----------\n        dataset : SFrame\n            Dataset of new observations. Must include columns with the same\n            names as the features used for model training, but does not require\n            a target column. Additional columns are ignored.\n\n        verbose : bool, optional\n            If True, print progress updates.\n\n        max_neighbors : int, optional\n            Maximum number of neighbors to consider for each point.\n\n        radius : float, optional\n            Maximum distance from each point to a neighbor in the reference\n            dataset.\n\n        Returns\n        -------\n        out : SFrame\n            An SFrame with model predictions. The first column is the most\n            likely class according to the model, and the second column is the\n            predicted probability for that class.\n\n        See Also\n        --------\n        create, predict, predict_topk\n\n        Notes\n        -----\n        - If the 'radius' parameter is small, it is possible that a query point\n          has no qualified neighbors in the training dataset. In this case, the\n          resulting class and probability for that query are 'None' in the\n          SFrame output by this method. If the target column in the training\n          dataset has missing values, these predictions will be ambiguous.\n\n        - Ties between predicted classes are broken randomly.\n\n        Examples\n        --------\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\n        ...                             'height': [9, 25, 20, 23],\n        ...                             'weight': [13, 28, 33, 22]})\n        ...\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\n        ...                           'weight': [25, 35]})\n        ...\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\n        >>> ystar = m.classify(sf_new, max_neighbors=2)\n        >>> print ystar\n        +-------+-------------+\n        | class | probability |\n        +-------+-------------+\n        |  dog  |     1.0     |\n        | fossa |     0.5     |\n        +-------+-------------+\n        \"\"\"\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    n_query = dataset.num_rows()\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'class': _tc.SArray([None] * n_query, self._target_type), 'probability': _tc.SArray([None] * n_query, int)})\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.groupby('query_label', {'class': _tc.aggregate.ARGMAX('Count', 'reference_label'), 'max_votes': _tc.aggregate.MAX('Count'), 'total_votes': _tc.aggregate.SUM('Count')})\n        ystar['probability'] = ystar['max_votes'] / ystar['total_votes']\n        row_ids = _tc.SFrame({'query_label': range(n_query)})\n        ystar = ystar.join(row_ids, how='right')\n        ystar = ystar.sort('query_label', ascending=True)\n        ystar = ystar[['class', 'probability']]\n    return ystar",
        "mutated": [
            "def classify(self, dataset, max_neighbors=10, radius=None, verbose=True):\n    if False:\n        i = 10\n    \"\\n        Return the predicted class for each observation in *dataset*. This\\n        prediction is made based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the features used for model training, but does not require\\n            a target column. Additional columns are ignored.\\n\\n        verbose : bool, optional\\n            If True, print progress updates.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame with model predictions. The first column is the most\\n            likely class according to the model, and the second column is the\\n            predicted probability for that class.\\n\\n        See Also\\n        --------\\n        create, predict, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          resulting class and probability for that query are 'None' in the\\n          SFrame output by this method. If the target column in the training\\n          dataset has missing values, these predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.classify(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +-------+-------------+\\n        | class | probability |\\n        +-------+-------------+\\n        |  dog  |     1.0     |\\n        | fossa |     0.5     |\\n        +-------+-------------+\\n        \"\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    n_query = dataset.num_rows()\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'class': _tc.SArray([None] * n_query, self._target_type), 'probability': _tc.SArray([None] * n_query, int)})\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.groupby('query_label', {'class': _tc.aggregate.ARGMAX('Count', 'reference_label'), 'max_votes': _tc.aggregate.MAX('Count'), 'total_votes': _tc.aggregate.SUM('Count')})\n        ystar['probability'] = ystar['max_votes'] / ystar['total_votes']\n        row_ids = _tc.SFrame({'query_label': range(n_query)})\n        ystar = ystar.join(row_ids, how='right')\n        ystar = ystar.sort('query_label', ascending=True)\n        ystar = ystar[['class', 'probability']]\n    return ystar",
            "def classify(self, dataset, max_neighbors=10, radius=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Return the predicted class for each observation in *dataset*. This\\n        prediction is made based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the features used for model training, but does not require\\n            a target column. Additional columns are ignored.\\n\\n        verbose : bool, optional\\n            If True, print progress updates.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame with model predictions. The first column is the most\\n            likely class according to the model, and the second column is the\\n            predicted probability for that class.\\n\\n        See Also\\n        --------\\n        create, predict, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          resulting class and probability for that query are 'None' in the\\n          SFrame output by this method. If the target column in the training\\n          dataset has missing values, these predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.classify(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +-------+-------------+\\n        | class | probability |\\n        +-------+-------------+\\n        |  dog  |     1.0     |\\n        | fossa |     0.5     |\\n        +-------+-------------+\\n        \"\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    n_query = dataset.num_rows()\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'class': _tc.SArray([None] * n_query, self._target_type), 'probability': _tc.SArray([None] * n_query, int)})\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.groupby('query_label', {'class': _tc.aggregate.ARGMAX('Count', 'reference_label'), 'max_votes': _tc.aggregate.MAX('Count'), 'total_votes': _tc.aggregate.SUM('Count')})\n        ystar['probability'] = ystar['max_votes'] / ystar['total_votes']\n        row_ids = _tc.SFrame({'query_label': range(n_query)})\n        ystar = ystar.join(row_ids, how='right')\n        ystar = ystar.sort('query_label', ascending=True)\n        ystar = ystar[['class', 'probability']]\n    return ystar",
            "def classify(self, dataset, max_neighbors=10, radius=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Return the predicted class for each observation in *dataset*. This\\n        prediction is made based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the features used for model training, but does not require\\n            a target column. Additional columns are ignored.\\n\\n        verbose : bool, optional\\n            If True, print progress updates.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame with model predictions. The first column is the most\\n            likely class according to the model, and the second column is the\\n            predicted probability for that class.\\n\\n        See Also\\n        --------\\n        create, predict, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          resulting class and probability for that query are 'None' in the\\n          SFrame output by this method. If the target column in the training\\n          dataset has missing values, these predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.classify(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +-------+-------------+\\n        | class | probability |\\n        +-------+-------------+\\n        |  dog  |     1.0     |\\n        | fossa |     0.5     |\\n        +-------+-------------+\\n        \"\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    n_query = dataset.num_rows()\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'class': _tc.SArray([None] * n_query, self._target_type), 'probability': _tc.SArray([None] * n_query, int)})\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.groupby('query_label', {'class': _tc.aggregate.ARGMAX('Count', 'reference_label'), 'max_votes': _tc.aggregate.MAX('Count'), 'total_votes': _tc.aggregate.SUM('Count')})\n        ystar['probability'] = ystar['max_votes'] / ystar['total_votes']\n        row_ids = _tc.SFrame({'query_label': range(n_query)})\n        ystar = ystar.join(row_ids, how='right')\n        ystar = ystar.sort('query_label', ascending=True)\n        ystar = ystar[['class', 'probability']]\n    return ystar",
            "def classify(self, dataset, max_neighbors=10, radius=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Return the predicted class for each observation in *dataset*. This\\n        prediction is made based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the features used for model training, but does not require\\n            a target column. Additional columns are ignored.\\n\\n        verbose : bool, optional\\n            If True, print progress updates.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame with model predictions. The first column is the most\\n            likely class according to the model, and the second column is the\\n            predicted probability for that class.\\n\\n        See Also\\n        --------\\n        create, predict, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          resulting class and probability for that query are 'None' in the\\n          SFrame output by this method. If the target column in the training\\n          dataset has missing values, these predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.classify(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +-------+-------------+\\n        | class | probability |\\n        +-------+-------------+\\n        |  dog  |     1.0     |\\n        | fossa |     0.5     |\\n        +-------+-------------+\\n        \"\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    n_query = dataset.num_rows()\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'class': _tc.SArray([None] * n_query, self._target_type), 'probability': _tc.SArray([None] * n_query, int)})\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.groupby('query_label', {'class': _tc.aggregate.ARGMAX('Count', 'reference_label'), 'max_votes': _tc.aggregate.MAX('Count'), 'total_votes': _tc.aggregate.SUM('Count')})\n        ystar['probability'] = ystar['max_votes'] / ystar['total_votes']\n        row_ids = _tc.SFrame({'query_label': range(n_query)})\n        ystar = ystar.join(row_ids, how='right')\n        ystar = ystar.sort('query_label', ascending=True)\n        ystar = ystar[['class', 'probability']]\n    return ystar",
            "def classify(self, dataset, max_neighbors=10, radius=None, verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Return the predicted class for each observation in *dataset*. This\\n        prediction is made based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the features used for model training, but does not require\\n            a target column. Additional columns are ignored.\\n\\n        verbose : bool, optional\\n            If True, print progress updates.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n            An SFrame with model predictions. The first column is the most\\n            likely class according to the model, and the second column is the\\n            predicted probability for that class.\\n\\n        See Also\\n        --------\\n        create, predict, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          resulting class and probability for that query are 'None' in the\\n          SFrame output by this method. If the target column in the training\\n          dataset has missing values, these predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.classify(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +-------+-------------+\\n        | class | probability |\\n        +-------+-------------+\\n        |  dog  |     1.0     |\\n        | fossa |     0.5     |\\n        +-------+-------------+\\n        \"\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    n_query = dataset.num_rows()\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'class': _tc.SArray([None] * n_query, self._target_type), 'probability': _tc.SArray([None] * n_query, int)})\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.groupby('query_label', {'class': _tc.aggregate.ARGMAX('Count', 'reference_label'), 'max_votes': _tc.aggregate.MAX('Count'), 'total_votes': _tc.aggregate.SUM('Count')})\n        ystar['probability'] = ystar['max_votes'] / ystar['total_votes']\n        row_ids = _tc.SFrame({'query_label': range(n_query)})\n        ystar = ystar.join(row_ids, how='right')\n        ystar = ystar.sort('query_label', ascending=True)\n        ystar = ystar[['class', 'probability']]\n    return ystar"
        ]
    },
    {
        "func_name": "predict",
        "original": "def predict(self, dataset, max_neighbors=10, radius=None, output_type='class', verbose=True):\n    \"\"\"\n        Return predicted class labels for instances in *dataset*. This model\n        makes predictions based on the closest neighbors stored in the nearest\n        neighbors classifier model.\n\n        Parameters\n        ----------\n        dataset : SFrame\n            Dataset of new observations. Must include the features used for\n            model training, but does not require a target column. Additional\n            columns are ignored.\n\n        max_neighbors : int, optional\n            Maximum number of neighbors to consider for each point.\n\n        radius : float, optional\n            Maximum distance from each point to a neighbor in the reference\n            dataset.\n\n        output_type : {'class', 'probability'}, optional\n            Type of prediction output:\n\n            - `class`: Predicted class label. The class with the maximum number\n              of votes among the nearest neighbors in the reference dataset.\n\n            - `probability`: Maximum number of votes for any class out of all\n              nearest neighbors in the reference dataset.\n\n        Returns\n        -------\n        out : SArray\n            An SArray with model predictions.\n\n        See Also\n        ----------\n        create, classify, predict_topk\n\n        Notes\n        -----\n        - If the 'radius' parameter is small, it is possible that a query point\n          has no qualified neighbors in the training dataset. In this case, the\n          result for that query is 'None' in the SArray output by this method.\n          If the target column in the training dataset has missing values, these\n          predictions will be ambiguous.\n\n        - Ties between predicted classes are broken randomly.\n\n        Examples\n        --------\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\n        ...                             'height': [9, 25, 20, 23],\n        ...                             'weight': [13, 28, 33, 22]})\n        ...\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\n        ...                           'weight': [25, 35]})\n        ...\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\n        >>> ystar = m.predict(sf_new, max_neighbors=2, output_type='class')\n        >>> print ystar\n        ['dog', 'fossa']\n        \"\"\"\n    ystar = self.classify(dataset=dataset, max_neighbors=max_neighbors, radius=radius, verbose=verbose)\n    if output_type == 'class':\n        return ystar['class']\n    elif output_type == 'probability':\n        return ystar['probability']\n    else:\n        raise ValueError(\"Input 'output_type' not understood. 'output_type' must be either 'class' or 'probability'.\")",
        "mutated": [
            "def predict(self, dataset, max_neighbors=10, radius=None, output_type='class', verbose=True):\n    if False:\n        i = 10\n    \"\\n        Return predicted class labels for instances in *dataset*. This model\\n        makes predictions based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        output_type : {'class', 'probability'}, optional\\n            Type of prediction output:\\n\\n            - `class`: Predicted class label. The class with the maximum number\\n              of votes among the nearest neighbors in the reference dataset.\\n\\n            - `probability`: Maximum number of votes for any class out of all\\n              nearest neighbors in the reference dataset.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            An SArray with model predictions.\\n\\n        See Also\\n        ----------\\n        create, classify, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          result for that query is 'None' in the SArray output by this method.\\n          If the target column in the training dataset has missing values, these\\n          predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.predict(sf_new, max_neighbors=2, output_type='class')\\n        >>> print ystar\\n        ['dog', 'fossa']\\n        \"\n    ystar = self.classify(dataset=dataset, max_neighbors=max_neighbors, radius=radius, verbose=verbose)\n    if output_type == 'class':\n        return ystar['class']\n    elif output_type == 'probability':\n        return ystar['probability']\n    else:\n        raise ValueError(\"Input 'output_type' not understood. 'output_type' must be either 'class' or 'probability'.\")",
            "def predict(self, dataset, max_neighbors=10, radius=None, output_type='class', verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Return predicted class labels for instances in *dataset*. This model\\n        makes predictions based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        output_type : {'class', 'probability'}, optional\\n            Type of prediction output:\\n\\n            - `class`: Predicted class label. The class with the maximum number\\n              of votes among the nearest neighbors in the reference dataset.\\n\\n            - `probability`: Maximum number of votes for any class out of all\\n              nearest neighbors in the reference dataset.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            An SArray with model predictions.\\n\\n        See Also\\n        ----------\\n        create, classify, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          result for that query is 'None' in the SArray output by this method.\\n          If the target column in the training dataset has missing values, these\\n          predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.predict(sf_new, max_neighbors=2, output_type='class')\\n        >>> print ystar\\n        ['dog', 'fossa']\\n        \"\n    ystar = self.classify(dataset=dataset, max_neighbors=max_neighbors, radius=radius, verbose=verbose)\n    if output_type == 'class':\n        return ystar['class']\n    elif output_type == 'probability':\n        return ystar['probability']\n    else:\n        raise ValueError(\"Input 'output_type' not understood. 'output_type' must be either 'class' or 'probability'.\")",
            "def predict(self, dataset, max_neighbors=10, radius=None, output_type='class', verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Return predicted class labels for instances in *dataset*. This model\\n        makes predictions based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        output_type : {'class', 'probability'}, optional\\n            Type of prediction output:\\n\\n            - `class`: Predicted class label. The class with the maximum number\\n              of votes among the nearest neighbors in the reference dataset.\\n\\n            - `probability`: Maximum number of votes for any class out of all\\n              nearest neighbors in the reference dataset.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            An SArray with model predictions.\\n\\n        See Also\\n        ----------\\n        create, classify, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          result for that query is 'None' in the SArray output by this method.\\n          If the target column in the training dataset has missing values, these\\n          predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.predict(sf_new, max_neighbors=2, output_type='class')\\n        >>> print ystar\\n        ['dog', 'fossa']\\n        \"\n    ystar = self.classify(dataset=dataset, max_neighbors=max_neighbors, radius=radius, verbose=verbose)\n    if output_type == 'class':\n        return ystar['class']\n    elif output_type == 'probability':\n        return ystar['probability']\n    else:\n        raise ValueError(\"Input 'output_type' not understood. 'output_type' must be either 'class' or 'probability'.\")",
            "def predict(self, dataset, max_neighbors=10, radius=None, output_type='class', verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Return predicted class labels for instances in *dataset*. This model\\n        makes predictions based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        output_type : {'class', 'probability'}, optional\\n            Type of prediction output:\\n\\n            - `class`: Predicted class label. The class with the maximum number\\n              of votes among the nearest neighbors in the reference dataset.\\n\\n            - `probability`: Maximum number of votes for any class out of all\\n              nearest neighbors in the reference dataset.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            An SArray with model predictions.\\n\\n        See Also\\n        ----------\\n        create, classify, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          result for that query is 'None' in the SArray output by this method.\\n          If the target column in the training dataset has missing values, these\\n          predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.predict(sf_new, max_neighbors=2, output_type='class')\\n        >>> print ystar\\n        ['dog', 'fossa']\\n        \"\n    ystar = self.classify(dataset=dataset, max_neighbors=max_neighbors, radius=radius, verbose=verbose)\n    if output_type == 'class':\n        return ystar['class']\n    elif output_type == 'probability':\n        return ystar['probability']\n    else:\n        raise ValueError(\"Input 'output_type' not understood. 'output_type' must be either 'class' or 'probability'.\")",
            "def predict(self, dataset, max_neighbors=10, radius=None, output_type='class', verbose=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Return predicted class labels for instances in *dataset*. This model\\n        makes predictions based on the closest neighbors stored in the nearest\\n        neighbors classifier model.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        output_type : {'class', 'probability'}, optional\\n            Type of prediction output:\\n\\n            - `class`: Predicted class label. The class with the maximum number\\n              of votes among the nearest neighbors in the reference dataset.\\n\\n            - `probability`: Maximum number of votes for any class out of all\\n              nearest neighbors in the reference dataset.\\n\\n        Returns\\n        -------\\n        out : SArray\\n            An SArray with model predictions.\\n\\n        See Also\\n        ----------\\n        create, classify, predict_topk\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no qualified neighbors in the training dataset. In this case, the\\n          result for that query is 'None' in the SArray output by this method.\\n          If the target column in the training dataset has missing values, these\\n          predictions will be ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ystar = m.predict(sf_new, max_neighbors=2, output_type='class')\\n        >>> print ystar\\n        ['dog', 'fossa']\\n        \"\n    ystar = self.classify(dataset=dataset, max_neighbors=max_neighbors, radius=radius, verbose=verbose)\n    if output_type == 'class':\n        return ystar['class']\n    elif output_type == 'probability':\n        return ystar['probability']\n    else:\n        raise ValueError(\"Input 'output_type' not understood. 'output_type' must be either 'class' or 'probability'.\")"
        ]
    },
    {
        "func_name": "predict_topk",
        "original": "def predict_topk(self, dataset, max_neighbors=10, radius=None, k=3, verbose=False):\n    \"\"\"\n        Return top-k most likely predictions for each observation in\n        ``dataset``. Predictions are returned as an SFrame with three columns:\n        `row_id`, `class`, and `probability`.\n\n        Parameters\n        ----------\n        dataset : SFrame\n            Dataset of new observations. Must include the features used for\n            model training, but does not require a target column. Additional\n            columns are ignored.\n\n        max_neighbors : int, optional\n            Maximum number of neighbors to consider for each point.\n\n        radius : float, optional\n            Maximum distance from each point to a neighbor in the reference\n            dataset.\n\n        k : int, optional\n            Number of classes to return for each input example.\n\n        Returns\n        -------\n        out : SFrame\n\n        See Also\n        ----------\n        create, classify, predict\n\n        Notes\n        -----\n        - If the 'radius' parameter is small, it is possible that a query point\n          has no neighbors in the training dataset. In this case, the query is\n          dropped from the SFrame output by this method. If all queries have no\n          neighbors, then the result is an empty SFrame. If the target column in\n          the training dataset has missing values, these predictions will be\n          ambiguous.\n\n        - Ties between predicted classes are broken randomly.\n\n        Examples\n        --------\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\n        ...                             'height': [9, 25, 20, 23],\n        ...                             'weight': [13, 28, 33, 22]})\n        ...\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\n        ...                           'weight': [25, 35]})\n        ...\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf_train, target='species')\n        >>> ystar = m.predict_topk(sf_new, max_neighbors=2)\n        >>> print ystar\n        +--------+-------+-------------+\n        | row_id | class | probability |\n        +--------+-------+-------------+\n        |   0    |  dog  |     1.0     |\n        |   1    | fossa |     0.5     |\n        |   1    |  dog  |     0.5     |\n        +--------+-------+-------------+\n        \"\"\"\n    if not isinstance(k, int) or k < 1:\n        raise TypeError('The number of results to return for each point, ' + \"'k', must be an integer greater than 0.\")\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'row_id': [], 'class': [], 'probability': []})\n        ystar['row_id'] = ystar['row_id'].astype(int)\n        ystar['class'] = ystar['class'].astype(str)\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.unstack(column_names=['reference_label', 'Count'], new_column_name='votes')\n        ystar['topk'] = ystar['votes'].apply(lambda x: _sort_topk_votes(x, k))\n        ystar['total_votes'] = ystar['votes'].apply(lambda x: sum(x.values()))\n        ystar = ystar.stack('topk', new_column_name='topk')\n        ystar = ystar.unpack('topk')\n        ystar.rename({'topk.class': 'class', 'query_label': 'row_id'}, inplace=True)\n        ystar['probability'] = ystar['topk.votes'] / ystar['total_votes']\n        ystar = ystar[['row_id', 'class', 'probability']]\n    return ystar",
        "mutated": [
            "def predict_topk(self, dataset, max_neighbors=10, radius=None, k=3, verbose=False):\n    if False:\n        i = 10\n    \"\\n        Return top-k most likely predictions for each observation in\\n        ``dataset``. Predictions are returned as an SFrame with three columns:\\n        `row_id`, `class`, and `probability`.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        k : int, optional\\n            Number of classes to return for each input example.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        ----------\\n        create, classify, predict\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no neighbors in the training dataset. In this case, the query is\\n          dropped from the SFrame output by this method. If all queries have no\\n          neighbors, then the result is an empty SFrame. If the target column in\\n          the training dataset has missing values, these predictions will be\\n          ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf_train, target='species')\\n        >>> ystar = m.predict_topk(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +--------+-------+-------------+\\n        | row_id | class | probability |\\n        +--------+-------+-------------+\\n        |   0    |  dog  |     1.0     |\\n        |   1    | fossa |     0.5     |\\n        |   1    |  dog  |     0.5     |\\n        +--------+-------+-------------+\\n        \"\n    if not isinstance(k, int) or k < 1:\n        raise TypeError('The number of results to return for each point, ' + \"'k', must be an integer greater than 0.\")\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'row_id': [], 'class': [], 'probability': []})\n        ystar['row_id'] = ystar['row_id'].astype(int)\n        ystar['class'] = ystar['class'].astype(str)\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.unstack(column_names=['reference_label', 'Count'], new_column_name='votes')\n        ystar['topk'] = ystar['votes'].apply(lambda x: _sort_topk_votes(x, k))\n        ystar['total_votes'] = ystar['votes'].apply(lambda x: sum(x.values()))\n        ystar = ystar.stack('topk', new_column_name='topk')\n        ystar = ystar.unpack('topk')\n        ystar.rename({'topk.class': 'class', 'query_label': 'row_id'}, inplace=True)\n        ystar['probability'] = ystar['topk.votes'] / ystar['total_votes']\n        ystar = ystar[['row_id', 'class', 'probability']]\n    return ystar",
            "def predict_topk(self, dataset, max_neighbors=10, radius=None, k=3, verbose=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Return top-k most likely predictions for each observation in\\n        ``dataset``. Predictions are returned as an SFrame with three columns:\\n        `row_id`, `class`, and `probability`.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        k : int, optional\\n            Number of classes to return for each input example.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        ----------\\n        create, classify, predict\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no neighbors in the training dataset. In this case, the query is\\n          dropped from the SFrame output by this method. If all queries have no\\n          neighbors, then the result is an empty SFrame. If the target column in\\n          the training dataset has missing values, these predictions will be\\n          ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf_train, target='species')\\n        >>> ystar = m.predict_topk(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +--------+-------+-------------+\\n        | row_id | class | probability |\\n        +--------+-------+-------------+\\n        |   0    |  dog  |     1.0     |\\n        |   1    | fossa |     0.5     |\\n        |   1    |  dog  |     0.5     |\\n        +--------+-------+-------------+\\n        \"\n    if not isinstance(k, int) or k < 1:\n        raise TypeError('The number of results to return for each point, ' + \"'k', must be an integer greater than 0.\")\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'row_id': [], 'class': [], 'probability': []})\n        ystar['row_id'] = ystar['row_id'].astype(int)\n        ystar['class'] = ystar['class'].astype(str)\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.unstack(column_names=['reference_label', 'Count'], new_column_name='votes')\n        ystar['topk'] = ystar['votes'].apply(lambda x: _sort_topk_votes(x, k))\n        ystar['total_votes'] = ystar['votes'].apply(lambda x: sum(x.values()))\n        ystar = ystar.stack('topk', new_column_name='topk')\n        ystar = ystar.unpack('topk')\n        ystar.rename({'topk.class': 'class', 'query_label': 'row_id'}, inplace=True)\n        ystar['probability'] = ystar['topk.votes'] / ystar['total_votes']\n        ystar = ystar[['row_id', 'class', 'probability']]\n    return ystar",
            "def predict_topk(self, dataset, max_neighbors=10, radius=None, k=3, verbose=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Return top-k most likely predictions for each observation in\\n        ``dataset``. Predictions are returned as an SFrame with three columns:\\n        `row_id`, `class`, and `probability`.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        k : int, optional\\n            Number of classes to return for each input example.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        ----------\\n        create, classify, predict\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no neighbors in the training dataset. In this case, the query is\\n          dropped from the SFrame output by this method. If all queries have no\\n          neighbors, then the result is an empty SFrame. If the target column in\\n          the training dataset has missing values, these predictions will be\\n          ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf_train, target='species')\\n        >>> ystar = m.predict_topk(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +--------+-------+-------------+\\n        | row_id | class | probability |\\n        +--------+-------+-------------+\\n        |   0    |  dog  |     1.0     |\\n        |   1    | fossa |     0.5     |\\n        |   1    |  dog  |     0.5     |\\n        +--------+-------+-------------+\\n        \"\n    if not isinstance(k, int) or k < 1:\n        raise TypeError('The number of results to return for each point, ' + \"'k', must be an integer greater than 0.\")\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'row_id': [], 'class': [], 'probability': []})\n        ystar['row_id'] = ystar['row_id'].astype(int)\n        ystar['class'] = ystar['class'].astype(str)\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.unstack(column_names=['reference_label', 'Count'], new_column_name='votes')\n        ystar['topk'] = ystar['votes'].apply(lambda x: _sort_topk_votes(x, k))\n        ystar['total_votes'] = ystar['votes'].apply(lambda x: sum(x.values()))\n        ystar = ystar.stack('topk', new_column_name='topk')\n        ystar = ystar.unpack('topk')\n        ystar.rename({'topk.class': 'class', 'query_label': 'row_id'}, inplace=True)\n        ystar['probability'] = ystar['topk.votes'] / ystar['total_votes']\n        ystar = ystar[['row_id', 'class', 'probability']]\n    return ystar",
            "def predict_topk(self, dataset, max_neighbors=10, radius=None, k=3, verbose=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Return top-k most likely predictions for each observation in\\n        ``dataset``. Predictions are returned as an SFrame with three columns:\\n        `row_id`, `class`, and `probability`.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        k : int, optional\\n            Number of classes to return for each input example.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        ----------\\n        create, classify, predict\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no neighbors in the training dataset. In this case, the query is\\n          dropped from the SFrame output by this method. If all queries have no\\n          neighbors, then the result is an empty SFrame. If the target column in\\n          the training dataset has missing values, these predictions will be\\n          ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf_train, target='species')\\n        >>> ystar = m.predict_topk(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +--------+-------+-------------+\\n        | row_id | class | probability |\\n        +--------+-------+-------------+\\n        |   0    |  dog  |     1.0     |\\n        |   1    | fossa |     0.5     |\\n        |   1    |  dog  |     0.5     |\\n        +--------+-------+-------------+\\n        \"\n    if not isinstance(k, int) or k < 1:\n        raise TypeError('The number of results to return for each point, ' + \"'k', must be an integer greater than 0.\")\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'row_id': [], 'class': [], 'probability': []})\n        ystar['row_id'] = ystar['row_id'].astype(int)\n        ystar['class'] = ystar['class'].astype(str)\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.unstack(column_names=['reference_label', 'Count'], new_column_name='votes')\n        ystar['topk'] = ystar['votes'].apply(lambda x: _sort_topk_votes(x, k))\n        ystar['total_votes'] = ystar['votes'].apply(lambda x: sum(x.values()))\n        ystar = ystar.stack('topk', new_column_name='topk')\n        ystar = ystar.unpack('topk')\n        ystar.rename({'topk.class': 'class', 'query_label': 'row_id'}, inplace=True)\n        ystar['probability'] = ystar['topk.votes'] / ystar['total_votes']\n        ystar = ystar[['row_id', 'class', 'probability']]\n    return ystar",
            "def predict_topk(self, dataset, max_neighbors=10, radius=None, k=3, verbose=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Return top-k most likely predictions for each observation in\\n        ``dataset``. Predictions are returned as an SFrame with three columns:\\n        `row_id`, `class`, and `probability`.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include the features used for\\n            model training, but does not require a target column. Additional\\n            columns are ignored.\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        k : int, optional\\n            Number of classes to return for each input example.\\n\\n        Returns\\n        -------\\n        out : SFrame\\n\\n        See Also\\n        ----------\\n        create, classify, predict\\n\\n        Notes\\n        -----\\n        - If the 'radius' parameter is small, it is possible that a query point\\n          has no neighbors in the training dataset. In this case, the query is\\n          dropped from the SFrame output by this method. If all queries have no\\n          neighbors, then the result is an empty SFrame. If the target column in\\n          the training dataset has missing values, these predictions will be\\n          ambiguous.\\n\\n        - Ties between predicted classes are broken randomly.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        ...\\n        >>> sf_new = turicreate.SFrame({'height': [26, 19],\\n        ...                           'weight': [25, 35]})\\n        ...\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf_train, target='species')\\n        >>> ystar = m.predict_topk(sf_new, max_neighbors=2)\\n        >>> print ystar\\n        +--------+-------+-------------+\\n        | row_id | class | probability |\\n        +--------+-------+-------------+\\n        |   0    |  dog  |     1.0     |\\n        |   1    | fossa |     0.5     |\\n        |   1    |  dog  |     0.5     |\\n        +--------+-------+-------------+\\n        \"\n    if not isinstance(k, int) or k < 1:\n        raise TypeError('The number of results to return for each point, ' + \"'k', must be an integer greater than 0.\")\n    _raise_error_if_not_sframe(dataset, 'dataset')\n    _raise_error_if_sframe_empty(dataset, 'dataset')\n    if max_neighbors is not None:\n        if not isinstance(max_neighbors, int):\n            raise ValueError(\"Input 'max_neighbors' must be an integer.\")\n        if max_neighbors <= 0:\n            raise ValueError(\"Input 'max_neighbors' must be larger than 0.\")\n    knn = self._knn_model.query(dataset, k=max_neighbors, radius=radius, verbose=verbose)\n    if knn.num_rows() == 0:\n        ystar = _tc.SFrame({'row_id': [], 'class': [], 'probability': []})\n        ystar['row_id'] = ystar['row_id'].astype(int)\n        ystar['class'] = ystar['class'].astype(str)\n    else:\n        grp = knn.groupby(['query_label', 'reference_label'], _tc.aggregate.COUNT)\n        ystar = grp.unstack(column_names=['reference_label', 'Count'], new_column_name='votes')\n        ystar['topk'] = ystar['votes'].apply(lambda x: _sort_topk_votes(x, k))\n        ystar['total_votes'] = ystar['votes'].apply(lambda x: sum(x.values()))\n        ystar = ystar.stack('topk', new_column_name='topk')\n        ystar = ystar.unpack('topk')\n        ystar.rename({'topk.class': 'class', 'query_label': 'row_id'}, inplace=True)\n        ystar['probability'] = ystar['topk.votes'] / ystar['total_votes']\n        ystar = ystar[['row_id', 'class', 'probability']]\n    return ystar"
        ]
    },
    {
        "func_name": "evaluate",
        "original": "def evaluate(self, dataset, metric='auto', max_neighbors=10, radius=None):\n    \"\"\"\n        Evaluate the model's predictive accuracy. This is done by predicting the\n        target class for instances in a new dataset and comparing to known\n        target values.\n\n        Parameters\n        ----------\n        dataset : SFrame\n            Dataset of new observations. Must include columns with the same\n            names as the target and features used for model training. Additional\n            columns are ignored.\n\n        metric : str, optional\n            Name of the evaluation metric.  Possible values are:\n\n            - 'auto': Returns all available metrics.\n\n            - 'accuracy': Classification accuracy.\n\n            - 'confusion_matrix': An SFrame with counts of possible\n              prediction/true label combinations.\n\n            - 'roc_curve': An SFrame containing information needed for an roc\n              curve (binary classification only).\n\n        max_neighbors : int, optional\n            Maximum number of neighbors to consider for each point.\n\n        radius : float, optional\n            Maximum distance from each point to a neighbor in the reference\n            dataset.\n\n        Returns\n        -------\n        out : dict\n            Evaluation results. The dictionary keys are *accuracy* and\n            *confusion_matrix* and *roc_curve* (if applicable).\n\n        See also\n        --------\n        create, predict, predict_topk, classify\n\n        Notes\n        -----\n        - Because the model randomly breaks ties between predicted classes, the\n          results of repeated calls to `evaluate` method may differ.\n\n        Examples\n        --------\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\n        ...                             'height': [9, 25, 20, 23],\n        ...                             'weight': [13, 28, 33, 22]})\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\n        >>> ans = m.evaluate(sf_train, max_neighbors=2,\n        ...                  metric='confusion_matrix')\n        >>> print ans['confusion_matrix']\n        +--------------+-----------------+-------+\n        | target_label | predicted_label | count |\n        +--------------+-----------------+-------+\n        |     cat      |       dog       |   1   |\n        |     dog      |       dog       |   2   |\n        |    fossa     |       dog       |   1   |\n        +--------------+-----------------+-------+\n        \"\"\"\n    _raise_error_evaluation_metric_is_valid(metric, ['auto', 'accuracy', 'confusion_matrix', 'roc_curve'])\n    target = self.target\n    _raise_error_if_column_exists(dataset, target, 'dataset', target)\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column of the evaluation dataset must contain integers or strings.')\n    if self.num_classes != 2:\n        if metric == 'roc_curve' or metric == ['roc_curve']:\n            err_msg = 'Currently, ROC curve is not supported for '\n            err_msg += 'multi-class classification in this model.'\n            raise _ToolkitError(err_msg)\n        else:\n            warn_msg = 'WARNING: Ignoring `roc_curve`. '\n            warn_msg += 'Not supported for multi-class classification.'\n            print(warn_msg)\n    ystar = self.predict(dataset, output_type='class', max_neighbors=max_neighbors, radius=radius)\n    ystar_prob = self.predict(dataset, output_type='probability', max_neighbors=max_neighbors, radius=radius)\n    results = {}\n    if metric in ['accuracy', 'auto']:\n        results['accuracy'] = _evaluation.accuracy(targets=dataset[target], predictions=ystar)\n    if metric in ['confusion_matrix', 'auto']:\n        results['confusion_matrix'] = _evaluation.confusion_matrix(targets=dataset[target], predictions=ystar)\n    if self.num_classes == 2:\n        if metric in ['roc_curve', 'auto']:\n            results['roc_curve'] = _evaluation.roc_curve(targets=dataset[target], predictions=ystar_prob)\n    return results",
        "mutated": [
            "def evaluate(self, dataset, metric='auto', max_neighbors=10, radius=None):\n    if False:\n        i = 10\n    \"\\n        Evaluate the model's predictive accuracy. This is done by predicting the\\n        target class for instances in a new dataset and comparing to known\\n        target values.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the target and features used for model training. Additional\\n            columns are ignored.\\n\\n        metric : str, optional\\n            Name of the evaluation metric.  Possible values are:\\n\\n            - 'auto': Returns all available metrics.\\n\\n            - 'accuracy': Classification accuracy.\\n\\n            - 'confusion_matrix': An SFrame with counts of possible\\n              prediction/true label combinations.\\n\\n            - 'roc_curve': An SFrame containing information needed for an roc\\n              curve (binary classification only).\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : dict\\n            Evaluation results. The dictionary keys are *accuracy* and\\n            *confusion_matrix* and *roc_curve* (if applicable).\\n\\n        See also\\n        --------\\n        create, predict, predict_topk, classify\\n\\n        Notes\\n        -----\\n        - Because the model randomly breaks ties between predicted classes, the\\n          results of repeated calls to `evaluate` method may differ.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ans = m.evaluate(sf_train, max_neighbors=2,\\n        ...                  metric='confusion_matrix')\\n        >>> print ans['confusion_matrix']\\n        +--------------+-----------------+-------+\\n        | target_label | predicted_label | count |\\n        +--------------+-----------------+-------+\\n        |     cat      |       dog       |   1   |\\n        |     dog      |       dog       |   2   |\\n        |    fossa     |       dog       |   1   |\\n        +--------------+-----------------+-------+\\n        \"\n    _raise_error_evaluation_metric_is_valid(metric, ['auto', 'accuracy', 'confusion_matrix', 'roc_curve'])\n    target = self.target\n    _raise_error_if_column_exists(dataset, target, 'dataset', target)\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column of the evaluation dataset must contain integers or strings.')\n    if self.num_classes != 2:\n        if metric == 'roc_curve' or metric == ['roc_curve']:\n            err_msg = 'Currently, ROC curve is not supported for '\n            err_msg += 'multi-class classification in this model.'\n            raise _ToolkitError(err_msg)\n        else:\n            warn_msg = 'WARNING: Ignoring `roc_curve`. '\n            warn_msg += 'Not supported for multi-class classification.'\n            print(warn_msg)\n    ystar = self.predict(dataset, output_type='class', max_neighbors=max_neighbors, radius=radius)\n    ystar_prob = self.predict(dataset, output_type='probability', max_neighbors=max_neighbors, radius=radius)\n    results = {}\n    if metric in ['accuracy', 'auto']:\n        results['accuracy'] = _evaluation.accuracy(targets=dataset[target], predictions=ystar)\n    if metric in ['confusion_matrix', 'auto']:\n        results['confusion_matrix'] = _evaluation.confusion_matrix(targets=dataset[target], predictions=ystar)\n    if self.num_classes == 2:\n        if metric in ['roc_curve', 'auto']:\n            results['roc_curve'] = _evaluation.roc_curve(targets=dataset[target], predictions=ystar_prob)\n    return results",
            "def evaluate(self, dataset, metric='auto', max_neighbors=10, radius=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Evaluate the model's predictive accuracy. This is done by predicting the\\n        target class for instances in a new dataset and comparing to known\\n        target values.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the target and features used for model training. Additional\\n            columns are ignored.\\n\\n        metric : str, optional\\n            Name of the evaluation metric.  Possible values are:\\n\\n            - 'auto': Returns all available metrics.\\n\\n            - 'accuracy': Classification accuracy.\\n\\n            - 'confusion_matrix': An SFrame with counts of possible\\n              prediction/true label combinations.\\n\\n            - 'roc_curve': An SFrame containing information needed for an roc\\n              curve (binary classification only).\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : dict\\n            Evaluation results. The dictionary keys are *accuracy* and\\n            *confusion_matrix* and *roc_curve* (if applicable).\\n\\n        See also\\n        --------\\n        create, predict, predict_topk, classify\\n\\n        Notes\\n        -----\\n        - Because the model randomly breaks ties between predicted classes, the\\n          results of repeated calls to `evaluate` method may differ.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ans = m.evaluate(sf_train, max_neighbors=2,\\n        ...                  metric='confusion_matrix')\\n        >>> print ans['confusion_matrix']\\n        +--------------+-----------------+-------+\\n        | target_label | predicted_label | count |\\n        +--------------+-----------------+-------+\\n        |     cat      |       dog       |   1   |\\n        |     dog      |       dog       |   2   |\\n        |    fossa     |       dog       |   1   |\\n        +--------------+-----------------+-------+\\n        \"\n    _raise_error_evaluation_metric_is_valid(metric, ['auto', 'accuracy', 'confusion_matrix', 'roc_curve'])\n    target = self.target\n    _raise_error_if_column_exists(dataset, target, 'dataset', target)\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column of the evaluation dataset must contain integers or strings.')\n    if self.num_classes != 2:\n        if metric == 'roc_curve' or metric == ['roc_curve']:\n            err_msg = 'Currently, ROC curve is not supported for '\n            err_msg += 'multi-class classification in this model.'\n            raise _ToolkitError(err_msg)\n        else:\n            warn_msg = 'WARNING: Ignoring `roc_curve`. '\n            warn_msg += 'Not supported for multi-class classification.'\n            print(warn_msg)\n    ystar = self.predict(dataset, output_type='class', max_neighbors=max_neighbors, radius=radius)\n    ystar_prob = self.predict(dataset, output_type='probability', max_neighbors=max_neighbors, radius=radius)\n    results = {}\n    if metric in ['accuracy', 'auto']:\n        results['accuracy'] = _evaluation.accuracy(targets=dataset[target], predictions=ystar)\n    if metric in ['confusion_matrix', 'auto']:\n        results['confusion_matrix'] = _evaluation.confusion_matrix(targets=dataset[target], predictions=ystar)\n    if self.num_classes == 2:\n        if metric in ['roc_curve', 'auto']:\n            results['roc_curve'] = _evaluation.roc_curve(targets=dataset[target], predictions=ystar_prob)\n    return results",
            "def evaluate(self, dataset, metric='auto', max_neighbors=10, radius=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Evaluate the model's predictive accuracy. This is done by predicting the\\n        target class for instances in a new dataset and comparing to known\\n        target values.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the target and features used for model training. Additional\\n            columns are ignored.\\n\\n        metric : str, optional\\n            Name of the evaluation metric.  Possible values are:\\n\\n            - 'auto': Returns all available metrics.\\n\\n            - 'accuracy': Classification accuracy.\\n\\n            - 'confusion_matrix': An SFrame with counts of possible\\n              prediction/true label combinations.\\n\\n            - 'roc_curve': An SFrame containing information needed for an roc\\n              curve (binary classification only).\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : dict\\n            Evaluation results. The dictionary keys are *accuracy* and\\n            *confusion_matrix* and *roc_curve* (if applicable).\\n\\n        See also\\n        --------\\n        create, predict, predict_topk, classify\\n\\n        Notes\\n        -----\\n        - Because the model randomly breaks ties between predicted classes, the\\n          results of repeated calls to `evaluate` method may differ.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ans = m.evaluate(sf_train, max_neighbors=2,\\n        ...                  metric='confusion_matrix')\\n        >>> print ans['confusion_matrix']\\n        +--------------+-----------------+-------+\\n        | target_label | predicted_label | count |\\n        +--------------+-----------------+-------+\\n        |     cat      |       dog       |   1   |\\n        |     dog      |       dog       |   2   |\\n        |    fossa     |       dog       |   1   |\\n        +--------------+-----------------+-------+\\n        \"\n    _raise_error_evaluation_metric_is_valid(metric, ['auto', 'accuracy', 'confusion_matrix', 'roc_curve'])\n    target = self.target\n    _raise_error_if_column_exists(dataset, target, 'dataset', target)\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column of the evaluation dataset must contain integers or strings.')\n    if self.num_classes != 2:\n        if metric == 'roc_curve' or metric == ['roc_curve']:\n            err_msg = 'Currently, ROC curve is not supported for '\n            err_msg += 'multi-class classification in this model.'\n            raise _ToolkitError(err_msg)\n        else:\n            warn_msg = 'WARNING: Ignoring `roc_curve`. '\n            warn_msg += 'Not supported for multi-class classification.'\n            print(warn_msg)\n    ystar = self.predict(dataset, output_type='class', max_neighbors=max_neighbors, radius=radius)\n    ystar_prob = self.predict(dataset, output_type='probability', max_neighbors=max_neighbors, radius=radius)\n    results = {}\n    if metric in ['accuracy', 'auto']:\n        results['accuracy'] = _evaluation.accuracy(targets=dataset[target], predictions=ystar)\n    if metric in ['confusion_matrix', 'auto']:\n        results['confusion_matrix'] = _evaluation.confusion_matrix(targets=dataset[target], predictions=ystar)\n    if self.num_classes == 2:\n        if metric in ['roc_curve', 'auto']:\n            results['roc_curve'] = _evaluation.roc_curve(targets=dataset[target], predictions=ystar_prob)\n    return results",
            "def evaluate(self, dataset, metric='auto', max_neighbors=10, radius=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Evaluate the model's predictive accuracy. This is done by predicting the\\n        target class for instances in a new dataset and comparing to known\\n        target values.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the target and features used for model training. Additional\\n            columns are ignored.\\n\\n        metric : str, optional\\n            Name of the evaluation metric.  Possible values are:\\n\\n            - 'auto': Returns all available metrics.\\n\\n            - 'accuracy': Classification accuracy.\\n\\n            - 'confusion_matrix': An SFrame with counts of possible\\n              prediction/true label combinations.\\n\\n            - 'roc_curve': An SFrame containing information needed for an roc\\n              curve (binary classification only).\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : dict\\n            Evaluation results. The dictionary keys are *accuracy* and\\n            *confusion_matrix* and *roc_curve* (if applicable).\\n\\n        See also\\n        --------\\n        create, predict, predict_topk, classify\\n\\n        Notes\\n        -----\\n        - Because the model randomly breaks ties between predicted classes, the\\n          results of repeated calls to `evaluate` method may differ.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ans = m.evaluate(sf_train, max_neighbors=2,\\n        ...                  metric='confusion_matrix')\\n        >>> print ans['confusion_matrix']\\n        +--------------+-----------------+-------+\\n        | target_label | predicted_label | count |\\n        +--------------+-----------------+-------+\\n        |     cat      |       dog       |   1   |\\n        |     dog      |       dog       |   2   |\\n        |    fossa     |       dog       |   1   |\\n        +--------------+-----------------+-------+\\n        \"\n    _raise_error_evaluation_metric_is_valid(metric, ['auto', 'accuracy', 'confusion_matrix', 'roc_curve'])\n    target = self.target\n    _raise_error_if_column_exists(dataset, target, 'dataset', target)\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column of the evaluation dataset must contain integers or strings.')\n    if self.num_classes != 2:\n        if metric == 'roc_curve' or metric == ['roc_curve']:\n            err_msg = 'Currently, ROC curve is not supported for '\n            err_msg += 'multi-class classification in this model.'\n            raise _ToolkitError(err_msg)\n        else:\n            warn_msg = 'WARNING: Ignoring `roc_curve`. '\n            warn_msg += 'Not supported for multi-class classification.'\n            print(warn_msg)\n    ystar = self.predict(dataset, output_type='class', max_neighbors=max_neighbors, radius=radius)\n    ystar_prob = self.predict(dataset, output_type='probability', max_neighbors=max_neighbors, radius=radius)\n    results = {}\n    if metric in ['accuracy', 'auto']:\n        results['accuracy'] = _evaluation.accuracy(targets=dataset[target], predictions=ystar)\n    if metric in ['confusion_matrix', 'auto']:\n        results['confusion_matrix'] = _evaluation.confusion_matrix(targets=dataset[target], predictions=ystar)\n    if self.num_classes == 2:\n        if metric in ['roc_curve', 'auto']:\n            results['roc_curve'] = _evaluation.roc_curve(targets=dataset[target], predictions=ystar_prob)\n    return results",
            "def evaluate(self, dataset, metric='auto', max_neighbors=10, radius=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Evaluate the model's predictive accuracy. This is done by predicting the\\n        target class for instances in a new dataset and comparing to known\\n        target values.\\n\\n        Parameters\\n        ----------\\n        dataset : SFrame\\n            Dataset of new observations. Must include columns with the same\\n            names as the target and features used for model training. Additional\\n            columns are ignored.\\n\\n        metric : str, optional\\n            Name of the evaluation metric.  Possible values are:\\n\\n            - 'auto': Returns all available metrics.\\n\\n            - 'accuracy': Classification accuracy.\\n\\n            - 'confusion_matrix': An SFrame with counts of possible\\n              prediction/true label combinations.\\n\\n            - 'roc_curve': An SFrame containing information needed for an roc\\n              curve (binary classification only).\\n\\n        max_neighbors : int, optional\\n            Maximum number of neighbors to consider for each point.\\n\\n        radius : float, optional\\n            Maximum distance from each point to a neighbor in the reference\\n            dataset.\\n\\n        Returns\\n        -------\\n        out : dict\\n            Evaluation results. The dictionary keys are *accuracy* and\\n            *confusion_matrix* and *roc_curve* (if applicable).\\n\\n        See also\\n        --------\\n        create, predict, predict_topk, classify\\n\\n        Notes\\n        -----\\n        - Because the model randomly breaks ties between predicted classes, the\\n          results of repeated calls to `evaluate` method may differ.\\n\\n        Examples\\n        --------\\n        >>> sf_train = turicreate.SFrame({'species': ['cat', 'dog', 'fossa', 'dog'],\\n        ...                             'height': [9, 25, 20, 23],\\n        ...                             'weight': [13, 28, 33, 22]})\\n        >>> m = turicreate.nearest_neighbor_classifier.create(sf, target='species')\\n        >>> ans = m.evaluate(sf_train, max_neighbors=2,\\n        ...                  metric='confusion_matrix')\\n        >>> print ans['confusion_matrix']\\n        +--------------+-----------------+-------+\\n        | target_label | predicted_label | count |\\n        +--------------+-----------------+-------+\\n        |     cat      |       dog       |   1   |\\n        |     dog      |       dog       |   2   |\\n        |    fossa     |       dog       |   1   |\\n        +--------------+-----------------+-------+\\n        \"\n    _raise_error_evaluation_metric_is_valid(metric, ['auto', 'accuracy', 'confusion_matrix', 'roc_curve'])\n    target = self.target\n    _raise_error_if_column_exists(dataset, target, 'dataset', target)\n    if not dataset[target].dtype == str and (not dataset[target].dtype == int):\n        raise TypeError('The target column of the evaluation dataset must contain integers or strings.')\n    if self.num_classes != 2:\n        if metric == 'roc_curve' or metric == ['roc_curve']:\n            err_msg = 'Currently, ROC curve is not supported for '\n            err_msg += 'multi-class classification in this model.'\n            raise _ToolkitError(err_msg)\n        else:\n            warn_msg = 'WARNING: Ignoring `roc_curve`. '\n            warn_msg += 'Not supported for multi-class classification.'\n            print(warn_msg)\n    ystar = self.predict(dataset, output_type='class', max_neighbors=max_neighbors, radius=radius)\n    ystar_prob = self.predict(dataset, output_type='probability', max_neighbors=max_neighbors, radius=radius)\n    results = {}\n    if metric in ['accuracy', 'auto']:\n        results['accuracy'] = _evaluation.accuracy(targets=dataset[target], predictions=ystar)\n    if metric in ['confusion_matrix', 'auto']:\n        results['confusion_matrix'] = _evaluation.confusion_matrix(targets=dataset[target], predictions=ystar)\n    if self.num_classes == 2:\n        if metric in ['roc_curve', 'auto']:\n            results['roc_curve'] = _evaluation.roc_curve(targets=dataset[target], predictions=ystar_prob)\n    return results"
        ]
    }
]