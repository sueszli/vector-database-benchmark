[
    {
        "func_name": "sparse_lengths_sum_ref",
        "original": "def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    if normalize_by_lengths:\n        for i in range(0, len(rptr[0:-1])):\n            if Lengths[i] != 0:\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n    else:\n        for i in range(0, len(rptr[0:-1])):\n            out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n    return [out.astype(np.float32)]",
        "mutated": [
            "def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n    if False:\n        i = 10\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    if normalize_by_lengths:\n        for i in range(0, len(rptr[0:-1])):\n            if Lengths[i] != 0:\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n    else:\n        for i in range(0, len(rptr[0:-1])):\n            out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    if normalize_by_lengths:\n        for i in range(0, len(rptr[0:-1])):\n            if Lengths[i] != 0:\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n    else:\n        for i in range(0, len(rptr[0:-1])):\n            out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    if normalize_by_lengths:\n        for i in range(0, len(rptr[0:-1])):\n            if Lengths[i] != 0:\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n    else:\n        for i in range(0, len(rptr[0:-1])):\n            out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    if normalize_by_lengths:\n        for i in range(0, len(rptr[0:-1])):\n            if Lengths[i] != 0:\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n    else:\n        for i in range(0, len(rptr[0:-1])):\n            out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    if normalize_by_lengths:\n        for i in range(0, len(rptr[0:-1])):\n            if Lengths[i] != 0:\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n    else:\n        for i in range(0, len(rptr[0:-1])):\n            out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n    return [out.astype(np.float32)]"
        ]
    },
    {
        "func_name": "test_sparse_lengths_sum_cpu",
        "original": "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_sum_cpu(self, batchsize, fptype, fp16asint, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_mean_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum'), ['Tbl', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        if normalize_by_lengths:\n            for i in range(0, len(rptr[0:-1])):\n                if Lengths[i] != 0:\n                    out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n        else:\n            for i in range(0, len(rptr[0:-1])):\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths], sparse_lengths_sum_ref, threshold=0.001, atol=atol)",
        "mutated": [
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_sum_cpu(self, batchsize, fptype, fp16asint, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_mean_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum'), ['Tbl', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        if normalize_by_lengths:\n            for i in range(0, len(rptr[0:-1])):\n                if Lengths[i] != 0:\n                    out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n        else:\n            for i in range(0, len(rptr[0:-1])):\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths], sparse_lengths_sum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_sum_cpu(self, batchsize, fptype, fp16asint, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_mean_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum'), ['Tbl', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        if normalize_by_lengths:\n            for i in range(0, len(rptr[0:-1])):\n                if Lengths[i] != 0:\n                    out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n        else:\n            for i in range(0, len(rptr[0:-1])):\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths], sparse_lengths_sum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_sum_cpu(self, batchsize, fptype, fp16asint, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_mean_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum'), ['Tbl', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        if normalize_by_lengths:\n            for i in range(0, len(rptr[0:-1])):\n                if Lengths[i] != 0:\n                    out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n        else:\n            for i in range(0, len(rptr[0:-1])):\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths], sparse_lengths_sum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_sum_cpu(self, batchsize, fptype, fp16asint, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_mean_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum'), ['Tbl', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        if normalize_by_lengths:\n            for i in range(0, len(rptr[0:-1])):\n                if Lengths[i] != 0:\n                    out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n        else:\n            for i in range(0, len(rptr[0:-1])):\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths], sparse_lengths_sum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_sum_cpu(self, batchsize, fptype, fp16asint, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_mean_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum'), ['Tbl', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_sum_ref(Tbl, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        if normalize_by_lengths:\n            for i in range(0, len(rptr[0:-1])):\n                if Lengths[i] != 0:\n                    out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0) * 1.0 / float(Lengths[i])\n        else:\n            for i in range(0, len(rptr[0:-1])):\n                out[i] = Tbl[Indices[rptr[i]:rptr[i + 1]]].sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths], sparse_lengths_sum_ref, threshold=0.001, atol=atol)"
        ]
    },
    {
        "func_name": "sparse_lengths_weightedsum_ref",
        "original": "def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n    return [out.astype(np.float32)]",
        "mutated": [
            "def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n    if False:\n        i = 10\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n    return [out.astype(np.float32)]"
        ]
    },
    {
        "func_name": "test_sparse_lengths_weightedsum_cpu",
        "original": "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_weightedsum_cpu(self, batchsize, fptype, fp16asint, blocksize, empty_indices, gc, dc):\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    print('<test_sparse_lengths_weightedsum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeightedSum', ['Tbl', 'Weights', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths], sparse_lengths_weightedsum_ref, threshold=0.001, atol=atol)",
        "mutated": [
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_weightedsum_cpu(self, batchsize, fptype, fp16asint, blocksize, empty_indices, gc, dc):\n    if False:\n        i = 10\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    print('<test_sparse_lengths_weightedsum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeightedSum', ['Tbl', 'Weights', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths], sparse_lengths_weightedsum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_weightedsum_cpu(self, batchsize, fptype, fp16asint, blocksize, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    print('<test_sparse_lengths_weightedsum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeightedSum', ['Tbl', 'Weights', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths], sparse_lengths_weightedsum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_weightedsum_cpu(self, batchsize, fptype, fp16asint, blocksize, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    print('<test_sparse_lengths_weightedsum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeightedSum', ['Tbl', 'Weights', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths], sparse_lengths_weightedsum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_weightedsum_cpu(self, batchsize, fptype, fp16asint, blocksize, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    print('<test_sparse_lengths_weightedsum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeightedSum', ['Tbl', 'Weights', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths], sparse_lengths_weightedsum_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), fptype=st.sampled_from([np.float16, np.float32]), fp16asint=st.booleans(), blocksize=st.sampled_from([8, 16, 32, 64, 85, 96, 128, 163]), empty_indices=st.booleans(), **hu.gcs)\ndef test_sparse_lengths_weightedsum_cpu(self, batchsize, fptype, fp16asint, blocksize, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if fptype != np.float32:\n        assume(gc.device_type == caffe2_pb2.CPU)\n        assume(not hiputl.run_in_hip(gc, dc))\n        assume(caffe2_pb2.CUDA not in {d.device_type for d in dc})\n    print('<test_sparse_lengths_weightedsum_cpu>')\n    tblsize = 300\n    if fptype == np.float32:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float32)\n        atol = 1e-05\n    elif fp16asint:\n        Tbl = (10.0 * np.random.rand(tblsize, blocksize)).round().astype(np.float16)\n        atol = 0.001\n    else:\n        Tbl = np.random.rand(tblsize, blocksize).astype(np.float16)\n        atol = 0.1\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeightedSum', ['Tbl', 'Weights', 'Indices', 'Lengths'], 'out')\n\n    def sparse_lengths_weightedsum_ref(Tbl, Weights, Indices, Lengths):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            out[i] = (Tbl[Indices[rptr[i]:rptr[i + 1]]] * w[:, np.newaxis]).sum(axis=0)\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths], sparse_lengths_weightedsum_ref, threshold=0.001, atol=atol)"
        ]
    },
    {
        "func_name": "sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref",
        "original": "def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n    return [out.astype(np.float32)]",
        "mutated": [
            "def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        w = Weights[rptr[i]:rptr[i + 1]]\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n    return [out.astype(np.float32)]"
        ]
    },
    {
        "func_name": "test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu",
        "original": "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeighted' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Weights', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths, Scale_Bias], sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref, threshold=0.001, atol=atol)",
        "mutated": [
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeighted' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Weights', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths, Scale_Bias], sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeighted' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Weights', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths, Scale_Bias], sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeighted' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Weights', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths, Scale_Bias], sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeighted' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Weights', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths, Scale_Bias], sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_weightedsum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_weightedsum_SparseLengthsWeightedSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Weights = np.random.rand(sum(Lengths)).astype(np.float32)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengthsWeighted' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Weights', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref(Tbl, Weights, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            w = Weights[rptr[i]:rptr[i + 1]]\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (w[:, np.newaxis] * (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b)).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Weights, Indices, Lengths, Scale_Bias], sparse_lengths_weightedsum_8BitsRowwiseOp_cpu_ref, threshold=0.001, atol=atol)"
        ]
    },
    {
        "func_name": "sparse_lengths_sum_8BitsRowwiseOp_cpu_reg",
        "original": "def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n    return [out.astype(np.float32)]",
        "mutated": [
            "def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n    return [out.astype(np.float32)]",
            "def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n    out = np.zeros((len(Lengths), blocksize))\n    for i in range(0, len(rptr[0:-1])):\n        s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n        b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n        f = 1.0\n        if normalize_by_lengths and Lengths[i] != 0:\n            f = 1.0 / float(Lengths[i])\n        out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n    return [out.astype(np.float32)]"
        ]
    },
    {
        "func_name": "test_sparse_lengths_sum_8BitsRowwiseOp_cpu",
        "original": "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_SparseLengthsMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_SparseLengthsSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths, Scale_Bias], sparse_lengths_sum_8BitsRowwiseOp_cpu_reg, threshold=0.001, atol=atol)",
        "mutated": [
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_SparseLengthsMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_SparseLengthsSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths, Scale_Bias], sparse_lengths_sum_8BitsRowwiseOp_cpu_reg, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_SparseLengthsMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_SparseLengthsSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths, Scale_Bias], sparse_lengths_sum_8BitsRowwiseOp_cpu_reg, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_SparseLengthsMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_SparseLengthsSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths, Scale_Bias], sparse_lengths_sum_8BitsRowwiseOp_cpu_reg, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_SparseLengthsMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_SparseLengthsSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths, Scale_Bias], sparse_lengths_sum_8BitsRowwiseOp_cpu_reg, threshold=0.001, atol=atol)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), empty_indices=st.booleans(), **hu.gcs_cpu_only)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu(self, batchsize, blocksize, normalize_by_lengths, empty_indices, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if normalize_by_lengths:\n        print('<test_sparse_lengths_sum_SparseLengthsMean8BitsRowwise_cpu>')\n    else:\n        print('<test_sparse_lengths_sum_SparseLengthsSum8BitsRowwise_cpu>')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    atol = 1e-05\n    if empty_indices:\n        Lengths = np.zeros(batchsize, dtype=np.int32)\n    else:\n        Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n\n    def sparse_lengths_sum_8BitsRowwiseOp_cpu_reg(Tbl, Indices, Lengths, Scale_Bias):\n        rptr = np.cumsum(np.insert(Lengths, [0], [0]))\n        out = np.zeros((len(Lengths), blocksize))\n        for i in range(0, len(rptr[0:-1])):\n            s = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 0][:, np.newaxis]\n            b = Scale_Bias[Indices[rptr[i]:rptr[i + 1]], 1][:, np.newaxis]\n            f = 1.0\n            if normalize_by_lengths and Lengths[i] != 0:\n                f = 1.0 / float(Lengths[i])\n            out[i] = (s * Tbl[Indices[rptr[i]:rptr[i + 1]]] + b).sum(axis=0) * f\n        return [out.astype(np.float32)]\n    self.assertReferenceChecks(gc, op, [Tbl, Indices, Lengths, Scale_Bias], sparse_lengths_sum_8BitsRowwiseOp_cpu_reg, threshold=0.001, atol=atol)"
        ]
    },
    {
        "func_name": "test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index",
        "original": "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index(self, batchsize, blocksize, normalize_by_lengths, gc, dc):\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Indices[0] += 1000\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n    self.ws.create_blob('Tbl').feed(Tbl)\n    self.ws.create_blob('Indices').feed(Indices)\n    self.ws.create_blob('Lengths').feed(Lengths)\n    self.ws.create_blob('Scale_Bias').feed(Scale_Bias)\n    with self.assertRaises(RuntimeError):\n        self.ws.run(op)",
        "mutated": [
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index(self, batchsize, blocksize, normalize_by_lengths, gc, dc):\n    if False:\n        i = 10\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Indices[0] += 1000\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n    self.ws.create_blob('Tbl').feed(Tbl)\n    self.ws.create_blob('Indices').feed(Indices)\n    self.ws.create_blob('Lengths').feed(Lengths)\n    self.ws.create_blob('Scale_Bias').feed(Scale_Bias)\n    with self.assertRaises(RuntimeError):\n        self.ws.run(op)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index(self, batchsize, blocksize, normalize_by_lengths, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Indices[0] += 1000\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n    self.ws.create_blob('Tbl').feed(Tbl)\n    self.ws.create_blob('Indices').feed(Indices)\n    self.ws.create_blob('Lengths').feed(Lengths)\n    self.ws.create_blob('Scale_Bias').feed(Scale_Bias)\n    with self.assertRaises(RuntimeError):\n        self.ws.run(op)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index(self, batchsize, blocksize, normalize_by_lengths, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Indices[0] += 1000\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n    self.ws.create_blob('Tbl').feed(Tbl)\n    self.ws.create_blob('Indices').feed(Indices)\n    self.ws.create_blob('Lengths').feed(Lengths)\n    self.ws.create_blob('Scale_Bias').feed(Scale_Bias)\n    with self.assertRaises(RuntimeError):\n        self.ws.run(op)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index(self, batchsize, blocksize, normalize_by_lengths, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Indices[0] += 1000\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n    self.ws.create_blob('Tbl').feed(Tbl)\n    self.ws.create_blob('Indices').feed(Indices)\n    self.ws.create_blob('Lengths').feed(Lengths)\n    self.ws.create_blob('Scale_Bias').feed(Scale_Bias)\n    with self.assertRaises(RuntimeError):\n        self.ws.run(op)",
            "@given(batchsize=st.integers(1, 20), blocksize=st.sampled_from([8, 16, 17, 26, 32, 64, 85, 96, 128, 148, 163]), normalize_by_lengths=st.booleans(), **hu.gcs_cpu_only)\n@settings(deadline=10000)\ndef test_sparse_lengths_sum_8BitsRowwiseOp_cpu_invalid_index(self, batchsize, blocksize, normalize_by_lengths, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    tblsize = 300\n    Tbl = np.random.randint(7, size=(tblsize, blocksize), dtype=np.uint8)\n    Lengths = np.random.randint(1, 30, size=batchsize, dtype=np.int32)\n    Indices = np.random.randint(0, tblsize, size=sum(Lengths), dtype=np.int64)\n    Indices[0] += 1000\n    Scale_Bias = np.random.rand(tblsize, 2).astype(np.float32)\n    op = core.CreateOperator('SparseLengths' + ('Mean' if normalize_by_lengths else 'Sum') + '8BitsRowwise', ['Tbl', 'Indices', 'Lengths', 'Scale_Bias'], 'out')\n    self.ws.create_blob('Tbl').feed(Tbl)\n    self.ws.create_blob('Indices').feed(Indices)\n    self.ws.create_blob('Lengths').feed(Lengths)\n    self.ws.create_blob('Scale_Bias').feed(Scale_Bias)\n    with self.assertRaises(RuntimeError):\n        self.ws.run(op)"
        ]
    }
]