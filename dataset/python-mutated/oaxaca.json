[
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, bifurcate, hasconst=True, swap=True, cov_type='nonrobust', cov_kwds=None):\n    if str(type(exog)).find('pandas') != -1:\n        bifurcate = exog.columns.get_loc(bifurcate)\n        (endog, exog) = (np.array(endog), np.array(exog))\n    self.two_fold_type = None\n    self.bifurcate = bifurcate\n    self.cov_type = cov_type\n    self.cov_kwds = cov_kwds\n    self.neumark = np.delete(exog, bifurcate, axis=1)\n    self.exog = exog\n    self.hasconst = hasconst\n    bi_col = exog[:, bifurcate]\n    endog = np.column_stack((bi_col, endog))\n    bi = np.unique(bi_col)\n    self.bi_col = bi_col\n    exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n    exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n    endog_f = endog[np.where(endog[:, 0] == bi[0])]\n    endog_s = endog[np.where(endog[:, 0] == bi[1])]\n    exog_f = np.delete(exog_f, bifurcate, axis=1)\n    exog_s = np.delete(exog_s, bifurcate, axis=1)\n    endog_f = endog_f[:, 1]\n    endog_s = endog_s[:, 1]\n    self.endog = endog[:, 1]\n    (self.len_f, self.len_s) = (len(endog_f), len(endog_s))\n    self.gap = endog_f.mean() - endog_s.mean()\n    if swap and self.gap < 0:\n        (endog_f, endog_s) = (endog_s, endog_f)\n        (exog_f, exog_s) = (exog_s, exog_f)\n        self.gap = endog_f.mean() - endog_s.mean()\n        (bi[0], bi[1]) = (bi[1], bi[0])\n    self.bi = bi\n    if hasconst is False:\n        exog_f = add_constant(exog_f, prepend=False)\n        exog_s = add_constant(exog_s, prepend=False)\n        self.exog = add_constant(self.exog, prepend=False)\n        self.neumark = add_constant(self.neumark, prepend=False)\n    self.exog_f_mean = np.mean(exog_f, axis=0)\n    self.exog_s_mean = np.mean(exog_s, axis=0)\n    self._f_model = OLS(endog_f, exog_f).fit(cov_type=cov_type, cov_kwds=cov_kwds)\n    self._s_model = OLS(endog_s, exog_s).fit(cov_type=cov_type, cov_kwds=cov_kwds)",
        "mutated": [
            "def __init__(self, endog, exog, bifurcate, hasconst=True, swap=True, cov_type='nonrobust', cov_kwds=None):\n    if False:\n        i = 10\n    if str(type(exog)).find('pandas') != -1:\n        bifurcate = exog.columns.get_loc(bifurcate)\n        (endog, exog) = (np.array(endog), np.array(exog))\n    self.two_fold_type = None\n    self.bifurcate = bifurcate\n    self.cov_type = cov_type\n    self.cov_kwds = cov_kwds\n    self.neumark = np.delete(exog, bifurcate, axis=1)\n    self.exog = exog\n    self.hasconst = hasconst\n    bi_col = exog[:, bifurcate]\n    endog = np.column_stack((bi_col, endog))\n    bi = np.unique(bi_col)\n    self.bi_col = bi_col\n    exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n    exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n    endog_f = endog[np.where(endog[:, 0] == bi[0])]\n    endog_s = endog[np.where(endog[:, 0] == bi[1])]\n    exog_f = np.delete(exog_f, bifurcate, axis=1)\n    exog_s = np.delete(exog_s, bifurcate, axis=1)\n    endog_f = endog_f[:, 1]\n    endog_s = endog_s[:, 1]\n    self.endog = endog[:, 1]\n    (self.len_f, self.len_s) = (len(endog_f), len(endog_s))\n    self.gap = endog_f.mean() - endog_s.mean()\n    if swap and self.gap < 0:\n        (endog_f, endog_s) = (endog_s, endog_f)\n        (exog_f, exog_s) = (exog_s, exog_f)\n        self.gap = endog_f.mean() - endog_s.mean()\n        (bi[0], bi[1]) = (bi[1], bi[0])\n    self.bi = bi\n    if hasconst is False:\n        exog_f = add_constant(exog_f, prepend=False)\n        exog_s = add_constant(exog_s, prepend=False)\n        self.exog = add_constant(self.exog, prepend=False)\n        self.neumark = add_constant(self.neumark, prepend=False)\n    self.exog_f_mean = np.mean(exog_f, axis=0)\n    self.exog_s_mean = np.mean(exog_s, axis=0)\n    self._f_model = OLS(endog_f, exog_f).fit(cov_type=cov_type, cov_kwds=cov_kwds)\n    self._s_model = OLS(endog_s, exog_s).fit(cov_type=cov_type, cov_kwds=cov_kwds)",
            "def __init__(self, endog, exog, bifurcate, hasconst=True, swap=True, cov_type='nonrobust', cov_kwds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if str(type(exog)).find('pandas') != -1:\n        bifurcate = exog.columns.get_loc(bifurcate)\n        (endog, exog) = (np.array(endog), np.array(exog))\n    self.two_fold_type = None\n    self.bifurcate = bifurcate\n    self.cov_type = cov_type\n    self.cov_kwds = cov_kwds\n    self.neumark = np.delete(exog, bifurcate, axis=1)\n    self.exog = exog\n    self.hasconst = hasconst\n    bi_col = exog[:, bifurcate]\n    endog = np.column_stack((bi_col, endog))\n    bi = np.unique(bi_col)\n    self.bi_col = bi_col\n    exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n    exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n    endog_f = endog[np.where(endog[:, 0] == bi[0])]\n    endog_s = endog[np.where(endog[:, 0] == bi[1])]\n    exog_f = np.delete(exog_f, bifurcate, axis=1)\n    exog_s = np.delete(exog_s, bifurcate, axis=1)\n    endog_f = endog_f[:, 1]\n    endog_s = endog_s[:, 1]\n    self.endog = endog[:, 1]\n    (self.len_f, self.len_s) = (len(endog_f), len(endog_s))\n    self.gap = endog_f.mean() - endog_s.mean()\n    if swap and self.gap < 0:\n        (endog_f, endog_s) = (endog_s, endog_f)\n        (exog_f, exog_s) = (exog_s, exog_f)\n        self.gap = endog_f.mean() - endog_s.mean()\n        (bi[0], bi[1]) = (bi[1], bi[0])\n    self.bi = bi\n    if hasconst is False:\n        exog_f = add_constant(exog_f, prepend=False)\n        exog_s = add_constant(exog_s, prepend=False)\n        self.exog = add_constant(self.exog, prepend=False)\n        self.neumark = add_constant(self.neumark, prepend=False)\n    self.exog_f_mean = np.mean(exog_f, axis=0)\n    self.exog_s_mean = np.mean(exog_s, axis=0)\n    self._f_model = OLS(endog_f, exog_f).fit(cov_type=cov_type, cov_kwds=cov_kwds)\n    self._s_model = OLS(endog_s, exog_s).fit(cov_type=cov_type, cov_kwds=cov_kwds)",
            "def __init__(self, endog, exog, bifurcate, hasconst=True, swap=True, cov_type='nonrobust', cov_kwds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if str(type(exog)).find('pandas') != -1:\n        bifurcate = exog.columns.get_loc(bifurcate)\n        (endog, exog) = (np.array(endog), np.array(exog))\n    self.two_fold_type = None\n    self.bifurcate = bifurcate\n    self.cov_type = cov_type\n    self.cov_kwds = cov_kwds\n    self.neumark = np.delete(exog, bifurcate, axis=1)\n    self.exog = exog\n    self.hasconst = hasconst\n    bi_col = exog[:, bifurcate]\n    endog = np.column_stack((bi_col, endog))\n    bi = np.unique(bi_col)\n    self.bi_col = bi_col\n    exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n    exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n    endog_f = endog[np.where(endog[:, 0] == bi[0])]\n    endog_s = endog[np.where(endog[:, 0] == bi[1])]\n    exog_f = np.delete(exog_f, bifurcate, axis=1)\n    exog_s = np.delete(exog_s, bifurcate, axis=1)\n    endog_f = endog_f[:, 1]\n    endog_s = endog_s[:, 1]\n    self.endog = endog[:, 1]\n    (self.len_f, self.len_s) = (len(endog_f), len(endog_s))\n    self.gap = endog_f.mean() - endog_s.mean()\n    if swap and self.gap < 0:\n        (endog_f, endog_s) = (endog_s, endog_f)\n        (exog_f, exog_s) = (exog_s, exog_f)\n        self.gap = endog_f.mean() - endog_s.mean()\n        (bi[0], bi[1]) = (bi[1], bi[0])\n    self.bi = bi\n    if hasconst is False:\n        exog_f = add_constant(exog_f, prepend=False)\n        exog_s = add_constant(exog_s, prepend=False)\n        self.exog = add_constant(self.exog, prepend=False)\n        self.neumark = add_constant(self.neumark, prepend=False)\n    self.exog_f_mean = np.mean(exog_f, axis=0)\n    self.exog_s_mean = np.mean(exog_s, axis=0)\n    self._f_model = OLS(endog_f, exog_f).fit(cov_type=cov_type, cov_kwds=cov_kwds)\n    self._s_model = OLS(endog_s, exog_s).fit(cov_type=cov_type, cov_kwds=cov_kwds)",
            "def __init__(self, endog, exog, bifurcate, hasconst=True, swap=True, cov_type='nonrobust', cov_kwds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if str(type(exog)).find('pandas') != -1:\n        bifurcate = exog.columns.get_loc(bifurcate)\n        (endog, exog) = (np.array(endog), np.array(exog))\n    self.two_fold_type = None\n    self.bifurcate = bifurcate\n    self.cov_type = cov_type\n    self.cov_kwds = cov_kwds\n    self.neumark = np.delete(exog, bifurcate, axis=1)\n    self.exog = exog\n    self.hasconst = hasconst\n    bi_col = exog[:, bifurcate]\n    endog = np.column_stack((bi_col, endog))\n    bi = np.unique(bi_col)\n    self.bi_col = bi_col\n    exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n    exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n    endog_f = endog[np.where(endog[:, 0] == bi[0])]\n    endog_s = endog[np.where(endog[:, 0] == bi[1])]\n    exog_f = np.delete(exog_f, bifurcate, axis=1)\n    exog_s = np.delete(exog_s, bifurcate, axis=1)\n    endog_f = endog_f[:, 1]\n    endog_s = endog_s[:, 1]\n    self.endog = endog[:, 1]\n    (self.len_f, self.len_s) = (len(endog_f), len(endog_s))\n    self.gap = endog_f.mean() - endog_s.mean()\n    if swap and self.gap < 0:\n        (endog_f, endog_s) = (endog_s, endog_f)\n        (exog_f, exog_s) = (exog_s, exog_f)\n        self.gap = endog_f.mean() - endog_s.mean()\n        (bi[0], bi[1]) = (bi[1], bi[0])\n    self.bi = bi\n    if hasconst is False:\n        exog_f = add_constant(exog_f, prepend=False)\n        exog_s = add_constant(exog_s, prepend=False)\n        self.exog = add_constant(self.exog, prepend=False)\n        self.neumark = add_constant(self.neumark, prepend=False)\n    self.exog_f_mean = np.mean(exog_f, axis=0)\n    self.exog_s_mean = np.mean(exog_s, axis=0)\n    self._f_model = OLS(endog_f, exog_f).fit(cov_type=cov_type, cov_kwds=cov_kwds)\n    self._s_model = OLS(endog_s, exog_s).fit(cov_type=cov_type, cov_kwds=cov_kwds)",
            "def __init__(self, endog, exog, bifurcate, hasconst=True, swap=True, cov_type='nonrobust', cov_kwds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if str(type(exog)).find('pandas') != -1:\n        bifurcate = exog.columns.get_loc(bifurcate)\n        (endog, exog) = (np.array(endog), np.array(exog))\n    self.two_fold_type = None\n    self.bifurcate = bifurcate\n    self.cov_type = cov_type\n    self.cov_kwds = cov_kwds\n    self.neumark = np.delete(exog, bifurcate, axis=1)\n    self.exog = exog\n    self.hasconst = hasconst\n    bi_col = exog[:, bifurcate]\n    endog = np.column_stack((bi_col, endog))\n    bi = np.unique(bi_col)\n    self.bi_col = bi_col\n    exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n    exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n    endog_f = endog[np.where(endog[:, 0] == bi[0])]\n    endog_s = endog[np.where(endog[:, 0] == bi[1])]\n    exog_f = np.delete(exog_f, bifurcate, axis=1)\n    exog_s = np.delete(exog_s, bifurcate, axis=1)\n    endog_f = endog_f[:, 1]\n    endog_s = endog_s[:, 1]\n    self.endog = endog[:, 1]\n    (self.len_f, self.len_s) = (len(endog_f), len(endog_s))\n    self.gap = endog_f.mean() - endog_s.mean()\n    if swap and self.gap < 0:\n        (endog_f, endog_s) = (endog_s, endog_f)\n        (exog_f, exog_s) = (exog_s, exog_f)\n        self.gap = endog_f.mean() - endog_s.mean()\n        (bi[0], bi[1]) = (bi[1], bi[0])\n    self.bi = bi\n    if hasconst is False:\n        exog_f = add_constant(exog_f, prepend=False)\n        exog_s = add_constant(exog_s, prepend=False)\n        self.exog = add_constant(self.exog, prepend=False)\n        self.neumark = add_constant(self.neumark, prepend=False)\n    self.exog_f_mean = np.mean(exog_f, axis=0)\n    self.exog_s_mean = np.mean(exog_s, axis=0)\n    self._f_model = OLS(endog_f, exog_f).fit(cov_type=cov_type, cov_kwds=cov_kwds)\n    self._s_model = OLS(endog_s, exog_s).fit(cov_type=cov_type, cov_kwds=cov_kwds)"
        ]
    },
    {
        "func_name": "variance",
        "original": "def variance(self, decomp_type, n=5000, conf=0.99):\n    \"\"\"\n        A helper function to calculate the variance/std. Used to keep\n        the decomposition functions cleaner\n        \"\"\"\n    if self.submitted_n is not None:\n        n = self.submitted_n\n    if self.submitted_conf is not None:\n        conf = self.submitted_conf\n    if self.submitted_weight is not None:\n        submitted_weight = [self.submitted_weight, 1 - self.submitted_weight]\n    bi = self.bi\n    bifurcate = self.bifurcate\n    endow_eff_list = []\n    coef_eff_list = []\n    int_eff_list = []\n    exp_eff_list = []\n    unexp_eff_list = []\n    for _ in range(0, n):\n        endog = np.column_stack((self.bi_col, self.endog))\n        exog = self.exog\n        amount = len(endog)\n        samples = np.random.randint(0, high=amount, size=amount)\n        endog = endog[samples]\n        exog = exog[samples]\n        neumark = np.delete(exog, bifurcate, axis=1)\n        exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n        exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n        endog_f = endog[np.where(endog[:, 0] == bi[0])]\n        endog_s = endog[np.where(endog[:, 0] == bi[1])]\n        exog_f = np.delete(exog_f, bifurcate, axis=1)\n        exog_s = np.delete(exog_s, bifurcate, axis=1)\n        endog_f = endog_f[:, 1]\n        endog_s = endog_s[:, 1]\n        endog = endog[:, 1]\n        two_fold_type = self.two_fold_type\n        if self.hasconst is False:\n            exog_f = add_constant(exog_f, prepend=False)\n            exog_s = add_constant(exog_s, prepend=False)\n            exog = add_constant(exog, prepend=False)\n            neumark = add_constant(neumark, prepend=False)\n        _f_model = OLS(endog_f, exog_f).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        _s_model = OLS(endog_s, exog_s).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        exog_f_mean = np.mean(exog_f, axis=0)\n        exog_s_mean = np.mean(exog_s, axis=0)\n        if decomp_type == 3:\n            endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params\n            coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)\n            int_eff = (exog_f_mean - exog_s_mean) @ (_f_model.params - _s_model.params)\n            endow_eff_list.append(endow_eff)\n            coef_eff_list.append(coef_eff)\n            int_eff_list.append(int_eff)\n        elif decomp_type == 2:\n            len_f = len(exog_f)\n            len_s = len(exog_s)\n            if two_fold_type == 'cotton':\n                t_params = len_f / (len_f + len_s) * _f_model.params + len_s / (len_f + len_s) * _s_model.params\n            elif two_fold_type == 'reimers':\n                t_params = 0.5 * (_f_model.params + _s_model.params)\n            elif two_fold_type == 'self_submitted':\n                t_params = submitted_weight[0] * _f_model.params + submitted_weight[1] * _s_model.params\n            elif two_fold_type == 'nuemark':\n                _t_model = OLS(endog, neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = _t_model.params\n            else:\n                _t_model = OLS(endog, exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = np.delete(_t_model.params, bifurcate)\n            unexplained = exog_f_mean @ (_f_model.params - t_params) + exog_s_mean @ (t_params - _s_model.params)\n            explained = (exog_f_mean - exog_s_mean) @ t_params\n            unexp_eff_list.append(unexplained)\n            exp_eff_list.append(explained)\n    (high, low) = (int(n * conf), int(n * (1 - conf)))\n    if decomp_type == 3:\n        return [np.std(np.sort(endow_eff_list)[low:high]), np.std(np.sort(coef_eff_list)[low:high]), np.std(np.sort(int_eff_list)[low:high])]\n    elif decomp_type == 2:\n        return [np.std(np.sort(unexp_eff_list)[low:high]), np.std(np.sort(exp_eff_list)[low:high])]",
        "mutated": [
            "def variance(self, decomp_type, n=5000, conf=0.99):\n    if False:\n        i = 10\n    '\\n        A helper function to calculate the variance/std. Used to keep\\n        the decomposition functions cleaner\\n        '\n    if self.submitted_n is not None:\n        n = self.submitted_n\n    if self.submitted_conf is not None:\n        conf = self.submitted_conf\n    if self.submitted_weight is not None:\n        submitted_weight = [self.submitted_weight, 1 - self.submitted_weight]\n    bi = self.bi\n    bifurcate = self.bifurcate\n    endow_eff_list = []\n    coef_eff_list = []\n    int_eff_list = []\n    exp_eff_list = []\n    unexp_eff_list = []\n    for _ in range(0, n):\n        endog = np.column_stack((self.bi_col, self.endog))\n        exog = self.exog\n        amount = len(endog)\n        samples = np.random.randint(0, high=amount, size=amount)\n        endog = endog[samples]\n        exog = exog[samples]\n        neumark = np.delete(exog, bifurcate, axis=1)\n        exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n        exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n        endog_f = endog[np.where(endog[:, 0] == bi[0])]\n        endog_s = endog[np.where(endog[:, 0] == bi[1])]\n        exog_f = np.delete(exog_f, bifurcate, axis=1)\n        exog_s = np.delete(exog_s, bifurcate, axis=1)\n        endog_f = endog_f[:, 1]\n        endog_s = endog_s[:, 1]\n        endog = endog[:, 1]\n        two_fold_type = self.two_fold_type\n        if self.hasconst is False:\n            exog_f = add_constant(exog_f, prepend=False)\n            exog_s = add_constant(exog_s, prepend=False)\n            exog = add_constant(exog, prepend=False)\n            neumark = add_constant(neumark, prepend=False)\n        _f_model = OLS(endog_f, exog_f).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        _s_model = OLS(endog_s, exog_s).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        exog_f_mean = np.mean(exog_f, axis=0)\n        exog_s_mean = np.mean(exog_s, axis=0)\n        if decomp_type == 3:\n            endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params\n            coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)\n            int_eff = (exog_f_mean - exog_s_mean) @ (_f_model.params - _s_model.params)\n            endow_eff_list.append(endow_eff)\n            coef_eff_list.append(coef_eff)\n            int_eff_list.append(int_eff)\n        elif decomp_type == 2:\n            len_f = len(exog_f)\n            len_s = len(exog_s)\n            if two_fold_type == 'cotton':\n                t_params = len_f / (len_f + len_s) * _f_model.params + len_s / (len_f + len_s) * _s_model.params\n            elif two_fold_type == 'reimers':\n                t_params = 0.5 * (_f_model.params + _s_model.params)\n            elif two_fold_type == 'self_submitted':\n                t_params = submitted_weight[0] * _f_model.params + submitted_weight[1] * _s_model.params\n            elif two_fold_type == 'nuemark':\n                _t_model = OLS(endog, neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = _t_model.params\n            else:\n                _t_model = OLS(endog, exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = np.delete(_t_model.params, bifurcate)\n            unexplained = exog_f_mean @ (_f_model.params - t_params) + exog_s_mean @ (t_params - _s_model.params)\n            explained = (exog_f_mean - exog_s_mean) @ t_params\n            unexp_eff_list.append(unexplained)\n            exp_eff_list.append(explained)\n    (high, low) = (int(n * conf), int(n * (1 - conf)))\n    if decomp_type == 3:\n        return [np.std(np.sort(endow_eff_list)[low:high]), np.std(np.sort(coef_eff_list)[low:high]), np.std(np.sort(int_eff_list)[low:high])]\n    elif decomp_type == 2:\n        return [np.std(np.sort(unexp_eff_list)[low:high]), np.std(np.sort(exp_eff_list)[low:high])]",
            "def variance(self, decomp_type, n=5000, conf=0.99):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        A helper function to calculate the variance/std. Used to keep\\n        the decomposition functions cleaner\\n        '\n    if self.submitted_n is not None:\n        n = self.submitted_n\n    if self.submitted_conf is not None:\n        conf = self.submitted_conf\n    if self.submitted_weight is not None:\n        submitted_weight = [self.submitted_weight, 1 - self.submitted_weight]\n    bi = self.bi\n    bifurcate = self.bifurcate\n    endow_eff_list = []\n    coef_eff_list = []\n    int_eff_list = []\n    exp_eff_list = []\n    unexp_eff_list = []\n    for _ in range(0, n):\n        endog = np.column_stack((self.bi_col, self.endog))\n        exog = self.exog\n        amount = len(endog)\n        samples = np.random.randint(0, high=amount, size=amount)\n        endog = endog[samples]\n        exog = exog[samples]\n        neumark = np.delete(exog, bifurcate, axis=1)\n        exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n        exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n        endog_f = endog[np.where(endog[:, 0] == bi[0])]\n        endog_s = endog[np.where(endog[:, 0] == bi[1])]\n        exog_f = np.delete(exog_f, bifurcate, axis=1)\n        exog_s = np.delete(exog_s, bifurcate, axis=1)\n        endog_f = endog_f[:, 1]\n        endog_s = endog_s[:, 1]\n        endog = endog[:, 1]\n        two_fold_type = self.two_fold_type\n        if self.hasconst is False:\n            exog_f = add_constant(exog_f, prepend=False)\n            exog_s = add_constant(exog_s, prepend=False)\n            exog = add_constant(exog, prepend=False)\n            neumark = add_constant(neumark, prepend=False)\n        _f_model = OLS(endog_f, exog_f).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        _s_model = OLS(endog_s, exog_s).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        exog_f_mean = np.mean(exog_f, axis=0)\n        exog_s_mean = np.mean(exog_s, axis=0)\n        if decomp_type == 3:\n            endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params\n            coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)\n            int_eff = (exog_f_mean - exog_s_mean) @ (_f_model.params - _s_model.params)\n            endow_eff_list.append(endow_eff)\n            coef_eff_list.append(coef_eff)\n            int_eff_list.append(int_eff)\n        elif decomp_type == 2:\n            len_f = len(exog_f)\n            len_s = len(exog_s)\n            if two_fold_type == 'cotton':\n                t_params = len_f / (len_f + len_s) * _f_model.params + len_s / (len_f + len_s) * _s_model.params\n            elif two_fold_type == 'reimers':\n                t_params = 0.5 * (_f_model.params + _s_model.params)\n            elif two_fold_type == 'self_submitted':\n                t_params = submitted_weight[0] * _f_model.params + submitted_weight[1] * _s_model.params\n            elif two_fold_type == 'nuemark':\n                _t_model = OLS(endog, neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = _t_model.params\n            else:\n                _t_model = OLS(endog, exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = np.delete(_t_model.params, bifurcate)\n            unexplained = exog_f_mean @ (_f_model.params - t_params) + exog_s_mean @ (t_params - _s_model.params)\n            explained = (exog_f_mean - exog_s_mean) @ t_params\n            unexp_eff_list.append(unexplained)\n            exp_eff_list.append(explained)\n    (high, low) = (int(n * conf), int(n * (1 - conf)))\n    if decomp_type == 3:\n        return [np.std(np.sort(endow_eff_list)[low:high]), np.std(np.sort(coef_eff_list)[low:high]), np.std(np.sort(int_eff_list)[low:high])]\n    elif decomp_type == 2:\n        return [np.std(np.sort(unexp_eff_list)[low:high]), np.std(np.sort(exp_eff_list)[low:high])]",
            "def variance(self, decomp_type, n=5000, conf=0.99):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        A helper function to calculate the variance/std. Used to keep\\n        the decomposition functions cleaner\\n        '\n    if self.submitted_n is not None:\n        n = self.submitted_n\n    if self.submitted_conf is not None:\n        conf = self.submitted_conf\n    if self.submitted_weight is not None:\n        submitted_weight = [self.submitted_weight, 1 - self.submitted_weight]\n    bi = self.bi\n    bifurcate = self.bifurcate\n    endow_eff_list = []\n    coef_eff_list = []\n    int_eff_list = []\n    exp_eff_list = []\n    unexp_eff_list = []\n    for _ in range(0, n):\n        endog = np.column_stack((self.bi_col, self.endog))\n        exog = self.exog\n        amount = len(endog)\n        samples = np.random.randint(0, high=amount, size=amount)\n        endog = endog[samples]\n        exog = exog[samples]\n        neumark = np.delete(exog, bifurcate, axis=1)\n        exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n        exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n        endog_f = endog[np.where(endog[:, 0] == bi[0])]\n        endog_s = endog[np.where(endog[:, 0] == bi[1])]\n        exog_f = np.delete(exog_f, bifurcate, axis=1)\n        exog_s = np.delete(exog_s, bifurcate, axis=1)\n        endog_f = endog_f[:, 1]\n        endog_s = endog_s[:, 1]\n        endog = endog[:, 1]\n        two_fold_type = self.two_fold_type\n        if self.hasconst is False:\n            exog_f = add_constant(exog_f, prepend=False)\n            exog_s = add_constant(exog_s, prepend=False)\n            exog = add_constant(exog, prepend=False)\n            neumark = add_constant(neumark, prepend=False)\n        _f_model = OLS(endog_f, exog_f).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        _s_model = OLS(endog_s, exog_s).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        exog_f_mean = np.mean(exog_f, axis=0)\n        exog_s_mean = np.mean(exog_s, axis=0)\n        if decomp_type == 3:\n            endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params\n            coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)\n            int_eff = (exog_f_mean - exog_s_mean) @ (_f_model.params - _s_model.params)\n            endow_eff_list.append(endow_eff)\n            coef_eff_list.append(coef_eff)\n            int_eff_list.append(int_eff)\n        elif decomp_type == 2:\n            len_f = len(exog_f)\n            len_s = len(exog_s)\n            if two_fold_type == 'cotton':\n                t_params = len_f / (len_f + len_s) * _f_model.params + len_s / (len_f + len_s) * _s_model.params\n            elif two_fold_type == 'reimers':\n                t_params = 0.5 * (_f_model.params + _s_model.params)\n            elif two_fold_type == 'self_submitted':\n                t_params = submitted_weight[0] * _f_model.params + submitted_weight[1] * _s_model.params\n            elif two_fold_type == 'nuemark':\n                _t_model = OLS(endog, neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = _t_model.params\n            else:\n                _t_model = OLS(endog, exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = np.delete(_t_model.params, bifurcate)\n            unexplained = exog_f_mean @ (_f_model.params - t_params) + exog_s_mean @ (t_params - _s_model.params)\n            explained = (exog_f_mean - exog_s_mean) @ t_params\n            unexp_eff_list.append(unexplained)\n            exp_eff_list.append(explained)\n    (high, low) = (int(n * conf), int(n * (1 - conf)))\n    if decomp_type == 3:\n        return [np.std(np.sort(endow_eff_list)[low:high]), np.std(np.sort(coef_eff_list)[low:high]), np.std(np.sort(int_eff_list)[low:high])]\n    elif decomp_type == 2:\n        return [np.std(np.sort(unexp_eff_list)[low:high]), np.std(np.sort(exp_eff_list)[low:high])]",
            "def variance(self, decomp_type, n=5000, conf=0.99):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        A helper function to calculate the variance/std. Used to keep\\n        the decomposition functions cleaner\\n        '\n    if self.submitted_n is not None:\n        n = self.submitted_n\n    if self.submitted_conf is not None:\n        conf = self.submitted_conf\n    if self.submitted_weight is not None:\n        submitted_weight = [self.submitted_weight, 1 - self.submitted_weight]\n    bi = self.bi\n    bifurcate = self.bifurcate\n    endow_eff_list = []\n    coef_eff_list = []\n    int_eff_list = []\n    exp_eff_list = []\n    unexp_eff_list = []\n    for _ in range(0, n):\n        endog = np.column_stack((self.bi_col, self.endog))\n        exog = self.exog\n        amount = len(endog)\n        samples = np.random.randint(0, high=amount, size=amount)\n        endog = endog[samples]\n        exog = exog[samples]\n        neumark = np.delete(exog, bifurcate, axis=1)\n        exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n        exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n        endog_f = endog[np.where(endog[:, 0] == bi[0])]\n        endog_s = endog[np.where(endog[:, 0] == bi[1])]\n        exog_f = np.delete(exog_f, bifurcate, axis=1)\n        exog_s = np.delete(exog_s, bifurcate, axis=1)\n        endog_f = endog_f[:, 1]\n        endog_s = endog_s[:, 1]\n        endog = endog[:, 1]\n        two_fold_type = self.two_fold_type\n        if self.hasconst is False:\n            exog_f = add_constant(exog_f, prepend=False)\n            exog_s = add_constant(exog_s, prepend=False)\n            exog = add_constant(exog, prepend=False)\n            neumark = add_constant(neumark, prepend=False)\n        _f_model = OLS(endog_f, exog_f).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        _s_model = OLS(endog_s, exog_s).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        exog_f_mean = np.mean(exog_f, axis=0)\n        exog_s_mean = np.mean(exog_s, axis=0)\n        if decomp_type == 3:\n            endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params\n            coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)\n            int_eff = (exog_f_mean - exog_s_mean) @ (_f_model.params - _s_model.params)\n            endow_eff_list.append(endow_eff)\n            coef_eff_list.append(coef_eff)\n            int_eff_list.append(int_eff)\n        elif decomp_type == 2:\n            len_f = len(exog_f)\n            len_s = len(exog_s)\n            if two_fold_type == 'cotton':\n                t_params = len_f / (len_f + len_s) * _f_model.params + len_s / (len_f + len_s) * _s_model.params\n            elif two_fold_type == 'reimers':\n                t_params = 0.5 * (_f_model.params + _s_model.params)\n            elif two_fold_type == 'self_submitted':\n                t_params = submitted_weight[0] * _f_model.params + submitted_weight[1] * _s_model.params\n            elif two_fold_type == 'nuemark':\n                _t_model = OLS(endog, neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = _t_model.params\n            else:\n                _t_model = OLS(endog, exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = np.delete(_t_model.params, bifurcate)\n            unexplained = exog_f_mean @ (_f_model.params - t_params) + exog_s_mean @ (t_params - _s_model.params)\n            explained = (exog_f_mean - exog_s_mean) @ t_params\n            unexp_eff_list.append(unexplained)\n            exp_eff_list.append(explained)\n    (high, low) = (int(n * conf), int(n * (1 - conf)))\n    if decomp_type == 3:\n        return [np.std(np.sort(endow_eff_list)[low:high]), np.std(np.sort(coef_eff_list)[low:high]), np.std(np.sort(int_eff_list)[low:high])]\n    elif decomp_type == 2:\n        return [np.std(np.sort(unexp_eff_list)[low:high]), np.std(np.sort(exp_eff_list)[low:high])]",
            "def variance(self, decomp_type, n=5000, conf=0.99):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        A helper function to calculate the variance/std. Used to keep\\n        the decomposition functions cleaner\\n        '\n    if self.submitted_n is not None:\n        n = self.submitted_n\n    if self.submitted_conf is not None:\n        conf = self.submitted_conf\n    if self.submitted_weight is not None:\n        submitted_weight = [self.submitted_weight, 1 - self.submitted_weight]\n    bi = self.bi\n    bifurcate = self.bifurcate\n    endow_eff_list = []\n    coef_eff_list = []\n    int_eff_list = []\n    exp_eff_list = []\n    unexp_eff_list = []\n    for _ in range(0, n):\n        endog = np.column_stack((self.bi_col, self.endog))\n        exog = self.exog\n        amount = len(endog)\n        samples = np.random.randint(0, high=amount, size=amount)\n        endog = endog[samples]\n        exog = exog[samples]\n        neumark = np.delete(exog, bifurcate, axis=1)\n        exog_f = exog[np.where(exog[:, bifurcate] == bi[0])]\n        exog_s = exog[np.where(exog[:, bifurcate] == bi[1])]\n        endog_f = endog[np.where(endog[:, 0] == bi[0])]\n        endog_s = endog[np.where(endog[:, 0] == bi[1])]\n        exog_f = np.delete(exog_f, bifurcate, axis=1)\n        exog_s = np.delete(exog_s, bifurcate, axis=1)\n        endog_f = endog_f[:, 1]\n        endog_s = endog_s[:, 1]\n        endog = endog[:, 1]\n        two_fold_type = self.two_fold_type\n        if self.hasconst is False:\n            exog_f = add_constant(exog_f, prepend=False)\n            exog_s = add_constant(exog_s, prepend=False)\n            exog = add_constant(exog, prepend=False)\n            neumark = add_constant(neumark, prepend=False)\n        _f_model = OLS(endog_f, exog_f).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        _s_model = OLS(endog_s, exog_s).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        exog_f_mean = np.mean(exog_f, axis=0)\n        exog_s_mean = np.mean(exog_s, axis=0)\n        if decomp_type == 3:\n            endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params\n            coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)\n            int_eff = (exog_f_mean - exog_s_mean) @ (_f_model.params - _s_model.params)\n            endow_eff_list.append(endow_eff)\n            coef_eff_list.append(coef_eff)\n            int_eff_list.append(int_eff)\n        elif decomp_type == 2:\n            len_f = len(exog_f)\n            len_s = len(exog_s)\n            if two_fold_type == 'cotton':\n                t_params = len_f / (len_f + len_s) * _f_model.params + len_s / (len_f + len_s) * _s_model.params\n            elif two_fold_type == 'reimers':\n                t_params = 0.5 * (_f_model.params + _s_model.params)\n            elif two_fold_type == 'self_submitted':\n                t_params = submitted_weight[0] * _f_model.params + submitted_weight[1] * _s_model.params\n            elif two_fold_type == 'nuemark':\n                _t_model = OLS(endog, neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = _t_model.params\n            else:\n                _t_model = OLS(endog, exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n                t_params = np.delete(_t_model.params, bifurcate)\n            unexplained = exog_f_mean @ (_f_model.params - t_params) + exog_s_mean @ (t_params - _s_model.params)\n            explained = (exog_f_mean - exog_s_mean) @ t_params\n            unexp_eff_list.append(unexplained)\n            exp_eff_list.append(explained)\n    (high, low) = (int(n * conf), int(n * (1 - conf)))\n    if decomp_type == 3:\n        return [np.std(np.sort(endow_eff_list)[low:high]), np.std(np.sort(coef_eff_list)[low:high]), np.std(np.sort(int_eff_list)[low:high])]\n    elif decomp_type == 2:\n        return [np.std(np.sort(unexp_eff_list)[low:high]), np.std(np.sort(exp_eff_list)[low:high])]"
        ]
    },
    {
        "func_name": "three_fold",
        "original": "def three_fold(self, std=False, n=None, conf=None):\n    \"\"\"\n        Calculates the three-fold Oaxaca Blinder Decompositions\n\n        Parameters\n        ----------\n        std: boolean, optional\n            If true, bootstrapped standard errors will be calculated.\n        n: int, optional\n            A amount of iterations to calculate the bootstrapped\n            standard errors. This defaults to 5000.\n        conf: float, optional\n            This is the confidence required for the standard error\n            calculation. Defaults to .99, but could be anything less\n            than or equal to one. One is heavy discouraged, due to the\n            extreme outliers inflating the variance.\n\n        Returns\n        -------\n        OaxacaResults\n            A results container for the three-fold decomposition.\n        \"\"\"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    self.submitted_weight = None\n    std_val = None\n    self.endow_eff = (self.exog_f_mean - self.exog_s_mean) @ self._s_model.params\n    self.coef_eff = self.exog_s_mean @ (self._f_model.params - self._s_model.params)\n    self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (self._f_model.params - self._s_model.params)\n    if std is True:\n        std_val = self.variance(3)\n    return OaxacaResults((self.endow_eff, self.coef_eff, self.int_eff, self.gap), 3, std_val=std_val)",
        "mutated": [
            "def three_fold(self, std=False, n=None, conf=None):\n    if False:\n        i = 10\n    '\\n        Calculates the three-fold Oaxaca Blinder Decompositions\\n\\n        Parameters\\n        ----------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the three-fold decomposition.\\n        '\n    self.submitted_n = n\n    self.submitted_conf = conf\n    self.submitted_weight = None\n    std_val = None\n    self.endow_eff = (self.exog_f_mean - self.exog_s_mean) @ self._s_model.params\n    self.coef_eff = self.exog_s_mean @ (self._f_model.params - self._s_model.params)\n    self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (self._f_model.params - self._s_model.params)\n    if std is True:\n        std_val = self.variance(3)\n    return OaxacaResults((self.endow_eff, self.coef_eff, self.int_eff, self.gap), 3, std_val=std_val)",
            "def three_fold(self, std=False, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Calculates the three-fold Oaxaca Blinder Decompositions\\n\\n        Parameters\\n        ----------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the three-fold decomposition.\\n        '\n    self.submitted_n = n\n    self.submitted_conf = conf\n    self.submitted_weight = None\n    std_val = None\n    self.endow_eff = (self.exog_f_mean - self.exog_s_mean) @ self._s_model.params\n    self.coef_eff = self.exog_s_mean @ (self._f_model.params - self._s_model.params)\n    self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (self._f_model.params - self._s_model.params)\n    if std is True:\n        std_val = self.variance(3)\n    return OaxacaResults((self.endow_eff, self.coef_eff, self.int_eff, self.gap), 3, std_val=std_val)",
            "def three_fold(self, std=False, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Calculates the three-fold Oaxaca Blinder Decompositions\\n\\n        Parameters\\n        ----------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the three-fold decomposition.\\n        '\n    self.submitted_n = n\n    self.submitted_conf = conf\n    self.submitted_weight = None\n    std_val = None\n    self.endow_eff = (self.exog_f_mean - self.exog_s_mean) @ self._s_model.params\n    self.coef_eff = self.exog_s_mean @ (self._f_model.params - self._s_model.params)\n    self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (self._f_model.params - self._s_model.params)\n    if std is True:\n        std_val = self.variance(3)\n    return OaxacaResults((self.endow_eff, self.coef_eff, self.int_eff, self.gap), 3, std_val=std_val)",
            "def three_fold(self, std=False, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Calculates the three-fold Oaxaca Blinder Decompositions\\n\\n        Parameters\\n        ----------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the three-fold decomposition.\\n        '\n    self.submitted_n = n\n    self.submitted_conf = conf\n    self.submitted_weight = None\n    std_val = None\n    self.endow_eff = (self.exog_f_mean - self.exog_s_mean) @ self._s_model.params\n    self.coef_eff = self.exog_s_mean @ (self._f_model.params - self._s_model.params)\n    self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (self._f_model.params - self._s_model.params)\n    if std is True:\n        std_val = self.variance(3)\n    return OaxacaResults((self.endow_eff, self.coef_eff, self.int_eff, self.gap), 3, std_val=std_val)",
            "def three_fold(self, std=False, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Calculates the three-fold Oaxaca Blinder Decompositions\\n\\n        Parameters\\n        ----------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the three-fold decomposition.\\n        '\n    self.submitted_n = n\n    self.submitted_conf = conf\n    self.submitted_weight = None\n    std_val = None\n    self.endow_eff = (self.exog_f_mean - self.exog_s_mean) @ self._s_model.params\n    self.coef_eff = self.exog_s_mean @ (self._f_model.params - self._s_model.params)\n    self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (self._f_model.params - self._s_model.params)\n    if std is True:\n        std_val = self.variance(3)\n    return OaxacaResults((self.endow_eff, self.coef_eff, self.int_eff, self.gap), 3, std_val=std_val)"
        ]
    },
    {
        "func_name": "two_fold",
        "original": "def two_fold(self, std=False, two_fold_type='pooled', submitted_weight=None, n=None, conf=None):\n    \"\"\"\n        Calculates the two-fold or pooled Oaxaca Blinder Decompositions\n\n        Methods\n        -------\n        std: boolean, optional\n            If true, bootstrapped standard errors will be calculated.\n\n        two_fold_type: string, optional\n            This method allows for the specific calculation of the\n            non-discriminatory model. There are four different types\n            available at this time. pooled, cotton, reimers, self_submitted.\n            Pooled is assumed and if a non-viable parameter is given,\n            pooled will be ran.\n\n            pooled - This type assumes that the pooled model's parameters\n            (a normal regression) is the non-discriminatory model.\n            This includes the indicator variable. This is generally\n            the best idea. If you have economic justification for\n            using others, then use others.\n\n            nuemark - This is similar to the pooled type, but the regression\n            is not done including the indicator variable.\n\n            cotton - This type uses the adjusted in Cotton (1988), which\n            accounts for the undervaluation of one group causing the\n            overevalution of another. It uses the sample size weights for\n            a linear combination of the two model parameters\n\n            reimers - This type uses a linear combination of the two\n            models with both parameters being 50% of the\n            non-discriminatory model.\n\n            self_submitted - This allows the user to submit their\n            own weights. Please be sure to put the weight of the larger mean\n            group only. This should be submitted in the\n            submitted_weights variable.\n\n        submitted_weight: int/float, required only for self_submitted,\n            This is the submitted weight for the larger mean. If the\n            weight for the larger mean is p, then the weight for the\n            other mean is 1-p. Only submit the first value.\n\n        n: int, optional\n            A amount of iterations to calculate the bootstrapped\n            standard errors. This defaults to 5000.\n        conf: float, optional\n            This is the confidence required for the standard error\n            calculation. Defaults to .99, but could be anything less\n            than or equal to one. One is heavy discouraged, due to the\n            extreme outliers inflating the variance.\n\n        Returns\n        -------\n        OaxacaResults\n            A results container for the two-fold decomposition.\n        \"\"\"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    std_val = None\n    self.two_fold_type = two_fold_type\n    self.submitted_weight = submitted_weight\n    if two_fold_type == 'cotton':\n        self.t_params = self.len_f / (self.len_f + self.len_s) * self._f_model.params + self.len_s / (self.len_f + self.len_s) * self._s_model.params\n    elif two_fold_type == 'reimers':\n        self.t_params = 0.5 * (self._f_model.params + self._s_model.params)\n    elif two_fold_type == 'self_submitted':\n        if submitted_weight is None:\n            raise ValueError('Please submit weights')\n        submitted_weight = [submitted_weight, 1 - submitted_weight]\n        self.t_params = submitted_weight[0] * self._f_model.params + submitted_weight[1] * self._s_model.params\n    elif two_fold_type == 'nuemark':\n        self._t_model = OLS(self.endog, self.neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = self._t_model.params\n    else:\n        self._t_model = OLS(self.endog, self.exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = np.delete(self._t_model.params, self.bifurcate)\n    self.unexplained = self.exog_f_mean @ (self._f_model.params - self.t_params) + self.exog_s_mean @ (self.t_params - self._s_model.params)\n    self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params\n    if std is True:\n        std_val = self.variance(2)\n    return OaxacaResults((self.unexplained, self.explained, self.gap), 2, std_val=std_val)",
        "mutated": [
            "def two_fold(self, std=False, two_fold_type='pooled', submitted_weight=None, n=None, conf=None):\n    if False:\n        i = 10\n    \"\\n        Calculates the two-fold or pooled Oaxaca Blinder Decompositions\\n\\n        Methods\\n        -------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n\\n        two_fold_type: string, optional\\n            This method allows for the specific calculation of the\\n            non-discriminatory model. There are four different types\\n            available at this time. pooled, cotton, reimers, self_submitted.\\n            Pooled is assumed and if a non-viable parameter is given,\\n            pooled will be ran.\\n\\n            pooled - This type assumes that the pooled model's parameters\\n            (a normal regression) is the non-discriminatory model.\\n            This includes the indicator variable. This is generally\\n            the best idea. If you have economic justification for\\n            using others, then use others.\\n\\n            nuemark - This is similar to the pooled type, but the regression\\n            is not done including the indicator variable.\\n\\n            cotton - This type uses the adjusted in Cotton (1988), which\\n            accounts for the undervaluation of one group causing the\\n            overevalution of another. It uses the sample size weights for\\n            a linear combination of the two model parameters\\n\\n            reimers - This type uses a linear combination of the two\\n            models with both parameters being 50% of the\\n            non-discriminatory model.\\n\\n            self_submitted - This allows the user to submit their\\n            own weights. Please be sure to put the weight of the larger mean\\n            group only. This should be submitted in the\\n            submitted_weights variable.\\n\\n        submitted_weight: int/float, required only for self_submitted,\\n            This is the submitted weight for the larger mean. If the\\n            weight for the larger mean is p, then the weight for the\\n            other mean is 1-p. Only submit the first value.\\n\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the two-fold decomposition.\\n        \"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    std_val = None\n    self.two_fold_type = two_fold_type\n    self.submitted_weight = submitted_weight\n    if two_fold_type == 'cotton':\n        self.t_params = self.len_f / (self.len_f + self.len_s) * self._f_model.params + self.len_s / (self.len_f + self.len_s) * self._s_model.params\n    elif two_fold_type == 'reimers':\n        self.t_params = 0.5 * (self._f_model.params + self._s_model.params)\n    elif two_fold_type == 'self_submitted':\n        if submitted_weight is None:\n            raise ValueError('Please submit weights')\n        submitted_weight = [submitted_weight, 1 - submitted_weight]\n        self.t_params = submitted_weight[0] * self._f_model.params + submitted_weight[1] * self._s_model.params\n    elif two_fold_type == 'nuemark':\n        self._t_model = OLS(self.endog, self.neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = self._t_model.params\n    else:\n        self._t_model = OLS(self.endog, self.exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = np.delete(self._t_model.params, self.bifurcate)\n    self.unexplained = self.exog_f_mean @ (self._f_model.params - self.t_params) + self.exog_s_mean @ (self.t_params - self._s_model.params)\n    self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params\n    if std is True:\n        std_val = self.variance(2)\n    return OaxacaResults((self.unexplained, self.explained, self.gap), 2, std_val=std_val)",
            "def two_fold(self, std=False, two_fold_type='pooled', submitted_weight=None, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Calculates the two-fold or pooled Oaxaca Blinder Decompositions\\n\\n        Methods\\n        -------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n\\n        two_fold_type: string, optional\\n            This method allows for the specific calculation of the\\n            non-discriminatory model. There are four different types\\n            available at this time. pooled, cotton, reimers, self_submitted.\\n            Pooled is assumed and if a non-viable parameter is given,\\n            pooled will be ran.\\n\\n            pooled - This type assumes that the pooled model's parameters\\n            (a normal regression) is the non-discriminatory model.\\n            This includes the indicator variable. This is generally\\n            the best idea. If you have economic justification for\\n            using others, then use others.\\n\\n            nuemark - This is similar to the pooled type, but the regression\\n            is not done including the indicator variable.\\n\\n            cotton - This type uses the adjusted in Cotton (1988), which\\n            accounts for the undervaluation of one group causing the\\n            overevalution of another. It uses the sample size weights for\\n            a linear combination of the two model parameters\\n\\n            reimers - This type uses a linear combination of the two\\n            models with both parameters being 50% of the\\n            non-discriminatory model.\\n\\n            self_submitted - This allows the user to submit their\\n            own weights. Please be sure to put the weight of the larger mean\\n            group only. This should be submitted in the\\n            submitted_weights variable.\\n\\n        submitted_weight: int/float, required only for self_submitted,\\n            This is the submitted weight for the larger mean. If the\\n            weight for the larger mean is p, then the weight for the\\n            other mean is 1-p. Only submit the first value.\\n\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the two-fold decomposition.\\n        \"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    std_val = None\n    self.two_fold_type = two_fold_type\n    self.submitted_weight = submitted_weight\n    if two_fold_type == 'cotton':\n        self.t_params = self.len_f / (self.len_f + self.len_s) * self._f_model.params + self.len_s / (self.len_f + self.len_s) * self._s_model.params\n    elif two_fold_type == 'reimers':\n        self.t_params = 0.5 * (self._f_model.params + self._s_model.params)\n    elif two_fold_type == 'self_submitted':\n        if submitted_weight is None:\n            raise ValueError('Please submit weights')\n        submitted_weight = [submitted_weight, 1 - submitted_weight]\n        self.t_params = submitted_weight[0] * self._f_model.params + submitted_weight[1] * self._s_model.params\n    elif two_fold_type == 'nuemark':\n        self._t_model = OLS(self.endog, self.neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = self._t_model.params\n    else:\n        self._t_model = OLS(self.endog, self.exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = np.delete(self._t_model.params, self.bifurcate)\n    self.unexplained = self.exog_f_mean @ (self._f_model.params - self.t_params) + self.exog_s_mean @ (self.t_params - self._s_model.params)\n    self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params\n    if std is True:\n        std_val = self.variance(2)\n    return OaxacaResults((self.unexplained, self.explained, self.gap), 2, std_val=std_val)",
            "def two_fold(self, std=False, two_fold_type='pooled', submitted_weight=None, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Calculates the two-fold or pooled Oaxaca Blinder Decompositions\\n\\n        Methods\\n        -------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n\\n        two_fold_type: string, optional\\n            This method allows for the specific calculation of the\\n            non-discriminatory model. There are four different types\\n            available at this time. pooled, cotton, reimers, self_submitted.\\n            Pooled is assumed and if a non-viable parameter is given,\\n            pooled will be ran.\\n\\n            pooled - This type assumes that the pooled model's parameters\\n            (a normal regression) is the non-discriminatory model.\\n            This includes the indicator variable. This is generally\\n            the best idea. If you have economic justification for\\n            using others, then use others.\\n\\n            nuemark - This is similar to the pooled type, but the regression\\n            is not done including the indicator variable.\\n\\n            cotton - This type uses the adjusted in Cotton (1988), which\\n            accounts for the undervaluation of one group causing the\\n            overevalution of another. It uses the sample size weights for\\n            a linear combination of the two model parameters\\n\\n            reimers - This type uses a linear combination of the two\\n            models with both parameters being 50% of the\\n            non-discriminatory model.\\n\\n            self_submitted - This allows the user to submit their\\n            own weights. Please be sure to put the weight of the larger mean\\n            group only. This should be submitted in the\\n            submitted_weights variable.\\n\\n        submitted_weight: int/float, required only for self_submitted,\\n            This is the submitted weight for the larger mean. If the\\n            weight for the larger mean is p, then the weight for the\\n            other mean is 1-p. Only submit the first value.\\n\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the two-fold decomposition.\\n        \"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    std_val = None\n    self.two_fold_type = two_fold_type\n    self.submitted_weight = submitted_weight\n    if two_fold_type == 'cotton':\n        self.t_params = self.len_f / (self.len_f + self.len_s) * self._f_model.params + self.len_s / (self.len_f + self.len_s) * self._s_model.params\n    elif two_fold_type == 'reimers':\n        self.t_params = 0.5 * (self._f_model.params + self._s_model.params)\n    elif two_fold_type == 'self_submitted':\n        if submitted_weight is None:\n            raise ValueError('Please submit weights')\n        submitted_weight = [submitted_weight, 1 - submitted_weight]\n        self.t_params = submitted_weight[0] * self._f_model.params + submitted_weight[1] * self._s_model.params\n    elif two_fold_type == 'nuemark':\n        self._t_model = OLS(self.endog, self.neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = self._t_model.params\n    else:\n        self._t_model = OLS(self.endog, self.exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = np.delete(self._t_model.params, self.bifurcate)\n    self.unexplained = self.exog_f_mean @ (self._f_model.params - self.t_params) + self.exog_s_mean @ (self.t_params - self._s_model.params)\n    self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params\n    if std is True:\n        std_val = self.variance(2)\n    return OaxacaResults((self.unexplained, self.explained, self.gap), 2, std_val=std_val)",
            "def two_fold(self, std=False, two_fold_type='pooled', submitted_weight=None, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Calculates the two-fold or pooled Oaxaca Blinder Decompositions\\n\\n        Methods\\n        -------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n\\n        two_fold_type: string, optional\\n            This method allows for the specific calculation of the\\n            non-discriminatory model. There are four different types\\n            available at this time. pooled, cotton, reimers, self_submitted.\\n            Pooled is assumed and if a non-viable parameter is given,\\n            pooled will be ran.\\n\\n            pooled - This type assumes that the pooled model's parameters\\n            (a normal regression) is the non-discriminatory model.\\n            This includes the indicator variable. This is generally\\n            the best idea. If you have economic justification for\\n            using others, then use others.\\n\\n            nuemark - This is similar to the pooled type, but the regression\\n            is not done including the indicator variable.\\n\\n            cotton - This type uses the adjusted in Cotton (1988), which\\n            accounts for the undervaluation of one group causing the\\n            overevalution of another. It uses the sample size weights for\\n            a linear combination of the two model parameters\\n\\n            reimers - This type uses a linear combination of the two\\n            models with both parameters being 50% of the\\n            non-discriminatory model.\\n\\n            self_submitted - This allows the user to submit their\\n            own weights. Please be sure to put the weight of the larger mean\\n            group only. This should be submitted in the\\n            submitted_weights variable.\\n\\n        submitted_weight: int/float, required only for self_submitted,\\n            This is the submitted weight for the larger mean. If the\\n            weight for the larger mean is p, then the weight for the\\n            other mean is 1-p. Only submit the first value.\\n\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the two-fold decomposition.\\n        \"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    std_val = None\n    self.two_fold_type = two_fold_type\n    self.submitted_weight = submitted_weight\n    if two_fold_type == 'cotton':\n        self.t_params = self.len_f / (self.len_f + self.len_s) * self._f_model.params + self.len_s / (self.len_f + self.len_s) * self._s_model.params\n    elif two_fold_type == 'reimers':\n        self.t_params = 0.5 * (self._f_model.params + self._s_model.params)\n    elif two_fold_type == 'self_submitted':\n        if submitted_weight is None:\n            raise ValueError('Please submit weights')\n        submitted_weight = [submitted_weight, 1 - submitted_weight]\n        self.t_params = submitted_weight[0] * self._f_model.params + submitted_weight[1] * self._s_model.params\n    elif two_fold_type == 'nuemark':\n        self._t_model = OLS(self.endog, self.neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = self._t_model.params\n    else:\n        self._t_model = OLS(self.endog, self.exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = np.delete(self._t_model.params, self.bifurcate)\n    self.unexplained = self.exog_f_mean @ (self._f_model.params - self.t_params) + self.exog_s_mean @ (self.t_params - self._s_model.params)\n    self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params\n    if std is True:\n        std_val = self.variance(2)\n    return OaxacaResults((self.unexplained, self.explained, self.gap), 2, std_val=std_val)",
            "def two_fold(self, std=False, two_fold_type='pooled', submitted_weight=None, n=None, conf=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Calculates the two-fold or pooled Oaxaca Blinder Decompositions\\n\\n        Methods\\n        -------\\n        std: boolean, optional\\n            If true, bootstrapped standard errors will be calculated.\\n\\n        two_fold_type: string, optional\\n            This method allows for the specific calculation of the\\n            non-discriminatory model. There are four different types\\n            available at this time. pooled, cotton, reimers, self_submitted.\\n            Pooled is assumed and if a non-viable parameter is given,\\n            pooled will be ran.\\n\\n            pooled - This type assumes that the pooled model's parameters\\n            (a normal regression) is the non-discriminatory model.\\n            This includes the indicator variable. This is generally\\n            the best idea. If you have economic justification for\\n            using others, then use others.\\n\\n            nuemark - This is similar to the pooled type, but the regression\\n            is not done including the indicator variable.\\n\\n            cotton - This type uses the adjusted in Cotton (1988), which\\n            accounts for the undervaluation of one group causing the\\n            overevalution of another. It uses the sample size weights for\\n            a linear combination of the two model parameters\\n\\n            reimers - This type uses a linear combination of the two\\n            models with both parameters being 50% of the\\n            non-discriminatory model.\\n\\n            self_submitted - This allows the user to submit their\\n            own weights. Please be sure to put the weight of the larger mean\\n            group only. This should be submitted in the\\n            submitted_weights variable.\\n\\n        submitted_weight: int/float, required only for self_submitted,\\n            This is the submitted weight for the larger mean. If the\\n            weight for the larger mean is p, then the weight for the\\n            other mean is 1-p. Only submit the first value.\\n\\n        n: int, optional\\n            A amount of iterations to calculate the bootstrapped\\n            standard errors. This defaults to 5000.\\n        conf: float, optional\\n            This is the confidence required for the standard error\\n            calculation. Defaults to .99, but could be anything less\\n            than or equal to one. One is heavy discouraged, due to the\\n            extreme outliers inflating the variance.\\n\\n        Returns\\n        -------\\n        OaxacaResults\\n            A results container for the two-fold decomposition.\\n        \"\n    self.submitted_n = n\n    self.submitted_conf = conf\n    std_val = None\n    self.two_fold_type = two_fold_type\n    self.submitted_weight = submitted_weight\n    if two_fold_type == 'cotton':\n        self.t_params = self.len_f / (self.len_f + self.len_s) * self._f_model.params + self.len_s / (self.len_f + self.len_s) * self._s_model.params\n    elif two_fold_type == 'reimers':\n        self.t_params = 0.5 * (self._f_model.params + self._s_model.params)\n    elif two_fold_type == 'self_submitted':\n        if submitted_weight is None:\n            raise ValueError('Please submit weights')\n        submitted_weight = [submitted_weight, 1 - submitted_weight]\n        self.t_params = submitted_weight[0] * self._f_model.params + submitted_weight[1] * self._s_model.params\n    elif two_fold_type == 'nuemark':\n        self._t_model = OLS(self.endog, self.neumark).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = self._t_model.params\n    else:\n        self._t_model = OLS(self.endog, self.exog).fit(cov_type=self.cov_type, cov_kwds=self.cov_kwds)\n        self.t_params = np.delete(self._t_model.params, self.bifurcate)\n    self.unexplained = self.exog_f_mean @ (self._f_model.params - self.t_params) + self.exog_s_mean @ (self.t_params - self._s_model.params)\n    self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params\n    if std is True:\n        std_val = self.variance(2)\n    return OaxacaResults((self.unexplained, self.explained, self.gap), 2, std_val=std_val)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, results, model_type, std_val=None):\n    self.params = results\n    self.std = std_val\n    self.model_type = model_type",
        "mutated": [
            "def __init__(self, results, model_type, std_val=None):\n    if False:\n        i = 10\n    self.params = results\n    self.std = std_val\n    self.model_type = model_type",
            "def __init__(self, results, model_type, std_val=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.params = results\n    self.std = std_val\n    self.model_type = model_type",
            "def __init__(self, results, model_type, std_val=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.params = results\n    self.std = std_val\n    self.model_type = model_type",
            "def __init__(self, results, model_type, std_val=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.params = results\n    self.std = std_val\n    self.model_type = model_type",
            "def __init__(self, results, model_type, std_val=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.params = results\n    self.std = std_val\n    self.model_type = model_type"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self):\n    \"\"\"\n        Print a summary table with the Oaxaca-Blinder effects\n        \"\"\"\n    if self.model_type == 2:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {self.params[0]:.5f}\\n                Explained Effect: {self.params[1]:.5f}\\n                Gap: {self.params[2]:.5f}'))\n        else:\n            print(dedent('                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {:.5f}\\n                Unexplained Standard Error: {:.5f}\\n                Explained Effect: {:.5f}\\n                Explained Standard Error: {:.5f}\\n                Gap: {:.5f}'.format(self.params[0], self.std[0], self.params[1], self.std[1], self.params[2])))\n    if self.model_type == 3:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))\n        else:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Endowment Standard Error: {self.std[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Coefficient Standard Error: {self.std[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Interaction Standard Error: {self.std[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))",
        "mutated": [
            "def summary(self):\n    if False:\n        i = 10\n    '\\n        Print a summary table with the Oaxaca-Blinder effects\\n        '\n    if self.model_type == 2:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {self.params[0]:.5f}\\n                Explained Effect: {self.params[1]:.5f}\\n                Gap: {self.params[2]:.5f}'))\n        else:\n            print(dedent('                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {:.5f}\\n                Unexplained Standard Error: {:.5f}\\n                Explained Effect: {:.5f}\\n                Explained Standard Error: {:.5f}\\n                Gap: {:.5f}'.format(self.params[0], self.std[0], self.params[1], self.std[1], self.params[2])))\n    if self.model_type == 3:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))\n        else:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Endowment Standard Error: {self.std[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Coefficient Standard Error: {self.std[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Interaction Standard Error: {self.std[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Print a summary table with the Oaxaca-Blinder effects\\n        '\n    if self.model_type == 2:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {self.params[0]:.5f}\\n                Explained Effect: {self.params[1]:.5f}\\n                Gap: {self.params[2]:.5f}'))\n        else:\n            print(dedent('                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {:.5f}\\n                Unexplained Standard Error: {:.5f}\\n                Explained Effect: {:.5f}\\n                Explained Standard Error: {:.5f}\\n                Gap: {:.5f}'.format(self.params[0], self.std[0], self.params[1], self.std[1], self.params[2])))\n    if self.model_type == 3:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))\n        else:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Endowment Standard Error: {self.std[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Coefficient Standard Error: {self.std[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Interaction Standard Error: {self.std[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Print a summary table with the Oaxaca-Blinder effects\\n        '\n    if self.model_type == 2:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {self.params[0]:.5f}\\n                Explained Effect: {self.params[1]:.5f}\\n                Gap: {self.params[2]:.5f}'))\n        else:\n            print(dedent('                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {:.5f}\\n                Unexplained Standard Error: {:.5f}\\n                Explained Effect: {:.5f}\\n                Explained Standard Error: {:.5f}\\n                Gap: {:.5f}'.format(self.params[0], self.std[0], self.params[1], self.std[1], self.params[2])))\n    if self.model_type == 3:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))\n        else:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Endowment Standard Error: {self.std[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Coefficient Standard Error: {self.std[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Interaction Standard Error: {self.std[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Print a summary table with the Oaxaca-Blinder effects\\n        '\n    if self.model_type == 2:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {self.params[0]:.5f}\\n                Explained Effect: {self.params[1]:.5f}\\n                Gap: {self.params[2]:.5f}'))\n        else:\n            print(dedent('                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {:.5f}\\n                Unexplained Standard Error: {:.5f}\\n                Explained Effect: {:.5f}\\n                Explained Standard Error: {:.5f}\\n                Gap: {:.5f}'.format(self.params[0], self.std[0], self.params[1], self.std[1], self.params[2])))\n    if self.model_type == 3:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))\n        else:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Endowment Standard Error: {self.std[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Coefficient Standard Error: {self.std[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Interaction Standard Error: {self.std[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Print a summary table with the Oaxaca-Blinder effects\\n        '\n    if self.model_type == 2:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {self.params[0]:.5f}\\n                Explained Effect: {self.params[1]:.5f}\\n                Gap: {self.params[2]:.5f}'))\n        else:\n            print(dedent('                Oaxaca-Blinder Two-fold Effects\\n                Unexplained Effect: {:.5f}\\n                Unexplained Standard Error: {:.5f}\\n                Explained Effect: {:.5f}\\n                Explained Standard Error: {:.5f}\\n                Gap: {:.5f}'.format(self.params[0], self.std[0], self.params[1], self.std[1], self.params[2])))\n    if self.model_type == 3:\n        if self.std is None:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))\n        else:\n            print(dedent(f'                Oaxaca-Blinder Three-fold Effects\\n                Endowment Effect: {self.params[0]:.5f}\\n                Endowment Standard Error: {self.std[0]:.5f}\\n                Coefficient Effect: {self.params[1]:.5f}\\n                Coefficient Standard Error: {self.std[1]:.5f}\\n                Interaction Effect: {self.params[2]:.5f}\\n                Interaction Standard Error: {self.std[2]:.5f}\\n                Gap: {self.params[3]:.5f}'))"
        ]
    }
]