import sys
sys.path.append('../')
import enum
from conv2d_common import CommonConvFunction, CommonCutlassConv2dDepthwiseKernelDeclare, CommonCutlassConvKernelExecute, CommonTail
from util import SubstituteTemplate
cdba_header = '\n// Generated by conv2d_depthwise_bias_act.py - Do not edit.\n\n#include <mutex>\n#include "paddle/phi/kernels/fusion/cutlass/conv2d/conv2d_util.h"\n#include <stdio.h>\n#include <algorithm>\n#include "cutlass/cutlass.h"\n#include "cutlass/gemm/device/gemm.h"\n#include "cutlass/conv/kernel/default_depthwise_fprop.h"\n#include "cutlass/epilogue/thread/linear_combination_silu.h"\n#include "cutlass/conv/device/direct_convolution.h"\n\n#include "cutlass/conv/device/implicit_gemm_convolution.h"\n#include "cutlass/conv/kernel/default_conv2d_fprop.h"\nnamespace phi {\nnamespace fusion {\nnamespace cutlass_internal {\n'
dict_for_declare_part = {'conv_kind_name': 'DefaultDepthwiseDirect2dConvFprop', 'epi_part': '${epi_func}< ${element_c}, ${epilogue_vector_length}, ${element_accum}, ${element_epilogue}>', 'swizzling_functor': 'cutlass::conv::threadblock::DepthwiseDirect2dConvIdentityThreadblockSwizzle<${swizzling_shape}>'}
cba_kernel_no_alpha = SubstituteTemplate(CommonCutlassConv2dDepthwiseKernelDeclare, dict_for_declare_part) + '\nsize_t filter_size = oc * kh * kw * kc * sizeof(half);\nphi::Allocator::AllocationPtr filter_gpu_ptrs_data =\n    phi::memory_utils::Alloc(\n        params.ctx->GetPlace(),\n        filter_size,\n        phi::Stream(reinterpret_cast<phi::StreamId>(params.ctx->stream())));\nvoid *filter_workspace = filter_gpu_ptrs_data->ptr();\n\n      typename ImplicitGemm::Arguments arguments{\n          problem_size,\n          {(cutlass::half_t *)input, {ic, ic * iw, ic * iw * ih}},\n          {(cutlass::half_t *)weight, {kc, kc * kw, kc * kw * kh}},\n          {(cutlass::half_t *)bias, {0, 0, 0}},\n          {(cutlass::half_t *)output, {oc, oc * ow, oc * ow * oh}},\n          {1.f, 1.f},\n           {(cutlass::half_t *)filter_workspace, {kc, kc * kw, kc * kw * kh}},\n           };\n' + CommonCutlassConvKernelExecute

class CbaAct(enum.Enum):
    Identity = 1
    Relu = 2
    Sigmoid = 3
    Silu = 4
SupportedAct = [CbaAct.Identity, CbaAct.Relu, CbaAct.Sigmoid, CbaAct.Silu]
ActTag = {SupportedAct[0]: 'cutlass::epilogue::thread::LinearCombination', SupportedAct[1]: 'cutlass::epilogue::thread::LinearCombinationRelu', SupportedAct[2]: 'cutlass::epilogue::thread::LinearCombinationSigmoid', SupportedAct[3]: 'cutlass::epilogue::thread::LinearCombinationSilu'}
UnderScoreName = {SupportedAct[0]: 'conv2d_depthwise_bias', SupportedAct[1]: 'conv2d_depthwise_bias_relu', SupportedAct[2]: 'conv2d_depthwise_bias_sigmoid', SupportedAct[3]: 'conv2d_depthwise_bias_silu'}
CamelName = {SupportedAct[0]: 'Conv2dDepthwiseBias', SupportedAct[1]: 'Conv2dDepthwiseBiasRelu', SupportedAct[2]: 'Conv2dDepthwiseBiasSigmoid', SupportedAct[3]: 'Conv2dDepthwiseBiasSilu'}

def intlist2str(input):
    if False:
        while True:
            i = 10
    return_str = ''
    for i in range(len(input)):
        return_str += str(input[i])
        if i != len(input) - 1:
            return_str += ','
    return return_str

def generate_conv2d_depthwise():
    if False:
        return 10
    kernel_dict = {'element_a': 'cutlass::half_t', 'layout_a': 'cutlass::layout::TensorNHWC', 'element_b': 'cutlass::half_t', 'layout_b': 'cutlass::layout::TensorNHWC', 'element_c': 'cutlass::half_t', 'layout_c': 'cutlass::layout::TensorNHWC', 'element_accum': 'cutlass::half_t', 'opcode_class': 'cutlass::arch::OpClassSimt', 'arch': 'cutlass::arch::Sm70', 'Ishape': '1,1,1', 'stages': '2', 'element_epilogue': 'float', 'math_operator': 'cutlass::arch::OpMultiplyAdd', 'iterator_algorithm': 'cutlass::conv::IteratorAlgorithm::kFixedStrideDilation', 'stride_support': 'cutlass::conv::StrideSupport::kStrided', 'dilation_shape': '1, 1'}
    kernel_dict['epilogue_vector_length'] = '4'
    all_code = ''
    for epi_func in SupportedAct:
        op_dict = {}
        op_dict['func_name'] = CamelName[epi_func]
        op_dict['enum_op_name'] = UnderScoreName[epi_func].upper()
        all_kernel_names = ''
        kernel_dict['epi_func'] = ActTag[epi_func]
        suffix = 0
        filter_shapes = [[3, 3], [5, 5]]
        stride_shapes = ['1,1', '2,2']
        for vec_length in ['8']:
            kernel_dict['epilogue_vector_length'] = vec_length
            for filter_shape in filter_shapes:
                for stride_shape in stride_shapes:
                    tiles = [[8, 8, 16, 16], [8, 8, 32, 16]]
                    filter_size = filter_shape[0] * filter_shape[1]
                    for tile in tiles:
                        kernel_dict['T_output_shape'] = intlist2str([1, tile[0], tile[1], tile[2]])
                        kernel_dict['Tshape'] = intlist2str([tile[0] * tile[1], tile[2], filter_size])
                        kernel_dict['Wshape'] = intlist2str([tile[3], tile[2], filter_size])
                        kernel_dict['swizzling_shape'] = intlist2str([1, 1, tile[0], tile[1]])
                        kernel_dict['split_k_slices'] = '(oh * ow + 63) / 64'
                        kernel_dict['filter_shape'] = intlist2str(filter_shape)
                        kernel_dict['strided_shape'] = stride_shape
                        kernel_dict['kernel_func_name'] = UnderScoreName[epi_func].lower() + '_' + str(suffix)
                        suffix += 1
                        all_code += SubstituteTemplate(cba_kernel_no_alpha, kernel_dict)
                        all_kernel_names += kernel_dict['kernel_func_name'] + ', \n'
        op_dict['all_kernel_func_name'] = all_kernel_names
        all_code += SubstituteTemplate(CommonConvFunction, op_dict)
    return all_code
if __name__ == '__main__':
    all_code = cdba_header
    all_code += generate_conv2d_depthwise()
    all_code += CommonTail
    with open('generated/conv2d_depthwise_bias_act.cu', 'w') as f:
        f.write(all_code)
        f.close()