[
    {
        "func_name": "__init__",
        "original": "def __init__(self, params: Optional[dict]=None) -> None:\n    self._assert_valid_params(params, self.DEFAULT_PARAM_DICT)\n    self.params = self.DEFAULT_PARAM_DICT.copy()\n    if params is not None:\n        self.params.update(params)\n    if self.params['adjust_pred_probs'] and self.params['method'] == 'gen':\n        print(\"CAUTION: GEN method is not recommended for use with adjusted pred_probs. To use GEN, we recommend setting: params['adjust_pred_probs'] = False\")",
        "mutated": [
            "def __init__(self, params: Optional[dict]=None) -> None:\n    if False:\n        i = 10\n    self._assert_valid_params(params, self.DEFAULT_PARAM_DICT)\n    self.params = self.DEFAULT_PARAM_DICT.copy()\n    if params is not None:\n        self.params.update(params)\n    if self.params['adjust_pred_probs'] and self.params['method'] == 'gen':\n        print(\"CAUTION: GEN method is not recommended for use with adjusted pred_probs. To use GEN, we recommend setting: params['adjust_pred_probs'] = False\")",
            "def __init__(self, params: Optional[dict]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._assert_valid_params(params, self.DEFAULT_PARAM_DICT)\n    self.params = self.DEFAULT_PARAM_DICT.copy()\n    if params is not None:\n        self.params.update(params)\n    if self.params['adjust_pred_probs'] and self.params['method'] == 'gen':\n        print(\"CAUTION: GEN method is not recommended for use with adjusted pred_probs. To use GEN, we recommend setting: params['adjust_pred_probs'] = False\")",
            "def __init__(self, params: Optional[dict]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._assert_valid_params(params, self.DEFAULT_PARAM_DICT)\n    self.params = self.DEFAULT_PARAM_DICT.copy()\n    if params is not None:\n        self.params.update(params)\n    if self.params['adjust_pred_probs'] and self.params['method'] == 'gen':\n        print(\"CAUTION: GEN method is not recommended for use with adjusted pred_probs. To use GEN, we recommend setting: params['adjust_pred_probs'] = False\")",
            "def __init__(self, params: Optional[dict]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._assert_valid_params(params, self.DEFAULT_PARAM_DICT)\n    self.params = self.DEFAULT_PARAM_DICT.copy()\n    if params is not None:\n        self.params.update(params)\n    if self.params['adjust_pred_probs'] and self.params['method'] == 'gen':\n        print(\"CAUTION: GEN method is not recommended for use with adjusted pred_probs. To use GEN, we recommend setting: params['adjust_pred_probs'] = False\")",
            "def __init__(self, params: Optional[dict]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._assert_valid_params(params, self.DEFAULT_PARAM_DICT)\n    self.params = self.DEFAULT_PARAM_DICT.copy()\n    if params is not None:\n        self.params.update(params)\n    if self.params['adjust_pred_probs'] and self.params['method'] == 'gen':\n        print(\"CAUTION: GEN method is not recommended for use with adjusted pred_probs. To use GEN, we recommend setting: params['adjust_pred_probs'] = False\")"
        ]
    },
    {
        "func_name": "fit_score",
        "original": "def fit_score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[np.ndarray]=None, verbose: bool=True) -> np.ndarray:\n    \"\"\"\n        Fits this estimator to a given dataset and returns out-of-distribution scores for the same dataset.\n\n        Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset\n        distribution (values near 0 indicate outliers). Exactly one of `features` or `pred_probs` needs to be passed\n        in to calculate scores.\n\n        If `features` are passed in a ``NearestNeighbors`` object is fit. If `pred_probs` and 'labels' are passed in a\n        `confident_thresholds` ``np.ndarray`` is fit. For details see `~cleanlab.outlier.OutOfDistribution.fit`.\n\n        Parameters\n        ----------\n        features : np.ndarray, optional\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\n          For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n        pred_probs : np.ndarray, optional\n          An array of shape ``(N, K)`` of predicted class probabilities output by a trained classifier.\n          For details, `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n        labels : array_like, optional\n          A discrete array of given class labels for the data of shape ``(N,)``.\n          For details, `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n        verbose : bool, default = True\n          Set to ``False`` to suppress all print statements.\n\n        Returns\n        -------\n        scores : np.ndarray\n          If `features` are passed in, `ood_features_scores` are returned.\n          If `pred_probs` are passed in, `ood_predictions_scores` are returned.\n          For details see return of `~cleanlab.outlier.OutOfDistribution.scores` function.\n\n        \"\"\"\n    scores = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)\n    if scores is None:\n        scores = self.score(features=features, pred_probs=pred_probs)\n    return scores",
        "mutated": [
            "def fit_score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[np.ndarray]=None, verbose: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n    \"\\n        Fits this estimator to a given dataset and returns out-of-distribution scores for the same dataset.\\n\\n        Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset\\n        distribution (values near 0 indicate outliers). Exactly one of `features` or `pred_probs` needs to be passed\\n        in to calculate scores.\\n\\n        If `features` are passed in a ``NearestNeighbors`` object is fit. If `pred_probs` and 'labels' are passed in a\\n        `confident_thresholds` ``np.ndarray`` is fit. For details see `~cleanlab.outlier.OutOfDistribution.fit`.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)`` of predicted class probabilities output by a trained classifier.\\n          For details, `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        labels : array_like, optional\\n          A discrete array of given class labels for the data of shape ``(N,)``.\\n          For details, `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          If `features` are passed in, `ood_features_scores` are returned.\\n          If `pred_probs` are passed in, `ood_predictions_scores` are returned.\\n          For details see return of `~cleanlab.outlier.OutOfDistribution.scores` function.\\n\\n        \"\n    scores = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)\n    if scores is None:\n        scores = self.score(features=features, pred_probs=pred_probs)\n    return scores",
            "def fit_score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[np.ndarray]=None, verbose: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Fits this estimator to a given dataset and returns out-of-distribution scores for the same dataset.\\n\\n        Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset\\n        distribution (values near 0 indicate outliers). Exactly one of `features` or `pred_probs` needs to be passed\\n        in to calculate scores.\\n\\n        If `features` are passed in a ``NearestNeighbors`` object is fit. If `pred_probs` and 'labels' are passed in a\\n        `confident_thresholds` ``np.ndarray`` is fit. For details see `~cleanlab.outlier.OutOfDistribution.fit`.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)`` of predicted class probabilities output by a trained classifier.\\n          For details, `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        labels : array_like, optional\\n          A discrete array of given class labels for the data of shape ``(N,)``.\\n          For details, `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          If `features` are passed in, `ood_features_scores` are returned.\\n          If `pred_probs` are passed in, `ood_predictions_scores` are returned.\\n          For details see return of `~cleanlab.outlier.OutOfDistribution.scores` function.\\n\\n        \"\n    scores = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)\n    if scores is None:\n        scores = self.score(features=features, pred_probs=pred_probs)\n    return scores",
            "def fit_score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[np.ndarray]=None, verbose: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Fits this estimator to a given dataset and returns out-of-distribution scores for the same dataset.\\n\\n        Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset\\n        distribution (values near 0 indicate outliers). Exactly one of `features` or `pred_probs` needs to be passed\\n        in to calculate scores.\\n\\n        If `features` are passed in a ``NearestNeighbors`` object is fit. If `pred_probs` and 'labels' are passed in a\\n        `confident_thresholds` ``np.ndarray`` is fit. For details see `~cleanlab.outlier.OutOfDistribution.fit`.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)`` of predicted class probabilities output by a trained classifier.\\n          For details, `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        labels : array_like, optional\\n          A discrete array of given class labels for the data of shape ``(N,)``.\\n          For details, `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          If `features` are passed in, `ood_features_scores` are returned.\\n          If `pred_probs` are passed in, `ood_predictions_scores` are returned.\\n          For details see return of `~cleanlab.outlier.OutOfDistribution.scores` function.\\n\\n        \"\n    scores = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)\n    if scores is None:\n        scores = self.score(features=features, pred_probs=pred_probs)\n    return scores",
            "def fit_score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[np.ndarray]=None, verbose: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Fits this estimator to a given dataset and returns out-of-distribution scores for the same dataset.\\n\\n        Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset\\n        distribution (values near 0 indicate outliers). Exactly one of `features` or `pred_probs` needs to be passed\\n        in to calculate scores.\\n\\n        If `features` are passed in a ``NearestNeighbors`` object is fit. If `pred_probs` and 'labels' are passed in a\\n        `confident_thresholds` ``np.ndarray`` is fit. For details see `~cleanlab.outlier.OutOfDistribution.fit`.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)`` of predicted class probabilities output by a trained classifier.\\n          For details, `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        labels : array_like, optional\\n          A discrete array of given class labels for the data of shape ``(N,)``.\\n          For details, `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          If `features` are passed in, `ood_features_scores` are returned.\\n          If `pred_probs` are passed in, `ood_predictions_scores` are returned.\\n          For details see return of `~cleanlab.outlier.OutOfDistribution.scores` function.\\n\\n        \"\n    scores = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)\n    if scores is None:\n        scores = self.score(features=features, pred_probs=pred_probs)\n    return scores",
            "def fit_score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[np.ndarray]=None, verbose: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Fits this estimator to a given dataset and returns out-of-distribution scores for the same dataset.\\n\\n        Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset\\n        distribution (values near 0 indicate outliers). Exactly one of `features` or `pred_probs` needs to be passed\\n        in to calculate scores.\\n\\n        If `features` are passed in a ``NearestNeighbors`` object is fit. If `pred_probs` and 'labels' are passed in a\\n        `confident_thresholds` ``np.ndarray`` is fit. For details see `~cleanlab.outlier.OutOfDistribution.fit`.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)`` of predicted class probabilities output by a trained classifier.\\n          For details, `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        labels : array_like, optional\\n          A discrete array of given class labels for the data of shape ``(N,)``.\\n          For details, `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          If `features` are passed in, `ood_features_scores` are returned.\\n          If `pred_probs` are passed in, `ood_predictions_scores` are returned.\\n          For details see return of `~cleanlab.outlier.OutOfDistribution.scores` function.\\n\\n        \"\n    scores = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)\n    if scores is None:\n        scores = self.score(features=features, pred_probs=pred_probs)\n    return scores"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True):\n    \"\"\"\n        Fits this estimator to a given dataset.\n\n        One of `features` or `pred_probs` must be specified.\n\n        If `features` are passed in, a ``NearestNeighbors`` object is fit.\n        If `pred_probs` and 'labels' are passed in, a `confident_thresholds` ``np.ndarray`` is fit.\n        For details see `~cleanlab.outlier.OutOfDistribution` documentation.\n\n        Parameters\n        ----------\n        features : np.ndarray, optional\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\n          All features should be **numeric**. For less structured data (e.g. images, text, categorical values, ...), you should provide\n          vector embeddings to represent each example (e.g. extracted from some pretrained neural network).\n\n        pred_probs : np.ndarray, optional\n           An array of shape ``(N, K)`` of model-predicted probabilities,\n          ``P(label=k|x)``. Each row of this matrix corresponds\n          to an example `x` and contains the model-predicted probabilities that\n          `x` belongs to each possible class, for each of the K classes. The\n          columns must be ordered such that these probabilities correspond to\n          class 0, 1, ..., K-1.\n\n        labels : array_like, optional\n          A discrete vector of given labels for the data of shape ``(N,)``. Supported `array_like` types include: ``np.ndarray`` or ``list``.\n          *Format requirements*: for dataset with K classes, labels must be in 0, 1, ..., K-1.\n          All the classes (0, 1, ..., and K-1) MUST be present in ``labels``, such that: ``len(set(labels)) == pred_probs.shape[1]``\n          If ``params[\"adjust_confident_thresholds\"]`` was previously set to ``False``, you do not have to pass in `labels`.\n          Note: multi-label classification is not supported by this method, each example must belong to a single class, e.g. ``labels = np.ndarray([1,0,2,1,1,0...])``.\n\n        verbose : bool, default = True\n          Set to ``False`` to suppress all print statements.\n\n        \"\"\"\n    _ = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)",
        "mutated": [
            "def fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True):\n    if False:\n        i = 10\n    '\\n        Fits this estimator to a given dataset.\\n\\n        One of `features` or `pred_probs` must be specified.\\n\\n        If `features` are passed in, a ``NearestNeighbors`` object is fit.\\n        If `pred_probs` and \\'labels\\' are passed in, a `confident_thresholds` ``np.ndarray`` is fit.\\n        For details see `~cleanlab.outlier.OutOfDistribution` documentation.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          All features should be **numeric**. For less structured data (e.g. images, text, categorical values, ...), you should provide\\n          vector embeddings to represent each example (e.g. extracted from some pretrained neural network).\\n\\n        pred_probs : np.ndarray, optional\\n           An array of shape ``(N, K)`` of model-predicted probabilities,\\n          ``P(label=k|x)``. Each row of this matrix corresponds\\n          to an example `x` and contains the model-predicted probabilities that\\n          `x` belongs to each possible class, for each of the K classes. The\\n          columns must be ordered such that these probabilities correspond to\\n          class 0, 1, ..., K-1.\\n\\n        labels : array_like, optional\\n          A discrete vector of given labels for the data of shape ``(N,)``. Supported `array_like` types include: ``np.ndarray`` or ``list``.\\n          *Format requirements*: for dataset with K classes, labels must be in 0, 1, ..., K-1.\\n          All the classes (0, 1, ..., and K-1) MUST be present in ``labels``, such that: ``len(set(labels)) == pred_probs.shape[1]``\\n          If ``params[\"adjust_confident_thresholds\"]`` was previously set to ``False``, you do not have to pass in `labels`.\\n          Note: multi-label classification is not supported by this method, each example must belong to a single class, e.g. ``labels = np.ndarray([1,0,2,1,1,0...])``.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        '\n    _ = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)",
            "def fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Fits this estimator to a given dataset.\\n\\n        One of `features` or `pred_probs` must be specified.\\n\\n        If `features` are passed in, a ``NearestNeighbors`` object is fit.\\n        If `pred_probs` and \\'labels\\' are passed in, a `confident_thresholds` ``np.ndarray`` is fit.\\n        For details see `~cleanlab.outlier.OutOfDistribution` documentation.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          All features should be **numeric**. For less structured data (e.g. images, text, categorical values, ...), you should provide\\n          vector embeddings to represent each example (e.g. extracted from some pretrained neural network).\\n\\n        pred_probs : np.ndarray, optional\\n           An array of shape ``(N, K)`` of model-predicted probabilities,\\n          ``P(label=k|x)``. Each row of this matrix corresponds\\n          to an example `x` and contains the model-predicted probabilities that\\n          `x` belongs to each possible class, for each of the K classes. The\\n          columns must be ordered such that these probabilities correspond to\\n          class 0, 1, ..., K-1.\\n\\n        labels : array_like, optional\\n          A discrete vector of given labels for the data of shape ``(N,)``. Supported `array_like` types include: ``np.ndarray`` or ``list``.\\n          *Format requirements*: for dataset with K classes, labels must be in 0, 1, ..., K-1.\\n          All the classes (0, 1, ..., and K-1) MUST be present in ``labels``, such that: ``len(set(labels)) == pred_probs.shape[1]``\\n          If ``params[\"adjust_confident_thresholds\"]`` was previously set to ``False``, you do not have to pass in `labels`.\\n          Note: multi-label classification is not supported by this method, each example must belong to a single class, e.g. ``labels = np.ndarray([1,0,2,1,1,0...])``.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        '\n    _ = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)",
            "def fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Fits this estimator to a given dataset.\\n\\n        One of `features` or `pred_probs` must be specified.\\n\\n        If `features` are passed in, a ``NearestNeighbors`` object is fit.\\n        If `pred_probs` and \\'labels\\' are passed in, a `confident_thresholds` ``np.ndarray`` is fit.\\n        For details see `~cleanlab.outlier.OutOfDistribution` documentation.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          All features should be **numeric**. For less structured data (e.g. images, text, categorical values, ...), you should provide\\n          vector embeddings to represent each example (e.g. extracted from some pretrained neural network).\\n\\n        pred_probs : np.ndarray, optional\\n           An array of shape ``(N, K)`` of model-predicted probabilities,\\n          ``P(label=k|x)``. Each row of this matrix corresponds\\n          to an example `x` and contains the model-predicted probabilities that\\n          `x` belongs to each possible class, for each of the K classes. The\\n          columns must be ordered such that these probabilities correspond to\\n          class 0, 1, ..., K-1.\\n\\n        labels : array_like, optional\\n          A discrete vector of given labels for the data of shape ``(N,)``. Supported `array_like` types include: ``np.ndarray`` or ``list``.\\n          *Format requirements*: for dataset with K classes, labels must be in 0, 1, ..., K-1.\\n          All the classes (0, 1, ..., and K-1) MUST be present in ``labels``, such that: ``len(set(labels)) == pred_probs.shape[1]``\\n          If ``params[\"adjust_confident_thresholds\"]`` was previously set to ``False``, you do not have to pass in `labels`.\\n          Note: multi-label classification is not supported by this method, each example must belong to a single class, e.g. ``labels = np.ndarray([1,0,2,1,1,0...])``.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        '\n    _ = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)",
            "def fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Fits this estimator to a given dataset.\\n\\n        One of `features` or `pred_probs` must be specified.\\n\\n        If `features` are passed in, a ``NearestNeighbors`` object is fit.\\n        If `pred_probs` and \\'labels\\' are passed in, a `confident_thresholds` ``np.ndarray`` is fit.\\n        For details see `~cleanlab.outlier.OutOfDistribution` documentation.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          All features should be **numeric**. For less structured data (e.g. images, text, categorical values, ...), you should provide\\n          vector embeddings to represent each example (e.g. extracted from some pretrained neural network).\\n\\n        pred_probs : np.ndarray, optional\\n           An array of shape ``(N, K)`` of model-predicted probabilities,\\n          ``P(label=k|x)``. Each row of this matrix corresponds\\n          to an example `x` and contains the model-predicted probabilities that\\n          `x` belongs to each possible class, for each of the K classes. The\\n          columns must be ordered such that these probabilities correspond to\\n          class 0, 1, ..., K-1.\\n\\n        labels : array_like, optional\\n          A discrete vector of given labels for the data of shape ``(N,)``. Supported `array_like` types include: ``np.ndarray`` or ``list``.\\n          *Format requirements*: for dataset with K classes, labels must be in 0, 1, ..., K-1.\\n          All the classes (0, 1, ..., and K-1) MUST be present in ``labels``, such that: ``len(set(labels)) == pred_probs.shape[1]``\\n          If ``params[\"adjust_confident_thresholds\"]`` was previously set to ``False``, you do not have to pass in `labels`.\\n          Note: multi-label classification is not supported by this method, each example must belong to a single class, e.g. ``labels = np.ndarray([1,0,2,1,1,0...])``.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        '\n    _ = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)",
            "def fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Fits this estimator to a given dataset.\\n\\n        One of `features` or `pred_probs` must be specified.\\n\\n        If `features` are passed in, a ``NearestNeighbors`` object is fit.\\n        If `pred_probs` and \\'labels\\' are passed in, a `confident_thresholds` ``np.ndarray`` is fit.\\n        For details see `~cleanlab.outlier.OutOfDistribution` documentation.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          All features should be **numeric**. For less structured data (e.g. images, text, categorical values, ...), you should provide\\n          vector embeddings to represent each example (e.g. extracted from some pretrained neural network).\\n\\n        pred_probs : np.ndarray, optional\\n           An array of shape ``(N, K)`` of model-predicted probabilities,\\n          ``P(label=k|x)``. Each row of this matrix corresponds\\n          to an example `x` and contains the model-predicted probabilities that\\n          `x` belongs to each possible class, for each of the K classes. The\\n          columns must be ordered such that these probabilities correspond to\\n          class 0, 1, ..., K-1.\\n\\n        labels : array_like, optional\\n          A discrete vector of given labels for the data of shape ``(N,)``. Supported `array_like` types include: ``np.ndarray`` or ``list``.\\n          *Format requirements*: for dataset with K classes, labels must be in 0, 1, ..., K-1.\\n          All the classes (0, 1, ..., and K-1) MUST be present in ``labels``, such that: ``len(set(labels)) == pred_probs.shape[1]``\\n          If ``params[\"adjust_confident_thresholds\"]`` was previously set to ``False``, you do not have to pass in `labels`.\\n          Note: multi-label classification is not supported by this method, each example must belong to a single class, e.g. ``labels = np.ndarray([1,0,2,1,1,0...])``.\\n\\n        verbose : bool, default = True\\n          Set to ``False`` to suppress all print statements.\\n\\n        '\n    _ = self._shared_fit(features=features, pred_probs=pred_probs, labels=labels, verbose=verbose)"
        ]
    },
    {
        "func_name": "score",
        "original": "def score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None) -> np.ndarray:\n    \"\"\"\n        Use fitted estimator and passed in `features` or `pred_probs` to calculate out-of-distribution scores for a dataset.\n\n        Score for each example corresponds to the likelihood this example stems from the same distribution as the dataset previously specified in ``fit()`` (i.e. is not an outlier).\n\n        If `features` are passed, returns OOD score for each example based on its feature values.\n        If `pred_probs` are passed, returns OOD score for each example based on classifier's probabilistic predictions.\n        You may have to previously call ``fit()`` or call ``fit_score()`` instead.\n\n        Parameters\n        ----------\n        features : np.ndarray, optional\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\n          For details, see `features` in `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n        pred_probs : np.ndarray, optional\n          An array of shape ``(N, K)``  of predicted class probabilities output by a trained classifier.\n          For details, see `pred_probs` in `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n        Returns\n        -------\n        scores : np.ndarray\n          Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset distribution\n          (values near 0 indicate outliers).\n\n          If `features` are passed, `ood_features_scores` are returned.\n          The score is based on the average distance between the example and its K nearest neighbors in the dataset\n          (in feature space).\n\n          If `pred_probs` are passed, `ood_predictions_scores` are returned.\n          The score is based on the uncertainty in the classifier's predicted probabilities.\n        \"\"\"\n    self._assert_valid_inputs(features, pred_probs)\n    if features is not None:\n        if self.params['knn'] is None:\n            raise ValueError('OOD estimator needs to be fit on features first. Call `fit()` or `fit_scores()` before this function.')\n        (scores, _) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is None and self.params['adjust_pred_probs']:\n            raise ValueError(\"OOD estimator needs to be fit on pred_probs first since params['adjust_pred_probs']=True. Call `fit()` or `fit_scores()` before this function.\")\n        (scores, _) = _get_ood_predictions_scores(pred_probs, **self._get_params(self.OOD_PARAMS))\n    return scores",
        "mutated": [
            "def score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None) -> np.ndarray:\n    if False:\n        i = 10\n    \"\\n        Use fitted estimator and passed in `features` or `pred_probs` to calculate out-of-distribution scores for a dataset.\\n\\n        Score for each example corresponds to the likelihood this example stems from the same distribution as the dataset previously specified in ``fit()`` (i.e. is not an outlier).\\n\\n        If `features` are passed, returns OOD score for each example based on its feature values.\\n        If `pred_probs` are passed, returns OOD score for each example based on classifier's probabilistic predictions.\\n        You may have to previously call ``fit()`` or call ``fit_score()`` instead.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, see `features` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)``  of predicted class probabilities output by a trained classifier.\\n          For details, see `pred_probs` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset distribution\\n          (values near 0 indicate outliers).\\n\\n          If `features` are passed, `ood_features_scores` are returned.\\n          The score is based on the average distance between the example and its K nearest neighbors in the dataset\\n          (in feature space).\\n\\n          If `pred_probs` are passed, `ood_predictions_scores` are returned.\\n          The score is based on the uncertainty in the classifier's predicted probabilities.\\n        \"\n    self._assert_valid_inputs(features, pred_probs)\n    if features is not None:\n        if self.params['knn'] is None:\n            raise ValueError('OOD estimator needs to be fit on features first. Call `fit()` or `fit_scores()` before this function.')\n        (scores, _) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is None and self.params['adjust_pred_probs']:\n            raise ValueError(\"OOD estimator needs to be fit on pred_probs first since params['adjust_pred_probs']=True. Call `fit()` or `fit_scores()` before this function.\")\n        (scores, _) = _get_ood_predictions_scores(pred_probs, **self._get_params(self.OOD_PARAMS))\n    return scores",
            "def score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Use fitted estimator and passed in `features` or `pred_probs` to calculate out-of-distribution scores for a dataset.\\n\\n        Score for each example corresponds to the likelihood this example stems from the same distribution as the dataset previously specified in ``fit()`` (i.e. is not an outlier).\\n\\n        If `features` are passed, returns OOD score for each example based on its feature values.\\n        If `pred_probs` are passed, returns OOD score for each example based on classifier's probabilistic predictions.\\n        You may have to previously call ``fit()`` or call ``fit_score()`` instead.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, see `features` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)``  of predicted class probabilities output by a trained classifier.\\n          For details, see `pred_probs` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset distribution\\n          (values near 0 indicate outliers).\\n\\n          If `features` are passed, `ood_features_scores` are returned.\\n          The score is based on the average distance between the example and its K nearest neighbors in the dataset\\n          (in feature space).\\n\\n          If `pred_probs` are passed, `ood_predictions_scores` are returned.\\n          The score is based on the uncertainty in the classifier's predicted probabilities.\\n        \"\n    self._assert_valid_inputs(features, pred_probs)\n    if features is not None:\n        if self.params['knn'] is None:\n            raise ValueError('OOD estimator needs to be fit on features first. Call `fit()` or `fit_scores()` before this function.')\n        (scores, _) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is None and self.params['adjust_pred_probs']:\n            raise ValueError(\"OOD estimator needs to be fit on pred_probs first since params['adjust_pred_probs']=True. Call `fit()` or `fit_scores()` before this function.\")\n        (scores, _) = _get_ood_predictions_scores(pred_probs, **self._get_params(self.OOD_PARAMS))\n    return scores",
            "def score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Use fitted estimator and passed in `features` or `pred_probs` to calculate out-of-distribution scores for a dataset.\\n\\n        Score for each example corresponds to the likelihood this example stems from the same distribution as the dataset previously specified in ``fit()`` (i.e. is not an outlier).\\n\\n        If `features` are passed, returns OOD score for each example based on its feature values.\\n        If `pred_probs` are passed, returns OOD score for each example based on classifier's probabilistic predictions.\\n        You may have to previously call ``fit()`` or call ``fit_score()`` instead.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, see `features` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)``  of predicted class probabilities output by a trained classifier.\\n          For details, see `pred_probs` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset distribution\\n          (values near 0 indicate outliers).\\n\\n          If `features` are passed, `ood_features_scores` are returned.\\n          The score is based on the average distance between the example and its K nearest neighbors in the dataset\\n          (in feature space).\\n\\n          If `pred_probs` are passed, `ood_predictions_scores` are returned.\\n          The score is based on the uncertainty in the classifier's predicted probabilities.\\n        \"\n    self._assert_valid_inputs(features, pred_probs)\n    if features is not None:\n        if self.params['knn'] is None:\n            raise ValueError('OOD estimator needs to be fit on features first. Call `fit()` or `fit_scores()` before this function.')\n        (scores, _) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is None and self.params['adjust_pred_probs']:\n            raise ValueError(\"OOD estimator needs to be fit on pred_probs first since params['adjust_pred_probs']=True. Call `fit()` or `fit_scores()` before this function.\")\n        (scores, _) = _get_ood_predictions_scores(pred_probs, **self._get_params(self.OOD_PARAMS))\n    return scores",
            "def score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Use fitted estimator and passed in `features` or `pred_probs` to calculate out-of-distribution scores for a dataset.\\n\\n        Score for each example corresponds to the likelihood this example stems from the same distribution as the dataset previously specified in ``fit()`` (i.e. is not an outlier).\\n\\n        If `features` are passed, returns OOD score for each example based on its feature values.\\n        If `pred_probs` are passed, returns OOD score for each example based on classifier's probabilistic predictions.\\n        You may have to previously call ``fit()`` or call ``fit_score()`` instead.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, see `features` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)``  of predicted class probabilities output by a trained classifier.\\n          For details, see `pred_probs` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset distribution\\n          (values near 0 indicate outliers).\\n\\n          If `features` are passed, `ood_features_scores` are returned.\\n          The score is based on the average distance between the example and its K nearest neighbors in the dataset\\n          (in feature space).\\n\\n          If `pred_probs` are passed, `ood_predictions_scores` are returned.\\n          The score is based on the uncertainty in the classifier's predicted probabilities.\\n        \"\n    self._assert_valid_inputs(features, pred_probs)\n    if features is not None:\n        if self.params['knn'] is None:\n            raise ValueError('OOD estimator needs to be fit on features first. Call `fit()` or `fit_scores()` before this function.')\n        (scores, _) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is None and self.params['adjust_pred_probs']:\n            raise ValueError(\"OOD estimator needs to be fit on pred_probs first since params['adjust_pred_probs']=True. Call `fit()` or `fit_scores()` before this function.\")\n        (scores, _) = _get_ood_predictions_scores(pred_probs, **self._get_params(self.OOD_PARAMS))\n    return scores",
            "def score(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Use fitted estimator and passed in `features` or `pred_probs` to calculate out-of-distribution scores for a dataset.\\n\\n        Score for each example corresponds to the likelihood this example stems from the same distribution as the dataset previously specified in ``fit()`` (i.e. is not an outlier).\\n\\n        If `features` are passed, returns OOD score for each example based on its feature values.\\n        If `pred_probs` are passed, returns OOD score for each example based on classifier's probabilistic predictions.\\n        You may have to previously call ``fit()`` or call ``fit_score()`` instead.\\n\\n        Parameters\\n        ----------\\n        features : np.ndarray, optional\\n          Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n          For details, see `features` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        pred_probs : np.ndarray, optional\\n          An array of shape ``(N, K)``  of predicted class probabilities output by a trained classifier.\\n          For details, see `pred_probs` in `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n        Returns\\n        -------\\n        scores : np.ndarray\\n          Scores lie in [0,1] with smaller values indicating examples that are less typical under the dataset distribution\\n          (values near 0 indicate outliers).\\n\\n          If `features` are passed, `ood_features_scores` are returned.\\n          The score is based on the average distance between the example and its K nearest neighbors in the dataset\\n          (in feature space).\\n\\n          If `pred_probs` are passed, `ood_predictions_scores` are returned.\\n          The score is based on the uncertainty in the classifier's predicted probabilities.\\n        \"\n    self._assert_valid_inputs(features, pred_probs)\n    if features is not None:\n        if self.params['knn'] is None:\n            raise ValueError('OOD estimator needs to be fit on features first. Call `fit()` or `fit_scores()` before this function.')\n        (scores, _) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is None and self.params['adjust_pred_probs']:\n            raise ValueError(\"OOD estimator needs to be fit on pred_probs first since params['adjust_pred_probs']=True. Call `fit()` or `fit_scores()` before this function.\")\n        (scores, _) = _get_ood_predictions_scores(pred_probs, **self._get_params(self.OOD_PARAMS))\n    return scores"
        ]
    },
    {
        "func_name": "_get_params",
        "original": "def _get_params(self, param_keys) -> dict:\n    \"\"\"Get function specific dictionary of parameters (i.e. only those in param_keys).\"\"\"\n    return {k: v for (k, v) in self.params.items() if k in param_keys}",
        "mutated": [
            "def _get_params(self, param_keys) -> dict:\n    if False:\n        i = 10\n    'Get function specific dictionary of parameters (i.e. only those in param_keys).'\n    return {k: v for (k, v) in self.params.items() if k in param_keys}",
            "def _get_params(self, param_keys) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Get function specific dictionary of parameters (i.e. only those in param_keys).'\n    return {k: v for (k, v) in self.params.items() if k in param_keys}",
            "def _get_params(self, param_keys) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Get function specific dictionary of parameters (i.e. only those in param_keys).'\n    return {k: v for (k, v) in self.params.items() if k in param_keys}",
            "def _get_params(self, param_keys) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Get function specific dictionary of parameters (i.e. only those in param_keys).'\n    return {k: v for (k, v) in self.params.items() if k in param_keys}",
            "def _get_params(self, param_keys) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Get function specific dictionary of parameters (i.e. only those in param_keys).'\n    return {k: v for (k, v) in self.params.items() if k in param_keys}"
        ]
    },
    {
        "func_name": "_assert_valid_params",
        "original": "@staticmethod\ndef _assert_valid_params(params, param_keys):\n    \"\"\"Validate passed in params and get list of parameters in param that are not in param_keys.\"\"\"\n    if params is not None:\n        wrong_params = list(set(params.keys()).difference(set(param_keys)))\n        if len(wrong_params) > 0:\n            raise ValueError(f'Passed in params dict can only contain {param_keys}. Remove {wrong_params} from params dict.')",
        "mutated": [
            "@staticmethod\ndef _assert_valid_params(params, param_keys):\n    if False:\n        i = 10\n    'Validate passed in params and get list of parameters in param that are not in param_keys.'\n    if params is not None:\n        wrong_params = list(set(params.keys()).difference(set(param_keys)))\n        if len(wrong_params) > 0:\n            raise ValueError(f'Passed in params dict can only contain {param_keys}. Remove {wrong_params} from params dict.')",
            "@staticmethod\ndef _assert_valid_params(params, param_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Validate passed in params and get list of parameters in param that are not in param_keys.'\n    if params is not None:\n        wrong_params = list(set(params.keys()).difference(set(param_keys)))\n        if len(wrong_params) > 0:\n            raise ValueError(f'Passed in params dict can only contain {param_keys}. Remove {wrong_params} from params dict.')",
            "@staticmethod\ndef _assert_valid_params(params, param_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Validate passed in params and get list of parameters in param that are not in param_keys.'\n    if params is not None:\n        wrong_params = list(set(params.keys()).difference(set(param_keys)))\n        if len(wrong_params) > 0:\n            raise ValueError(f'Passed in params dict can only contain {param_keys}. Remove {wrong_params} from params dict.')",
            "@staticmethod\ndef _assert_valid_params(params, param_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Validate passed in params and get list of parameters in param that are not in param_keys.'\n    if params is not None:\n        wrong_params = list(set(params.keys()).difference(set(param_keys)))\n        if len(wrong_params) > 0:\n            raise ValueError(f'Passed in params dict can only contain {param_keys}. Remove {wrong_params} from params dict.')",
            "@staticmethod\ndef _assert_valid_params(params, param_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Validate passed in params and get list of parameters in param that are not in param_keys.'\n    if params is not None:\n        wrong_params = list(set(params.keys()).difference(set(param_keys)))\n        if len(wrong_params) > 0:\n            raise ValueError(f'Passed in params dict can only contain {param_keys}. Remove {wrong_params} from params dict.')"
        ]
    },
    {
        "func_name": "_assert_valid_inputs",
        "original": "@staticmethod\ndef _assert_valid_inputs(features, pred_probs):\n    \"\"\"Check whether features and pred_prob inputs are valid, throw error if not.\"\"\"\n    if features is None and pred_probs is None:\n        raise ValueError('Not enough information to compute scores. Pass in either features or pred_probs.')\n    if features is not None and pred_probs is not None:\n        raise ValueError('Cannot fit to OOD Estimator to both features and pred_probs. Pass in either one or the other.')\n    if features is not None and len(features.shape) != 2:\n        raise ValueError('Feature array needs to be of shape (N, M), where N is the number of examples and M is the number of features used to represent each example. ')",
        "mutated": [
            "@staticmethod\ndef _assert_valid_inputs(features, pred_probs):\n    if False:\n        i = 10\n    'Check whether features and pred_prob inputs are valid, throw error if not.'\n    if features is None and pred_probs is None:\n        raise ValueError('Not enough information to compute scores. Pass in either features or pred_probs.')\n    if features is not None and pred_probs is not None:\n        raise ValueError('Cannot fit to OOD Estimator to both features and pred_probs. Pass in either one or the other.')\n    if features is not None and len(features.shape) != 2:\n        raise ValueError('Feature array needs to be of shape (N, M), where N is the number of examples and M is the number of features used to represent each example. ')",
            "@staticmethod\ndef _assert_valid_inputs(features, pred_probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Check whether features and pred_prob inputs are valid, throw error if not.'\n    if features is None and pred_probs is None:\n        raise ValueError('Not enough information to compute scores. Pass in either features or pred_probs.')\n    if features is not None and pred_probs is not None:\n        raise ValueError('Cannot fit to OOD Estimator to both features and pred_probs. Pass in either one or the other.')\n    if features is not None and len(features.shape) != 2:\n        raise ValueError('Feature array needs to be of shape (N, M), where N is the number of examples and M is the number of features used to represent each example. ')",
            "@staticmethod\ndef _assert_valid_inputs(features, pred_probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Check whether features and pred_prob inputs are valid, throw error if not.'\n    if features is None and pred_probs is None:\n        raise ValueError('Not enough information to compute scores. Pass in either features or pred_probs.')\n    if features is not None and pred_probs is not None:\n        raise ValueError('Cannot fit to OOD Estimator to both features and pred_probs. Pass in either one or the other.')\n    if features is not None and len(features.shape) != 2:\n        raise ValueError('Feature array needs to be of shape (N, M), where N is the number of examples and M is the number of features used to represent each example. ')",
            "@staticmethod\ndef _assert_valid_inputs(features, pred_probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Check whether features and pred_prob inputs are valid, throw error if not.'\n    if features is None and pred_probs is None:\n        raise ValueError('Not enough information to compute scores. Pass in either features or pred_probs.')\n    if features is not None and pred_probs is not None:\n        raise ValueError('Cannot fit to OOD Estimator to both features and pred_probs. Pass in either one or the other.')\n    if features is not None and len(features.shape) != 2:\n        raise ValueError('Feature array needs to be of shape (N, M), where N is the number of examples and M is the number of features used to represent each example. ')",
            "@staticmethod\ndef _assert_valid_inputs(features, pred_probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Check whether features and pred_prob inputs are valid, throw error if not.'\n    if features is None and pred_probs is None:\n        raise ValueError('Not enough information to compute scores. Pass in either features or pred_probs.')\n    if features is not None and pred_probs is not None:\n        raise ValueError('Cannot fit to OOD Estimator to both features and pred_probs. Pass in either one or the other.')\n    if features is not None and len(features.shape) != 2:\n        raise ValueError('Feature array needs to be of shape (N, M), where N is the number of examples and M is the number of features used to represent each example. ')"
        ]
    },
    {
        "func_name": "_shared_fit",
        "original": "def _shared_fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True) -> Optional[np.ndarray]:\n    \"\"\"\n        Shared fit functionality between ``fit()`` and ``fit_score()``.\n\n        For details, refer to `~cleanlab.outlier.OutOfDistribution.fit`\n        or `~cleanlab.outlier.OutOfDistribution.fit_score`.\n        \"\"\"\n    self._assert_valid_inputs(features, pred_probs)\n    scores = None\n    if features is not None:\n        if self.params['knn'] is not None:\n            warnings.warn('A KNN estimator has previously already been fit, call score() to apply it to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided features ...')\n            (scores, knn) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n            self.params['knn'] = knn\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is not None:\n            warnings.warn('Confident thresholds have previously already been fit, call score() to apply them to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided pred_probs ...')\n            (scores, confident_thresholds) = _get_ood_predictions_scores(pred_probs, labels=labels, **self._get_params(self.OOD_PARAMS))\n            if confident_thresholds is None:\n                warnings.warn('No estimates need to be be fit under the provided params, so you could directly call score() as an alternative.', UserWarning)\n            else:\n                self.params['confident_thresholds'] = confident_thresholds\n    return scores",
        "mutated": [
            "def _shared_fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True) -> Optional[np.ndarray]:\n    if False:\n        i = 10\n    '\\n        Shared fit functionality between ``fit()`` and ``fit_score()``.\\n\\n        For details, refer to `~cleanlab.outlier.OutOfDistribution.fit`\\n        or `~cleanlab.outlier.OutOfDistribution.fit_score`.\\n        '\n    self._assert_valid_inputs(features, pred_probs)\n    scores = None\n    if features is not None:\n        if self.params['knn'] is not None:\n            warnings.warn('A KNN estimator has previously already been fit, call score() to apply it to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided features ...')\n            (scores, knn) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n            self.params['knn'] = knn\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is not None:\n            warnings.warn('Confident thresholds have previously already been fit, call score() to apply them to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided pred_probs ...')\n            (scores, confident_thresholds) = _get_ood_predictions_scores(pred_probs, labels=labels, **self._get_params(self.OOD_PARAMS))\n            if confident_thresholds is None:\n                warnings.warn('No estimates need to be be fit under the provided params, so you could directly call score() as an alternative.', UserWarning)\n            else:\n                self.params['confident_thresholds'] = confident_thresholds\n    return scores",
            "def _shared_fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True) -> Optional[np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Shared fit functionality between ``fit()`` and ``fit_score()``.\\n\\n        For details, refer to `~cleanlab.outlier.OutOfDistribution.fit`\\n        or `~cleanlab.outlier.OutOfDistribution.fit_score`.\\n        '\n    self._assert_valid_inputs(features, pred_probs)\n    scores = None\n    if features is not None:\n        if self.params['knn'] is not None:\n            warnings.warn('A KNN estimator has previously already been fit, call score() to apply it to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided features ...')\n            (scores, knn) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n            self.params['knn'] = knn\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is not None:\n            warnings.warn('Confident thresholds have previously already been fit, call score() to apply them to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided pred_probs ...')\n            (scores, confident_thresholds) = _get_ood_predictions_scores(pred_probs, labels=labels, **self._get_params(self.OOD_PARAMS))\n            if confident_thresholds is None:\n                warnings.warn('No estimates need to be be fit under the provided params, so you could directly call score() as an alternative.', UserWarning)\n            else:\n                self.params['confident_thresholds'] = confident_thresholds\n    return scores",
            "def _shared_fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True) -> Optional[np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Shared fit functionality between ``fit()`` and ``fit_score()``.\\n\\n        For details, refer to `~cleanlab.outlier.OutOfDistribution.fit`\\n        or `~cleanlab.outlier.OutOfDistribution.fit_score`.\\n        '\n    self._assert_valid_inputs(features, pred_probs)\n    scores = None\n    if features is not None:\n        if self.params['knn'] is not None:\n            warnings.warn('A KNN estimator has previously already been fit, call score() to apply it to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided features ...')\n            (scores, knn) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n            self.params['knn'] = knn\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is not None:\n            warnings.warn('Confident thresholds have previously already been fit, call score() to apply them to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided pred_probs ...')\n            (scores, confident_thresholds) = _get_ood_predictions_scores(pred_probs, labels=labels, **self._get_params(self.OOD_PARAMS))\n            if confident_thresholds is None:\n                warnings.warn('No estimates need to be be fit under the provided params, so you could directly call score() as an alternative.', UserWarning)\n            else:\n                self.params['confident_thresholds'] = confident_thresholds\n    return scores",
            "def _shared_fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True) -> Optional[np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Shared fit functionality between ``fit()`` and ``fit_score()``.\\n\\n        For details, refer to `~cleanlab.outlier.OutOfDistribution.fit`\\n        or `~cleanlab.outlier.OutOfDistribution.fit_score`.\\n        '\n    self._assert_valid_inputs(features, pred_probs)\n    scores = None\n    if features is not None:\n        if self.params['knn'] is not None:\n            warnings.warn('A KNN estimator has previously already been fit, call score() to apply it to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided features ...')\n            (scores, knn) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n            self.params['knn'] = knn\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is not None:\n            warnings.warn('Confident thresholds have previously already been fit, call score() to apply them to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided pred_probs ...')\n            (scores, confident_thresholds) = _get_ood_predictions_scores(pred_probs, labels=labels, **self._get_params(self.OOD_PARAMS))\n            if confident_thresholds is None:\n                warnings.warn('No estimates need to be be fit under the provided params, so you could directly call score() as an alternative.', UserWarning)\n            else:\n                self.params['confident_thresholds'] = confident_thresholds\n    return scores",
            "def _shared_fit(self, *, features: Optional[np.ndarray]=None, pred_probs: Optional[np.ndarray]=None, labels: Optional[LabelLike]=None, verbose: bool=True) -> Optional[np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Shared fit functionality between ``fit()`` and ``fit_score()``.\\n\\n        For details, refer to `~cleanlab.outlier.OutOfDistribution.fit`\\n        or `~cleanlab.outlier.OutOfDistribution.fit_score`.\\n        '\n    self._assert_valid_inputs(features, pred_probs)\n    scores = None\n    if features is not None:\n        if self.params['knn'] is not None:\n            warnings.warn('A KNN estimator has previously already been fit, call score() to apply it to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided features ...')\n            (scores, knn) = _get_ood_features_scores(features, **self._get_params(self.OUTLIER_PARAMS))\n            self.params['knn'] = knn\n    if pred_probs is not None:\n        if self.params['confident_thresholds'] is not None:\n            warnings.warn('Confident thresholds have previously already been fit, call score() to apply them to data, or create a new OutOfDistribution object to fit a different estimator.', UserWarning)\n        else:\n            if verbose:\n                print('Fitting OOD estimator based on provided pred_probs ...')\n            (scores, confident_thresholds) = _get_ood_predictions_scores(pred_probs, labels=labels, **self._get_params(self.OOD_PARAMS))\n            if confident_thresholds is None:\n                warnings.warn('No estimates need to be be fit under the provided params, so you could directly call score() as an alternative.', UserWarning)\n            else:\n                self.params['confident_thresholds'] = confident_thresholds\n    return scores"
        ]
    },
    {
        "func_name": "_get_ood_features_scores",
        "original": "def _get_ood_features_scores(features: Optional[np.ndarray]=None, knn: Optional[NearestNeighbors]=None, k: Optional[int]=None, t: int=1) -> Tuple[np.ndarray, Optional[NearestNeighbors]]:\n    \"\"\"\n    Return outlier score based on feature values using `k` nearest neighbors.\n\n    The outlier score for each example is computed inversely proportional to\n    the average distance between this example and its K nearest neighbors (in feature space).\n\n    Parameters\n    ----------\n    features : np.ndarray\n      Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\n      For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n    knn : sklearn.neighbors.NearestNeighbors, default = None\n      For details, see key `knn` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\n\n    k : int, default=None\n      Optional number of neighbors to use when calculating outlier score (average distance to neighbors).\n      For details, see key `k` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\n\n    t : int, default=1\n      Controls transformation of distances between examples into similarity scores that lie in [0,1].\n      For details, see key `t` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\n\n    Returns\n    -------\n    ood_features_scores : Tuple[np.ndarray, Optional[NearestNeighbors]]\n      Return a tuple whose first element is array of `ood_features_scores` and second is a `knn` Estimator object.\n    \"\"\"\n    DEFAULT_K = 10\n    if knn is None:\n        if features is None:\n            raise ValueError('Both knn and features arguments cannot be None at the same time. Not enough information to compute outlier scores.')\n        if k is None:\n            k = DEFAULT_K\n        if k > len(features):\n            raise ValueError(f'Number of nearest neighbors k={k} cannot exceed the number of examples N={len(features)} passed into the estimator (knn).')\n        if features.shape[1] > 3:\n            metric = 'cosine'\n        else:\n            metric = 'euclidean'\n        knn = NearestNeighbors(n_neighbors=k, metric=metric).fit(features)\n        features = None\n    elif k is None:\n        k = knn.n_neighbors\n    max_k = knn.n_neighbors\n    if k > max_k:\n        warnings.warn(f'Chosen k={k} cannot be greater than n_neighbors={max_k} which was used when fitting NearestNeighbors object! Value of k changed to k={max_k}.', UserWarning)\n        k = max_k\n    try:\n        knn.kneighbors(features)\n    except NotFittedError:\n        knn.fit(features)\n    (distances, _) = knn.kneighbors(features)\n    ood_features_scores = transform_distances_to_scores(distances, cast(int, k), t)\n    return (ood_features_scores, knn)",
        "mutated": [
            "def _get_ood_features_scores(features: Optional[np.ndarray]=None, knn: Optional[NearestNeighbors]=None, k: Optional[int]=None, t: int=1) -> Tuple[np.ndarray, Optional[NearestNeighbors]]:\n    if False:\n        i = 10\n    '\\n    Return outlier score based on feature values using `k` nearest neighbors.\\n\\n    The outlier score for each example is computed inversely proportional to\\n    the average distance between this example and its K nearest neighbors (in feature space).\\n\\n    Parameters\\n    ----------\\n    features : np.ndarray\\n      Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n      For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    knn : sklearn.neighbors.NearestNeighbors, default = None\\n      For details, see key `knn` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    k : int, default=None\\n      Optional number of neighbors to use when calculating outlier score (average distance to neighbors).\\n      For details, see key `k` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    t : int, default=1\\n      Controls transformation of distances between examples into similarity scores that lie in [0,1].\\n      For details, see key `t` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    Returns\\n    -------\\n    ood_features_scores : Tuple[np.ndarray, Optional[NearestNeighbors]]\\n      Return a tuple whose first element is array of `ood_features_scores` and second is a `knn` Estimator object.\\n    '\n    DEFAULT_K = 10\n    if knn is None:\n        if features is None:\n            raise ValueError('Both knn and features arguments cannot be None at the same time. Not enough information to compute outlier scores.')\n        if k is None:\n            k = DEFAULT_K\n        if k > len(features):\n            raise ValueError(f'Number of nearest neighbors k={k} cannot exceed the number of examples N={len(features)} passed into the estimator (knn).')\n        if features.shape[1] > 3:\n            metric = 'cosine'\n        else:\n            metric = 'euclidean'\n        knn = NearestNeighbors(n_neighbors=k, metric=metric).fit(features)\n        features = None\n    elif k is None:\n        k = knn.n_neighbors\n    max_k = knn.n_neighbors\n    if k > max_k:\n        warnings.warn(f'Chosen k={k} cannot be greater than n_neighbors={max_k} which was used when fitting NearestNeighbors object! Value of k changed to k={max_k}.', UserWarning)\n        k = max_k\n    try:\n        knn.kneighbors(features)\n    except NotFittedError:\n        knn.fit(features)\n    (distances, _) = knn.kneighbors(features)\n    ood_features_scores = transform_distances_to_scores(distances, cast(int, k), t)\n    return (ood_features_scores, knn)",
            "def _get_ood_features_scores(features: Optional[np.ndarray]=None, knn: Optional[NearestNeighbors]=None, k: Optional[int]=None, t: int=1) -> Tuple[np.ndarray, Optional[NearestNeighbors]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Return outlier score based on feature values using `k` nearest neighbors.\\n\\n    The outlier score for each example is computed inversely proportional to\\n    the average distance between this example and its K nearest neighbors (in feature space).\\n\\n    Parameters\\n    ----------\\n    features : np.ndarray\\n      Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n      For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    knn : sklearn.neighbors.NearestNeighbors, default = None\\n      For details, see key `knn` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    k : int, default=None\\n      Optional number of neighbors to use when calculating outlier score (average distance to neighbors).\\n      For details, see key `k` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    t : int, default=1\\n      Controls transformation of distances between examples into similarity scores that lie in [0,1].\\n      For details, see key `t` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    Returns\\n    -------\\n    ood_features_scores : Tuple[np.ndarray, Optional[NearestNeighbors]]\\n      Return a tuple whose first element is array of `ood_features_scores` and second is a `knn` Estimator object.\\n    '\n    DEFAULT_K = 10\n    if knn is None:\n        if features is None:\n            raise ValueError('Both knn and features arguments cannot be None at the same time. Not enough information to compute outlier scores.')\n        if k is None:\n            k = DEFAULT_K\n        if k > len(features):\n            raise ValueError(f'Number of nearest neighbors k={k} cannot exceed the number of examples N={len(features)} passed into the estimator (knn).')\n        if features.shape[1] > 3:\n            metric = 'cosine'\n        else:\n            metric = 'euclidean'\n        knn = NearestNeighbors(n_neighbors=k, metric=metric).fit(features)\n        features = None\n    elif k is None:\n        k = knn.n_neighbors\n    max_k = knn.n_neighbors\n    if k > max_k:\n        warnings.warn(f'Chosen k={k} cannot be greater than n_neighbors={max_k} which was used when fitting NearestNeighbors object! Value of k changed to k={max_k}.', UserWarning)\n        k = max_k\n    try:\n        knn.kneighbors(features)\n    except NotFittedError:\n        knn.fit(features)\n    (distances, _) = knn.kneighbors(features)\n    ood_features_scores = transform_distances_to_scores(distances, cast(int, k), t)\n    return (ood_features_scores, knn)",
            "def _get_ood_features_scores(features: Optional[np.ndarray]=None, knn: Optional[NearestNeighbors]=None, k: Optional[int]=None, t: int=1) -> Tuple[np.ndarray, Optional[NearestNeighbors]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Return outlier score based on feature values using `k` nearest neighbors.\\n\\n    The outlier score for each example is computed inversely proportional to\\n    the average distance between this example and its K nearest neighbors (in feature space).\\n\\n    Parameters\\n    ----------\\n    features : np.ndarray\\n      Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n      For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    knn : sklearn.neighbors.NearestNeighbors, default = None\\n      For details, see key `knn` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    k : int, default=None\\n      Optional number of neighbors to use when calculating outlier score (average distance to neighbors).\\n      For details, see key `k` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    t : int, default=1\\n      Controls transformation of distances between examples into similarity scores that lie in [0,1].\\n      For details, see key `t` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    Returns\\n    -------\\n    ood_features_scores : Tuple[np.ndarray, Optional[NearestNeighbors]]\\n      Return a tuple whose first element is array of `ood_features_scores` and second is a `knn` Estimator object.\\n    '\n    DEFAULT_K = 10\n    if knn is None:\n        if features is None:\n            raise ValueError('Both knn and features arguments cannot be None at the same time. Not enough information to compute outlier scores.')\n        if k is None:\n            k = DEFAULT_K\n        if k > len(features):\n            raise ValueError(f'Number of nearest neighbors k={k} cannot exceed the number of examples N={len(features)} passed into the estimator (knn).')\n        if features.shape[1] > 3:\n            metric = 'cosine'\n        else:\n            metric = 'euclidean'\n        knn = NearestNeighbors(n_neighbors=k, metric=metric).fit(features)\n        features = None\n    elif k is None:\n        k = knn.n_neighbors\n    max_k = knn.n_neighbors\n    if k > max_k:\n        warnings.warn(f'Chosen k={k} cannot be greater than n_neighbors={max_k} which was used when fitting NearestNeighbors object! Value of k changed to k={max_k}.', UserWarning)\n        k = max_k\n    try:\n        knn.kneighbors(features)\n    except NotFittedError:\n        knn.fit(features)\n    (distances, _) = knn.kneighbors(features)\n    ood_features_scores = transform_distances_to_scores(distances, cast(int, k), t)\n    return (ood_features_scores, knn)",
            "def _get_ood_features_scores(features: Optional[np.ndarray]=None, knn: Optional[NearestNeighbors]=None, k: Optional[int]=None, t: int=1) -> Tuple[np.ndarray, Optional[NearestNeighbors]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Return outlier score based on feature values using `k` nearest neighbors.\\n\\n    The outlier score for each example is computed inversely proportional to\\n    the average distance between this example and its K nearest neighbors (in feature space).\\n\\n    Parameters\\n    ----------\\n    features : np.ndarray\\n      Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n      For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    knn : sklearn.neighbors.NearestNeighbors, default = None\\n      For details, see key `knn` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    k : int, default=None\\n      Optional number of neighbors to use when calculating outlier score (average distance to neighbors).\\n      For details, see key `k` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    t : int, default=1\\n      Controls transformation of distances between examples into similarity scores that lie in [0,1].\\n      For details, see key `t` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    Returns\\n    -------\\n    ood_features_scores : Tuple[np.ndarray, Optional[NearestNeighbors]]\\n      Return a tuple whose first element is array of `ood_features_scores` and second is a `knn` Estimator object.\\n    '\n    DEFAULT_K = 10\n    if knn is None:\n        if features is None:\n            raise ValueError('Both knn and features arguments cannot be None at the same time. Not enough information to compute outlier scores.')\n        if k is None:\n            k = DEFAULT_K\n        if k > len(features):\n            raise ValueError(f'Number of nearest neighbors k={k} cannot exceed the number of examples N={len(features)} passed into the estimator (knn).')\n        if features.shape[1] > 3:\n            metric = 'cosine'\n        else:\n            metric = 'euclidean'\n        knn = NearestNeighbors(n_neighbors=k, metric=metric).fit(features)\n        features = None\n    elif k is None:\n        k = knn.n_neighbors\n    max_k = knn.n_neighbors\n    if k > max_k:\n        warnings.warn(f'Chosen k={k} cannot be greater than n_neighbors={max_k} which was used when fitting NearestNeighbors object! Value of k changed to k={max_k}.', UserWarning)\n        k = max_k\n    try:\n        knn.kneighbors(features)\n    except NotFittedError:\n        knn.fit(features)\n    (distances, _) = knn.kneighbors(features)\n    ood_features_scores = transform_distances_to_scores(distances, cast(int, k), t)\n    return (ood_features_scores, knn)",
            "def _get_ood_features_scores(features: Optional[np.ndarray]=None, knn: Optional[NearestNeighbors]=None, k: Optional[int]=None, t: int=1) -> Tuple[np.ndarray, Optional[NearestNeighbors]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Return outlier score based on feature values using `k` nearest neighbors.\\n\\n    The outlier score for each example is computed inversely proportional to\\n    the average distance between this example and its K nearest neighbors (in feature space).\\n\\n    Parameters\\n    ----------\\n    features : np.ndarray\\n      Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\\n      For details, `features` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    knn : sklearn.neighbors.NearestNeighbors, default = None\\n      For details, see key `knn` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    k : int, default=None\\n      Optional number of neighbors to use when calculating outlier score (average distance to neighbors).\\n      For details, see key `k` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    t : int, default=1\\n      Controls transformation of distances between examples into similarity scores that lie in [0,1].\\n      For details, see key `t` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    Returns\\n    -------\\n    ood_features_scores : Tuple[np.ndarray, Optional[NearestNeighbors]]\\n      Return a tuple whose first element is array of `ood_features_scores` and second is a `knn` Estimator object.\\n    '\n    DEFAULT_K = 10\n    if knn is None:\n        if features is None:\n            raise ValueError('Both knn and features arguments cannot be None at the same time. Not enough information to compute outlier scores.')\n        if k is None:\n            k = DEFAULT_K\n        if k > len(features):\n            raise ValueError(f'Number of nearest neighbors k={k} cannot exceed the number of examples N={len(features)} passed into the estimator (knn).')\n        if features.shape[1] > 3:\n            metric = 'cosine'\n        else:\n            metric = 'euclidean'\n        knn = NearestNeighbors(n_neighbors=k, metric=metric).fit(features)\n        features = None\n    elif k is None:\n        k = knn.n_neighbors\n    max_k = knn.n_neighbors\n    if k > max_k:\n        warnings.warn(f'Chosen k={k} cannot be greater than n_neighbors={max_k} which was used when fitting NearestNeighbors object! Value of k changed to k={max_k}.', UserWarning)\n        k = max_k\n    try:\n        knn.kneighbors(features)\n    except NotFittedError:\n        knn.fit(features)\n    (distances, _) = knn.kneighbors(features)\n    ood_features_scores = transform_distances_to_scores(distances, cast(int, k), t)\n    return (ood_features_scores, knn)"
        ]
    },
    {
        "func_name": "_get_ood_predictions_scores",
        "original": "def _get_ood_predictions_scores(pred_probs: np.ndarray, *, labels: Optional[LabelLike]=None, confident_thresholds: Optional[np.ndarray]=None, adjust_pred_probs: bool=True, method: str='entropy', M: int=100, gamma: float=0.1) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n    \"\"\"Return an OOD (out of distribution) score for each example based on it pred_prob values.\n\n    Parameters\n    ----------\n    pred_probs : np.ndarray\n      An array of shape ``(N, K)`` of model-predicted probabilities,\n      `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n    confident_thresholds : np.ndarray, default = None\n      For details, see key `confident_thresholds` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\n\n    labels : array_like, optional\n      `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\n\n    adjust_pred_probs : bool, True\n      Account for class imbalance in the label-quality scoring.\n      For details, see key `adjust_pred_probs` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\n\n    method : {\"entropy\", \"least_confidence\", \"gen\"}, default=\"entropy\"\n      Which method to use for computing outlier scores based on pred_probs.\n      For details see key `method` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\n\n    M : int, default=100\n      For GEN method only. Hyperparameter that controls the number of top classes to consider when calculating OOD scores.\n\n    gamma : float, default=0.1\n      For GEN method only. Hyperparameter that controls the weight of the second term in the GEN score.\n\n\n    Returns\n    -------\n    ood_predictions_scores : Tuple[np.ndarray, Optional[np.ndarray]]\n      Returns a tuple. First element is array of `ood_predictions_scores` and second is an np.ndarray of `confident_thresholds` or None is 'confident_thresholds' is not calculated.\n    \"\"\"\n    valid_methods = ('entropy', 'least_confidence', 'gen')\n    if (confident_thresholds is not None or labels is not None) and (not adjust_pred_probs):\n        warnings.warn(\"OOD scores are not adjusted with confident thresholds. If scores need to be adjusted set params['adjusted_pred_probs'] = True. Otherwise passing in confident_thresholds and/or labels does not change score calculation.\", UserWarning)\n    if adjust_pred_probs:\n        if confident_thresholds is None:\n            if labels is None:\n                raise ValueError(\"Cannot calculate adjust_pred_probs without labels. Either pass in labels parameter or set params['adjusted_pred_probs'] = False. \")\n            labels = labels_to_array(labels)\n            assert_valid_inputs(X=None, y=labels, pred_probs=pred_probs, multi_label=False)\n            confident_thresholds = get_confident_thresholds(labels, pred_probs, multi_label=False)\n        pred_probs = _subtract_confident_thresholds(None, pred_probs, multi_label=False, confident_thresholds=confident_thresholds)\n    if method == 'entropy':\n        ood_predictions_scores = 1.0 - get_normalized_entropy(pred_probs)\n    elif method == 'least_confidence':\n        ood_predictions_scores = pred_probs.max(axis=1)\n    elif method == 'gen':\n        if pred_probs.shape[1] < M:\n            warnings.warn(f\"GEN with the default hyperparameter settings is intended for datasets with at least {M} classes. You can adjust params['M'] according to the number of classes in your dataset.\", UserWarning)\n        probs = softmax(pred_probs, axis=1)\n        probs_sorted = np.sort(probs, axis=1)[:, -M:]\n        ood_predictions_scores = 1 - np.sum(probs_sorted ** gamma * (1 - probs_sorted) ** gamma, axis=1) / M\n    else:\n        raise ValueError(f'\\n            {method} is not a valid OOD scoring method!\\n            Please choose a valid scoring_method: {valid_methods}\\n            ')\n    return (ood_predictions_scores, confident_thresholds)",
        "mutated": [
            "def _get_ood_predictions_scores(pred_probs: np.ndarray, *, labels: Optional[LabelLike]=None, confident_thresholds: Optional[np.ndarray]=None, adjust_pred_probs: bool=True, method: str='entropy', M: int=100, gamma: float=0.1) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n    if False:\n        i = 10\n    'Return an OOD (out of distribution) score for each example based on it pred_prob values.\\n\\n    Parameters\\n    ----------\\n    pred_probs : np.ndarray\\n      An array of shape ``(N, K)`` of model-predicted probabilities,\\n      `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    confident_thresholds : np.ndarray, default = None\\n      For details, see key `confident_thresholds` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    labels : array_like, optional\\n      `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    adjust_pred_probs : bool, True\\n      Account for class imbalance in the label-quality scoring.\\n      For details, see key `adjust_pred_probs` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    method : {\"entropy\", \"least_confidence\", \"gen\"}, default=\"entropy\"\\n      Which method to use for computing outlier scores based on pred_probs.\\n      For details see key `method` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    M : int, default=100\\n      For GEN method only. Hyperparameter that controls the number of top classes to consider when calculating OOD scores.\\n\\n    gamma : float, default=0.1\\n      For GEN method only. Hyperparameter that controls the weight of the second term in the GEN score.\\n\\n\\n    Returns\\n    -------\\n    ood_predictions_scores : Tuple[np.ndarray, Optional[np.ndarray]]\\n      Returns a tuple. First element is array of `ood_predictions_scores` and second is an np.ndarray of `confident_thresholds` or None is \\'confident_thresholds\\' is not calculated.\\n    '\n    valid_methods = ('entropy', 'least_confidence', 'gen')\n    if (confident_thresholds is not None or labels is not None) and (not adjust_pred_probs):\n        warnings.warn(\"OOD scores are not adjusted with confident thresholds. If scores need to be adjusted set params['adjusted_pred_probs'] = True. Otherwise passing in confident_thresholds and/or labels does not change score calculation.\", UserWarning)\n    if adjust_pred_probs:\n        if confident_thresholds is None:\n            if labels is None:\n                raise ValueError(\"Cannot calculate adjust_pred_probs without labels. Either pass in labels parameter or set params['adjusted_pred_probs'] = False. \")\n            labels = labels_to_array(labels)\n            assert_valid_inputs(X=None, y=labels, pred_probs=pred_probs, multi_label=False)\n            confident_thresholds = get_confident_thresholds(labels, pred_probs, multi_label=False)\n        pred_probs = _subtract_confident_thresholds(None, pred_probs, multi_label=False, confident_thresholds=confident_thresholds)\n    if method == 'entropy':\n        ood_predictions_scores = 1.0 - get_normalized_entropy(pred_probs)\n    elif method == 'least_confidence':\n        ood_predictions_scores = pred_probs.max(axis=1)\n    elif method == 'gen':\n        if pred_probs.shape[1] < M:\n            warnings.warn(f\"GEN with the default hyperparameter settings is intended for datasets with at least {M} classes. You can adjust params['M'] according to the number of classes in your dataset.\", UserWarning)\n        probs = softmax(pred_probs, axis=1)\n        probs_sorted = np.sort(probs, axis=1)[:, -M:]\n        ood_predictions_scores = 1 - np.sum(probs_sorted ** gamma * (1 - probs_sorted) ** gamma, axis=1) / M\n    else:\n        raise ValueError(f'\\n            {method} is not a valid OOD scoring method!\\n            Please choose a valid scoring_method: {valid_methods}\\n            ')\n    return (ood_predictions_scores, confident_thresholds)",
            "def _get_ood_predictions_scores(pred_probs: np.ndarray, *, labels: Optional[LabelLike]=None, confident_thresholds: Optional[np.ndarray]=None, adjust_pred_probs: bool=True, method: str='entropy', M: int=100, gamma: float=0.1) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Return an OOD (out of distribution) score for each example based on it pred_prob values.\\n\\n    Parameters\\n    ----------\\n    pred_probs : np.ndarray\\n      An array of shape ``(N, K)`` of model-predicted probabilities,\\n      `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    confident_thresholds : np.ndarray, default = None\\n      For details, see key `confident_thresholds` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    labels : array_like, optional\\n      `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    adjust_pred_probs : bool, True\\n      Account for class imbalance in the label-quality scoring.\\n      For details, see key `adjust_pred_probs` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    method : {\"entropy\", \"least_confidence\", \"gen\"}, default=\"entropy\"\\n      Which method to use for computing outlier scores based on pred_probs.\\n      For details see key `method` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    M : int, default=100\\n      For GEN method only. Hyperparameter that controls the number of top classes to consider when calculating OOD scores.\\n\\n    gamma : float, default=0.1\\n      For GEN method only. Hyperparameter that controls the weight of the second term in the GEN score.\\n\\n\\n    Returns\\n    -------\\n    ood_predictions_scores : Tuple[np.ndarray, Optional[np.ndarray]]\\n      Returns a tuple. First element is array of `ood_predictions_scores` and second is an np.ndarray of `confident_thresholds` or None is \\'confident_thresholds\\' is not calculated.\\n    '\n    valid_methods = ('entropy', 'least_confidence', 'gen')\n    if (confident_thresholds is not None or labels is not None) and (not adjust_pred_probs):\n        warnings.warn(\"OOD scores are not adjusted with confident thresholds. If scores need to be adjusted set params['adjusted_pred_probs'] = True. Otherwise passing in confident_thresholds and/or labels does not change score calculation.\", UserWarning)\n    if adjust_pred_probs:\n        if confident_thresholds is None:\n            if labels is None:\n                raise ValueError(\"Cannot calculate adjust_pred_probs without labels. Either pass in labels parameter or set params['adjusted_pred_probs'] = False. \")\n            labels = labels_to_array(labels)\n            assert_valid_inputs(X=None, y=labels, pred_probs=pred_probs, multi_label=False)\n            confident_thresholds = get_confident_thresholds(labels, pred_probs, multi_label=False)\n        pred_probs = _subtract_confident_thresholds(None, pred_probs, multi_label=False, confident_thresholds=confident_thresholds)\n    if method == 'entropy':\n        ood_predictions_scores = 1.0 - get_normalized_entropy(pred_probs)\n    elif method == 'least_confidence':\n        ood_predictions_scores = pred_probs.max(axis=1)\n    elif method == 'gen':\n        if pred_probs.shape[1] < M:\n            warnings.warn(f\"GEN with the default hyperparameter settings is intended for datasets with at least {M} classes. You can adjust params['M'] according to the number of classes in your dataset.\", UserWarning)\n        probs = softmax(pred_probs, axis=1)\n        probs_sorted = np.sort(probs, axis=1)[:, -M:]\n        ood_predictions_scores = 1 - np.sum(probs_sorted ** gamma * (1 - probs_sorted) ** gamma, axis=1) / M\n    else:\n        raise ValueError(f'\\n            {method} is not a valid OOD scoring method!\\n            Please choose a valid scoring_method: {valid_methods}\\n            ')\n    return (ood_predictions_scores, confident_thresholds)",
            "def _get_ood_predictions_scores(pred_probs: np.ndarray, *, labels: Optional[LabelLike]=None, confident_thresholds: Optional[np.ndarray]=None, adjust_pred_probs: bool=True, method: str='entropy', M: int=100, gamma: float=0.1) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Return an OOD (out of distribution) score for each example based on it pred_prob values.\\n\\n    Parameters\\n    ----------\\n    pred_probs : np.ndarray\\n      An array of shape ``(N, K)`` of model-predicted probabilities,\\n      `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    confident_thresholds : np.ndarray, default = None\\n      For details, see key `confident_thresholds` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    labels : array_like, optional\\n      `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    adjust_pred_probs : bool, True\\n      Account for class imbalance in the label-quality scoring.\\n      For details, see key `adjust_pred_probs` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    method : {\"entropy\", \"least_confidence\", \"gen\"}, default=\"entropy\"\\n      Which method to use for computing outlier scores based on pred_probs.\\n      For details see key `method` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    M : int, default=100\\n      For GEN method only. Hyperparameter that controls the number of top classes to consider when calculating OOD scores.\\n\\n    gamma : float, default=0.1\\n      For GEN method only. Hyperparameter that controls the weight of the second term in the GEN score.\\n\\n\\n    Returns\\n    -------\\n    ood_predictions_scores : Tuple[np.ndarray, Optional[np.ndarray]]\\n      Returns a tuple. First element is array of `ood_predictions_scores` and second is an np.ndarray of `confident_thresholds` or None is \\'confident_thresholds\\' is not calculated.\\n    '\n    valid_methods = ('entropy', 'least_confidence', 'gen')\n    if (confident_thresholds is not None or labels is not None) and (not adjust_pred_probs):\n        warnings.warn(\"OOD scores are not adjusted with confident thresholds. If scores need to be adjusted set params['adjusted_pred_probs'] = True. Otherwise passing in confident_thresholds and/or labels does not change score calculation.\", UserWarning)\n    if adjust_pred_probs:\n        if confident_thresholds is None:\n            if labels is None:\n                raise ValueError(\"Cannot calculate adjust_pred_probs without labels. Either pass in labels parameter or set params['adjusted_pred_probs'] = False. \")\n            labels = labels_to_array(labels)\n            assert_valid_inputs(X=None, y=labels, pred_probs=pred_probs, multi_label=False)\n            confident_thresholds = get_confident_thresholds(labels, pred_probs, multi_label=False)\n        pred_probs = _subtract_confident_thresholds(None, pred_probs, multi_label=False, confident_thresholds=confident_thresholds)\n    if method == 'entropy':\n        ood_predictions_scores = 1.0 - get_normalized_entropy(pred_probs)\n    elif method == 'least_confidence':\n        ood_predictions_scores = pred_probs.max(axis=1)\n    elif method == 'gen':\n        if pred_probs.shape[1] < M:\n            warnings.warn(f\"GEN with the default hyperparameter settings is intended for datasets with at least {M} classes. You can adjust params['M'] according to the number of classes in your dataset.\", UserWarning)\n        probs = softmax(pred_probs, axis=1)\n        probs_sorted = np.sort(probs, axis=1)[:, -M:]\n        ood_predictions_scores = 1 - np.sum(probs_sorted ** gamma * (1 - probs_sorted) ** gamma, axis=1) / M\n    else:\n        raise ValueError(f'\\n            {method} is not a valid OOD scoring method!\\n            Please choose a valid scoring_method: {valid_methods}\\n            ')\n    return (ood_predictions_scores, confident_thresholds)",
            "def _get_ood_predictions_scores(pred_probs: np.ndarray, *, labels: Optional[LabelLike]=None, confident_thresholds: Optional[np.ndarray]=None, adjust_pred_probs: bool=True, method: str='entropy', M: int=100, gamma: float=0.1) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Return an OOD (out of distribution) score for each example based on it pred_prob values.\\n\\n    Parameters\\n    ----------\\n    pred_probs : np.ndarray\\n      An array of shape ``(N, K)`` of model-predicted probabilities,\\n      `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    confident_thresholds : np.ndarray, default = None\\n      For details, see key `confident_thresholds` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    labels : array_like, optional\\n      `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    adjust_pred_probs : bool, True\\n      Account for class imbalance in the label-quality scoring.\\n      For details, see key `adjust_pred_probs` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    method : {\"entropy\", \"least_confidence\", \"gen\"}, default=\"entropy\"\\n      Which method to use for computing outlier scores based on pred_probs.\\n      For details see key `method` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    M : int, default=100\\n      For GEN method only. Hyperparameter that controls the number of top classes to consider when calculating OOD scores.\\n\\n    gamma : float, default=0.1\\n      For GEN method only. Hyperparameter that controls the weight of the second term in the GEN score.\\n\\n\\n    Returns\\n    -------\\n    ood_predictions_scores : Tuple[np.ndarray, Optional[np.ndarray]]\\n      Returns a tuple. First element is array of `ood_predictions_scores` and second is an np.ndarray of `confident_thresholds` or None is \\'confident_thresholds\\' is not calculated.\\n    '\n    valid_methods = ('entropy', 'least_confidence', 'gen')\n    if (confident_thresholds is not None or labels is not None) and (not adjust_pred_probs):\n        warnings.warn(\"OOD scores are not adjusted with confident thresholds. If scores need to be adjusted set params['adjusted_pred_probs'] = True. Otherwise passing in confident_thresholds and/or labels does not change score calculation.\", UserWarning)\n    if adjust_pred_probs:\n        if confident_thresholds is None:\n            if labels is None:\n                raise ValueError(\"Cannot calculate adjust_pred_probs without labels. Either pass in labels parameter or set params['adjusted_pred_probs'] = False. \")\n            labels = labels_to_array(labels)\n            assert_valid_inputs(X=None, y=labels, pred_probs=pred_probs, multi_label=False)\n            confident_thresholds = get_confident_thresholds(labels, pred_probs, multi_label=False)\n        pred_probs = _subtract_confident_thresholds(None, pred_probs, multi_label=False, confident_thresholds=confident_thresholds)\n    if method == 'entropy':\n        ood_predictions_scores = 1.0 - get_normalized_entropy(pred_probs)\n    elif method == 'least_confidence':\n        ood_predictions_scores = pred_probs.max(axis=1)\n    elif method == 'gen':\n        if pred_probs.shape[1] < M:\n            warnings.warn(f\"GEN with the default hyperparameter settings is intended for datasets with at least {M} classes. You can adjust params['M'] according to the number of classes in your dataset.\", UserWarning)\n        probs = softmax(pred_probs, axis=1)\n        probs_sorted = np.sort(probs, axis=1)[:, -M:]\n        ood_predictions_scores = 1 - np.sum(probs_sorted ** gamma * (1 - probs_sorted) ** gamma, axis=1) / M\n    else:\n        raise ValueError(f'\\n            {method} is not a valid OOD scoring method!\\n            Please choose a valid scoring_method: {valid_methods}\\n            ')\n    return (ood_predictions_scores, confident_thresholds)",
            "def _get_ood_predictions_scores(pred_probs: np.ndarray, *, labels: Optional[LabelLike]=None, confident_thresholds: Optional[np.ndarray]=None, adjust_pred_probs: bool=True, method: str='entropy', M: int=100, gamma: float=0.1) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Return an OOD (out of distribution) score for each example based on it pred_prob values.\\n\\n    Parameters\\n    ----------\\n    pred_probs : np.ndarray\\n      An array of shape ``(N, K)`` of model-predicted probabilities,\\n      `pred_probs` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    confident_thresholds : np.ndarray, default = None\\n      For details, see key `confident_thresholds` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    labels : array_like, optional\\n      `labels` in the same format expected by the `~cleanlab.outlier.OutOfDistribution.fit` function.\\n\\n    adjust_pred_probs : bool, True\\n      Account for class imbalance in the label-quality scoring.\\n      For details, see key `adjust_pred_probs` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    method : {\"entropy\", \"least_confidence\", \"gen\"}, default=\"entropy\"\\n      Which method to use for computing outlier scores based on pred_probs.\\n      For details see key `method` in the params dict arg of `~cleanlab.outlier.OutOfDistribution`.\\n\\n    M : int, default=100\\n      For GEN method only. Hyperparameter that controls the number of top classes to consider when calculating OOD scores.\\n\\n    gamma : float, default=0.1\\n      For GEN method only. Hyperparameter that controls the weight of the second term in the GEN score.\\n\\n\\n    Returns\\n    -------\\n    ood_predictions_scores : Tuple[np.ndarray, Optional[np.ndarray]]\\n      Returns a tuple. First element is array of `ood_predictions_scores` and second is an np.ndarray of `confident_thresholds` or None is \\'confident_thresholds\\' is not calculated.\\n    '\n    valid_methods = ('entropy', 'least_confidence', 'gen')\n    if (confident_thresholds is not None or labels is not None) and (not adjust_pred_probs):\n        warnings.warn(\"OOD scores are not adjusted with confident thresholds. If scores need to be adjusted set params['adjusted_pred_probs'] = True. Otherwise passing in confident_thresholds and/or labels does not change score calculation.\", UserWarning)\n    if adjust_pred_probs:\n        if confident_thresholds is None:\n            if labels is None:\n                raise ValueError(\"Cannot calculate adjust_pred_probs without labels. Either pass in labels parameter or set params['adjusted_pred_probs'] = False. \")\n            labels = labels_to_array(labels)\n            assert_valid_inputs(X=None, y=labels, pred_probs=pred_probs, multi_label=False)\n            confident_thresholds = get_confident_thresholds(labels, pred_probs, multi_label=False)\n        pred_probs = _subtract_confident_thresholds(None, pred_probs, multi_label=False, confident_thresholds=confident_thresholds)\n    if method == 'entropy':\n        ood_predictions_scores = 1.0 - get_normalized_entropy(pred_probs)\n    elif method == 'least_confidence':\n        ood_predictions_scores = pred_probs.max(axis=1)\n    elif method == 'gen':\n        if pred_probs.shape[1] < M:\n            warnings.warn(f\"GEN with the default hyperparameter settings is intended for datasets with at least {M} classes. You can adjust params['M'] according to the number of classes in your dataset.\", UserWarning)\n        probs = softmax(pred_probs, axis=1)\n        probs_sorted = np.sort(probs, axis=1)[:, -M:]\n        ood_predictions_scores = 1 - np.sum(probs_sorted ** gamma * (1 - probs_sorted) ** gamma, axis=1) / M\n    else:\n        raise ValueError(f'\\n            {method} is not a valid OOD scoring method!\\n            Please choose a valid scoring_method: {valid_methods}\\n            ')\n    return (ood_predictions_scores, confident_thresholds)"
        ]
    }
]