[
    {
        "func_name": "extract_part",
        "original": "def extract_part(part_id):\n    smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n    smil = self._download_smil(smil_url, lecture_id)\n    info = self._parse_smil(smil, smil_url, lecture_id)\n    info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n    info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n    if multipart:\n        info['title'] += ' (Part %s)' % part_id\n    switch = smil.find('.//switch')\n    if switch is not None:\n        info['duration'] = parse_duration(switch.attrib.get('dur'))\n    item_info = lecture_info.copy()\n    item_info.update(info)\n    return item_info",
        "mutated": [
            "def extract_part(part_id):\n    if False:\n        i = 10\n    smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n    smil = self._download_smil(smil_url, lecture_id)\n    info = self._parse_smil(smil, smil_url, lecture_id)\n    info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n    info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n    if multipart:\n        info['title'] += ' (Part %s)' % part_id\n    switch = smil.find('.//switch')\n    if switch is not None:\n        info['duration'] = parse_duration(switch.attrib.get('dur'))\n    item_info = lecture_info.copy()\n    item_info.update(info)\n    return item_info",
            "def extract_part(part_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n    smil = self._download_smil(smil_url, lecture_id)\n    info = self._parse_smil(smil, smil_url, lecture_id)\n    info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n    info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n    if multipart:\n        info['title'] += ' (Part %s)' % part_id\n    switch = smil.find('.//switch')\n    if switch is not None:\n        info['duration'] = parse_duration(switch.attrib.get('dur'))\n    item_info = lecture_info.copy()\n    item_info.update(info)\n    return item_info",
            "def extract_part(part_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n    smil = self._download_smil(smil_url, lecture_id)\n    info = self._parse_smil(smil, smil_url, lecture_id)\n    info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n    info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n    if multipart:\n        info['title'] += ' (Part %s)' % part_id\n    switch = smil.find('.//switch')\n    if switch is not None:\n        info['duration'] = parse_duration(switch.attrib.get('dur'))\n    item_info = lecture_info.copy()\n    item_info.update(info)\n    return item_info",
            "def extract_part(part_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n    smil = self._download_smil(smil_url, lecture_id)\n    info = self._parse_smil(smil, smil_url, lecture_id)\n    info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n    info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n    if multipart:\n        info['title'] += ' (Part %s)' % part_id\n    switch = smil.find('.//switch')\n    if switch is not None:\n        info['duration'] = parse_duration(switch.attrib.get('dur'))\n    item_info = lecture_info.copy()\n    item_info.update(info)\n    return item_info",
            "def extract_part(part_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n    smil = self._download_smil(smil_url, lecture_id)\n    info = self._parse_smil(smil, smil_url, lecture_id)\n    info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n    info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n    if multipart:\n        info['title'] += ' (Part %s)' % part_id\n    switch = smil.find('.//switch')\n    if switch is not None:\n        info['duration'] = parse_duration(switch.attrib.get('dur'))\n    item_info = lecture_info.copy()\n    item_info.update(info)\n    return item_info"
        ]
    },
    {
        "func_name": "_real_extract",
        "original": "def _real_extract(self, url):\n    (lecture_slug, explicit_part_id) = self._match_valid_url(url).groups()\n    webpage = self._download_webpage(url, lecture_slug)\n    cfg = self._parse_json(self._search_regex(['cfg\\\\s*:\\\\s*({.+?})\\\\s*,\\\\s*[\\\\da-zA-Z_]+\\\\s*:\\\\s*\\\\(?\\\\s*function', 'cfg\\\\s*:\\\\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)\n    lecture_id = compat_str(cfg['obj_id'])\n    base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n    try:\n        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]\n    except ExtractorError as e:\n        if isinstance(e.cause, HTTPError) and e.cause.status == 403:\n            msg = self._parse_json(e.cause.response.read().decode('utf-8'), lecture_id)\n            raise ExtractorError(msg['detail'], expected=True)\n        raise\n    lecture_info = {'id': lecture_id, 'display_id': lecture_slug, 'title': lecture_data['title'], 'timestamp': parse_iso8601(lecture_data.get('time')), 'description': lecture_data.get('description_wiki'), 'thumbnail': lecture_data.get('thumb')}\n    playlist_entries = []\n    lecture_type = lecture_data.get('type')\n    parts = [compat_str(video) for video in cfg.get('videos', [])]\n    if parts:\n        multipart = len(parts) > 1\n\n        def extract_part(part_id):\n            smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n            smil = self._download_smil(smil_url, lecture_id)\n            info = self._parse_smil(smil, smil_url, lecture_id)\n            info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n            info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n            if multipart:\n                info['title'] += ' (Part %s)' % part_id\n            switch = smil.find('.//switch')\n            if switch is not None:\n                info['duration'] = parse_duration(switch.attrib.get('dur'))\n            item_info = lecture_info.copy()\n            item_info.update(info)\n            return item_info\n        if explicit_part_id or not multipart:\n            result = extract_part(explicit_part_id or parts[0])\n        else:\n            result = {'_type': 'multi_video', 'entries': [extract_part(part) for part in parts]}\n            result.update(lecture_info)\n        if explicit_part_id or lecture_type != 'evt':\n            return result\n        playlist_entries.append(result)\n    if not parts or lecture_type == 'evt':\n        playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n        entries = [self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea') for (_, video_url) in re.findall('<a[^>]+href=([\"\\\\\\'])(.+?)\\\\1[^>]+id=[\"\\\\\\']lec=\\\\d+', playlist_webpage)]\n        playlist_entries.extend(entries)\n    playlist = self.playlist_result(playlist_entries, lecture_id)\n    playlist.update(lecture_info)\n    return playlist",
        "mutated": [
            "def _real_extract(self, url):\n    if False:\n        i = 10\n    (lecture_slug, explicit_part_id) = self._match_valid_url(url).groups()\n    webpage = self._download_webpage(url, lecture_slug)\n    cfg = self._parse_json(self._search_regex(['cfg\\\\s*:\\\\s*({.+?})\\\\s*,\\\\s*[\\\\da-zA-Z_]+\\\\s*:\\\\s*\\\\(?\\\\s*function', 'cfg\\\\s*:\\\\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)\n    lecture_id = compat_str(cfg['obj_id'])\n    base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n    try:\n        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]\n    except ExtractorError as e:\n        if isinstance(e.cause, HTTPError) and e.cause.status == 403:\n            msg = self._parse_json(e.cause.response.read().decode('utf-8'), lecture_id)\n            raise ExtractorError(msg['detail'], expected=True)\n        raise\n    lecture_info = {'id': lecture_id, 'display_id': lecture_slug, 'title': lecture_data['title'], 'timestamp': parse_iso8601(lecture_data.get('time')), 'description': lecture_data.get('description_wiki'), 'thumbnail': lecture_data.get('thumb')}\n    playlist_entries = []\n    lecture_type = lecture_data.get('type')\n    parts = [compat_str(video) for video in cfg.get('videos', [])]\n    if parts:\n        multipart = len(parts) > 1\n\n        def extract_part(part_id):\n            smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n            smil = self._download_smil(smil_url, lecture_id)\n            info = self._parse_smil(smil, smil_url, lecture_id)\n            info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n            info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n            if multipart:\n                info['title'] += ' (Part %s)' % part_id\n            switch = smil.find('.//switch')\n            if switch is not None:\n                info['duration'] = parse_duration(switch.attrib.get('dur'))\n            item_info = lecture_info.copy()\n            item_info.update(info)\n            return item_info\n        if explicit_part_id or not multipart:\n            result = extract_part(explicit_part_id or parts[0])\n        else:\n            result = {'_type': 'multi_video', 'entries': [extract_part(part) for part in parts]}\n            result.update(lecture_info)\n        if explicit_part_id or lecture_type != 'evt':\n            return result\n        playlist_entries.append(result)\n    if not parts or lecture_type == 'evt':\n        playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n        entries = [self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea') for (_, video_url) in re.findall('<a[^>]+href=([\"\\\\\\'])(.+?)\\\\1[^>]+id=[\"\\\\\\']lec=\\\\d+', playlist_webpage)]\n        playlist_entries.extend(entries)\n    playlist = self.playlist_result(playlist_entries, lecture_id)\n    playlist.update(lecture_info)\n    return playlist",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (lecture_slug, explicit_part_id) = self._match_valid_url(url).groups()\n    webpage = self._download_webpage(url, lecture_slug)\n    cfg = self._parse_json(self._search_regex(['cfg\\\\s*:\\\\s*({.+?})\\\\s*,\\\\s*[\\\\da-zA-Z_]+\\\\s*:\\\\s*\\\\(?\\\\s*function', 'cfg\\\\s*:\\\\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)\n    lecture_id = compat_str(cfg['obj_id'])\n    base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n    try:\n        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]\n    except ExtractorError as e:\n        if isinstance(e.cause, HTTPError) and e.cause.status == 403:\n            msg = self._parse_json(e.cause.response.read().decode('utf-8'), lecture_id)\n            raise ExtractorError(msg['detail'], expected=True)\n        raise\n    lecture_info = {'id': lecture_id, 'display_id': lecture_slug, 'title': lecture_data['title'], 'timestamp': parse_iso8601(lecture_data.get('time')), 'description': lecture_data.get('description_wiki'), 'thumbnail': lecture_data.get('thumb')}\n    playlist_entries = []\n    lecture_type = lecture_data.get('type')\n    parts = [compat_str(video) for video in cfg.get('videos', [])]\n    if parts:\n        multipart = len(parts) > 1\n\n        def extract_part(part_id):\n            smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n            smil = self._download_smil(smil_url, lecture_id)\n            info = self._parse_smil(smil, smil_url, lecture_id)\n            info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n            info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n            if multipart:\n                info['title'] += ' (Part %s)' % part_id\n            switch = smil.find('.//switch')\n            if switch is not None:\n                info['duration'] = parse_duration(switch.attrib.get('dur'))\n            item_info = lecture_info.copy()\n            item_info.update(info)\n            return item_info\n        if explicit_part_id or not multipart:\n            result = extract_part(explicit_part_id or parts[0])\n        else:\n            result = {'_type': 'multi_video', 'entries': [extract_part(part) for part in parts]}\n            result.update(lecture_info)\n        if explicit_part_id or lecture_type != 'evt':\n            return result\n        playlist_entries.append(result)\n    if not parts or lecture_type == 'evt':\n        playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n        entries = [self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea') for (_, video_url) in re.findall('<a[^>]+href=([\"\\\\\\'])(.+?)\\\\1[^>]+id=[\"\\\\\\']lec=\\\\d+', playlist_webpage)]\n        playlist_entries.extend(entries)\n    playlist = self.playlist_result(playlist_entries, lecture_id)\n    playlist.update(lecture_info)\n    return playlist",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (lecture_slug, explicit_part_id) = self._match_valid_url(url).groups()\n    webpage = self._download_webpage(url, lecture_slug)\n    cfg = self._parse_json(self._search_regex(['cfg\\\\s*:\\\\s*({.+?})\\\\s*,\\\\s*[\\\\da-zA-Z_]+\\\\s*:\\\\s*\\\\(?\\\\s*function', 'cfg\\\\s*:\\\\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)\n    lecture_id = compat_str(cfg['obj_id'])\n    base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n    try:\n        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]\n    except ExtractorError as e:\n        if isinstance(e.cause, HTTPError) and e.cause.status == 403:\n            msg = self._parse_json(e.cause.response.read().decode('utf-8'), lecture_id)\n            raise ExtractorError(msg['detail'], expected=True)\n        raise\n    lecture_info = {'id': lecture_id, 'display_id': lecture_slug, 'title': lecture_data['title'], 'timestamp': parse_iso8601(lecture_data.get('time')), 'description': lecture_data.get('description_wiki'), 'thumbnail': lecture_data.get('thumb')}\n    playlist_entries = []\n    lecture_type = lecture_data.get('type')\n    parts = [compat_str(video) for video in cfg.get('videos', [])]\n    if parts:\n        multipart = len(parts) > 1\n\n        def extract_part(part_id):\n            smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n            smil = self._download_smil(smil_url, lecture_id)\n            info = self._parse_smil(smil, smil_url, lecture_id)\n            info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n            info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n            if multipart:\n                info['title'] += ' (Part %s)' % part_id\n            switch = smil.find('.//switch')\n            if switch is not None:\n                info['duration'] = parse_duration(switch.attrib.get('dur'))\n            item_info = lecture_info.copy()\n            item_info.update(info)\n            return item_info\n        if explicit_part_id or not multipart:\n            result = extract_part(explicit_part_id or parts[0])\n        else:\n            result = {'_type': 'multi_video', 'entries': [extract_part(part) for part in parts]}\n            result.update(lecture_info)\n        if explicit_part_id or lecture_type != 'evt':\n            return result\n        playlist_entries.append(result)\n    if not parts or lecture_type == 'evt':\n        playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n        entries = [self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea') for (_, video_url) in re.findall('<a[^>]+href=([\"\\\\\\'])(.+?)\\\\1[^>]+id=[\"\\\\\\']lec=\\\\d+', playlist_webpage)]\n        playlist_entries.extend(entries)\n    playlist = self.playlist_result(playlist_entries, lecture_id)\n    playlist.update(lecture_info)\n    return playlist",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (lecture_slug, explicit_part_id) = self._match_valid_url(url).groups()\n    webpage = self._download_webpage(url, lecture_slug)\n    cfg = self._parse_json(self._search_regex(['cfg\\\\s*:\\\\s*({.+?})\\\\s*,\\\\s*[\\\\da-zA-Z_]+\\\\s*:\\\\s*\\\\(?\\\\s*function', 'cfg\\\\s*:\\\\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)\n    lecture_id = compat_str(cfg['obj_id'])\n    base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n    try:\n        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]\n    except ExtractorError as e:\n        if isinstance(e.cause, HTTPError) and e.cause.status == 403:\n            msg = self._parse_json(e.cause.response.read().decode('utf-8'), lecture_id)\n            raise ExtractorError(msg['detail'], expected=True)\n        raise\n    lecture_info = {'id': lecture_id, 'display_id': lecture_slug, 'title': lecture_data['title'], 'timestamp': parse_iso8601(lecture_data.get('time')), 'description': lecture_data.get('description_wiki'), 'thumbnail': lecture_data.get('thumb')}\n    playlist_entries = []\n    lecture_type = lecture_data.get('type')\n    parts = [compat_str(video) for video in cfg.get('videos', [])]\n    if parts:\n        multipart = len(parts) > 1\n\n        def extract_part(part_id):\n            smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n            smil = self._download_smil(smil_url, lecture_id)\n            info = self._parse_smil(smil, smil_url, lecture_id)\n            info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n            info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n            if multipart:\n                info['title'] += ' (Part %s)' % part_id\n            switch = smil.find('.//switch')\n            if switch is not None:\n                info['duration'] = parse_duration(switch.attrib.get('dur'))\n            item_info = lecture_info.copy()\n            item_info.update(info)\n            return item_info\n        if explicit_part_id or not multipart:\n            result = extract_part(explicit_part_id or parts[0])\n        else:\n            result = {'_type': 'multi_video', 'entries': [extract_part(part) for part in parts]}\n            result.update(lecture_info)\n        if explicit_part_id or lecture_type != 'evt':\n            return result\n        playlist_entries.append(result)\n    if not parts or lecture_type == 'evt':\n        playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n        entries = [self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea') for (_, video_url) in re.findall('<a[^>]+href=([\"\\\\\\'])(.+?)\\\\1[^>]+id=[\"\\\\\\']lec=\\\\d+', playlist_webpage)]\n        playlist_entries.extend(entries)\n    playlist = self.playlist_result(playlist_entries, lecture_id)\n    playlist.update(lecture_info)\n    return playlist",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (lecture_slug, explicit_part_id) = self._match_valid_url(url).groups()\n    webpage = self._download_webpage(url, lecture_slug)\n    cfg = self._parse_json(self._search_regex(['cfg\\\\s*:\\\\s*({.+?})\\\\s*,\\\\s*[\\\\da-zA-Z_]+\\\\s*:\\\\s*\\\\(?\\\\s*function', 'cfg\\\\s*:\\\\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)\n    lecture_id = compat_str(cfg['obj_id'])\n    base_url = self._proto_relative_url(cfg['livepipe'], 'http:')\n    try:\n        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]\n    except ExtractorError as e:\n        if isinstance(e.cause, HTTPError) and e.cause.status == 403:\n            msg = self._parse_json(e.cause.response.read().decode('utf-8'), lecture_id)\n            raise ExtractorError(msg['detail'], expected=True)\n        raise\n    lecture_info = {'id': lecture_id, 'display_id': lecture_slug, 'title': lecture_data['title'], 'timestamp': parse_iso8601(lecture_data.get('time')), 'description': lecture_data.get('description_wiki'), 'thumbnail': lecture_data.get('thumb')}\n    playlist_entries = []\n    lecture_type = lecture_data.get('type')\n    parts = [compat_str(video) for video in cfg.get('videos', [])]\n    if parts:\n        multipart = len(parts) > 1\n\n        def extract_part(part_id):\n            smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part_id)\n            smil = self._download_smil(smil_url, lecture_id)\n            info = self._parse_smil(smil, smil_url, lecture_id)\n            info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)\n            info['display_id'] = lecture_slug if not multipart else '%s_part%s' % (lecture_slug, part_id)\n            if multipart:\n                info['title'] += ' (Part %s)' % part_id\n            switch = smil.find('.//switch')\n            if switch is not None:\n                info['duration'] = parse_duration(switch.attrib.get('dur'))\n            item_info = lecture_info.copy()\n            item_info.update(info)\n            return item_info\n        if explicit_part_id or not multipart:\n            result = extract_part(explicit_part_id or parts[0])\n        else:\n            result = {'_type': 'multi_video', 'entries': [extract_part(part) for part in parts]}\n            result.update(lecture_info)\n        if explicit_part_id or lecture_type != 'evt':\n            return result\n        playlist_entries.append(result)\n    if not parts or lecture_type == 'evt':\n        playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)\n        entries = [self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea') for (_, video_url) in re.findall('<a[^>]+href=([\"\\\\\\'])(.+?)\\\\1[^>]+id=[\"\\\\\\']lec=\\\\d+', playlist_webpage)]\n        playlist_entries.extend(entries)\n    playlist = self.playlist_result(playlist_entries, lecture_id)\n    playlist.update(lecture_info)\n    return playlist"
        ]
    }
]