[
    {
        "func_name": "__init__",
        "original": "def __init__(self, name, type, start_ns, end_ns, process_id, thread_id):\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.children_node = []\n    self.runtime_node = []\n    self.device_node = []\n    self.mem_node = []",
        "mutated": [
            "def __init__(self, name, type, start_ns, end_ns, process_id, thread_id):\n    if False:\n        i = 10\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.children_node = []\n    self.runtime_node = []\n    self.device_node = []\n    self.mem_node = []",
            "def __init__(self, name, type, start_ns, end_ns, process_id, thread_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.children_node = []\n    self.runtime_node = []\n    self.device_node = []\n    self.mem_node = []",
            "def __init__(self, name, type, start_ns, end_ns, process_id, thread_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.children_node = []\n    self.runtime_node = []\n    self.device_node = []\n    self.mem_node = []",
            "def __init__(self, name, type, start_ns, end_ns, process_id, thread_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.children_node = []\n    self.runtime_node = []\n    self.device_node = []\n    self.mem_node = []",
            "def __init__(self, name, type, start_ns, end_ns, process_id, thread_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.children_node = []\n    self.runtime_node = []\n    self.device_node = []\n    self.mem_node = []"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, name, type, start_ns, end_ns, device_id, context_id, stream_id):\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.device_id = device_id\n    self.context_id = context_id\n    self.stream_id = stream_id",
        "mutated": [
            "def __init__(self, name, type, start_ns, end_ns, device_id, context_id, stream_id):\n    if False:\n        i = 10\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.device_id = device_id\n    self.context_id = context_id\n    self.stream_id = stream_id",
            "def __init__(self, name, type, start_ns, end_ns, device_id, context_id, stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.device_id = device_id\n    self.context_id = context_id\n    self.stream_id = stream_id",
            "def __init__(self, name, type, start_ns, end_ns, device_id, context_id, stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.device_id = device_id\n    self.context_id = context_id\n    self.stream_id = stream_id",
            "def __init__(self, name, type, start_ns, end_ns, device_id, context_id, stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.device_id = device_id\n    self.context_id = context_id\n    self.stream_id = stream_id",
            "def __init__(self, name, type, start_ns, end_ns, device_id, context_id, stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.name = name\n    self.type = type\n    self.start_ns = start_ns\n    self.end_ns = end_ns\n    self.device_id = device_id\n    self.context_id = context_id\n    self.stream_id = stream_id"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, timestamp_ns, addr, type, process_id, thread_id, increase_bytes, place, current_allocated, current_reserved, peak_allocated, peak_reserved):\n    self.timestamp_ns = timestamp_ns\n    self.addr = addr\n    self.type = type\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.increase_bytes = increase_bytes\n    self.place = place\n    self.current_allocated = current_allocated\n    self.current_reserved = current_reserved\n    self.peak_allocated = peak_allocated\n    self.peak_reserved = peak_reserved",
        "mutated": [
            "def __init__(self, timestamp_ns, addr, type, process_id, thread_id, increase_bytes, place, current_allocated, current_reserved, peak_allocated, peak_reserved):\n    if False:\n        i = 10\n    self.timestamp_ns = timestamp_ns\n    self.addr = addr\n    self.type = type\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.increase_bytes = increase_bytes\n    self.place = place\n    self.current_allocated = current_allocated\n    self.current_reserved = current_reserved\n    self.peak_allocated = peak_allocated\n    self.peak_reserved = peak_reserved",
            "def __init__(self, timestamp_ns, addr, type, process_id, thread_id, increase_bytes, place, current_allocated, current_reserved, peak_allocated, peak_reserved):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.timestamp_ns = timestamp_ns\n    self.addr = addr\n    self.type = type\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.increase_bytes = increase_bytes\n    self.place = place\n    self.current_allocated = current_allocated\n    self.current_reserved = current_reserved\n    self.peak_allocated = peak_allocated\n    self.peak_reserved = peak_reserved",
            "def __init__(self, timestamp_ns, addr, type, process_id, thread_id, increase_bytes, place, current_allocated, current_reserved, peak_allocated, peak_reserved):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.timestamp_ns = timestamp_ns\n    self.addr = addr\n    self.type = type\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.increase_bytes = increase_bytes\n    self.place = place\n    self.current_allocated = current_allocated\n    self.current_reserved = current_reserved\n    self.peak_allocated = peak_allocated\n    self.peak_reserved = peak_reserved",
            "def __init__(self, timestamp_ns, addr, type, process_id, thread_id, increase_bytes, place, current_allocated, current_reserved, peak_allocated, peak_reserved):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.timestamp_ns = timestamp_ns\n    self.addr = addr\n    self.type = type\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.increase_bytes = increase_bytes\n    self.place = place\n    self.current_allocated = current_allocated\n    self.current_reserved = current_reserved\n    self.peak_allocated = peak_allocated\n    self.peak_reserved = peak_reserved",
            "def __init__(self, timestamp_ns, addr, type, process_id, thread_id, increase_bytes, place, current_allocated, current_reserved, peak_allocated, peak_reserved):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.timestamp_ns = timestamp_ns\n    self.addr = addr\n    self.type = type\n    self.process_id = process_id\n    self.thread_id = thread_id\n    self.increase_bytes = increase_bytes\n    self.place = place\n    self.current_allocated = current_allocated\n    self.current_reserved = current_reserved\n    self.peak_allocated = peak_allocated\n    self.peak_reserved = peak_reserved"
        ]
    },
    {
        "func_name": "test_statistic_case1",
        "original": "def test_statistic_case1(self):\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_compute.mem_node.append(MemPythonNode(33, 0, profiler_statistic.TracerMemEventType.Allocate, 1000, 1001, 20, 'place(gpu:0)', 200, 200, 800, 800))\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 155, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 55)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 45)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 30)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 75)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(len(event_summary.items), 2)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 135)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_count, 1)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.peak_allocation_values['place(gpu:0)'], 800)\n    self.assertEqual(statistic_data.memory_summary.peak_reserved_values['place(gpu:0)'], 800)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
        "mutated": [
            "def test_statistic_case1(self):\n    if False:\n        i = 10\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_compute.mem_node.append(MemPythonNode(33, 0, profiler_statistic.TracerMemEventType.Allocate, 1000, 1001, 20, 'place(gpu:0)', 200, 200, 800, 800))\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 155, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 55)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 45)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 30)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 75)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(len(event_summary.items), 2)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 135)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_count, 1)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.peak_allocation_values['place(gpu:0)'], 800)\n    self.assertEqual(statistic_data.memory_summary.peak_reserved_values['place(gpu:0)'], 800)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case1(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_compute.mem_node.append(MemPythonNode(33, 0, profiler_statistic.TracerMemEventType.Allocate, 1000, 1001, 20, 'place(gpu:0)', 200, 200, 800, 800))\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 155, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 55)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 45)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 30)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 75)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(len(event_summary.items), 2)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 135)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_count, 1)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.peak_allocation_values['place(gpu:0)'], 800)\n    self.assertEqual(statistic_data.memory_summary.peak_reserved_values['place(gpu:0)'], 800)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case1(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_compute.mem_node.append(MemPythonNode(33, 0, profiler_statistic.TracerMemEventType.Allocate, 1000, 1001, 20, 'place(gpu:0)', 200, 200, 800, 800))\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 155, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 55)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 45)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 30)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 75)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(len(event_summary.items), 2)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 135)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_count, 1)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.peak_allocation_values['place(gpu:0)'], 800)\n    self.assertEqual(statistic_data.memory_summary.peak_reserved_values['place(gpu:0)'], 800)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case1(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_compute.mem_node.append(MemPythonNode(33, 0, profiler_statistic.TracerMemEventType.Allocate, 1000, 1001, 20, 'place(gpu:0)', 200, 200, 800, 800))\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 155, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 55)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 45)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 30)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 75)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(len(event_summary.items), 2)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 135)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_count, 1)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.peak_allocation_values['place(gpu:0)'], 800)\n    self.assertEqual(statistic_data.memory_summary.peak_reserved_values['place(gpu:0)'], 800)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case1(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_compute.mem_node.append(MemPythonNode(33, 0, profiler_statistic.TracerMemEventType.Allocate, 1000, 1001, 20, 'place(gpu:0)', 200, 200, 800, 800))\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 155, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 55)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 45)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 30)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 75)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(len(event_summary.items), 2)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 135)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_count, 1)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].allocation_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.allocated_items['place(gpu:0)']['conv2d'].increase_size, 20)\n    self.assertEqual(statistic_data.memory_summary.peak_allocation_values['place(gpu:0)'], 800)\n    self.assertEqual(statistic_data.memory_summary.peak_reserved_values['place(gpu:0)'], 800)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))"
        ]
    },
    {
        "func_name": "test_statistic_case2",
        "original": "def test_statistic_case2(self):\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    allreduce_launchkernel0 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 102, 104, 1000, 1001)\n    nccl_allreduce_kernel0 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 105, 120, 0, 0, 2)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    allreduce_op1 = HostPythonNode('allreduce_op1', profiler.TracerEventType.Operator, 105, 108, 1000, 1001)\n    allreduce_op1_infershape = HostPythonNode('allreduce_op1::infershape', profiler.TracerEventType.OperatorInner, 105, 106, 1000, 1001)\n    allreduce_launchkernel1 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 106, 107, 1000, 1001)\n    nccl_allreduce_kernel1 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 130, 150, 0, 0, 2)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 300, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    allreduce_node2 = HostPythonNode('allreduce', profiler.TracerEventType.Operator, 230, 250, 1000, 1001)\n    allreduce_node2_infershape = HostPythonNode('allreduce_node2::infershape', profiler.TracerEventType.OperatorInner, 231, 232, 1000, 1001)\n    allreduce_launchkernel2 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 235, 240, 1000, 1001)\n    nccl_allreduce_kernel2 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 250, 280, 0, 0, 2)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    userdefined_node.runtime_node.append(allreduce_launchkernel0)\n    allreduce_launchkernel0.device_node.append(nccl_allreduce_kernel0)\n    communication_node.children_node.append(allreduce_op1)\n    allreduce_op1.children_node.append(allreduce_op1_infershape)\n    allreduce_op1.runtime_node.append(allreduce_launchkernel1)\n    allreduce_launchkernel1.device_node.append(nccl_allreduce_kernel1)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    optimization_node.children_node.append(allreduce_node2)\n    allreduce_node2.children_node.append(allreduce_node2_infershape)\n    allreduce_node2.runtime_node.append(allreduce_launchkernel2)\n    allreduce_launchkernel2.device_node.append(nccl_allreduce_kernel2)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    distributed_summary = statistic_data.distributed_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 78)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 47)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 38)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 220)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.cpu_communication_range), 25)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.gpu_communication_range), 65)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.communication_range), 85)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.computation_range), 220)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.overlap_range), 85)\n    self.assertEqual(len(event_summary.items), 4)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 315)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
        "mutated": [
            "def test_statistic_case2(self):\n    if False:\n        i = 10\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    allreduce_launchkernel0 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 102, 104, 1000, 1001)\n    nccl_allreduce_kernel0 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 105, 120, 0, 0, 2)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    allreduce_op1 = HostPythonNode('allreduce_op1', profiler.TracerEventType.Operator, 105, 108, 1000, 1001)\n    allreduce_op1_infershape = HostPythonNode('allreduce_op1::infershape', profiler.TracerEventType.OperatorInner, 105, 106, 1000, 1001)\n    allreduce_launchkernel1 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 106, 107, 1000, 1001)\n    nccl_allreduce_kernel1 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 130, 150, 0, 0, 2)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 300, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    allreduce_node2 = HostPythonNode('allreduce', profiler.TracerEventType.Operator, 230, 250, 1000, 1001)\n    allreduce_node2_infershape = HostPythonNode('allreduce_node2::infershape', profiler.TracerEventType.OperatorInner, 231, 232, 1000, 1001)\n    allreduce_launchkernel2 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 235, 240, 1000, 1001)\n    nccl_allreduce_kernel2 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 250, 280, 0, 0, 2)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    userdefined_node.runtime_node.append(allreduce_launchkernel0)\n    allreduce_launchkernel0.device_node.append(nccl_allreduce_kernel0)\n    communication_node.children_node.append(allreduce_op1)\n    allreduce_op1.children_node.append(allreduce_op1_infershape)\n    allreduce_op1.runtime_node.append(allreduce_launchkernel1)\n    allreduce_launchkernel1.device_node.append(nccl_allreduce_kernel1)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    optimization_node.children_node.append(allreduce_node2)\n    allreduce_node2.children_node.append(allreduce_node2_infershape)\n    allreduce_node2.runtime_node.append(allreduce_launchkernel2)\n    allreduce_launchkernel2.device_node.append(nccl_allreduce_kernel2)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    distributed_summary = statistic_data.distributed_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 78)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 47)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 38)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 220)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.cpu_communication_range), 25)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.gpu_communication_range), 65)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.communication_range), 85)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.computation_range), 220)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.overlap_range), 85)\n    self.assertEqual(len(event_summary.items), 4)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 315)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case2(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    allreduce_launchkernel0 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 102, 104, 1000, 1001)\n    nccl_allreduce_kernel0 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 105, 120, 0, 0, 2)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    allreduce_op1 = HostPythonNode('allreduce_op1', profiler.TracerEventType.Operator, 105, 108, 1000, 1001)\n    allreduce_op1_infershape = HostPythonNode('allreduce_op1::infershape', profiler.TracerEventType.OperatorInner, 105, 106, 1000, 1001)\n    allreduce_launchkernel1 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 106, 107, 1000, 1001)\n    nccl_allreduce_kernel1 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 130, 150, 0, 0, 2)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 300, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    allreduce_node2 = HostPythonNode('allreduce', profiler.TracerEventType.Operator, 230, 250, 1000, 1001)\n    allreduce_node2_infershape = HostPythonNode('allreduce_node2::infershape', profiler.TracerEventType.OperatorInner, 231, 232, 1000, 1001)\n    allreduce_launchkernel2 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 235, 240, 1000, 1001)\n    nccl_allreduce_kernel2 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 250, 280, 0, 0, 2)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    userdefined_node.runtime_node.append(allreduce_launchkernel0)\n    allreduce_launchkernel0.device_node.append(nccl_allreduce_kernel0)\n    communication_node.children_node.append(allreduce_op1)\n    allreduce_op1.children_node.append(allreduce_op1_infershape)\n    allreduce_op1.runtime_node.append(allreduce_launchkernel1)\n    allreduce_launchkernel1.device_node.append(nccl_allreduce_kernel1)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    optimization_node.children_node.append(allreduce_node2)\n    allreduce_node2.children_node.append(allreduce_node2_infershape)\n    allreduce_node2.runtime_node.append(allreduce_launchkernel2)\n    allreduce_launchkernel2.device_node.append(nccl_allreduce_kernel2)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    distributed_summary = statistic_data.distributed_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 78)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 47)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 38)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 220)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.cpu_communication_range), 25)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.gpu_communication_range), 65)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.communication_range), 85)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.computation_range), 220)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.overlap_range), 85)\n    self.assertEqual(len(event_summary.items), 4)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 315)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case2(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    allreduce_launchkernel0 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 102, 104, 1000, 1001)\n    nccl_allreduce_kernel0 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 105, 120, 0, 0, 2)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    allreduce_op1 = HostPythonNode('allreduce_op1', profiler.TracerEventType.Operator, 105, 108, 1000, 1001)\n    allreduce_op1_infershape = HostPythonNode('allreduce_op1::infershape', profiler.TracerEventType.OperatorInner, 105, 106, 1000, 1001)\n    allreduce_launchkernel1 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 106, 107, 1000, 1001)\n    nccl_allreduce_kernel1 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 130, 150, 0, 0, 2)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 300, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    allreduce_node2 = HostPythonNode('allreduce', profiler.TracerEventType.Operator, 230, 250, 1000, 1001)\n    allreduce_node2_infershape = HostPythonNode('allreduce_node2::infershape', profiler.TracerEventType.OperatorInner, 231, 232, 1000, 1001)\n    allreduce_launchkernel2 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 235, 240, 1000, 1001)\n    nccl_allreduce_kernel2 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 250, 280, 0, 0, 2)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    userdefined_node.runtime_node.append(allreduce_launchkernel0)\n    allreduce_launchkernel0.device_node.append(nccl_allreduce_kernel0)\n    communication_node.children_node.append(allreduce_op1)\n    allreduce_op1.children_node.append(allreduce_op1_infershape)\n    allreduce_op1.runtime_node.append(allreduce_launchkernel1)\n    allreduce_launchkernel1.device_node.append(nccl_allreduce_kernel1)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    optimization_node.children_node.append(allreduce_node2)\n    allreduce_node2.children_node.append(allreduce_node2_infershape)\n    allreduce_node2.runtime_node.append(allreduce_launchkernel2)\n    allreduce_launchkernel2.device_node.append(nccl_allreduce_kernel2)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    distributed_summary = statistic_data.distributed_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 78)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 47)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 38)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 220)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.cpu_communication_range), 25)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.gpu_communication_range), 65)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.communication_range), 85)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.computation_range), 220)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.overlap_range), 85)\n    self.assertEqual(len(event_summary.items), 4)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 315)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case2(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    allreduce_launchkernel0 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 102, 104, 1000, 1001)\n    nccl_allreduce_kernel0 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 105, 120, 0, 0, 2)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    allreduce_op1 = HostPythonNode('allreduce_op1', profiler.TracerEventType.Operator, 105, 108, 1000, 1001)\n    allreduce_op1_infershape = HostPythonNode('allreduce_op1::infershape', profiler.TracerEventType.OperatorInner, 105, 106, 1000, 1001)\n    allreduce_launchkernel1 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 106, 107, 1000, 1001)\n    nccl_allreduce_kernel1 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 130, 150, 0, 0, 2)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 300, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    allreduce_node2 = HostPythonNode('allreduce', profiler.TracerEventType.Operator, 230, 250, 1000, 1001)\n    allreduce_node2_infershape = HostPythonNode('allreduce_node2::infershape', profiler.TracerEventType.OperatorInner, 231, 232, 1000, 1001)\n    allreduce_launchkernel2 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 235, 240, 1000, 1001)\n    nccl_allreduce_kernel2 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 250, 280, 0, 0, 2)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    userdefined_node.runtime_node.append(allreduce_launchkernel0)\n    allreduce_launchkernel0.device_node.append(nccl_allreduce_kernel0)\n    communication_node.children_node.append(allreduce_op1)\n    allreduce_op1.children_node.append(allreduce_op1_infershape)\n    allreduce_op1.runtime_node.append(allreduce_launchkernel1)\n    allreduce_launchkernel1.device_node.append(nccl_allreduce_kernel1)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    optimization_node.children_node.append(allreduce_node2)\n    allreduce_node2.children_node.append(allreduce_node2_infershape)\n    allreduce_node2.runtime_node.append(allreduce_launchkernel2)\n    allreduce_launchkernel2.device_node.append(nccl_allreduce_kernel2)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    distributed_summary = statistic_data.distributed_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 78)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 47)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 38)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 220)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.cpu_communication_range), 25)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.gpu_communication_range), 65)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.communication_range), 85)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.computation_range), 220)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.overlap_range), 85)\n    self.assertEqual(len(event_summary.items), 4)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 315)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case2(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    yolonet_node = HostPythonNode('Yolov3Net', profiler.TracerEventType.Forward, 50, 110, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 100, 110, 1000, 1001)\n    allreduce_launchkernel0 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 102, 104, 1000, 1001)\n    nccl_allreduce_kernel0 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 105, 120, 0, 0, 2)\n    communication_node = HostPythonNode('Communication', profiler.TracerEventType.Communication, 105, 110, 1000, 1001)\n    allreduce_op1 = HostPythonNode('allreduce_op1', profiler.TracerEventType.Operator, 105, 108, 1000, 1001)\n    allreduce_op1_infershape = HostPythonNode('allreduce_op1::infershape', profiler.TracerEventType.OperatorInner, 105, 106, 1000, 1001)\n    allreduce_launchkernel1 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 106, 107, 1000, 1001)\n    nccl_allreduce_kernel1 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 130, 150, 0, 0, 2)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 40, 1000, 1001)\n    sync_batch_norm_node = HostPythonNode('sync_batch_norm', profiler.TracerEventType.Operator, 60, 100, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 30, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 30, 40, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 30, 35, 1000, 1001)\n    conv2d_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 35, 40, 1000, 1001)\n    conv2d_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 35, 40, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 50, 0, 0, 0)\n    conv2d_memcpy = DevicePythonNode('conv2d_memcpy', profiler.TracerEventType.Memcpy, 50, 60, 0, 0, 0)\n    sync_batch_norm_infer_shape = HostPythonNode('sync_batch_norm::infer_shape', profiler.TracerEventType.OperatorInner, 60, 70, 1000, 1001)\n    sync_batch_norm_compute = HostPythonNode('sync_batch_norm::compute', profiler.TracerEventType.OperatorInner, 80, 100, 1000, 1001)\n    sync_batch_norm_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 80, 90, 1000, 1001)\n    sync_batch_norm_MemCpy = HostPythonNode('AsyncMemcpy', profiler.TracerEventType.UserDefined, 90, 100, 1000, 1001)\n    sync_batch_norm_cudaMemCpy = HostPythonNode('cudaMemcpy', profiler.TracerEventType.CudaRuntime, 90, 100, 1000, 1001)\n    sync_batch_norm_kernel = DevicePythonNode('sync_batch_norm_kernel', profiler.TracerEventType.Kernel, 95, 300, 0, 0, 0)\n    sync_batch_norm_memcpy = DevicePythonNode('sync_batch_norm_memcpy', profiler.TracerEventType.Memcpy, 150, 200, 0, 0, 1)\n    allreduce_node2 = HostPythonNode('allreduce', profiler.TracerEventType.Operator, 230, 250, 1000, 1001)\n    allreduce_node2_infershape = HostPythonNode('allreduce_node2::infershape', profiler.TracerEventType.OperatorInner, 231, 232, 1000, 1001)\n    allreduce_launchkernel2 = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 235, 240, 1000, 1001)\n    nccl_allreduce_kernel2 = DevicePythonNode('nccl_allreduce_kernel', profiler.TracerEventType.Kernel, 250, 280, 0, 0, 2)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, yolonet_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    yolonet_node.children_node.extend([sync_batch_norm_node, userdefined_node])\n    userdefined_node.children_node.append(communication_node)\n    userdefined_node.runtime_node.append(allreduce_launchkernel0)\n    allreduce_launchkernel0.device_node.append(nccl_allreduce_kernel0)\n    communication_node.children_node.append(allreduce_op1)\n    allreduce_op1.children_node.append(allreduce_op1_infershape)\n    allreduce_op1.runtime_node.append(allreduce_launchkernel1)\n    allreduce_launchkernel1.device_node.append(nccl_allreduce_kernel1)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute, conv2d_MemCpy])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_MemCpy.runtime_node.append(conv2d_cudaMemCpy)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_cudaMemCpy.device_node.append(conv2d_memcpy)\n    sync_batch_norm_node.children_node.extend([sync_batch_norm_infer_shape, sync_batch_norm_compute, sync_batch_norm_MemCpy])\n    sync_batch_norm_compute.runtime_node.append(sync_batch_norm_launchkernel)\n    sync_batch_norm_MemCpy.runtime_node.append(sync_batch_norm_cudaMemCpy)\n    sync_batch_norm_launchkernel.device_node.append(sync_batch_norm_kernel)\n    sync_batch_norm_cudaMemCpy.device_node.append(sync_batch_norm_memcpy)\n    optimization_node.children_node.append(allreduce_node2)\n    allreduce_node2.children_node.append(allreduce_node2_infershape)\n    allreduce_node2.runtime_node.append(allreduce_launchkernel2)\n    allreduce_launchkernel2.device_node.append(nccl_allreduce_kernel2)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    distributed_summary = statistic_data.distributed_summary\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.ProfileStep), 400)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Forward), 90)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Backward), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Optimization), 80)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Operator), 78)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.OperatorInner), 47)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.CudaRuntime), 38)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Kernel), 220)\n    self.assertEqual(time_range_summary.get_gpu_range_sum(0, profiler.TracerEventType.Memcpy), 60)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.UserDefined), 15)\n    self.assertEqual(time_range_summary.get_cpu_range_sum(profiler.TracerEventType.Communication), 5)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.cpu_communication_range), 25)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.gpu_communication_range), 65)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.communication_range), 85)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.computation_range), 220)\n    self.assertEqual(profiler.statistic_helper.sum_ranges(distributed_summary.overlap_range), 85)\n    self.assertEqual(len(event_summary.items), 4)\n    self.assertEqual(len(event_summary.userdefined_items), 1)\n    self.assertEqual(len(event_summary.model_perspective_items), 5)\n    self.assertEqual(len(event_summary.memory_manipulation_items), 1)\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 15)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 25)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].cpu_time, 90)\n    self.assertEqual(event_summary.model_perspective_items['Forward'].general_gpu_time, 315)\n    self.assertEqual(event_summary.model_perspective_items['Backward'].general_gpu_time, 0)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].cpu_time, 15)\n    self.assertEqual(event_summary.memory_manipulation_items['AsyncMemcpy'].general_gpu_time, 60)\n    print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=profiler.SortedKeys.CPUTotal, op_detail=True, thread_sep=False, time_unit='ms'))"
        ]
    },
    {
        "func_name": "test_statistic_case3",
        "original": "def test_statistic_case3(self):\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 60, 70, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 25, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 25, 25, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    another_kernel = DevicePythonNode('void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::AddFunctor<float>, phi::funcs::AddFunctor<float>>()', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, userdefined_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_launchkernel.device_node.append(another_kernel)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 0)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 0)\n    self.assertEqual(event_summary.userdefined_items['Communication Time'].general_gpu_time, 0)\n    for sort_key in [profiler.SortedKeys.CPUTotal, profiler.SortedKeys.CPUMax, profiler.SortedKeys.CPUMin, profiler.SortedKeys.CPUAvg, profiler.SortedKeys.GPUTotal, profiler.SortedKeys.GPUMax, profiler.SortedKeys.GPUMin, profiler.SortedKeys.GPUAvg]:\n        print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=sort_key, op_detail=True, thread_sep=False, time_unit='ms'))",
        "mutated": [
            "def test_statistic_case3(self):\n    if False:\n        i = 10\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 60, 70, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 25, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 25, 25, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    another_kernel = DevicePythonNode('void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::AddFunctor<float>, phi::funcs::AddFunctor<float>>()', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, userdefined_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_launchkernel.device_node.append(another_kernel)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 0)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 0)\n    self.assertEqual(event_summary.userdefined_items['Communication Time'].general_gpu_time, 0)\n    for sort_key in [profiler.SortedKeys.CPUTotal, profiler.SortedKeys.CPUMax, profiler.SortedKeys.CPUMin, profiler.SortedKeys.CPUAvg, profiler.SortedKeys.GPUTotal, profiler.SortedKeys.GPUMax, profiler.SortedKeys.GPUMin, profiler.SortedKeys.GPUAvg]:\n        print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=sort_key, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case3(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 60, 70, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 25, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 25, 25, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    another_kernel = DevicePythonNode('void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::AddFunctor<float>, phi::funcs::AddFunctor<float>>()', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, userdefined_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_launchkernel.device_node.append(another_kernel)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 0)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 0)\n    self.assertEqual(event_summary.userdefined_items['Communication Time'].general_gpu_time, 0)\n    for sort_key in [profiler.SortedKeys.CPUTotal, profiler.SortedKeys.CPUMax, profiler.SortedKeys.CPUMin, profiler.SortedKeys.CPUAvg, profiler.SortedKeys.GPUTotal, profiler.SortedKeys.GPUMax, profiler.SortedKeys.GPUMin, profiler.SortedKeys.GPUAvg]:\n        print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=sort_key, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case3(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 60, 70, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 25, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 25, 25, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    another_kernel = DevicePythonNode('void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::AddFunctor<float>, phi::funcs::AddFunctor<float>>()', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, userdefined_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_launchkernel.device_node.append(another_kernel)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 0)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 0)\n    self.assertEqual(event_summary.userdefined_items['Communication Time'].general_gpu_time, 0)\n    for sort_key in [profiler.SortedKeys.CPUTotal, profiler.SortedKeys.CPUMax, profiler.SortedKeys.CPUMin, profiler.SortedKeys.CPUAvg, profiler.SortedKeys.GPUTotal, profiler.SortedKeys.GPUMax, profiler.SortedKeys.GPUMin, profiler.SortedKeys.GPUAvg]:\n        print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=sort_key, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case3(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 60, 70, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 25, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 25, 25, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    another_kernel = DevicePythonNode('void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::AddFunctor<float>, phi::funcs::AddFunctor<float>>()', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, userdefined_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_launchkernel.device_node.append(another_kernel)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 0)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 0)\n    self.assertEqual(event_summary.userdefined_items['Communication Time'].general_gpu_time, 0)\n    for sort_key in [profiler.SortedKeys.CPUTotal, profiler.SortedKeys.CPUMax, profiler.SortedKeys.CPUMin, profiler.SortedKeys.CPUAvg, profiler.SortedKeys.GPUTotal, profiler.SortedKeys.GPUMax, profiler.SortedKeys.GPUMin, profiler.SortedKeys.GPUAvg]:\n        print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=sort_key, op_detail=True, thread_sep=False, time_unit='ms'))",
            "def test_statistic_case3(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    root_node = HostPythonNode('Root Node', profiler.TracerEventType.UserDefined, 0, float('inf'), 1000, 1001)\n    profilerstep_node = HostPythonNode('ProfileStep#1', profiler.TracerEventType.ProfileStep, 0, 400, 1000, 1001)\n    dataloader_node = HostPythonNode('Dataloader', profiler.TracerEventType.Dataloader, 5, 15, 1000, 1001)\n    mobilenet_node = HostPythonNode('MobileNet', profiler.TracerEventType.Forward, 20, 50, 1000, 1001)\n    backward_node = HostPythonNode('Gradient Backward', profiler.TracerEventType.Backward, 120, 200, 1000, 1001)\n    optimization_node = HostPythonNode('Optimization', profiler.TracerEventType.Optimization, 220, 300, 1000, 1001)\n    userdefined_node = HostPythonNode('Communication Time', profiler.TracerEventType.PythonUserDefined, 60, 70, 1000, 1001)\n    conv2d_node = HostPythonNode('conv2d', profiler.TracerEventType.Operator, 25, 25, 1000, 1001)\n    conv2d_infer_shape = HostPythonNode('conv2d::infer_shape', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_compute = HostPythonNode('conv2d::compute', profiler.TracerEventType.OperatorInner, 25, 25, 1000, 1001)\n    conv2d_launchkernel = HostPythonNode('cudalaunchkernel', profiler.TracerEventType.CudaRuntime, 25, 25, 1000, 1001)\n    conv2d_kernel = DevicePythonNode('conv2d_kernel', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    another_kernel = DevicePythonNode('void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::AddFunctor<float>, phi::funcs::AddFunctor<float>>()', profiler.TracerEventType.Kernel, 35, 35, 0, 0, 0)\n    root_node.children_node.append(profilerstep_node)\n    profilerstep_node.children_node.extend([dataloader_node, mobilenet_node, userdefined_node, backward_node, optimization_node])\n    mobilenet_node.children_node.append(conv2d_node)\n    conv2d_node.children_node.extend([conv2d_infer_shape, conv2d_compute])\n    conv2d_compute.runtime_node.append(conv2d_launchkernel)\n    conv2d_launchkernel.device_node.append(conv2d_kernel)\n    conv2d_launchkernel.device_node.append(another_kernel)\n    thread_tree = {'thread1001': root_node}\n    extra_info = {'Process Cpu Utilization': '1.02', 'System Cpu Utilization': '0.68'}\n    statistic_data = profiler.profiler_statistic.StatisticData(thread_tree, extra_info)\n    time_range_summary = statistic_data.time_range_summary\n    event_summary = statistic_data.event_summary\n    self.assertEqual(event_summary.items['conv2d'].cpu_time, 0)\n    self.assertEqual(event_summary.items['conv2d'].general_gpu_time, 0)\n    self.assertEqual(event_summary.userdefined_items['Communication Time'].general_gpu_time, 0)\n    for sort_key in [profiler.SortedKeys.CPUTotal, profiler.SortedKeys.CPUMax, profiler.SortedKeys.CPUMin, profiler.SortedKeys.CPUAvg, profiler.SortedKeys.GPUTotal, profiler.SortedKeys.GPUMax, profiler.SortedKeys.GPUMin, profiler.SortedKeys.GPUAvg]:\n        print(profiler.profiler_statistic._build_table(statistic_data, sorted_by=sort_key, op_detail=True, thread_sep=False, time_unit='ms'))"
        ]
    }
]