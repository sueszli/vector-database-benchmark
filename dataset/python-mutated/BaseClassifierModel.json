[
    {
        "func_name": "train",
        "original": "def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:\n    \"\"\"\n        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\n        for storing, saving, loading, and analyzing the data.\n        :param unfiltered_df: Full dataframe for the current training period\n        :param metadata: pair metadata from strategy.\n        :return:\n        :model: Trained model which can be used to inference (self.predict)\n        \"\"\"\n    logger.info(f'-------------------- Starting training {pair} --------------------')\n    start_time = time()\n    (features_filtered, labels_filtered) = dk.filter_features(unfiltered_df, dk.training_features_list, dk.label_list, training_filter=True)\n    start_date = unfiltered_df['date'].iloc[0].strftime('%Y-%m-%d')\n    end_date = unfiltered_df['date'].iloc[-1].strftime('%Y-%m-%d')\n    logger.info(f'-------------------- Training on data from {start_date} to {end_date} --------------------')\n    dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n    if not self.freqai_info.get('fit_live_predictions_candles', 0) or not self.live:\n        dk.fit_labels()\n    dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n    (dd['train_features'], dd['train_labels'], dd['train_weights']) = dk.feature_pipeline.fit_transform(dd['train_features'], dd['train_labels'], dd['train_weights'])\n    if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n        (dd['test_features'], dd['test_labels'], dd['test_weights']) = dk.feature_pipeline.transform(dd['test_features'], dd['test_labels'], dd['test_weights'])\n    logger.info(f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\")\n    logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n    model = self.fit(dd, dk)\n    end_time = time()\n    logger.info(f'-------------------- Done training {pair} ({end_time - start_time:.2f} secs) --------------------')\n    return model",
        "mutated": [
            "def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:\n    if False:\n        i = 10\n    '\\n        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\\n        for storing, saving, loading, and analyzing the data.\\n        :param unfiltered_df: Full dataframe for the current training period\\n        :param metadata: pair metadata from strategy.\\n        :return:\\n        :model: Trained model which can be used to inference (self.predict)\\n        '\n    logger.info(f'-------------------- Starting training {pair} --------------------')\n    start_time = time()\n    (features_filtered, labels_filtered) = dk.filter_features(unfiltered_df, dk.training_features_list, dk.label_list, training_filter=True)\n    start_date = unfiltered_df['date'].iloc[0].strftime('%Y-%m-%d')\n    end_date = unfiltered_df['date'].iloc[-1].strftime('%Y-%m-%d')\n    logger.info(f'-------------------- Training on data from {start_date} to {end_date} --------------------')\n    dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n    if not self.freqai_info.get('fit_live_predictions_candles', 0) or not self.live:\n        dk.fit_labels()\n    dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n    (dd['train_features'], dd['train_labels'], dd['train_weights']) = dk.feature_pipeline.fit_transform(dd['train_features'], dd['train_labels'], dd['train_weights'])\n    if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n        (dd['test_features'], dd['test_labels'], dd['test_weights']) = dk.feature_pipeline.transform(dd['test_features'], dd['test_labels'], dd['test_weights'])\n    logger.info(f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\")\n    logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n    model = self.fit(dd, dk)\n    end_time = time()\n    logger.info(f'-------------------- Done training {pair} ({end_time - start_time:.2f} secs) --------------------')\n    return model",
            "def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\\n        for storing, saving, loading, and analyzing the data.\\n        :param unfiltered_df: Full dataframe for the current training period\\n        :param metadata: pair metadata from strategy.\\n        :return:\\n        :model: Trained model which can be used to inference (self.predict)\\n        '\n    logger.info(f'-------------------- Starting training {pair} --------------------')\n    start_time = time()\n    (features_filtered, labels_filtered) = dk.filter_features(unfiltered_df, dk.training_features_list, dk.label_list, training_filter=True)\n    start_date = unfiltered_df['date'].iloc[0].strftime('%Y-%m-%d')\n    end_date = unfiltered_df['date'].iloc[-1].strftime('%Y-%m-%d')\n    logger.info(f'-------------------- Training on data from {start_date} to {end_date} --------------------')\n    dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n    if not self.freqai_info.get('fit_live_predictions_candles', 0) or not self.live:\n        dk.fit_labels()\n    dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n    (dd['train_features'], dd['train_labels'], dd['train_weights']) = dk.feature_pipeline.fit_transform(dd['train_features'], dd['train_labels'], dd['train_weights'])\n    if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n        (dd['test_features'], dd['test_labels'], dd['test_weights']) = dk.feature_pipeline.transform(dd['test_features'], dd['test_labels'], dd['test_weights'])\n    logger.info(f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\")\n    logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n    model = self.fit(dd, dk)\n    end_time = time()\n    logger.info(f'-------------------- Done training {pair} ({end_time - start_time:.2f} secs) --------------------')\n    return model",
            "def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\\n        for storing, saving, loading, and analyzing the data.\\n        :param unfiltered_df: Full dataframe for the current training period\\n        :param metadata: pair metadata from strategy.\\n        :return:\\n        :model: Trained model which can be used to inference (self.predict)\\n        '\n    logger.info(f'-------------------- Starting training {pair} --------------------')\n    start_time = time()\n    (features_filtered, labels_filtered) = dk.filter_features(unfiltered_df, dk.training_features_list, dk.label_list, training_filter=True)\n    start_date = unfiltered_df['date'].iloc[0].strftime('%Y-%m-%d')\n    end_date = unfiltered_df['date'].iloc[-1].strftime('%Y-%m-%d')\n    logger.info(f'-------------------- Training on data from {start_date} to {end_date} --------------------')\n    dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n    if not self.freqai_info.get('fit_live_predictions_candles', 0) or not self.live:\n        dk.fit_labels()\n    dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n    (dd['train_features'], dd['train_labels'], dd['train_weights']) = dk.feature_pipeline.fit_transform(dd['train_features'], dd['train_labels'], dd['train_weights'])\n    if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n        (dd['test_features'], dd['test_labels'], dd['test_weights']) = dk.feature_pipeline.transform(dd['test_features'], dd['test_labels'], dd['test_weights'])\n    logger.info(f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\")\n    logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n    model = self.fit(dd, dk)\n    end_time = time()\n    logger.info(f'-------------------- Done training {pair} ({end_time - start_time:.2f} secs) --------------------')\n    return model",
            "def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\\n        for storing, saving, loading, and analyzing the data.\\n        :param unfiltered_df: Full dataframe for the current training period\\n        :param metadata: pair metadata from strategy.\\n        :return:\\n        :model: Trained model which can be used to inference (self.predict)\\n        '\n    logger.info(f'-------------------- Starting training {pair} --------------------')\n    start_time = time()\n    (features_filtered, labels_filtered) = dk.filter_features(unfiltered_df, dk.training_features_list, dk.label_list, training_filter=True)\n    start_date = unfiltered_df['date'].iloc[0].strftime('%Y-%m-%d')\n    end_date = unfiltered_df['date'].iloc[-1].strftime('%Y-%m-%d')\n    logger.info(f'-------------------- Training on data from {start_date} to {end_date} --------------------')\n    dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n    if not self.freqai_info.get('fit_live_predictions_candles', 0) or not self.live:\n        dk.fit_labels()\n    dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n    (dd['train_features'], dd['train_labels'], dd['train_weights']) = dk.feature_pipeline.fit_transform(dd['train_features'], dd['train_labels'], dd['train_weights'])\n    if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n        (dd['test_features'], dd['test_labels'], dd['test_weights']) = dk.feature_pipeline.transform(dd['test_features'], dd['test_labels'], dd['test_weights'])\n    logger.info(f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\")\n    logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n    model = self.fit(dd, dk)\n    end_time = time()\n    logger.info(f'-------------------- Done training {pair} ({end_time - start_time:.2f} secs) --------------------')\n    return model",
            "def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\\n        for storing, saving, loading, and analyzing the data.\\n        :param unfiltered_df: Full dataframe for the current training period\\n        :param metadata: pair metadata from strategy.\\n        :return:\\n        :model: Trained model which can be used to inference (self.predict)\\n        '\n    logger.info(f'-------------------- Starting training {pair} --------------------')\n    start_time = time()\n    (features_filtered, labels_filtered) = dk.filter_features(unfiltered_df, dk.training_features_list, dk.label_list, training_filter=True)\n    start_date = unfiltered_df['date'].iloc[0].strftime('%Y-%m-%d')\n    end_date = unfiltered_df['date'].iloc[-1].strftime('%Y-%m-%d')\n    logger.info(f'-------------------- Training on data from {start_date} to {end_date} --------------------')\n    dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n    if not self.freqai_info.get('fit_live_predictions_candles', 0) or not self.live:\n        dk.fit_labels()\n    dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n    (dd['train_features'], dd['train_labels'], dd['train_weights']) = dk.feature_pipeline.fit_transform(dd['train_features'], dd['train_labels'], dd['train_weights'])\n    if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n        (dd['test_features'], dd['test_labels'], dd['test_weights']) = dk.feature_pipeline.transform(dd['test_features'], dd['test_labels'], dd['test_weights'])\n    logger.info(f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\")\n    logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n    model = self.fit(dd, dk)\n    end_time = time()\n    logger.info(f'-------------------- Done training {pair} ({end_time - start_time:.2f} secs) --------------------')\n    return model"
        ]
    },
    {
        "func_name": "predict",
        "original": "def predict(self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n    \"\"\"\n        Filter the prediction features data and predict with it.\n        :param unfiltered_df: Full dataframe for the current backtest period.\n        :return:\n        :pred_df: dataframe containing the predictions\n        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\n        data (NaNs) or felt uncertain about data (PCA and DI index)\n        \"\"\"\n    dk.find_features(unfiltered_df)\n    (filtered_df, _) = dk.filter_features(unfiltered_df, dk.training_features_list, training_filter=False)\n    dk.data_dictionary['prediction_features'] = filtered_df\n    (dk.data_dictionary['prediction_features'], outliers, _) = dk.feature_pipeline.transform(dk.data_dictionary['prediction_features'], outlier_check=True)\n    predictions = self.model.predict(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions = np.reshape(predictions, (-1, len(dk.label_list)))\n    pred_df = DataFrame(predictions, columns=dk.label_list)\n    predictions_prob = self.model.predict_proba(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))\n    pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)\n    pred_df = pd.concat([pred_df, pred_df_prob], axis=1)\n    if dk.feature_pipeline['di']:\n        dk.DI_values = dk.feature_pipeline['di'].di_values\n    else:\n        dk.DI_values = np.zeros(outliers.shape[0])\n    dk.do_predict = outliers\n    return (pred_df, dk.do_predict)",
        "mutated": [
            "def predict(self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n    if False:\n        i = 10\n    '\\n        Filter the prediction features data and predict with it.\\n        :param unfiltered_df: Full dataframe for the current backtest period.\\n        :return:\\n        :pred_df: dataframe containing the predictions\\n        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\\n        data (NaNs) or felt uncertain about data (PCA and DI index)\\n        '\n    dk.find_features(unfiltered_df)\n    (filtered_df, _) = dk.filter_features(unfiltered_df, dk.training_features_list, training_filter=False)\n    dk.data_dictionary['prediction_features'] = filtered_df\n    (dk.data_dictionary['prediction_features'], outliers, _) = dk.feature_pipeline.transform(dk.data_dictionary['prediction_features'], outlier_check=True)\n    predictions = self.model.predict(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions = np.reshape(predictions, (-1, len(dk.label_list)))\n    pred_df = DataFrame(predictions, columns=dk.label_list)\n    predictions_prob = self.model.predict_proba(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))\n    pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)\n    pred_df = pd.concat([pred_df, pred_df_prob], axis=1)\n    if dk.feature_pipeline['di']:\n        dk.DI_values = dk.feature_pipeline['di'].di_values\n    else:\n        dk.DI_values = np.zeros(outliers.shape[0])\n    dk.do_predict = outliers\n    return (pred_df, dk.do_predict)",
            "def predict(self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Filter the prediction features data and predict with it.\\n        :param unfiltered_df: Full dataframe for the current backtest period.\\n        :return:\\n        :pred_df: dataframe containing the predictions\\n        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\\n        data (NaNs) or felt uncertain about data (PCA and DI index)\\n        '\n    dk.find_features(unfiltered_df)\n    (filtered_df, _) = dk.filter_features(unfiltered_df, dk.training_features_list, training_filter=False)\n    dk.data_dictionary['prediction_features'] = filtered_df\n    (dk.data_dictionary['prediction_features'], outliers, _) = dk.feature_pipeline.transform(dk.data_dictionary['prediction_features'], outlier_check=True)\n    predictions = self.model.predict(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions = np.reshape(predictions, (-1, len(dk.label_list)))\n    pred_df = DataFrame(predictions, columns=dk.label_list)\n    predictions_prob = self.model.predict_proba(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))\n    pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)\n    pred_df = pd.concat([pred_df, pred_df_prob], axis=1)\n    if dk.feature_pipeline['di']:\n        dk.DI_values = dk.feature_pipeline['di'].di_values\n    else:\n        dk.DI_values = np.zeros(outliers.shape[0])\n    dk.do_predict = outliers\n    return (pred_df, dk.do_predict)",
            "def predict(self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Filter the prediction features data and predict with it.\\n        :param unfiltered_df: Full dataframe for the current backtest period.\\n        :return:\\n        :pred_df: dataframe containing the predictions\\n        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\\n        data (NaNs) or felt uncertain about data (PCA and DI index)\\n        '\n    dk.find_features(unfiltered_df)\n    (filtered_df, _) = dk.filter_features(unfiltered_df, dk.training_features_list, training_filter=False)\n    dk.data_dictionary['prediction_features'] = filtered_df\n    (dk.data_dictionary['prediction_features'], outliers, _) = dk.feature_pipeline.transform(dk.data_dictionary['prediction_features'], outlier_check=True)\n    predictions = self.model.predict(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions = np.reshape(predictions, (-1, len(dk.label_list)))\n    pred_df = DataFrame(predictions, columns=dk.label_list)\n    predictions_prob = self.model.predict_proba(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))\n    pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)\n    pred_df = pd.concat([pred_df, pred_df_prob], axis=1)\n    if dk.feature_pipeline['di']:\n        dk.DI_values = dk.feature_pipeline['di'].di_values\n    else:\n        dk.DI_values = np.zeros(outliers.shape[0])\n    dk.do_predict = outliers\n    return (pred_df, dk.do_predict)",
            "def predict(self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Filter the prediction features data and predict with it.\\n        :param unfiltered_df: Full dataframe for the current backtest period.\\n        :return:\\n        :pred_df: dataframe containing the predictions\\n        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\\n        data (NaNs) or felt uncertain about data (PCA and DI index)\\n        '\n    dk.find_features(unfiltered_df)\n    (filtered_df, _) = dk.filter_features(unfiltered_df, dk.training_features_list, training_filter=False)\n    dk.data_dictionary['prediction_features'] = filtered_df\n    (dk.data_dictionary['prediction_features'], outliers, _) = dk.feature_pipeline.transform(dk.data_dictionary['prediction_features'], outlier_check=True)\n    predictions = self.model.predict(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions = np.reshape(predictions, (-1, len(dk.label_list)))\n    pred_df = DataFrame(predictions, columns=dk.label_list)\n    predictions_prob = self.model.predict_proba(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))\n    pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)\n    pred_df = pd.concat([pred_df, pred_df_prob], axis=1)\n    if dk.feature_pipeline['di']:\n        dk.DI_values = dk.feature_pipeline['di'].di_values\n    else:\n        dk.DI_values = np.zeros(outliers.shape[0])\n    dk.do_predict = outliers\n    return (pred_df, dk.do_predict)",
            "def predict(self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Filter the prediction features data and predict with it.\\n        :param unfiltered_df: Full dataframe for the current backtest period.\\n        :return:\\n        :pred_df: dataframe containing the predictions\\n        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\\n        data (NaNs) or felt uncertain about data (PCA and DI index)\\n        '\n    dk.find_features(unfiltered_df)\n    (filtered_df, _) = dk.filter_features(unfiltered_df, dk.training_features_list, training_filter=False)\n    dk.data_dictionary['prediction_features'] = filtered_df\n    (dk.data_dictionary['prediction_features'], outliers, _) = dk.feature_pipeline.transform(dk.data_dictionary['prediction_features'], outlier_check=True)\n    predictions = self.model.predict(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions = np.reshape(predictions, (-1, len(dk.label_list)))\n    pred_df = DataFrame(predictions, columns=dk.label_list)\n    predictions_prob = self.model.predict_proba(dk.data_dictionary['prediction_features'])\n    if self.CONV_WIDTH == 1:\n        predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))\n    pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)\n    pred_df = pd.concat([pred_df, pred_df_prob], axis=1)\n    if dk.feature_pipeline['di']:\n        dk.DI_values = dk.feature_pipeline['di'].di_values\n    else:\n        dk.DI_values = np.zeros(outliers.shape[0])\n    dk.do_predict = outliers\n    return (pred_df, dk.do_predict)"
        ]
    }
]