[
    {
        "func_name": "print_confusion",
        "original": "def print_confusion(label, confusions, do_mal):\n    row_labels = ['Non-Nodules', 'Benign', 'Malignant']\n    if do_mal:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Benign', 'Pred. Malignant']\n    else:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Nodule']\n        confusions[:, -2] += confusions[:, -1]\n        confusions = confusions[:, :-1]\n    cell_width = 16\n    f = '{:>' + str(cell_width) + '}'\n    print(label)\n    print(' | '.join([f.format(s) for s in col_labels]))\n    for (i, (l, r)) in enumerate(zip(row_labels, confusions)):\n        r = [l] + list(r)\n        if i == 0:\n            r[1] = ''\n        print(' | '.join([f.format(i) for i in r]))",
        "mutated": [
            "def print_confusion(label, confusions, do_mal):\n    if False:\n        i = 10\n    row_labels = ['Non-Nodules', 'Benign', 'Malignant']\n    if do_mal:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Benign', 'Pred. Malignant']\n    else:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Nodule']\n        confusions[:, -2] += confusions[:, -1]\n        confusions = confusions[:, :-1]\n    cell_width = 16\n    f = '{:>' + str(cell_width) + '}'\n    print(label)\n    print(' | '.join([f.format(s) for s in col_labels]))\n    for (i, (l, r)) in enumerate(zip(row_labels, confusions)):\n        r = [l] + list(r)\n        if i == 0:\n            r[1] = ''\n        print(' | '.join([f.format(i) for i in r]))",
            "def print_confusion(label, confusions, do_mal):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    row_labels = ['Non-Nodules', 'Benign', 'Malignant']\n    if do_mal:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Benign', 'Pred. Malignant']\n    else:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Nodule']\n        confusions[:, -2] += confusions[:, -1]\n        confusions = confusions[:, :-1]\n    cell_width = 16\n    f = '{:>' + str(cell_width) + '}'\n    print(label)\n    print(' | '.join([f.format(s) for s in col_labels]))\n    for (i, (l, r)) in enumerate(zip(row_labels, confusions)):\n        r = [l] + list(r)\n        if i == 0:\n            r[1] = ''\n        print(' | '.join([f.format(i) for i in r]))",
            "def print_confusion(label, confusions, do_mal):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    row_labels = ['Non-Nodules', 'Benign', 'Malignant']\n    if do_mal:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Benign', 'Pred. Malignant']\n    else:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Nodule']\n        confusions[:, -2] += confusions[:, -1]\n        confusions = confusions[:, :-1]\n    cell_width = 16\n    f = '{:>' + str(cell_width) + '}'\n    print(label)\n    print(' | '.join([f.format(s) for s in col_labels]))\n    for (i, (l, r)) in enumerate(zip(row_labels, confusions)):\n        r = [l] + list(r)\n        if i == 0:\n            r[1] = ''\n        print(' | '.join([f.format(i) for i in r]))",
            "def print_confusion(label, confusions, do_mal):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    row_labels = ['Non-Nodules', 'Benign', 'Malignant']\n    if do_mal:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Benign', 'Pred. Malignant']\n    else:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Nodule']\n        confusions[:, -2] += confusions[:, -1]\n        confusions = confusions[:, :-1]\n    cell_width = 16\n    f = '{:>' + str(cell_width) + '}'\n    print(label)\n    print(' | '.join([f.format(s) for s in col_labels]))\n    for (i, (l, r)) in enumerate(zip(row_labels, confusions)):\n        r = [l] + list(r)\n        if i == 0:\n            r[1] = ''\n        print(' | '.join([f.format(i) for i in r]))",
            "def print_confusion(label, confusions, do_mal):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    row_labels = ['Non-Nodules', 'Benign', 'Malignant']\n    if do_mal:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Benign', 'Pred. Malignant']\n    else:\n        col_labels = ['', 'Complete Miss', 'Filtered Out', 'Pred. Nodule']\n        confusions[:, -2] += confusions[:, -1]\n        confusions = confusions[:, :-1]\n    cell_width = 16\n    f = '{:>' + str(cell_width) + '}'\n    print(label)\n    print(' | '.join([f.format(s) for s in col_labels]))\n    for (i, (l, r)) in enumerate(zip(row_labels, confusions)):\n        r = [l] + list(r)\n        if i == 0:\n            r[1] = ''\n        print(' | '.join([f.format(i) for i in r]))"
        ]
    },
    {
        "func_name": "match_and_score",
        "original": "def match_and_score(detections, truth, threshold=0.5, threshold_mal=0.5):\n    true_nodules = [c for c in truth if c.isNodule_bool]\n    truth_diams = np.array([c.diameter_mm for c in true_nodules])\n    truth_xyz = np.array([c.center_xyz for c in true_nodules])\n    detected_xyz = np.array([n[2] for n in detections])\n    detected_classes = np.array([1 if d[0] < threshold else 2 if d[1] < threshold else 3 for d in detections])\n    confusion = np.zeros((3, 4), dtype=np.int)\n    if len(detected_xyz) == 0:\n        for tn in true_nodules:\n            confusion[2 if tn.isMal_bool else 1, 0] += 1\n    elif len(truth_xyz) == 0:\n        for dc in detected_classes:\n            confusion[0, dc] += 1\n    else:\n        normalized_dists = np.linalg.norm(truth_xyz[:, None] - detected_xyz[None], ord=2, axis=-1) / truth_diams[:, None]\n        matches = normalized_dists < 0.7\n        unmatched_detections = np.ones(len(detections), dtype=np.bool)\n        matched_true_nodules = np.zeros(len(true_nodules), dtype=np.int)\n        for (i_tn, i_detection) in zip(*matches.nonzero()):\n            matched_true_nodules[i_tn] = max(matched_true_nodules[i_tn], detected_classes[i_detection])\n            unmatched_detections[i_detection] = False\n        for (ud, dc) in zip(unmatched_detections, detected_classes):\n            if ud:\n                confusion[0, dc] += 1\n        for (tn, dc) in zip(true_nodules, matched_true_nodules):\n            confusion[2 if tn.isMal_bool else 1, dc] += 1\n    return confusion",
        "mutated": [
            "def match_and_score(detections, truth, threshold=0.5, threshold_mal=0.5):\n    if False:\n        i = 10\n    true_nodules = [c for c in truth if c.isNodule_bool]\n    truth_diams = np.array([c.diameter_mm for c in true_nodules])\n    truth_xyz = np.array([c.center_xyz for c in true_nodules])\n    detected_xyz = np.array([n[2] for n in detections])\n    detected_classes = np.array([1 if d[0] < threshold else 2 if d[1] < threshold else 3 for d in detections])\n    confusion = np.zeros((3, 4), dtype=np.int)\n    if len(detected_xyz) == 0:\n        for tn in true_nodules:\n            confusion[2 if tn.isMal_bool else 1, 0] += 1\n    elif len(truth_xyz) == 0:\n        for dc in detected_classes:\n            confusion[0, dc] += 1\n    else:\n        normalized_dists = np.linalg.norm(truth_xyz[:, None] - detected_xyz[None], ord=2, axis=-1) / truth_diams[:, None]\n        matches = normalized_dists < 0.7\n        unmatched_detections = np.ones(len(detections), dtype=np.bool)\n        matched_true_nodules = np.zeros(len(true_nodules), dtype=np.int)\n        for (i_tn, i_detection) in zip(*matches.nonzero()):\n            matched_true_nodules[i_tn] = max(matched_true_nodules[i_tn], detected_classes[i_detection])\n            unmatched_detections[i_detection] = False\n        for (ud, dc) in zip(unmatched_detections, detected_classes):\n            if ud:\n                confusion[0, dc] += 1\n        for (tn, dc) in zip(true_nodules, matched_true_nodules):\n            confusion[2 if tn.isMal_bool else 1, dc] += 1\n    return confusion",
            "def match_and_score(detections, truth, threshold=0.5, threshold_mal=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    true_nodules = [c for c in truth if c.isNodule_bool]\n    truth_diams = np.array([c.diameter_mm for c in true_nodules])\n    truth_xyz = np.array([c.center_xyz for c in true_nodules])\n    detected_xyz = np.array([n[2] for n in detections])\n    detected_classes = np.array([1 if d[0] < threshold else 2 if d[1] < threshold else 3 for d in detections])\n    confusion = np.zeros((3, 4), dtype=np.int)\n    if len(detected_xyz) == 0:\n        for tn in true_nodules:\n            confusion[2 if tn.isMal_bool else 1, 0] += 1\n    elif len(truth_xyz) == 0:\n        for dc in detected_classes:\n            confusion[0, dc] += 1\n    else:\n        normalized_dists = np.linalg.norm(truth_xyz[:, None] - detected_xyz[None], ord=2, axis=-1) / truth_diams[:, None]\n        matches = normalized_dists < 0.7\n        unmatched_detections = np.ones(len(detections), dtype=np.bool)\n        matched_true_nodules = np.zeros(len(true_nodules), dtype=np.int)\n        for (i_tn, i_detection) in zip(*matches.nonzero()):\n            matched_true_nodules[i_tn] = max(matched_true_nodules[i_tn], detected_classes[i_detection])\n            unmatched_detections[i_detection] = False\n        for (ud, dc) in zip(unmatched_detections, detected_classes):\n            if ud:\n                confusion[0, dc] += 1\n        for (tn, dc) in zip(true_nodules, matched_true_nodules):\n            confusion[2 if tn.isMal_bool else 1, dc] += 1\n    return confusion",
            "def match_and_score(detections, truth, threshold=0.5, threshold_mal=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    true_nodules = [c for c in truth if c.isNodule_bool]\n    truth_diams = np.array([c.diameter_mm for c in true_nodules])\n    truth_xyz = np.array([c.center_xyz for c in true_nodules])\n    detected_xyz = np.array([n[2] for n in detections])\n    detected_classes = np.array([1 if d[0] < threshold else 2 if d[1] < threshold else 3 for d in detections])\n    confusion = np.zeros((3, 4), dtype=np.int)\n    if len(detected_xyz) == 0:\n        for tn in true_nodules:\n            confusion[2 if tn.isMal_bool else 1, 0] += 1\n    elif len(truth_xyz) == 0:\n        for dc in detected_classes:\n            confusion[0, dc] += 1\n    else:\n        normalized_dists = np.linalg.norm(truth_xyz[:, None] - detected_xyz[None], ord=2, axis=-1) / truth_diams[:, None]\n        matches = normalized_dists < 0.7\n        unmatched_detections = np.ones(len(detections), dtype=np.bool)\n        matched_true_nodules = np.zeros(len(true_nodules), dtype=np.int)\n        for (i_tn, i_detection) in zip(*matches.nonzero()):\n            matched_true_nodules[i_tn] = max(matched_true_nodules[i_tn], detected_classes[i_detection])\n            unmatched_detections[i_detection] = False\n        for (ud, dc) in zip(unmatched_detections, detected_classes):\n            if ud:\n                confusion[0, dc] += 1\n        for (tn, dc) in zip(true_nodules, matched_true_nodules):\n            confusion[2 if tn.isMal_bool else 1, dc] += 1\n    return confusion",
            "def match_and_score(detections, truth, threshold=0.5, threshold_mal=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    true_nodules = [c for c in truth if c.isNodule_bool]\n    truth_diams = np.array([c.diameter_mm for c in true_nodules])\n    truth_xyz = np.array([c.center_xyz for c in true_nodules])\n    detected_xyz = np.array([n[2] for n in detections])\n    detected_classes = np.array([1 if d[0] < threshold else 2 if d[1] < threshold else 3 for d in detections])\n    confusion = np.zeros((3, 4), dtype=np.int)\n    if len(detected_xyz) == 0:\n        for tn in true_nodules:\n            confusion[2 if tn.isMal_bool else 1, 0] += 1\n    elif len(truth_xyz) == 0:\n        for dc in detected_classes:\n            confusion[0, dc] += 1\n    else:\n        normalized_dists = np.linalg.norm(truth_xyz[:, None] - detected_xyz[None], ord=2, axis=-1) / truth_diams[:, None]\n        matches = normalized_dists < 0.7\n        unmatched_detections = np.ones(len(detections), dtype=np.bool)\n        matched_true_nodules = np.zeros(len(true_nodules), dtype=np.int)\n        for (i_tn, i_detection) in zip(*matches.nonzero()):\n            matched_true_nodules[i_tn] = max(matched_true_nodules[i_tn], detected_classes[i_detection])\n            unmatched_detections[i_detection] = False\n        for (ud, dc) in zip(unmatched_detections, detected_classes):\n            if ud:\n                confusion[0, dc] += 1\n        for (tn, dc) in zip(true_nodules, matched_true_nodules):\n            confusion[2 if tn.isMal_bool else 1, dc] += 1\n    return confusion",
            "def match_and_score(detections, truth, threshold=0.5, threshold_mal=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    true_nodules = [c for c in truth if c.isNodule_bool]\n    truth_diams = np.array([c.diameter_mm for c in true_nodules])\n    truth_xyz = np.array([c.center_xyz for c in true_nodules])\n    detected_xyz = np.array([n[2] for n in detections])\n    detected_classes = np.array([1 if d[0] < threshold else 2 if d[1] < threshold else 3 for d in detections])\n    confusion = np.zeros((3, 4), dtype=np.int)\n    if len(detected_xyz) == 0:\n        for tn in true_nodules:\n            confusion[2 if tn.isMal_bool else 1, 0] += 1\n    elif len(truth_xyz) == 0:\n        for dc in detected_classes:\n            confusion[0, dc] += 1\n    else:\n        normalized_dists = np.linalg.norm(truth_xyz[:, None] - detected_xyz[None], ord=2, axis=-1) / truth_diams[:, None]\n        matches = normalized_dists < 0.7\n        unmatched_detections = np.ones(len(detections), dtype=np.bool)\n        matched_true_nodules = np.zeros(len(true_nodules), dtype=np.int)\n        for (i_tn, i_detection) in zip(*matches.nonzero()):\n            matched_true_nodules[i_tn] = max(matched_true_nodules[i_tn], detected_classes[i_detection])\n            unmatched_detections[i_detection] = False\n        for (ud, dc) in zip(unmatched_detections, detected_classes):\n            if ud:\n                confusion[0, dc] += 1\n        for (tn, dc) in zip(true_nodules, matched_true_nodules):\n            confusion[2 if tn.isMal_bool else 1, dc] += 1\n    return confusion"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, sys_argv=None):\n    if sys_argv is None:\n        log.debug(sys.argv)\n        sys_argv = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', help='Batch size to use for training', default=4, type=int)\n    parser.add_argument('--num-workers', help='Number of worker processes for background data loading', default=4, type=int)\n    parser.add_argument('--run-validation', help='Run over validation rather than a single CT.', action='store_true', default=False)\n    parser.add_argument('--include-train', help='Include data that was in the training set. (default: validation data only)', action='store_true', default=False)\n    parser.add_argument('--segmentation-path', help='Path to the saved segmentation model', nargs='?', default='data/part2/models/seg_2020-01-26_19.45.12_w4d3c1-bal_1_nodupe-label_pos-d1_fn8-adam.best.state')\n    parser.add_argument('--cls-model', help='What to model class name to use for the classifier.', action='store', default='LunaModel')\n    parser.add_argument('--classification-path', help='Path to the saved classification model', nargs='?', default='data/part2/models/cls_2020-02-06_14.16.55_final-nodule-nonnodule.best.state')\n    parser.add_argument('--malignancy-model', help='What to model class name to use for the malignancy classifier.', action='store', default='LunaModel')\n    parser.add_argument('--malignancy-path', help='Path to the saved malignancy classification model', nargs='?', default=None)\n    parser.add_argument('--tb-prefix', default='p2ch14', help='Data prefix to use for Tensorboard run. Defaults to chapter.')\n    parser.add_argument('series_uid', nargs='?', default=None, help='Series UID to use.')\n    self.cli_args = parser.parse_args(sys_argv)\n    if not bool(self.cli_args.series_uid) ^ self.cli_args.run_validation:\n        raise Exception('One and only one of series_uid and --run-validation should be given')\n    self.use_cuda = torch.cuda.is_available()\n    self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n    if not self.cli_args.segmentation_path:\n        self.cli_args.segmentation_path = self.initModelPath('seg')\n    if not self.cli_args.classification_path:\n        self.cli_args.classification_path = self.initModelPath('cls')\n    (self.seg_model, self.cls_model, self.malignancy_model) = self.initModels()",
        "mutated": [
            "def __init__(self, sys_argv=None):\n    if False:\n        i = 10\n    if sys_argv is None:\n        log.debug(sys.argv)\n        sys_argv = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', help='Batch size to use for training', default=4, type=int)\n    parser.add_argument('--num-workers', help='Number of worker processes for background data loading', default=4, type=int)\n    parser.add_argument('--run-validation', help='Run over validation rather than a single CT.', action='store_true', default=False)\n    parser.add_argument('--include-train', help='Include data that was in the training set. (default: validation data only)', action='store_true', default=False)\n    parser.add_argument('--segmentation-path', help='Path to the saved segmentation model', nargs='?', default='data/part2/models/seg_2020-01-26_19.45.12_w4d3c1-bal_1_nodupe-label_pos-d1_fn8-adam.best.state')\n    parser.add_argument('--cls-model', help='What to model class name to use for the classifier.', action='store', default='LunaModel')\n    parser.add_argument('--classification-path', help='Path to the saved classification model', nargs='?', default='data/part2/models/cls_2020-02-06_14.16.55_final-nodule-nonnodule.best.state')\n    parser.add_argument('--malignancy-model', help='What to model class name to use for the malignancy classifier.', action='store', default='LunaModel')\n    parser.add_argument('--malignancy-path', help='Path to the saved malignancy classification model', nargs='?', default=None)\n    parser.add_argument('--tb-prefix', default='p2ch14', help='Data prefix to use for Tensorboard run. Defaults to chapter.')\n    parser.add_argument('series_uid', nargs='?', default=None, help='Series UID to use.')\n    self.cli_args = parser.parse_args(sys_argv)\n    if not bool(self.cli_args.series_uid) ^ self.cli_args.run_validation:\n        raise Exception('One and only one of series_uid and --run-validation should be given')\n    self.use_cuda = torch.cuda.is_available()\n    self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n    if not self.cli_args.segmentation_path:\n        self.cli_args.segmentation_path = self.initModelPath('seg')\n    if not self.cli_args.classification_path:\n        self.cli_args.classification_path = self.initModelPath('cls')\n    (self.seg_model, self.cls_model, self.malignancy_model) = self.initModels()",
            "def __init__(self, sys_argv=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if sys_argv is None:\n        log.debug(sys.argv)\n        sys_argv = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', help='Batch size to use for training', default=4, type=int)\n    parser.add_argument('--num-workers', help='Number of worker processes for background data loading', default=4, type=int)\n    parser.add_argument('--run-validation', help='Run over validation rather than a single CT.', action='store_true', default=False)\n    parser.add_argument('--include-train', help='Include data that was in the training set. (default: validation data only)', action='store_true', default=False)\n    parser.add_argument('--segmentation-path', help='Path to the saved segmentation model', nargs='?', default='data/part2/models/seg_2020-01-26_19.45.12_w4d3c1-bal_1_nodupe-label_pos-d1_fn8-adam.best.state')\n    parser.add_argument('--cls-model', help='What to model class name to use for the classifier.', action='store', default='LunaModel')\n    parser.add_argument('--classification-path', help='Path to the saved classification model', nargs='?', default='data/part2/models/cls_2020-02-06_14.16.55_final-nodule-nonnodule.best.state')\n    parser.add_argument('--malignancy-model', help='What to model class name to use for the malignancy classifier.', action='store', default='LunaModel')\n    parser.add_argument('--malignancy-path', help='Path to the saved malignancy classification model', nargs='?', default=None)\n    parser.add_argument('--tb-prefix', default='p2ch14', help='Data prefix to use for Tensorboard run. Defaults to chapter.')\n    parser.add_argument('series_uid', nargs='?', default=None, help='Series UID to use.')\n    self.cli_args = parser.parse_args(sys_argv)\n    if not bool(self.cli_args.series_uid) ^ self.cli_args.run_validation:\n        raise Exception('One and only one of series_uid and --run-validation should be given')\n    self.use_cuda = torch.cuda.is_available()\n    self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n    if not self.cli_args.segmentation_path:\n        self.cli_args.segmentation_path = self.initModelPath('seg')\n    if not self.cli_args.classification_path:\n        self.cli_args.classification_path = self.initModelPath('cls')\n    (self.seg_model, self.cls_model, self.malignancy_model) = self.initModels()",
            "def __init__(self, sys_argv=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if sys_argv is None:\n        log.debug(sys.argv)\n        sys_argv = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', help='Batch size to use for training', default=4, type=int)\n    parser.add_argument('--num-workers', help='Number of worker processes for background data loading', default=4, type=int)\n    parser.add_argument('--run-validation', help='Run over validation rather than a single CT.', action='store_true', default=False)\n    parser.add_argument('--include-train', help='Include data that was in the training set. (default: validation data only)', action='store_true', default=False)\n    parser.add_argument('--segmentation-path', help='Path to the saved segmentation model', nargs='?', default='data/part2/models/seg_2020-01-26_19.45.12_w4d3c1-bal_1_nodupe-label_pos-d1_fn8-adam.best.state')\n    parser.add_argument('--cls-model', help='What to model class name to use for the classifier.', action='store', default='LunaModel')\n    parser.add_argument('--classification-path', help='Path to the saved classification model', nargs='?', default='data/part2/models/cls_2020-02-06_14.16.55_final-nodule-nonnodule.best.state')\n    parser.add_argument('--malignancy-model', help='What to model class name to use for the malignancy classifier.', action='store', default='LunaModel')\n    parser.add_argument('--malignancy-path', help='Path to the saved malignancy classification model', nargs='?', default=None)\n    parser.add_argument('--tb-prefix', default='p2ch14', help='Data prefix to use for Tensorboard run. Defaults to chapter.')\n    parser.add_argument('series_uid', nargs='?', default=None, help='Series UID to use.')\n    self.cli_args = parser.parse_args(sys_argv)\n    if not bool(self.cli_args.series_uid) ^ self.cli_args.run_validation:\n        raise Exception('One and only one of series_uid and --run-validation should be given')\n    self.use_cuda = torch.cuda.is_available()\n    self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n    if not self.cli_args.segmentation_path:\n        self.cli_args.segmentation_path = self.initModelPath('seg')\n    if not self.cli_args.classification_path:\n        self.cli_args.classification_path = self.initModelPath('cls')\n    (self.seg_model, self.cls_model, self.malignancy_model) = self.initModels()",
            "def __init__(self, sys_argv=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if sys_argv is None:\n        log.debug(sys.argv)\n        sys_argv = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', help='Batch size to use for training', default=4, type=int)\n    parser.add_argument('--num-workers', help='Number of worker processes for background data loading', default=4, type=int)\n    parser.add_argument('--run-validation', help='Run over validation rather than a single CT.', action='store_true', default=False)\n    parser.add_argument('--include-train', help='Include data that was in the training set. (default: validation data only)', action='store_true', default=False)\n    parser.add_argument('--segmentation-path', help='Path to the saved segmentation model', nargs='?', default='data/part2/models/seg_2020-01-26_19.45.12_w4d3c1-bal_1_nodupe-label_pos-d1_fn8-adam.best.state')\n    parser.add_argument('--cls-model', help='What to model class name to use for the classifier.', action='store', default='LunaModel')\n    parser.add_argument('--classification-path', help='Path to the saved classification model', nargs='?', default='data/part2/models/cls_2020-02-06_14.16.55_final-nodule-nonnodule.best.state')\n    parser.add_argument('--malignancy-model', help='What to model class name to use for the malignancy classifier.', action='store', default='LunaModel')\n    parser.add_argument('--malignancy-path', help='Path to the saved malignancy classification model', nargs='?', default=None)\n    parser.add_argument('--tb-prefix', default='p2ch14', help='Data prefix to use for Tensorboard run. Defaults to chapter.')\n    parser.add_argument('series_uid', nargs='?', default=None, help='Series UID to use.')\n    self.cli_args = parser.parse_args(sys_argv)\n    if not bool(self.cli_args.series_uid) ^ self.cli_args.run_validation:\n        raise Exception('One and only one of series_uid and --run-validation should be given')\n    self.use_cuda = torch.cuda.is_available()\n    self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n    if not self.cli_args.segmentation_path:\n        self.cli_args.segmentation_path = self.initModelPath('seg')\n    if not self.cli_args.classification_path:\n        self.cli_args.classification_path = self.initModelPath('cls')\n    (self.seg_model, self.cls_model, self.malignancy_model) = self.initModels()",
            "def __init__(self, sys_argv=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if sys_argv is None:\n        log.debug(sys.argv)\n        sys_argv = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', help='Batch size to use for training', default=4, type=int)\n    parser.add_argument('--num-workers', help='Number of worker processes for background data loading', default=4, type=int)\n    parser.add_argument('--run-validation', help='Run over validation rather than a single CT.', action='store_true', default=False)\n    parser.add_argument('--include-train', help='Include data that was in the training set. (default: validation data only)', action='store_true', default=False)\n    parser.add_argument('--segmentation-path', help='Path to the saved segmentation model', nargs='?', default='data/part2/models/seg_2020-01-26_19.45.12_w4d3c1-bal_1_nodupe-label_pos-d1_fn8-adam.best.state')\n    parser.add_argument('--cls-model', help='What to model class name to use for the classifier.', action='store', default='LunaModel')\n    parser.add_argument('--classification-path', help='Path to the saved classification model', nargs='?', default='data/part2/models/cls_2020-02-06_14.16.55_final-nodule-nonnodule.best.state')\n    parser.add_argument('--malignancy-model', help='What to model class name to use for the malignancy classifier.', action='store', default='LunaModel')\n    parser.add_argument('--malignancy-path', help='Path to the saved malignancy classification model', nargs='?', default=None)\n    parser.add_argument('--tb-prefix', default='p2ch14', help='Data prefix to use for Tensorboard run. Defaults to chapter.')\n    parser.add_argument('series_uid', nargs='?', default=None, help='Series UID to use.')\n    self.cli_args = parser.parse_args(sys_argv)\n    if not bool(self.cli_args.series_uid) ^ self.cli_args.run_validation:\n        raise Exception('One and only one of series_uid and --run-validation should be given')\n    self.use_cuda = torch.cuda.is_available()\n    self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n    if not self.cli_args.segmentation_path:\n        self.cli_args.segmentation_path = self.initModelPath('seg')\n    if not self.cli_args.classification_path:\n        self.cli_args.classification_path = self.initModelPath('cls')\n    (self.seg_model, self.cls_model, self.malignancy_model) = self.initModels()"
        ]
    },
    {
        "func_name": "initModelPath",
        "original": "def initModelPath(self, type_str):\n    local_path = os.path.join('data-unversioned', 'part2', 'models', 'p2ch13', type_str + '_{}_{}.{}.state'.format('*', '*', 'best'))\n    file_list = glob.glob(local_path)\n    if not file_list:\n        pretrained_path = os.path.join('data', 'part2', 'models', type_str + '_{}_{}.{}.state'.format('*', '*', '*'))\n        file_list = glob.glob(pretrained_path)\n    else:\n        pretrained_path = None\n    file_list.sort()\n    try:\n        return file_list[-1]\n    except IndexError:\n        log.debug([local_path, pretrained_path, file_list])\n        raise",
        "mutated": [
            "def initModelPath(self, type_str):\n    if False:\n        i = 10\n    local_path = os.path.join('data-unversioned', 'part2', 'models', 'p2ch13', type_str + '_{}_{}.{}.state'.format('*', '*', 'best'))\n    file_list = glob.glob(local_path)\n    if not file_list:\n        pretrained_path = os.path.join('data', 'part2', 'models', type_str + '_{}_{}.{}.state'.format('*', '*', '*'))\n        file_list = glob.glob(pretrained_path)\n    else:\n        pretrained_path = None\n    file_list.sort()\n    try:\n        return file_list[-1]\n    except IndexError:\n        log.debug([local_path, pretrained_path, file_list])\n        raise",
            "def initModelPath(self, type_str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    local_path = os.path.join('data-unversioned', 'part2', 'models', 'p2ch13', type_str + '_{}_{}.{}.state'.format('*', '*', 'best'))\n    file_list = glob.glob(local_path)\n    if not file_list:\n        pretrained_path = os.path.join('data', 'part2', 'models', type_str + '_{}_{}.{}.state'.format('*', '*', '*'))\n        file_list = glob.glob(pretrained_path)\n    else:\n        pretrained_path = None\n    file_list.sort()\n    try:\n        return file_list[-1]\n    except IndexError:\n        log.debug([local_path, pretrained_path, file_list])\n        raise",
            "def initModelPath(self, type_str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    local_path = os.path.join('data-unversioned', 'part2', 'models', 'p2ch13', type_str + '_{}_{}.{}.state'.format('*', '*', 'best'))\n    file_list = glob.glob(local_path)\n    if not file_list:\n        pretrained_path = os.path.join('data', 'part2', 'models', type_str + '_{}_{}.{}.state'.format('*', '*', '*'))\n        file_list = glob.glob(pretrained_path)\n    else:\n        pretrained_path = None\n    file_list.sort()\n    try:\n        return file_list[-1]\n    except IndexError:\n        log.debug([local_path, pretrained_path, file_list])\n        raise",
            "def initModelPath(self, type_str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    local_path = os.path.join('data-unversioned', 'part2', 'models', 'p2ch13', type_str + '_{}_{}.{}.state'.format('*', '*', 'best'))\n    file_list = glob.glob(local_path)\n    if not file_list:\n        pretrained_path = os.path.join('data', 'part2', 'models', type_str + '_{}_{}.{}.state'.format('*', '*', '*'))\n        file_list = glob.glob(pretrained_path)\n    else:\n        pretrained_path = None\n    file_list.sort()\n    try:\n        return file_list[-1]\n    except IndexError:\n        log.debug([local_path, pretrained_path, file_list])\n        raise",
            "def initModelPath(self, type_str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    local_path = os.path.join('data-unversioned', 'part2', 'models', 'p2ch13', type_str + '_{}_{}.{}.state'.format('*', '*', 'best'))\n    file_list = glob.glob(local_path)\n    if not file_list:\n        pretrained_path = os.path.join('data', 'part2', 'models', type_str + '_{}_{}.{}.state'.format('*', '*', '*'))\n        file_list = glob.glob(pretrained_path)\n    else:\n        pretrained_path = None\n    file_list.sort()\n    try:\n        return file_list[-1]\n    except IndexError:\n        log.debug([local_path, pretrained_path, file_list])\n        raise"
        ]
    },
    {
        "func_name": "initModels",
        "original": "def initModels(self):\n    log.debug(self.cli_args.segmentation_path)\n    seg_dict = torch.load(self.cli_args.segmentation_path)\n    seg_model = UNetWrapper(in_channels=7, n_classes=1, depth=3, wf=4, padding=True, batch_norm=True, up_mode='upconv')\n    seg_model.load_state_dict(seg_dict['model_state'])\n    seg_model.eval()\n    log.debug(self.cli_args.classification_path)\n    cls_dict = torch.load(self.cli_args.classification_path)\n    model_cls = getattr(p2ch14.model, self.cli_args.cls_model)\n    cls_model = model_cls()\n    cls_model.load_state_dict(cls_dict['model_state'])\n    cls_model.eval()\n    if self.use_cuda:\n        if torch.cuda.device_count() > 1:\n            seg_model = nn.DataParallel(seg_model)\n            cls_model = nn.DataParallel(cls_model)\n        seg_model.to(self.device)\n        cls_model.to(self.device)\n    if self.cli_args.malignancy_path:\n        model_cls = getattr(p2ch14.model, self.cli_args.malignancy_model)\n        malignancy_model = model_cls()\n        malignancy_dict = torch.load(self.cli_args.malignancy_path)\n        malignancy_model.load_state_dict(malignancy_dict['model_state'])\n        malignancy_model.eval()\n        if self.use_cuda:\n            malignancy_model.to(self.device)\n    else:\n        malignancy_model = None\n    return (seg_model, cls_model, malignancy_model)",
        "mutated": [
            "def initModels(self):\n    if False:\n        i = 10\n    log.debug(self.cli_args.segmentation_path)\n    seg_dict = torch.load(self.cli_args.segmentation_path)\n    seg_model = UNetWrapper(in_channels=7, n_classes=1, depth=3, wf=4, padding=True, batch_norm=True, up_mode='upconv')\n    seg_model.load_state_dict(seg_dict['model_state'])\n    seg_model.eval()\n    log.debug(self.cli_args.classification_path)\n    cls_dict = torch.load(self.cli_args.classification_path)\n    model_cls = getattr(p2ch14.model, self.cli_args.cls_model)\n    cls_model = model_cls()\n    cls_model.load_state_dict(cls_dict['model_state'])\n    cls_model.eval()\n    if self.use_cuda:\n        if torch.cuda.device_count() > 1:\n            seg_model = nn.DataParallel(seg_model)\n            cls_model = nn.DataParallel(cls_model)\n        seg_model.to(self.device)\n        cls_model.to(self.device)\n    if self.cli_args.malignancy_path:\n        model_cls = getattr(p2ch14.model, self.cli_args.malignancy_model)\n        malignancy_model = model_cls()\n        malignancy_dict = torch.load(self.cli_args.malignancy_path)\n        malignancy_model.load_state_dict(malignancy_dict['model_state'])\n        malignancy_model.eval()\n        if self.use_cuda:\n            malignancy_model.to(self.device)\n    else:\n        malignancy_model = None\n    return (seg_model, cls_model, malignancy_model)",
            "def initModels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    log.debug(self.cli_args.segmentation_path)\n    seg_dict = torch.load(self.cli_args.segmentation_path)\n    seg_model = UNetWrapper(in_channels=7, n_classes=1, depth=3, wf=4, padding=True, batch_norm=True, up_mode='upconv')\n    seg_model.load_state_dict(seg_dict['model_state'])\n    seg_model.eval()\n    log.debug(self.cli_args.classification_path)\n    cls_dict = torch.load(self.cli_args.classification_path)\n    model_cls = getattr(p2ch14.model, self.cli_args.cls_model)\n    cls_model = model_cls()\n    cls_model.load_state_dict(cls_dict['model_state'])\n    cls_model.eval()\n    if self.use_cuda:\n        if torch.cuda.device_count() > 1:\n            seg_model = nn.DataParallel(seg_model)\n            cls_model = nn.DataParallel(cls_model)\n        seg_model.to(self.device)\n        cls_model.to(self.device)\n    if self.cli_args.malignancy_path:\n        model_cls = getattr(p2ch14.model, self.cli_args.malignancy_model)\n        malignancy_model = model_cls()\n        malignancy_dict = torch.load(self.cli_args.malignancy_path)\n        malignancy_model.load_state_dict(malignancy_dict['model_state'])\n        malignancy_model.eval()\n        if self.use_cuda:\n            malignancy_model.to(self.device)\n    else:\n        malignancy_model = None\n    return (seg_model, cls_model, malignancy_model)",
            "def initModels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    log.debug(self.cli_args.segmentation_path)\n    seg_dict = torch.load(self.cli_args.segmentation_path)\n    seg_model = UNetWrapper(in_channels=7, n_classes=1, depth=3, wf=4, padding=True, batch_norm=True, up_mode='upconv')\n    seg_model.load_state_dict(seg_dict['model_state'])\n    seg_model.eval()\n    log.debug(self.cli_args.classification_path)\n    cls_dict = torch.load(self.cli_args.classification_path)\n    model_cls = getattr(p2ch14.model, self.cli_args.cls_model)\n    cls_model = model_cls()\n    cls_model.load_state_dict(cls_dict['model_state'])\n    cls_model.eval()\n    if self.use_cuda:\n        if torch.cuda.device_count() > 1:\n            seg_model = nn.DataParallel(seg_model)\n            cls_model = nn.DataParallel(cls_model)\n        seg_model.to(self.device)\n        cls_model.to(self.device)\n    if self.cli_args.malignancy_path:\n        model_cls = getattr(p2ch14.model, self.cli_args.malignancy_model)\n        malignancy_model = model_cls()\n        malignancy_dict = torch.load(self.cli_args.malignancy_path)\n        malignancy_model.load_state_dict(malignancy_dict['model_state'])\n        malignancy_model.eval()\n        if self.use_cuda:\n            malignancy_model.to(self.device)\n    else:\n        malignancy_model = None\n    return (seg_model, cls_model, malignancy_model)",
            "def initModels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    log.debug(self.cli_args.segmentation_path)\n    seg_dict = torch.load(self.cli_args.segmentation_path)\n    seg_model = UNetWrapper(in_channels=7, n_classes=1, depth=3, wf=4, padding=True, batch_norm=True, up_mode='upconv')\n    seg_model.load_state_dict(seg_dict['model_state'])\n    seg_model.eval()\n    log.debug(self.cli_args.classification_path)\n    cls_dict = torch.load(self.cli_args.classification_path)\n    model_cls = getattr(p2ch14.model, self.cli_args.cls_model)\n    cls_model = model_cls()\n    cls_model.load_state_dict(cls_dict['model_state'])\n    cls_model.eval()\n    if self.use_cuda:\n        if torch.cuda.device_count() > 1:\n            seg_model = nn.DataParallel(seg_model)\n            cls_model = nn.DataParallel(cls_model)\n        seg_model.to(self.device)\n        cls_model.to(self.device)\n    if self.cli_args.malignancy_path:\n        model_cls = getattr(p2ch14.model, self.cli_args.malignancy_model)\n        malignancy_model = model_cls()\n        malignancy_dict = torch.load(self.cli_args.malignancy_path)\n        malignancy_model.load_state_dict(malignancy_dict['model_state'])\n        malignancy_model.eval()\n        if self.use_cuda:\n            malignancy_model.to(self.device)\n    else:\n        malignancy_model = None\n    return (seg_model, cls_model, malignancy_model)",
            "def initModels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    log.debug(self.cli_args.segmentation_path)\n    seg_dict = torch.load(self.cli_args.segmentation_path)\n    seg_model = UNetWrapper(in_channels=7, n_classes=1, depth=3, wf=4, padding=True, batch_norm=True, up_mode='upconv')\n    seg_model.load_state_dict(seg_dict['model_state'])\n    seg_model.eval()\n    log.debug(self.cli_args.classification_path)\n    cls_dict = torch.load(self.cli_args.classification_path)\n    model_cls = getattr(p2ch14.model, self.cli_args.cls_model)\n    cls_model = model_cls()\n    cls_model.load_state_dict(cls_dict['model_state'])\n    cls_model.eval()\n    if self.use_cuda:\n        if torch.cuda.device_count() > 1:\n            seg_model = nn.DataParallel(seg_model)\n            cls_model = nn.DataParallel(cls_model)\n        seg_model.to(self.device)\n        cls_model.to(self.device)\n    if self.cli_args.malignancy_path:\n        model_cls = getattr(p2ch14.model, self.cli_args.malignancy_model)\n        malignancy_model = model_cls()\n        malignancy_dict = torch.load(self.cli_args.malignancy_path)\n        malignancy_model.load_state_dict(malignancy_dict['model_state'])\n        malignancy_model.eval()\n        if self.use_cuda:\n            malignancy_model.to(self.device)\n    else:\n        malignancy_model = None\n    return (seg_model, cls_model, malignancy_model)"
        ]
    },
    {
        "func_name": "initSegmentationDl",
        "original": "def initSegmentationDl(self, series_uid):\n    seg_ds = Luna2dSegmentationDataset(contextSlices_count=3, series_uid=series_uid, fullCt_bool=True)\n    seg_dl = DataLoader(seg_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return seg_dl",
        "mutated": [
            "def initSegmentationDl(self, series_uid):\n    if False:\n        i = 10\n    seg_ds = Luna2dSegmentationDataset(contextSlices_count=3, series_uid=series_uid, fullCt_bool=True)\n    seg_dl = DataLoader(seg_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return seg_dl",
            "def initSegmentationDl(self, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    seg_ds = Luna2dSegmentationDataset(contextSlices_count=3, series_uid=series_uid, fullCt_bool=True)\n    seg_dl = DataLoader(seg_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return seg_dl",
            "def initSegmentationDl(self, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    seg_ds = Luna2dSegmentationDataset(contextSlices_count=3, series_uid=series_uid, fullCt_bool=True)\n    seg_dl = DataLoader(seg_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return seg_dl",
            "def initSegmentationDl(self, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    seg_ds = Luna2dSegmentationDataset(contextSlices_count=3, series_uid=series_uid, fullCt_bool=True)\n    seg_dl = DataLoader(seg_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return seg_dl",
            "def initSegmentationDl(self, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    seg_ds = Luna2dSegmentationDataset(contextSlices_count=3, series_uid=series_uid, fullCt_bool=True)\n    seg_dl = DataLoader(seg_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return seg_dl"
        ]
    },
    {
        "func_name": "initClassificationDl",
        "original": "def initClassificationDl(self, candidateInfo_list):\n    cls_ds = LunaDataset(sortby_str='series_uid', candidateInfo_list=candidateInfo_list)\n    cls_dl = DataLoader(cls_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return cls_dl",
        "mutated": [
            "def initClassificationDl(self, candidateInfo_list):\n    if False:\n        i = 10\n    cls_ds = LunaDataset(sortby_str='series_uid', candidateInfo_list=candidateInfo_list)\n    cls_dl = DataLoader(cls_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return cls_dl",
            "def initClassificationDl(self, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cls_ds = LunaDataset(sortby_str='series_uid', candidateInfo_list=candidateInfo_list)\n    cls_dl = DataLoader(cls_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return cls_dl",
            "def initClassificationDl(self, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cls_ds = LunaDataset(sortby_str='series_uid', candidateInfo_list=candidateInfo_list)\n    cls_dl = DataLoader(cls_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return cls_dl",
            "def initClassificationDl(self, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cls_ds = LunaDataset(sortby_str='series_uid', candidateInfo_list=candidateInfo_list)\n    cls_dl = DataLoader(cls_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return cls_dl",
            "def initClassificationDl(self, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cls_ds = LunaDataset(sortby_str='series_uid', candidateInfo_list=candidateInfo_list)\n    cls_dl = DataLoader(cls_ds, batch_size=self.cli_args.batch_size * (torch.cuda.device_count() if self.use_cuda else 1), num_workers=self.cli_args.num_workers, pin_memory=self.use_cuda)\n    return cls_dl"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(self):\n    log.info('Starting {}, {}'.format(type(self).__name__, self.cli_args))\n    val_ds = LunaDataset(val_stride=10, isValSet_bool=True)\n    val_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in val_ds.candidateInfo_list))\n    positive_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList() if candidateInfo_tup.isNodule_bool))\n    if self.cli_args.series_uid:\n        series_set = set(self.cli_args.series_uid.split(','))\n    else:\n        series_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList()))\n    if self.cli_args.include_train:\n        train_list = sorted(series_set - val_set)\n    else:\n        train_list = []\n    val_list = sorted(series_set & val_set)\n    candidateInfo_dict = getCandidateInfoDict()\n    series_iter = enumerateWithEstimate(val_list + train_list, 'Series')\n    all_confusion = np.zeros((3, 4), dtype=np.int)\n    for (_, series_uid) in series_iter:\n        ct = getCt(series_uid)\n        mask_a = self.segmentCt(ct, series_uid)\n        candidateInfo_list = self.groupSegmentationOutput(series_uid, ct, mask_a)\n        classifications_list = self.classifyCandidates(ct, candidateInfo_list)\n        if not self.cli_args.run_validation:\n            print(f'found nodule candidates in {series_uid}:')\n            for (prob, prob_mal, center_xyz, center_irc) in classifications_list:\n                if prob > 0.5:\n                    s = f'nodule prob {prob:.3f}, '\n                    if self.malignancy_model:\n                        s += f'malignancy prob {prob_mal:.3f}, '\n                    s += f'center xyz {center_xyz}'\n                    print(s)\n        if series_uid in candidateInfo_dict:\n            one_confusion = match_and_score(classifications_list, candidateInfo_dict[series_uid])\n            all_confusion += one_confusion\n            print_confusion(series_uid, one_confusion, self.malignancy_model is not None)\n    print_confusion('Total', all_confusion, self.malignancy_model is not None)",
        "mutated": [
            "def main(self):\n    if False:\n        i = 10\n    log.info('Starting {}, {}'.format(type(self).__name__, self.cli_args))\n    val_ds = LunaDataset(val_stride=10, isValSet_bool=True)\n    val_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in val_ds.candidateInfo_list))\n    positive_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList() if candidateInfo_tup.isNodule_bool))\n    if self.cli_args.series_uid:\n        series_set = set(self.cli_args.series_uid.split(','))\n    else:\n        series_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList()))\n    if self.cli_args.include_train:\n        train_list = sorted(series_set - val_set)\n    else:\n        train_list = []\n    val_list = sorted(series_set & val_set)\n    candidateInfo_dict = getCandidateInfoDict()\n    series_iter = enumerateWithEstimate(val_list + train_list, 'Series')\n    all_confusion = np.zeros((3, 4), dtype=np.int)\n    for (_, series_uid) in series_iter:\n        ct = getCt(series_uid)\n        mask_a = self.segmentCt(ct, series_uid)\n        candidateInfo_list = self.groupSegmentationOutput(series_uid, ct, mask_a)\n        classifications_list = self.classifyCandidates(ct, candidateInfo_list)\n        if not self.cli_args.run_validation:\n            print(f'found nodule candidates in {series_uid}:')\n            for (prob, prob_mal, center_xyz, center_irc) in classifications_list:\n                if prob > 0.5:\n                    s = f'nodule prob {prob:.3f}, '\n                    if self.malignancy_model:\n                        s += f'malignancy prob {prob_mal:.3f}, '\n                    s += f'center xyz {center_xyz}'\n                    print(s)\n        if series_uid in candidateInfo_dict:\n            one_confusion = match_and_score(classifications_list, candidateInfo_dict[series_uid])\n            all_confusion += one_confusion\n            print_confusion(series_uid, one_confusion, self.malignancy_model is not None)\n    print_confusion('Total', all_confusion, self.malignancy_model is not None)",
            "def main(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    log.info('Starting {}, {}'.format(type(self).__name__, self.cli_args))\n    val_ds = LunaDataset(val_stride=10, isValSet_bool=True)\n    val_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in val_ds.candidateInfo_list))\n    positive_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList() if candidateInfo_tup.isNodule_bool))\n    if self.cli_args.series_uid:\n        series_set = set(self.cli_args.series_uid.split(','))\n    else:\n        series_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList()))\n    if self.cli_args.include_train:\n        train_list = sorted(series_set - val_set)\n    else:\n        train_list = []\n    val_list = sorted(series_set & val_set)\n    candidateInfo_dict = getCandidateInfoDict()\n    series_iter = enumerateWithEstimate(val_list + train_list, 'Series')\n    all_confusion = np.zeros((3, 4), dtype=np.int)\n    for (_, series_uid) in series_iter:\n        ct = getCt(series_uid)\n        mask_a = self.segmentCt(ct, series_uid)\n        candidateInfo_list = self.groupSegmentationOutput(series_uid, ct, mask_a)\n        classifications_list = self.classifyCandidates(ct, candidateInfo_list)\n        if not self.cli_args.run_validation:\n            print(f'found nodule candidates in {series_uid}:')\n            for (prob, prob_mal, center_xyz, center_irc) in classifications_list:\n                if prob > 0.5:\n                    s = f'nodule prob {prob:.3f}, '\n                    if self.malignancy_model:\n                        s += f'malignancy prob {prob_mal:.3f}, '\n                    s += f'center xyz {center_xyz}'\n                    print(s)\n        if series_uid in candidateInfo_dict:\n            one_confusion = match_and_score(classifications_list, candidateInfo_dict[series_uid])\n            all_confusion += one_confusion\n            print_confusion(series_uid, one_confusion, self.malignancy_model is not None)\n    print_confusion('Total', all_confusion, self.malignancy_model is not None)",
            "def main(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    log.info('Starting {}, {}'.format(type(self).__name__, self.cli_args))\n    val_ds = LunaDataset(val_stride=10, isValSet_bool=True)\n    val_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in val_ds.candidateInfo_list))\n    positive_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList() if candidateInfo_tup.isNodule_bool))\n    if self.cli_args.series_uid:\n        series_set = set(self.cli_args.series_uid.split(','))\n    else:\n        series_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList()))\n    if self.cli_args.include_train:\n        train_list = sorted(series_set - val_set)\n    else:\n        train_list = []\n    val_list = sorted(series_set & val_set)\n    candidateInfo_dict = getCandidateInfoDict()\n    series_iter = enumerateWithEstimate(val_list + train_list, 'Series')\n    all_confusion = np.zeros((3, 4), dtype=np.int)\n    for (_, series_uid) in series_iter:\n        ct = getCt(series_uid)\n        mask_a = self.segmentCt(ct, series_uid)\n        candidateInfo_list = self.groupSegmentationOutput(series_uid, ct, mask_a)\n        classifications_list = self.classifyCandidates(ct, candidateInfo_list)\n        if not self.cli_args.run_validation:\n            print(f'found nodule candidates in {series_uid}:')\n            for (prob, prob_mal, center_xyz, center_irc) in classifications_list:\n                if prob > 0.5:\n                    s = f'nodule prob {prob:.3f}, '\n                    if self.malignancy_model:\n                        s += f'malignancy prob {prob_mal:.3f}, '\n                    s += f'center xyz {center_xyz}'\n                    print(s)\n        if series_uid in candidateInfo_dict:\n            one_confusion = match_and_score(classifications_list, candidateInfo_dict[series_uid])\n            all_confusion += one_confusion\n            print_confusion(series_uid, one_confusion, self.malignancy_model is not None)\n    print_confusion('Total', all_confusion, self.malignancy_model is not None)",
            "def main(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    log.info('Starting {}, {}'.format(type(self).__name__, self.cli_args))\n    val_ds = LunaDataset(val_stride=10, isValSet_bool=True)\n    val_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in val_ds.candidateInfo_list))\n    positive_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList() if candidateInfo_tup.isNodule_bool))\n    if self.cli_args.series_uid:\n        series_set = set(self.cli_args.series_uid.split(','))\n    else:\n        series_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList()))\n    if self.cli_args.include_train:\n        train_list = sorted(series_set - val_set)\n    else:\n        train_list = []\n    val_list = sorted(series_set & val_set)\n    candidateInfo_dict = getCandidateInfoDict()\n    series_iter = enumerateWithEstimate(val_list + train_list, 'Series')\n    all_confusion = np.zeros((3, 4), dtype=np.int)\n    for (_, series_uid) in series_iter:\n        ct = getCt(series_uid)\n        mask_a = self.segmentCt(ct, series_uid)\n        candidateInfo_list = self.groupSegmentationOutput(series_uid, ct, mask_a)\n        classifications_list = self.classifyCandidates(ct, candidateInfo_list)\n        if not self.cli_args.run_validation:\n            print(f'found nodule candidates in {series_uid}:')\n            for (prob, prob_mal, center_xyz, center_irc) in classifications_list:\n                if prob > 0.5:\n                    s = f'nodule prob {prob:.3f}, '\n                    if self.malignancy_model:\n                        s += f'malignancy prob {prob_mal:.3f}, '\n                    s += f'center xyz {center_xyz}'\n                    print(s)\n        if series_uid in candidateInfo_dict:\n            one_confusion = match_and_score(classifications_list, candidateInfo_dict[series_uid])\n            all_confusion += one_confusion\n            print_confusion(series_uid, one_confusion, self.malignancy_model is not None)\n    print_confusion('Total', all_confusion, self.malignancy_model is not None)",
            "def main(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    log.info('Starting {}, {}'.format(type(self).__name__, self.cli_args))\n    val_ds = LunaDataset(val_stride=10, isValSet_bool=True)\n    val_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in val_ds.candidateInfo_list))\n    positive_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList() if candidateInfo_tup.isNodule_bool))\n    if self.cli_args.series_uid:\n        series_set = set(self.cli_args.series_uid.split(','))\n    else:\n        series_set = set((candidateInfo_tup.series_uid for candidateInfo_tup in getCandidateInfoList()))\n    if self.cli_args.include_train:\n        train_list = sorted(series_set - val_set)\n    else:\n        train_list = []\n    val_list = sorted(series_set & val_set)\n    candidateInfo_dict = getCandidateInfoDict()\n    series_iter = enumerateWithEstimate(val_list + train_list, 'Series')\n    all_confusion = np.zeros((3, 4), dtype=np.int)\n    for (_, series_uid) in series_iter:\n        ct = getCt(series_uid)\n        mask_a = self.segmentCt(ct, series_uid)\n        candidateInfo_list = self.groupSegmentationOutput(series_uid, ct, mask_a)\n        classifications_list = self.classifyCandidates(ct, candidateInfo_list)\n        if not self.cli_args.run_validation:\n            print(f'found nodule candidates in {series_uid}:')\n            for (prob, prob_mal, center_xyz, center_irc) in classifications_list:\n                if prob > 0.5:\n                    s = f'nodule prob {prob:.3f}, '\n                    if self.malignancy_model:\n                        s += f'malignancy prob {prob_mal:.3f}, '\n                    s += f'center xyz {center_xyz}'\n                    print(s)\n        if series_uid in candidateInfo_dict:\n            one_confusion = match_and_score(classifications_list, candidateInfo_dict[series_uid])\n            all_confusion += one_confusion\n            print_confusion(series_uid, one_confusion, self.malignancy_model is not None)\n    print_confusion('Total', all_confusion, self.malignancy_model is not None)"
        ]
    },
    {
        "func_name": "classifyCandidates",
        "original": "def classifyCandidates(self, ct, candidateInfo_list):\n    cls_dl = self.initClassificationDl(candidateInfo_list)\n    classifications_list = []\n    for (batch_ndx, batch_tup) in enumerate(cls_dl):\n        (input_t, _, _, series_list, center_list) = batch_tup\n        input_g = input_t.to(self.device)\n        with torch.no_grad():\n            (_, probability_nodule_g) = self.cls_model(input_g)\n            if self.malignancy_model is not None:\n                (_, probability_mal_g) = self.malignancy_model(input_g)\n            else:\n                probability_mal_g = torch.zeros_like(probability_nodule_g)\n        zip_iter = zip(center_list, probability_nodule_g[:, 1].tolist(), probability_mal_g[:, 1].tolist())\n        for (center_irc, prob_nodule, prob_mal) in zip_iter:\n            center_xyz = irc2xyz(center_irc, direction_a=ct.direction_a, origin_xyz=ct.origin_xyz, vxSize_xyz=ct.vxSize_xyz)\n            cls_tup = (prob_nodule, prob_mal, center_xyz, center_irc)\n            classifications_list.append(cls_tup)\n    return classifications_list",
        "mutated": [
            "def classifyCandidates(self, ct, candidateInfo_list):\n    if False:\n        i = 10\n    cls_dl = self.initClassificationDl(candidateInfo_list)\n    classifications_list = []\n    for (batch_ndx, batch_tup) in enumerate(cls_dl):\n        (input_t, _, _, series_list, center_list) = batch_tup\n        input_g = input_t.to(self.device)\n        with torch.no_grad():\n            (_, probability_nodule_g) = self.cls_model(input_g)\n            if self.malignancy_model is not None:\n                (_, probability_mal_g) = self.malignancy_model(input_g)\n            else:\n                probability_mal_g = torch.zeros_like(probability_nodule_g)\n        zip_iter = zip(center_list, probability_nodule_g[:, 1].tolist(), probability_mal_g[:, 1].tolist())\n        for (center_irc, prob_nodule, prob_mal) in zip_iter:\n            center_xyz = irc2xyz(center_irc, direction_a=ct.direction_a, origin_xyz=ct.origin_xyz, vxSize_xyz=ct.vxSize_xyz)\n            cls_tup = (prob_nodule, prob_mal, center_xyz, center_irc)\n            classifications_list.append(cls_tup)\n    return classifications_list",
            "def classifyCandidates(self, ct, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cls_dl = self.initClassificationDl(candidateInfo_list)\n    classifications_list = []\n    for (batch_ndx, batch_tup) in enumerate(cls_dl):\n        (input_t, _, _, series_list, center_list) = batch_tup\n        input_g = input_t.to(self.device)\n        with torch.no_grad():\n            (_, probability_nodule_g) = self.cls_model(input_g)\n            if self.malignancy_model is not None:\n                (_, probability_mal_g) = self.malignancy_model(input_g)\n            else:\n                probability_mal_g = torch.zeros_like(probability_nodule_g)\n        zip_iter = zip(center_list, probability_nodule_g[:, 1].tolist(), probability_mal_g[:, 1].tolist())\n        for (center_irc, prob_nodule, prob_mal) in zip_iter:\n            center_xyz = irc2xyz(center_irc, direction_a=ct.direction_a, origin_xyz=ct.origin_xyz, vxSize_xyz=ct.vxSize_xyz)\n            cls_tup = (prob_nodule, prob_mal, center_xyz, center_irc)\n            classifications_list.append(cls_tup)\n    return classifications_list",
            "def classifyCandidates(self, ct, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cls_dl = self.initClassificationDl(candidateInfo_list)\n    classifications_list = []\n    for (batch_ndx, batch_tup) in enumerate(cls_dl):\n        (input_t, _, _, series_list, center_list) = batch_tup\n        input_g = input_t.to(self.device)\n        with torch.no_grad():\n            (_, probability_nodule_g) = self.cls_model(input_g)\n            if self.malignancy_model is not None:\n                (_, probability_mal_g) = self.malignancy_model(input_g)\n            else:\n                probability_mal_g = torch.zeros_like(probability_nodule_g)\n        zip_iter = zip(center_list, probability_nodule_g[:, 1].tolist(), probability_mal_g[:, 1].tolist())\n        for (center_irc, prob_nodule, prob_mal) in zip_iter:\n            center_xyz = irc2xyz(center_irc, direction_a=ct.direction_a, origin_xyz=ct.origin_xyz, vxSize_xyz=ct.vxSize_xyz)\n            cls_tup = (prob_nodule, prob_mal, center_xyz, center_irc)\n            classifications_list.append(cls_tup)\n    return classifications_list",
            "def classifyCandidates(self, ct, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cls_dl = self.initClassificationDl(candidateInfo_list)\n    classifications_list = []\n    for (batch_ndx, batch_tup) in enumerate(cls_dl):\n        (input_t, _, _, series_list, center_list) = batch_tup\n        input_g = input_t.to(self.device)\n        with torch.no_grad():\n            (_, probability_nodule_g) = self.cls_model(input_g)\n            if self.malignancy_model is not None:\n                (_, probability_mal_g) = self.malignancy_model(input_g)\n            else:\n                probability_mal_g = torch.zeros_like(probability_nodule_g)\n        zip_iter = zip(center_list, probability_nodule_g[:, 1].tolist(), probability_mal_g[:, 1].tolist())\n        for (center_irc, prob_nodule, prob_mal) in zip_iter:\n            center_xyz = irc2xyz(center_irc, direction_a=ct.direction_a, origin_xyz=ct.origin_xyz, vxSize_xyz=ct.vxSize_xyz)\n            cls_tup = (prob_nodule, prob_mal, center_xyz, center_irc)\n            classifications_list.append(cls_tup)\n    return classifications_list",
            "def classifyCandidates(self, ct, candidateInfo_list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cls_dl = self.initClassificationDl(candidateInfo_list)\n    classifications_list = []\n    for (batch_ndx, batch_tup) in enumerate(cls_dl):\n        (input_t, _, _, series_list, center_list) = batch_tup\n        input_g = input_t.to(self.device)\n        with torch.no_grad():\n            (_, probability_nodule_g) = self.cls_model(input_g)\n            if self.malignancy_model is not None:\n                (_, probability_mal_g) = self.malignancy_model(input_g)\n            else:\n                probability_mal_g = torch.zeros_like(probability_nodule_g)\n        zip_iter = zip(center_list, probability_nodule_g[:, 1].tolist(), probability_mal_g[:, 1].tolist())\n        for (center_irc, prob_nodule, prob_mal) in zip_iter:\n            center_xyz = irc2xyz(center_irc, direction_a=ct.direction_a, origin_xyz=ct.origin_xyz, vxSize_xyz=ct.vxSize_xyz)\n            cls_tup = (prob_nodule, prob_mal, center_xyz, center_irc)\n            classifications_list.append(cls_tup)\n    return classifications_list"
        ]
    },
    {
        "func_name": "segmentCt",
        "original": "def segmentCt(self, ct, series_uid):\n    with torch.no_grad():\n        output_a = np.zeros_like(ct.hu_a, dtype=np.float32)\n        seg_dl = self.initSegmentationDl(series_uid)\n        for (input_t, _, _, slice_ndx_list) in seg_dl:\n            input_g = input_t.to(self.device)\n            prediction_g = self.seg_model(input_g)\n            for (i, slice_ndx) in enumerate(slice_ndx_list):\n                output_a[slice_ndx] = prediction_g[i].cpu().numpy()\n        mask_a = output_a > 0.5\n        mask_a = morphology.binary_erosion(mask_a, iterations=1)\n    return mask_a",
        "mutated": [
            "def segmentCt(self, ct, series_uid):\n    if False:\n        i = 10\n    with torch.no_grad():\n        output_a = np.zeros_like(ct.hu_a, dtype=np.float32)\n        seg_dl = self.initSegmentationDl(series_uid)\n        for (input_t, _, _, slice_ndx_list) in seg_dl:\n            input_g = input_t.to(self.device)\n            prediction_g = self.seg_model(input_g)\n            for (i, slice_ndx) in enumerate(slice_ndx_list):\n                output_a[slice_ndx] = prediction_g[i].cpu().numpy()\n        mask_a = output_a > 0.5\n        mask_a = morphology.binary_erosion(mask_a, iterations=1)\n    return mask_a",
            "def segmentCt(self, ct, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with torch.no_grad():\n        output_a = np.zeros_like(ct.hu_a, dtype=np.float32)\n        seg_dl = self.initSegmentationDl(series_uid)\n        for (input_t, _, _, slice_ndx_list) in seg_dl:\n            input_g = input_t.to(self.device)\n            prediction_g = self.seg_model(input_g)\n            for (i, slice_ndx) in enumerate(slice_ndx_list):\n                output_a[slice_ndx] = prediction_g[i].cpu().numpy()\n        mask_a = output_a > 0.5\n        mask_a = morphology.binary_erosion(mask_a, iterations=1)\n    return mask_a",
            "def segmentCt(self, ct, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with torch.no_grad():\n        output_a = np.zeros_like(ct.hu_a, dtype=np.float32)\n        seg_dl = self.initSegmentationDl(series_uid)\n        for (input_t, _, _, slice_ndx_list) in seg_dl:\n            input_g = input_t.to(self.device)\n            prediction_g = self.seg_model(input_g)\n            for (i, slice_ndx) in enumerate(slice_ndx_list):\n                output_a[slice_ndx] = prediction_g[i].cpu().numpy()\n        mask_a = output_a > 0.5\n        mask_a = morphology.binary_erosion(mask_a, iterations=1)\n    return mask_a",
            "def segmentCt(self, ct, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with torch.no_grad():\n        output_a = np.zeros_like(ct.hu_a, dtype=np.float32)\n        seg_dl = self.initSegmentationDl(series_uid)\n        for (input_t, _, _, slice_ndx_list) in seg_dl:\n            input_g = input_t.to(self.device)\n            prediction_g = self.seg_model(input_g)\n            for (i, slice_ndx) in enumerate(slice_ndx_list):\n                output_a[slice_ndx] = prediction_g[i].cpu().numpy()\n        mask_a = output_a > 0.5\n        mask_a = morphology.binary_erosion(mask_a, iterations=1)\n    return mask_a",
            "def segmentCt(self, ct, series_uid):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with torch.no_grad():\n        output_a = np.zeros_like(ct.hu_a, dtype=np.float32)\n        seg_dl = self.initSegmentationDl(series_uid)\n        for (input_t, _, _, slice_ndx_list) in seg_dl:\n            input_g = input_t.to(self.device)\n            prediction_g = self.seg_model(input_g)\n            for (i, slice_ndx) in enumerate(slice_ndx_list):\n                output_a[slice_ndx] = prediction_g[i].cpu().numpy()\n        mask_a = output_a > 0.5\n        mask_a = morphology.binary_erosion(mask_a, iterations=1)\n    return mask_a"
        ]
    },
    {
        "func_name": "groupSegmentationOutput",
        "original": "def groupSegmentationOutput(self, series_uid, ct, clean_a):\n    (candidateLabel_a, candidate_count) = measurements.label(clean_a)\n    centerIrc_list = measurements.center_of_mass(ct.hu_a.clip(-1000, 1000) + 1001, labels=candidateLabel_a, index=np.arange(1, candidate_count + 1))\n    candidateInfo_list = []\n    for (i, center_irc) in enumerate(centerIrc_list):\n        center_xyz = irc2xyz(center_irc, ct.origin_xyz, ct.vxSize_xyz, ct.direction_a)\n        assert np.all(np.isfinite(center_irc)), repr(['irc', center_irc, i, candidate_count])\n        assert np.all(np.isfinite(center_xyz)), repr(['xyz', center_xyz])\n        candidateInfo_tup = CandidateInfoTuple(False, False, False, 0.0, series_uid, center_xyz)\n        candidateInfo_list.append(candidateInfo_tup)\n    return candidateInfo_list",
        "mutated": [
            "def groupSegmentationOutput(self, series_uid, ct, clean_a):\n    if False:\n        i = 10\n    (candidateLabel_a, candidate_count) = measurements.label(clean_a)\n    centerIrc_list = measurements.center_of_mass(ct.hu_a.clip(-1000, 1000) + 1001, labels=candidateLabel_a, index=np.arange(1, candidate_count + 1))\n    candidateInfo_list = []\n    for (i, center_irc) in enumerate(centerIrc_list):\n        center_xyz = irc2xyz(center_irc, ct.origin_xyz, ct.vxSize_xyz, ct.direction_a)\n        assert np.all(np.isfinite(center_irc)), repr(['irc', center_irc, i, candidate_count])\n        assert np.all(np.isfinite(center_xyz)), repr(['xyz', center_xyz])\n        candidateInfo_tup = CandidateInfoTuple(False, False, False, 0.0, series_uid, center_xyz)\n        candidateInfo_list.append(candidateInfo_tup)\n    return candidateInfo_list",
            "def groupSegmentationOutput(self, series_uid, ct, clean_a):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (candidateLabel_a, candidate_count) = measurements.label(clean_a)\n    centerIrc_list = measurements.center_of_mass(ct.hu_a.clip(-1000, 1000) + 1001, labels=candidateLabel_a, index=np.arange(1, candidate_count + 1))\n    candidateInfo_list = []\n    for (i, center_irc) in enumerate(centerIrc_list):\n        center_xyz = irc2xyz(center_irc, ct.origin_xyz, ct.vxSize_xyz, ct.direction_a)\n        assert np.all(np.isfinite(center_irc)), repr(['irc', center_irc, i, candidate_count])\n        assert np.all(np.isfinite(center_xyz)), repr(['xyz', center_xyz])\n        candidateInfo_tup = CandidateInfoTuple(False, False, False, 0.0, series_uid, center_xyz)\n        candidateInfo_list.append(candidateInfo_tup)\n    return candidateInfo_list",
            "def groupSegmentationOutput(self, series_uid, ct, clean_a):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (candidateLabel_a, candidate_count) = measurements.label(clean_a)\n    centerIrc_list = measurements.center_of_mass(ct.hu_a.clip(-1000, 1000) + 1001, labels=candidateLabel_a, index=np.arange(1, candidate_count + 1))\n    candidateInfo_list = []\n    for (i, center_irc) in enumerate(centerIrc_list):\n        center_xyz = irc2xyz(center_irc, ct.origin_xyz, ct.vxSize_xyz, ct.direction_a)\n        assert np.all(np.isfinite(center_irc)), repr(['irc', center_irc, i, candidate_count])\n        assert np.all(np.isfinite(center_xyz)), repr(['xyz', center_xyz])\n        candidateInfo_tup = CandidateInfoTuple(False, False, False, 0.0, series_uid, center_xyz)\n        candidateInfo_list.append(candidateInfo_tup)\n    return candidateInfo_list",
            "def groupSegmentationOutput(self, series_uid, ct, clean_a):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (candidateLabel_a, candidate_count) = measurements.label(clean_a)\n    centerIrc_list = measurements.center_of_mass(ct.hu_a.clip(-1000, 1000) + 1001, labels=candidateLabel_a, index=np.arange(1, candidate_count + 1))\n    candidateInfo_list = []\n    for (i, center_irc) in enumerate(centerIrc_list):\n        center_xyz = irc2xyz(center_irc, ct.origin_xyz, ct.vxSize_xyz, ct.direction_a)\n        assert np.all(np.isfinite(center_irc)), repr(['irc', center_irc, i, candidate_count])\n        assert np.all(np.isfinite(center_xyz)), repr(['xyz', center_xyz])\n        candidateInfo_tup = CandidateInfoTuple(False, False, False, 0.0, series_uid, center_xyz)\n        candidateInfo_list.append(candidateInfo_tup)\n    return candidateInfo_list",
            "def groupSegmentationOutput(self, series_uid, ct, clean_a):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (candidateLabel_a, candidate_count) = measurements.label(clean_a)\n    centerIrc_list = measurements.center_of_mass(ct.hu_a.clip(-1000, 1000) + 1001, labels=candidateLabel_a, index=np.arange(1, candidate_count + 1))\n    candidateInfo_list = []\n    for (i, center_irc) in enumerate(centerIrc_list):\n        center_xyz = irc2xyz(center_irc, ct.origin_xyz, ct.vxSize_xyz, ct.direction_a)\n        assert np.all(np.isfinite(center_irc)), repr(['irc', center_irc, i, candidate_count])\n        assert np.all(np.isfinite(center_xyz)), repr(['xyz', center_xyz])\n        candidateInfo_tup = CandidateInfoTuple(False, False, False, 0.0, series_uid, center_xyz)\n        candidateInfo_list.append(candidateInfo_tup)\n    return candidateInfo_list"
        ]
    },
    {
        "func_name": "logResults",
        "original": "def logResults(self, mode_str, filtered_list, series2diagnosis_dict, positive_set):\n    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n    for series_uid in filtered_list:\n        (probablity_float, center_irc) = series2diagnosis_dict.get(series_uid, (0.0, None))\n        if center_irc is not None:\n            center_irc = tuple((int(x.item()) for x in center_irc))\n        positive_bool = series_uid in positive_set\n        prediction_bool = probablity_float > 0.5\n        correct_bool = positive_bool == prediction_bool\n        if positive_bool and prediction_bool:\n            count_dict['tp'] += 1\n        if not positive_bool and (not prediction_bool):\n            count_dict['tn'] += 1\n        if not positive_bool and prediction_bool:\n            count_dict['fp'] += 1\n        if positive_bool and (not prediction_bool):\n            count_dict['fn'] += 1\n        log.info('{} {} Label:{!r:5} Pred:{!r:5} Correct?:{!r:5} Value:{:.4f} {}'.format(mode_str, series_uid, positive_bool, prediction_bool, correct_bool, probablity_float, center_irc))\n    total_count = sum(count_dict.values())\n    percent_dict = {k: v / (total_count or 1) * 100 for (k, v) in count_dict.items()}\n    precision = percent_dict['p'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fp'] or 1)\n    recall = percent_dict['r'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fn'] or 1)\n    percent_dict['f1'] = 2 * (precision * recall) / (precision + recall or 1)\n    log.info(mode_str + ' tp:{tp:.1f}%, tn:{tn:.1f}%, fp:{fp:.1f}%, fn:{fn:.1f}%'.format(**percent_dict))\n    log.info(mode_str + ' precision:{p:.3f}, recall:{r:.3f}, F1:{f1:.3f}'.format(**percent_dict))",
        "mutated": [
            "def logResults(self, mode_str, filtered_list, series2diagnosis_dict, positive_set):\n    if False:\n        i = 10\n    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n    for series_uid in filtered_list:\n        (probablity_float, center_irc) = series2diagnosis_dict.get(series_uid, (0.0, None))\n        if center_irc is not None:\n            center_irc = tuple((int(x.item()) for x in center_irc))\n        positive_bool = series_uid in positive_set\n        prediction_bool = probablity_float > 0.5\n        correct_bool = positive_bool == prediction_bool\n        if positive_bool and prediction_bool:\n            count_dict['tp'] += 1\n        if not positive_bool and (not prediction_bool):\n            count_dict['tn'] += 1\n        if not positive_bool and prediction_bool:\n            count_dict['fp'] += 1\n        if positive_bool and (not prediction_bool):\n            count_dict['fn'] += 1\n        log.info('{} {} Label:{!r:5} Pred:{!r:5} Correct?:{!r:5} Value:{:.4f} {}'.format(mode_str, series_uid, positive_bool, prediction_bool, correct_bool, probablity_float, center_irc))\n    total_count = sum(count_dict.values())\n    percent_dict = {k: v / (total_count or 1) * 100 for (k, v) in count_dict.items()}\n    precision = percent_dict['p'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fp'] or 1)\n    recall = percent_dict['r'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fn'] or 1)\n    percent_dict['f1'] = 2 * (precision * recall) / (precision + recall or 1)\n    log.info(mode_str + ' tp:{tp:.1f}%, tn:{tn:.1f}%, fp:{fp:.1f}%, fn:{fn:.1f}%'.format(**percent_dict))\n    log.info(mode_str + ' precision:{p:.3f}, recall:{r:.3f}, F1:{f1:.3f}'.format(**percent_dict))",
            "def logResults(self, mode_str, filtered_list, series2diagnosis_dict, positive_set):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n    for series_uid in filtered_list:\n        (probablity_float, center_irc) = series2diagnosis_dict.get(series_uid, (0.0, None))\n        if center_irc is not None:\n            center_irc = tuple((int(x.item()) for x in center_irc))\n        positive_bool = series_uid in positive_set\n        prediction_bool = probablity_float > 0.5\n        correct_bool = positive_bool == prediction_bool\n        if positive_bool and prediction_bool:\n            count_dict['tp'] += 1\n        if not positive_bool and (not prediction_bool):\n            count_dict['tn'] += 1\n        if not positive_bool and prediction_bool:\n            count_dict['fp'] += 1\n        if positive_bool and (not prediction_bool):\n            count_dict['fn'] += 1\n        log.info('{} {} Label:{!r:5} Pred:{!r:5} Correct?:{!r:5} Value:{:.4f} {}'.format(mode_str, series_uid, positive_bool, prediction_bool, correct_bool, probablity_float, center_irc))\n    total_count = sum(count_dict.values())\n    percent_dict = {k: v / (total_count or 1) * 100 for (k, v) in count_dict.items()}\n    precision = percent_dict['p'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fp'] or 1)\n    recall = percent_dict['r'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fn'] or 1)\n    percent_dict['f1'] = 2 * (precision * recall) / (precision + recall or 1)\n    log.info(mode_str + ' tp:{tp:.1f}%, tn:{tn:.1f}%, fp:{fp:.1f}%, fn:{fn:.1f}%'.format(**percent_dict))\n    log.info(mode_str + ' precision:{p:.3f}, recall:{r:.3f}, F1:{f1:.3f}'.format(**percent_dict))",
            "def logResults(self, mode_str, filtered_list, series2diagnosis_dict, positive_set):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n    for series_uid in filtered_list:\n        (probablity_float, center_irc) = series2diagnosis_dict.get(series_uid, (0.0, None))\n        if center_irc is not None:\n            center_irc = tuple((int(x.item()) for x in center_irc))\n        positive_bool = series_uid in positive_set\n        prediction_bool = probablity_float > 0.5\n        correct_bool = positive_bool == prediction_bool\n        if positive_bool and prediction_bool:\n            count_dict['tp'] += 1\n        if not positive_bool and (not prediction_bool):\n            count_dict['tn'] += 1\n        if not positive_bool and prediction_bool:\n            count_dict['fp'] += 1\n        if positive_bool and (not prediction_bool):\n            count_dict['fn'] += 1\n        log.info('{} {} Label:{!r:5} Pred:{!r:5} Correct?:{!r:5} Value:{:.4f} {}'.format(mode_str, series_uid, positive_bool, prediction_bool, correct_bool, probablity_float, center_irc))\n    total_count = sum(count_dict.values())\n    percent_dict = {k: v / (total_count or 1) * 100 for (k, v) in count_dict.items()}\n    precision = percent_dict['p'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fp'] or 1)\n    recall = percent_dict['r'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fn'] or 1)\n    percent_dict['f1'] = 2 * (precision * recall) / (precision + recall or 1)\n    log.info(mode_str + ' tp:{tp:.1f}%, tn:{tn:.1f}%, fp:{fp:.1f}%, fn:{fn:.1f}%'.format(**percent_dict))\n    log.info(mode_str + ' precision:{p:.3f}, recall:{r:.3f}, F1:{f1:.3f}'.format(**percent_dict))",
            "def logResults(self, mode_str, filtered_list, series2diagnosis_dict, positive_set):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n    for series_uid in filtered_list:\n        (probablity_float, center_irc) = series2diagnosis_dict.get(series_uid, (0.0, None))\n        if center_irc is not None:\n            center_irc = tuple((int(x.item()) for x in center_irc))\n        positive_bool = series_uid in positive_set\n        prediction_bool = probablity_float > 0.5\n        correct_bool = positive_bool == prediction_bool\n        if positive_bool and prediction_bool:\n            count_dict['tp'] += 1\n        if not positive_bool and (not prediction_bool):\n            count_dict['tn'] += 1\n        if not positive_bool and prediction_bool:\n            count_dict['fp'] += 1\n        if positive_bool and (not prediction_bool):\n            count_dict['fn'] += 1\n        log.info('{} {} Label:{!r:5} Pred:{!r:5} Correct?:{!r:5} Value:{:.4f} {}'.format(mode_str, series_uid, positive_bool, prediction_bool, correct_bool, probablity_float, center_irc))\n    total_count = sum(count_dict.values())\n    percent_dict = {k: v / (total_count or 1) * 100 for (k, v) in count_dict.items()}\n    precision = percent_dict['p'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fp'] or 1)\n    recall = percent_dict['r'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fn'] or 1)\n    percent_dict['f1'] = 2 * (precision * recall) / (precision + recall or 1)\n    log.info(mode_str + ' tp:{tp:.1f}%, tn:{tn:.1f}%, fp:{fp:.1f}%, fn:{fn:.1f}%'.format(**percent_dict))\n    log.info(mode_str + ' precision:{p:.3f}, recall:{r:.3f}, F1:{f1:.3f}'.format(**percent_dict))",
            "def logResults(self, mode_str, filtered_list, series2diagnosis_dict, positive_set):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    count_dict = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n    for series_uid in filtered_list:\n        (probablity_float, center_irc) = series2diagnosis_dict.get(series_uid, (0.0, None))\n        if center_irc is not None:\n            center_irc = tuple((int(x.item()) for x in center_irc))\n        positive_bool = series_uid in positive_set\n        prediction_bool = probablity_float > 0.5\n        correct_bool = positive_bool == prediction_bool\n        if positive_bool and prediction_bool:\n            count_dict['tp'] += 1\n        if not positive_bool and (not prediction_bool):\n            count_dict['tn'] += 1\n        if not positive_bool and prediction_bool:\n            count_dict['fp'] += 1\n        if positive_bool and (not prediction_bool):\n            count_dict['fn'] += 1\n        log.info('{} {} Label:{!r:5} Pred:{!r:5} Correct?:{!r:5} Value:{:.4f} {}'.format(mode_str, series_uid, positive_bool, prediction_bool, correct_bool, probablity_float, center_irc))\n    total_count = sum(count_dict.values())\n    percent_dict = {k: v / (total_count or 1) * 100 for (k, v) in count_dict.items()}\n    precision = percent_dict['p'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fp'] or 1)\n    recall = percent_dict['r'] = count_dict['tp'] / (count_dict['tp'] + count_dict['fn'] or 1)\n    percent_dict['f1'] = 2 * (precision * recall) / (precision + recall or 1)\n    log.info(mode_str + ' tp:{tp:.1f}%, tn:{tn:.1f}%, fp:{fp:.1f}%, fn:{fn:.1f}%'.format(**percent_dict))\n    log.info(mode_str + ' precision:{p:.3f}, recall:{r:.3f}, F1:{f1:.3f}'.format(**percent_dict))"
        ]
    }
]