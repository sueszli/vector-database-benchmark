[
    {
        "func_name": "depthwise_convolution_2d",
        "original": "def depthwise_convolution_2d(x, W, b=None, stride=1, pad=0):\n    \"\"\"Two-dimensional depthwise convolution function.\n\n    This is an implementation of two-dimensional depthwise convolution.\n    It takes two or three variables: the input image ``x``, the filter weight\n    ``W``, and optionally, the bias vector ``b``.\n\n    Notation: here is a notation for dimensionalities.\n\n    - :math:`n` is the batch size.\n    - :math:`c_I` is the number of the input.\n    - :math:`c_M` is the channel multiplier.\n    - :math:`h` and :math:`w` are the height and width of the input image,\n      respectively.\n    - :math:`h_O` and :math:`w_O` are the height and width of the output image,\n      respectively.\n    - :math:`k_H` and :math:`k_W` are the height and width of the filters,\n      respectively.\n\n    Args:\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\n            Input variable of shape :math:`(n, c_I, h, w)`.\n        W (:class:`~chainer.Variable` or :ref:`ndarray`):\n            Weight variable of shape :math:`(c_M, c_I, k_H, k_W)`.\n        b (:class:`~chainer.Variable` or :ref:`ndarray`):\n            Bias variable of length :math:`c_M * c_I` (optional).\n        stride (int or pair of ints): Stride of filter applications.\n            ``stride=s`` and ``stride=(s, s)`` are equivalent.\n        pad (int or pair of ints): Spatial padding width for input arrays.\n            ``pad=p`` and ``pad=(p, p)`` are equivalent.\n\n\n    Returns:\n        ~chainer.Variable:\n            Output variable. Its shape is :math:`(n, c_I * c_M, h_O, w_O)`.\n\n    Like ``Convolution2D``, ``DepthwiseConvolution2D`` function computes\n    correlations between filters and patches of size :math:`(k_H, k_W)` in\n    ``x``.\n    But unlike ``Convolution2D``, ``DepthwiseConvolution2D`` does not add up\n    input channels of filters but concatenates them.\n    For that reason, the shape of outputs of depthwise convolution are\n    :math:`(n, c_I * c_M, h_O, w_O)`, :math:`c_M` is called channel_multiplier.\n\n    :math:`(h_O, w_O)` is determined by the equivalent equation of\n    ``Convolution2D``.\n\n    If the bias vector is given, then it is added to all spatial locations of\n    the output of convolution.\n\n    See: `L. Sifre. Rigid-motion scattering for image classification\n    <https://www.di.ens.fr/data/publications/papers/phd_sifre.pdf>`_\n\n    .. seealso::\n\n        :class:`~chainer.links.DepthwiseConvolution2D`\n        to manage the model parameters ``W`` and ``b``.\n\n    .. admonition:: Example\n\n        >>> x = np.random.uniform(0, 1, (2, 3, 4, 7))\n        >>> W = np.random.uniform(0, 1, (2, 3, 3, 3))\n        >>> b = np.random.uniform(0, 1, (6,))\n        >>> y = F.depthwise_convolution_2d(x, W, b)\n        >>> y.shape\n        (2, 6, 2, 5)\n\n    \"\"\"\n    (multiplier, in_channels, kh, kw) = W.shape\n    F = chainer.functions\n    W = F.transpose(W, (1, 0, 2, 3))\n    W = F.reshape(W, (multiplier * in_channels, 1, kh, kw))\n    return F.convolution_2d(x, W, b, stride, pad, groups=in_channels)",
        "mutated": [
            "def depthwise_convolution_2d(x, W, b=None, stride=1, pad=0):\n    if False:\n        i = 10\n    'Two-dimensional depthwise convolution function.\\n\\n    This is an implementation of two-dimensional depthwise convolution.\\n    It takes two or three variables: the input image ``x``, the filter weight\\n    ``W``, and optionally, the bias vector ``b``.\\n\\n    Notation: here is a notation for dimensionalities.\\n\\n    - :math:`n` is the batch size.\\n    - :math:`c_I` is the number of the input.\\n    - :math:`c_M` is the channel multiplier.\\n    - :math:`h` and :math:`w` are the height and width of the input image,\\n      respectively.\\n    - :math:`h_O` and :math:`w_O` are the height and width of the output image,\\n      respectively.\\n    - :math:`k_H` and :math:`k_W` are the height and width of the filters,\\n      respectively.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable of shape :math:`(n, c_I, h, w)`.\\n        W (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Weight variable of shape :math:`(c_M, c_I, k_H, k_W)`.\\n        b (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Bias variable of length :math:`c_M * c_I` (optional).\\n        stride (int or pair of ints): Stride of filter applications.\\n            ``stride=s`` and ``stride=(s, s)`` are equivalent.\\n        pad (int or pair of ints): Spatial padding width for input arrays.\\n            ``pad=p`` and ``pad=(p, p)`` are equivalent.\\n\\n\\n    Returns:\\n        ~chainer.Variable:\\n            Output variable. Its shape is :math:`(n, c_I * c_M, h_O, w_O)`.\\n\\n    Like ``Convolution2D``, ``DepthwiseConvolution2D`` function computes\\n    correlations between filters and patches of size :math:`(k_H, k_W)` in\\n    ``x``.\\n    But unlike ``Convolution2D``, ``DepthwiseConvolution2D`` does not add up\\n    input channels of filters but concatenates them.\\n    For that reason, the shape of outputs of depthwise convolution are\\n    :math:`(n, c_I * c_M, h_O, w_O)`, :math:`c_M` is called channel_multiplier.\\n\\n    :math:`(h_O, w_O)` is determined by the equivalent equation of\\n    ``Convolution2D``.\\n\\n    If the bias vector is given, then it is added to all spatial locations of\\n    the output of convolution.\\n\\n    See: `L. Sifre. Rigid-motion scattering for image classification\\n    <https://www.di.ens.fr/data/publications/papers/phd_sifre.pdf>`_\\n\\n    .. seealso::\\n\\n        :class:`~chainer.links.DepthwiseConvolution2D`\\n        to manage the model parameters ``W`` and ``b``.\\n\\n    .. admonition:: Example\\n\\n        >>> x = np.random.uniform(0, 1, (2, 3, 4, 7))\\n        >>> W = np.random.uniform(0, 1, (2, 3, 3, 3))\\n        >>> b = np.random.uniform(0, 1, (6,))\\n        >>> y = F.depthwise_convolution_2d(x, W, b)\\n        >>> y.shape\\n        (2, 6, 2, 5)\\n\\n    '\n    (multiplier, in_channels, kh, kw) = W.shape\n    F = chainer.functions\n    W = F.transpose(W, (1, 0, 2, 3))\n    W = F.reshape(W, (multiplier * in_channels, 1, kh, kw))\n    return F.convolution_2d(x, W, b, stride, pad, groups=in_channels)",
            "def depthwise_convolution_2d(x, W, b=None, stride=1, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Two-dimensional depthwise convolution function.\\n\\n    This is an implementation of two-dimensional depthwise convolution.\\n    It takes two or three variables: the input image ``x``, the filter weight\\n    ``W``, and optionally, the bias vector ``b``.\\n\\n    Notation: here is a notation for dimensionalities.\\n\\n    - :math:`n` is the batch size.\\n    - :math:`c_I` is the number of the input.\\n    - :math:`c_M` is the channel multiplier.\\n    - :math:`h` and :math:`w` are the height and width of the input image,\\n      respectively.\\n    - :math:`h_O` and :math:`w_O` are the height and width of the output image,\\n      respectively.\\n    - :math:`k_H` and :math:`k_W` are the height and width of the filters,\\n      respectively.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable of shape :math:`(n, c_I, h, w)`.\\n        W (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Weight variable of shape :math:`(c_M, c_I, k_H, k_W)`.\\n        b (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Bias variable of length :math:`c_M * c_I` (optional).\\n        stride (int or pair of ints): Stride of filter applications.\\n            ``stride=s`` and ``stride=(s, s)`` are equivalent.\\n        pad (int or pair of ints): Spatial padding width for input arrays.\\n            ``pad=p`` and ``pad=(p, p)`` are equivalent.\\n\\n\\n    Returns:\\n        ~chainer.Variable:\\n            Output variable. Its shape is :math:`(n, c_I * c_M, h_O, w_O)`.\\n\\n    Like ``Convolution2D``, ``DepthwiseConvolution2D`` function computes\\n    correlations between filters and patches of size :math:`(k_H, k_W)` in\\n    ``x``.\\n    But unlike ``Convolution2D``, ``DepthwiseConvolution2D`` does not add up\\n    input channels of filters but concatenates them.\\n    For that reason, the shape of outputs of depthwise convolution are\\n    :math:`(n, c_I * c_M, h_O, w_O)`, :math:`c_M` is called channel_multiplier.\\n\\n    :math:`(h_O, w_O)` is determined by the equivalent equation of\\n    ``Convolution2D``.\\n\\n    If the bias vector is given, then it is added to all spatial locations of\\n    the output of convolution.\\n\\n    See: `L. Sifre. Rigid-motion scattering for image classification\\n    <https://www.di.ens.fr/data/publications/papers/phd_sifre.pdf>`_\\n\\n    .. seealso::\\n\\n        :class:`~chainer.links.DepthwiseConvolution2D`\\n        to manage the model parameters ``W`` and ``b``.\\n\\n    .. admonition:: Example\\n\\n        >>> x = np.random.uniform(0, 1, (2, 3, 4, 7))\\n        >>> W = np.random.uniform(0, 1, (2, 3, 3, 3))\\n        >>> b = np.random.uniform(0, 1, (6,))\\n        >>> y = F.depthwise_convolution_2d(x, W, b)\\n        >>> y.shape\\n        (2, 6, 2, 5)\\n\\n    '\n    (multiplier, in_channels, kh, kw) = W.shape\n    F = chainer.functions\n    W = F.transpose(W, (1, 0, 2, 3))\n    W = F.reshape(W, (multiplier * in_channels, 1, kh, kw))\n    return F.convolution_2d(x, W, b, stride, pad, groups=in_channels)",
            "def depthwise_convolution_2d(x, W, b=None, stride=1, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Two-dimensional depthwise convolution function.\\n\\n    This is an implementation of two-dimensional depthwise convolution.\\n    It takes two or three variables: the input image ``x``, the filter weight\\n    ``W``, and optionally, the bias vector ``b``.\\n\\n    Notation: here is a notation for dimensionalities.\\n\\n    - :math:`n` is the batch size.\\n    - :math:`c_I` is the number of the input.\\n    - :math:`c_M` is the channel multiplier.\\n    - :math:`h` and :math:`w` are the height and width of the input image,\\n      respectively.\\n    - :math:`h_O` and :math:`w_O` are the height and width of the output image,\\n      respectively.\\n    - :math:`k_H` and :math:`k_W` are the height and width of the filters,\\n      respectively.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable of shape :math:`(n, c_I, h, w)`.\\n        W (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Weight variable of shape :math:`(c_M, c_I, k_H, k_W)`.\\n        b (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Bias variable of length :math:`c_M * c_I` (optional).\\n        stride (int or pair of ints): Stride of filter applications.\\n            ``stride=s`` and ``stride=(s, s)`` are equivalent.\\n        pad (int or pair of ints): Spatial padding width for input arrays.\\n            ``pad=p`` and ``pad=(p, p)`` are equivalent.\\n\\n\\n    Returns:\\n        ~chainer.Variable:\\n            Output variable. Its shape is :math:`(n, c_I * c_M, h_O, w_O)`.\\n\\n    Like ``Convolution2D``, ``DepthwiseConvolution2D`` function computes\\n    correlations between filters and patches of size :math:`(k_H, k_W)` in\\n    ``x``.\\n    But unlike ``Convolution2D``, ``DepthwiseConvolution2D`` does not add up\\n    input channels of filters but concatenates them.\\n    For that reason, the shape of outputs of depthwise convolution are\\n    :math:`(n, c_I * c_M, h_O, w_O)`, :math:`c_M` is called channel_multiplier.\\n\\n    :math:`(h_O, w_O)` is determined by the equivalent equation of\\n    ``Convolution2D``.\\n\\n    If the bias vector is given, then it is added to all spatial locations of\\n    the output of convolution.\\n\\n    See: `L. Sifre. Rigid-motion scattering for image classification\\n    <https://www.di.ens.fr/data/publications/papers/phd_sifre.pdf>`_\\n\\n    .. seealso::\\n\\n        :class:`~chainer.links.DepthwiseConvolution2D`\\n        to manage the model parameters ``W`` and ``b``.\\n\\n    .. admonition:: Example\\n\\n        >>> x = np.random.uniform(0, 1, (2, 3, 4, 7))\\n        >>> W = np.random.uniform(0, 1, (2, 3, 3, 3))\\n        >>> b = np.random.uniform(0, 1, (6,))\\n        >>> y = F.depthwise_convolution_2d(x, W, b)\\n        >>> y.shape\\n        (2, 6, 2, 5)\\n\\n    '\n    (multiplier, in_channels, kh, kw) = W.shape\n    F = chainer.functions\n    W = F.transpose(W, (1, 0, 2, 3))\n    W = F.reshape(W, (multiplier * in_channels, 1, kh, kw))\n    return F.convolution_2d(x, W, b, stride, pad, groups=in_channels)",
            "def depthwise_convolution_2d(x, W, b=None, stride=1, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Two-dimensional depthwise convolution function.\\n\\n    This is an implementation of two-dimensional depthwise convolution.\\n    It takes two or three variables: the input image ``x``, the filter weight\\n    ``W``, and optionally, the bias vector ``b``.\\n\\n    Notation: here is a notation for dimensionalities.\\n\\n    - :math:`n` is the batch size.\\n    - :math:`c_I` is the number of the input.\\n    - :math:`c_M` is the channel multiplier.\\n    - :math:`h` and :math:`w` are the height and width of the input image,\\n      respectively.\\n    - :math:`h_O` and :math:`w_O` are the height and width of the output image,\\n      respectively.\\n    - :math:`k_H` and :math:`k_W` are the height and width of the filters,\\n      respectively.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable of shape :math:`(n, c_I, h, w)`.\\n        W (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Weight variable of shape :math:`(c_M, c_I, k_H, k_W)`.\\n        b (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Bias variable of length :math:`c_M * c_I` (optional).\\n        stride (int or pair of ints): Stride of filter applications.\\n            ``stride=s`` and ``stride=(s, s)`` are equivalent.\\n        pad (int or pair of ints): Spatial padding width for input arrays.\\n            ``pad=p`` and ``pad=(p, p)`` are equivalent.\\n\\n\\n    Returns:\\n        ~chainer.Variable:\\n            Output variable. Its shape is :math:`(n, c_I * c_M, h_O, w_O)`.\\n\\n    Like ``Convolution2D``, ``DepthwiseConvolution2D`` function computes\\n    correlations between filters and patches of size :math:`(k_H, k_W)` in\\n    ``x``.\\n    But unlike ``Convolution2D``, ``DepthwiseConvolution2D`` does not add up\\n    input channels of filters but concatenates them.\\n    For that reason, the shape of outputs of depthwise convolution are\\n    :math:`(n, c_I * c_M, h_O, w_O)`, :math:`c_M` is called channel_multiplier.\\n\\n    :math:`(h_O, w_O)` is determined by the equivalent equation of\\n    ``Convolution2D``.\\n\\n    If the bias vector is given, then it is added to all spatial locations of\\n    the output of convolution.\\n\\n    See: `L. Sifre. Rigid-motion scattering for image classification\\n    <https://www.di.ens.fr/data/publications/papers/phd_sifre.pdf>`_\\n\\n    .. seealso::\\n\\n        :class:`~chainer.links.DepthwiseConvolution2D`\\n        to manage the model parameters ``W`` and ``b``.\\n\\n    .. admonition:: Example\\n\\n        >>> x = np.random.uniform(0, 1, (2, 3, 4, 7))\\n        >>> W = np.random.uniform(0, 1, (2, 3, 3, 3))\\n        >>> b = np.random.uniform(0, 1, (6,))\\n        >>> y = F.depthwise_convolution_2d(x, W, b)\\n        >>> y.shape\\n        (2, 6, 2, 5)\\n\\n    '\n    (multiplier, in_channels, kh, kw) = W.shape\n    F = chainer.functions\n    W = F.transpose(W, (1, 0, 2, 3))\n    W = F.reshape(W, (multiplier * in_channels, 1, kh, kw))\n    return F.convolution_2d(x, W, b, stride, pad, groups=in_channels)",
            "def depthwise_convolution_2d(x, W, b=None, stride=1, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Two-dimensional depthwise convolution function.\\n\\n    This is an implementation of two-dimensional depthwise convolution.\\n    It takes two or three variables: the input image ``x``, the filter weight\\n    ``W``, and optionally, the bias vector ``b``.\\n\\n    Notation: here is a notation for dimensionalities.\\n\\n    - :math:`n` is the batch size.\\n    - :math:`c_I` is the number of the input.\\n    - :math:`c_M` is the channel multiplier.\\n    - :math:`h` and :math:`w` are the height and width of the input image,\\n      respectively.\\n    - :math:`h_O` and :math:`w_O` are the height and width of the output image,\\n      respectively.\\n    - :math:`k_H` and :math:`k_W` are the height and width of the filters,\\n      respectively.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable of shape :math:`(n, c_I, h, w)`.\\n        W (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Weight variable of shape :math:`(c_M, c_I, k_H, k_W)`.\\n        b (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Bias variable of length :math:`c_M * c_I` (optional).\\n        stride (int or pair of ints): Stride of filter applications.\\n            ``stride=s`` and ``stride=(s, s)`` are equivalent.\\n        pad (int or pair of ints): Spatial padding width for input arrays.\\n            ``pad=p`` and ``pad=(p, p)`` are equivalent.\\n\\n\\n    Returns:\\n        ~chainer.Variable:\\n            Output variable. Its shape is :math:`(n, c_I * c_M, h_O, w_O)`.\\n\\n    Like ``Convolution2D``, ``DepthwiseConvolution2D`` function computes\\n    correlations between filters and patches of size :math:`(k_H, k_W)` in\\n    ``x``.\\n    But unlike ``Convolution2D``, ``DepthwiseConvolution2D`` does not add up\\n    input channels of filters but concatenates them.\\n    For that reason, the shape of outputs of depthwise convolution are\\n    :math:`(n, c_I * c_M, h_O, w_O)`, :math:`c_M` is called channel_multiplier.\\n\\n    :math:`(h_O, w_O)` is determined by the equivalent equation of\\n    ``Convolution2D``.\\n\\n    If the bias vector is given, then it is added to all spatial locations of\\n    the output of convolution.\\n\\n    See: `L. Sifre. Rigid-motion scattering for image classification\\n    <https://www.di.ens.fr/data/publications/papers/phd_sifre.pdf>`_\\n\\n    .. seealso::\\n\\n        :class:`~chainer.links.DepthwiseConvolution2D`\\n        to manage the model parameters ``W`` and ``b``.\\n\\n    .. admonition:: Example\\n\\n        >>> x = np.random.uniform(0, 1, (2, 3, 4, 7))\\n        >>> W = np.random.uniform(0, 1, (2, 3, 3, 3))\\n        >>> b = np.random.uniform(0, 1, (6,))\\n        >>> y = F.depthwise_convolution_2d(x, W, b)\\n        >>> y.shape\\n        (2, 6, 2, 5)\\n\\n    '\n    (multiplier, in_channels, kh, kw) = W.shape\n    F = chainer.functions\n    W = F.transpose(W, (1, 0, 2, 3))\n    W = F.reshape(W, (multiplier * in_channels, 1, kh, kw))\n    return F.convolution_2d(x, W, b, stride, pad, groups=in_channels)"
        ]
    }
]