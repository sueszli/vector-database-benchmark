[
    {
        "func_name": "preprocess_mlp",
        "original": "def preprocess_mlp(dataset, log):\n    \"\"\"\n    For MLP:\n    - For numerical features, normalize them after null imputation. \n    - For categorical features, use one-hot encoding after null imputation. \n    \"\"\"\n    (cat_columns, num_columns) = ([], [])\n    shift_amount = 0\n    for (i, f) in enumerate(dataset.features):\n        if f.is_target:\n            shift_amount += 1\n            continue\n        elif f.is_categorical():\n            cat_columns.append(i - shift_amount)\n        else:\n            num_columns.append(i - shift_amount)\n    cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot_encoder', OneHotEncoder())])\n    num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())])\n    data_pipeline = ColumnTransformer([('categorical', cat_pipeline, cat_columns), ('numerical', num_pipeline, num_columns)])\n    data_pipeline.fit(np.concatenate([dataset.train.X, dataset.test.X], axis=0))\n    X_train = data_pipeline.transform(dataset.train.X)\n    X_test = data_pipeline.transform(dataset.test.X)\n    return (X_train, X_test)",
        "mutated": [
            "def preprocess_mlp(dataset, log):\n    if False:\n        i = 10\n    '\\n    For MLP:\\n    - For numerical features, normalize them after null imputation. \\n    - For categorical features, use one-hot encoding after null imputation. \\n    '\n    (cat_columns, num_columns) = ([], [])\n    shift_amount = 0\n    for (i, f) in enumerate(dataset.features):\n        if f.is_target:\n            shift_amount += 1\n            continue\n        elif f.is_categorical():\n            cat_columns.append(i - shift_amount)\n        else:\n            num_columns.append(i - shift_amount)\n    cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot_encoder', OneHotEncoder())])\n    num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())])\n    data_pipeline = ColumnTransformer([('categorical', cat_pipeline, cat_columns), ('numerical', num_pipeline, num_columns)])\n    data_pipeline.fit(np.concatenate([dataset.train.X, dataset.test.X], axis=0))\n    X_train = data_pipeline.transform(dataset.train.X)\n    X_test = data_pipeline.transform(dataset.test.X)\n    return (X_train, X_test)",
            "def preprocess_mlp(dataset, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    For MLP:\\n    - For numerical features, normalize them after null imputation. \\n    - For categorical features, use one-hot encoding after null imputation. \\n    '\n    (cat_columns, num_columns) = ([], [])\n    shift_amount = 0\n    for (i, f) in enumerate(dataset.features):\n        if f.is_target:\n            shift_amount += 1\n            continue\n        elif f.is_categorical():\n            cat_columns.append(i - shift_amount)\n        else:\n            num_columns.append(i - shift_amount)\n    cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot_encoder', OneHotEncoder())])\n    num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())])\n    data_pipeline = ColumnTransformer([('categorical', cat_pipeline, cat_columns), ('numerical', num_pipeline, num_columns)])\n    data_pipeline.fit(np.concatenate([dataset.train.X, dataset.test.X], axis=0))\n    X_train = data_pipeline.transform(dataset.train.X)\n    X_test = data_pipeline.transform(dataset.test.X)\n    return (X_train, X_test)",
            "def preprocess_mlp(dataset, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    For MLP:\\n    - For numerical features, normalize them after null imputation. \\n    - For categorical features, use one-hot encoding after null imputation. \\n    '\n    (cat_columns, num_columns) = ([], [])\n    shift_amount = 0\n    for (i, f) in enumerate(dataset.features):\n        if f.is_target:\n            shift_amount += 1\n            continue\n        elif f.is_categorical():\n            cat_columns.append(i - shift_amount)\n        else:\n            num_columns.append(i - shift_amount)\n    cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot_encoder', OneHotEncoder())])\n    num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())])\n    data_pipeline = ColumnTransformer([('categorical', cat_pipeline, cat_columns), ('numerical', num_pipeline, num_columns)])\n    data_pipeline.fit(np.concatenate([dataset.train.X, dataset.test.X], axis=0))\n    X_train = data_pipeline.transform(dataset.train.X)\n    X_test = data_pipeline.transform(dataset.test.X)\n    return (X_train, X_test)",
            "def preprocess_mlp(dataset, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    For MLP:\\n    - For numerical features, normalize them after null imputation. \\n    - For categorical features, use one-hot encoding after null imputation. \\n    '\n    (cat_columns, num_columns) = ([], [])\n    shift_amount = 0\n    for (i, f) in enumerate(dataset.features):\n        if f.is_target:\n            shift_amount += 1\n            continue\n        elif f.is_categorical():\n            cat_columns.append(i - shift_amount)\n        else:\n            num_columns.append(i - shift_amount)\n    cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot_encoder', OneHotEncoder())])\n    num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())])\n    data_pipeline = ColumnTransformer([('categorical', cat_pipeline, cat_columns), ('numerical', num_pipeline, num_columns)])\n    data_pipeline.fit(np.concatenate([dataset.train.X, dataset.test.X], axis=0))\n    X_train = data_pipeline.transform(dataset.train.X)\n    X_test = data_pipeline.transform(dataset.test.X)\n    return (X_train, X_test)",
            "def preprocess_mlp(dataset, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    For MLP:\\n    - For numerical features, normalize them after null imputation. \\n    - For categorical features, use one-hot encoding after null imputation. \\n    '\n    (cat_columns, num_columns) = ([], [])\n    shift_amount = 0\n    for (i, f) in enumerate(dataset.features):\n        if f.is_target:\n            shift_amount += 1\n            continue\n        elif f.is_categorical():\n            cat_columns.append(i - shift_amount)\n        else:\n            num_columns.append(i - shift_amount)\n    cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot_encoder', OneHotEncoder())])\n    num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')), ('standard_scaler', StandardScaler())])\n    data_pipeline = ColumnTransformer([('categorical', cat_pipeline, cat_columns), ('numerical', num_pipeline, num_columns)])\n    data_pipeline.fit(np.concatenate([dataset.train.X, dataset.test.X], axis=0))\n    X_train = data_pipeline.transform(dataset.train.X)\n    X_test = data_pipeline.transform(dataset.test.X)\n    return (X_train, X_test)"
        ]
    },
    {
        "func_name": "run_mlp",
        "original": "def run_mlp(dataset, config, tuner, log):\n    \"\"\"\n    Using the given tuner, tune a random forest within the given time constraint.\n    This function uses cross validation score as the feedback score to the tuner. \n    The search space on which tuners search on is defined above empirically as a global variable.\n    \"\"\"\n    (limit_type, trial_limit) = (config.framework_params['limit_type'], None)\n    if limit_type == 'ntrials':\n        trial_limit = int(config.framework_params['trial_limit'])\n    (X_train, X_test) = preprocess_mlp(dataset, log)\n    (y_train, y_test) = (dataset.train.y, dataset.test.y)\n    is_classification = config.type == 'classification'\n    estimator = MLPClassifier if is_classification else MLPRegressor\n    (best_score, best_params, best_model) = (None, None, None)\n    score_higher_better = True\n    tuner.update_search_space(SEARCH_SPACE)\n    start_time = time.time()\n    trial_count = 0\n    intermediate_scores = []\n    intermediate_best_scores = []\n    while True:\n        try:\n            (param_idx, cur_params) = tuner.generate_parameters()\n            if cur_params is not None and cur_params != {}:\n                trial_count += 1\n                train_params = cur_params.copy()\n                if 'TRIAL_BUDGET' in cur_params:\n                    train_params.pop('TRIAL_BUDGET')\n                log.info('Trial {}: \\n{}\\n'.format(param_idx, train_params))\n                cur_model = estimator(random_state=config.seed, **train_params)\n                cur_score = cross_val_score(cur_model, X_train, y_train)\n                cur_score = np.mean(cur_score)\n                if np.isnan(cur_score):\n                    cur_score = 0\n                log.info('Score: {}\\n'.format(cur_score))\n                if best_score is None or (score_higher_better and cur_score > best_score) or (not score_higher_better and cur_score < best_score):\n                    (best_score, best_params, best_model) = (cur_score, cur_params, cur_model)\n                intermediate_scores.append(cur_score)\n                intermediate_best_scores.append(best_score)\n                tuner.receive_trial_result(param_idx, cur_params, cur_score)\n            if limit_type == 'time':\n                current_time = time.time()\n                elapsed_time = current_time - start_time\n                if elapsed_time >= config.max_runtime_seconds:\n                    break\n            elif limit_type == 'ntrials':\n                if trial_count >= trial_limit:\n                    break\n        except:\n            break\n    tuner.handle_terminate()\n    log.info('Tuning done, the best parameters are:\\n{}\\n'.format(best_params))\n    with Timer() as training:\n        best_model.fit(X_train, y_train)\n    predictions = best_model.predict(X_test)\n    probabilities = best_model.predict_proba(X_test) if is_classification else None\n    return (probabilities, predictions, training, y_test, intermediate_scores, intermediate_best_scores)",
        "mutated": [
            "def run_mlp(dataset, config, tuner, log):\n    if False:\n        i = 10\n    '\\n    Using the given tuner, tune a random forest within the given time constraint.\\n    This function uses cross validation score as the feedback score to the tuner. \\n    The search space on which tuners search on is defined above empirically as a global variable.\\n    '\n    (limit_type, trial_limit) = (config.framework_params['limit_type'], None)\n    if limit_type == 'ntrials':\n        trial_limit = int(config.framework_params['trial_limit'])\n    (X_train, X_test) = preprocess_mlp(dataset, log)\n    (y_train, y_test) = (dataset.train.y, dataset.test.y)\n    is_classification = config.type == 'classification'\n    estimator = MLPClassifier if is_classification else MLPRegressor\n    (best_score, best_params, best_model) = (None, None, None)\n    score_higher_better = True\n    tuner.update_search_space(SEARCH_SPACE)\n    start_time = time.time()\n    trial_count = 0\n    intermediate_scores = []\n    intermediate_best_scores = []\n    while True:\n        try:\n            (param_idx, cur_params) = tuner.generate_parameters()\n            if cur_params is not None and cur_params != {}:\n                trial_count += 1\n                train_params = cur_params.copy()\n                if 'TRIAL_BUDGET' in cur_params:\n                    train_params.pop('TRIAL_BUDGET')\n                log.info('Trial {}: \\n{}\\n'.format(param_idx, train_params))\n                cur_model = estimator(random_state=config.seed, **train_params)\n                cur_score = cross_val_score(cur_model, X_train, y_train)\n                cur_score = np.mean(cur_score)\n                if np.isnan(cur_score):\n                    cur_score = 0\n                log.info('Score: {}\\n'.format(cur_score))\n                if best_score is None or (score_higher_better and cur_score > best_score) or (not score_higher_better and cur_score < best_score):\n                    (best_score, best_params, best_model) = (cur_score, cur_params, cur_model)\n                intermediate_scores.append(cur_score)\n                intermediate_best_scores.append(best_score)\n                tuner.receive_trial_result(param_idx, cur_params, cur_score)\n            if limit_type == 'time':\n                current_time = time.time()\n                elapsed_time = current_time - start_time\n                if elapsed_time >= config.max_runtime_seconds:\n                    break\n            elif limit_type == 'ntrials':\n                if trial_count >= trial_limit:\n                    break\n        except:\n            break\n    tuner.handle_terminate()\n    log.info('Tuning done, the best parameters are:\\n{}\\n'.format(best_params))\n    with Timer() as training:\n        best_model.fit(X_train, y_train)\n    predictions = best_model.predict(X_test)\n    probabilities = best_model.predict_proba(X_test) if is_classification else None\n    return (probabilities, predictions, training, y_test, intermediate_scores, intermediate_best_scores)",
            "def run_mlp(dataset, config, tuner, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Using the given tuner, tune a random forest within the given time constraint.\\n    This function uses cross validation score as the feedback score to the tuner. \\n    The search space on which tuners search on is defined above empirically as a global variable.\\n    '\n    (limit_type, trial_limit) = (config.framework_params['limit_type'], None)\n    if limit_type == 'ntrials':\n        trial_limit = int(config.framework_params['trial_limit'])\n    (X_train, X_test) = preprocess_mlp(dataset, log)\n    (y_train, y_test) = (dataset.train.y, dataset.test.y)\n    is_classification = config.type == 'classification'\n    estimator = MLPClassifier if is_classification else MLPRegressor\n    (best_score, best_params, best_model) = (None, None, None)\n    score_higher_better = True\n    tuner.update_search_space(SEARCH_SPACE)\n    start_time = time.time()\n    trial_count = 0\n    intermediate_scores = []\n    intermediate_best_scores = []\n    while True:\n        try:\n            (param_idx, cur_params) = tuner.generate_parameters()\n            if cur_params is not None and cur_params != {}:\n                trial_count += 1\n                train_params = cur_params.copy()\n                if 'TRIAL_BUDGET' in cur_params:\n                    train_params.pop('TRIAL_BUDGET')\n                log.info('Trial {}: \\n{}\\n'.format(param_idx, train_params))\n                cur_model = estimator(random_state=config.seed, **train_params)\n                cur_score = cross_val_score(cur_model, X_train, y_train)\n                cur_score = np.mean(cur_score)\n                if np.isnan(cur_score):\n                    cur_score = 0\n                log.info('Score: {}\\n'.format(cur_score))\n                if best_score is None or (score_higher_better and cur_score > best_score) or (not score_higher_better and cur_score < best_score):\n                    (best_score, best_params, best_model) = (cur_score, cur_params, cur_model)\n                intermediate_scores.append(cur_score)\n                intermediate_best_scores.append(best_score)\n                tuner.receive_trial_result(param_idx, cur_params, cur_score)\n            if limit_type == 'time':\n                current_time = time.time()\n                elapsed_time = current_time - start_time\n                if elapsed_time >= config.max_runtime_seconds:\n                    break\n            elif limit_type == 'ntrials':\n                if trial_count >= trial_limit:\n                    break\n        except:\n            break\n    tuner.handle_terminate()\n    log.info('Tuning done, the best parameters are:\\n{}\\n'.format(best_params))\n    with Timer() as training:\n        best_model.fit(X_train, y_train)\n    predictions = best_model.predict(X_test)\n    probabilities = best_model.predict_proba(X_test) if is_classification else None\n    return (probabilities, predictions, training, y_test, intermediate_scores, intermediate_best_scores)",
            "def run_mlp(dataset, config, tuner, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Using the given tuner, tune a random forest within the given time constraint.\\n    This function uses cross validation score as the feedback score to the tuner. \\n    The search space on which tuners search on is defined above empirically as a global variable.\\n    '\n    (limit_type, trial_limit) = (config.framework_params['limit_type'], None)\n    if limit_type == 'ntrials':\n        trial_limit = int(config.framework_params['trial_limit'])\n    (X_train, X_test) = preprocess_mlp(dataset, log)\n    (y_train, y_test) = (dataset.train.y, dataset.test.y)\n    is_classification = config.type == 'classification'\n    estimator = MLPClassifier if is_classification else MLPRegressor\n    (best_score, best_params, best_model) = (None, None, None)\n    score_higher_better = True\n    tuner.update_search_space(SEARCH_SPACE)\n    start_time = time.time()\n    trial_count = 0\n    intermediate_scores = []\n    intermediate_best_scores = []\n    while True:\n        try:\n            (param_idx, cur_params) = tuner.generate_parameters()\n            if cur_params is not None and cur_params != {}:\n                trial_count += 1\n                train_params = cur_params.copy()\n                if 'TRIAL_BUDGET' in cur_params:\n                    train_params.pop('TRIAL_BUDGET')\n                log.info('Trial {}: \\n{}\\n'.format(param_idx, train_params))\n                cur_model = estimator(random_state=config.seed, **train_params)\n                cur_score = cross_val_score(cur_model, X_train, y_train)\n                cur_score = np.mean(cur_score)\n                if np.isnan(cur_score):\n                    cur_score = 0\n                log.info('Score: {}\\n'.format(cur_score))\n                if best_score is None or (score_higher_better and cur_score > best_score) or (not score_higher_better and cur_score < best_score):\n                    (best_score, best_params, best_model) = (cur_score, cur_params, cur_model)\n                intermediate_scores.append(cur_score)\n                intermediate_best_scores.append(best_score)\n                tuner.receive_trial_result(param_idx, cur_params, cur_score)\n            if limit_type == 'time':\n                current_time = time.time()\n                elapsed_time = current_time - start_time\n                if elapsed_time >= config.max_runtime_seconds:\n                    break\n            elif limit_type == 'ntrials':\n                if trial_count >= trial_limit:\n                    break\n        except:\n            break\n    tuner.handle_terminate()\n    log.info('Tuning done, the best parameters are:\\n{}\\n'.format(best_params))\n    with Timer() as training:\n        best_model.fit(X_train, y_train)\n    predictions = best_model.predict(X_test)\n    probabilities = best_model.predict_proba(X_test) if is_classification else None\n    return (probabilities, predictions, training, y_test, intermediate_scores, intermediate_best_scores)",
            "def run_mlp(dataset, config, tuner, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Using the given tuner, tune a random forest within the given time constraint.\\n    This function uses cross validation score as the feedback score to the tuner. \\n    The search space on which tuners search on is defined above empirically as a global variable.\\n    '\n    (limit_type, trial_limit) = (config.framework_params['limit_type'], None)\n    if limit_type == 'ntrials':\n        trial_limit = int(config.framework_params['trial_limit'])\n    (X_train, X_test) = preprocess_mlp(dataset, log)\n    (y_train, y_test) = (dataset.train.y, dataset.test.y)\n    is_classification = config.type == 'classification'\n    estimator = MLPClassifier if is_classification else MLPRegressor\n    (best_score, best_params, best_model) = (None, None, None)\n    score_higher_better = True\n    tuner.update_search_space(SEARCH_SPACE)\n    start_time = time.time()\n    trial_count = 0\n    intermediate_scores = []\n    intermediate_best_scores = []\n    while True:\n        try:\n            (param_idx, cur_params) = tuner.generate_parameters()\n            if cur_params is not None and cur_params != {}:\n                trial_count += 1\n                train_params = cur_params.copy()\n                if 'TRIAL_BUDGET' in cur_params:\n                    train_params.pop('TRIAL_BUDGET')\n                log.info('Trial {}: \\n{}\\n'.format(param_idx, train_params))\n                cur_model = estimator(random_state=config.seed, **train_params)\n                cur_score = cross_val_score(cur_model, X_train, y_train)\n                cur_score = np.mean(cur_score)\n                if np.isnan(cur_score):\n                    cur_score = 0\n                log.info('Score: {}\\n'.format(cur_score))\n                if best_score is None or (score_higher_better and cur_score > best_score) or (not score_higher_better and cur_score < best_score):\n                    (best_score, best_params, best_model) = (cur_score, cur_params, cur_model)\n                intermediate_scores.append(cur_score)\n                intermediate_best_scores.append(best_score)\n                tuner.receive_trial_result(param_idx, cur_params, cur_score)\n            if limit_type == 'time':\n                current_time = time.time()\n                elapsed_time = current_time - start_time\n                if elapsed_time >= config.max_runtime_seconds:\n                    break\n            elif limit_type == 'ntrials':\n                if trial_count >= trial_limit:\n                    break\n        except:\n            break\n    tuner.handle_terminate()\n    log.info('Tuning done, the best parameters are:\\n{}\\n'.format(best_params))\n    with Timer() as training:\n        best_model.fit(X_train, y_train)\n    predictions = best_model.predict(X_test)\n    probabilities = best_model.predict_proba(X_test) if is_classification else None\n    return (probabilities, predictions, training, y_test, intermediate_scores, intermediate_best_scores)",
            "def run_mlp(dataset, config, tuner, log):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Using the given tuner, tune a random forest within the given time constraint.\\n    This function uses cross validation score as the feedback score to the tuner. \\n    The search space on which tuners search on is defined above empirically as a global variable.\\n    '\n    (limit_type, trial_limit) = (config.framework_params['limit_type'], None)\n    if limit_type == 'ntrials':\n        trial_limit = int(config.framework_params['trial_limit'])\n    (X_train, X_test) = preprocess_mlp(dataset, log)\n    (y_train, y_test) = (dataset.train.y, dataset.test.y)\n    is_classification = config.type == 'classification'\n    estimator = MLPClassifier if is_classification else MLPRegressor\n    (best_score, best_params, best_model) = (None, None, None)\n    score_higher_better = True\n    tuner.update_search_space(SEARCH_SPACE)\n    start_time = time.time()\n    trial_count = 0\n    intermediate_scores = []\n    intermediate_best_scores = []\n    while True:\n        try:\n            (param_idx, cur_params) = tuner.generate_parameters()\n            if cur_params is not None and cur_params != {}:\n                trial_count += 1\n                train_params = cur_params.copy()\n                if 'TRIAL_BUDGET' in cur_params:\n                    train_params.pop('TRIAL_BUDGET')\n                log.info('Trial {}: \\n{}\\n'.format(param_idx, train_params))\n                cur_model = estimator(random_state=config.seed, **train_params)\n                cur_score = cross_val_score(cur_model, X_train, y_train)\n                cur_score = np.mean(cur_score)\n                if np.isnan(cur_score):\n                    cur_score = 0\n                log.info('Score: {}\\n'.format(cur_score))\n                if best_score is None or (score_higher_better and cur_score > best_score) or (not score_higher_better and cur_score < best_score):\n                    (best_score, best_params, best_model) = (cur_score, cur_params, cur_model)\n                intermediate_scores.append(cur_score)\n                intermediate_best_scores.append(best_score)\n                tuner.receive_trial_result(param_idx, cur_params, cur_score)\n            if limit_type == 'time':\n                current_time = time.time()\n                elapsed_time = current_time - start_time\n                if elapsed_time >= config.max_runtime_seconds:\n                    break\n            elif limit_type == 'ntrials':\n                if trial_count >= trial_limit:\n                    break\n        except:\n            break\n    tuner.handle_terminate()\n    log.info('Tuning done, the best parameters are:\\n{}\\n'.format(best_params))\n    with Timer() as training:\n        best_model.fit(X_train, y_train)\n    predictions = best_model.predict(X_test)\n    probabilities = best_model.predict_proba(X_test) if is_classification else None\n    return (probabilities, predictions, training, y_test, intermediate_scores, intermediate_best_scores)"
        ]
    }
]