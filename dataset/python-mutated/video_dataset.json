[
    {
        "func_name": "get_dataset",
        "original": "def get_dataset(dataset_name, split_name, dataset_dir, file_pattern=None, data_type='tf_sequence_example', decode_video_frames=False):\n    \"\"\"Gets an instance of slim Dataset.\n\n  Args:\n    dataset_name: String, dataset name.\n    split_name: String, the train/val Split name.\n    dataset_dir: String, the directory of the dataset sources.\n    file_pattern: String, file pattern of SSTable.\n    data_type: String, data type. Currently supports 'tf_example' and\n      'annotated_image'.\n    decode_video_frames: Boolean, decode the images or not. Not decoding it here\n        is useful if we subsample later\n\n  Returns:\n    An instance of slim Dataset.\n\n  Raises:\n    ValueError: If the dataset_name or split_name is not recognized, or if\n      the dataset_type is not supported.\n  \"\"\"\n    if dataset_name not in _DATASETS_INFORMATION:\n        raise ValueError('The specified dataset is not supported yet.')\n    splits_to_sizes = _DATASETS_INFORMATION[dataset_name].splits_to_sizes\n    if split_name not in splits_to_sizes:\n        raise ValueError('data split name %s not recognized' % split_name)\n    num_classes = _DATASETS_INFORMATION[dataset_name].num_classes\n    ignore_label = _DATASETS_INFORMATION[dataset_name].ignore_label\n    if file_pattern is None:\n        file_pattern = _FILE_PATTERN\n    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n    if data_type == 'tf_sequence_example':\n        keys_to_context_features = {'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'), 'image/height': tf.FixedLenFeature((), tf.int64, default_value=0), 'image/width': tf.FixedLenFeature((), tf.int64, default_value=0), 'segmentation/object/format': tf.FixedLenFeature((), tf.string, default_value='png'), 'video_id': tf.FixedLenFeature((), tf.string, default_value='unknown')}\n        label_name = 'class' if dataset_name == 'davis_2016' else 'object'\n        keys_to_sequence_features = {'image/encoded': tf.FixedLenSequenceFeature((), dtype=tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string)}\n        items_to_handlers = {'height': tfexample_decoder.Tensor('image/height'), 'width': tfexample_decoder.Tensor('image/width'), 'video_id': tfexample_decoder.Tensor('video_id')}\n        if decode_video_frames:\n            decode_image_handler = tfexample_decoder.Image(image_key='image/encoded', format_key='image/format', channels=3, repeated=True)\n            items_to_handlers['image'] = decode_image_handler\n            decode_label_handler = tfexample_decoder.Image(image_key='segmentation/{}/encoded'.format(label_name), format_key='segmentation/{}/format'.format(label_name), channels=1, repeated=True)\n            items_to_handlers['labels_class'] = decode_label_handler\n        else:\n            items_to_handlers['image/encoded'] = tfexample_decoder.Tensor('image/encoded')\n            items_to_handlers['segmentation/object/encoded'] = tfexample_decoder.Tensor('segmentation/{}/encoded'.format(label_name))\n        decoder = tfsequence_example_decoder.TFSequenceExampleDecoder(keys_to_context_features, keys_to_sequence_features, items_to_handlers)\n    else:\n        raise ValueError('Unknown data type.')\n    size = splits_to_sizes[split_name]\n    if isinstance(size, collections.Sequence):\n        num_videos = size[0]\n        num_samples = size[1]\n    else:\n        num_videos = 0\n        num_samples = size\n    return dataset.Dataset(data_sources=file_pattern, reader=tf.TFRecordReader, decoder=decoder, num_samples=num_samples, num_videos=num_videos, items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, ignore_label=ignore_label, num_classes=num_classes, name=dataset_name, multi_label=True)",
        "mutated": [
            "def get_dataset(dataset_name, split_name, dataset_dir, file_pattern=None, data_type='tf_sequence_example', decode_video_frames=False):\n    if False:\n        i = 10\n    \"Gets an instance of slim Dataset.\\n\\n  Args:\\n    dataset_name: String, dataset name.\\n    split_name: String, the train/val Split name.\\n    dataset_dir: String, the directory of the dataset sources.\\n    file_pattern: String, file pattern of SSTable.\\n    data_type: String, data type. Currently supports 'tf_example' and\\n      'annotated_image'.\\n    decode_video_frames: Boolean, decode the images or not. Not decoding it here\\n        is useful if we subsample later\\n\\n  Returns:\\n    An instance of slim Dataset.\\n\\n  Raises:\\n    ValueError: If the dataset_name or split_name is not recognized, or if\\n      the dataset_type is not supported.\\n  \"\n    if dataset_name not in _DATASETS_INFORMATION:\n        raise ValueError('The specified dataset is not supported yet.')\n    splits_to_sizes = _DATASETS_INFORMATION[dataset_name].splits_to_sizes\n    if split_name not in splits_to_sizes:\n        raise ValueError('data split name %s not recognized' % split_name)\n    num_classes = _DATASETS_INFORMATION[dataset_name].num_classes\n    ignore_label = _DATASETS_INFORMATION[dataset_name].ignore_label\n    if file_pattern is None:\n        file_pattern = _FILE_PATTERN\n    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n    if data_type == 'tf_sequence_example':\n        keys_to_context_features = {'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'), 'image/height': tf.FixedLenFeature((), tf.int64, default_value=0), 'image/width': tf.FixedLenFeature((), tf.int64, default_value=0), 'segmentation/object/format': tf.FixedLenFeature((), tf.string, default_value='png'), 'video_id': tf.FixedLenFeature((), tf.string, default_value='unknown')}\n        label_name = 'class' if dataset_name == 'davis_2016' else 'object'\n        keys_to_sequence_features = {'image/encoded': tf.FixedLenSequenceFeature((), dtype=tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string)}\n        items_to_handlers = {'height': tfexample_decoder.Tensor('image/height'), 'width': tfexample_decoder.Tensor('image/width'), 'video_id': tfexample_decoder.Tensor('video_id')}\n        if decode_video_frames:\n            decode_image_handler = tfexample_decoder.Image(image_key='image/encoded', format_key='image/format', channels=3, repeated=True)\n            items_to_handlers['image'] = decode_image_handler\n            decode_label_handler = tfexample_decoder.Image(image_key='segmentation/{}/encoded'.format(label_name), format_key='segmentation/{}/format'.format(label_name), channels=1, repeated=True)\n            items_to_handlers['labels_class'] = decode_label_handler\n        else:\n            items_to_handlers['image/encoded'] = tfexample_decoder.Tensor('image/encoded')\n            items_to_handlers['segmentation/object/encoded'] = tfexample_decoder.Tensor('segmentation/{}/encoded'.format(label_name))\n        decoder = tfsequence_example_decoder.TFSequenceExampleDecoder(keys_to_context_features, keys_to_sequence_features, items_to_handlers)\n    else:\n        raise ValueError('Unknown data type.')\n    size = splits_to_sizes[split_name]\n    if isinstance(size, collections.Sequence):\n        num_videos = size[0]\n        num_samples = size[1]\n    else:\n        num_videos = 0\n        num_samples = size\n    return dataset.Dataset(data_sources=file_pattern, reader=tf.TFRecordReader, decoder=decoder, num_samples=num_samples, num_videos=num_videos, items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, ignore_label=ignore_label, num_classes=num_classes, name=dataset_name, multi_label=True)",
            "def get_dataset(dataset_name, split_name, dataset_dir, file_pattern=None, data_type='tf_sequence_example', decode_video_frames=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Gets an instance of slim Dataset.\\n\\n  Args:\\n    dataset_name: String, dataset name.\\n    split_name: String, the train/val Split name.\\n    dataset_dir: String, the directory of the dataset sources.\\n    file_pattern: String, file pattern of SSTable.\\n    data_type: String, data type. Currently supports 'tf_example' and\\n      'annotated_image'.\\n    decode_video_frames: Boolean, decode the images or not. Not decoding it here\\n        is useful if we subsample later\\n\\n  Returns:\\n    An instance of slim Dataset.\\n\\n  Raises:\\n    ValueError: If the dataset_name or split_name is not recognized, or if\\n      the dataset_type is not supported.\\n  \"\n    if dataset_name not in _DATASETS_INFORMATION:\n        raise ValueError('The specified dataset is not supported yet.')\n    splits_to_sizes = _DATASETS_INFORMATION[dataset_name].splits_to_sizes\n    if split_name not in splits_to_sizes:\n        raise ValueError('data split name %s not recognized' % split_name)\n    num_classes = _DATASETS_INFORMATION[dataset_name].num_classes\n    ignore_label = _DATASETS_INFORMATION[dataset_name].ignore_label\n    if file_pattern is None:\n        file_pattern = _FILE_PATTERN\n    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n    if data_type == 'tf_sequence_example':\n        keys_to_context_features = {'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'), 'image/height': tf.FixedLenFeature((), tf.int64, default_value=0), 'image/width': tf.FixedLenFeature((), tf.int64, default_value=0), 'segmentation/object/format': tf.FixedLenFeature((), tf.string, default_value='png'), 'video_id': tf.FixedLenFeature((), tf.string, default_value='unknown')}\n        label_name = 'class' if dataset_name == 'davis_2016' else 'object'\n        keys_to_sequence_features = {'image/encoded': tf.FixedLenSequenceFeature((), dtype=tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string)}\n        items_to_handlers = {'height': tfexample_decoder.Tensor('image/height'), 'width': tfexample_decoder.Tensor('image/width'), 'video_id': tfexample_decoder.Tensor('video_id')}\n        if decode_video_frames:\n            decode_image_handler = tfexample_decoder.Image(image_key='image/encoded', format_key='image/format', channels=3, repeated=True)\n            items_to_handlers['image'] = decode_image_handler\n            decode_label_handler = tfexample_decoder.Image(image_key='segmentation/{}/encoded'.format(label_name), format_key='segmentation/{}/format'.format(label_name), channels=1, repeated=True)\n            items_to_handlers['labels_class'] = decode_label_handler\n        else:\n            items_to_handlers['image/encoded'] = tfexample_decoder.Tensor('image/encoded')\n            items_to_handlers['segmentation/object/encoded'] = tfexample_decoder.Tensor('segmentation/{}/encoded'.format(label_name))\n        decoder = tfsequence_example_decoder.TFSequenceExampleDecoder(keys_to_context_features, keys_to_sequence_features, items_to_handlers)\n    else:\n        raise ValueError('Unknown data type.')\n    size = splits_to_sizes[split_name]\n    if isinstance(size, collections.Sequence):\n        num_videos = size[0]\n        num_samples = size[1]\n    else:\n        num_videos = 0\n        num_samples = size\n    return dataset.Dataset(data_sources=file_pattern, reader=tf.TFRecordReader, decoder=decoder, num_samples=num_samples, num_videos=num_videos, items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, ignore_label=ignore_label, num_classes=num_classes, name=dataset_name, multi_label=True)",
            "def get_dataset(dataset_name, split_name, dataset_dir, file_pattern=None, data_type='tf_sequence_example', decode_video_frames=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Gets an instance of slim Dataset.\\n\\n  Args:\\n    dataset_name: String, dataset name.\\n    split_name: String, the train/val Split name.\\n    dataset_dir: String, the directory of the dataset sources.\\n    file_pattern: String, file pattern of SSTable.\\n    data_type: String, data type. Currently supports 'tf_example' and\\n      'annotated_image'.\\n    decode_video_frames: Boolean, decode the images or not. Not decoding it here\\n        is useful if we subsample later\\n\\n  Returns:\\n    An instance of slim Dataset.\\n\\n  Raises:\\n    ValueError: If the dataset_name or split_name is not recognized, or if\\n      the dataset_type is not supported.\\n  \"\n    if dataset_name not in _DATASETS_INFORMATION:\n        raise ValueError('The specified dataset is not supported yet.')\n    splits_to_sizes = _DATASETS_INFORMATION[dataset_name].splits_to_sizes\n    if split_name not in splits_to_sizes:\n        raise ValueError('data split name %s not recognized' % split_name)\n    num_classes = _DATASETS_INFORMATION[dataset_name].num_classes\n    ignore_label = _DATASETS_INFORMATION[dataset_name].ignore_label\n    if file_pattern is None:\n        file_pattern = _FILE_PATTERN\n    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n    if data_type == 'tf_sequence_example':\n        keys_to_context_features = {'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'), 'image/height': tf.FixedLenFeature((), tf.int64, default_value=0), 'image/width': tf.FixedLenFeature((), tf.int64, default_value=0), 'segmentation/object/format': tf.FixedLenFeature((), tf.string, default_value='png'), 'video_id': tf.FixedLenFeature((), tf.string, default_value='unknown')}\n        label_name = 'class' if dataset_name == 'davis_2016' else 'object'\n        keys_to_sequence_features = {'image/encoded': tf.FixedLenSequenceFeature((), dtype=tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string)}\n        items_to_handlers = {'height': tfexample_decoder.Tensor('image/height'), 'width': tfexample_decoder.Tensor('image/width'), 'video_id': tfexample_decoder.Tensor('video_id')}\n        if decode_video_frames:\n            decode_image_handler = tfexample_decoder.Image(image_key='image/encoded', format_key='image/format', channels=3, repeated=True)\n            items_to_handlers['image'] = decode_image_handler\n            decode_label_handler = tfexample_decoder.Image(image_key='segmentation/{}/encoded'.format(label_name), format_key='segmentation/{}/format'.format(label_name), channels=1, repeated=True)\n            items_to_handlers['labels_class'] = decode_label_handler\n        else:\n            items_to_handlers['image/encoded'] = tfexample_decoder.Tensor('image/encoded')\n            items_to_handlers['segmentation/object/encoded'] = tfexample_decoder.Tensor('segmentation/{}/encoded'.format(label_name))\n        decoder = tfsequence_example_decoder.TFSequenceExampleDecoder(keys_to_context_features, keys_to_sequence_features, items_to_handlers)\n    else:\n        raise ValueError('Unknown data type.')\n    size = splits_to_sizes[split_name]\n    if isinstance(size, collections.Sequence):\n        num_videos = size[0]\n        num_samples = size[1]\n    else:\n        num_videos = 0\n        num_samples = size\n    return dataset.Dataset(data_sources=file_pattern, reader=tf.TFRecordReader, decoder=decoder, num_samples=num_samples, num_videos=num_videos, items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, ignore_label=ignore_label, num_classes=num_classes, name=dataset_name, multi_label=True)",
            "def get_dataset(dataset_name, split_name, dataset_dir, file_pattern=None, data_type='tf_sequence_example', decode_video_frames=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Gets an instance of slim Dataset.\\n\\n  Args:\\n    dataset_name: String, dataset name.\\n    split_name: String, the train/val Split name.\\n    dataset_dir: String, the directory of the dataset sources.\\n    file_pattern: String, file pattern of SSTable.\\n    data_type: String, data type. Currently supports 'tf_example' and\\n      'annotated_image'.\\n    decode_video_frames: Boolean, decode the images or not. Not decoding it here\\n        is useful if we subsample later\\n\\n  Returns:\\n    An instance of slim Dataset.\\n\\n  Raises:\\n    ValueError: If the dataset_name or split_name is not recognized, or if\\n      the dataset_type is not supported.\\n  \"\n    if dataset_name not in _DATASETS_INFORMATION:\n        raise ValueError('The specified dataset is not supported yet.')\n    splits_to_sizes = _DATASETS_INFORMATION[dataset_name].splits_to_sizes\n    if split_name not in splits_to_sizes:\n        raise ValueError('data split name %s not recognized' % split_name)\n    num_classes = _DATASETS_INFORMATION[dataset_name].num_classes\n    ignore_label = _DATASETS_INFORMATION[dataset_name].ignore_label\n    if file_pattern is None:\n        file_pattern = _FILE_PATTERN\n    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n    if data_type == 'tf_sequence_example':\n        keys_to_context_features = {'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'), 'image/height': tf.FixedLenFeature((), tf.int64, default_value=0), 'image/width': tf.FixedLenFeature((), tf.int64, default_value=0), 'segmentation/object/format': tf.FixedLenFeature((), tf.string, default_value='png'), 'video_id': tf.FixedLenFeature((), tf.string, default_value='unknown')}\n        label_name = 'class' if dataset_name == 'davis_2016' else 'object'\n        keys_to_sequence_features = {'image/encoded': tf.FixedLenSequenceFeature((), dtype=tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string)}\n        items_to_handlers = {'height': tfexample_decoder.Tensor('image/height'), 'width': tfexample_decoder.Tensor('image/width'), 'video_id': tfexample_decoder.Tensor('video_id')}\n        if decode_video_frames:\n            decode_image_handler = tfexample_decoder.Image(image_key='image/encoded', format_key='image/format', channels=3, repeated=True)\n            items_to_handlers['image'] = decode_image_handler\n            decode_label_handler = tfexample_decoder.Image(image_key='segmentation/{}/encoded'.format(label_name), format_key='segmentation/{}/format'.format(label_name), channels=1, repeated=True)\n            items_to_handlers['labels_class'] = decode_label_handler\n        else:\n            items_to_handlers['image/encoded'] = tfexample_decoder.Tensor('image/encoded')\n            items_to_handlers['segmentation/object/encoded'] = tfexample_decoder.Tensor('segmentation/{}/encoded'.format(label_name))\n        decoder = tfsequence_example_decoder.TFSequenceExampleDecoder(keys_to_context_features, keys_to_sequence_features, items_to_handlers)\n    else:\n        raise ValueError('Unknown data type.')\n    size = splits_to_sizes[split_name]\n    if isinstance(size, collections.Sequence):\n        num_videos = size[0]\n        num_samples = size[1]\n    else:\n        num_videos = 0\n        num_samples = size\n    return dataset.Dataset(data_sources=file_pattern, reader=tf.TFRecordReader, decoder=decoder, num_samples=num_samples, num_videos=num_videos, items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, ignore_label=ignore_label, num_classes=num_classes, name=dataset_name, multi_label=True)",
            "def get_dataset(dataset_name, split_name, dataset_dir, file_pattern=None, data_type='tf_sequence_example', decode_video_frames=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Gets an instance of slim Dataset.\\n\\n  Args:\\n    dataset_name: String, dataset name.\\n    split_name: String, the train/val Split name.\\n    dataset_dir: String, the directory of the dataset sources.\\n    file_pattern: String, file pattern of SSTable.\\n    data_type: String, data type. Currently supports 'tf_example' and\\n      'annotated_image'.\\n    decode_video_frames: Boolean, decode the images or not. Not decoding it here\\n        is useful if we subsample later\\n\\n  Returns:\\n    An instance of slim Dataset.\\n\\n  Raises:\\n    ValueError: If the dataset_name or split_name is not recognized, or if\\n      the dataset_type is not supported.\\n  \"\n    if dataset_name not in _DATASETS_INFORMATION:\n        raise ValueError('The specified dataset is not supported yet.')\n    splits_to_sizes = _DATASETS_INFORMATION[dataset_name].splits_to_sizes\n    if split_name not in splits_to_sizes:\n        raise ValueError('data split name %s not recognized' % split_name)\n    num_classes = _DATASETS_INFORMATION[dataset_name].num_classes\n    ignore_label = _DATASETS_INFORMATION[dataset_name].ignore_label\n    if file_pattern is None:\n        file_pattern = _FILE_PATTERN\n    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n    if data_type == 'tf_sequence_example':\n        keys_to_context_features = {'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'), 'image/height': tf.FixedLenFeature((), tf.int64, default_value=0), 'image/width': tf.FixedLenFeature((), tf.int64, default_value=0), 'segmentation/object/format': tf.FixedLenFeature((), tf.string, default_value='png'), 'video_id': tf.FixedLenFeature((), tf.string, default_value='unknown')}\n        label_name = 'class' if dataset_name == 'davis_2016' else 'object'\n        keys_to_sequence_features = {'image/encoded': tf.FixedLenSequenceFeature((), dtype=tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string), 'segmentation/{}/encoded'.format(label_name): tf.FixedLenSequenceFeature((), tf.string)}\n        items_to_handlers = {'height': tfexample_decoder.Tensor('image/height'), 'width': tfexample_decoder.Tensor('image/width'), 'video_id': tfexample_decoder.Tensor('video_id')}\n        if decode_video_frames:\n            decode_image_handler = tfexample_decoder.Image(image_key='image/encoded', format_key='image/format', channels=3, repeated=True)\n            items_to_handlers['image'] = decode_image_handler\n            decode_label_handler = tfexample_decoder.Image(image_key='segmentation/{}/encoded'.format(label_name), format_key='segmentation/{}/format'.format(label_name), channels=1, repeated=True)\n            items_to_handlers['labels_class'] = decode_label_handler\n        else:\n            items_to_handlers['image/encoded'] = tfexample_decoder.Tensor('image/encoded')\n            items_to_handlers['segmentation/object/encoded'] = tfexample_decoder.Tensor('segmentation/{}/encoded'.format(label_name))\n        decoder = tfsequence_example_decoder.TFSequenceExampleDecoder(keys_to_context_features, keys_to_sequence_features, items_to_handlers)\n    else:\n        raise ValueError('Unknown data type.')\n    size = splits_to_sizes[split_name]\n    if isinstance(size, collections.Sequence):\n        num_videos = size[0]\n        num_samples = size[1]\n    else:\n        num_videos = 0\n        num_samples = size\n    return dataset.Dataset(data_sources=file_pattern, reader=tf.TFRecordReader, decoder=decoder, num_samples=num_samples, num_videos=num_videos, items_to_descriptions=_ITEMS_TO_DESCRIPTIONS, ignore_label=ignore_label, num_classes=num_classes, name=dataset_name, multi_label=True)"
        ]
    }
]