[
    {
        "func_name": "name",
        "original": "@staticmethod\ndef name():\n    return 'tt_hubspot_bookmarks_static'",
        "mutated": [
            "@staticmethod\ndef name():\n    if False:\n        i = 10\n    return 'tt_hubspot_bookmarks_static'",
            "@staticmethod\ndef name():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return 'tt_hubspot_bookmarks_static'",
            "@staticmethod\ndef name():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return 'tt_hubspot_bookmarks_static'",
            "@staticmethod\ndef name():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return 'tt_hubspot_bookmarks_static'",
            "@staticmethod\ndef name():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return 'tt_hubspot_bookmarks_static'"
        ]
    },
    {
        "func_name": "streams_to_test",
        "original": "def streams_to_test(self):\n    \"\"\"expected streams minus the streams not under test\"\"\"\n    return STREAMS_WITHOUT_CREATES",
        "mutated": [
            "def streams_to_test(self):\n    if False:\n        i = 10\n    'expected streams minus the streams not under test'\n    return STREAMS_WITHOUT_CREATES",
            "def streams_to_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'expected streams minus the streams not under test'\n    return STREAMS_WITHOUT_CREATES",
            "def streams_to_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'expected streams minus the streams not under test'\n    return STREAMS_WITHOUT_CREATES",
            "def streams_to_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'expected streams minus the streams not under test'\n    return STREAMS_WITHOUT_CREATES",
            "def streams_to_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'expected streams minus the streams not under test'\n    return STREAMS_WITHOUT_CREATES"
        ]
    },
    {
        "func_name": "get_properties",
        "original": "def get_properties(self):\n    return {'start_date': '2017-11-22T00:00:00Z'}",
        "mutated": [
            "def get_properties(self):\n    if False:\n        i = 10\n    return {'start_date': '2017-11-22T00:00:00Z'}",
            "def get_properties(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return {'start_date': '2017-11-22T00:00:00Z'}",
            "def get_properties(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return {'start_date': '2017-11-22T00:00:00Z'}",
            "def get_properties(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return {'start_date': '2017-11-22T00:00:00Z'}",
            "def get_properties(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return {'start_date': '2017-11-22T00:00:00Z'}"
        ]
    },
    {
        "func_name": "setUp",
        "original": "def setUp(self):\n    self.maxDiff = None",
        "mutated": [
            "def setUp(self):\n    if False:\n        i = 10\n    self.maxDiff = None",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.maxDiff = None",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.maxDiff = None",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.maxDiff = None",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.maxDiff = None"
        ]
    },
    {
        "func_name": "test_run",
        "original": "def test_run(self):\n    expected_streams = self.streams_to_test()\n    conn_id = connections.ensure_connection(self)\n    found_catalogs = self.run_and_verify_check_mode(conn_id)\n    catalog_entries = [ce for ce in found_catalogs if ce['tap_stream_id'] in expected_streams]\n    for catalog_entry in catalog_entries:\n        stream_schema = menagerie.get_annotated_schema(conn_id, catalog_entry['stream_id'])\n        connections.select_catalog_and_fields_via_metadata(conn_id, catalog_entry, stream_schema)\n    first_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records = runner.get_records_from_target_output()\n    state_1 = menagerie.get_state(conn_id)\n    new_state = copy.deepcopy(state_1)\n    for stream in state_1['bookmarks'].keys():\n        if self.expected_replication_method()[stream] == self.INCREMENTAL:\n            calculated_bookmark_value = self.timedelta_formatted(state_1['bookmarks']['owners']['updatedAt'], days=-1, str_format=self.BASIC_DATE_FORMAT)\n    menagerie.set_state(conn_id, new_state)\n    second_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records_2 = runner.get_records_from_target_output()\n    state_2 = menagerie.get_state(conn_id)\n    for stream in expected_streams:\n        with self.subTest(stream=stream):\n            replication_method = self.expected_replication_method()[stream]\n            primary_keys = self.expected_primary_keys()[stream]\n            actual_record_count_2 = second_record_count_by_stream[stream]\n            actual_records_2 = [message['data'] for message in synced_records_2[stream]['messages'] if message['action'] == 'upsert']\n            actual_record_count_1 = first_record_count_by_stream[stream]\n            actual_records_1 = [message['data'] for message in synced_records[stream]['messages'] if message['action'] == 'upsert']\n            if replication_method == self.INCREMENTAL:\n                stream_replication_key = list(self.expected_replication_keys()[stream])[0]\n                bookmark_1 = state_1['bookmarks'][stream][stream_replication_key]\n                bookmark_2 = state_2['bookmarks'][stream][stream_replication_key]\n                self.assertEqual(bookmark_1, bookmark_2)\n                sync_1_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_1]\n                sync_2_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_2]\n                self.assertCountEqual(set(sync_1_pks), sync_1_pks)\n                self.assertCountEqual(set(sync_2_pks), sync_2_pks)\n                self.assertTrue(set(sync_2_pks).issubset(set(sync_1_pks)))\n                self.assertGreater(actual_record_count_1, actual_record_count_2)\n            elif replication_method == self.FULL:\n                self.assertEqual(actual_record_count_1, actual_record_count_2)\n                self.assertEqual(actual_records_1, actual_records_2)\n            else:\n                raise AssertionError(f'Replication method is {replication_method} for stream: {stream}')",
        "mutated": [
            "def test_run(self):\n    if False:\n        i = 10\n    expected_streams = self.streams_to_test()\n    conn_id = connections.ensure_connection(self)\n    found_catalogs = self.run_and_verify_check_mode(conn_id)\n    catalog_entries = [ce for ce in found_catalogs if ce['tap_stream_id'] in expected_streams]\n    for catalog_entry in catalog_entries:\n        stream_schema = menagerie.get_annotated_schema(conn_id, catalog_entry['stream_id'])\n        connections.select_catalog_and_fields_via_metadata(conn_id, catalog_entry, stream_schema)\n    first_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records = runner.get_records_from_target_output()\n    state_1 = menagerie.get_state(conn_id)\n    new_state = copy.deepcopy(state_1)\n    for stream in state_1['bookmarks'].keys():\n        if self.expected_replication_method()[stream] == self.INCREMENTAL:\n            calculated_bookmark_value = self.timedelta_formatted(state_1['bookmarks']['owners']['updatedAt'], days=-1, str_format=self.BASIC_DATE_FORMAT)\n    menagerie.set_state(conn_id, new_state)\n    second_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records_2 = runner.get_records_from_target_output()\n    state_2 = menagerie.get_state(conn_id)\n    for stream in expected_streams:\n        with self.subTest(stream=stream):\n            replication_method = self.expected_replication_method()[stream]\n            primary_keys = self.expected_primary_keys()[stream]\n            actual_record_count_2 = second_record_count_by_stream[stream]\n            actual_records_2 = [message['data'] for message in synced_records_2[stream]['messages'] if message['action'] == 'upsert']\n            actual_record_count_1 = first_record_count_by_stream[stream]\n            actual_records_1 = [message['data'] for message in synced_records[stream]['messages'] if message['action'] == 'upsert']\n            if replication_method == self.INCREMENTAL:\n                stream_replication_key = list(self.expected_replication_keys()[stream])[0]\n                bookmark_1 = state_1['bookmarks'][stream][stream_replication_key]\n                bookmark_2 = state_2['bookmarks'][stream][stream_replication_key]\n                self.assertEqual(bookmark_1, bookmark_2)\n                sync_1_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_1]\n                sync_2_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_2]\n                self.assertCountEqual(set(sync_1_pks), sync_1_pks)\n                self.assertCountEqual(set(sync_2_pks), sync_2_pks)\n                self.assertTrue(set(sync_2_pks).issubset(set(sync_1_pks)))\n                self.assertGreater(actual_record_count_1, actual_record_count_2)\n            elif replication_method == self.FULL:\n                self.assertEqual(actual_record_count_1, actual_record_count_2)\n                self.assertEqual(actual_records_1, actual_records_2)\n            else:\n                raise AssertionError(f'Replication method is {replication_method} for stream: {stream}')",
            "def test_run(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    expected_streams = self.streams_to_test()\n    conn_id = connections.ensure_connection(self)\n    found_catalogs = self.run_and_verify_check_mode(conn_id)\n    catalog_entries = [ce for ce in found_catalogs if ce['tap_stream_id'] in expected_streams]\n    for catalog_entry in catalog_entries:\n        stream_schema = menagerie.get_annotated_schema(conn_id, catalog_entry['stream_id'])\n        connections.select_catalog_and_fields_via_metadata(conn_id, catalog_entry, stream_schema)\n    first_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records = runner.get_records_from_target_output()\n    state_1 = menagerie.get_state(conn_id)\n    new_state = copy.deepcopy(state_1)\n    for stream in state_1['bookmarks'].keys():\n        if self.expected_replication_method()[stream] == self.INCREMENTAL:\n            calculated_bookmark_value = self.timedelta_formatted(state_1['bookmarks']['owners']['updatedAt'], days=-1, str_format=self.BASIC_DATE_FORMAT)\n    menagerie.set_state(conn_id, new_state)\n    second_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records_2 = runner.get_records_from_target_output()\n    state_2 = menagerie.get_state(conn_id)\n    for stream in expected_streams:\n        with self.subTest(stream=stream):\n            replication_method = self.expected_replication_method()[stream]\n            primary_keys = self.expected_primary_keys()[stream]\n            actual_record_count_2 = second_record_count_by_stream[stream]\n            actual_records_2 = [message['data'] for message in synced_records_2[stream]['messages'] if message['action'] == 'upsert']\n            actual_record_count_1 = first_record_count_by_stream[stream]\n            actual_records_1 = [message['data'] for message in synced_records[stream]['messages'] if message['action'] == 'upsert']\n            if replication_method == self.INCREMENTAL:\n                stream_replication_key = list(self.expected_replication_keys()[stream])[0]\n                bookmark_1 = state_1['bookmarks'][stream][stream_replication_key]\n                bookmark_2 = state_2['bookmarks'][stream][stream_replication_key]\n                self.assertEqual(bookmark_1, bookmark_2)\n                sync_1_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_1]\n                sync_2_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_2]\n                self.assertCountEqual(set(sync_1_pks), sync_1_pks)\n                self.assertCountEqual(set(sync_2_pks), sync_2_pks)\n                self.assertTrue(set(sync_2_pks).issubset(set(sync_1_pks)))\n                self.assertGreater(actual_record_count_1, actual_record_count_2)\n            elif replication_method == self.FULL:\n                self.assertEqual(actual_record_count_1, actual_record_count_2)\n                self.assertEqual(actual_records_1, actual_records_2)\n            else:\n                raise AssertionError(f'Replication method is {replication_method} for stream: {stream}')",
            "def test_run(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    expected_streams = self.streams_to_test()\n    conn_id = connections.ensure_connection(self)\n    found_catalogs = self.run_and_verify_check_mode(conn_id)\n    catalog_entries = [ce for ce in found_catalogs if ce['tap_stream_id'] in expected_streams]\n    for catalog_entry in catalog_entries:\n        stream_schema = menagerie.get_annotated_schema(conn_id, catalog_entry['stream_id'])\n        connections.select_catalog_and_fields_via_metadata(conn_id, catalog_entry, stream_schema)\n    first_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records = runner.get_records_from_target_output()\n    state_1 = menagerie.get_state(conn_id)\n    new_state = copy.deepcopy(state_1)\n    for stream in state_1['bookmarks'].keys():\n        if self.expected_replication_method()[stream] == self.INCREMENTAL:\n            calculated_bookmark_value = self.timedelta_formatted(state_1['bookmarks']['owners']['updatedAt'], days=-1, str_format=self.BASIC_DATE_FORMAT)\n    menagerie.set_state(conn_id, new_state)\n    second_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records_2 = runner.get_records_from_target_output()\n    state_2 = menagerie.get_state(conn_id)\n    for stream in expected_streams:\n        with self.subTest(stream=stream):\n            replication_method = self.expected_replication_method()[stream]\n            primary_keys = self.expected_primary_keys()[stream]\n            actual_record_count_2 = second_record_count_by_stream[stream]\n            actual_records_2 = [message['data'] for message in synced_records_2[stream]['messages'] if message['action'] == 'upsert']\n            actual_record_count_1 = first_record_count_by_stream[stream]\n            actual_records_1 = [message['data'] for message in synced_records[stream]['messages'] if message['action'] == 'upsert']\n            if replication_method == self.INCREMENTAL:\n                stream_replication_key = list(self.expected_replication_keys()[stream])[0]\n                bookmark_1 = state_1['bookmarks'][stream][stream_replication_key]\n                bookmark_2 = state_2['bookmarks'][stream][stream_replication_key]\n                self.assertEqual(bookmark_1, bookmark_2)\n                sync_1_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_1]\n                sync_2_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_2]\n                self.assertCountEqual(set(sync_1_pks), sync_1_pks)\n                self.assertCountEqual(set(sync_2_pks), sync_2_pks)\n                self.assertTrue(set(sync_2_pks).issubset(set(sync_1_pks)))\n                self.assertGreater(actual_record_count_1, actual_record_count_2)\n            elif replication_method == self.FULL:\n                self.assertEqual(actual_record_count_1, actual_record_count_2)\n                self.assertEqual(actual_records_1, actual_records_2)\n            else:\n                raise AssertionError(f'Replication method is {replication_method} for stream: {stream}')",
            "def test_run(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    expected_streams = self.streams_to_test()\n    conn_id = connections.ensure_connection(self)\n    found_catalogs = self.run_and_verify_check_mode(conn_id)\n    catalog_entries = [ce for ce in found_catalogs if ce['tap_stream_id'] in expected_streams]\n    for catalog_entry in catalog_entries:\n        stream_schema = menagerie.get_annotated_schema(conn_id, catalog_entry['stream_id'])\n        connections.select_catalog_and_fields_via_metadata(conn_id, catalog_entry, stream_schema)\n    first_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records = runner.get_records_from_target_output()\n    state_1 = menagerie.get_state(conn_id)\n    new_state = copy.deepcopy(state_1)\n    for stream in state_1['bookmarks'].keys():\n        if self.expected_replication_method()[stream] == self.INCREMENTAL:\n            calculated_bookmark_value = self.timedelta_formatted(state_1['bookmarks']['owners']['updatedAt'], days=-1, str_format=self.BASIC_DATE_FORMAT)\n    menagerie.set_state(conn_id, new_state)\n    second_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records_2 = runner.get_records_from_target_output()\n    state_2 = menagerie.get_state(conn_id)\n    for stream in expected_streams:\n        with self.subTest(stream=stream):\n            replication_method = self.expected_replication_method()[stream]\n            primary_keys = self.expected_primary_keys()[stream]\n            actual_record_count_2 = second_record_count_by_stream[stream]\n            actual_records_2 = [message['data'] for message in synced_records_2[stream]['messages'] if message['action'] == 'upsert']\n            actual_record_count_1 = first_record_count_by_stream[stream]\n            actual_records_1 = [message['data'] for message in synced_records[stream]['messages'] if message['action'] == 'upsert']\n            if replication_method == self.INCREMENTAL:\n                stream_replication_key = list(self.expected_replication_keys()[stream])[0]\n                bookmark_1 = state_1['bookmarks'][stream][stream_replication_key]\n                bookmark_2 = state_2['bookmarks'][stream][stream_replication_key]\n                self.assertEqual(bookmark_1, bookmark_2)\n                sync_1_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_1]\n                sync_2_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_2]\n                self.assertCountEqual(set(sync_1_pks), sync_1_pks)\n                self.assertCountEqual(set(sync_2_pks), sync_2_pks)\n                self.assertTrue(set(sync_2_pks).issubset(set(sync_1_pks)))\n                self.assertGreater(actual_record_count_1, actual_record_count_2)\n            elif replication_method == self.FULL:\n                self.assertEqual(actual_record_count_1, actual_record_count_2)\n                self.assertEqual(actual_records_1, actual_records_2)\n            else:\n                raise AssertionError(f'Replication method is {replication_method} for stream: {stream}')",
            "def test_run(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    expected_streams = self.streams_to_test()\n    conn_id = connections.ensure_connection(self)\n    found_catalogs = self.run_and_verify_check_mode(conn_id)\n    catalog_entries = [ce for ce in found_catalogs if ce['tap_stream_id'] in expected_streams]\n    for catalog_entry in catalog_entries:\n        stream_schema = menagerie.get_annotated_schema(conn_id, catalog_entry['stream_id'])\n        connections.select_catalog_and_fields_via_metadata(conn_id, catalog_entry, stream_schema)\n    first_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records = runner.get_records_from_target_output()\n    state_1 = menagerie.get_state(conn_id)\n    new_state = copy.deepcopy(state_1)\n    for stream in state_1['bookmarks'].keys():\n        if self.expected_replication_method()[stream] == self.INCREMENTAL:\n            calculated_bookmark_value = self.timedelta_formatted(state_1['bookmarks']['owners']['updatedAt'], days=-1, str_format=self.BASIC_DATE_FORMAT)\n    menagerie.set_state(conn_id, new_state)\n    second_record_count_by_stream = self.run_and_verify_sync(conn_id)\n    synced_records_2 = runner.get_records_from_target_output()\n    state_2 = menagerie.get_state(conn_id)\n    for stream in expected_streams:\n        with self.subTest(stream=stream):\n            replication_method = self.expected_replication_method()[stream]\n            primary_keys = self.expected_primary_keys()[stream]\n            actual_record_count_2 = second_record_count_by_stream[stream]\n            actual_records_2 = [message['data'] for message in synced_records_2[stream]['messages'] if message['action'] == 'upsert']\n            actual_record_count_1 = first_record_count_by_stream[stream]\n            actual_records_1 = [message['data'] for message in synced_records[stream]['messages'] if message['action'] == 'upsert']\n            if replication_method == self.INCREMENTAL:\n                stream_replication_key = list(self.expected_replication_keys()[stream])[0]\n                bookmark_1 = state_1['bookmarks'][stream][stream_replication_key]\n                bookmark_2 = state_2['bookmarks'][stream][stream_replication_key]\n                self.assertEqual(bookmark_1, bookmark_2)\n                sync_1_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_1]\n                sync_2_pks = [tuple([record[pk] for pk in primary_keys]) for record in actual_records_2]\n                self.assertCountEqual(set(sync_1_pks), sync_1_pks)\n                self.assertCountEqual(set(sync_2_pks), sync_2_pks)\n                self.assertTrue(set(sync_2_pks).issubset(set(sync_1_pks)))\n                self.assertGreater(actual_record_count_1, actual_record_count_2)\n            elif replication_method == self.FULL:\n                self.assertEqual(actual_record_count_1, actual_record_count_2)\n                self.assertEqual(actual_records_1, actual_records_2)\n            else:\n                raise AssertionError(f'Replication method is {replication_method} for stream: {stream}')"
        ]
    }
]