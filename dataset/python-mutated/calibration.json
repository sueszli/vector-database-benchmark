[
    {
        "func_name": "_correlation_matrix_using_hypersphere_decomposition",
        "original": "def _correlation_matrix_using_hypersphere_decomposition(num_assets, thetas, dtype=None):\n    \"\"\"Rebonato-Jaeckel method to generate valid correlation matrix.\n\n  The method returns a valid correlation matrix using the hypersphere\n  decomposition approach described in Ref [1].\n\n  #### References:\n  [1]: Riccardo Rebonato, Peter Jaeckel, The Most General Methodology to Create\n       a Valid Correlation Matrix for Risk Management and Option Pricing\n       Purposes.\n  https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1969689_code1760921.pdf?abstractid=1969689&mirid=1\n\n  Args:\n    num_assets: An integer `Tensor` specifying the number of correlated assets.\n    thetas: A real `Tensor` of shape `[num_assets * (num_assets - 1)]`\n      specifying the angles used for the construction of the correlation matrix.\n    dtype: The default dtype to use when converting values to `Tensor`s.\n      Default value: `None` which means that default dtypes inferred by\n        TensorFlow are used.\n\n  Returns:\n    A real `Tensor` of shape `(num_assets, num_assets)` containing the\n    correlation matrix derived from `thetas` using the hypersphere\n    decomposition method.\n  \"\"\"\n    thetas = tf.convert_to_tensor(thetas, dtype=dtype)\n    dtype = dtype or thetas.dtype\n    thetas = tf.reshape(thetas, shape=[num_assets, num_assets - 1])\n    cos_theta = tf.math.cos(thetas)\n    cos_theta = tf.concat([cos_theta, tf.ones([num_assets, 1], dtype=dtype)], axis=1)\n    sin_cumprod = tf.math.cumprod(tf.math.sin(thetas), axis=-1)\n    sin_cumprod = tf.concat([tf.ones([num_assets, 1], dtype=dtype), sin_cumprod], axis=1)\n    j = tf.expand_dims(tf.range(1, num_assets + 1), axis=0)\n    corr_matrix = tf.where(j < num_assets, cos_theta * sin_cumprod, sin_cumprod)\n    corr_matrix = tf.linalg.matmul(corr_matrix, corr_matrix, transpose_b=True)\n    return corr_matrix",
        "mutated": [
            "def _correlation_matrix_using_hypersphere_decomposition(num_assets, thetas, dtype=None):\n    if False:\n        i = 10\n    'Rebonato-Jaeckel method to generate valid correlation matrix.\\n\\n  The method returns a valid correlation matrix using the hypersphere\\n  decomposition approach described in Ref [1].\\n\\n  #### References:\\n  [1]: Riccardo Rebonato, Peter Jaeckel, The Most General Methodology to Create\\n       a Valid Correlation Matrix for Risk Management and Option Pricing\\n       Purposes.\\n  https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1969689_code1760921.pdf?abstractid=1969689&mirid=1\\n\\n  Args:\\n    num_assets: An integer `Tensor` specifying the number of correlated assets.\\n    thetas: A real `Tensor` of shape `[num_assets * (num_assets - 1)]`\\n      specifying the angles used for the construction of the correlation matrix.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n\\n  Returns:\\n    A real `Tensor` of shape `(num_assets, num_assets)` containing the\\n    correlation matrix derived from `thetas` using the hypersphere\\n    decomposition method.\\n  '\n    thetas = tf.convert_to_tensor(thetas, dtype=dtype)\n    dtype = dtype or thetas.dtype\n    thetas = tf.reshape(thetas, shape=[num_assets, num_assets - 1])\n    cos_theta = tf.math.cos(thetas)\n    cos_theta = tf.concat([cos_theta, tf.ones([num_assets, 1], dtype=dtype)], axis=1)\n    sin_cumprod = tf.math.cumprod(tf.math.sin(thetas), axis=-1)\n    sin_cumprod = tf.concat([tf.ones([num_assets, 1], dtype=dtype), sin_cumprod], axis=1)\n    j = tf.expand_dims(tf.range(1, num_assets + 1), axis=0)\n    corr_matrix = tf.where(j < num_assets, cos_theta * sin_cumprod, sin_cumprod)\n    corr_matrix = tf.linalg.matmul(corr_matrix, corr_matrix, transpose_b=True)\n    return corr_matrix",
            "def _correlation_matrix_using_hypersphere_decomposition(num_assets, thetas, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Rebonato-Jaeckel method to generate valid correlation matrix.\\n\\n  The method returns a valid correlation matrix using the hypersphere\\n  decomposition approach described in Ref [1].\\n\\n  #### References:\\n  [1]: Riccardo Rebonato, Peter Jaeckel, The Most General Methodology to Create\\n       a Valid Correlation Matrix for Risk Management and Option Pricing\\n       Purposes.\\n  https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1969689_code1760921.pdf?abstractid=1969689&mirid=1\\n\\n  Args:\\n    num_assets: An integer `Tensor` specifying the number of correlated assets.\\n    thetas: A real `Tensor` of shape `[num_assets * (num_assets - 1)]`\\n      specifying the angles used for the construction of the correlation matrix.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n\\n  Returns:\\n    A real `Tensor` of shape `(num_assets, num_assets)` containing the\\n    correlation matrix derived from `thetas` using the hypersphere\\n    decomposition method.\\n  '\n    thetas = tf.convert_to_tensor(thetas, dtype=dtype)\n    dtype = dtype or thetas.dtype\n    thetas = tf.reshape(thetas, shape=[num_assets, num_assets - 1])\n    cos_theta = tf.math.cos(thetas)\n    cos_theta = tf.concat([cos_theta, tf.ones([num_assets, 1], dtype=dtype)], axis=1)\n    sin_cumprod = tf.math.cumprod(tf.math.sin(thetas), axis=-1)\n    sin_cumprod = tf.concat([tf.ones([num_assets, 1], dtype=dtype), sin_cumprod], axis=1)\n    j = tf.expand_dims(tf.range(1, num_assets + 1), axis=0)\n    corr_matrix = tf.where(j < num_assets, cos_theta * sin_cumprod, sin_cumprod)\n    corr_matrix = tf.linalg.matmul(corr_matrix, corr_matrix, transpose_b=True)\n    return corr_matrix",
            "def _correlation_matrix_using_hypersphere_decomposition(num_assets, thetas, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Rebonato-Jaeckel method to generate valid correlation matrix.\\n\\n  The method returns a valid correlation matrix using the hypersphere\\n  decomposition approach described in Ref [1].\\n\\n  #### References:\\n  [1]: Riccardo Rebonato, Peter Jaeckel, The Most General Methodology to Create\\n       a Valid Correlation Matrix for Risk Management and Option Pricing\\n       Purposes.\\n  https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1969689_code1760921.pdf?abstractid=1969689&mirid=1\\n\\n  Args:\\n    num_assets: An integer `Tensor` specifying the number of correlated assets.\\n    thetas: A real `Tensor` of shape `[num_assets * (num_assets - 1)]`\\n      specifying the angles used for the construction of the correlation matrix.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n\\n  Returns:\\n    A real `Tensor` of shape `(num_assets, num_assets)` containing the\\n    correlation matrix derived from `thetas` using the hypersphere\\n    decomposition method.\\n  '\n    thetas = tf.convert_to_tensor(thetas, dtype=dtype)\n    dtype = dtype or thetas.dtype\n    thetas = tf.reshape(thetas, shape=[num_assets, num_assets - 1])\n    cos_theta = tf.math.cos(thetas)\n    cos_theta = tf.concat([cos_theta, tf.ones([num_assets, 1], dtype=dtype)], axis=1)\n    sin_cumprod = tf.math.cumprod(tf.math.sin(thetas), axis=-1)\n    sin_cumprod = tf.concat([tf.ones([num_assets, 1], dtype=dtype), sin_cumprod], axis=1)\n    j = tf.expand_dims(tf.range(1, num_assets + 1), axis=0)\n    corr_matrix = tf.where(j < num_assets, cos_theta * sin_cumprod, sin_cumprod)\n    corr_matrix = tf.linalg.matmul(corr_matrix, corr_matrix, transpose_b=True)\n    return corr_matrix",
            "def _correlation_matrix_using_hypersphere_decomposition(num_assets, thetas, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Rebonato-Jaeckel method to generate valid correlation matrix.\\n\\n  The method returns a valid correlation matrix using the hypersphere\\n  decomposition approach described in Ref [1].\\n\\n  #### References:\\n  [1]: Riccardo Rebonato, Peter Jaeckel, The Most General Methodology to Create\\n       a Valid Correlation Matrix for Risk Management and Option Pricing\\n       Purposes.\\n  https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1969689_code1760921.pdf?abstractid=1969689&mirid=1\\n\\n  Args:\\n    num_assets: An integer `Tensor` specifying the number of correlated assets.\\n    thetas: A real `Tensor` of shape `[num_assets * (num_assets - 1)]`\\n      specifying the angles used for the construction of the correlation matrix.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n\\n  Returns:\\n    A real `Tensor` of shape `(num_assets, num_assets)` containing the\\n    correlation matrix derived from `thetas` using the hypersphere\\n    decomposition method.\\n  '\n    thetas = tf.convert_to_tensor(thetas, dtype=dtype)\n    dtype = dtype or thetas.dtype\n    thetas = tf.reshape(thetas, shape=[num_assets, num_assets - 1])\n    cos_theta = tf.math.cos(thetas)\n    cos_theta = tf.concat([cos_theta, tf.ones([num_assets, 1], dtype=dtype)], axis=1)\n    sin_cumprod = tf.math.cumprod(tf.math.sin(thetas), axis=-1)\n    sin_cumprod = tf.concat([tf.ones([num_assets, 1], dtype=dtype), sin_cumprod], axis=1)\n    j = tf.expand_dims(tf.range(1, num_assets + 1), axis=0)\n    corr_matrix = tf.where(j < num_assets, cos_theta * sin_cumprod, sin_cumprod)\n    corr_matrix = tf.linalg.matmul(corr_matrix, corr_matrix, transpose_b=True)\n    return corr_matrix",
            "def _correlation_matrix_using_hypersphere_decomposition(num_assets, thetas, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Rebonato-Jaeckel method to generate valid correlation matrix.\\n\\n  The method returns a valid correlation matrix using the hypersphere\\n  decomposition approach described in Ref [1].\\n\\n  #### References:\\n  [1]: Riccardo Rebonato, Peter Jaeckel, The Most General Methodology to Create\\n       a Valid Correlation Matrix for Risk Management and Option Pricing\\n       Purposes.\\n  https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1969689_code1760921.pdf?abstractid=1969689&mirid=1\\n\\n  Args:\\n    num_assets: An integer `Tensor` specifying the number of correlated assets.\\n    thetas: A real `Tensor` of shape `[num_assets * (num_assets - 1)]`\\n      specifying the angles used for the construction of the correlation matrix.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n\\n  Returns:\\n    A real `Tensor` of shape `(num_assets, num_assets)` containing the\\n    correlation matrix derived from `thetas` using the hypersphere\\n    decomposition method.\\n  '\n    thetas = tf.convert_to_tensor(thetas, dtype=dtype)\n    dtype = dtype or thetas.dtype\n    thetas = tf.reshape(thetas, shape=[num_assets, num_assets - 1])\n    cos_theta = tf.math.cos(thetas)\n    cos_theta = tf.concat([cos_theta, tf.ones([num_assets, 1], dtype=dtype)], axis=1)\n    sin_cumprod = tf.math.cumprod(tf.math.sin(thetas), axis=-1)\n    sin_cumprod = tf.concat([tf.ones([num_assets, 1], dtype=dtype), sin_cumprod], axis=1)\n    j = tf.expand_dims(tf.range(1, num_assets + 1), axis=0)\n    corr_matrix = tf.where(j < num_assets, cos_theta * sin_cumprod, sin_cumprod)\n    corr_matrix = tf.linalg.matmul(corr_matrix, corr_matrix, transpose_b=True)\n    return corr_matrix"
        ]
    },
    {
        "func_name": "_price_to_normal_vol",
        "original": "def _price_to_normal_vol(x, swap_rate, annuity):\n    vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n    return vols",
        "mutated": [
            "def _price_to_normal_vol(x, swap_rate, annuity):\n    if False:\n        i = 10\n    vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n    return vols",
            "def _price_to_normal_vol(x, swap_rate, annuity):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n    return vols",
            "def _price_to_normal_vol(x, swap_rate, annuity):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n    return vols",
            "def _price_to_normal_vol(x, swap_rate, annuity):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n    return vols",
            "def _price_to_normal_vol(x, swap_rate, annuity):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n    return vols"
        ]
    },
    {
        "func_name": "_scale",
        "original": "def _scale(x, lb, ub):\n    return (x - lb) / (ub - lb)",
        "mutated": [
            "def _scale(x, lb, ub):\n    if False:\n        i = 10\n    return (x - lb) / (ub - lb)",
            "def _scale(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return (x - lb) / (ub - lb)",
            "def _scale(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return (x - lb) / (ub - lb)",
            "def _scale(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return (x - lb) / (ub - lb)",
            "def _scale(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return (x - lb) / (ub - lb)"
        ]
    },
    {
        "func_name": "_to_unconstrained",
        "original": "def _to_unconstrained(x, lb, ub):\n    x = _scale(x, lb, ub)\n    return -tf.math.log((1.0 - x) / x)",
        "mutated": [
            "def _to_unconstrained(x, lb, ub):\n    if False:\n        i = 10\n    x = _scale(x, lb, ub)\n    return -tf.math.log((1.0 - x) / x)",
            "def _to_unconstrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    x = _scale(x, lb, ub)\n    return -tf.math.log((1.0 - x) / x)",
            "def _to_unconstrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    x = _scale(x, lb, ub)\n    return -tf.math.log((1.0 - x) / x)",
            "def _to_unconstrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    x = _scale(x, lb, ub)\n    return -tf.math.log((1.0 - x) / x)",
            "def _to_unconstrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    x = _scale(x, lb, ub)\n    return -tf.math.log((1.0 - x) / x)"
        ]
    },
    {
        "func_name": "_to_constrained",
        "original": "def _to_constrained(x, lb, ub):\n    x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n    return x * (ub - lb) + lb",
        "mutated": [
            "def _to_constrained(x, lb, ub):\n    if False:\n        i = 10\n    x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n    return x * (ub - lb) + lb",
            "def _to_constrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n    return x * (ub - lb) + lb",
            "def _to_constrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n    return x * (ub - lb) + lb",
            "def _to_constrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n    return x * (ub - lb) + lb",
            "def _to_constrained(x, lb, ub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n    return x * (ub - lb) + lb"
        ]
    },
    {
        "func_name": "loss_function",
        "original": "@make_val_and_grad_fn\ndef loss_function(x):\n    \"\"\"Loss function for the optimization.\"\"\"\n    x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n    x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n    if calibrate_correlation:\n        thetas = x[..., 2 * num_hjm_factors:]\n        thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n        x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n    else:\n        x_corr = None\n    volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n    model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n    if volatility_based_calibration:\n        model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n        model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n    value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n    return value",
        "mutated": [
            "@make_val_and_grad_fn\ndef loss_function(x):\n    if False:\n        i = 10\n    'Loss function for the optimization.'\n    x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n    x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n    if calibrate_correlation:\n        thetas = x[..., 2 * num_hjm_factors:]\n        thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n        x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n    else:\n        x_corr = None\n    volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n    model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n    if volatility_based_calibration:\n        model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n        model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n    value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n    return value",
            "@make_val_and_grad_fn\ndef loss_function(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Loss function for the optimization.'\n    x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n    x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n    if calibrate_correlation:\n        thetas = x[..., 2 * num_hjm_factors:]\n        thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n        x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n    else:\n        x_corr = None\n    volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n    model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n    if volatility_based_calibration:\n        model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n        model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n    value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n    return value",
            "@make_val_and_grad_fn\ndef loss_function(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Loss function for the optimization.'\n    x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n    x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n    if calibrate_correlation:\n        thetas = x[..., 2 * num_hjm_factors:]\n        thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n        x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n    else:\n        x_corr = None\n    volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n    model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n    if volatility_based_calibration:\n        model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n        model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n    value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n    return value",
            "@make_val_and_grad_fn\ndef loss_function(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Loss function for the optimization.'\n    x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n    x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n    if calibrate_correlation:\n        thetas = x[..., 2 * num_hjm_factors:]\n        thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n        x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n    else:\n        x_corr = None\n    volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n    model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n    if volatility_based_calibration:\n        model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n        model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n    value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n    return value",
            "@make_val_and_grad_fn\ndef loss_function(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Loss function for the optimization.'\n    x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n    x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n    if calibrate_correlation:\n        thetas = x[..., 2 * num_hjm_factors:]\n        thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n        x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n    else:\n        x_corr = None\n    volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n    model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n    if volatility_based_calibration:\n        model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n        model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n    value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n    return value"
        ]
    },
    {
        "func_name": "calibration_from_swaptions",
        "original": "def calibration_from_swaptions(*, prices: types.RealTensor, expiries: types.RealTensor, floating_leg_start_times: types.RealTensor, floating_leg_end_times: types.RealTensor, fixed_leg_payment_times: types.RealTensor, floating_leg_daycount_fractions: types.RealTensor, fixed_leg_daycount_fractions: types.RealTensor, fixed_leg_coupon: types.RealTensor, reference_rate_fn: Callable[..., types.RealTensor], num_hjm_factors: types.RealTensor, mean_reversion: types.RealTensor, volatility: types.RealTensor, notional: types.RealTensor=None, is_payer_swaption: types.BoolTensor=None, swaption_valuation_method: vm.ValuationMethod=None, num_samples: types.IntTensor=1, random_type: random.RandomType=None, seed: types.IntTensor=None, skip: types.IntTensor=0, times: types.RealTensor=None, time_step: types.RealTensor=None, num_time_steps: types.IntTensor=None, curve_times: types.RealTensor=None, time_step_finite_difference: types.RealTensor=None, num_grid_points_finite_difference: types.IntTensor=101, volatility_based_calibration: bool=True, calibrate_correlation: bool=True, optimizer_fn: Callable[..., types.RealTensor]=None, mean_reversion_lower_bound: types.RealTensor=0.001, mean_reversion_upper_bound: types.RealTensor=0.5, volatility_lower_bound: types.RealTensor=1e-05, volatility_upper_bound: types.RealTensor=0.1, tolerance: types.RealTensor=1e-06, maximum_iterations: types.IntTensor=50, dtype: tf.DType=None, name: str=None) -> Tuple[CalibrationResult, types.BoolTensor, types.IntTensor]:\n    \"\"\"Calibrates a batch of HJM models using European Swaption prices.\n\n  This function estimates the mean-reversion rates, volatility and correlation\n  parameters of a multi factor HJM model using a set of European swaption\n  prices as the target. The calibration is performed using least-squares\n  optimization where the loss function minimizes the squared error between the\n  target swaption prices (or volatilities) and the model implied swaption\n  prices (or volatilities). The current calibration supports constant mean\n  reversion, volatility and correlation parameters.\n\n  #### Example\n  The example shows how to calibrate a Two factor HJM model with constant mean\n  reversion rate and constant volatility.\n\n  ````python\n  import numpy as np\n  import tensorflow.compat.v2 as tf\n  import tf_quant_finance as tff\n\n  dtype = tf.float64\n\n  expiries = np.array(\n      [0.5, 0.5, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 10., 10.])\n  float_leg_start_times = np.array([\n      [0.5, 1.0, 1.5, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5],  # 6M x 2Y  swap\n      [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],  # 6M x 5Y  swap\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],  # 1Y x 2Y  swap\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5],  # 1Y x 5Y  swap\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],  # 2Y x 2Y  swap\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5],  # 2Y x 5Y  swap\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],  # 3Y x 2Y  swap\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5],  # 3Y x 5Y  swap\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],  # 4Y x 2Y  swap\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5],  # 4Y x 5Y  swap\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0],  # 5Y x 2Y  swap\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5],  # 5Y x 5Y  swap\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.0, 12.0, 12.0, 12.0,\n       12.0],  # 10Y x 2Y  swap\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0,\n       14.5]  # 10Y x 5Y  swap\n  ])\n  float_leg_end_times = float_leg_start_times + 0.5\n  max_maturities = np.array(\n      [2.5, 5.5, 3.0, 6.0, 4., 7., 5., 8., 6., 9., 7., 10., 12., 15.])\n  for i in range(float_leg_end_times.shape[0]):\n    float_leg_end_times[i] = np.clip(\n        float_leg_end_times[i], 0.0, max_maturities[i])\n\n  fixed_leg_payment_times = float_leg_end_times\n  float_leg_daycount_fractions = (\n      float_leg_end_times - float_leg_start_times)\n  fixed_leg_daycount_fractions = float_leg_daycount_fractions\n  fixed_leg_coupon = 0.01 * np.ones_like(fixed_leg_payment_times)\n\n  zero_rate_fn = lambda x: 0.01 * tf.ones_like(x, dtype=dtype)\n  notional = 1.0\n  prices = np.array([\n      0.42919881, 0.98046542, 0.59045074, 1.34909391, 0.79491583,\n      1.81768802, 0.93210461, 2.13625342, 1.05114573, 2.40921088,\n      1.12941064, 2.58857507, 1.37029637, 3.15081683])\n\n  (calibrated_mr, calibrated_vol, calibrated_corr), _, _ = (\n  tff.models.hjm.calibration_from_swaptions(\n      prices=prices,\n      expiries=expiries,\n      floating_leg_start_times=float_leg_start_times,\n      floating_leg_end_times=float_leg_end_times,\n      fixed_leg_payment_times=fixed_leg_payment_times,\n      floating_leg_daycount_fractions=float_leg_daycount_fractions,\n      fixed_leg_daycount_fractions=fixed_leg_daycount_fractions,\n      fixed_leg_coupon=fixed_leg_coupon,\n      reference_rate_fn=zero_rate_fn,\n      notional=100.,\n      mean_reversion=[0.01, 0.01],  # Initial guess for mean reversion rate\n      volatility=[0.005, 0.004],  # Initial guess for volatility\n      volatility_based_calibration=True,\n      calibrate_correlation=True,\n      num_samples=2000,\n      time_step=0.1,\n      random_type=random.RandomType.STATELESS_ANTITHETIC,\n      seed=[0,0],\n      maximum_iterations=50,\n      dtype=dtype))\n  # Expected calibrated_mr: [0.00621303, 0.3601772]\n  # Expected calibrated_vol: [0.00586125, 0.00384013]\n  # Expected correlation: 0.65126492\n  # Prices using calibrated model: [\n      0.42939121, 0.95362327, 0.59186236, 1.32622752, 0.79575526,\n      1.80457544, 0.93909176, 2.14336776, 1.04132595, 2.39385229,\n      1.11770416, 2.58809336, 1.39557389, 3.29306317]\n  ````\n\n  Args:\n    prices: An N-D real `Tensor` of shape `batch_shape + [k]`. `batch_shape` is\n      the shape of the batch of models to calibrate and `k` is the number of\n      swaptions per calibration. The input represents the prices of swaptions\n      used for calibration.\n    expiries: A real `Tensor` of same shape and dtype as `prices`. The time to\n      expiration of the swaptions.\n    floating_leg_start_times: A real `Tensor` of the same dtype as `prices`. The\n      times when accrual begins for each payment in the floating leg. The shape\n      of this input should be `expiries.shape + [m]` where `m` denotes the\n      number of floating payments in each leg.\n    floating_leg_end_times: A real `Tensor` of the same dtype as `prices`. The\n      times when accrual ends for each payment in the floating leg. The shape of\n      this input should be `expiries.shape + [m]` where `m` denotes the number\n      of floating payments in each leg.\n    fixed_leg_payment_times: A real `Tensor` of the same dtype as `prices`. The\n      payment times for each payment in the fixed leg. The shape of this input\n      should be `expiries.shape + [n]` where `n` denotes the number of fixed\n      payments in each leg.\n    floating_leg_daycount_fractions: A real `Tensor` of the same dtype and\n      compatible shape as `floating_leg_start_times`. The daycount fractions for\n      each payment in the floating leg.\n    fixed_leg_daycount_fractions: A real `Tensor` of the same dtype and\n      compatible shape as `fixed_leg_payment_times`. The daycount fractions for\n      each payment in the fixed leg.\n    fixed_leg_coupon: A real `Tensor` of the same dtype and compatible shape as\n      `fixed_leg_payment_times`. The fixed rate for each payment in the fixed\n      leg.\n    reference_rate_fn: A Python callable that accepts expiry time as a real\n      `Tensor` and returns a `Tensor` of shape `input_shape`. Returns\n      the continuously compounded zero rate at the present time for the input\n      expiry time.\n    num_hjm_factors: A Python scalar which corresponds to the number of factors\n      in the batch of calibrated HJM models.\n    mean_reversion: A real positive `Tensor` of same dtype as `prices` and shape\n      `batch_shape  + [num_hjm_factors]`. Corresponds to the initial values of\n      the mean reversion rates of the factors for calibration.\n    volatility: A real positive `Tensor` of the same `dtype` and shape as\n      `mean_reversion`. Corresponds to the initial values of the volatility of\n      the factors for calibration.\n    notional: An optional `Tensor` of same dtype and compatible shape as\n      `strikes`specifying the notional amount for the underlying swap.\n       Default value: None in which case the notional is set to 1.\n    is_payer_swaption: A boolean `Tensor` of a shape compatible with `expiries`.\n      Indicates whether the prices correspond to payer (if True) or receiver (if\n      False) swaption. If not supplied, payer swaptions are assumed.\n    swaption_valuation_method: An enum of type\n      `valuation_method.ValuationMethod` specifying the method to be used for\n      swaption valuation during calibration. Currently the valuation is\n      supported using `MONTE_CARLO` and `FINITE_DIFFERENCE` methods. Valuation\n      using finite difference is only supported for Gaussian HJM models, i.e.\n      for models with constant mean-reversion rate and time-dependent\n      volatility.\n      Default value: `valuation_method.ValuationMethod.MONTE_CARLO`, in which\n      case swaption valuation is done using Monte Carlo simulations.\n    num_samples: Positive scalar `int32` `Tensor`. The number of simulation\n      paths during Monte-Carlo valuation of swaptions. This input is ignored\n      during analytic valuation.\n      Default value: The default value is 1.\n    random_type: Enum value of `RandomType`. The type of (quasi)-random number\n      generator to use to generate the simulation paths. This input is relevant\n      only for Monte-Carlo valuation and ignored during analytic valuation.\n      Default value: `None` which maps to the standard pseudo-random numbers.\n    seed: Seed for the random number generator. The seed is only relevant if\n      `random_type` is one of `[STATELESS, PSEUDO, HALTON_RANDOMIZED,\n      PSEUDO_ANTITHETIC, STATELESS_ANTITHETIC]`. For `PSEUDO`,\n      `PSEUDO_ANTITHETIC` and `HALTON_RANDOMIZED` the seed should be an Python\n      integer. For `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as\n      an integer `Tensor` of shape `[2]`. This input is relevant only for\n      Monte-Carlo valuation and ignored during analytic valuation.\n      Default value: `None` which means no seed is set.\n    skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\n      Halton sequence to skip. Used only when `random_type` is 'SOBOL',\n      'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\n      Default value: `0`.\n    times: An optional rank 1 `Tensor` of increasing positive real values. The\n      times at which Monte Carlo simulations are performed. Relevant when\n      swaption valuation is done using Monte Calro simulations.\n      Default value: `None` in which case simulation times are computed based\n      on either `time_step` or `num_time_steps` inputs.\n    time_step: Scalar real `Tensor`. Maximal distance between time grid points\n      in Euler scheme. Relevant when Euler scheme is used for simulation. This\n      input is ignored during analytic valuation.\n      Default value: `None`.\n    num_time_steps: An optional scalar integer `Tensor` - a total number of\n      time steps during Monte Carlo simulations. The maximal distance betwen\n      points in grid is bounded by\n      `times[-1] / (num_time_steps - times.shape[0])`.\n      Either this or `time_step` should be supplied when the valuation method\n      is Monte Carlo.\n      Default value: `None`.\n    curve_times: An optional rank 1 `Tensor` of positive real values. The\n      maturities at which spot discount curve is computed during simulations.\n      Default value: `None` in which case `curve_times` is computed based on\n      swaption expities and `fixed_leg_payments_times` inputs.\n    time_step_finite_difference: Scalar real `Tensor`. Spacing between time\n      grid points in finite difference discretization. This input is only\n      relevant for valuation using finite difference.\n      Default value: `None`, in which case a `time_step` corresponding to 100\n      discrete steps is used.\n    num_grid_points_finite_difference: Scalar real `Tensor`. Number of spatial\n      grid points for discretization. This input is only relevant for valuation\n      using finite difference.\n      Default value: 100.\n    volatility_based_calibration: An optional Python boolean specifying whether\n      calibration is performed using swaption implied volatilities. If the input\n      is `True`, then the swaption prices are first converted to normal implied\n      volatilities and calibration is performed by minimizing the error between\n      input implied volatilities and model implied volatilities.\n      Default value: True.\n    calibrate_correlation: An optional Python boolean specifying if the\n      correlation matrix between HJM factors should calibrated. If the input is\n      `False`, then the model is calibrated assuming that the HJM factors are\n      uncorrelated.\n      Default value: True.\n    optimizer_fn: Optional Python callable which implements the algorithm used\n      to minimize the objective function during calibration. It should have\n      the following interface:\n      result = optimizer_fn(value_and_gradients_function, initial_position,\n        tolerance, max_iterations)\n      `value_and_gradients_function` is a Python callable that accepts a point\n      as a real `Tensor` and returns a tuple of `Tensor`s of real dtype\n      containing the value of the function and its gradient at that point.\n      'initial_position' is a real `Tensor` containing the starting point of\n      the optimization, 'tolerance' is a real scalar `Tensor` for stopping\n      tolerance for the procedure and `max_iterations` specifies the maximum\n      number of iterations.\n      `optimizer_fn` should return a namedtuple containing the items: `position`\n      (a tensor containing the optimal value), `converged` (a boolean\n      indicating whether the optimize converged according the specified\n      criteria), `failed` (a boolean indicating if the optimization resulted\n      in a failure), `num_iterations` (the number of iterations used), and\n      `objective_value` ( the value of the objective function at the optimal\n      value). The default value for `optimizer_fn` is None and conjugate\n      gradient algorithm is used.\n    mean_reversion_lower_bound: An optional scalar `Tensor` specifying the lower\n      limit of mean reversion rate during calibration.\n      Default value: 0.001.\n    mean_reversion_upper_bound: An optional scalar `Tensor` specifying the upper\n      limit of mean reversion rate during calibration.\n      Default value: 0.5.\n    volatility_lower_bound: An optional scalar `Tensor` specifying the lower\n      limit of volatility during calibration.\n      Default value: 0.00001 (0.1 basis points).\n    volatility_upper_bound: An optional scalar `Tensor` specifying the upper\n      limit of volatility during calibration.\n      Default value: 0.1.\n    tolerance: Scalar `Tensor` of real dtype. The absolute tolerance for\n      terminating the iterations.\n      Default value: 1e-6.\n    maximum_iterations: Scalar positive int32 `Tensor`. The maximum number of\n      iterations during the optimization.\n      Default value: 50.\n    dtype: The default dtype to use when converting values to `Tensor`s.\n      Default value: `None` which means that default dtypes inferred by\n        TensorFlow are used.\n    name: Python string. The name to give to the ops created by this function.\n      Default value: `None` which maps to the default name\n        `hjm_swaption_calibration`.\n\n  Returns:\n    A Tuple of three elements:\n    * The first element is an instance of `CalibrationResult` whose parameters\n      are calibrated to the input swaption prices.\n    * A `Tensor` of optimization status for each batch element (whether the\n      optimization algorithm has found the optimal point based on the specified\n      convergance criteria).\n    * A `Tensor` containing the number of iterations performed by the\n      optimization algorithm.\n  \"\"\"\n    del floating_leg_daycount_fractions\n    name = name or 'hjm_swaption_calibration'\n    with tf.name_scope(name):\n        prices = tf.convert_to_tensor(prices, dtype=dtype, name='prices')\n        dtype = dtype or prices.dtype\n        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n        float_leg_start_times = tf.convert_to_tensor(floating_leg_start_times, dtype=dtype, name='float_leg_start_times')\n        float_leg_end_times = tf.convert_to_tensor(floating_leg_end_times, dtype=dtype, name='float_leg_end_times')\n        fixed_leg_payment_times = tf.convert_to_tensor(fixed_leg_payment_times, dtype=dtype, name='fixed_leg_payment_times')\n        fixed_leg_daycount_fractions = tf.convert_to_tensor(fixed_leg_daycount_fractions, dtype=dtype, name='fixed_leg_daycount_fractions')\n        fixed_leg_coupon = tf.convert_to_tensor(fixed_leg_coupon, dtype=dtype, name='fixed_leg_coupon')\n        if times is None:\n            (times, _) = tf.unique(tf.reshape(expiries, [-1]))\n            times = tf.sort(times, name='sort_times')\n        else:\n            times = tf.convert_to_tensor(times, dtype=dtype)\n        if curve_times is None:\n            tau = fixed_leg_payment_times - tf.expand_dims(expiries, axis=-1)\n            (curve_times, _) = tf.unique(tf.reshape(tau, [-1]))\n            curve_times = tf.sort(curve_times)\n        else:\n            curve_times = tf.convert_to_tensor(curve_times, dtype=dtype)\n        notional = tf.convert_to_tensor(notional, dtype=dtype, name='notional')\n        vol_lb = tf.convert_to_tensor(volatility_lower_bound, dtype=dtype)\n        vol_ub = tf.convert_to_tensor(volatility_upper_bound, dtype=dtype)\n        mr_lb = tf.convert_to_tensor(mean_reversion_lower_bound, dtype=dtype)\n        mr_ub = tf.convert_to_tensor(mean_reversion_upper_bound, dtype=dtype)\n        theta_lb = tf.convert_to_tensor(0, dtype=dtype)\n        theta_ub = tf.convert_to_tensor(_THETA_UB, dtype=dtype)\n        mean_reversion = tf.convert_to_tensor(mean_reversion, dtype=dtype)\n        volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n        swaption_valuation_method = swaption_valuation_method or vm.ValuationMethod.MONTE_CARLO\n        if optimizer_fn is None:\n            optimizer_fn = optimizer.conjugate_gradient_minimize\n\n        def _price_to_normal_vol(x, swap_rate, annuity):\n            vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n            return vols\n        if volatility_based_calibration:\n            batch_shape = tf.shape(prices)[:-1]\n            batch_size = tf.math.reduce_prod(batch_shape)\n            num_instruments = tf.shape(prices)[-1]\n            (swap_rate, annuity) = swap.ir_swap_par_rate_and_annuity(float_leg_start_times, float_leg_end_times, fixed_leg_payment_times, fixed_leg_daycount_fractions, reference_rate_fn)\n            swap_rate = tf.reshape(swap_rate, [batch_size, batch_size, num_instruments])\n            annuity = tf.reshape(annuity, [batch_size, batch_size, num_instruments])\n            indices = tf.stack([tf.range(batch_size, dtype=tf.int32), tf.range(batch_size, dtype=tf.int32)], axis=-1)\n            swap_rate = tf.gather_nd(swap_rate, indices)\n            annuity = tf.gather_nd(annuity, indices)\n            swap_rate = tf.reshape(swap_rate, tf.shape(prices))\n            annuity = tf.reshape(annuity, tf.shape(prices))\n            target_values = _price_to_normal_vol(prices, swap_rate, annuity)\n        else:\n            target_values = prices\n        with tf.control_dependencies([target_values]):\n            tf.debugging.assert_all_finite(target_values, 'Conversion to implied vols resulted in failure for input swaption prices.')\n        target_lb = tf.constant(0.0, dtype=dtype)\n        target_ub = tf.math.reduce_max(target_values)\n\n        def _scale(x, lb, ub):\n            return (x - lb) / (ub - lb)\n\n        def _to_unconstrained(x, lb, ub):\n            x = _scale(x, lb, ub)\n            return -tf.math.log((1.0 - x) / x)\n\n        def _to_constrained(x, lb, ub):\n            x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n            return x * (ub - lb) + lb\n        if calibrate_correlation:\n            num_thetas = num_hjm_factors * (num_hjm_factors - 1)\n            init_corr = tf.range(0.1, num_thetas + 0.1, dtype=dtype) / num_thetas\n        else:\n            init_corr = []\n            if mean_reversion.shape.rank > 1:\n                init_corr = [[]] * mean_reversion.shape.rank\n        initial_guess = tf.concat([_to_unconstrained(mean_reversion, mr_lb, mr_ub), _to_unconstrained(volatility, vol_lb, vol_ub), _to_unconstrained(init_corr, theta_lb, theta_ub)], axis=-1)\n        scaled_target = _scale(target_values, target_lb, target_ub)\n\n        @make_val_and_grad_fn\n        def loss_function(x):\n            \"\"\"Loss function for the optimization.\"\"\"\n            x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n            x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n            if calibrate_correlation:\n                thetas = x[..., 2 * num_hjm_factors:]\n                thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n                x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n            else:\n                x_corr = None\n            volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n            model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n            if volatility_based_calibration:\n                model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n                model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n            value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n            return value\n        optimization_result = optimizer_fn(loss_function, initial_position=initial_guess, tolerance=tolerance, max_iterations=maximum_iterations)\n        calibrated_parameters = optimization_result.position\n        mean_reversion_calibrated = _to_constrained(calibrated_parameters[..., :num_hjm_factors], mr_lb, mr_ub)\n        volatility_calibrated = _to_constrained(calibrated_parameters[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n        if calibrate_correlation:\n            correlation_calibrated = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(calibrated_parameters[..., 2 * num_hjm_factors:], theta_lb, theta_ub))\n        else:\n            correlation_calibrated = None\n        return (CalibrationResult(mean_reversion=mean_reversion_calibrated, volatility=volatility_calibrated, corr_matrix=correlation_calibrated), optimization_result.converged, optimization_result.num_iterations)",
        "mutated": [
            "def calibration_from_swaptions(*, prices: types.RealTensor, expiries: types.RealTensor, floating_leg_start_times: types.RealTensor, floating_leg_end_times: types.RealTensor, fixed_leg_payment_times: types.RealTensor, floating_leg_daycount_fractions: types.RealTensor, fixed_leg_daycount_fractions: types.RealTensor, fixed_leg_coupon: types.RealTensor, reference_rate_fn: Callable[..., types.RealTensor], num_hjm_factors: types.RealTensor, mean_reversion: types.RealTensor, volatility: types.RealTensor, notional: types.RealTensor=None, is_payer_swaption: types.BoolTensor=None, swaption_valuation_method: vm.ValuationMethod=None, num_samples: types.IntTensor=1, random_type: random.RandomType=None, seed: types.IntTensor=None, skip: types.IntTensor=0, times: types.RealTensor=None, time_step: types.RealTensor=None, num_time_steps: types.IntTensor=None, curve_times: types.RealTensor=None, time_step_finite_difference: types.RealTensor=None, num_grid_points_finite_difference: types.IntTensor=101, volatility_based_calibration: bool=True, calibrate_correlation: bool=True, optimizer_fn: Callable[..., types.RealTensor]=None, mean_reversion_lower_bound: types.RealTensor=0.001, mean_reversion_upper_bound: types.RealTensor=0.5, volatility_lower_bound: types.RealTensor=1e-05, volatility_upper_bound: types.RealTensor=0.1, tolerance: types.RealTensor=1e-06, maximum_iterations: types.IntTensor=50, dtype: tf.DType=None, name: str=None) -> Tuple[CalibrationResult, types.BoolTensor, types.IntTensor]:\n    if False:\n        i = 10\n    \"Calibrates a batch of HJM models using European Swaption prices.\\n\\n  This function estimates the mean-reversion rates, volatility and correlation\\n  parameters of a multi factor HJM model using a set of European swaption\\n  prices as the target. The calibration is performed using least-squares\\n  optimization where the loss function minimizes the squared error between the\\n  target swaption prices (or volatilities) and the model implied swaption\\n  prices (or volatilities). The current calibration supports constant mean\\n  reversion, volatility and correlation parameters.\\n\\n  #### Example\\n  The example shows how to calibrate a Two factor HJM model with constant mean\\n  reversion rate and constant volatility.\\n\\n  ````python\\n  import numpy as np\\n  import tensorflow.compat.v2 as tf\\n  import tf_quant_finance as tff\\n\\n  dtype = tf.float64\\n\\n  expiries = np.array(\\n      [0.5, 0.5, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 10., 10.])\\n  float_leg_start_times = np.array([\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5],  # 6M x 2Y  swap\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],  # 6M x 5Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],  # 1Y x 2Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5],  # 1Y x 5Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],  # 2Y x 2Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5],  # 2Y x 5Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],  # 3Y x 2Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5],  # 3Y x 5Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],  # 4Y x 2Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5],  # 4Y x 5Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0],  # 5Y x 2Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5],  # 5Y x 5Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.0, 12.0, 12.0, 12.0,\\n       12.0],  # 10Y x 2Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0,\\n       14.5]  # 10Y x 5Y  swap\\n  ])\\n  float_leg_end_times = float_leg_start_times + 0.5\\n  max_maturities = np.array(\\n      [2.5, 5.5, 3.0, 6.0, 4., 7., 5., 8., 6., 9., 7., 10., 12., 15.])\\n  for i in range(float_leg_end_times.shape[0]):\\n    float_leg_end_times[i] = np.clip(\\n        float_leg_end_times[i], 0.0, max_maturities[i])\\n\\n  fixed_leg_payment_times = float_leg_end_times\\n  float_leg_daycount_fractions = (\\n      float_leg_end_times - float_leg_start_times)\\n  fixed_leg_daycount_fractions = float_leg_daycount_fractions\\n  fixed_leg_coupon = 0.01 * np.ones_like(fixed_leg_payment_times)\\n\\n  zero_rate_fn = lambda x: 0.01 * tf.ones_like(x, dtype=dtype)\\n  notional = 1.0\\n  prices = np.array([\\n      0.42919881, 0.98046542, 0.59045074, 1.34909391, 0.79491583,\\n      1.81768802, 0.93210461, 2.13625342, 1.05114573, 2.40921088,\\n      1.12941064, 2.58857507, 1.37029637, 3.15081683])\\n\\n  (calibrated_mr, calibrated_vol, calibrated_corr), _, _ = (\\n  tff.models.hjm.calibration_from_swaptions(\\n      prices=prices,\\n      expiries=expiries,\\n      floating_leg_start_times=float_leg_start_times,\\n      floating_leg_end_times=float_leg_end_times,\\n      fixed_leg_payment_times=fixed_leg_payment_times,\\n      floating_leg_daycount_fractions=float_leg_daycount_fractions,\\n      fixed_leg_daycount_fractions=fixed_leg_daycount_fractions,\\n      fixed_leg_coupon=fixed_leg_coupon,\\n      reference_rate_fn=zero_rate_fn,\\n      notional=100.,\\n      mean_reversion=[0.01, 0.01],  # Initial guess for mean reversion rate\\n      volatility=[0.005, 0.004],  # Initial guess for volatility\\n      volatility_based_calibration=True,\\n      calibrate_correlation=True,\\n      num_samples=2000,\\n      time_step=0.1,\\n      random_type=random.RandomType.STATELESS_ANTITHETIC,\\n      seed=[0,0],\\n      maximum_iterations=50,\\n      dtype=dtype))\\n  # Expected calibrated_mr: [0.00621303, 0.3601772]\\n  # Expected calibrated_vol: [0.00586125, 0.00384013]\\n  # Expected correlation: 0.65126492\\n  # Prices using calibrated model: [\\n      0.42939121, 0.95362327, 0.59186236, 1.32622752, 0.79575526,\\n      1.80457544, 0.93909176, 2.14336776, 1.04132595, 2.39385229,\\n      1.11770416, 2.58809336, 1.39557389, 3.29306317]\\n  ````\\n\\n  Args:\\n    prices: An N-D real `Tensor` of shape `batch_shape + [k]`. `batch_shape` is\\n      the shape of the batch of models to calibrate and `k` is the number of\\n      swaptions per calibration. The input represents the prices of swaptions\\n      used for calibration.\\n    expiries: A real `Tensor` of same shape and dtype as `prices`. The time to\\n      expiration of the swaptions.\\n    floating_leg_start_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual begins for each payment in the floating leg. The shape\\n      of this input should be `expiries.shape + [m]` where `m` denotes the\\n      number of floating payments in each leg.\\n    floating_leg_end_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual ends for each payment in the floating leg. The shape of\\n      this input should be `expiries.shape + [m]` where `m` denotes the number\\n      of floating payments in each leg.\\n    fixed_leg_payment_times: A real `Tensor` of the same dtype as `prices`. The\\n      payment times for each payment in the fixed leg. The shape of this input\\n      should be `expiries.shape + [n]` where `n` denotes the number of fixed\\n      payments in each leg.\\n    floating_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `floating_leg_start_times`. The daycount fractions for\\n      each payment in the floating leg.\\n    fixed_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `fixed_leg_payment_times`. The daycount fractions for\\n      each payment in the fixed leg.\\n    fixed_leg_coupon: A real `Tensor` of the same dtype and compatible shape as\\n      `fixed_leg_payment_times`. The fixed rate for each payment in the fixed\\n      leg.\\n    reference_rate_fn: A Python callable that accepts expiry time as a real\\n      `Tensor` and returns a `Tensor` of shape `input_shape`. Returns\\n      the continuously compounded zero rate at the present time for the input\\n      expiry time.\\n    num_hjm_factors: A Python scalar which corresponds to the number of factors\\n      in the batch of calibrated HJM models.\\n    mean_reversion: A real positive `Tensor` of same dtype as `prices` and shape\\n      `batch_shape  + [num_hjm_factors]`. Corresponds to the initial values of\\n      the mean reversion rates of the factors for calibration.\\n    volatility: A real positive `Tensor` of the same `dtype` and shape as\\n      `mean_reversion`. Corresponds to the initial values of the volatility of\\n      the factors for calibration.\\n    notional: An optional `Tensor` of same dtype and compatible shape as\\n      `strikes`specifying the notional amount for the underlying swap.\\n       Default value: None in which case the notional is set to 1.\\n    is_payer_swaption: A boolean `Tensor` of a shape compatible with `expiries`.\\n      Indicates whether the prices correspond to payer (if True) or receiver (if\\n      False) swaption. If not supplied, payer swaptions are assumed.\\n    swaption_valuation_method: An enum of type\\n      `valuation_method.ValuationMethod` specifying the method to be used for\\n      swaption valuation during calibration. Currently the valuation is\\n      supported using `MONTE_CARLO` and `FINITE_DIFFERENCE` methods. Valuation\\n      using finite difference is only supported for Gaussian HJM models, i.e.\\n      for models with constant mean-reversion rate and time-dependent\\n      volatility.\\n      Default value: `valuation_method.ValuationMethod.MONTE_CARLO`, in which\\n      case swaption valuation is done using Monte Carlo simulations.\\n    num_samples: Positive scalar `int32` `Tensor`. The number of simulation\\n      paths during Monte-Carlo valuation of swaptions. This input is ignored\\n      during analytic valuation.\\n      Default value: The default value is 1.\\n    random_type: Enum value of `RandomType`. The type of (quasi)-random number\\n      generator to use to generate the simulation paths. This input is relevant\\n      only for Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which maps to the standard pseudo-random numbers.\\n    seed: Seed for the random number generator. The seed is only relevant if\\n      `random_type` is one of `[STATELESS, PSEUDO, HALTON_RANDOMIZED,\\n      PSEUDO_ANTITHETIC, STATELESS_ANTITHETIC]`. For `PSEUDO`,\\n      `PSEUDO_ANTITHETIC` and `HALTON_RANDOMIZED` the seed should be an Python\\n      integer. For `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as\\n      an integer `Tensor` of shape `[2]`. This input is relevant only for\\n      Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which means no seed is set.\\n    skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\\n      Halton sequence to skip. Used only when `random_type` is 'SOBOL',\\n      'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\\n      Default value: `0`.\\n    times: An optional rank 1 `Tensor` of increasing positive real values. The\\n      times at which Monte Carlo simulations are performed. Relevant when\\n      swaption valuation is done using Monte Calro simulations.\\n      Default value: `None` in which case simulation times are computed based\\n      on either `time_step` or `num_time_steps` inputs.\\n    time_step: Scalar real `Tensor`. Maximal distance between time grid points\\n      in Euler scheme. Relevant when Euler scheme is used for simulation. This\\n      input is ignored during analytic valuation.\\n      Default value: `None`.\\n    num_time_steps: An optional scalar integer `Tensor` - a total number of\\n      time steps during Monte Carlo simulations. The maximal distance betwen\\n      points in grid is bounded by\\n      `times[-1] / (num_time_steps - times.shape[0])`.\\n      Either this or `time_step` should be supplied when the valuation method\\n      is Monte Carlo.\\n      Default value: `None`.\\n    curve_times: An optional rank 1 `Tensor` of positive real values. The\\n      maturities at which spot discount curve is computed during simulations.\\n      Default value: `None` in which case `curve_times` is computed based on\\n      swaption expities and `fixed_leg_payments_times` inputs.\\n    time_step_finite_difference: Scalar real `Tensor`. Spacing between time\\n      grid points in finite difference discretization. This input is only\\n      relevant for valuation using finite difference.\\n      Default value: `None`, in which case a `time_step` corresponding to 100\\n      discrete steps is used.\\n    num_grid_points_finite_difference: Scalar real `Tensor`. Number of spatial\\n      grid points for discretization. This input is only relevant for valuation\\n      using finite difference.\\n      Default value: 100.\\n    volatility_based_calibration: An optional Python boolean specifying whether\\n      calibration is performed using swaption implied volatilities. If the input\\n      is `True`, then the swaption prices are first converted to normal implied\\n      volatilities and calibration is performed by minimizing the error between\\n      input implied volatilities and model implied volatilities.\\n      Default value: True.\\n    calibrate_correlation: An optional Python boolean specifying if the\\n      correlation matrix between HJM factors should calibrated. If the input is\\n      `False`, then the model is calibrated assuming that the HJM factors are\\n      uncorrelated.\\n      Default value: True.\\n    optimizer_fn: Optional Python callable which implements the algorithm used\\n      to minimize the objective function during calibration. It should have\\n      the following interface:\\n      result = optimizer_fn(value_and_gradients_function, initial_position,\\n        tolerance, max_iterations)\\n      `value_and_gradients_function` is a Python callable that accepts a point\\n      as a real `Tensor` and returns a tuple of `Tensor`s of real dtype\\n      containing the value of the function and its gradient at that point.\\n      'initial_position' is a real `Tensor` containing the starting point of\\n      the optimization, 'tolerance' is a real scalar `Tensor` for stopping\\n      tolerance for the procedure and `max_iterations` specifies the maximum\\n      number of iterations.\\n      `optimizer_fn` should return a namedtuple containing the items: `position`\\n      (a tensor containing the optimal value), `converged` (a boolean\\n      indicating whether the optimize converged according the specified\\n      criteria), `failed` (a boolean indicating if the optimization resulted\\n      in a failure), `num_iterations` (the number of iterations used), and\\n      `objective_value` ( the value of the objective function at the optimal\\n      value). The default value for `optimizer_fn` is None and conjugate\\n      gradient algorithm is used.\\n    mean_reversion_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.001.\\n    mean_reversion_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.5.\\n    volatility_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of volatility during calibration.\\n      Default value: 0.00001 (0.1 basis points).\\n    volatility_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of volatility during calibration.\\n      Default value: 0.1.\\n    tolerance: Scalar `Tensor` of real dtype. The absolute tolerance for\\n      terminating the iterations.\\n      Default value: 1e-6.\\n    maximum_iterations: Scalar positive int32 `Tensor`. The maximum number of\\n      iterations during the optimization.\\n      Default value: 50.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n    name: Python string. The name to give to the ops created by this function.\\n      Default value: `None` which maps to the default name\\n        `hjm_swaption_calibration`.\\n\\n  Returns:\\n    A Tuple of three elements:\\n    * The first element is an instance of `CalibrationResult` whose parameters\\n      are calibrated to the input swaption prices.\\n    * A `Tensor` of optimization status for each batch element (whether the\\n      optimization algorithm has found the optimal point based on the specified\\n      convergance criteria).\\n    * A `Tensor` containing the number of iterations performed by the\\n      optimization algorithm.\\n  \"\n    del floating_leg_daycount_fractions\n    name = name or 'hjm_swaption_calibration'\n    with tf.name_scope(name):\n        prices = tf.convert_to_tensor(prices, dtype=dtype, name='prices')\n        dtype = dtype or prices.dtype\n        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n        float_leg_start_times = tf.convert_to_tensor(floating_leg_start_times, dtype=dtype, name='float_leg_start_times')\n        float_leg_end_times = tf.convert_to_tensor(floating_leg_end_times, dtype=dtype, name='float_leg_end_times')\n        fixed_leg_payment_times = tf.convert_to_tensor(fixed_leg_payment_times, dtype=dtype, name='fixed_leg_payment_times')\n        fixed_leg_daycount_fractions = tf.convert_to_tensor(fixed_leg_daycount_fractions, dtype=dtype, name='fixed_leg_daycount_fractions')\n        fixed_leg_coupon = tf.convert_to_tensor(fixed_leg_coupon, dtype=dtype, name='fixed_leg_coupon')\n        if times is None:\n            (times, _) = tf.unique(tf.reshape(expiries, [-1]))\n            times = tf.sort(times, name='sort_times')\n        else:\n            times = tf.convert_to_tensor(times, dtype=dtype)\n        if curve_times is None:\n            tau = fixed_leg_payment_times - tf.expand_dims(expiries, axis=-1)\n            (curve_times, _) = tf.unique(tf.reshape(tau, [-1]))\n            curve_times = tf.sort(curve_times)\n        else:\n            curve_times = tf.convert_to_tensor(curve_times, dtype=dtype)\n        notional = tf.convert_to_tensor(notional, dtype=dtype, name='notional')\n        vol_lb = tf.convert_to_tensor(volatility_lower_bound, dtype=dtype)\n        vol_ub = tf.convert_to_tensor(volatility_upper_bound, dtype=dtype)\n        mr_lb = tf.convert_to_tensor(mean_reversion_lower_bound, dtype=dtype)\n        mr_ub = tf.convert_to_tensor(mean_reversion_upper_bound, dtype=dtype)\n        theta_lb = tf.convert_to_tensor(0, dtype=dtype)\n        theta_ub = tf.convert_to_tensor(_THETA_UB, dtype=dtype)\n        mean_reversion = tf.convert_to_tensor(mean_reversion, dtype=dtype)\n        volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n        swaption_valuation_method = swaption_valuation_method or vm.ValuationMethod.MONTE_CARLO\n        if optimizer_fn is None:\n            optimizer_fn = optimizer.conjugate_gradient_minimize\n\n        def _price_to_normal_vol(x, swap_rate, annuity):\n            vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n            return vols\n        if volatility_based_calibration:\n            batch_shape = tf.shape(prices)[:-1]\n            batch_size = tf.math.reduce_prod(batch_shape)\n            num_instruments = tf.shape(prices)[-1]\n            (swap_rate, annuity) = swap.ir_swap_par_rate_and_annuity(float_leg_start_times, float_leg_end_times, fixed_leg_payment_times, fixed_leg_daycount_fractions, reference_rate_fn)\n            swap_rate = tf.reshape(swap_rate, [batch_size, batch_size, num_instruments])\n            annuity = tf.reshape(annuity, [batch_size, batch_size, num_instruments])\n            indices = tf.stack([tf.range(batch_size, dtype=tf.int32), tf.range(batch_size, dtype=tf.int32)], axis=-1)\n            swap_rate = tf.gather_nd(swap_rate, indices)\n            annuity = tf.gather_nd(annuity, indices)\n            swap_rate = tf.reshape(swap_rate, tf.shape(prices))\n            annuity = tf.reshape(annuity, tf.shape(prices))\n            target_values = _price_to_normal_vol(prices, swap_rate, annuity)\n        else:\n            target_values = prices\n        with tf.control_dependencies([target_values]):\n            tf.debugging.assert_all_finite(target_values, 'Conversion to implied vols resulted in failure for input swaption prices.')\n        target_lb = tf.constant(0.0, dtype=dtype)\n        target_ub = tf.math.reduce_max(target_values)\n\n        def _scale(x, lb, ub):\n            return (x - lb) / (ub - lb)\n\n        def _to_unconstrained(x, lb, ub):\n            x = _scale(x, lb, ub)\n            return -tf.math.log((1.0 - x) / x)\n\n        def _to_constrained(x, lb, ub):\n            x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n            return x * (ub - lb) + lb\n        if calibrate_correlation:\n            num_thetas = num_hjm_factors * (num_hjm_factors - 1)\n            init_corr = tf.range(0.1, num_thetas + 0.1, dtype=dtype) / num_thetas\n        else:\n            init_corr = []\n            if mean_reversion.shape.rank > 1:\n                init_corr = [[]] * mean_reversion.shape.rank\n        initial_guess = tf.concat([_to_unconstrained(mean_reversion, mr_lb, mr_ub), _to_unconstrained(volatility, vol_lb, vol_ub), _to_unconstrained(init_corr, theta_lb, theta_ub)], axis=-1)\n        scaled_target = _scale(target_values, target_lb, target_ub)\n\n        @make_val_and_grad_fn\n        def loss_function(x):\n            \"\"\"Loss function for the optimization.\"\"\"\n            x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n            x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n            if calibrate_correlation:\n                thetas = x[..., 2 * num_hjm_factors:]\n                thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n                x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n            else:\n                x_corr = None\n            volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n            model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n            if volatility_based_calibration:\n                model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n                model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n            value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n            return value\n        optimization_result = optimizer_fn(loss_function, initial_position=initial_guess, tolerance=tolerance, max_iterations=maximum_iterations)\n        calibrated_parameters = optimization_result.position\n        mean_reversion_calibrated = _to_constrained(calibrated_parameters[..., :num_hjm_factors], mr_lb, mr_ub)\n        volatility_calibrated = _to_constrained(calibrated_parameters[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n        if calibrate_correlation:\n            correlation_calibrated = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(calibrated_parameters[..., 2 * num_hjm_factors:], theta_lb, theta_ub))\n        else:\n            correlation_calibrated = None\n        return (CalibrationResult(mean_reversion=mean_reversion_calibrated, volatility=volatility_calibrated, corr_matrix=correlation_calibrated), optimization_result.converged, optimization_result.num_iterations)",
            "def calibration_from_swaptions(*, prices: types.RealTensor, expiries: types.RealTensor, floating_leg_start_times: types.RealTensor, floating_leg_end_times: types.RealTensor, fixed_leg_payment_times: types.RealTensor, floating_leg_daycount_fractions: types.RealTensor, fixed_leg_daycount_fractions: types.RealTensor, fixed_leg_coupon: types.RealTensor, reference_rate_fn: Callable[..., types.RealTensor], num_hjm_factors: types.RealTensor, mean_reversion: types.RealTensor, volatility: types.RealTensor, notional: types.RealTensor=None, is_payer_swaption: types.BoolTensor=None, swaption_valuation_method: vm.ValuationMethod=None, num_samples: types.IntTensor=1, random_type: random.RandomType=None, seed: types.IntTensor=None, skip: types.IntTensor=0, times: types.RealTensor=None, time_step: types.RealTensor=None, num_time_steps: types.IntTensor=None, curve_times: types.RealTensor=None, time_step_finite_difference: types.RealTensor=None, num_grid_points_finite_difference: types.IntTensor=101, volatility_based_calibration: bool=True, calibrate_correlation: bool=True, optimizer_fn: Callable[..., types.RealTensor]=None, mean_reversion_lower_bound: types.RealTensor=0.001, mean_reversion_upper_bound: types.RealTensor=0.5, volatility_lower_bound: types.RealTensor=1e-05, volatility_upper_bound: types.RealTensor=0.1, tolerance: types.RealTensor=1e-06, maximum_iterations: types.IntTensor=50, dtype: tf.DType=None, name: str=None) -> Tuple[CalibrationResult, types.BoolTensor, types.IntTensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Calibrates a batch of HJM models using European Swaption prices.\\n\\n  This function estimates the mean-reversion rates, volatility and correlation\\n  parameters of a multi factor HJM model using a set of European swaption\\n  prices as the target. The calibration is performed using least-squares\\n  optimization where the loss function minimizes the squared error between the\\n  target swaption prices (or volatilities) and the model implied swaption\\n  prices (or volatilities). The current calibration supports constant mean\\n  reversion, volatility and correlation parameters.\\n\\n  #### Example\\n  The example shows how to calibrate a Two factor HJM model with constant mean\\n  reversion rate and constant volatility.\\n\\n  ````python\\n  import numpy as np\\n  import tensorflow.compat.v2 as tf\\n  import tf_quant_finance as tff\\n\\n  dtype = tf.float64\\n\\n  expiries = np.array(\\n      [0.5, 0.5, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 10., 10.])\\n  float_leg_start_times = np.array([\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5],  # 6M x 2Y  swap\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],  # 6M x 5Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],  # 1Y x 2Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5],  # 1Y x 5Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],  # 2Y x 2Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5],  # 2Y x 5Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],  # 3Y x 2Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5],  # 3Y x 5Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],  # 4Y x 2Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5],  # 4Y x 5Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0],  # 5Y x 2Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5],  # 5Y x 5Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.0, 12.0, 12.0, 12.0,\\n       12.0],  # 10Y x 2Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0,\\n       14.5]  # 10Y x 5Y  swap\\n  ])\\n  float_leg_end_times = float_leg_start_times + 0.5\\n  max_maturities = np.array(\\n      [2.5, 5.5, 3.0, 6.0, 4., 7., 5., 8., 6., 9., 7., 10., 12., 15.])\\n  for i in range(float_leg_end_times.shape[0]):\\n    float_leg_end_times[i] = np.clip(\\n        float_leg_end_times[i], 0.0, max_maturities[i])\\n\\n  fixed_leg_payment_times = float_leg_end_times\\n  float_leg_daycount_fractions = (\\n      float_leg_end_times - float_leg_start_times)\\n  fixed_leg_daycount_fractions = float_leg_daycount_fractions\\n  fixed_leg_coupon = 0.01 * np.ones_like(fixed_leg_payment_times)\\n\\n  zero_rate_fn = lambda x: 0.01 * tf.ones_like(x, dtype=dtype)\\n  notional = 1.0\\n  prices = np.array([\\n      0.42919881, 0.98046542, 0.59045074, 1.34909391, 0.79491583,\\n      1.81768802, 0.93210461, 2.13625342, 1.05114573, 2.40921088,\\n      1.12941064, 2.58857507, 1.37029637, 3.15081683])\\n\\n  (calibrated_mr, calibrated_vol, calibrated_corr), _, _ = (\\n  tff.models.hjm.calibration_from_swaptions(\\n      prices=prices,\\n      expiries=expiries,\\n      floating_leg_start_times=float_leg_start_times,\\n      floating_leg_end_times=float_leg_end_times,\\n      fixed_leg_payment_times=fixed_leg_payment_times,\\n      floating_leg_daycount_fractions=float_leg_daycount_fractions,\\n      fixed_leg_daycount_fractions=fixed_leg_daycount_fractions,\\n      fixed_leg_coupon=fixed_leg_coupon,\\n      reference_rate_fn=zero_rate_fn,\\n      notional=100.,\\n      mean_reversion=[0.01, 0.01],  # Initial guess for mean reversion rate\\n      volatility=[0.005, 0.004],  # Initial guess for volatility\\n      volatility_based_calibration=True,\\n      calibrate_correlation=True,\\n      num_samples=2000,\\n      time_step=0.1,\\n      random_type=random.RandomType.STATELESS_ANTITHETIC,\\n      seed=[0,0],\\n      maximum_iterations=50,\\n      dtype=dtype))\\n  # Expected calibrated_mr: [0.00621303, 0.3601772]\\n  # Expected calibrated_vol: [0.00586125, 0.00384013]\\n  # Expected correlation: 0.65126492\\n  # Prices using calibrated model: [\\n      0.42939121, 0.95362327, 0.59186236, 1.32622752, 0.79575526,\\n      1.80457544, 0.93909176, 2.14336776, 1.04132595, 2.39385229,\\n      1.11770416, 2.58809336, 1.39557389, 3.29306317]\\n  ````\\n\\n  Args:\\n    prices: An N-D real `Tensor` of shape `batch_shape + [k]`. `batch_shape` is\\n      the shape of the batch of models to calibrate and `k` is the number of\\n      swaptions per calibration. The input represents the prices of swaptions\\n      used for calibration.\\n    expiries: A real `Tensor` of same shape and dtype as `prices`. The time to\\n      expiration of the swaptions.\\n    floating_leg_start_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual begins for each payment in the floating leg. The shape\\n      of this input should be `expiries.shape + [m]` where `m` denotes the\\n      number of floating payments in each leg.\\n    floating_leg_end_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual ends for each payment in the floating leg. The shape of\\n      this input should be `expiries.shape + [m]` where `m` denotes the number\\n      of floating payments in each leg.\\n    fixed_leg_payment_times: A real `Tensor` of the same dtype as `prices`. The\\n      payment times for each payment in the fixed leg. The shape of this input\\n      should be `expiries.shape + [n]` where `n` denotes the number of fixed\\n      payments in each leg.\\n    floating_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `floating_leg_start_times`. The daycount fractions for\\n      each payment in the floating leg.\\n    fixed_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `fixed_leg_payment_times`. The daycount fractions for\\n      each payment in the fixed leg.\\n    fixed_leg_coupon: A real `Tensor` of the same dtype and compatible shape as\\n      `fixed_leg_payment_times`. The fixed rate for each payment in the fixed\\n      leg.\\n    reference_rate_fn: A Python callable that accepts expiry time as a real\\n      `Tensor` and returns a `Tensor` of shape `input_shape`. Returns\\n      the continuously compounded zero rate at the present time for the input\\n      expiry time.\\n    num_hjm_factors: A Python scalar which corresponds to the number of factors\\n      in the batch of calibrated HJM models.\\n    mean_reversion: A real positive `Tensor` of same dtype as `prices` and shape\\n      `batch_shape  + [num_hjm_factors]`. Corresponds to the initial values of\\n      the mean reversion rates of the factors for calibration.\\n    volatility: A real positive `Tensor` of the same `dtype` and shape as\\n      `mean_reversion`. Corresponds to the initial values of the volatility of\\n      the factors for calibration.\\n    notional: An optional `Tensor` of same dtype and compatible shape as\\n      `strikes`specifying the notional amount for the underlying swap.\\n       Default value: None in which case the notional is set to 1.\\n    is_payer_swaption: A boolean `Tensor` of a shape compatible with `expiries`.\\n      Indicates whether the prices correspond to payer (if True) or receiver (if\\n      False) swaption. If not supplied, payer swaptions are assumed.\\n    swaption_valuation_method: An enum of type\\n      `valuation_method.ValuationMethod` specifying the method to be used for\\n      swaption valuation during calibration. Currently the valuation is\\n      supported using `MONTE_CARLO` and `FINITE_DIFFERENCE` methods. Valuation\\n      using finite difference is only supported for Gaussian HJM models, i.e.\\n      for models with constant mean-reversion rate and time-dependent\\n      volatility.\\n      Default value: `valuation_method.ValuationMethod.MONTE_CARLO`, in which\\n      case swaption valuation is done using Monte Carlo simulations.\\n    num_samples: Positive scalar `int32` `Tensor`. The number of simulation\\n      paths during Monte-Carlo valuation of swaptions. This input is ignored\\n      during analytic valuation.\\n      Default value: The default value is 1.\\n    random_type: Enum value of `RandomType`. The type of (quasi)-random number\\n      generator to use to generate the simulation paths. This input is relevant\\n      only for Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which maps to the standard pseudo-random numbers.\\n    seed: Seed for the random number generator. The seed is only relevant if\\n      `random_type` is one of `[STATELESS, PSEUDO, HALTON_RANDOMIZED,\\n      PSEUDO_ANTITHETIC, STATELESS_ANTITHETIC]`. For `PSEUDO`,\\n      `PSEUDO_ANTITHETIC` and `HALTON_RANDOMIZED` the seed should be an Python\\n      integer. For `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as\\n      an integer `Tensor` of shape `[2]`. This input is relevant only for\\n      Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which means no seed is set.\\n    skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\\n      Halton sequence to skip. Used only when `random_type` is 'SOBOL',\\n      'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\\n      Default value: `0`.\\n    times: An optional rank 1 `Tensor` of increasing positive real values. The\\n      times at which Monte Carlo simulations are performed. Relevant when\\n      swaption valuation is done using Monte Calro simulations.\\n      Default value: `None` in which case simulation times are computed based\\n      on either `time_step` or `num_time_steps` inputs.\\n    time_step: Scalar real `Tensor`. Maximal distance between time grid points\\n      in Euler scheme. Relevant when Euler scheme is used for simulation. This\\n      input is ignored during analytic valuation.\\n      Default value: `None`.\\n    num_time_steps: An optional scalar integer `Tensor` - a total number of\\n      time steps during Monte Carlo simulations. The maximal distance betwen\\n      points in grid is bounded by\\n      `times[-1] / (num_time_steps - times.shape[0])`.\\n      Either this or `time_step` should be supplied when the valuation method\\n      is Monte Carlo.\\n      Default value: `None`.\\n    curve_times: An optional rank 1 `Tensor` of positive real values. The\\n      maturities at which spot discount curve is computed during simulations.\\n      Default value: `None` in which case `curve_times` is computed based on\\n      swaption expities and `fixed_leg_payments_times` inputs.\\n    time_step_finite_difference: Scalar real `Tensor`. Spacing between time\\n      grid points in finite difference discretization. This input is only\\n      relevant for valuation using finite difference.\\n      Default value: `None`, in which case a `time_step` corresponding to 100\\n      discrete steps is used.\\n    num_grid_points_finite_difference: Scalar real `Tensor`. Number of spatial\\n      grid points for discretization. This input is only relevant for valuation\\n      using finite difference.\\n      Default value: 100.\\n    volatility_based_calibration: An optional Python boolean specifying whether\\n      calibration is performed using swaption implied volatilities. If the input\\n      is `True`, then the swaption prices are first converted to normal implied\\n      volatilities and calibration is performed by minimizing the error between\\n      input implied volatilities and model implied volatilities.\\n      Default value: True.\\n    calibrate_correlation: An optional Python boolean specifying if the\\n      correlation matrix between HJM factors should calibrated. If the input is\\n      `False`, then the model is calibrated assuming that the HJM factors are\\n      uncorrelated.\\n      Default value: True.\\n    optimizer_fn: Optional Python callable which implements the algorithm used\\n      to minimize the objective function during calibration. It should have\\n      the following interface:\\n      result = optimizer_fn(value_and_gradients_function, initial_position,\\n        tolerance, max_iterations)\\n      `value_and_gradients_function` is a Python callable that accepts a point\\n      as a real `Tensor` and returns a tuple of `Tensor`s of real dtype\\n      containing the value of the function and its gradient at that point.\\n      'initial_position' is a real `Tensor` containing the starting point of\\n      the optimization, 'tolerance' is a real scalar `Tensor` for stopping\\n      tolerance for the procedure and `max_iterations` specifies the maximum\\n      number of iterations.\\n      `optimizer_fn` should return a namedtuple containing the items: `position`\\n      (a tensor containing the optimal value), `converged` (a boolean\\n      indicating whether the optimize converged according the specified\\n      criteria), `failed` (a boolean indicating if the optimization resulted\\n      in a failure), `num_iterations` (the number of iterations used), and\\n      `objective_value` ( the value of the objective function at the optimal\\n      value). The default value for `optimizer_fn` is None and conjugate\\n      gradient algorithm is used.\\n    mean_reversion_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.001.\\n    mean_reversion_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.5.\\n    volatility_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of volatility during calibration.\\n      Default value: 0.00001 (0.1 basis points).\\n    volatility_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of volatility during calibration.\\n      Default value: 0.1.\\n    tolerance: Scalar `Tensor` of real dtype. The absolute tolerance for\\n      terminating the iterations.\\n      Default value: 1e-6.\\n    maximum_iterations: Scalar positive int32 `Tensor`. The maximum number of\\n      iterations during the optimization.\\n      Default value: 50.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n    name: Python string. The name to give to the ops created by this function.\\n      Default value: `None` which maps to the default name\\n        `hjm_swaption_calibration`.\\n\\n  Returns:\\n    A Tuple of three elements:\\n    * The first element is an instance of `CalibrationResult` whose parameters\\n      are calibrated to the input swaption prices.\\n    * A `Tensor` of optimization status for each batch element (whether the\\n      optimization algorithm has found the optimal point based on the specified\\n      convergance criteria).\\n    * A `Tensor` containing the number of iterations performed by the\\n      optimization algorithm.\\n  \"\n    del floating_leg_daycount_fractions\n    name = name or 'hjm_swaption_calibration'\n    with tf.name_scope(name):\n        prices = tf.convert_to_tensor(prices, dtype=dtype, name='prices')\n        dtype = dtype or prices.dtype\n        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n        float_leg_start_times = tf.convert_to_tensor(floating_leg_start_times, dtype=dtype, name='float_leg_start_times')\n        float_leg_end_times = tf.convert_to_tensor(floating_leg_end_times, dtype=dtype, name='float_leg_end_times')\n        fixed_leg_payment_times = tf.convert_to_tensor(fixed_leg_payment_times, dtype=dtype, name='fixed_leg_payment_times')\n        fixed_leg_daycount_fractions = tf.convert_to_tensor(fixed_leg_daycount_fractions, dtype=dtype, name='fixed_leg_daycount_fractions')\n        fixed_leg_coupon = tf.convert_to_tensor(fixed_leg_coupon, dtype=dtype, name='fixed_leg_coupon')\n        if times is None:\n            (times, _) = tf.unique(tf.reshape(expiries, [-1]))\n            times = tf.sort(times, name='sort_times')\n        else:\n            times = tf.convert_to_tensor(times, dtype=dtype)\n        if curve_times is None:\n            tau = fixed_leg_payment_times - tf.expand_dims(expiries, axis=-1)\n            (curve_times, _) = tf.unique(tf.reshape(tau, [-1]))\n            curve_times = tf.sort(curve_times)\n        else:\n            curve_times = tf.convert_to_tensor(curve_times, dtype=dtype)\n        notional = tf.convert_to_tensor(notional, dtype=dtype, name='notional')\n        vol_lb = tf.convert_to_tensor(volatility_lower_bound, dtype=dtype)\n        vol_ub = tf.convert_to_tensor(volatility_upper_bound, dtype=dtype)\n        mr_lb = tf.convert_to_tensor(mean_reversion_lower_bound, dtype=dtype)\n        mr_ub = tf.convert_to_tensor(mean_reversion_upper_bound, dtype=dtype)\n        theta_lb = tf.convert_to_tensor(0, dtype=dtype)\n        theta_ub = tf.convert_to_tensor(_THETA_UB, dtype=dtype)\n        mean_reversion = tf.convert_to_tensor(mean_reversion, dtype=dtype)\n        volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n        swaption_valuation_method = swaption_valuation_method or vm.ValuationMethod.MONTE_CARLO\n        if optimizer_fn is None:\n            optimizer_fn = optimizer.conjugate_gradient_minimize\n\n        def _price_to_normal_vol(x, swap_rate, annuity):\n            vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n            return vols\n        if volatility_based_calibration:\n            batch_shape = tf.shape(prices)[:-1]\n            batch_size = tf.math.reduce_prod(batch_shape)\n            num_instruments = tf.shape(prices)[-1]\n            (swap_rate, annuity) = swap.ir_swap_par_rate_and_annuity(float_leg_start_times, float_leg_end_times, fixed_leg_payment_times, fixed_leg_daycount_fractions, reference_rate_fn)\n            swap_rate = tf.reshape(swap_rate, [batch_size, batch_size, num_instruments])\n            annuity = tf.reshape(annuity, [batch_size, batch_size, num_instruments])\n            indices = tf.stack([tf.range(batch_size, dtype=tf.int32), tf.range(batch_size, dtype=tf.int32)], axis=-1)\n            swap_rate = tf.gather_nd(swap_rate, indices)\n            annuity = tf.gather_nd(annuity, indices)\n            swap_rate = tf.reshape(swap_rate, tf.shape(prices))\n            annuity = tf.reshape(annuity, tf.shape(prices))\n            target_values = _price_to_normal_vol(prices, swap_rate, annuity)\n        else:\n            target_values = prices\n        with tf.control_dependencies([target_values]):\n            tf.debugging.assert_all_finite(target_values, 'Conversion to implied vols resulted in failure for input swaption prices.')\n        target_lb = tf.constant(0.0, dtype=dtype)\n        target_ub = tf.math.reduce_max(target_values)\n\n        def _scale(x, lb, ub):\n            return (x - lb) / (ub - lb)\n\n        def _to_unconstrained(x, lb, ub):\n            x = _scale(x, lb, ub)\n            return -tf.math.log((1.0 - x) / x)\n\n        def _to_constrained(x, lb, ub):\n            x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n            return x * (ub - lb) + lb\n        if calibrate_correlation:\n            num_thetas = num_hjm_factors * (num_hjm_factors - 1)\n            init_corr = tf.range(0.1, num_thetas + 0.1, dtype=dtype) / num_thetas\n        else:\n            init_corr = []\n            if mean_reversion.shape.rank > 1:\n                init_corr = [[]] * mean_reversion.shape.rank\n        initial_guess = tf.concat([_to_unconstrained(mean_reversion, mr_lb, mr_ub), _to_unconstrained(volatility, vol_lb, vol_ub), _to_unconstrained(init_corr, theta_lb, theta_ub)], axis=-1)\n        scaled_target = _scale(target_values, target_lb, target_ub)\n\n        @make_val_and_grad_fn\n        def loss_function(x):\n            \"\"\"Loss function for the optimization.\"\"\"\n            x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n            x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n            if calibrate_correlation:\n                thetas = x[..., 2 * num_hjm_factors:]\n                thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n                x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n            else:\n                x_corr = None\n            volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n            model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n            if volatility_based_calibration:\n                model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n                model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n            value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n            return value\n        optimization_result = optimizer_fn(loss_function, initial_position=initial_guess, tolerance=tolerance, max_iterations=maximum_iterations)\n        calibrated_parameters = optimization_result.position\n        mean_reversion_calibrated = _to_constrained(calibrated_parameters[..., :num_hjm_factors], mr_lb, mr_ub)\n        volatility_calibrated = _to_constrained(calibrated_parameters[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n        if calibrate_correlation:\n            correlation_calibrated = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(calibrated_parameters[..., 2 * num_hjm_factors:], theta_lb, theta_ub))\n        else:\n            correlation_calibrated = None\n        return (CalibrationResult(mean_reversion=mean_reversion_calibrated, volatility=volatility_calibrated, corr_matrix=correlation_calibrated), optimization_result.converged, optimization_result.num_iterations)",
            "def calibration_from_swaptions(*, prices: types.RealTensor, expiries: types.RealTensor, floating_leg_start_times: types.RealTensor, floating_leg_end_times: types.RealTensor, fixed_leg_payment_times: types.RealTensor, floating_leg_daycount_fractions: types.RealTensor, fixed_leg_daycount_fractions: types.RealTensor, fixed_leg_coupon: types.RealTensor, reference_rate_fn: Callable[..., types.RealTensor], num_hjm_factors: types.RealTensor, mean_reversion: types.RealTensor, volatility: types.RealTensor, notional: types.RealTensor=None, is_payer_swaption: types.BoolTensor=None, swaption_valuation_method: vm.ValuationMethod=None, num_samples: types.IntTensor=1, random_type: random.RandomType=None, seed: types.IntTensor=None, skip: types.IntTensor=0, times: types.RealTensor=None, time_step: types.RealTensor=None, num_time_steps: types.IntTensor=None, curve_times: types.RealTensor=None, time_step_finite_difference: types.RealTensor=None, num_grid_points_finite_difference: types.IntTensor=101, volatility_based_calibration: bool=True, calibrate_correlation: bool=True, optimizer_fn: Callable[..., types.RealTensor]=None, mean_reversion_lower_bound: types.RealTensor=0.001, mean_reversion_upper_bound: types.RealTensor=0.5, volatility_lower_bound: types.RealTensor=1e-05, volatility_upper_bound: types.RealTensor=0.1, tolerance: types.RealTensor=1e-06, maximum_iterations: types.IntTensor=50, dtype: tf.DType=None, name: str=None) -> Tuple[CalibrationResult, types.BoolTensor, types.IntTensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Calibrates a batch of HJM models using European Swaption prices.\\n\\n  This function estimates the mean-reversion rates, volatility and correlation\\n  parameters of a multi factor HJM model using a set of European swaption\\n  prices as the target. The calibration is performed using least-squares\\n  optimization where the loss function minimizes the squared error between the\\n  target swaption prices (or volatilities) and the model implied swaption\\n  prices (or volatilities). The current calibration supports constant mean\\n  reversion, volatility and correlation parameters.\\n\\n  #### Example\\n  The example shows how to calibrate a Two factor HJM model with constant mean\\n  reversion rate and constant volatility.\\n\\n  ````python\\n  import numpy as np\\n  import tensorflow.compat.v2 as tf\\n  import tf_quant_finance as tff\\n\\n  dtype = tf.float64\\n\\n  expiries = np.array(\\n      [0.5, 0.5, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 10., 10.])\\n  float_leg_start_times = np.array([\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5],  # 6M x 2Y  swap\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],  # 6M x 5Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],  # 1Y x 2Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5],  # 1Y x 5Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],  # 2Y x 2Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5],  # 2Y x 5Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],  # 3Y x 2Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5],  # 3Y x 5Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],  # 4Y x 2Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5],  # 4Y x 5Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0],  # 5Y x 2Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5],  # 5Y x 5Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.0, 12.0, 12.0, 12.0,\\n       12.0],  # 10Y x 2Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0,\\n       14.5]  # 10Y x 5Y  swap\\n  ])\\n  float_leg_end_times = float_leg_start_times + 0.5\\n  max_maturities = np.array(\\n      [2.5, 5.5, 3.0, 6.0, 4., 7., 5., 8., 6., 9., 7., 10., 12., 15.])\\n  for i in range(float_leg_end_times.shape[0]):\\n    float_leg_end_times[i] = np.clip(\\n        float_leg_end_times[i], 0.0, max_maturities[i])\\n\\n  fixed_leg_payment_times = float_leg_end_times\\n  float_leg_daycount_fractions = (\\n      float_leg_end_times - float_leg_start_times)\\n  fixed_leg_daycount_fractions = float_leg_daycount_fractions\\n  fixed_leg_coupon = 0.01 * np.ones_like(fixed_leg_payment_times)\\n\\n  zero_rate_fn = lambda x: 0.01 * tf.ones_like(x, dtype=dtype)\\n  notional = 1.0\\n  prices = np.array([\\n      0.42919881, 0.98046542, 0.59045074, 1.34909391, 0.79491583,\\n      1.81768802, 0.93210461, 2.13625342, 1.05114573, 2.40921088,\\n      1.12941064, 2.58857507, 1.37029637, 3.15081683])\\n\\n  (calibrated_mr, calibrated_vol, calibrated_corr), _, _ = (\\n  tff.models.hjm.calibration_from_swaptions(\\n      prices=prices,\\n      expiries=expiries,\\n      floating_leg_start_times=float_leg_start_times,\\n      floating_leg_end_times=float_leg_end_times,\\n      fixed_leg_payment_times=fixed_leg_payment_times,\\n      floating_leg_daycount_fractions=float_leg_daycount_fractions,\\n      fixed_leg_daycount_fractions=fixed_leg_daycount_fractions,\\n      fixed_leg_coupon=fixed_leg_coupon,\\n      reference_rate_fn=zero_rate_fn,\\n      notional=100.,\\n      mean_reversion=[0.01, 0.01],  # Initial guess for mean reversion rate\\n      volatility=[0.005, 0.004],  # Initial guess for volatility\\n      volatility_based_calibration=True,\\n      calibrate_correlation=True,\\n      num_samples=2000,\\n      time_step=0.1,\\n      random_type=random.RandomType.STATELESS_ANTITHETIC,\\n      seed=[0,0],\\n      maximum_iterations=50,\\n      dtype=dtype))\\n  # Expected calibrated_mr: [0.00621303, 0.3601772]\\n  # Expected calibrated_vol: [0.00586125, 0.00384013]\\n  # Expected correlation: 0.65126492\\n  # Prices using calibrated model: [\\n      0.42939121, 0.95362327, 0.59186236, 1.32622752, 0.79575526,\\n      1.80457544, 0.93909176, 2.14336776, 1.04132595, 2.39385229,\\n      1.11770416, 2.58809336, 1.39557389, 3.29306317]\\n  ````\\n\\n  Args:\\n    prices: An N-D real `Tensor` of shape `batch_shape + [k]`. `batch_shape` is\\n      the shape of the batch of models to calibrate and `k` is the number of\\n      swaptions per calibration. The input represents the prices of swaptions\\n      used for calibration.\\n    expiries: A real `Tensor` of same shape and dtype as `prices`. The time to\\n      expiration of the swaptions.\\n    floating_leg_start_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual begins for each payment in the floating leg. The shape\\n      of this input should be `expiries.shape + [m]` where `m` denotes the\\n      number of floating payments in each leg.\\n    floating_leg_end_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual ends for each payment in the floating leg. The shape of\\n      this input should be `expiries.shape + [m]` where `m` denotes the number\\n      of floating payments in each leg.\\n    fixed_leg_payment_times: A real `Tensor` of the same dtype as `prices`. The\\n      payment times for each payment in the fixed leg. The shape of this input\\n      should be `expiries.shape + [n]` where `n` denotes the number of fixed\\n      payments in each leg.\\n    floating_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `floating_leg_start_times`. The daycount fractions for\\n      each payment in the floating leg.\\n    fixed_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `fixed_leg_payment_times`. The daycount fractions for\\n      each payment in the fixed leg.\\n    fixed_leg_coupon: A real `Tensor` of the same dtype and compatible shape as\\n      `fixed_leg_payment_times`. The fixed rate for each payment in the fixed\\n      leg.\\n    reference_rate_fn: A Python callable that accepts expiry time as a real\\n      `Tensor` and returns a `Tensor` of shape `input_shape`. Returns\\n      the continuously compounded zero rate at the present time for the input\\n      expiry time.\\n    num_hjm_factors: A Python scalar which corresponds to the number of factors\\n      in the batch of calibrated HJM models.\\n    mean_reversion: A real positive `Tensor` of same dtype as `prices` and shape\\n      `batch_shape  + [num_hjm_factors]`. Corresponds to the initial values of\\n      the mean reversion rates of the factors for calibration.\\n    volatility: A real positive `Tensor` of the same `dtype` and shape as\\n      `mean_reversion`. Corresponds to the initial values of the volatility of\\n      the factors for calibration.\\n    notional: An optional `Tensor` of same dtype and compatible shape as\\n      `strikes`specifying the notional amount for the underlying swap.\\n       Default value: None in which case the notional is set to 1.\\n    is_payer_swaption: A boolean `Tensor` of a shape compatible with `expiries`.\\n      Indicates whether the prices correspond to payer (if True) or receiver (if\\n      False) swaption. If not supplied, payer swaptions are assumed.\\n    swaption_valuation_method: An enum of type\\n      `valuation_method.ValuationMethod` specifying the method to be used for\\n      swaption valuation during calibration. Currently the valuation is\\n      supported using `MONTE_CARLO` and `FINITE_DIFFERENCE` methods. Valuation\\n      using finite difference is only supported for Gaussian HJM models, i.e.\\n      for models with constant mean-reversion rate and time-dependent\\n      volatility.\\n      Default value: `valuation_method.ValuationMethod.MONTE_CARLO`, in which\\n      case swaption valuation is done using Monte Carlo simulations.\\n    num_samples: Positive scalar `int32` `Tensor`. The number of simulation\\n      paths during Monte-Carlo valuation of swaptions. This input is ignored\\n      during analytic valuation.\\n      Default value: The default value is 1.\\n    random_type: Enum value of `RandomType`. The type of (quasi)-random number\\n      generator to use to generate the simulation paths. This input is relevant\\n      only for Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which maps to the standard pseudo-random numbers.\\n    seed: Seed for the random number generator. The seed is only relevant if\\n      `random_type` is one of `[STATELESS, PSEUDO, HALTON_RANDOMIZED,\\n      PSEUDO_ANTITHETIC, STATELESS_ANTITHETIC]`. For `PSEUDO`,\\n      `PSEUDO_ANTITHETIC` and `HALTON_RANDOMIZED` the seed should be an Python\\n      integer. For `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as\\n      an integer `Tensor` of shape `[2]`. This input is relevant only for\\n      Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which means no seed is set.\\n    skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\\n      Halton sequence to skip. Used only when `random_type` is 'SOBOL',\\n      'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\\n      Default value: `0`.\\n    times: An optional rank 1 `Tensor` of increasing positive real values. The\\n      times at which Monte Carlo simulations are performed. Relevant when\\n      swaption valuation is done using Monte Calro simulations.\\n      Default value: `None` in which case simulation times are computed based\\n      on either `time_step` or `num_time_steps` inputs.\\n    time_step: Scalar real `Tensor`. Maximal distance between time grid points\\n      in Euler scheme. Relevant when Euler scheme is used for simulation. This\\n      input is ignored during analytic valuation.\\n      Default value: `None`.\\n    num_time_steps: An optional scalar integer `Tensor` - a total number of\\n      time steps during Monte Carlo simulations. The maximal distance betwen\\n      points in grid is bounded by\\n      `times[-1] / (num_time_steps - times.shape[0])`.\\n      Either this or `time_step` should be supplied when the valuation method\\n      is Monte Carlo.\\n      Default value: `None`.\\n    curve_times: An optional rank 1 `Tensor` of positive real values. The\\n      maturities at which spot discount curve is computed during simulations.\\n      Default value: `None` in which case `curve_times` is computed based on\\n      swaption expities and `fixed_leg_payments_times` inputs.\\n    time_step_finite_difference: Scalar real `Tensor`. Spacing between time\\n      grid points in finite difference discretization. This input is only\\n      relevant for valuation using finite difference.\\n      Default value: `None`, in which case a `time_step` corresponding to 100\\n      discrete steps is used.\\n    num_grid_points_finite_difference: Scalar real `Tensor`. Number of spatial\\n      grid points for discretization. This input is only relevant for valuation\\n      using finite difference.\\n      Default value: 100.\\n    volatility_based_calibration: An optional Python boolean specifying whether\\n      calibration is performed using swaption implied volatilities. If the input\\n      is `True`, then the swaption prices are first converted to normal implied\\n      volatilities and calibration is performed by minimizing the error between\\n      input implied volatilities and model implied volatilities.\\n      Default value: True.\\n    calibrate_correlation: An optional Python boolean specifying if the\\n      correlation matrix between HJM factors should calibrated. If the input is\\n      `False`, then the model is calibrated assuming that the HJM factors are\\n      uncorrelated.\\n      Default value: True.\\n    optimizer_fn: Optional Python callable which implements the algorithm used\\n      to minimize the objective function during calibration. It should have\\n      the following interface:\\n      result = optimizer_fn(value_and_gradients_function, initial_position,\\n        tolerance, max_iterations)\\n      `value_and_gradients_function` is a Python callable that accepts a point\\n      as a real `Tensor` and returns a tuple of `Tensor`s of real dtype\\n      containing the value of the function and its gradient at that point.\\n      'initial_position' is a real `Tensor` containing the starting point of\\n      the optimization, 'tolerance' is a real scalar `Tensor` for stopping\\n      tolerance for the procedure and `max_iterations` specifies the maximum\\n      number of iterations.\\n      `optimizer_fn` should return a namedtuple containing the items: `position`\\n      (a tensor containing the optimal value), `converged` (a boolean\\n      indicating whether the optimize converged according the specified\\n      criteria), `failed` (a boolean indicating if the optimization resulted\\n      in a failure), `num_iterations` (the number of iterations used), and\\n      `objective_value` ( the value of the objective function at the optimal\\n      value). The default value for `optimizer_fn` is None and conjugate\\n      gradient algorithm is used.\\n    mean_reversion_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.001.\\n    mean_reversion_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.5.\\n    volatility_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of volatility during calibration.\\n      Default value: 0.00001 (0.1 basis points).\\n    volatility_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of volatility during calibration.\\n      Default value: 0.1.\\n    tolerance: Scalar `Tensor` of real dtype. The absolute tolerance for\\n      terminating the iterations.\\n      Default value: 1e-6.\\n    maximum_iterations: Scalar positive int32 `Tensor`. The maximum number of\\n      iterations during the optimization.\\n      Default value: 50.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n    name: Python string. The name to give to the ops created by this function.\\n      Default value: `None` which maps to the default name\\n        `hjm_swaption_calibration`.\\n\\n  Returns:\\n    A Tuple of three elements:\\n    * The first element is an instance of `CalibrationResult` whose parameters\\n      are calibrated to the input swaption prices.\\n    * A `Tensor` of optimization status for each batch element (whether the\\n      optimization algorithm has found the optimal point based on the specified\\n      convergance criteria).\\n    * A `Tensor` containing the number of iterations performed by the\\n      optimization algorithm.\\n  \"\n    del floating_leg_daycount_fractions\n    name = name or 'hjm_swaption_calibration'\n    with tf.name_scope(name):\n        prices = tf.convert_to_tensor(prices, dtype=dtype, name='prices')\n        dtype = dtype or prices.dtype\n        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n        float_leg_start_times = tf.convert_to_tensor(floating_leg_start_times, dtype=dtype, name='float_leg_start_times')\n        float_leg_end_times = tf.convert_to_tensor(floating_leg_end_times, dtype=dtype, name='float_leg_end_times')\n        fixed_leg_payment_times = tf.convert_to_tensor(fixed_leg_payment_times, dtype=dtype, name='fixed_leg_payment_times')\n        fixed_leg_daycount_fractions = tf.convert_to_tensor(fixed_leg_daycount_fractions, dtype=dtype, name='fixed_leg_daycount_fractions')\n        fixed_leg_coupon = tf.convert_to_tensor(fixed_leg_coupon, dtype=dtype, name='fixed_leg_coupon')\n        if times is None:\n            (times, _) = tf.unique(tf.reshape(expiries, [-1]))\n            times = tf.sort(times, name='sort_times')\n        else:\n            times = tf.convert_to_tensor(times, dtype=dtype)\n        if curve_times is None:\n            tau = fixed_leg_payment_times - tf.expand_dims(expiries, axis=-1)\n            (curve_times, _) = tf.unique(tf.reshape(tau, [-1]))\n            curve_times = tf.sort(curve_times)\n        else:\n            curve_times = tf.convert_to_tensor(curve_times, dtype=dtype)\n        notional = tf.convert_to_tensor(notional, dtype=dtype, name='notional')\n        vol_lb = tf.convert_to_tensor(volatility_lower_bound, dtype=dtype)\n        vol_ub = tf.convert_to_tensor(volatility_upper_bound, dtype=dtype)\n        mr_lb = tf.convert_to_tensor(mean_reversion_lower_bound, dtype=dtype)\n        mr_ub = tf.convert_to_tensor(mean_reversion_upper_bound, dtype=dtype)\n        theta_lb = tf.convert_to_tensor(0, dtype=dtype)\n        theta_ub = tf.convert_to_tensor(_THETA_UB, dtype=dtype)\n        mean_reversion = tf.convert_to_tensor(mean_reversion, dtype=dtype)\n        volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n        swaption_valuation_method = swaption_valuation_method or vm.ValuationMethod.MONTE_CARLO\n        if optimizer_fn is None:\n            optimizer_fn = optimizer.conjugate_gradient_minimize\n\n        def _price_to_normal_vol(x, swap_rate, annuity):\n            vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n            return vols\n        if volatility_based_calibration:\n            batch_shape = tf.shape(prices)[:-1]\n            batch_size = tf.math.reduce_prod(batch_shape)\n            num_instruments = tf.shape(prices)[-1]\n            (swap_rate, annuity) = swap.ir_swap_par_rate_and_annuity(float_leg_start_times, float_leg_end_times, fixed_leg_payment_times, fixed_leg_daycount_fractions, reference_rate_fn)\n            swap_rate = tf.reshape(swap_rate, [batch_size, batch_size, num_instruments])\n            annuity = tf.reshape(annuity, [batch_size, batch_size, num_instruments])\n            indices = tf.stack([tf.range(batch_size, dtype=tf.int32), tf.range(batch_size, dtype=tf.int32)], axis=-1)\n            swap_rate = tf.gather_nd(swap_rate, indices)\n            annuity = tf.gather_nd(annuity, indices)\n            swap_rate = tf.reshape(swap_rate, tf.shape(prices))\n            annuity = tf.reshape(annuity, tf.shape(prices))\n            target_values = _price_to_normal_vol(prices, swap_rate, annuity)\n        else:\n            target_values = prices\n        with tf.control_dependencies([target_values]):\n            tf.debugging.assert_all_finite(target_values, 'Conversion to implied vols resulted in failure for input swaption prices.')\n        target_lb = tf.constant(0.0, dtype=dtype)\n        target_ub = tf.math.reduce_max(target_values)\n\n        def _scale(x, lb, ub):\n            return (x - lb) / (ub - lb)\n\n        def _to_unconstrained(x, lb, ub):\n            x = _scale(x, lb, ub)\n            return -tf.math.log((1.0 - x) / x)\n\n        def _to_constrained(x, lb, ub):\n            x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n            return x * (ub - lb) + lb\n        if calibrate_correlation:\n            num_thetas = num_hjm_factors * (num_hjm_factors - 1)\n            init_corr = tf.range(0.1, num_thetas + 0.1, dtype=dtype) / num_thetas\n        else:\n            init_corr = []\n            if mean_reversion.shape.rank > 1:\n                init_corr = [[]] * mean_reversion.shape.rank\n        initial_guess = tf.concat([_to_unconstrained(mean_reversion, mr_lb, mr_ub), _to_unconstrained(volatility, vol_lb, vol_ub), _to_unconstrained(init_corr, theta_lb, theta_ub)], axis=-1)\n        scaled_target = _scale(target_values, target_lb, target_ub)\n\n        @make_val_and_grad_fn\n        def loss_function(x):\n            \"\"\"Loss function for the optimization.\"\"\"\n            x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n            x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n            if calibrate_correlation:\n                thetas = x[..., 2 * num_hjm_factors:]\n                thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n                x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n            else:\n                x_corr = None\n            volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n            model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n            if volatility_based_calibration:\n                model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n                model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n            value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n            return value\n        optimization_result = optimizer_fn(loss_function, initial_position=initial_guess, tolerance=tolerance, max_iterations=maximum_iterations)\n        calibrated_parameters = optimization_result.position\n        mean_reversion_calibrated = _to_constrained(calibrated_parameters[..., :num_hjm_factors], mr_lb, mr_ub)\n        volatility_calibrated = _to_constrained(calibrated_parameters[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n        if calibrate_correlation:\n            correlation_calibrated = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(calibrated_parameters[..., 2 * num_hjm_factors:], theta_lb, theta_ub))\n        else:\n            correlation_calibrated = None\n        return (CalibrationResult(mean_reversion=mean_reversion_calibrated, volatility=volatility_calibrated, corr_matrix=correlation_calibrated), optimization_result.converged, optimization_result.num_iterations)",
            "def calibration_from_swaptions(*, prices: types.RealTensor, expiries: types.RealTensor, floating_leg_start_times: types.RealTensor, floating_leg_end_times: types.RealTensor, fixed_leg_payment_times: types.RealTensor, floating_leg_daycount_fractions: types.RealTensor, fixed_leg_daycount_fractions: types.RealTensor, fixed_leg_coupon: types.RealTensor, reference_rate_fn: Callable[..., types.RealTensor], num_hjm_factors: types.RealTensor, mean_reversion: types.RealTensor, volatility: types.RealTensor, notional: types.RealTensor=None, is_payer_swaption: types.BoolTensor=None, swaption_valuation_method: vm.ValuationMethod=None, num_samples: types.IntTensor=1, random_type: random.RandomType=None, seed: types.IntTensor=None, skip: types.IntTensor=0, times: types.RealTensor=None, time_step: types.RealTensor=None, num_time_steps: types.IntTensor=None, curve_times: types.RealTensor=None, time_step_finite_difference: types.RealTensor=None, num_grid_points_finite_difference: types.IntTensor=101, volatility_based_calibration: bool=True, calibrate_correlation: bool=True, optimizer_fn: Callable[..., types.RealTensor]=None, mean_reversion_lower_bound: types.RealTensor=0.001, mean_reversion_upper_bound: types.RealTensor=0.5, volatility_lower_bound: types.RealTensor=1e-05, volatility_upper_bound: types.RealTensor=0.1, tolerance: types.RealTensor=1e-06, maximum_iterations: types.IntTensor=50, dtype: tf.DType=None, name: str=None) -> Tuple[CalibrationResult, types.BoolTensor, types.IntTensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Calibrates a batch of HJM models using European Swaption prices.\\n\\n  This function estimates the mean-reversion rates, volatility and correlation\\n  parameters of a multi factor HJM model using a set of European swaption\\n  prices as the target. The calibration is performed using least-squares\\n  optimization where the loss function minimizes the squared error between the\\n  target swaption prices (or volatilities) and the model implied swaption\\n  prices (or volatilities). The current calibration supports constant mean\\n  reversion, volatility and correlation parameters.\\n\\n  #### Example\\n  The example shows how to calibrate a Two factor HJM model with constant mean\\n  reversion rate and constant volatility.\\n\\n  ````python\\n  import numpy as np\\n  import tensorflow.compat.v2 as tf\\n  import tf_quant_finance as tff\\n\\n  dtype = tf.float64\\n\\n  expiries = np.array(\\n      [0.5, 0.5, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 10., 10.])\\n  float_leg_start_times = np.array([\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5],  # 6M x 2Y  swap\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],  # 6M x 5Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],  # 1Y x 2Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5],  # 1Y x 5Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],  # 2Y x 2Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5],  # 2Y x 5Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],  # 3Y x 2Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5],  # 3Y x 5Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],  # 4Y x 2Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5],  # 4Y x 5Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0],  # 5Y x 2Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5],  # 5Y x 5Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.0, 12.0, 12.0, 12.0,\\n       12.0],  # 10Y x 2Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0,\\n       14.5]  # 10Y x 5Y  swap\\n  ])\\n  float_leg_end_times = float_leg_start_times + 0.5\\n  max_maturities = np.array(\\n      [2.5, 5.5, 3.0, 6.0, 4., 7., 5., 8., 6., 9., 7., 10., 12., 15.])\\n  for i in range(float_leg_end_times.shape[0]):\\n    float_leg_end_times[i] = np.clip(\\n        float_leg_end_times[i], 0.0, max_maturities[i])\\n\\n  fixed_leg_payment_times = float_leg_end_times\\n  float_leg_daycount_fractions = (\\n      float_leg_end_times - float_leg_start_times)\\n  fixed_leg_daycount_fractions = float_leg_daycount_fractions\\n  fixed_leg_coupon = 0.01 * np.ones_like(fixed_leg_payment_times)\\n\\n  zero_rate_fn = lambda x: 0.01 * tf.ones_like(x, dtype=dtype)\\n  notional = 1.0\\n  prices = np.array([\\n      0.42919881, 0.98046542, 0.59045074, 1.34909391, 0.79491583,\\n      1.81768802, 0.93210461, 2.13625342, 1.05114573, 2.40921088,\\n      1.12941064, 2.58857507, 1.37029637, 3.15081683])\\n\\n  (calibrated_mr, calibrated_vol, calibrated_corr), _, _ = (\\n  tff.models.hjm.calibration_from_swaptions(\\n      prices=prices,\\n      expiries=expiries,\\n      floating_leg_start_times=float_leg_start_times,\\n      floating_leg_end_times=float_leg_end_times,\\n      fixed_leg_payment_times=fixed_leg_payment_times,\\n      floating_leg_daycount_fractions=float_leg_daycount_fractions,\\n      fixed_leg_daycount_fractions=fixed_leg_daycount_fractions,\\n      fixed_leg_coupon=fixed_leg_coupon,\\n      reference_rate_fn=zero_rate_fn,\\n      notional=100.,\\n      mean_reversion=[0.01, 0.01],  # Initial guess for mean reversion rate\\n      volatility=[0.005, 0.004],  # Initial guess for volatility\\n      volatility_based_calibration=True,\\n      calibrate_correlation=True,\\n      num_samples=2000,\\n      time_step=0.1,\\n      random_type=random.RandomType.STATELESS_ANTITHETIC,\\n      seed=[0,0],\\n      maximum_iterations=50,\\n      dtype=dtype))\\n  # Expected calibrated_mr: [0.00621303, 0.3601772]\\n  # Expected calibrated_vol: [0.00586125, 0.00384013]\\n  # Expected correlation: 0.65126492\\n  # Prices using calibrated model: [\\n      0.42939121, 0.95362327, 0.59186236, 1.32622752, 0.79575526,\\n      1.80457544, 0.93909176, 2.14336776, 1.04132595, 2.39385229,\\n      1.11770416, 2.58809336, 1.39557389, 3.29306317]\\n  ````\\n\\n  Args:\\n    prices: An N-D real `Tensor` of shape `batch_shape + [k]`. `batch_shape` is\\n      the shape of the batch of models to calibrate and `k` is the number of\\n      swaptions per calibration. The input represents the prices of swaptions\\n      used for calibration.\\n    expiries: A real `Tensor` of same shape and dtype as `prices`. The time to\\n      expiration of the swaptions.\\n    floating_leg_start_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual begins for each payment in the floating leg. The shape\\n      of this input should be `expiries.shape + [m]` where `m` denotes the\\n      number of floating payments in each leg.\\n    floating_leg_end_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual ends for each payment in the floating leg. The shape of\\n      this input should be `expiries.shape + [m]` where `m` denotes the number\\n      of floating payments in each leg.\\n    fixed_leg_payment_times: A real `Tensor` of the same dtype as `prices`. The\\n      payment times for each payment in the fixed leg. The shape of this input\\n      should be `expiries.shape + [n]` where `n` denotes the number of fixed\\n      payments in each leg.\\n    floating_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `floating_leg_start_times`. The daycount fractions for\\n      each payment in the floating leg.\\n    fixed_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `fixed_leg_payment_times`. The daycount fractions for\\n      each payment in the fixed leg.\\n    fixed_leg_coupon: A real `Tensor` of the same dtype and compatible shape as\\n      `fixed_leg_payment_times`. The fixed rate for each payment in the fixed\\n      leg.\\n    reference_rate_fn: A Python callable that accepts expiry time as a real\\n      `Tensor` and returns a `Tensor` of shape `input_shape`. Returns\\n      the continuously compounded zero rate at the present time for the input\\n      expiry time.\\n    num_hjm_factors: A Python scalar which corresponds to the number of factors\\n      in the batch of calibrated HJM models.\\n    mean_reversion: A real positive `Tensor` of same dtype as `prices` and shape\\n      `batch_shape  + [num_hjm_factors]`. Corresponds to the initial values of\\n      the mean reversion rates of the factors for calibration.\\n    volatility: A real positive `Tensor` of the same `dtype` and shape as\\n      `mean_reversion`. Corresponds to the initial values of the volatility of\\n      the factors for calibration.\\n    notional: An optional `Tensor` of same dtype and compatible shape as\\n      `strikes`specifying the notional amount for the underlying swap.\\n       Default value: None in which case the notional is set to 1.\\n    is_payer_swaption: A boolean `Tensor` of a shape compatible with `expiries`.\\n      Indicates whether the prices correspond to payer (if True) or receiver (if\\n      False) swaption. If not supplied, payer swaptions are assumed.\\n    swaption_valuation_method: An enum of type\\n      `valuation_method.ValuationMethod` specifying the method to be used for\\n      swaption valuation during calibration. Currently the valuation is\\n      supported using `MONTE_CARLO` and `FINITE_DIFFERENCE` methods. Valuation\\n      using finite difference is only supported for Gaussian HJM models, i.e.\\n      for models with constant mean-reversion rate and time-dependent\\n      volatility.\\n      Default value: `valuation_method.ValuationMethod.MONTE_CARLO`, in which\\n      case swaption valuation is done using Monte Carlo simulations.\\n    num_samples: Positive scalar `int32` `Tensor`. The number of simulation\\n      paths during Monte-Carlo valuation of swaptions. This input is ignored\\n      during analytic valuation.\\n      Default value: The default value is 1.\\n    random_type: Enum value of `RandomType`. The type of (quasi)-random number\\n      generator to use to generate the simulation paths. This input is relevant\\n      only for Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which maps to the standard pseudo-random numbers.\\n    seed: Seed for the random number generator. The seed is only relevant if\\n      `random_type` is one of `[STATELESS, PSEUDO, HALTON_RANDOMIZED,\\n      PSEUDO_ANTITHETIC, STATELESS_ANTITHETIC]`. For `PSEUDO`,\\n      `PSEUDO_ANTITHETIC` and `HALTON_RANDOMIZED` the seed should be an Python\\n      integer. For `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as\\n      an integer `Tensor` of shape `[2]`. This input is relevant only for\\n      Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which means no seed is set.\\n    skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\\n      Halton sequence to skip. Used only when `random_type` is 'SOBOL',\\n      'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\\n      Default value: `0`.\\n    times: An optional rank 1 `Tensor` of increasing positive real values. The\\n      times at which Monte Carlo simulations are performed. Relevant when\\n      swaption valuation is done using Monte Calro simulations.\\n      Default value: `None` in which case simulation times are computed based\\n      on either `time_step` or `num_time_steps` inputs.\\n    time_step: Scalar real `Tensor`. Maximal distance between time grid points\\n      in Euler scheme. Relevant when Euler scheme is used for simulation. This\\n      input is ignored during analytic valuation.\\n      Default value: `None`.\\n    num_time_steps: An optional scalar integer `Tensor` - a total number of\\n      time steps during Monte Carlo simulations. The maximal distance betwen\\n      points in grid is bounded by\\n      `times[-1] / (num_time_steps - times.shape[0])`.\\n      Either this or `time_step` should be supplied when the valuation method\\n      is Monte Carlo.\\n      Default value: `None`.\\n    curve_times: An optional rank 1 `Tensor` of positive real values. The\\n      maturities at which spot discount curve is computed during simulations.\\n      Default value: `None` in which case `curve_times` is computed based on\\n      swaption expities and `fixed_leg_payments_times` inputs.\\n    time_step_finite_difference: Scalar real `Tensor`. Spacing between time\\n      grid points in finite difference discretization. This input is only\\n      relevant for valuation using finite difference.\\n      Default value: `None`, in which case a `time_step` corresponding to 100\\n      discrete steps is used.\\n    num_grid_points_finite_difference: Scalar real `Tensor`. Number of spatial\\n      grid points for discretization. This input is only relevant for valuation\\n      using finite difference.\\n      Default value: 100.\\n    volatility_based_calibration: An optional Python boolean specifying whether\\n      calibration is performed using swaption implied volatilities. If the input\\n      is `True`, then the swaption prices are first converted to normal implied\\n      volatilities and calibration is performed by minimizing the error between\\n      input implied volatilities and model implied volatilities.\\n      Default value: True.\\n    calibrate_correlation: An optional Python boolean specifying if the\\n      correlation matrix between HJM factors should calibrated. If the input is\\n      `False`, then the model is calibrated assuming that the HJM factors are\\n      uncorrelated.\\n      Default value: True.\\n    optimizer_fn: Optional Python callable which implements the algorithm used\\n      to minimize the objective function during calibration. It should have\\n      the following interface:\\n      result = optimizer_fn(value_and_gradients_function, initial_position,\\n        tolerance, max_iterations)\\n      `value_and_gradients_function` is a Python callable that accepts a point\\n      as a real `Tensor` and returns a tuple of `Tensor`s of real dtype\\n      containing the value of the function and its gradient at that point.\\n      'initial_position' is a real `Tensor` containing the starting point of\\n      the optimization, 'tolerance' is a real scalar `Tensor` for stopping\\n      tolerance for the procedure and `max_iterations` specifies the maximum\\n      number of iterations.\\n      `optimizer_fn` should return a namedtuple containing the items: `position`\\n      (a tensor containing the optimal value), `converged` (a boolean\\n      indicating whether the optimize converged according the specified\\n      criteria), `failed` (a boolean indicating if the optimization resulted\\n      in a failure), `num_iterations` (the number of iterations used), and\\n      `objective_value` ( the value of the objective function at the optimal\\n      value). The default value for `optimizer_fn` is None and conjugate\\n      gradient algorithm is used.\\n    mean_reversion_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.001.\\n    mean_reversion_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.5.\\n    volatility_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of volatility during calibration.\\n      Default value: 0.00001 (0.1 basis points).\\n    volatility_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of volatility during calibration.\\n      Default value: 0.1.\\n    tolerance: Scalar `Tensor` of real dtype. The absolute tolerance for\\n      terminating the iterations.\\n      Default value: 1e-6.\\n    maximum_iterations: Scalar positive int32 `Tensor`. The maximum number of\\n      iterations during the optimization.\\n      Default value: 50.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n    name: Python string. The name to give to the ops created by this function.\\n      Default value: `None` which maps to the default name\\n        `hjm_swaption_calibration`.\\n\\n  Returns:\\n    A Tuple of three elements:\\n    * The first element is an instance of `CalibrationResult` whose parameters\\n      are calibrated to the input swaption prices.\\n    * A `Tensor` of optimization status for each batch element (whether the\\n      optimization algorithm has found the optimal point based on the specified\\n      convergance criteria).\\n    * A `Tensor` containing the number of iterations performed by the\\n      optimization algorithm.\\n  \"\n    del floating_leg_daycount_fractions\n    name = name or 'hjm_swaption_calibration'\n    with tf.name_scope(name):\n        prices = tf.convert_to_tensor(prices, dtype=dtype, name='prices')\n        dtype = dtype or prices.dtype\n        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n        float_leg_start_times = tf.convert_to_tensor(floating_leg_start_times, dtype=dtype, name='float_leg_start_times')\n        float_leg_end_times = tf.convert_to_tensor(floating_leg_end_times, dtype=dtype, name='float_leg_end_times')\n        fixed_leg_payment_times = tf.convert_to_tensor(fixed_leg_payment_times, dtype=dtype, name='fixed_leg_payment_times')\n        fixed_leg_daycount_fractions = tf.convert_to_tensor(fixed_leg_daycount_fractions, dtype=dtype, name='fixed_leg_daycount_fractions')\n        fixed_leg_coupon = tf.convert_to_tensor(fixed_leg_coupon, dtype=dtype, name='fixed_leg_coupon')\n        if times is None:\n            (times, _) = tf.unique(tf.reshape(expiries, [-1]))\n            times = tf.sort(times, name='sort_times')\n        else:\n            times = tf.convert_to_tensor(times, dtype=dtype)\n        if curve_times is None:\n            tau = fixed_leg_payment_times - tf.expand_dims(expiries, axis=-1)\n            (curve_times, _) = tf.unique(tf.reshape(tau, [-1]))\n            curve_times = tf.sort(curve_times)\n        else:\n            curve_times = tf.convert_to_tensor(curve_times, dtype=dtype)\n        notional = tf.convert_to_tensor(notional, dtype=dtype, name='notional')\n        vol_lb = tf.convert_to_tensor(volatility_lower_bound, dtype=dtype)\n        vol_ub = tf.convert_to_tensor(volatility_upper_bound, dtype=dtype)\n        mr_lb = tf.convert_to_tensor(mean_reversion_lower_bound, dtype=dtype)\n        mr_ub = tf.convert_to_tensor(mean_reversion_upper_bound, dtype=dtype)\n        theta_lb = tf.convert_to_tensor(0, dtype=dtype)\n        theta_ub = tf.convert_to_tensor(_THETA_UB, dtype=dtype)\n        mean_reversion = tf.convert_to_tensor(mean_reversion, dtype=dtype)\n        volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n        swaption_valuation_method = swaption_valuation_method or vm.ValuationMethod.MONTE_CARLO\n        if optimizer_fn is None:\n            optimizer_fn = optimizer.conjugate_gradient_minimize\n\n        def _price_to_normal_vol(x, swap_rate, annuity):\n            vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n            return vols\n        if volatility_based_calibration:\n            batch_shape = tf.shape(prices)[:-1]\n            batch_size = tf.math.reduce_prod(batch_shape)\n            num_instruments = tf.shape(prices)[-1]\n            (swap_rate, annuity) = swap.ir_swap_par_rate_and_annuity(float_leg_start_times, float_leg_end_times, fixed_leg_payment_times, fixed_leg_daycount_fractions, reference_rate_fn)\n            swap_rate = tf.reshape(swap_rate, [batch_size, batch_size, num_instruments])\n            annuity = tf.reshape(annuity, [batch_size, batch_size, num_instruments])\n            indices = tf.stack([tf.range(batch_size, dtype=tf.int32), tf.range(batch_size, dtype=tf.int32)], axis=-1)\n            swap_rate = tf.gather_nd(swap_rate, indices)\n            annuity = tf.gather_nd(annuity, indices)\n            swap_rate = tf.reshape(swap_rate, tf.shape(prices))\n            annuity = tf.reshape(annuity, tf.shape(prices))\n            target_values = _price_to_normal_vol(prices, swap_rate, annuity)\n        else:\n            target_values = prices\n        with tf.control_dependencies([target_values]):\n            tf.debugging.assert_all_finite(target_values, 'Conversion to implied vols resulted in failure for input swaption prices.')\n        target_lb = tf.constant(0.0, dtype=dtype)\n        target_ub = tf.math.reduce_max(target_values)\n\n        def _scale(x, lb, ub):\n            return (x - lb) / (ub - lb)\n\n        def _to_unconstrained(x, lb, ub):\n            x = _scale(x, lb, ub)\n            return -tf.math.log((1.0 - x) / x)\n\n        def _to_constrained(x, lb, ub):\n            x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n            return x * (ub - lb) + lb\n        if calibrate_correlation:\n            num_thetas = num_hjm_factors * (num_hjm_factors - 1)\n            init_corr = tf.range(0.1, num_thetas + 0.1, dtype=dtype) / num_thetas\n        else:\n            init_corr = []\n            if mean_reversion.shape.rank > 1:\n                init_corr = [[]] * mean_reversion.shape.rank\n        initial_guess = tf.concat([_to_unconstrained(mean_reversion, mr_lb, mr_ub), _to_unconstrained(volatility, vol_lb, vol_ub), _to_unconstrained(init_corr, theta_lb, theta_ub)], axis=-1)\n        scaled_target = _scale(target_values, target_lb, target_ub)\n\n        @make_val_and_grad_fn\n        def loss_function(x):\n            \"\"\"Loss function for the optimization.\"\"\"\n            x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n            x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n            if calibrate_correlation:\n                thetas = x[..., 2 * num_hjm_factors:]\n                thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n                x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n            else:\n                x_corr = None\n            volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n            model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n            if volatility_based_calibration:\n                model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n                model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n            value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n            return value\n        optimization_result = optimizer_fn(loss_function, initial_position=initial_guess, tolerance=tolerance, max_iterations=maximum_iterations)\n        calibrated_parameters = optimization_result.position\n        mean_reversion_calibrated = _to_constrained(calibrated_parameters[..., :num_hjm_factors], mr_lb, mr_ub)\n        volatility_calibrated = _to_constrained(calibrated_parameters[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n        if calibrate_correlation:\n            correlation_calibrated = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(calibrated_parameters[..., 2 * num_hjm_factors:], theta_lb, theta_ub))\n        else:\n            correlation_calibrated = None\n        return (CalibrationResult(mean_reversion=mean_reversion_calibrated, volatility=volatility_calibrated, corr_matrix=correlation_calibrated), optimization_result.converged, optimization_result.num_iterations)",
            "def calibration_from_swaptions(*, prices: types.RealTensor, expiries: types.RealTensor, floating_leg_start_times: types.RealTensor, floating_leg_end_times: types.RealTensor, fixed_leg_payment_times: types.RealTensor, floating_leg_daycount_fractions: types.RealTensor, fixed_leg_daycount_fractions: types.RealTensor, fixed_leg_coupon: types.RealTensor, reference_rate_fn: Callable[..., types.RealTensor], num_hjm_factors: types.RealTensor, mean_reversion: types.RealTensor, volatility: types.RealTensor, notional: types.RealTensor=None, is_payer_swaption: types.BoolTensor=None, swaption_valuation_method: vm.ValuationMethod=None, num_samples: types.IntTensor=1, random_type: random.RandomType=None, seed: types.IntTensor=None, skip: types.IntTensor=0, times: types.RealTensor=None, time_step: types.RealTensor=None, num_time_steps: types.IntTensor=None, curve_times: types.RealTensor=None, time_step_finite_difference: types.RealTensor=None, num_grid_points_finite_difference: types.IntTensor=101, volatility_based_calibration: bool=True, calibrate_correlation: bool=True, optimizer_fn: Callable[..., types.RealTensor]=None, mean_reversion_lower_bound: types.RealTensor=0.001, mean_reversion_upper_bound: types.RealTensor=0.5, volatility_lower_bound: types.RealTensor=1e-05, volatility_upper_bound: types.RealTensor=0.1, tolerance: types.RealTensor=1e-06, maximum_iterations: types.IntTensor=50, dtype: tf.DType=None, name: str=None) -> Tuple[CalibrationResult, types.BoolTensor, types.IntTensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Calibrates a batch of HJM models using European Swaption prices.\\n\\n  This function estimates the mean-reversion rates, volatility and correlation\\n  parameters of a multi factor HJM model using a set of European swaption\\n  prices as the target. The calibration is performed using least-squares\\n  optimization where the loss function minimizes the squared error between the\\n  target swaption prices (or volatilities) and the model implied swaption\\n  prices (or volatilities). The current calibration supports constant mean\\n  reversion, volatility and correlation parameters.\\n\\n  #### Example\\n  The example shows how to calibrate a Two factor HJM model with constant mean\\n  reversion rate and constant volatility.\\n\\n  ````python\\n  import numpy as np\\n  import tensorflow.compat.v2 as tf\\n  import tf_quant_finance as tff\\n\\n  dtype = tf.float64\\n\\n  expiries = np.array(\\n      [0.5, 0.5, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 10., 10.])\\n  float_leg_start_times = np.array([\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5],  # 6M x 2Y  swap\\n      [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],  # 6M x 5Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],  # 1Y x 2Y  swap\\n      [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5],  # 1Y x 5Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],  # 2Y x 2Y  swap\\n      [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5],  # 2Y x 5Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],  # 3Y x 2Y  swap\\n      [3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5],  # 3Y x 5Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],  # 4Y x 2Y  swap\\n      [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5],  # 4Y x 5Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0],  # 5Y x 2Y  swap\\n      [5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5],  # 5Y x 5Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.0, 12.0, 12.0, 12.0,\\n       12.0],  # 10Y x 2Y  swap\\n      [10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0,\\n       14.5]  # 10Y x 5Y  swap\\n  ])\\n  float_leg_end_times = float_leg_start_times + 0.5\\n  max_maturities = np.array(\\n      [2.5, 5.5, 3.0, 6.0, 4., 7., 5., 8., 6., 9., 7., 10., 12., 15.])\\n  for i in range(float_leg_end_times.shape[0]):\\n    float_leg_end_times[i] = np.clip(\\n        float_leg_end_times[i], 0.0, max_maturities[i])\\n\\n  fixed_leg_payment_times = float_leg_end_times\\n  float_leg_daycount_fractions = (\\n      float_leg_end_times - float_leg_start_times)\\n  fixed_leg_daycount_fractions = float_leg_daycount_fractions\\n  fixed_leg_coupon = 0.01 * np.ones_like(fixed_leg_payment_times)\\n\\n  zero_rate_fn = lambda x: 0.01 * tf.ones_like(x, dtype=dtype)\\n  notional = 1.0\\n  prices = np.array([\\n      0.42919881, 0.98046542, 0.59045074, 1.34909391, 0.79491583,\\n      1.81768802, 0.93210461, 2.13625342, 1.05114573, 2.40921088,\\n      1.12941064, 2.58857507, 1.37029637, 3.15081683])\\n\\n  (calibrated_mr, calibrated_vol, calibrated_corr), _, _ = (\\n  tff.models.hjm.calibration_from_swaptions(\\n      prices=prices,\\n      expiries=expiries,\\n      floating_leg_start_times=float_leg_start_times,\\n      floating_leg_end_times=float_leg_end_times,\\n      fixed_leg_payment_times=fixed_leg_payment_times,\\n      floating_leg_daycount_fractions=float_leg_daycount_fractions,\\n      fixed_leg_daycount_fractions=fixed_leg_daycount_fractions,\\n      fixed_leg_coupon=fixed_leg_coupon,\\n      reference_rate_fn=zero_rate_fn,\\n      notional=100.,\\n      mean_reversion=[0.01, 0.01],  # Initial guess for mean reversion rate\\n      volatility=[0.005, 0.004],  # Initial guess for volatility\\n      volatility_based_calibration=True,\\n      calibrate_correlation=True,\\n      num_samples=2000,\\n      time_step=0.1,\\n      random_type=random.RandomType.STATELESS_ANTITHETIC,\\n      seed=[0,0],\\n      maximum_iterations=50,\\n      dtype=dtype))\\n  # Expected calibrated_mr: [0.00621303, 0.3601772]\\n  # Expected calibrated_vol: [0.00586125, 0.00384013]\\n  # Expected correlation: 0.65126492\\n  # Prices using calibrated model: [\\n      0.42939121, 0.95362327, 0.59186236, 1.32622752, 0.79575526,\\n      1.80457544, 0.93909176, 2.14336776, 1.04132595, 2.39385229,\\n      1.11770416, 2.58809336, 1.39557389, 3.29306317]\\n  ````\\n\\n  Args:\\n    prices: An N-D real `Tensor` of shape `batch_shape + [k]`. `batch_shape` is\\n      the shape of the batch of models to calibrate and `k` is the number of\\n      swaptions per calibration. The input represents the prices of swaptions\\n      used for calibration.\\n    expiries: A real `Tensor` of same shape and dtype as `prices`. The time to\\n      expiration of the swaptions.\\n    floating_leg_start_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual begins for each payment in the floating leg. The shape\\n      of this input should be `expiries.shape + [m]` where `m` denotes the\\n      number of floating payments in each leg.\\n    floating_leg_end_times: A real `Tensor` of the same dtype as `prices`. The\\n      times when accrual ends for each payment in the floating leg. The shape of\\n      this input should be `expiries.shape + [m]` where `m` denotes the number\\n      of floating payments in each leg.\\n    fixed_leg_payment_times: A real `Tensor` of the same dtype as `prices`. The\\n      payment times for each payment in the fixed leg. The shape of this input\\n      should be `expiries.shape + [n]` where `n` denotes the number of fixed\\n      payments in each leg.\\n    floating_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `floating_leg_start_times`. The daycount fractions for\\n      each payment in the floating leg.\\n    fixed_leg_daycount_fractions: A real `Tensor` of the same dtype and\\n      compatible shape as `fixed_leg_payment_times`. The daycount fractions for\\n      each payment in the fixed leg.\\n    fixed_leg_coupon: A real `Tensor` of the same dtype and compatible shape as\\n      `fixed_leg_payment_times`. The fixed rate for each payment in the fixed\\n      leg.\\n    reference_rate_fn: A Python callable that accepts expiry time as a real\\n      `Tensor` and returns a `Tensor` of shape `input_shape`. Returns\\n      the continuously compounded zero rate at the present time for the input\\n      expiry time.\\n    num_hjm_factors: A Python scalar which corresponds to the number of factors\\n      in the batch of calibrated HJM models.\\n    mean_reversion: A real positive `Tensor` of same dtype as `prices` and shape\\n      `batch_shape  + [num_hjm_factors]`. Corresponds to the initial values of\\n      the mean reversion rates of the factors for calibration.\\n    volatility: A real positive `Tensor` of the same `dtype` and shape as\\n      `mean_reversion`. Corresponds to the initial values of the volatility of\\n      the factors for calibration.\\n    notional: An optional `Tensor` of same dtype and compatible shape as\\n      `strikes`specifying the notional amount for the underlying swap.\\n       Default value: None in which case the notional is set to 1.\\n    is_payer_swaption: A boolean `Tensor` of a shape compatible with `expiries`.\\n      Indicates whether the prices correspond to payer (if True) or receiver (if\\n      False) swaption. If not supplied, payer swaptions are assumed.\\n    swaption_valuation_method: An enum of type\\n      `valuation_method.ValuationMethod` specifying the method to be used for\\n      swaption valuation during calibration. Currently the valuation is\\n      supported using `MONTE_CARLO` and `FINITE_DIFFERENCE` methods. Valuation\\n      using finite difference is only supported for Gaussian HJM models, i.e.\\n      for models with constant mean-reversion rate and time-dependent\\n      volatility.\\n      Default value: `valuation_method.ValuationMethod.MONTE_CARLO`, in which\\n      case swaption valuation is done using Monte Carlo simulations.\\n    num_samples: Positive scalar `int32` `Tensor`. The number of simulation\\n      paths during Monte-Carlo valuation of swaptions. This input is ignored\\n      during analytic valuation.\\n      Default value: The default value is 1.\\n    random_type: Enum value of `RandomType`. The type of (quasi)-random number\\n      generator to use to generate the simulation paths. This input is relevant\\n      only for Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which maps to the standard pseudo-random numbers.\\n    seed: Seed for the random number generator. The seed is only relevant if\\n      `random_type` is one of `[STATELESS, PSEUDO, HALTON_RANDOMIZED,\\n      PSEUDO_ANTITHETIC, STATELESS_ANTITHETIC]`. For `PSEUDO`,\\n      `PSEUDO_ANTITHETIC` and `HALTON_RANDOMIZED` the seed should be an Python\\n      integer. For `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as\\n      an integer `Tensor` of shape `[2]`. This input is relevant only for\\n      Monte-Carlo valuation and ignored during analytic valuation.\\n      Default value: `None` which means no seed is set.\\n    skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\\n      Halton sequence to skip. Used only when `random_type` is 'SOBOL',\\n      'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\\n      Default value: `0`.\\n    times: An optional rank 1 `Tensor` of increasing positive real values. The\\n      times at which Monte Carlo simulations are performed. Relevant when\\n      swaption valuation is done using Monte Calro simulations.\\n      Default value: `None` in which case simulation times are computed based\\n      on either `time_step` or `num_time_steps` inputs.\\n    time_step: Scalar real `Tensor`. Maximal distance between time grid points\\n      in Euler scheme. Relevant when Euler scheme is used for simulation. This\\n      input is ignored during analytic valuation.\\n      Default value: `None`.\\n    num_time_steps: An optional scalar integer `Tensor` - a total number of\\n      time steps during Monte Carlo simulations. The maximal distance betwen\\n      points in grid is bounded by\\n      `times[-1] / (num_time_steps - times.shape[0])`.\\n      Either this or `time_step` should be supplied when the valuation method\\n      is Monte Carlo.\\n      Default value: `None`.\\n    curve_times: An optional rank 1 `Tensor` of positive real values. The\\n      maturities at which spot discount curve is computed during simulations.\\n      Default value: `None` in which case `curve_times` is computed based on\\n      swaption expities and `fixed_leg_payments_times` inputs.\\n    time_step_finite_difference: Scalar real `Tensor`. Spacing between time\\n      grid points in finite difference discretization. This input is only\\n      relevant for valuation using finite difference.\\n      Default value: `None`, in which case a `time_step` corresponding to 100\\n      discrete steps is used.\\n    num_grid_points_finite_difference: Scalar real `Tensor`. Number of spatial\\n      grid points for discretization. This input is only relevant for valuation\\n      using finite difference.\\n      Default value: 100.\\n    volatility_based_calibration: An optional Python boolean specifying whether\\n      calibration is performed using swaption implied volatilities. If the input\\n      is `True`, then the swaption prices are first converted to normal implied\\n      volatilities and calibration is performed by minimizing the error between\\n      input implied volatilities and model implied volatilities.\\n      Default value: True.\\n    calibrate_correlation: An optional Python boolean specifying if the\\n      correlation matrix between HJM factors should calibrated. If the input is\\n      `False`, then the model is calibrated assuming that the HJM factors are\\n      uncorrelated.\\n      Default value: True.\\n    optimizer_fn: Optional Python callable which implements the algorithm used\\n      to minimize the objective function during calibration. It should have\\n      the following interface:\\n      result = optimizer_fn(value_and_gradients_function, initial_position,\\n        tolerance, max_iterations)\\n      `value_and_gradients_function` is a Python callable that accepts a point\\n      as a real `Tensor` and returns a tuple of `Tensor`s of real dtype\\n      containing the value of the function and its gradient at that point.\\n      'initial_position' is a real `Tensor` containing the starting point of\\n      the optimization, 'tolerance' is a real scalar `Tensor` for stopping\\n      tolerance for the procedure and `max_iterations` specifies the maximum\\n      number of iterations.\\n      `optimizer_fn` should return a namedtuple containing the items: `position`\\n      (a tensor containing the optimal value), `converged` (a boolean\\n      indicating whether the optimize converged according the specified\\n      criteria), `failed` (a boolean indicating if the optimization resulted\\n      in a failure), `num_iterations` (the number of iterations used), and\\n      `objective_value` ( the value of the objective function at the optimal\\n      value). The default value for `optimizer_fn` is None and conjugate\\n      gradient algorithm is used.\\n    mean_reversion_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.001.\\n    mean_reversion_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of mean reversion rate during calibration.\\n      Default value: 0.5.\\n    volatility_lower_bound: An optional scalar `Tensor` specifying the lower\\n      limit of volatility during calibration.\\n      Default value: 0.00001 (0.1 basis points).\\n    volatility_upper_bound: An optional scalar `Tensor` specifying the upper\\n      limit of volatility during calibration.\\n      Default value: 0.1.\\n    tolerance: Scalar `Tensor` of real dtype. The absolute tolerance for\\n      terminating the iterations.\\n      Default value: 1e-6.\\n    maximum_iterations: Scalar positive int32 `Tensor`. The maximum number of\\n      iterations during the optimization.\\n      Default value: 50.\\n    dtype: The default dtype to use when converting values to `Tensor`s.\\n      Default value: `None` which means that default dtypes inferred by\\n        TensorFlow are used.\\n    name: Python string. The name to give to the ops created by this function.\\n      Default value: `None` which maps to the default name\\n        `hjm_swaption_calibration`.\\n\\n  Returns:\\n    A Tuple of three elements:\\n    * The first element is an instance of `CalibrationResult` whose parameters\\n      are calibrated to the input swaption prices.\\n    * A `Tensor` of optimization status for each batch element (whether the\\n      optimization algorithm has found the optimal point based on the specified\\n      convergance criteria).\\n    * A `Tensor` containing the number of iterations performed by the\\n      optimization algorithm.\\n  \"\n    del floating_leg_daycount_fractions\n    name = name or 'hjm_swaption_calibration'\n    with tf.name_scope(name):\n        prices = tf.convert_to_tensor(prices, dtype=dtype, name='prices')\n        dtype = dtype or prices.dtype\n        expiries = tf.convert_to_tensor(expiries, dtype=dtype, name='expiries')\n        float_leg_start_times = tf.convert_to_tensor(floating_leg_start_times, dtype=dtype, name='float_leg_start_times')\n        float_leg_end_times = tf.convert_to_tensor(floating_leg_end_times, dtype=dtype, name='float_leg_end_times')\n        fixed_leg_payment_times = tf.convert_to_tensor(fixed_leg_payment_times, dtype=dtype, name='fixed_leg_payment_times')\n        fixed_leg_daycount_fractions = tf.convert_to_tensor(fixed_leg_daycount_fractions, dtype=dtype, name='fixed_leg_daycount_fractions')\n        fixed_leg_coupon = tf.convert_to_tensor(fixed_leg_coupon, dtype=dtype, name='fixed_leg_coupon')\n        if times is None:\n            (times, _) = tf.unique(tf.reshape(expiries, [-1]))\n            times = tf.sort(times, name='sort_times')\n        else:\n            times = tf.convert_to_tensor(times, dtype=dtype)\n        if curve_times is None:\n            tau = fixed_leg_payment_times - tf.expand_dims(expiries, axis=-1)\n            (curve_times, _) = tf.unique(tf.reshape(tau, [-1]))\n            curve_times = tf.sort(curve_times)\n        else:\n            curve_times = tf.convert_to_tensor(curve_times, dtype=dtype)\n        notional = tf.convert_to_tensor(notional, dtype=dtype, name='notional')\n        vol_lb = tf.convert_to_tensor(volatility_lower_bound, dtype=dtype)\n        vol_ub = tf.convert_to_tensor(volatility_upper_bound, dtype=dtype)\n        mr_lb = tf.convert_to_tensor(mean_reversion_lower_bound, dtype=dtype)\n        mr_ub = tf.convert_to_tensor(mean_reversion_upper_bound, dtype=dtype)\n        theta_lb = tf.convert_to_tensor(0, dtype=dtype)\n        theta_ub = tf.convert_to_tensor(_THETA_UB, dtype=dtype)\n        mean_reversion = tf.convert_to_tensor(mean_reversion, dtype=dtype)\n        volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n        swaption_valuation_method = swaption_valuation_method or vm.ValuationMethod.MONTE_CARLO\n        if optimizer_fn is None:\n            optimizer_fn = optimizer.conjugate_gradient_minimize\n\n        def _price_to_normal_vol(x, swap_rate, annuity):\n            vols = implied_vol(prices=x / annuity / notional, strikes=fixed_leg_coupon[..., 0], expiries=expiries, forwards=swap_rate, is_call_options=is_payer_swaption, underlying_distribution=UnderlyingDistribution.NORMAL, dtype=dtype)\n            return vols\n        if volatility_based_calibration:\n            batch_shape = tf.shape(prices)[:-1]\n            batch_size = tf.math.reduce_prod(batch_shape)\n            num_instruments = tf.shape(prices)[-1]\n            (swap_rate, annuity) = swap.ir_swap_par_rate_and_annuity(float_leg_start_times, float_leg_end_times, fixed_leg_payment_times, fixed_leg_daycount_fractions, reference_rate_fn)\n            swap_rate = tf.reshape(swap_rate, [batch_size, batch_size, num_instruments])\n            annuity = tf.reshape(annuity, [batch_size, batch_size, num_instruments])\n            indices = tf.stack([tf.range(batch_size, dtype=tf.int32), tf.range(batch_size, dtype=tf.int32)], axis=-1)\n            swap_rate = tf.gather_nd(swap_rate, indices)\n            annuity = tf.gather_nd(annuity, indices)\n            swap_rate = tf.reshape(swap_rate, tf.shape(prices))\n            annuity = tf.reshape(annuity, tf.shape(prices))\n            target_values = _price_to_normal_vol(prices, swap_rate, annuity)\n        else:\n            target_values = prices\n        with tf.control_dependencies([target_values]):\n            tf.debugging.assert_all_finite(target_values, 'Conversion to implied vols resulted in failure for input swaption prices.')\n        target_lb = tf.constant(0.0, dtype=dtype)\n        target_ub = tf.math.reduce_max(target_values)\n\n        def _scale(x, lb, ub):\n            return (x - lb) / (ub - lb)\n\n        def _to_unconstrained(x, lb, ub):\n            x = _scale(x, lb, ub)\n            return -tf.math.log((1.0 - x) / x)\n\n        def _to_constrained(x, lb, ub):\n            x = tf.math.exp(x) / (1.0 + tf.math.exp(x))\n            return x * (ub - lb) + lb\n        if calibrate_correlation:\n            num_thetas = num_hjm_factors * (num_hjm_factors - 1)\n            init_corr = tf.range(0.1, num_thetas + 0.1, dtype=dtype) / num_thetas\n        else:\n            init_corr = []\n            if mean_reversion.shape.rank > 1:\n                init_corr = [[]] * mean_reversion.shape.rank\n        initial_guess = tf.concat([_to_unconstrained(mean_reversion, mr_lb, mr_ub), _to_unconstrained(volatility, vol_lb, vol_ub), _to_unconstrained(init_corr, theta_lb, theta_ub)], axis=-1)\n        scaled_target = _scale(target_values, target_lb, target_ub)\n\n        @make_val_and_grad_fn\n        def loss_function(x):\n            \"\"\"Loss function for the optimization.\"\"\"\n            x_mr = _to_constrained(x[..., :num_hjm_factors], mr_lb, mr_ub)\n            x_vol = _to_constrained(x[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n            if calibrate_correlation:\n                thetas = x[..., 2 * num_hjm_factors:]\n                thetas = tfp.math.clip_by_value_preserve_gradient(thetas, -25.0, 25.0)\n                x_corr = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(thetas, theta_lb, theta_ub))\n            else:\n                x_corr = None\n            volatility_param = _make_hjm_volatility_fn(x_vol, dtype)\n            model_values = swaption_price(expiries=expiries, fixed_leg_payment_times=fixed_leg_payment_times, fixed_leg_daycount_fractions=fixed_leg_daycount_fractions, fixed_leg_coupon=fixed_leg_coupon, reference_rate_fn=reference_rate_fn, num_hjm_factors=num_hjm_factors, mean_reversion=x_mr, volatility=volatility_param, corr_matrix=x_corr, notional=notional, is_payer_swaption=is_payer_swaption, valuation_method=swaption_valuation_method, num_samples=num_samples, random_type=random_type, seed=seed, skip=skip, times=times, time_step=time_step, num_time_steps=num_time_steps, curve_times=curve_times, time_step_finite_difference=time_step_finite_difference, num_grid_points_finite_difference=num_grid_points_finite_difference, dtype=dtype)\n            if volatility_based_calibration:\n                model_values = _price_to_normal_vol(model_values, swap_rate, annuity)\n                model_values = tf.where(tf.math.is_nan(model_values), tf.constant(1e-07, dtype=dtype), model_values)\n            value = tf.math.reduce_sum((_scale(model_values, target_lb, target_ub) - scaled_target) ** 2, axis=-1)\n            return value\n        optimization_result = optimizer_fn(loss_function, initial_position=initial_guess, tolerance=tolerance, max_iterations=maximum_iterations)\n        calibrated_parameters = optimization_result.position\n        mean_reversion_calibrated = _to_constrained(calibrated_parameters[..., :num_hjm_factors], mr_lb, mr_ub)\n        volatility_calibrated = _to_constrained(calibrated_parameters[..., num_hjm_factors:2 * num_hjm_factors], vol_lb, vol_ub)\n        if calibrate_correlation:\n            correlation_calibrated = _correlation_matrix_using_hypersphere_decomposition(num_hjm_factors, _to_constrained(calibrated_parameters[..., 2 * num_hjm_factors:], theta_lb, theta_ub))\n        else:\n            correlation_calibrated = None\n        return (CalibrationResult(mean_reversion=mean_reversion_calibrated, volatility=volatility_calibrated, corr_matrix=correlation_calibrated), optimization_result.converged, optimization_result.num_iterations)"
        ]
    },
    {
        "func_name": "_make_hjm_volatility_fn",
        "original": "def _make_hjm_volatility_fn(volatility, dtype):\n    volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n    return volatility",
        "mutated": [
            "def _make_hjm_volatility_fn(volatility, dtype):\n    if False:\n        i = 10\n    volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n    return volatility",
            "def _make_hjm_volatility_fn(volatility, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n    return volatility",
            "def _make_hjm_volatility_fn(volatility, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n    return volatility",
            "def _make_hjm_volatility_fn(volatility, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n    return volatility",
            "def _make_hjm_volatility_fn(volatility, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    volatility = tf.convert_to_tensor(volatility, dtype=dtype)\n    return volatility"
        ]
    }
]