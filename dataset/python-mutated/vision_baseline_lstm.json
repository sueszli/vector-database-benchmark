[
    {
        "func_name": "lstm_online",
        "original": "def lstm_online(cell_fn, num_steps, inputs, state, varscope):\n    inputs = tf.unstack(inputs, axis=1, num=num_steps)\n    state = tf.unstack(state, axis=1, num=1)[0]\n    outputs = []\n    if num_steps > 1:\n        varscope.reuse_variables()\n    for s in range(num_steps):\n        (output, state) = cell_fn(inputs[s], state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=1)\n    state = tf.stack([state], axis=1)\n    return (outputs, state)",
        "mutated": [
            "def lstm_online(cell_fn, num_steps, inputs, state, varscope):\n    if False:\n        i = 10\n    inputs = tf.unstack(inputs, axis=1, num=num_steps)\n    state = tf.unstack(state, axis=1, num=1)[0]\n    outputs = []\n    if num_steps > 1:\n        varscope.reuse_variables()\n    for s in range(num_steps):\n        (output, state) = cell_fn(inputs[s], state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=1)\n    state = tf.stack([state], axis=1)\n    return (outputs, state)",
            "def lstm_online(cell_fn, num_steps, inputs, state, varscope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    inputs = tf.unstack(inputs, axis=1, num=num_steps)\n    state = tf.unstack(state, axis=1, num=1)[0]\n    outputs = []\n    if num_steps > 1:\n        varscope.reuse_variables()\n    for s in range(num_steps):\n        (output, state) = cell_fn(inputs[s], state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=1)\n    state = tf.stack([state], axis=1)\n    return (outputs, state)",
            "def lstm_online(cell_fn, num_steps, inputs, state, varscope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    inputs = tf.unstack(inputs, axis=1, num=num_steps)\n    state = tf.unstack(state, axis=1, num=1)[0]\n    outputs = []\n    if num_steps > 1:\n        varscope.reuse_variables()\n    for s in range(num_steps):\n        (output, state) = cell_fn(inputs[s], state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=1)\n    state = tf.stack([state], axis=1)\n    return (outputs, state)",
            "def lstm_online(cell_fn, num_steps, inputs, state, varscope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    inputs = tf.unstack(inputs, axis=1, num=num_steps)\n    state = tf.unstack(state, axis=1, num=1)[0]\n    outputs = []\n    if num_steps > 1:\n        varscope.reuse_variables()\n    for s in range(num_steps):\n        (output, state) = cell_fn(inputs[s], state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=1)\n    state = tf.stack([state], axis=1)\n    return (outputs, state)",
            "def lstm_online(cell_fn, num_steps, inputs, state, varscope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    inputs = tf.unstack(inputs, axis=1, num=num_steps)\n    state = tf.unstack(state, axis=1, num=1)[0]\n    outputs = []\n    if num_steps > 1:\n        varscope.reuse_variables()\n    for s in range(num_steps):\n        (output, state) = cell_fn(inputs[s], state)\n        outputs.append(output)\n    outputs = tf.stack(outputs, axis=1)\n    state = tf.stack([state], axis=1)\n    return (outputs, state)"
        ]
    },
    {
        "func_name": "_inputs",
        "original": "def _inputs(problem, lstm_states, lstm_state_dims):\n    with tf.name_scope('inputs'):\n        n_views = problem.n_views\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        inputs.append(('rel_goal_loc_at_start', tf.float32, (problem.batch_size, problem.num_goals, problem.rel_goal_loc_dim)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('imgs', tf.float32, (problem.batch_size, None, n_views, problem.img_height, problem.img_width, problem.img_channels)))\n        inputs.append(('rel_goal_loc', tf.float32, (problem.batch_size, None, problem.rel_goal_loc_dim)))\n        if problem.outputs.visit_count:\n            inputs.append(('visit_count', tf.int32, (problem.batch_size, None, 1)))\n            inputs.append(('last_visit', tf.int32, (problem.batch_size, None, 1)))\n        for (i, (state, dim)) in enumerate(zip(lstm_states, lstm_state_dims)):\n            inputs.append((state, tf.float32, (problem.batch_size, 1, dim)))\n        if problem.outputs.egomotion:\n            inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n            inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('executed_actions', tf.int32, (problem.batch_size, None)))\n        inputs.append(('rewards', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action_sample_wts', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
        "mutated": [
            "def _inputs(problem, lstm_states, lstm_state_dims):\n    if False:\n        i = 10\n    with tf.name_scope('inputs'):\n        n_views = problem.n_views\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        inputs.append(('rel_goal_loc_at_start', tf.float32, (problem.batch_size, problem.num_goals, problem.rel_goal_loc_dim)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('imgs', tf.float32, (problem.batch_size, None, n_views, problem.img_height, problem.img_width, problem.img_channels)))\n        inputs.append(('rel_goal_loc', tf.float32, (problem.batch_size, None, problem.rel_goal_loc_dim)))\n        if problem.outputs.visit_count:\n            inputs.append(('visit_count', tf.int32, (problem.batch_size, None, 1)))\n            inputs.append(('last_visit', tf.int32, (problem.batch_size, None, 1)))\n        for (i, (state, dim)) in enumerate(zip(lstm_states, lstm_state_dims)):\n            inputs.append((state, tf.float32, (problem.batch_size, 1, dim)))\n        if problem.outputs.egomotion:\n            inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n            inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('executed_actions', tf.int32, (problem.batch_size, None)))\n        inputs.append(('rewards', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action_sample_wts', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem, lstm_states, lstm_state_dims):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.name_scope('inputs'):\n        n_views = problem.n_views\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        inputs.append(('rel_goal_loc_at_start', tf.float32, (problem.batch_size, problem.num_goals, problem.rel_goal_loc_dim)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('imgs', tf.float32, (problem.batch_size, None, n_views, problem.img_height, problem.img_width, problem.img_channels)))\n        inputs.append(('rel_goal_loc', tf.float32, (problem.batch_size, None, problem.rel_goal_loc_dim)))\n        if problem.outputs.visit_count:\n            inputs.append(('visit_count', tf.int32, (problem.batch_size, None, 1)))\n            inputs.append(('last_visit', tf.int32, (problem.batch_size, None, 1)))\n        for (i, (state, dim)) in enumerate(zip(lstm_states, lstm_state_dims)):\n            inputs.append((state, tf.float32, (problem.batch_size, 1, dim)))\n        if problem.outputs.egomotion:\n            inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n            inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('executed_actions', tf.int32, (problem.batch_size, None)))\n        inputs.append(('rewards', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action_sample_wts', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem, lstm_states, lstm_state_dims):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.name_scope('inputs'):\n        n_views = problem.n_views\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        inputs.append(('rel_goal_loc_at_start', tf.float32, (problem.batch_size, problem.num_goals, problem.rel_goal_loc_dim)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('imgs', tf.float32, (problem.batch_size, None, n_views, problem.img_height, problem.img_width, problem.img_channels)))\n        inputs.append(('rel_goal_loc', tf.float32, (problem.batch_size, None, problem.rel_goal_loc_dim)))\n        if problem.outputs.visit_count:\n            inputs.append(('visit_count', tf.int32, (problem.batch_size, None, 1)))\n            inputs.append(('last_visit', tf.int32, (problem.batch_size, None, 1)))\n        for (i, (state, dim)) in enumerate(zip(lstm_states, lstm_state_dims)):\n            inputs.append((state, tf.float32, (problem.batch_size, 1, dim)))\n        if problem.outputs.egomotion:\n            inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n            inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('executed_actions', tf.int32, (problem.batch_size, None)))\n        inputs.append(('rewards', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action_sample_wts', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem, lstm_states, lstm_state_dims):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.name_scope('inputs'):\n        n_views = problem.n_views\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        inputs.append(('rel_goal_loc_at_start', tf.float32, (problem.batch_size, problem.num_goals, problem.rel_goal_loc_dim)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('imgs', tf.float32, (problem.batch_size, None, n_views, problem.img_height, problem.img_width, problem.img_channels)))\n        inputs.append(('rel_goal_loc', tf.float32, (problem.batch_size, None, problem.rel_goal_loc_dim)))\n        if problem.outputs.visit_count:\n            inputs.append(('visit_count', tf.int32, (problem.batch_size, None, 1)))\n            inputs.append(('last_visit', tf.int32, (problem.batch_size, None, 1)))\n        for (i, (state, dim)) in enumerate(zip(lstm_states, lstm_state_dims)):\n            inputs.append((state, tf.float32, (problem.batch_size, 1, dim)))\n        if problem.outputs.egomotion:\n            inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n            inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('executed_actions', tf.int32, (problem.batch_size, None)))\n        inputs.append(('rewards', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action_sample_wts', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem, lstm_states, lstm_state_dims):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.name_scope('inputs'):\n        n_views = problem.n_views\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        inputs.append(('rel_goal_loc_at_start', tf.float32, (problem.batch_size, problem.num_goals, problem.rel_goal_loc_dim)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('imgs', tf.float32, (problem.batch_size, None, n_views, problem.img_height, problem.img_width, problem.img_channels)))\n        inputs.append(('rel_goal_loc', tf.float32, (problem.batch_size, None, problem.rel_goal_loc_dim)))\n        if problem.outputs.visit_count:\n            inputs.append(('visit_count', tf.int32, (problem.batch_size, None, 1)))\n            inputs.append(('last_visit', tf.int32, (problem.batch_size, None, 1)))\n        for (i, (state, dim)) in enumerate(zip(lstm_states, lstm_state_dims)):\n            inputs.append((state, tf.float32, (problem.batch_size, 1, dim)))\n        if problem.outputs.egomotion:\n            inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n            inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('executed_actions', tf.int32, (problem.batch_size, None)))\n        inputs.append(('rewards', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action_sample_wts', tf.float32, (problem.batch_size, None)))\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)"
        ]
    },
    {
        "func_name": "_add_summaries",
        "original": "def _add_summaries(m, summary_mode, arop_full_summary_iters):\n    summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op, m.total_loss_op, m.data_loss_op, m.reg_loss_op] + m.acc_ops\n    summarize_names = ['lr', 'global_step', 'sample_gt_prob_op', 'total_loss', 'data_loss', 'reg_loss'] + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n    to_aggregate = [0, 0, 0, 1, 1, 1] + [1] * len(m.acc_ops)\n    scope_name = 'summary'\n    with tf.name_scope(scope_name):\n        s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters, summarize_ops, summarize_names, to_aggregate, m.action_prob_op, m.input_tensors, scope_name=scope_name)\n        m.summary_ops = {summary_mode: s_ops}",
        "mutated": [
            "def _add_summaries(m, summary_mode, arop_full_summary_iters):\n    if False:\n        i = 10\n    summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op, m.total_loss_op, m.data_loss_op, m.reg_loss_op] + m.acc_ops\n    summarize_names = ['lr', 'global_step', 'sample_gt_prob_op', 'total_loss', 'data_loss', 'reg_loss'] + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n    to_aggregate = [0, 0, 0, 1, 1, 1] + [1] * len(m.acc_ops)\n    scope_name = 'summary'\n    with tf.name_scope(scope_name):\n        s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters, summarize_ops, summarize_names, to_aggregate, m.action_prob_op, m.input_tensors, scope_name=scope_name)\n        m.summary_ops = {summary_mode: s_ops}",
            "def _add_summaries(m, summary_mode, arop_full_summary_iters):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op, m.total_loss_op, m.data_loss_op, m.reg_loss_op] + m.acc_ops\n    summarize_names = ['lr', 'global_step', 'sample_gt_prob_op', 'total_loss', 'data_loss', 'reg_loss'] + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n    to_aggregate = [0, 0, 0, 1, 1, 1] + [1] * len(m.acc_ops)\n    scope_name = 'summary'\n    with tf.name_scope(scope_name):\n        s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters, summarize_ops, summarize_names, to_aggregate, m.action_prob_op, m.input_tensors, scope_name=scope_name)\n        m.summary_ops = {summary_mode: s_ops}",
            "def _add_summaries(m, summary_mode, arop_full_summary_iters):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op, m.total_loss_op, m.data_loss_op, m.reg_loss_op] + m.acc_ops\n    summarize_names = ['lr', 'global_step', 'sample_gt_prob_op', 'total_loss', 'data_loss', 'reg_loss'] + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n    to_aggregate = [0, 0, 0, 1, 1, 1] + [1] * len(m.acc_ops)\n    scope_name = 'summary'\n    with tf.name_scope(scope_name):\n        s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters, summarize_ops, summarize_names, to_aggregate, m.action_prob_op, m.input_tensors, scope_name=scope_name)\n        m.summary_ops = {summary_mode: s_ops}",
            "def _add_summaries(m, summary_mode, arop_full_summary_iters):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op, m.total_loss_op, m.data_loss_op, m.reg_loss_op] + m.acc_ops\n    summarize_names = ['lr', 'global_step', 'sample_gt_prob_op', 'total_loss', 'data_loss', 'reg_loss'] + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n    to_aggregate = [0, 0, 0, 1, 1, 1] + [1] * len(m.acc_ops)\n    scope_name = 'summary'\n    with tf.name_scope(scope_name):\n        s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters, summarize_ops, summarize_names, to_aggregate, m.action_prob_op, m.input_tensors, scope_name=scope_name)\n        m.summary_ops = {summary_mode: s_ops}",
            "def _add_summaries(m, summary_mode, arop_full_summary_iters):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op, m.total_loss_op, m.data_loss_op, m.reg_loss_op] + m.acc_ops\n    summarize_names = ['lr', 'global_step', 'sample_gt_prob_op', 'total_loss', 'data_loss', 'reg_loss'] + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n    to_aggregate = [0, 0, 0, 1, 1, 1] + [1] * len(m.acc_ops)\n    scope_name = 'summary'\n    with tf.name_scope(scope_name):\n        s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters, summarize_ops, summarize_names, to_aggregate, m.action_prob_op, m.input_tensors, scope_name=scope_name)\n        m.summary_ops = {summary_mode: s_ops}"
        ]
    },
    {
        "func_name": "visit_count_fc",
        "original": "def visit_count_fc(visit_count, last_visit, embed_neurons, wt_decay, fc_dropout):\n    with tf.variable_scope('embed_visit_count'):\n        visit_count = tf.reshape(visit_count, shape=[-1])\n        last_visit = tf.reshape(last_visit, shape=[-1])\n        visit_count = tf.clip_by_value(visit_count, clip_value_min=-1, clip_value_max=15)\n        last_visit = tf.clip_by_value(last_visit, clip_value_min=-1, clip_value_max=15)\n        visit_count = tf.one_hot(visit_count, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        last_visit = tf.one_hot(last_visit, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        f = tf.concat([visit_count, last_visit], 1)\n        (x, _) = tf_utils.fc_network(f, neurons=embed_neurons, wt_decay=wt_decay, name='visit_count_embed', offset=0, batch_norm_param=None, dropout_ratio=fc_dropout, is_training=is_training)\n    return x",
        "mutated": [
            "def visit_count_fc(visit_count, last_visit, embed_neurons, wt_decay, fc_dropout):\n    if False:\n        i = 10\n    with tf.variable_scope('embed_visit_count'):\n        visit_count = tf.reshape(visit_count, shape=[-1])\n        last_visit = tf.reshape(last_visit, shape=[-1])\n        visit_count = tf.clip_by_value(visit_count, clip_value_min=-1, clip_value_max=15)\n        last_visit = tf.clip_by_value(last_visit, clip_value_min=-1, clip_value_max=15)\n        visit_count = tf.one_hot(visit_count, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        last_visit = tf.one_hot(last_visit, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        f = tf.concat([visit_count, last_visit], 1)\n        (x, _) = tf_utils.fc_network(f, neurons=embed_neurons, wt_decay=wt_decay, name='visit_count_embed', offset=0, batch_norm_param=None, dropout_ratio=fc_dropout, is_training=is_training)\n    return x",
            "def visit_count_fc(visit_count, last_visit, embed_neurons, wt_decay, fc_dropout):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.variable_scope('embed_visit_count'):\n        visit_count = tf.reshape(visit_count, shape=[-1])\n        last_visit = tf.reshape(last_visit, shape=[-1])\n        visit_count = tf.clip_by_value(visit_count, clip_value_min=-1, clip_value_max=15)\n        last_visit = tf.clip_by_value(last_visit, clip_value_min=-1, clip_value_max=15)\n        visit_count = tf.one_hot(visit_count, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        last_visit = tf.one_hot(last_visit, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        f = tf.concat([visit_count, last_visit], 1)\n        (x, _) = tf_utils.fc_network(f, neurons=embed_neurons, wt_decay=wt_decay, name='visit_count_embed', offset=0, batch_norm_param=None, dropout_ratio=fc_dropout, is_training=is_training)\n    return x",
            "def visit_count_fc(visit_count, last_visit, embed_neurons, wt_decay, fc_dropout):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.variable_scope('embed_visit_count'):\n        visit_count = tf.reshape(visit_count, shape=[-1])\n        last_visit = tf.reshape(last_visit, shape=[-1])\n        visit_count = tf.clip_by_value(visit_count, clip_value_min=-1, clip_value_max=15)\n        last_visit = tf.clip_by_value(last_visit, clip_value_min=-1, clip_value_max=15)\n        visit_count = tf.one_hot(visit_count, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        last_visit = tf.one_hot(last_visit, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        f = tf.concat([visit_count, last_visit], 1)\n        (x, _) = tf_utils.fc_network(f, neurons=embed_neurons, wt_decay=wt_decay, name='visit_count_embed', offset=0, batch_norm_param=None, dropout_ratio=fc_dropout, is_training=is_training)\n    return x",
            "def visit_count_fc(visit_count, last_visit, embed_neurons, wt_decay, fc_dropout):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.variable_scope('embed_visit_count'):\n        visit_count = tf.reshape(visit_count, shape=[-1])\n        last_visit = tf.reshape(last_visit, shape=[-1])\n        visit_count = tf.clip_by_value(visit_count, clip_value_min=-1, clip_value_max=15)\n        last_visit = tf.clip_by_value(last_visit, clip_value_min=-1, clip_value_max=15)\n        visit_count = tf.one_hot(visit_count, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        last_visit = tf.one_hot(last_visit, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        f = tf.concat([visit_count, last_visit], 1)\n        (x, _) = tf_utils.fc_network(f, neurons=embed_neurons, wt_decay=wt_decay, name='visit_count_embed', offset=0, batch_norm_param=None, dropout_ratio=fc_dropout, is_training=is_training)\n    return x",
            "def visit_count_fc(visit_count, last_visit, embed_neurons, wt_decay, fc_dropout):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.variable_scope('embed_visit_count'):\n        visit_count = tf.reshape(visit_count, shape=[-1])\n        last_visit = tf.reshape(last_visit, shape=[-1])\n        visit_count = tf.clip_by_value(visit_count, clip_value_min=-1, clip_value_max=15)\n        last_visit = tf.clip_by_value(last_visit, clip_value_min=-1, clip_value_max=15)\n        visit_count = tf.one_hot(visit_count, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        last_visit = tf.one_hot(last_visit, depth=16, axis=1, dtype=tf.float32, on_value=10.0, off_value=0.0)\n        f = tf.concat([visit_count, last_visit], 1)\n        (x, _) = tf_utils.fc_network(f, neurons=embed_neurons, wt_decay=wt_decay, name='visit_count_embed', offset=0, batch_norm_param=None, dropout_ratio=fc_dropout, is_training=is_training)\n    return x"
        ]
    },
    {
        "func_name": "lstm_setup",
        "original": "def lstm_setup(name, x, batch_size, is_single_step, lstm_dim, lstm_out, num_steps, state_input_op):\n    with tf.name_scope('reshape_' + name):\n        sh = x.get_shape().as_list()\n        x = tf.reshape(x, shape=[batch_size, -1, sh[-1]])\n    with tf.variable_scope(name) as varscope:\n        cell = tf.contrib.rnn.LSTMCell(num_units=lstm_dim, forget_bias=1.0, state_is_tuple=False, num_proj=lstm_out, use_peepholes=True, initializer=tf.random_uniform_initializer(-0.01, 0.01, seed=0), cell_clip=None, proj_clip=None)\n        sh = [batch_size, 1, lstm_dim + lstm_out]\n        state_init_op = tf.constant(0.0, dtype=tf.float32, shape=sh)\n        fn = lambda ns: lstm_online(cell, ns, x, state_input_op, varscope)\n        (out_op, updated_state_op) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps))\n    return (name, state_init_op, updated_state_op, out_op)",
        "mutated": [
            "def lstm_setup(name, x, batch_size, is_single_step, lstm_dim, lstm_out, num_steps, state_input_op):\n    if False:\n        i = 10\n    with tf.name_scope('reshape_' + name):\n        sh = x.get_shape().as_list()\n        x = tf.reshape(x, shape=[batch_size, -1, sh[-1]])\n    with tf.variable_scope(name) as varscope:\n        cell = tf.contrib.rnn.LSTMCell(num_units=lstm_dim, forget_bias=1.0, state_is_tuple=False, num_proj=lstm_out, use_peepholes=True, initializer=tf.random_uniform_initializer(-0.01, 0.01, seed=0), cell_clip=None, proj_clip=None)\n        sh = [batch_size, 1, lstm_dim + lstm_out]\n        state_init_op = tf.constant(0.0, dtype=tf.float32, shape=sh)\n        fn = lambda ns: lstm_online(cell, ns, x, state_input_op, varscope)\n        (out_op, updated_state_op) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps))\n    return (name, state_init_op, updated_state_op, out_op)",
            "def lstm_setup(name, x, batch_size, is_single_step, lstm_dim, lstm_out, num_steps, state_input_op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.name_scope('reshape_' + name):\n        sh = x.get_shape().as_list()\n        x = tf.reshape(x, shape=[batch_size, -1, sh[-1]])\n    with tf.variable_scope(name) as varscope:\n        cell = tf.contrib.rnn.LSTMCell(num_units=lstm_dim, forget_bias=1.0, state_is_tuple=False, num_proj=lstm_out, use_peepholes=True, initializer=tf.random_uniform_initializer(-0.01, 0.01, seed=0), cell_clip=None, proj_clip=None)\n        sh = [batch_size, 1, lstm_dim + lstm_out]\n        state_init_op = tf.constant(0.0, dtype=tf.float32, shape=sh)\n        fn = lambda ns: lstm_online(cell, ns, x, state_input_op, varscope)\n        (out_op, updated_state_op) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps))\n    return (name, state_init_op, updated_state_op, out_op)",
            "def lstm_setup(name, x, batch_size, is_single_step, lstm_dim, lstm_out, num_steps, state_input_op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.name_scope('reshape_' + name):\n        sh = x.get_shape().as_list()\n        x = tf.reshape(x, shape=[batch_size, -1, sh[-1]])\n    with tf.variable_scope(name) as varscope:\n        cell = tf.contrib.rnn.LSTMCell(num_units=lstm_dim, forget_bias=1.0, state_is_tuple=False, num_proj=lstm_out, use_peepholes=True, initializer=tf.random_uniform_initializer(-0.01, 0.01, seed=0), cell_clip=None, proj_clip=None)\n        sh = [batch_size, 1, lstm_dim + lstm_out]\n        state_init_op = tf.constant(0.0, dtype=tf.float32, shape=sh)\n        fn = lambda ns: lstm_online(cell, ns, x, state_input_op, varscope)\n        (out_op, updated_state_op) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps))\n    return (name, state_init_op, updated_state_op, out_op)",
            "def lstm_setup(name, x, batch_size, is_single_step, lstm_dim, lstm_out, num_steps, state_input_op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.name_scope('reshape_' + name):\n        sh = x.get_shape().as_list()\n        x = tf.reshape(x, shape=[batch_size, -1, sh[-1]])\n    with tf.variable_scope(name) as varscope:\n        cell = tf.contrib.rnn.LSTMCell(num_units=lstm_dim, forget_bias=1.0, state_is_tuple=False, num_proj=lstm_out, use_peepholes=True, initializer=tf.random_uniform_initializer(-0.01, 0.01, seed=0), cell_clip=None, proj_clip=None)\n        sh = [batch_size, 1, lstm_dim + lstm_out]\n        state_init_op = tf.constant(0.0, dtype=tf.float32, shape=sh)\n        fn = lambda ns: lstm_online(cell, ns, x, state_input_op, varscope)\n        (out_op, updated_state_op) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps))\n    return (name, state_init_op, updated_state_op, out_op)",
            "def lstm_setup(name, x, batch_size, is_single_step, lstm_dim, lstm_out, num_steps, state_input_op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.name_scope('reshape_' + name):\n        sh = x.get_shape().as_list()\n        x = tf.reshape(x, shape=[batch_size, -1, sh[-1]])\n    with tf.variable_scope(name) as varscope:\n        cell = tf.contrib.rnn.LSTMCell(num_units=lstm_dim, forget_bias=1.0, state_is_tuple=False, num_proj=lstm_out, use_peepholes=True, initializer=tf.random_uniform_initializer(-0.01, 0.01, seed=0), cell_clip=None, proj_clip=None)\n        sh = [batch_size, 1, lstm_dim + lstm_out]\n        state_init_op = tf.constant(0.0, dtype=tf.float32, shape=sh)\n        fn = lambda ns: lstm_online(cell, ns, x, state_input_op, varscope)\n        (out_op, updated_state_op) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps))\n    return (name, state_init_op, updated_state_op, out_op)"
        ]
    },
    {
        "func_name": "combine_setup",
        "original": "def combine_setup(name, combine_type, embed_img, embed_goal, num_img_neuorons=None, num_goal_neurons=None):\n    with tf.name_scope(name + '_' + combine_type):\n        if combine_type == 'add':\n            out = embed_img + embed_goal\n        elif combine_type == 'multiply':\n            re_embed_img = tf.reshape(embed_img, shape=[-1, num_img_neuorons / num_goal_neurons, num_goal_neurons])\n            re_embed_goal = tf.reshape(embed_goal, shape=[-1, num_goal_neurons, 1])\n            x = tf.matmul(re_embed_img, re_embed_goal, transpose_a=False, transpose_b=False)\n            out = slim.flatten(x)\n        elif combine_type == 'none' or combine_type == 'imgonly':\n            out = embed_img\n        elif combine_type == 'goalonly':\n            out = embed_goal\n        else:\n            logging.fatal('Undefined combine_type: %s', combine_type)\n    return out",
        "mutated": [
            "def combine_setup(name, combine_type, embed_img, embed_goal, num_img_neuorons=None, num_goal_neurons=None):\n    if False:\n        i = 10\n    with tf.name_scope(name + '_' + combine_type):\n        if combine_type == 'add':\n            out = embed_img + embed_goal\n        elif combine_type == 'multiply':\n            re_embed_img = tf.reshape(embed_img, shape=[-1, num_img_neuorons / num_goal_neurons, num_goal_neurons])\n            re_embed_goal = tf.reshape(embed_goal, shape=[-1, num_goal_neurons, 1])\n            x = tf.matmul(re_embed_img, re_embed_goal, transpose_a=False, transpose_b=False)\n            out = slim.flatten(x)\n        elif combine_type == 'none' or combine_type == 'imgonly':\n            out = embed_img\n        elif combine_type == 'goalonly':\n            out = embed_goal\n        else:\n            logging.fatal('Undefined combine_type: %s', combine_type)\n    return out",
            "def combine_setup(name, combine_type, embed_img, embed_goal, num_img_neuorons=None, num_goal_neurons=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.name_scope(name + '_' + combine_type):\n        if combine_type == 'add':\n            out = embed_img + embed_goal\n        elif combine_type == 'multiply':\n            re_embed_img = tf.reshape(embed_img, shape=[-1, num_img_neuorons / num_goal_neurons, num_goal_neurons])\n            re_embed_goal = tf.reshape(embed_goal, shape=[-1, num_goal_neurons, 1])\n            x = tf.matmul(re_embed_img, re_embed_goal, transpose_a=False, transpose_b=False)\n            out = slim.flatten(x)\n        elif combine_type == 'none' or combine_type == 'imgonly':\n            out = embed_img\n        elif combine_type == 'goalonly':\n            out = embed_goal\n        else:\n            logging.fatal('Undefined combine_type: %s', combine_type)\n    return out",
            "def combine_setup(name, combine_type, embed_img, embed_goal, num_img_neuorons=None, num_goal_neurons=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.name_scope(name + '_' + combine_type):\n        if combine_type == 'add':\n            out = embed_img + embed_goal\n        elif combine_type == 'multiply':\n            re_embed_img = tf.reshape(embed_img, shape=[-1, num_img_neuorons / num_goal_neurons, num_goal_neurons])\n            re_embed_goal = tf.reshape(embed_goal, shape=[-1, num_goal_neurons, 1])\n            x = tf.matmul(re_embed_img, re_embed_goal, transpose_a=False, transpose_b=False)\n            out = slim.flatten(x)\n        elif combine_type == 'none' or combine_type == 'imgonly':\n            out = embed_img\n        elif combine_type == 'goalonly':\n            out = embed_goal\n        else:\n            logging.fatal('Undefined combine_type: %s', combine_type)\n    return out",
            "def combine_setup(name, combine_type, embed_img, embed_goal, num_img_neuorons=None, num_goal_neurons=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.name_scope(name + '_' + combine_type):\n        if combine_type == 'add':\n            out = embed_img + embed_goal\n        elif combine_type == 'multiply':\n            re_embed_img = tf.reshape(embed_img, shape=[-1, num_img_neuorons / num_goal_neurons, num_goal_neurons])\n            re_embed_goal = tf.reshape(embed_goal, shape=[-1, num_goal_neurons, 1])\n            x = tf.matmul(re_embed_img, re_embed_goal, transpose_a=False, transpose_b=False)\n            out = slim.flatten(x)\n        elif combine_type == 'none' or combine_type == 'imgonly':\n            out = embed_img\n        elif combine_type == 'goalonly':\n            out = embed_goal\n        else:\n            logging.fatal('Undefined combine_type: %s', combine_type)\n    return out",
            "def combine_setup(name, combine_type, embed_img, embed_goal, num_img_neuorons=None, num_goal_neurons=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.name_scope(name + '_' + combine_type):\n        if combine_type == 'add':\n            out = embed_img + embed_goal\n        elif combine_type == 'multiply':\n            re_embed_img = tf.reshape(embed_img, shape=[-1, num_img_neuorons / num_goal_neurons, num_goal_neurons])\n            re_embed_goal = tf.reshape(embed_goal, shape=[-1, num_goal_neurons, 1])\n            x = tf.matmul(re_embed_img, re_embed_goal, transpose_a=False, transpose_b=False)\n            out = slim.flatten(x)\n        elif combine_type == 'none' or combine_type == 'imgonly':\n            out = embed_img\n        elif combine_type == 'goalonly':\n            out = embed_goal\n        else:\n            logging.fatal('Undefined combine_type: %s', combine_type)\n    return out"
        ]
    },
    {
        "func_name": "preprocess_egomotion",
        "original": "def preprocess_egomotion(locs, thetas):\n    with tf.name_scope('pre_ego'):\n        pre_ego = tf.concat([locs, tf.sin(thetas), tf.cos(thetas)], 2)\n        sh = pre_ego.get_shape().as_list()\n        pre_ego = tf.reshape(pre_ego, [-1, sh[-1]])\n    return pre_ego",
        "mutated": [
            "def preprocess_egomotion(locs, thetas):\n    if False:\n        i = 10\n    with tf.name_scope('pre_ego'):\n        pre_ego = tf.concat([locs, tf.sin(thetas), tf.cos(thetas)], 2)\n        sh = pre_ego.get_shape().as_list()\n        pre_ego = tf.reshape(pre_ego, [-1, sh[-1]])\n    return pre_ego",
            "def preprocess_egomotion(locs, thetas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.name_scope('pre_ego'):\n        pre_ego = tf.concat([locs, tf.sin(thetas), tf.cos(thetas)], 2)\n        sh = pre_ego.get_shape().as_list()\n        pre_ego = tf.reshape(pre_ego, [-1, sh[-1]])\n    return pre_ego",
            "def preprocess_egomotion(locs, thetas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.name_scope('pre_ego'):\n        pre_ego = tf.concat([locs, tf.sin(thetas), tf.cos(thetas)], 2)\n        sh = pre_ego.get_shape().as_list()\n        pre_ego = tf.reshape(pre_ego, [-1, sh[-1]])\n    return pre_ego",
            "def preprocess_egomotion(locs, thetas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.name_scope('pre_ego'):\n        pre_ego = tf.concat([locs, tf.sin(thetas), tf.cos(thetas)], 2)\n        sh = pre_ego.get_shape().as_list()\n        pre_ego = tf.reshape(pre_ego, [-1, sh[-1]])\n    return pre_ego",
            "def preprocess_egomotion(locs, thetas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.name_scope('pre_ego'):\n        pre_ego = tf.concat([locs, tf.sin(thetas), tf.cos(thetas)], 2)\n        sh = pre_ego.get_shape().as_list()\n        pre_ego = tf.reshape(pre_ego, [-1, sh[-1]])\n    return pre_ego"
        ]
    },
    {
        "func_name": "setup_to_run",
        "original": "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    num_actions = task_params.num_actions\n    num_actions_ = num_actions\n    n_views = task_params.n_views\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    lstm_states = []\n    lstm_state_dims = []\n    state_names = []\n    updated_state_ops = []\n    init_state_ops = []\n    if args.arch.lstm_output:\n        lstm_states += ['lstm_output']\n        lstm_state_dims += [args.arch.lstm_output_dim + task_params.num_actions]\n    if args.arch.lstm_ego:\n        lstm_states += ['lstm_ego']\n        lstm_state_dims += [args.arch.lstm_ego_dim + args.arch.lstm_ego_out]\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    elif args.arch.lstm_img:\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    else:\n        None\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params, lstm_states, lstm_state_dims)\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.input_tensors['step']['imgs']), num=6)[1], 1)\n    images_reshaped = tf.reshape(m.input_tensors['step']['imgs'], shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    rel_goal_loc_reshaped = tf.reshape(m.input_tensors['step']['rel_goal_loc'], shape=[-1, task_params.rel_goal_loc_dim], name='re_rel_goal_loc')\n    (x, vars_) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, args.arch.encoder, args.solver.freeze_conv, args.solver.wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    m.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(m.encoder_output, shape=[-1] + sh_before[1:])\n    if args.arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = args.arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        m.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(args.solver.wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(m.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        m.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    if args.solver.pretrained_path is not None:\n        m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, vars_)\n    else:\n        m.init_fn = None\n    with tf.variable_scope('embed_goal'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_goal, _) = tf_utils.fc_network(rel_goal_loc_reshaped, neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.embed_goal_for_state:\n        with tf.variable_scope('embed_goal_for_state'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_goal_for_state, _) = tf_utils.fc_network(m.input_tensors['common']['rel_goal_loc_at_start'][:, 0, :], neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    with tf.variable_scope('embed_img'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_img, _) = tf_utils.fc_network(m.reshape_conv_feat, neurons=args.arch.img_embed_neurons, wt_decay=args.solver.wt_decay, name='img_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.lstm_ego:\n        ego_reshaped = preprocess_egomotion(m.input_tensors['step']['incremental_locs'], m.input_tensors['step']['incremental_thetas'])\n        with tf.variable_scope('embed_ego'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_ego, _) = tf_utils.fc_network(ego_reshaped, neurons=args.arch.ego_embed_neurons, wt_decay=args.solver.wt_decay, name='ego_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_ego', m.embed_ego, task_params.batch_size, is_single_step, args.arch.lstm_ego_dim, args.arch.lstm_ego_out, num_steps * num_goals, m.input_tensors['step']['lstm_ego'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_ego_op = combine_setup('img_ego', args.arch.combine_type_ego, m.embed_img, out_op, args.arch.img_embed_neurons[-1], args.arch.lstm_ego_out)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.img_ego_op, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    elif args.arch.lstm_img:\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.embed_img, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    else:\n        m.img_for_goal = m.embed_img\n        num_img_for_goal_neurons = args.arch.img_embed_neurons[-1]\n    if args.arch.use_visit_count:\n        m.embed_visit_count = visit_count_fc(m.input_tensors['step']['visit_count'], m.input_tensors['step']['last_visit'], args.arch.goal_embed_neurons, args.solver.wt_decay, args.arch.fc_dropout, is_training=is_training)\n        m.embed_goal = m.embed_goal + m.embed_visit_count\n    m.combined_f = combine_setup('img_goal', args.arch.combine_type, m.img_for_goal, m.embed_goal, num_img_for_goal_neurons, args.arch.goal_embed_neurons[-1])\n    if args.arch.lstm_output:\n        name = 'lstm_output'\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (x, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout)\n        if args.arch.lstm_output_init_state_from_goal:\n            m.embed_goal_for_state = tf.expand_dims(m.embed_goal_for_state, dim=1)\n            state_op = tf.cond(is_single_step, lambda : m.input_tensors['step'][name], lambda : m.embed_goal_for_state)\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [m.embed_goal_for_state]\n        else:\n            state_op = m.input_tensors['step'][name]\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [state_init_op]\n        state_names += [state_name]\n        updated_state_ops += [updated_state_op]\n        out_op = tf.reshape(out_op, shape=[-1, num_actions_])\n        if num_actions_ > num_actions:\n            m.action_logits_op = out_op[:, :num_actions]\n            m.baseline_op = out_op[:, num_actions:]\n        else:\n            m.action_logits_op = out_op\n            m.baseline_op = None\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    else:\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (out_op, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=num_actions_, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n            if num_actions_ > num_actions:\n                m.action_logits_op = out_op[:, :num_actions]\n                m.baseline_op = out_op[:, num_actions:]\n            else:\n                m.action_logits_op = out_op\n                m.baseline_op = None\n            m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    m.train_ops = {}\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc'], m.input_tensors['common']['rel_goal_loc_at_start']]\n    m.train_ops['state_names'] = state_names\n    m.train_ops['init_state'] = init_state_ops\n    m.train_ops['updated_state'] = updated_state_ops\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.train_ops['step_data_cache'] = [tf.no_op()]\n    if args.solver.freeze_conv:\n        m.train_ops['step_data_cache'] = [m.encoder_output]\n    else:\n        m.train_ops['step_data_cache'] = []\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(vars_))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    _add_summaries(m, summary_mode, args.summary.arop_full_summary_iters)\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
        "mutated": [
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    num_actions = task_params.num_actions\n    num_actions_ = num_actions\n    n_views = task_params.n_views\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    lstm_states = []\n    lstm_state_dims = []\n    state_names = []\n    updated_state_ops = []\n    init_state_ops = []\n    if args.arch.lstm_output:\n        lstm_states += ['lstm_output']\n        lstm_state_dims += [args.arch.lstm_output_dim + task_params.num_actions]\n    if args.arch.lstm_ego:\n        lstm_states += ['lstm_ego']\n        lstm_state_dims += [args.arch.lstm_ego_dim + args.arch.lstm_ego_out]\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    elif args.arch.lstm_img:\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    else:\n        None\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params, lstm_states, lstm_state_dims)\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.input_tensors['step']['imgs']), num=6)[1], 1)\n    images_reshaped = tf.reshape(m.input_tensors['step']['imgs'], shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    rel_goal_loc_reshaped = tf.reshape(m.input_tensors['step']['rel_goal_loc'], shape=[-1, task_params.rel_goal_loc_dim], name='re_rel_goal_loc')\n    (x, vars_) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, args.arch.encoder, args.solver.freeze_conv, args.solver.wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    m.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(m.encoder_output, shape=[-1] + sh_before[1:])\n    if args.arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = args.arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        m.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(args.solver.wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(m.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        m.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    if args.solver.pretrained_path is not None:\n        m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, vars_)\n    else:\n        m.init_fn = None\n    with tf.variable_scope('embed_goal'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_goal, _) = tf_utils.fc_network(rel_goal_loc_reshaped, neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.embed_goal_for_state:\n        with tf.variable_scope('embed_goal_for_state'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_goal_for_state, _) = tf_utils.fc_network(m.input_tensors['common']['rel_goal_loc_at_start'][:, 0, :], neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    with tf.variable_scope('embed_img'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_img, _) = tf_utils.fc_network(m.reshape_conv_feat, neurons=args.arch.img_embed_neurons, wt_decay=args.solver.wt_decay, name='img_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.lstm_ego:\n        ego_reshaped = preprocess_egomotion(m.input_tensors['step']['incremental_locs'], m.input_tensors['step']['incremental_thetas'])\n        with tf.variable_scope('embed_ego'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_ego, _) = tf_utils.fc_network(ego_reshaped, neurons=args.arch.ego_embed_neurons, wt_decay=args.solver.wt_decay, name='ego_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_ego', m.embed_ego, task_params.batch_size, is_single_step, args.arch.lstm_ego_dim, args.arch.lstm_ego_out, num_steps * num_goals, m.input_tensors['step']['lstm_ego'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_ego_op = combine_setup('img_ego', args.arch.combine_type_ego, m.embed_img, out_op, args.arch.img_embed_neurons[-1], args.arch.lstm_ego_out)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.img_ego_op, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    elif args.arch.lstm_img:\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.embed_img, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    else:\n        m.img_for_goal = m.embed_img\n        num_img_for_goal_neurons = args.arch.img_embed_neurons[-1]\n    if args.arch.use_visit_count:\n        m.embed_visit_count = visit_count_fc(m.input_tensors['step']['visit_count'], m.input_tensors['step']['last_visit'], args.arch.goal_embed_neurons, args.solver.wt_decay, args.arch.fc_dropout, is_training=is_training)\n        m.embed_goal = m.embed_goal + m.embed_visit_count\n    m.combined_f = combine_setup('img_goal', args.arch.combine_type, m.img_for_goal, m.embed_goal, num_img_for_goal_neurons, args.arch.goal_embed_neurons[-1])\n    if args.arch.lstm_output:\n        name = 'lstm_output'\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (x, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout)\n        if args.arch.lstm_output_init_state_from_goal:\n            m.embed_goal_for_state = tf.expand_dims(m.embed_goal_for_state, dim=1)\n            state_op = tf.cond(is_single_step, lambda : m.input_tensors['step'][name], lambda : m.embed_goal_for_state)\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [m.embed_goal_for_state]\n        else:\n            state_op = m.input_tensors['step'][name]\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [state_init_op]\n        state_names += [state_name]\n        updated_state_ops += [updated_state_op]\n        out_op = tf.reshape(out_op, shape=[-1, num_actions_])\n        if num_actions_ > num_actions:\n            m.action_logits_op = out_op[:, :num_actions]\n            m.baseline_op = out_op[:, num_actions:]\n        else:\n            m.action_logits_op = out_op\n            m.baseline_op = None\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    else:\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (out_op, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=num_actions_, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n            if num_actions_ > num_actions:\n                m.action_logits_op = out_op[:, :num_actions]\n                m.baseline_op = out_op[:, num_actions:]\n            else:\n                m.action_logits_op = out_op\n                m.baseline_op = None\n            m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    m.train_ops = {}\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc'], m.input_tensors['common']['rel_goal_loc_at_start']]\n    m.train_ops['state_names'] = state_names\n    m.train_ops['init_state'] = init_state_ops\n    m.train_ops['updated_state'] = updated_state_ops\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.train_ops['step_data_cache'] = [tf.no_op()]\n    if args.solver.freeze_conv:\n        m.train_ops['step_data_cache'] = [m.encoder_output]\n    else:\n        m.train_ops['step_data_cache'] = []\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(vars_))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    _add_summaries(m, summary_mode, args.summary.arop_full_summary_iters)\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    num_actions = task_params.num_actions\n    num_actions_ = num_actions\n    n_views = task_params.n_views\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    lstm_states = []\n    lstm_state_dims = []\n    state_names = []\n    updated_state_ops = []\n    init_state_ops = []\n    if args.arch.lstm_output:\n        lstm_states += ['lstm_output']\n        lstm_state_dims += [args.arch.lstm_output_dim + task_params.num_actions]\n    if args.arch.lstm_ego:\n        lstm_states += ['lstm_ego']\n        lstm_state_dims += [args.arch.lstm_ego_dim + args.arch.lstm_ego_out]\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    elif args.arch.lstm_img:\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    else:\n        None\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params, lstm_states, lstm_state_dims)\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.input_tensors['step']['imgs']), num=6)[1], 1)\n    images_reshaped = tf.reshape(m.input_tensors['step']['imgs'], shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    rel_goal_loc_reshaped = tf.reshape(m.input_tensors['step']['rel_goal_loc'], shape=[-1, task_params.rel_goal_loc_dim], name='re_rel_goal_loc')\n    (x, vars_) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, args.arch.encoder, args.solver.freeze_conv, args.solver.wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    m.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(m.encoder_output, shape=[-1] + sh_before[1:])\n    if args.arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = args.arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        m.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(args.solver.wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(m.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        m.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    if args.solver.pretrained_path is not None:\n        m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, vars_)\n    else:\n        m.init_fn = None\n    with tf.variable_scope('embed_goal'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_goal, _) = tf_utils.fc_network(rel_goal_loc_reshaped, neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.embed_goal_for_state:\n        with tf.variable_scope('embed_goal_for_state'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_goal_for_state, _) = tf_utils.fc_network(m.input_tensors['common']['rel_goal_loc_at_start'][:, 0, :], neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    with tf.variable_scope('embed_img'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_img, _) = tf_utils.fc_network(m.reshape_conv_feat, neurons=args.arch.img_embed_neurons, wt_decay=args.solver.wt_decay, name='img_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.lstm_ego:\n        ego_reshaped = preprocess_egomotion(m.input_tensors['step']['incremental_locs'], m.input_tensors['step']['incremental_thetas'])\n        with tf.variable_scope('embed_ego'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_ego, _) = tf_utils.fc_network(ego_reshaped, neurons=args.arch.ego_embed_neurons, wt_decay=args.solver.wt_decay, name='ego_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_ego', m.embed_ego, task_params.batch_size, is_single_step, args.arch.lstm_ego_dim, args.arch.lstm_ego_out, num_steps * num_goals, m.input_tensors['step']['lstm_ego'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_ego_op = combine_setup('img_ego', args.arch.combine_type_ego, m.embed_img, out_op, args.arch.img_embed_neurons[-1], args.arch.lstm_ego_out)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.img_ego_op, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    elif args.arch.lstm_img:\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.embed_img, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    else:\n        m.img_for_goal = m.embed_img\n        num_img_for_goal_neurons = args.arch.img_embed_neurons[-1]\n    if args.arch.use_visit_count:\n        m.embed_visit_count = visit_count_fc(m.input_tensors['step']['visit_count'], m.input_tensors['step']['last_visit'], args.arch.goal_embed_neurons, args.solver.wt_decay, args.arch.fc_dropout, is_training=is_training)\n        m.embed_goal = m.embed_goal + m.embed_visit_count\n    m.combined_f = combine_setup('img_goal', args.arch.combine_type, m.img_for_goal, m.embed_goal, num_img_for_goal_neurons, args.arch.goal_embed_neurons[-1])\n    if args.arch.lstm_output:\n        name = 'lstm_output'\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (x, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout)\n        if args.arch.lstm_output_init_state_from_goal:\n            m.embed_goal_for_state = tf.expand_dims(m.embed_goal_for_state, dim=1)\n            state_op = tf.cond(is_single_step, lambda : m.input_tensors['step'][name], lambda : m.embed_goal_for_state)\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [m.embed_goal_for_state]\n        else:\n            state_op = m.input_tensors['step'][name]\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [state_init_op]\n        state_names += [state_name]\n        updated_state_ops += [updated_state_op]\n        out_op = tf.reshape(out_op, shape=[-1, num_actions_])\n        if num_actions_ > num_actions:\n            m.action_logits_op = out_op[:, :num_actions]\n            m.baseline_op = out_op[:, num_actions:]\n        else:\n            m.action_logits_op = out_op\n            m.baseline_op = None\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    else:\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (out_op, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=num_actions_, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n            if num_actions_ > num_actions:\n                m.action_logits_op = out_op[:, :num_actions]\n                m.baseline_op = out_op[:, num_actions:]\n            else:\n                m.action_logits_op = out_op\n                m.baseline_op = None\n            m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    m.train_ops = {}\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc'], m.input_tensors['common']['rel_goal_loc_at_start']]\n    m.train_ops['state_names'] = state_names\n    m.train_ops['init_state'] = init_state_ops\n    m.train_ops['updated_state'] = updated_state_ops\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.train_ops['step_data_cache'] = [tf.no_op()]\n    if args.solver.freeze_conv:\n        m.train_ops['step_data_cache'] = [m.encoder_output]\n    else:\n        m.train_ops['step_data_cache'] = []\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(vars_))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    _add_summaries(m, summary_mode, args.summary.arop_full_summary_iters)\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    num_actions = task_params.num_actions\n    num_actions_ = num_actions\n    n_views = task_params.n_views\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    lstm_states = []\n    lstm_state_dims = []\n    state_names = []\n    updated_state_ops = []\n    init_state_ops = []\n    if args.arch.lstm_output:\n        lstm_states += ['lstm_output']\n        lstm_state_dims += [args.arch.lstm_output_dim + task_params.num_actions]\n    if args.arch.lstm_ego:\n        lstm_states += ['lstm_ego']\n        lstm_state_dims += [args.arch.lstm_ego_dim + args.arch.lstm_ego_out]\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    elif args.arch.lstm_img:\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    else:\n        None\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params, lstm_states, lstm_state_dims)\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.input_tensors['step']['imgs']), num=6)[1], 1)\n    images_reshaped = tf.reshape(m.input_tensors['step']['imgs'], shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    rel_goal_loc_reshaped = tf.reshape(m.input_tensors['step']['rel_goal_loc'], shape=[-1, task_params.rel_goal_loc_dim], name='re_rel_goal_loc')\n    (x, vars_) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, args.arch.encoder, args.solver.freeze_conv, args.solver.wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    m.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(m.encoder_output, shape=[-1] + sh_before[1:])\n    if args.arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = args.arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        m.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(args.solver.wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(m.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        m.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    if args.solver.pretrained_path is not None:\n        m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, vars_)\n    else:\n        m.init_fn = None\n    with tf.variable_scope('embed_goal'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_goal, _) = tf_utils.fc_network(rel_goal_loc_reshaped, neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.embed_goal_for_state:\n        with tf.variable_scope('embed_goal_for_state'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_goal_for_state, _) = tf_utils.fc_network(m.input_tensors['common']['rel_goal_loc_at_start'][:, 0, :], neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    with tf.variable_scope('embed_img'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_img, _) = tf_utils.fc_network(m.reshape_conv_feat, neurons=args.arch.img_embed_neurons, wt_decay=args.solver.wt_decay, name='img_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.lstm_ego:\n        ego_reshaped = preprocess_egomotion(m.input_tensors['step']['incremental_locs'], m.input_tensors['step']['incremental_thetas'])\n        with tf.variable_scope('embed_ego'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_ego, _) = tf_utils.fc_network(ego_reshaped, neurons=args.arch.ego_embed_neurons, wt_decay=args.solver.wt_decay, name='ego_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_ego', m.embed_ego, task_params.batch_size, is_single_step, args.arch.lstm_ego_dim, args.arch.lstm_ego_out, num_steps * num_goals, m.input_tensors['step']['lstm_ego'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_ego_op = combine_setup('img_ego', args.arch.combine_type_ego, m.embed_img, out_op, args.arch.img_embed_neurons[-1], args.arch.lstm_ego_out)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.img_ego_op, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    elif args.arch.lstm_img:\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.embed_img, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    else:\n        m.img_for_goal = m.embed_img\n        num_img_for_goal_neurons = args.arch.img_embed_neurons[-1]\n    if args.arch.use_visit_count:\n        m.embed_visit_count = visit_count_fc(m.input_tensors['step']['visit_count'], m.input_tensors['step']['last_visit'], args.arch.goal_embed_neurons, args.solver.wt_decay, args.arch.fc_dropout, is_training=is_training)\n        m.embed_goal = m.embed_goal + m.embed_visit_count\n    m.combined_f = combine_setup('img_goal', args.arch.combine_type, m.img_for_goal, m.embed_goal, num_img_for_goal_neurons, args.arch.goal_embed_neurons[-1])\n    if args.arch.lstm_output:\n        name = 'lstm_output'\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (x, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout)\n        if args.arch.lstm_output_init_state_from_goal:\n            m.embed_goal_for_state = tf.expand_dims(m.embed_goal_for_state, dim=1)\n            state_op = tf.cond(is_single_step, lambda : m.input_tensors['step'][name], lambda : m.embed_goal_for_state)\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [m.embed_goal_for_state]\n        else:\n            state_op = m.input_tensors['step'][name]\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [state_init_op]\n        state_names += [state_name]\n        updated_state_ops += [updated_state_op]\n        out_op = tf.reshape(out_op, shape=[-1, num_actions_])\n        if num_actions_ > num_actions:\n            m.action_logits_op = out_op[:, :num_actions]\n            m.baseline_op = out_op[:, num_actions:]\n        else:\n            m.action_logits_op = out_op\n            m.baseline_op = None\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    else:\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (out_op, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=num_actions_, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n            if num_actions_ > num_actions:\n                m.action_logits_op = out_op[:, :num_actions]\n                m.baseline_op = out_op[:, num_actions:]\n            else:\n                m.action_logits_op = out_op\n                m.baseline_op = None\n            m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    m.train_ops = {}\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc'], m.input_tensors['common']['rel_goal_loc_at_start']]\n    m.train_ops['state_names'] = state_names\n    m.train_ops['init_state'] = init_state_ops\n    m.train_ops['updated_state'] = updated_state_ops\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.train_ops['step_data_cache'] = [tf.no_op()]\n    if args.solver.freeze_conv:\n        m.train_ops['step_data_cache'] = [m.encoder_output]\n    else:\n        m.train_ops['step_data_cache'] = []\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(vars_))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    _add_summaries(m, summary_mode, args.summary.arop_full_summary_iters)\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    num_actions = task_params.num_actions\n    num_actions_ = num_actions\n    n_views = task_params.n_views\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    lstm_states = []\n    lstm_state_dims = []\n    state_names = []\n    updated_state_ops = []\n    init_state_ops = []\n    if args.arch.lstm_output:\n        lstm_states += ['lstm_output']\n        lstm_state_dims += [args.arch.lstm_output_dim + task_params.num_actions]\n    if args.arch.lstm_ego:\n        lstm_states += ['lstm_ego']\n        lstm_state_dims += [args.arch.lstm_ego_dim + args.arch.lstm_ego_out]\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    elif args.arch.lstm_img:\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    else:\n        None\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params, lstm_states, lstm_state_dims)\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.input_tensors['step']['imgs']), num=6)[1], 1)\n    images_reshaped = tf.reshape(m.input_tensors['step']['imgs'], shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    rel_goal_loc_reshaped = tf.reshape(m.input_tensors['step']['rel_goal_loc'], shape=[-1, task_params.rel_goal_loc_dim], name='re_rel_goal_loc')\n    (x, vars_) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, args.arch.encoder, args.solver.freeze_conv, args.solver.wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    m.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(m.encoder_output, shape=[-1] + sh_before[1:])\n    if args.arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = args.arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        m.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(args.solver.wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(m.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        m.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    if args.solver.pretrained_path is not None:\n        m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, vars_)\n    else:\n        m.init_fn = None\n    with tf.variable_scope('embed_goal'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_goal, _) = tf_utils.fc_network(rel_goal_loc_reshaped, neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.embed_goal_for_state:\n        with tf.variable_scope('embed_goal_for_state'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_goal_for_state, _) = tf_utils.fc_network(m.input_tensors['common']['rel_goal_loc_at_start'][:, 0, :], neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    with tf.variable_scope('embed_img'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_img, _) = tf_utils.fc_network(m.reshape_conv_feat, neurons=args.arch.img_embed_neurons, wt_decay=args.solver.wt_decay, name='img_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.lstm_ego:\n        ego_reshaped = preprocess_egomotion(m.input_tensors['step']['incremental_locs'], m.input_tensors['step']['incremental_thetas'])\n        with tf.variable_scope('embed_ego'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_ego, _) = tf_utils.fc_network(ego_reshaped, neurons=args.arch.ego_embed_neurons, wt_decay=args.solver.wt_decay, name='ego_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_ego', m.embed_ego, task_params.batch_size, is_single_step, args.arch.lstm_ego_dim, args.arch.lstm_ego_out, num_steps * num_goals, m.input_tensors['step']['lstm_ego'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_ego_op = combine_setup('img_ego', args.arch.combine_type_ego, m.embed_img, out_op, args.arch.img_embed_neurons[-1], args.arch.lstm_ego_out)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.img_ego_op, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    elif args.arch.lstm_img:\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.embed_img, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    else:\n        m.img_for_goal = m.embed_img\n        num_img_for_goal_neurons = args.arch.img_embed_neurons[-1]\n    if args.arch.use_visit_count:\n        m.embed_visit_count = visit_count_fc(m.input_tensors['step']['visit_count'], m.input_tensors['step']['last_visit'], args.arch.goal_embed_neurons, args.solver.wt_decay, args.arch.fc_dropout, is_training=is_training)\n        m.embed_goal = m.embed_goal + m.embed_visit_count\n    m.combined_f = combine_setup('img_goal', args.arch.combine_type, m.img_for_goal, m.embed_goal, num_img_for_goal_neurons, args.arch.goal_embed_neurons[-1])\n    if args.arch.lstm_output:\n        name = 'lstm_output'\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (x, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout)\n        if args.arch.lstm_output_init_state_from_goal:\n            m.embed_goal_for_state = tf.expand_dims(m.embed_goal_for_state, dim=1)\n            state_op = tf.cond(is_single_step, lambda : m.input_tensors['step'][name], lambda : m.embed_goal_for_state)\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [m.embed_goal_for_state]\n        else:\n            state_op = m.input_tensors['step'][name]\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [state_init_op]\n        state_names += [state_name]\n        updated_state_ops += [updated_state_op]\n        out_op = tf.reshape(out_op, shape=[-1, num_actions_])\n        if num_actions_ > num_actions:\n            m.action_logits_op = out_op[:, :num_actions]\n            m.baseline_op = out_op[:, num_actions:]\n        else:\n            m.action_logits_op = out_op\n            m.baseline_op = None\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    else:\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (out_op, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=num_actions_, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n            if num_actions_ > num_actions:\n                m.action_logits_op = out_op[:, :num_actions]\n                m.baseline_op = out_op[:, num_actions:]\n            else:\n                m.action_logits_op = out_op\n                m.baseline_op = None\n            m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    m.train_ops = {}\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc'], m.input_tensors['common']['rel_goal_loc_at_start']]\n    m.train_ops['state_names'] = state_names\n    m.train_ops['init_state'] = init_state_ops\n    m.train_ops['updated_state'] = updated_state_ops\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.train_ops['step_data_cache'] = [tf.no_op()]\n    if args.solver.freeze_conv:\n        m.train_ops['step_data_cache'] = [m.encoder_output]\n    else:\n        m.train_ops['step_data_cache'] = []\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(vars_))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    _add_summaries(m, summary_mode, args.summary.arop_full_summary_iters)\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    num_actions = task_params.num_actions\n    num_actions_ = num_actions\n    n_views = task_params.n_views\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    lstm_states = []\n    lstm_state_dims = []\n    state_names = []\n    updated_state_ops = []\n    init_state_ops = []\n    if args.arch.lstm_output:\n        lstm_states += ['lstm_output']\n        lstm_state_dims += [args.arch.lstm_output_dim + task_params.num_actions]\n    if args.arch.lstm_ego:\n        lstm_states += ['lstm_ego']\n        lstm_state_dims += [args.arch.lstm_ego_dim + args.arch.lstm_ego_out]\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    elif args.arch.lstm_img:\n        lstm_states += ['lstm_img']\n        lstm_state_dims += [args.arch.lstm_img_dim + args.arch.lstm_img_out]\n    else:\n        None\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params, lstm_states, lstm_state_dims)\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.input_tensors['step']['imgs']), num=6)[1], 1)\n    images_reshaped = tf.reshape(m.input_tensors['step']['imgs'], shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    rel_goal_loc_reshaped = tf.reshape(m.input_tensors['step']['rel_goal_loc'], shape=[-1, task_params.rel_goal_loc_dim], name='re_rel_goal_loc')\n    (x, vars_) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, args.arch.encoder, args.solver.freeze_conv, args.solver.wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    m.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(m.encoder_output, shape=[-1] + sh_before[1:])\n    if args.arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = args.arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        m.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(args.solver.wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(m.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        m.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    if args.solver.pretrained_path is not None:\n        m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, vars_)\n    else:\n        m.init_fn = None\n    with tf.variable_scope('embed_goal'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_goal, _) = tf_utils.fc_network(rel_goal_loc_reshaped, neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.embed_goal_for_state:\n        with tf.variable_scope('embed_goal_for_state'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_goal_for_state, _) = tf_utils.fc_network(m.input_tensors['common']['rel_goal_loc_at_start'][:, 0, :], neurons=args.arch.goal_embed_neurons, wt_decay=args.solver.wt_decay, name='goal_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    with tf.variable_scope('embed_img'):\n        batch_norm_param = args.arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.embed_img, _) = tf_utils.fc_network(m.reshape_conv_feat, neurons=args.arch.img_embed_neurons, wt_decay=args.solver.wt_decay, name='img_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n    if args.arch.lstm_ego:\n        ego_reshaped = preprocess_egomotion(m.input_tensors['step']['incremental_locs'], m.input_tensors['step']['incremental_thetas'])\n        with tf.variable_scope('embed_ego'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (m.embed_ego, _) = tf_utils.fc_network(ego_reshaped, neurons=args.arch.ego_embed_neurons, wt_decay=args.solver.wt_decay, name='ego_embed', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_ego', m.embed_ego, task_params.batch_size, is_single_step, args.arch.lstm_ego_dim, args.arch.lstm_ego_out, num_steps * num_goals, m.input_tensors['step']['lstm_ego'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_ego_op = combine_setup('img_ego', args.arch.combine_type_ego, m.embed_img, out_op, args.arch.img_embed_neurons[-1], args.arch.lstm_ego_out)\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.img_ego_op, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    elif args.arch.lstm_img:\n        (state_name, state_init_op, updated_state_op, out_op) = lstm_setup('lstm_img', m.embed_img, task_params.batch_size, is_single_step, args.arch.lstm_img_dim, args.arch.lstm_img_out, num_steps * num_goals, m.input_tensors['step']['lstm_img'])\n        state_names += [state_name]\n        init_state_ops += [state_init_op]\n        updated_state_ops += [updated_state_op]\n        m.img_for_goal = out_op\n        num_img_for_goal_neurons = args.arch.lstm_img_out\n    else:\n        m.img_for_goal = m.embed_img\n        num_img_for_goal_neurons = args.arch.img_embed_neurons[-1]\n    if args.arch.use_visit_count:\n        m.embed_visit_count = visit_count_fc(m.input_tensors['step']['visit_count'], m.input_tensors['step']['last_visit'], args.arch.goal_embed_neurons, args.solver.wt_decay, args.arch.fc_dropout, is_training=is_training)\n        m.embed_goal = m.embed_goal + m.embed_visit_count\n    m.combined_f = combine_setup('img_goal', args.arch.combine_type, m.img_for_goal, m.embed_goal, num_img_for_goal_neurons, args.arch.goal_embed_neurons[-1])\n    if args.arch.lstm_output:\n        name = 'lstm_output'\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (x, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout)\n        if args.arch.lstm_output_init_state_from_goal:\n            m.embed_goal_for_state = tf.expand_dims(m.embed_goal_for_state, dim=1)\n            state_op = tf.cond(is_single_step, lambda : m.input_tensors['step'][name], lambda : m.embed_goal_for_state)\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [m.embed_goal_for_state]\n        else:\n            state_op = m.input_tensors['step'][name]\n            (state_name, state_init_op, updated_state_op, out_op) = lstm_setup(name, x, task_params.batch_size, is_single_step, args.arch.lstm_output_dim, num_actions_, num_steps * num_goals, state_op)\n            init_state_ops += [state_init_op]\n        state_names += [state_name]\n        updated_state_ops += [updated_state_op]\n        out_op = tf.reshape(out_op, shape=[-1, num_actions_])\n        if num_actions_ > num_actions:\n            m.action_logits_op = out_op[:, :num_actions]\n            m.baseline_op = out_op[:, num_actions:]\n        else:\n            m.action_logits_op = out_op\n            m.baseline_op = None\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    else:\n        with tf.variable_scope('action_pred'):\n            batch_norm_param = args.arch.batch_norm_param\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n            (out_op, _) = tf_utils.fc_network(m.combined_f, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=num_actions_, batch_norm_param=batch_norm_param, dropout_ratio=args.arch.fc_dropout, is_training=is_training)\n            if num_actions_ > num_actions:\n                m.action_logits_op = out_op[:, :num_actions]\n                m.baseline_op = out_op[:, num_actions:]\n            else:\n                m.action_logits_op = out_op\n                m.baseline_op = None\n            m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    m.train_ops = {}\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc'], m.input_tensors['common']['rel_goal_loc_at_start']]\n    m.train_ops['state_names'] = state_names\n    m.train_ops['init_state'] = init_state_ops\n    m.train_ops['updated_state'] = updated_state_ops\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.train_ops['step_data_cache'] = [tf.no_op()]\n    if args.solver.freeze_conv:\n        m.train_ops['step_data_cache'] = [m.encoder_output]\n    else:\n        m.train_ops['step_data_cache'] = []\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(vars_))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    _add_summaries(m, summary_mode, args.summary.arop_full_summary_iters)\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m"
        ]
    }
]