[
    {
        "func_name": "memory_optimize",
        "original": "def memory_optimize(input_program, skip_opt_set=None, print_log=False, level=0, skip_grads=True):\n    \"\"\"\n        :api_attr: Static Graph\n\n    This API is deprecated since 1.6. Please do not use it. The better\n    memory optimization strategies are enabled by default.\n    \"\"\"\n    logging.warn('Caution! paddle.distributed.transpiler.memory_optimize() is deprecated and not maintained any more, since it is not stable!\\nThis API would not take any memory optimizations on your Program now, since we have provided default strategies for you.\\nThe newest and stable memory optimization strategies (they are all enabled by default) are as follows:\\n 1. Garbage collection strategy, which is enabled by exporting environment variable FLAGS_eager_delete_tensor_gb=0 (0 is the default value).\\n 2. Inplace strategy, which is enabled by setting build_strategy.enable_inplace=True (True is the default value) when using CompiledProgram or ParallelExecutor.\\n')",
        "mutated": [
            "def memory_optimize(input_program, skip_opt_set=None, print_log=False, level=0, skip_grads=True):\n    if False:\n        i = 10\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('Caution! paddle.distributed.transpiler.memory_optimize() is deprecated and not maintained any more, since it is not stable!\\nThis API would not take any memory optimizations on your Program now, since we have provided default strategies for you.\\nThe newest and stable memory optimization strategies (they are all enabled by default) are as follows:\\n 1. Garbage collection strategy, which is enabled by exporting environment variable FLAGS_eager_delete_tensor_gb=0 (0 is the default value).\\n 2. Inplace strategy, which is enabled by setting build_strategy.enable_inplace=True (True is the default value) when using CompiledProgram or ParallelExecutor.\\n')",
            "def memory_optimize(input_program, skip_opt_set=None, print_log=False, level=0, skip_grads=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('Caution! paddle.distributed.transpiler.memory_optimize() is deprecated and not maintained any more, since it is not stable!\\nThis API would not take any memory optimizations on your Program now, since we have provided default strategies for you.\\nThe newest and stable memory optimization strategies (they are all enabled by default) are as follows:\\n 1. Garbage collection strategy, which is enabled by exporting environment variable FLAGS_eager_delete_tensor_gb=0 (0 is the default value).\\n 2. Inplace strategy, which is enabled by setting build_strategy.enable_inplace=True (True is the default value) when using CompiledProgram or ParallelExecutor.\\n')",
            "def memory_optimize(input_program, skip_opt_set=None, print_log=False, level=0, skip_grads=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('Caution! paddle.distributed.transpiler.memory_optimize() is deprecated and not maintained any more, since it is not stable!\\nThis API would not take any memory optimizations on your Program now, since we have provided default strategies for you.\\nThe newest and stable memory optimization strategies (they are all enabled by default) are as follows:\\n 1. Garbage collection strategy, which is enabled by exporting environment variable FLAGS_eager_delete_tensor_gb=0 (0 is the default value).\\n 2. Inplace strategy, which is enabled by setting build_strategy.enable_inplace=True (True is the default value) when using CompiledProgram or ParallelExecutor.\\n')",
            "def memory_optimize(input_program, skip_opt_set=None, print_log=False, level=0, skip_grads=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('Caution! paddle.distributed.transpiler.memory_optimize() is deprecated and not maintained any more, since it is not stable!\\nThis API would not take any memory optimizations on your Program now, since we have provided default strategies for you.\\nThe newest and stable memory optimization strategies (they are all enabled by default) are as follows:\\n 1. Garbage collection strategy, which is enabled by exporting environment variable FLAGS_eager_delete_tensor_gb=0 (0 is the default value).\\n 2. Inplace strategy, which is enabled by setting build_strategy.enable_inplace=True (True is the default value) when using CompiledProgram or ParallelExecutor.\\n')",
            "def memory_optimize(input_program, skip_opt_set=None, print_log=False, level=0, skip_grads=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('Caution! paddle.distributed.transpiler.memory_optimize() is deprecated and not maintained any more, since it is not stable!\\nThis API would not take any memory optimizations on your Program now, since we have provided default strategies for you.\\nThe newest and stable memory optimization strategies (they are all enabled by default) are as follows:\\n 1. Garbage collection strategy, which is enabled by exporting environment variable FLAGS_eager_delete_tensor_gb=0 (0 is the default value).\\n 2. Inplace strategy, which is enabled by setting build_strategy.enable_inplace=True (True is the default value) when using CompiledProgram or ParallelExecutor.\\n')"
        ]
    },
    {
        "func_name": "release_memory",
        "original": "def release_memory(input_program, skip_opt_set=None):\n    \"\"\"\n        :api_attr: Static Graph\n\n    This API is deprecated since 1.6. Please do not use it. The better\n    memory optimization strategies are enabled by default.\n    \"\"\"\n    logging.warn('paddle.distributed.transpiler.release_memory() is deprecated, it would not take any memory release on your program')",
        "mutated": [
            "def release_memory(input_program, skip_opt_set=None):\n    if False:\n        i = 10\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('paddle.distributed.transpiler.release_memory() is deprecated, it would not take any memory release on your program')",
            "def release_memory(input_program, skip_opt_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('paddle.distributed.transpiler.release_memory() is deprecated, it would not take any memory release on your program')",
            "def release_memory(input_program, skip_opt_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('paddle.distributed.transpiler.release_memory() is deprecated, it would not take any memory release on your program')",
            "def release_memory(input_program, skip_opt_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('paddle.distributed.transpiler.release_memory() is deprecated, it would not take any memory release on your program')",
            "def release_memory(input_program, skip_opt_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        :api_attr: Static Graph\\n\\n    This API is deprecated since 1.6. Please do not use it. The better\\n    memory optimization strategies are enabled by default.\\n    '\n    logging.warn('paddle.distributed.transpiler.release_memory() is deprecated, it would not take any memory release on your program')"
        ]
    }
]