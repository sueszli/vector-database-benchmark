[
    {
        "func_name": "_forward_pre_hook",
        "original": "def _forward_pre_hook(mod, input):\n    if mod.training:\n        if not is_conv:\n            weight = mod.weight\n            in_features = weight.size(1)\n            out_features = weight.size(0)\n            mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n            mask.bernoulli_(p)\n            mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n        else:\n            weight = mod.weight\n            in_channels = mod.in_channels\n            out_channels = mod.out_channels\n            if mod.kernel_size == (1, 1):\n                mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n            else:\n                mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n        mask = mask.to(torch.bool)\n        s = 1 / (1 - p)\n        mod.weight.data = s * weight.masked_fill(mask, 0)",
        "mutated": [
            "def _forward_pre_hook(mod, input):\n    if False:\n        i = 10\n    if mod.training:\n        if not is_conv:\n            weight = mod.weight\n            in_features = weight.size(1)\n            out_features = weight.size(0)\n            mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n            mask.bernoulli_(p)\n            mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n        else:\n            weight = mod.weight\n            in_channels = mod.in_channels\n            out_channels = mod.out_channels\n            if mod.kernel_size == (1, 1):\n                mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n            else:\n                mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n        mask = mask.to(torch.bool)\n        s = 1 / (1 - p)\n        mod.weight.data = s * weight.masked_fill(mask, 0)",
            "def _forward_pre_hook(mod, input):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if mod.training:\n        if not is_conv:\n            weight = mod.weight\n            in_features = weight.size(1)\n            out_features = weight.size(0)\n            mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n            mask.bernoulli_(p)\n            mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n        else:\n            weight = mod.weight\n            in_channels = mod.in_channels\n            out_channels = mod.out_channels\n            if mod.kernel_size == (1, 1):\n                mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n            else:\n                mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n        mask = mask.to(torch.bool)\n        s = 1 / (1 - p)\n        mod.weight.data = s * weight.masked_fill(mask, 0)",
            "def _forward_pre_hook(mod, input):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if mod.training:\n        if not is_conv:\n            weight = mod.weight\n            in_features = weight.size(1)\n            out_features = weight.size(0)\n            mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n            mask.bernoulli_(p)\n            mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n        else:\n            weight = mod.weight\n            in_channels = mod.in_channels\n            out_channels = mod.out_channels\n            if mod.kernel_size == (1, 1):\n                mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n            else:\n                mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n        mask = mask.to(torch.bool)\n        s = 1 / (1 - p)\n        mod.weight.data = s * weight.masked_fill(mask, 0)",
            "def _forward_pre_hook(mod, input):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if mod.training:\n        if not is_conv:\n            weight = mod.weight\n            in_features = weight.size(1)\n            out_features = weight.size(0)\n            mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n            mask.bernoulli_(p)\n            mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n        else:\n            weight = mod.weight\n            in_channels = mod.in_channels\n            out_channels = mod.out_channels\n            if mod.kernel_size == (1, 1):\n                mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n            else:\n                mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n        mask = mask.to(torch.bool)\n        s = 1 / (1 - p)\n        mod.weight.data = s * weight.masked_fill(mask, 0)",
            "def _forward_pre_hook(mod, input):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if mod.training:\n        if not is_conv:\n            weight = mod.weight\n            in_features = weight.size(1)\n            out_features = weight.size(0)\n            mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n            mask.bernoulli_(p)\n            mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n        else:\n            weight = mod.weight\n            in_channels = mod.in_channels\n            out_channels = mod.out_channels\n            if mod.kernel_size == (1, 1):\n                mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n            else:\n                mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n        mask = mask.to(torch.bool)\n        s = 1 / (1 - p)\n        mod.weight.data = s * weight.masked_fill(mask, 0)"
        ]
    },
    {
        "func_name": "quant_noise",
        "original": "def quant_noise(module, p, block_size):\n    \"\"\"\n    Wraps modules and applies quantization noise to the weights for\n    subsequent quantization with Iterative Product Quantization as\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\n\n    Args:\n        - module: nn.Module\n        - p: amount of Quantization Noise\n        - block_size: size of the blocks for subsequent quantization with iPQ\n\n    Remarks:\n        - Module weights must have the right sizes wrt the block size\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\n        - For more detail on how to quantize by blocks with convolutional weights,\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\n        - We implement the simplest form of noise here as stated in the paper\n          which consists in randomly dropping blocks\n    \"\"\"\n    if p <= 0:\n        return module\n    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n    is_conv = module.weight.ndim == 4\n    if not is_conv:\n        assert module.weight.size(1) % block_size == 0, 'Input features must be a multiple of block sizes'\n    elif module.kernel_size == (1, 1):\n        assert module.in_channels % block_size == 0, 'Input channels must be a multiple of block sizes'\n    else:\n        k = module.kernel_size[0] * module.kernel_size[1]\n        assert k % block_size == 0, 'Kernel size must be a multiple of block size'\n\n    def _forward_pre_hook(mod, input):\n        if mod.training:\n            if not is_conv:\n                weight = mod.weight\n                in_features = weight.size(1)\n                out_features = weight.size(0)\n                mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n            else:\n                weight = mod.weight\n                in_channels = mod.in_channels\n                out_channels = mod.out_channels\n                if mod.kernel_size == (1, 1):\n                    mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n                else:\n                    mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n            mask = mask.to(torch.bool)\n            s = 1 / (1 - p)\n            mod.weight.data = s * weight.masked_fill(mask, 0)\n    module.register_forward_pre_hook(_forward_pre_hook)\n    return module",
        "mutated": [
            "def quant_noise(module, p, block_size):\n    if False:\n        i = 10\n    '\\n    Wraps modules and applies quantization noise to the weights for\\n    subsequent quantization with Iterative Product Quantization as\\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\\n\\n    Args:\\n        - module: nn.Module\\n        - p: amount of Quantization Noise\\n        - block_size: size of the blocks for subsequent quantization with iPQ\\n\\n    Remarks:\\n        - Module weights must have the right sizes wrt the block size\\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\\n        - For more detail on how to quantize by blocks with convolutional weights,\\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\\n        - We implement the simplest form of noise here as stated in the paper\\n          which consists in randomly dropping blocks\\n    '\n    if p <= 0:\n        return module\n    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n    is_conv = module.weight.ndim == 4\n    if not is_conv:\n        assert module.weight.size(1) % block_size == 0, 'Input features must be a multiple of block sizes'\n    elif module.kernel_size == (1, 1):\n        assert module.in_channels % block_size == 0, 'Input channels must be a multiple of block sizes'\n    else:\n        k = module.kernel_size[0] * module.kernel_size[1]\n        assert k % block_size == 0, 'Kernel size must be a multiple of block size'\n\n    def _forward_pre_hook(mod, input):\n        if mod.training:\n            if not is_conv:\n                weight = mod.weight\n                in_features = weight.size(1)\n                out_features = weight.size(0)\n                mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n            else:\n                weight = mod.weight\n                in_channels = mod.in_channels\n                out_channels = mod.out_channels\n                if mod.kernel_size == (1, 1):\n                    mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n                else:\n                    mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n            mask = mask.to(torch.bool)\n            s = 1 / (1 - p)\n            mod.weight.data = s * weight.masked_fill(mask, 0)\n    module.register_forward_pre_hook(_forward_pre_hook)\n    return module",
            "def quant_noise(module, p, block_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Wraps modules and applies quantization noise to the weights for\\n    subsequent quantization with Iterative Product Quantization as\\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\\n\\n    Args:\\n        - module: nn.Module\\n        - p: amount of Quantization Noise\\n        - block_size: size of the blocks for subsequent quantization with iPQ\\n\\n    Remarks:\\n        - Module weights must have the right sizes wrt the block size\\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\\n        - For more detail on how to quantize by blocks with convolutional weights,\\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\\n        - We implement the simplest form of noise here as stated in the paper\\n          which consists in randomly dropping blocks\\n    '\n    if p <= 0:\n        return module\n    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n    is_conv = module.weight.ndim == 4\n    if not is_conv:\n        assert module.weight.size(1) % block_size == 0, 'Input features must be a multiple of block sizes'\n    elif module.kernel_size == (1, 1):\n        assert module.in_channels % block_size == 0, 'Input channels must be a multiple of block sizes'\n    else:\n        k = module.kernel_size[0] * module.kernel_size[1]\n        assert k % block_size == 0, 'Kernel size must be a multiple of block size'\n\n    def _forward_pre_hook(mod, input):\n        if mod.training:\n            if not is_conv:\n                weight = mod.weight\n                in_features = weight.size(1)\n                out_features = weight.size(0)\n                mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n            else:\n                weight = mod.weight\n                in_channels = mod.in_channels\n                out_channels = mod.out_channels\n                if mod.kernel_size == (1, 1):\n                    mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n                else:\n                    mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n            mask = mask.to(torch.bool)\n            s = 1 / (1 - p)\n            mod.weight.data = s * weight.masked_fill(mask, 0)\n    module.register_forward_pre_hook(_forward_pre_hook)\n    return module",
            "def quant_noise(module, p, block_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Wraps modules and applies quantization noise to the weights for\\n    subsequent quantization with Iterative Product Quantization as\\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\\n\\n    Args:\\n        - module: nn.Module\\n        - p: amount of Quantization Noise\\n        - block_size: size of the blocks for subsequent quantization with iPQ\\n\\n    Remarks:\\n        - Module weights must have the right sizes wrt the block size\\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\\n        - For more detail on how to quantize by blocks with convolutional weights,\\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\\n        - We implement the simplest form of noise here as stated in the paper\\n          which consists in randomly dropping blocks\\n    '\n    if p <= 0:\n        return module\n    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n    is_conv = module.weight.ndim == 4\n    if not is_conv:\n        assert module.weight.size(1) % block_size == 0, 'Input features must be a multiple of block sizes'\n    elif module.kernel_size == (1, 1):\n        assert module.in_channels % block_size == 0, 'Input channels must be a multiple of block sizes'\n    else:\n        k = module.kernel_size[0] * module.kernel_size[1]\n        assert k % block_size == 0, 'Kernel size must be a multiple of block size'\n\n    def _forward_pre_hook(mod, input):\n        if mod.training:\n            if not is_conv:\n                weight = mod.weight\n                in_features = weight.size(1)\n                out_features = weight.size(0)\n                mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n            else:\n                weight = mod.weight\n                in_channels = mod.in_channels\n                out_channels = mod.out_channels\n                if mod.kernel_size == (1, 1):\n                    mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n                else:\n                    mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n            mask = mask.to(torch.bool)\n            s = 1 / (1 - p)\n            mod.weight.data = s * weight.masked_fill(mask, 0)\n    module.register_forward_pre_hook(_forward_pre_hook)\n    return module",
            "def quant_noise(module, p, block_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Wraps modules and applies quantization noise to the weights for\\n    subsequent quantization with Iterative Product Quantization as\\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\\n\\n    Args:\\n        - module: nn.Module\\n        - p: amount of Quantization Noise\\n        - block_size: size of the blocks for subsequent quantization with iPQ\\n\\n    Remarks:\\n        - Module weights must have the right sizes wrt the block size\\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\\n        - For more detail on how to quantize by blocks with convolutional weights,\\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\\n        - We implement the simplest form of noise here as stated in the paper\\n          which consists in randomly dropping blocks\\n    '\n    if p <= 0:\n        return module\n    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n    is_conv = module.weight.ndim == 4\n    if not is_conv:\n        assert module.weight.size(1) % block_size == 0, 'Input features must be a multiple of block sizes'\n    elif module.kernel_size == (1, 1):\n        assert module.in_channels % block_size == 0, 'Input channels must be a multiple of block sizes'\n    else:\n        k = module.kernel_size[0] * module.kernel_size[1]\n        assert k % block_size == 0, 'Kernel size must be a multiple of block size'\n\n    def _forward_pre_hook(mod, input):\n        if mod.training:\n            if not is_conv:\n                weight = mod.weight\n                in_features = weight.size(1)\n                out_features = weight.size(0)\n                mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n            else:\n                weight = mod.weight\n                in_channels = mod.in_channels\n                out_channels = mod.out_channels\n                if mod.kernel_size == (1, 1):\n                    mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n                else:\n                    mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n            mask = mask.to(torch.bool)\n            s = 1 / (1 - p)\n            mod.weight.data = s * weight.masked_fill(mask, 0)\n    module.register_forward_pre_hook(_forward_pre_hook)\n    return module",
            "def quant_noise(module, p, block_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Wraps modules and applies quantization noise to the weights for\\n    subsequent quantization with Iterative Product Quantization as\\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\\n\\n    Args:\\n        - module: nn.Module\\n        - p: amount of Quantization Noise\\n        - block_size: size of the blocks for subsequent quantization with iPQ\\n\\n    Remarks:\\n        - Module weights must have the right sizes wrt the block size\\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\\n        - For more detail on how to quantize by blocks with convolutional weights,\\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\\n        - We implement the simplest form of noise here as stated in the paper\\n          which consists in randomly dropping blocks\\n    '\n    if p <= 0:\n        return module\n    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n    is_conv = module.weight.ndim == 4\n    if not is_conv:\n        assert module.weight.size(1) % block_size == 0, 'Input features must be a multiple of block sizes'\n    elif module.kernel_size == (1, 1):\n        assert module.in_channels % block_size == 0, 'Input channels must be a multiple of block sizes'\n    else:\n        k = module.kernel_size[0] * module.kernel_size[1]\n        assert k % block_size == 0, 'Kernel size must be a multiple of block size'\n\n    def _forward_pre_hook(mod, input):\n        if mod.training:\n            if not is_conv:\n                weight = mod.weight\n                in_features = weight.size(1)\n                out_features = weight.size(0)\n                mask = torch.zeros(in_features // block_size * out_features, device=weight.device)\n                mask.bernoulli_(p)\n                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n            else:\n                weight = mod.weight\n                in_channels = mod.in_channels\n                out_channels = mod.out_channels\n                if mod.kernel_size == (1, 1):\n                    mask = torch.zeros(int(in_channels // block_size * out_channels), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n                else:\n                    mask = torch.zeros(weight.size(0), weight.size(1), device=weight.device)\n                    mask.bernoulli_(p)\n                    mask = mask.unsqueeze(2).unsqueeze(3).repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n            mask = mask.to(torch.bool)\n            s = 1 / (1 - p)\n            mod.weight.data = s * weight.masked_fill(mask, 0)\n    module.register_forward_pre_hook(_forward_pre_hook)\n    return module"
        ]
    }
]