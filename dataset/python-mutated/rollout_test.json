[
    {
        "func_name": "MakeRollout",
        "original": "def MakeRollout(self, states, actions, rewards, values=None, terminated=True):\n    rollout = rollout_lib.Rollout()\n    rollout.add_many(states=states, actions=actions, rewards=rewards, values=values, terminated=terminated)\n    return rollout",
        "mutated": [
            "def MakeRollout(self, states, actions, rewards, values=None, terminated=True):\n    if False:\n        i = 10\n    rollout = rollout_lib.Rollout()\n    rollout.add_many(states=states, actions=actions, rewards=rewards, values=values, terminated=terminated)\n    return rollout",
            "def MakeRollout(self, states, actions, rewards, values=None, terminated=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rollout = rollout_lib.Rollout()\n    rollout.add_many(states=states, actions=actions, rewards=rewards, values=values, terminated=terminated)\n    return rollout",
            "def MakeRollout(self, states, actions, rewards, values=None, terminated=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rollout = rollout_lib.Rollout()\n    rollout.add_many(states=states, actions=actions, rewards=rewards, values=values, terminated=terminated)\n    return rollout",
            "def MakeRollout(self, states, actions, rewards, values=None, terminated=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rollout = rollout_lib.Rollout()\n    rollout.add_many(states=states, actions=actions, rewards=rewards, values=values, terminated=terminated)\n    return rollout",
            "def MakeRollout(self, states, actions, rewards, values=None, terminated=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rollout = rollout_lib.Rollout()\n    rollout.add_many(states=states, actions=actions, rewards=rewards, values=values, terminated=terminated)\n    return rollout"
        ]
    },
    {
        "func_name": "testDiscount",
        "original": "def testDiscount(self):\n    discounted = np.array([1.0 / 2 ** n for n in range(4, -1, -1)])\n    discounted[:2] += [1.0 / 2 ** n for n in range(1, -1, -1)]\n    self.assertTrue(np.array_equal(rollout_lib.discount([0.0, 1.0, 0.0, 0.0, 1.0], 0.5), discounted))\n    self.assertTrue(np.array_equal(rollout_lib.discount(np.array([0.0, 1.0, 0.0, 0.0, 1.0]), 0.5), discounted))",
        "mutated": [
            "def testDiscount(self):\n    if False:\n        i = 10\n    discounted = np.array([1.0 / 2 ** n for n in range(4, -1, -1)])\n    discounted[:2] += [1.0 / 2 ** n for n in range(1, -1, -1)]\n    self.assertTrue(np.array_equal(rollout_lib.discount([0.0, 1.0, 0.0, 0.0, 1.0], 0.5), discounted))\n    self.assertTrue(np.array_equal(rollout_lib.discount(np.array([0.0, 1.0, 0.0, 0.0, 1.0]), 0.5), discounted))",
            "def testDiscount(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    discounted = np.array([1.0 / 2 ** n for n in range(4, -1, -1)])\n    discounted[:2] += [1.0 / 2 ** n for n in range(1, -1, -1)]\n    self.assertTrue(np.array_equal(rollout_lib.discount([0.0, 1.0, 0.0, 0.0, 1.0], 0.5), discounted))\n    self.assertTrue(np.array_equal(rollout_lib.discount(np.array([0.0, 1.0, 0.0, 0.0, 1.0]), 0.5), discounted))",
            "def testDiscount(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    discounted = np.array([1.0 / 2 ** n for n in range(4, -1, -1)])\n    discounted[:2] += [1.0 / 2 ** n for n in range(1, -1, -1)]\n    self.assertTrue(np.array_equal(rollout_lib.discount([0.0, 1.0, 0.0, 0.0, 1.0], 0.5), discounted))\n    self.assertTrue(np.array_equal(rollout_lib.discount(np.array([0.0, 1.0, 0.0, 0.0, 1.0]), 0.5), discounted))",
            "def testDiscount(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    discounted = np.array([1.0 / 2 ** n for n in range(4, -1, -1)])\n    discounted[:2] += [1.0 / 2 ** n for n in range(1, -1, -1)]\n    self.assertTrue(np.array_equal(rollout_lib.discount([0.0, 1.0, 0.0, 0.0, 1.0], 0.5), discounted))\n    self.assertTrue(np.array_equal(rollout_lib.discount(np.array([0.0, 1.0, 0.0, 0.0, 1.0]), 0.5), discounted))",
            "def testDiscount(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    discounted = np.array([1.0 / 2 ** n for n in range(4, -1, -1)])\n    discounted[:2] += [1.0 / 2 ** n for n in range(1, -1, -1)]\n    self.assertTrue(np.array_equal(rollout_lib.discount([0.0, 1.0, 0.0, 0.0, 1.0], 0.5), discounted))\n    self.assertTrue(np.array_equal(rollout_lib.discount(np.array([0.0, 1.0, 0.0, 0.0, 1.0]), 0.5), discounted))"
        ]
    },
    {
        "func_name": "testDiscountedAdvantageAndRewards",
        "original": "def testDiscountedAdvantageAndRewards(self):\n    values = [0.1, 0.5, 0.5, 0.25]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([0.75 * 0.75 ** n for n in range(4, 0, -1)]) + np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    rewards = [0.0, 0.0, 0.0, 1.0]\n    l = 0.5\n    g = 0.75\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards(rewards, values, gamma=g, lambda_=l)\n    expected_discounted_r = np.array([0.75 * g ** n for n in range(4, 0, -1)]) + np.array([1.0 * g ** n for n in range(3, -1, -1)])\n    expected_adv = [0.0] * len(values)\n    for t in range(3, -1, -1):\n        delta_t = rewards[t] + g * values[t + 1] - values[t]\n        expected_adv[t] = delta_t + g * l * expected_adv[t + 1]\n    expected_adv = expected_adv[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))",
        "mutated": [
            "def testDiscountedAdvantageAndRewards(self):\n    if False:\n        i = 10\n    values = [0.1, 0.5, 0.5, 0.25]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([0.75 * 0.75 ** n for n in range(4, 0, -1)]) + np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    rewards = [0.0, 0.0, 0.0, 1.0]\n    l = 0.5\n    g = 0.75\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards(rewards, values, gamma=g, lambda_=l)\n    expected_discounted_r = np.array([0.75 * g ** n for n in range(4, 0, -1)]) + np.array([1.0 * g ** n for n in range(3, -1, -1)])\n    expected_adv = [0.0] * len(values)\n    for t in range(3, -1, -1):\n        delta_t = rewards[t] + g * values[t + 1] - values[t]\n        expected_adv[t] = delta_t + g * l * expected_adv[t + 1]\n    expected_adv = expected_adv[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))",
            "def testDiscountedAdvantageAndRewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    values = [0.1, 0.5, 0.5, 0.25]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([0.75 * 0.75 ** n for n in range(4, 0, -1)]) + np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    rewards = [0.0, 0.0, 0.0, 1.0]\n    l = 0.5\n    g = 0.75\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards(rewards, values, gamma=g, lambda_=l)\n    expected_discounted_r = np.array([0.75 * g ** n for n in range(4, 0, -1)]) + np.array([1.0 * g ** n for n in range(3, -1, -1)])\n    expected_adv = [0.0] * len(values)\n    for t in range(3, -1, -1):\n        delta_t = rewards[t] + g * values[t + 1] - values[t]\n        expected_adv[t] = delta_t + g * l * expected_adv[t + 1]\n    expected_adv = expected_adv[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))",
            "def testDiscountedAdvantageAndRewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    values = [0.1, 0.5, 0.5, 0.25]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([0.75 * 0.75 ** n for n in range(4, 0, -1)]) + np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    rewards = [0.0, 0.0, 0.0, 1.0]\n    l = 0.5\n    g = 0.75\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards(rewards, values, gamma=g, lambda_=l)\n    expected_discounted_r = np.array([0.75 * g ** n for n in range(4, 0, -1)]) + np.array([1.0 * g ** n for n in range(3, -1, -1)])\n    expected_adv = [0.0] * len(values)\n    for t in range(3, -1, -1):\n        delta_t = rewards[t] + g * values[t + 1] - values[t]\n        expected_adv[t] = delta_t + g * l * expected_adv[t + 1]\n    expected_adv = expected_adv[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))",
            "def testDiscountedAdvantageAndRewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    values = [0.1, 0.5, 0.5, 0.25]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([0.75 * 0.75 ** n for n in range(4, 0, -1)]) + np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    rewards = [0.0, 0.0, 0.0, 1.0]\n    l = 0.5\n    g = 0.75\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards(rewards, values, gamma=g, lambda_=l)\n    expected_discounted_r = np.array([0.75 * g ** n for n in range(4, 0, -1)]) + np.array([1.0 * g ** n for n in range(3, -1, -1)])\n    expected_adv = [0.0] * len(values)\n    for t in range(3, -1, -1):\n        delta_t = rewards[t] + g * values[t + 1] - values[t]\n        expected_adv[t] = delta_t + g * l * expected_adv[t + 1]\n    expected_adv = expected_adv[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))",
            "def testDiscountedAdvantageAndRewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    values = [0.1, 0.5, 0.5, 0.25]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards([0.0, 0.0, 0.0, 1.0], values, gamma=0.75, lambda_=1.0)\n    expected_discounted_r = np.array([0.75 * 0.75 ** n for n in range(4, 0, -1)]) + np.array([1.0 * 0.75 ** n for n in range(3, -1, -1)])\n    expected_adv = expected_discounted_r - values[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))\n    values = [0.1, 0.5, 0.5, 0.25, 0.75]\n    rewards = [0.0, 0.0, 0.0, 1.0]\n    l = 0.5\n    g = 0.75\n    (empirical_values, generalized_advantage) = rollout_lib.discounted_advantage_and_rewards(rewards, values, gamma=g, lambda_=l)\n    expected_discounted_r = np.array([0.75 * g ** n for n in range(4, 0, -1)]) + np.array([1.0 * g ** n for n in range(3, -1, -1)])\n    expected_adv = [0.0] * len(values)\n    for t in range(3, -1, -1):\n        delta_t = rewards[t] + g * values[t + 1] - values[t]\n        expected_adv[t] = delta_t + g * l * expected_adv[t + 1]\n    expected_adv = expected_adv[:-1]\n    self.assertTrue(np.array_equal(empirical_values, expected_discounted_r))\n    self.assertTrue(np.allclose(generalized_advantage, expected_adv))"
        ]
    },
    {
        "func_name": "testProcessRollouts",
        "original": "def testProcessRollouts(self):\n    g = 0.95\n    rollouts = [self.MakeRollout(states=[3, 6, 9], actions=[1, 2, 3], rewards=[1.0, -1.0, 0.5], values=[0.5, 0.5, 0.1]), self.MakeRollout(states=[10], actions=[5], rewards=[1.0], values=[0.5])]\n    batch = rollout_lib.process_rollouts(rollouts, gamma=g)\n    self.assertEqual(2, batch.batch_size)\n    self.assertEqual(3, batch.max_time)\n    self.assertEqual([3, 1], batch.episode_lengths)\n    self.assertEqual([0.5, 1.0], batch.total_rewards)\n    self.assertEqual([[3, 6, 9], [10, 0, 0]], batch.states.tolist())\n    self.assertEqual([[1, 2, 3], [5, 0, 0]], batch.actions.tolist())\n    (rew1, rew2) = (rollouts[0].rewards, rollouts[1].rewards)\n    expected_discounted_rewards = [[rew1[0] + g * rew1[1] + g * g * rew1[2], rew1[1] + g * rew1[2], rew1[2]], [rew2[0], 0.0, 0.0]]\n    expected_advantages = [[dr - v for (dr, v) in zip(expected_discounted_rewards[0], rollouts[0].values)], [expected_discounted_rewards[1][0] - rollouts[1].values[0], 0.0, 0.0]]\n    self.assertTrue(np.allclose(expected_discounted_rewards, batch.discounted_r))\n    self.assertTrue(np.allclose(expected_advantages, batch.discounted_adv))",
        "mutated": [
            "def testProcessRollouts(self):\n    if False:\n        i = 10\n    g = 0.95\n    rollouts = [self.MakeRollout(states=[3, 6, 9], actions=[1, 2, 3], rewards=[1.0, -1.0, 0.5], values=[0.5, 0.5, 0.1]), self.MakeRollout(states=[10], actions=[5], rewards=[1.0], values=[0.5])]\n    batch = rollout_lib.process_rollouts(rollouts, gamma=g)\n    self.assertEqual(2, batch.batch_size)\n    self.assertEqual(3, batch.max_time)\n    self.assertEqual([3, 1], batch.episode_lengths)\n    self.assertEqual([0.5, 1.0], batch.total_rewards)\n    self.assertEqual([[3, 6, 9], [10, 0, 0]], batch.states.tolist())\n    self.assertEqual([[1, 2, 3], [5, 0, 0]], batch.actions.tolist())\n    (rew1, rew2) = (rollouts[0].rewards, rollouts[1].rewards)\n    expected_discounted_rewards = [[rew1[0] + g * rew1[1] + g * g * rew1[2], rew1[1] + g * rew1[2], rew1[2]], [rew2[0], 0.0, 0.0]]\n    expected_advantages = [[dr - v for (dr, v) in zip(expected_discounted_rewards[0], rollouts[0].values)], [expected_discounted_rewards[1][0] - rollouts[1].values[0], 0.0, 0.0]]\n    self.assertTrue(np.allclose(expected_discounted_rewards, batch.discounted_r))\n    self.assertTrue(np.allclose(expected_advantages, batch.discounted_adv))",
            "def testProcessRollouts(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    g = 0.95\n    rollouts = [self.MakeRollout(states=[3, 6, 9], actions=[1, 2, 3], rewards=[1.0, -1.0, 0.5], values=[0.5, 0.5, 0.1]), self.MakeRollout(states=[10], actions=[5], rewards=[1.0], values=[0.5])]\n    batch = rollout_lib.process_rollouts(rollouts, gamma=g)\n    self.assertEqual(2, batch.batch_size)\n    self.assertEqual(3, batch.max_time)\n    self.assertEqual([3, 1], batch.episode_lengths)\n    self.assertEqual([0.5, 1.0], batch.total_rewards)\n    self.assertEqual([[3, 6, 9], [10, 0, 0]], batch.states.tolist())\n    self.assertEqual([[1, 2, 3], [5, 0, 0]], batch.actions.tolist())\n    (rew1, rew2) = (rollouts[0].rewards, rollouts[1].rewards)\n    expected_discounted_rewards = [[rew1[0] + g * rew1[1] + g * g * rew1[2], rew1[1] + g * rew1[2], rew1[2]], [rew2[0], 0.0, 0.0]]\n    expected_advantages = [[dr - v for (dr, v) in zip(expected_discounted_rewards[0], rollouts[0].values)], [expected_discounted_rewards[1][0] - rollouts[1].values[0], 0.0, 0.0]]\n    self.assertTrue(np.allclose(expected_discounted_rewards, batch.discounted_r))\n    self.assertTrue(np.allclose(expected_advantages, batch.discounted_adv))",
            "def testProcessRollouts(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    g = 0.95\n    rollouts = [self.MakeRollout(states=[3, 6, 9], actions=[1, 2, 3], rewards=[1.0, -1.0, 0.5], values=[0.5, 0.5, 0.1]), self.MakeRollout(states=[10], actions=[5], rewards=[1.0], values=[0.5])]\n    batch = rollout_lib.process_rollouts(rollouts, gamma=g)\n    self.assertEqual(2, batch.batch_size)\n    self.assertEqual(3, batch.max_time)\n    self.assertEqual([3, 1], batch.episode_lengths)\n    self.assertEqual([0.5, 1.0], batch.total_rewards)\n    self.assertEqual([[3, 6, 9], [10, 0, 0]], batch.states.tolist())\n    self.assertEqual([[1, 2, 3], [5, 0, 0]], batch.actions.tolist())\n    (rew1, rew2) = (rollouts[0].rewards, rollouts[1].rewards)\n    expected_discounted_rewards = [[rew1[0] + g * rew1[1] + g * g * rew1[2], rew1[1] + g * rew1[2], rew1[2]], [rew2[0], 0.0, 0.0]]\n    expected_advantages = [[dr - v for (dr, v) in zip(expected_discounted_rewards[0], rollouts[0].values)], [expected_discounted_rewards[1][0] - rollouts[1].values[0], 0.0, 0.0]]\n    self.assertTrue(np.allclose(expected_discounted_rewards, batch.discounted_r))\n    self.assertTrue(np.allclose(expected_advantages, batch.discounted_adv))",
            "def testProcessRollouts(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    g = 0.95\n    rollouts = [self.MakeRollout(states=[3, 6, 9], actions=[1, 2, 3], rewards=[1.0, -1.0, 0.5], values=[0.5, 0.5, 0.1]), self.MakeRollout(states=[10], actions=[5], rewards=[1.0], values=[0.5])]\n    batch = rollout_lib.process_rollouts(rollouts, gamma=g)\n    self.assertEqual(2, batch.batch_size)\n    self.assertEqual(3, batch.max_time)\n    self.assertEqual([3, 1], batch.episode_lengths)\n    self.assertEqual([0.5, 1.0], batch.total_rewards)\n    self.assertEqual([[3, 6, 9], [10, 0, 0]], batch.states.tolist())\n    self.assertEqual([[1, 2, 3], [5, 0, 0]], batch.actions.tolist())\n    (rew1, rew2) = (rollouts[0].rewards, rollouts[1].rewards)\n    expected_discounted_rewards = [[rew1[0] + g * rew1[1] + g * g * rew1[2], rew1[1] + g * rew1[2], rew1[2]], [rew2[0], 0.0, 0.0]]\n    expected_advantages = [[dr - v for (dr, v) in zip(expected_discounted_rewards[0], rollouts[0].values)], [expected_discounted_rewards[1][0] - rollouts[1].values[0], 0.0, 0.0]]\n    self.assertTrue(np.allclose(expected_discounted_rewards, batch.discounted_r))\n    self.assertTrue(np.allclose(expected_advantages, batch.discounted_adv))",
            "def testProcessRollouts(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    g = 0.95\n    rollouts = [self.MakeRollout(states=[3, 6, 9], actions=[1, 2, 3], rewards=[1.0, -1.0, 0.5], values=[0.5, 0.5, 0.1]), self.MakeRollout(states=[10], actions=[5], rewards=[1.0], values=[0.5])]\n    batch = rollout_lib.process_rollouts(rollouts, gamma=g)\n    self.assertEqual(2, batch.batch_size)\n    self.assertEqual(3, batch.max_time)\n    self.assertEqual([3, 1], batch.episode_lengths)\n    self.assertEqual([0.5, 1.0], batch.total_rewards)\n    self.assertEqual([[3, 6, 9], [10, 0, 0]], batch.states.tolist())\n    self.assertEqual([[1, 2, 3], [5, 0, 0]], batch.actions.tolist())\n    (rew1, rew2) = (rollouts[0].rewards, rollouts[1].rewards)\n    expected_discounted_rewards = [[rew1[0] + g * rew1[1] + g * g * rew1[2], rew1[1] + g * rew1[2], rew1[2]], [rew2[0], 0.0, 0.0]]\n    expected_advantages = [[dr - v for (dr, v) in zip(expected_discounted_rewards[0], rollouts[0].values)], [expected_discounted_rewards[1][0] - rollouts[1].values[0], 0.0, 0.0]]\n    self.assertTrue(np.allclose(expected_discounted_rewards, batch.discounted_r))\n    self.assertTrue(np.allclose(expected_advantages, batch.discounted_adv))"
        ]
    }
]