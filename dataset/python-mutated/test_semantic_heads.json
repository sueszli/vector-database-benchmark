[
    {
        "func_name": "test_PointwiseSemanticHead",
        "original": "def test_PointwiseSemanticHead():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    from mmdet3d.models.builder import build_head\n    head_cfg = dict(type='PointwiseSemanticHead', in_channels=8, extra_width=0.2, seg_score_thr=0.3, num_classes=3, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n    self = build_head(head_cfg)\n    self.cuda()\n    voxel_features = torch.rand([4, 8], dtype=torch.float32).cuda()\n    feats_dict = self.forward(voxel_features)\n    assert feats_dict['seg_preds'].shape == torch.Size([voxel_features.shape[0], 1])\n    assert feats_dict['part_preds'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert feats_dict['part_feats'].shape == torch.Size([voxel_features.shape[0], 4])\n    voxel_centers = torch.tensor([[6.56126, 0.9648336, -1.7339306], [6.8162713, -2.480431, -1.3616394], [11.643568, -4.744306, -1.3580885], [23.482342, 6.5036807, 0.5806964]], dtype=torch.float32).cuda()\n    coordinates = torch.tensor([[0, 12, 819, 131], [0, 16, 750, 136], [1, 16, 705, 232], [1, 35, 930, 469]], dtype=torch.int32).cuda()\n    voxel_dict = dict(voxel_centers=voxel_centers, coors=coordinates)\n    gt_bboxes = [LiDARInstance3DBoxes(torch.tensor([[6.4118, -3.4305, -1.7291, 1.7033, 3.4693, 1.6197, 0.9091]], dtype=torch.float32).cuda()), LiDARInstance3DBoxes(torch.tensor([[16.9107, 9.7925, -1.9201, 1.6097, 3.2786, 1.5307, 2.4056]], dtype=torch.float32).cuda())]\n    gt_labels = list(torch.tensor([[0], [1]], dtype=torch.int64).cuda())\n    target_dict = self.get_targets(voxel_dict, gt_bboxes, gt_labels)\n    assert target_dict['seg_targets'].shape == torch.Size([voxel_features.shape[0]])\n    assert torch.allclose(target_dict['seg_targets'], target_dict['seg_targets'].new_tensor([3, -1, 3, 3]))\n    assert target_dict['part_targets'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert target_dict['part_targets'].sum() == 0\n    loss_dict = self.loss(feats_dict, target_dict)\n    assert loss_dict['loss_seg'] > 0\n    assert loss_dict['loss_part'] == 0\n    total_loss = loss_dict['loss_seg'] + loss_dict['loss_part']\n    total_loss.backward()",
        "mutated": [
            "def test_PointwiseSemanticHead():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    from mmdet3d.models.builder import build_head\n    head_cfg = dict(type='PointwiseSemanticHead', in_channels=8, extra_width=0.2, seg_score_thr=0.3, num_classes=3, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n    self = build_head(head_cfg)\n    self.cuda()\n    voxel_features = torch.rand([4, 8], dtype=torch.float32).cuda()\n    feats_dict = self.forward(voxel_features)\n    assert feats_dict['seg_preds'].shape == torch.Size([voxel_features.shape[0], 1])\n    assert feats_dict['part_preds'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert feats_dict['part_feats'].shape == torch.Size([voxel_features.shape[0], 4])\n    voxel_centers = torch.tensor([[6.56126, 0.9648336, -1.7339306], [6.8162713, -2.480431, -1.3616394], [11.643568, -4.744306, -1.3580885], [23.482342, 6.5036807, 0.5806964]], dtype=torch.float32).cuda()\n    coordinates = torch.tensor([[0, 12, 819, 131], [0, 16, 750, 136], [1, 16, 705, 232], [1, 35, 930, 469]], dtype=torch.int32).cuda()\n    voxel_dict = dict(voxel_centers=voxel_centers, coors=coordinates)\n    gt_bboxes = [LiDARInstance3DBoxes(torch.tensor([[6.4118, -3.4305, -1.7291, 1.7033, 3.4693, 1.6197, 0.9091]], dtype=torch.float32).cuda()), LiDARInstance3DBoxes(torch.tensor([[16.9107, 9.7925, -1.9201, 1.6097, 3.2786, 1.5307, 2.4056]], dtype=torch.float32).cuda())]\n    gt_labels = list(torch.tensor([[0], [1]], dtype=torch.int64).cuda())\n    target_dict = self.get_targets(voxel_dict, gt_bboxes, gt_labels)\n    assert target_dict['seg_targets'].shape == torch.Size([voxel_features.shape[0]])\n    assert torch.allclose(target_dict['seg_targets'], target_dict['seg_targets'].new_tensor([3, -1, 3, 3]))\n    assert target_dict['part_targets'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert target_dict['part_targets'].sum() == 0\n    loss_dict = self.loss(feats_dict, target_dict)\n    assert loss_dict['loss_seg'] > 0\n    assert loss_dict['loss_part'] == 0\n    total_loss = loss_dict['loss_seg'] + loss_dict['loss_part']\n    total_loss.backward()",
            "def test_PointwiseSemanticHead():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    from mmdet3d.models.builder import build_head\n    head_cfg = dict(type='PointwiseSemanticHead', in_channels=8, extra_width=0.2, seg_score_thr=0.3, num_classes=3, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n    self = build_head(head_cfg)\n    self.cuda()\n    voxel_features = torch.rand([4, 8], dtype=torch.float32).cuda()\n    feats_dict = self.forward(voxel_features)\n    assert feats_dict['seg_preds'].shape == torch.Size([voxel_features.shape[0], 1])\n    assert feats_dict['part_preds'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert feats_dict['part_feats'].shape == torch.Size([voxel_features.shape[0], 4])\n    voxel_centers = torch.tensor([[6.56126, 0.9648336, -1.7339306], [6.8162713, -2.480431, -1.3616394], [11.643568, -4.744306, -1.3580885], [23.482342, 6.5036807, 0.5806964]], dtype=torch.float32).cuda()\n    coordinates = torch.tensor([[0, 12, 819, 131], [0, 16, 750, 136], [1, 16, 705, 232], [1, 35, 930, 469]], dtype=torch.int32).cuda()\n    voxel_dict = dict(voxel_centers=voxel_centers, coors=coordinates)\n    gt_bboxes = [LiDARInstance3DBoxes(torch.tensor([[6.4118, -3.4305, -1.7291, 1.7033, 3.4693, 1.6197, 0.9091]], dtype=torch.float32).cuda()), LiDARInstance3DBoxes(torch.tensor([[16.9107, 9.7925, -1.9201, 1.6097, 3.2786, 1.5307, 2.4056]], dtype=torch.float32).cuda())]\n    gt_labels = list(torch.tensor([[0], [1]], dtype=torch.int64).cuda())\n    target_dict = self.get_targets(voxel_dict, gt_bboxes, gt_labels)\n    assert target_dict['seg_targets'].shape == torch.Size([voxel_features.shape[0]])\n    assert torch.allclose(target_dict['seg_targets'], target_dict['seg_targets'].new_tensor([3, -1, 3, 3]))\n    assert target_dict['part_targets'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert target_dict['part_targets'].sum() == 0\n    loss_dict = self.loss(feats_dict, target_dict)\n    assert loss_dict['loss_seg'] > 0\n    assert loss_dict['loss_part'] == 0\n    total_loss = loss_dict['loss_seg'] + loss_dict['loss_part']\n    total_loss.backward()",
            "def test_PointwiseSemanticHead():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    from mmdet3d.models.builder import build_head\n    head_cfg = dict(type='PointwiseSemanticHead', in_channels=8, extra_width=0.2, seg_score_thr=0.3, num_classes=3, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n    self = build_head(head_cfg)\n    self.cuda()\n    voxel_features = torch.rand([4, 8], dtype=torch.float32).cuda()\n    feats_dict = self.forward(voxel_features)\n    assert feats_dict['seg_preds'].shape == torch.Size([voxel_features.shape[0], 1])\n    assert feats_dict['part_preds'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert feats_dict['part_feats'].shape == torch.Size([voxel_features.shape[0], 4])\n    voxel_centers = torch.tensor([[6.56126, 0.9648336, -1.7339306], [6.8162713, -2.480431, -1.3616394], [11.643568, -4.744306, -1.3580885], [23.482342, 6.5036807, 0.5806964]], dtype=torch.float32).cuda()\n    coordinates = torch.tensor([[0, 12, 819, 131], [0, 16, 750, 136], [1, 16, 705, 232], [1, 35, 930, 469]], dtype=torch.int32).cuda()\n    voxel_dict = dict(voxel_centers=voxel_centers, coors=coordinates)\n    gt_bboxes = [LiDARInstance3DBoxes(torch.tensor([[6.4118, -3.4305, -1.7291, 1.7033, 3.4693, 1.6197, 0.9091]], dtype=torch.float32).cuda()), LiDARInstance3DBoxes(torch.tensor([[16.9107, 9.7925, -1.9201, 1.6097, 3.2786, 1.5307, 2.4056]], dtype=torch.float32).cuda())]\n    gt_labels = list(torch.tensor([[0], [1]], dtype=torch.int64).cuda())\n    target_dict = self.get_targets(voxel_dict, gt_bboxes, gt_labels)\n    assert target_dict['seg_targets'].shape == torch.Size([voxel_features.shape[0]])\n    assert torch.allclose(target_dict['seg_targets'], target_dict['seg_targets'].new_tensor([3, -1, 3, 3]))\n    assert target_dict['part_targets'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert target_dict['part_targets'].sum() == 0\n    loss_dict = self.loss(feats_dict, target_dict)\n    assert loss_dict['loss_seg'] > 0\n    assert loss_dict['loss_part'] == 0\n    total_loss = loss_dict['loss_seg'] + loss_dict['loss_part']\n    total_loss.backward()",
            "def test_PointwiseSemanticHead():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    from mmdet3d.models.builder import build_head\n    head_cfg = dict(type='PointwiseSemanticHead', in_channels=8, extra_width=0.2, seg_score_thr=0.3, num_classes=3, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n    self = build_head(head_cfg)\n    self.cuda()\n    voxel_features = torch.rand([4, 8], dtype=torch.float32).cuda()\n    feats_dict = self.forward(voxel_features)\n    assert feats_dict['seg_preds'].shape == torch.Size([voxel_features.shape[0], 1])\n    assert feats_dict['part_preds'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert feats_dict['part_feats'].shape == torch.Size([voxel_features.shape[0], 4])\n    voxel_centers = torch.tensor([[6.56126, 0.9648336, -1.7339306], [6.8162713, -2.480431, -1.3616394], [11.643568, -4.744306, -1.3580885], [23.482342, 6.5036807, 0.5806964]], dtype=torch.float32).cuda()\n    coordinates = torch.tensor([[0, 12, 819, 131], [0, 16, 750, 136], [1, 16, 705, 232], [1, 35, 930, 469]], dtype=torch.int32).cuda()\n    voxel_dict = dict(voxel_centers=voxel_centers, coors=coordinates)\n    gt_bboxes = [LiDARInstance3DBoxes(torch.tensor([[6.4118, -3.4305, -1.7291, 1.7033, 3.4693, 1.6197, 0.9091]], dtype=torch.float32).cuda()), LiDARInstance3DBoxes(torch.tensor([[16.9107, 9.7925, -1.9201, 1.6097, 3.2786, 1.5307, 2.4056]], dtype=torch.float32).cuda())]\n    gt_labels = list(torch.tensor([[0], [1]], dtype=torch.int64).cuda())\n    target_dict = self.get_targets(voxel_dict, gt_bboxes, gt_labels)\n    assert target_dict['seg_targets'].shape == torch.Size([voxel_features.shape[0]])\n    assert torch.allclose(target_dict['seg_targets'], target_dict['seg_targets'].new_tensor([3, -1, 3, 3]))\n    assert target_dict['part_targets'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert target_dict['part_targets'].sum() == 0\n    loss_dict = self.loss(feats_dict, target_dict)\n    assert loss_dict['loss_seg'] > 0\n    assert loss_dict['loss_part'] == 0\n    total_loss = loss_dict['loss_seg'] + loss_dict['loss_part']\n    total_loss.backward()",
            "def test_PointwiseSemanticHead():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    from mmdet3d.models.builder import build_head\n    head_cfg = dict(type='PointwiseSemanticHead', in_channels=8, extra_width=0.2, seg_score_thr=0.3, num_classes=3, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n    self = build_head(head_cfg)\n    self.cuda()\n    voxel_features = torch.rand([4, 8], dtype=torch.float32).cuda()\n    feats_dict = self.forward(voxel_features)\n    assert feats_dict['seg_preds'].shape == torch.Size([voxel_features.shape[0], 1])\n    assert feats_dict['part_preds'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert feats_dict['part_feats'].shape == torch.Size([voxel_features.shape[0], 4])\n    voxel_centers = torch.tensor([[6.56126, 0.9648336, -1.7339306], [6.8162713, -2.480431, -1.3616394], [11.643568, -4.744306, -1.3580885], [23.482342, 6.5036807, 0.5806964]], dtype=torch.float32).cuda()\n    coordinates = torch.tensor([[0, 12, 819, 131], [0, 16, 750, 136], [1, 16, 705, 232], [1, 35, 930, 469]], dtype=torch.int32).cuda()\n    voxel_dict = dict(voxel_centers=voxel_centers, coors=coordinates)\n    gt_bboxes = [LiDARInstance3DBoxes(torch.tensor([[6.4118, -3.4305, -1.7291, 1.7033, 3.4693, 1.6197, 0.9091]], dtype=torch.float32).cuda()), LiDARInstance3DBoxes(torch.tensor([[16.9107, 9.7925, -1.9201, 1.6097, 3.2786, 1.5307, 2.4056]], dtype=torch.float32).cuda())]\n    gt_labels = list(torch.tensor([[0], [1]], dtype=torch.int64).cuda())\n    target_dict = self.get_targets(voxel_dict, gt_bboxes, gt_labels)\n    assert target_dict['seg_targets'].shape == torch.Size([voxel_features.shape[0]])\n    assert torch.allclose(target_dict['seg_targets'], target_dict['seg_targets'].new_tensor([3, -1, 3, 3]))\n    assert target_dict['part_targets'].shape == torch.Size([voxel_features.shape[0], 3])\n    assert target_dict['part_targets'].sum() == 0\n    loss_dict = self.loss(feats_dict, target_dict)\n    assert loss_dict['loss_seg'] > 0\n    assert loss_dict['loss_part'] == 0\n    total_loss = loss_dict['loss_seg'] + loss_dict['loss_part']\n    total_loss.backward()"
        ]
    }
]