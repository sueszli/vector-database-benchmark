[
    {
        "func_name": "_wait_session",
        "original": "def _wait_session(session_id: str, boto3_session: Optional[boto3.Session]=None, athena_session_wait_polling_delay: float=_SESSION_WAIT_POLLING_DELAY) -> 'GetSessionStatusResponseTypeDef':\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetSessionStatusResponseTypeDef' = client_athena.get_session_status(SessionId=session_id)\n    state: str = response['Status']['State']\n    while state not in _SESSION_FINAL_STATES:\n        time.sleep(athena_session_wait_polling_delay)\n        response = client_athena.get_session_status(SessionId=session_id)\n        state = response['Status']['State']\n    _logger.debug('Session state: %s', state)\n    _logger.debug('Session state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['FAILED', 'DEGRADED', 'TERMINATED']:\n        raise exceptions.SessionFailed(response['Status'].get('StateChangeReason'))\n    return response",
        "mutated": [
            "def _wait_session(session_id: str, boto3_session: Optional[boto3.Session]=None, athena_session_wait_polling_delay: float=_SESSION_WAIT_POLLING_DELAY) -> 'GetSessionStatusResponseTypeDef':\n    if False:\n        i = 10\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetSessionStatusResponseTypeDef' = client_athena.get_session_status(SessionId=session_id)\n    state: str = response['Status']['State']\n    while state not in _SESSION_FINAL_STATES:\n        time.sleep(athena_session_wait_polling_delay)\n        response = client_athena.get_session_status(SessionId=session_id)\n        state = response['Status']['State']\n    _logger.debug('Session state: %s', state)\n    _logger.debug('Session state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['FAILED', 'DEGRADED', 'TERMINATED']:\n        raise exceptions.SessionFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_session(session_id: str, boto3_session: Optional[boto3.Session]=None, athena_session_wait_polling_delay: float=_SESSION_WAIT_POLLING_DELAY) -> 'GetSessionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetSessionStatusResponseTypeDef' = client_athena.get_session_status(SessionId=session_id)\n    state: str = response['Status']['State']\n    while state not in _SESSION_FINAL_STATES:\n        time.sleep(athena_session_wait_polling_delay)\n        response = client_athena.get_session_status(SessionId=session_id)\n        state = response['Status']['State']\n    _logger.debug('Session state: %s', state)\n    _logger.debug('Session state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['FAILED', 'DEGRADED', 'TERMINATED']:\n        raise exceptions.SessionFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_session(session_id: str, boto3_session: Optional[boto3.Session]=None, athena_session_wait_polling_delay: float=_SESSION_WAIT_POLLING_DELAY) -> 'GetSessionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetSessionStatusResponseTypeDef' = client_athena.get_session_status(SessionId=session_id)\n    state: str = response['Status']['State']\n    while state not in _SESSION_FINAL_STATES:\n        time.sleep(athena_session_wait_polling_delay)\n        response = client_athena.get_session_status(SessionId=session_id)\n        state = response['Status']['State']\n    _logger.debug('Session state: %s', state)\n    _logger.debug('Session state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['FAILED', 'DEGRADED', 'TERMINATED']:\n        raise exceptions.SessionFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_session(session_id: str, boto3_session: Optional[boto3.Session]=None, athena_session_wait_polling_delay: float=_SESSION_WAIT_POLLING_DELAY) -> 'GetSessionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetSessionStatusResponseTypeDef' = client_athena.get_session_status(SessionId=session_id)\n    state: str = response['Status']['State']\n    while state not in _SESSION_FINAL_STATES:\n        time.sleep(athena_session_wait_polling_delay)\n        response = client_athena.get_session_status(SessionId=session_id)\n        state = response['Status']['State']\n    _logger.debug('Session state: %s', state)\n    _logger.debug('Session state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['FAILED', 'DEGRADED', 'TERMINATED']:\n        raise exceptions.SessionFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_session(session_id: str, boto3_session: Optional[boto3.Session]=None, athena_session_wait_polling_delay: float=_SESSION_WAIT_POLLING_DELAY) -> 'GetSessionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetSessionStatusResponseTypeDef' = client_athena.get_session_status(SessionId=session_id)\n    state: str = response['Status']['State']\n    while state not in _SESSION_FINAL_STATES:\n        time.sleep(athena_session_wait_polling_delay)\n        response = client_athena.get_session_status(SessionId=session_id)\n        state = response['Status']['State']\n    _logger.debug('Session state: %s', state)\n    _logger.debug('Session state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['FAILED', 'DEGRADED', 'TERMINATED']:\n        raise exceptions.SessionFailed(response['Status'].get('StateChangeReason'))\n    return response"
        ]
    },
    {
        "func_name": "_wait_calculation_execution",
        "original": "def _wait_calculation_execution(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None, athena_calculation_execution_wait_polling_delay: float=_CALCULATION_EXECUTION_WAIT_POLLING_DELAY) -> 'GetCalculationExecutionStatusResponseTypeDef':\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetCalculationExecutionStatusResponseTypeDef' = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n    state: str = response['Status']['State']\n    while state not in _CALCULATION_EXECUTION_FINAL_STATES:\n        time.sleep(athena_calculation_execution_wait_polling_delay)\n        response = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n        state = response['Status']['State']\n    _logger.debug('Calculation execution state: %s', state)\n    _logger.debug('Calculation execution state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['CANCELED', 'FAILED']:\n        raise exceptions.CalculationFailed(response['Status'].get('StateChangeReason'))\n    return response",
        "mutated": [
            "def _wait_calculation_execution(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None, athena_calculation_execution_wait_polling_delay: float=_CALCULATION_EXECUTION_WAIT_POLLING_DELAY) -> 'GetCalculationExecutionStatusResponseTypeDef':\n    if False:\n        i = 10\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetCalculationExecutionStatusResponseTypeDef' = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n    state: str = response['Status']['State']\n    while state not in _CALCULATION_EXECUTION_FINAL_STATES:\n        time.sleep(athena_calculation_execution_wait_polling_delay)\n        response = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n        state = response['Status']['State']\n    _logger.debug('Calculation execution state: %s', state)\n    _logger.debug('Calculation execution state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['CANCELED', 'FAILED']:\n        raise exceptions.CalculationFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_calculation_execution(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None, athena_calculation_execution_wait_polling_delay: float=_CALCULATION_EXECUTION_WAIT_POLLING_DELAY) -> 'GetCalculationExecutionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetCalculationExecutionStatusResponseTypeDef' = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n    state: str = response['Status']['State']\n    while state not in _CALCULATION_EXECUTION_FINAL_STATES:\n        time.sleep(athena_calculation_execution_wait_polling_delay)\n        response = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n        state = response['Status']['State']\n    _logger.debug('Calculation execution state: %s', state)\n    _logger.debug('Calculation execution state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['CANCELED', 'FAILED']:\n        raise exceptions.CalculationFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_calculation_execution(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None, athena_calculation_execution_wait_polling_delay: float=_CALCULATION_EXECUTION_WAIT_POLLING_DELAY) -> 'GetCalculationExecutionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetCalculationExecutionStatusResponseTypeDef' = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n    state: str = response['Status']['State']\n    while state not in _CALCULATION_EXECUTION_FINAL_STATES:\n        time.sleep(athena_calculation_execution_wait_polling_delay)\n        response = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n        state = response['Status']['State']\n    _logger.debug('Calculation execution state: %s', state)\n    _logger.debug('Calculation execution state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['CANCELED', 'FAILED']:\n        raise exceptions.CalculationFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_calculation_execution(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None, athena_calculation_execution_wait_polling_delay: float=_CALCULATION_EXECUTION_WAIT_POLLING_DELAY) -> 'GetCalculationExecutionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetCalculationExecutionStatusResponseTypeDef' = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n    state: str = response['Status']['State']\n    while state not in _CALCULATION_EXECUTION_FINAL_STATES:\n        time.sleep(athena_calculation_execution_wait_polling_delay)\n        response = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n        state = response['Status']['State']\n    _logger.debug('Calculation execution state: %s', state)\n    _logger.debug('Calculation execution state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['CANCELED', 'FAILED']:\n        raise exceptions.CalculationFailed(response['Status'].get('StateChangeReason'))\n    return response",
            "def _wait_calculation_execution(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None, athena_calculation_execution_wait_polling_delay: float=_CALCULATION_EXECUTION_WAIT_POLLING_DELAY) -> 'GetCalculationExecutionStatusResponseTypeDef':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    response: 'GetCalculationExecutionStatusResponseTypeDef' = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n    state: str = response['Status']['State']\n    while state not in _CALCULATION_EXECUTION_FINAL_STATES:\n        time.sleep(athena_calculation_execution_wait_polling_delay)\n        response = client_athena.get_calculation_execution_status(CalculationExecutionId=calculation_execution_id)\n        state = response['Status']['State']\n    _logger.debug('Calculation execution state: %s', state)\n    _logger.debug('Calculation execution state change reason: %s', response['Status'].get('StateChangeReason'))\n    if state in ['CANCELED', 'FAILED']:\n        raise exceptions.CalculationFailed(response['Status'].get('StateChangeReason'))\n    return response"
        ]
    },
    {
        "func_name": "_get_calculation_execution_results",
        "original": "def _get_calculation_execution_results(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    _wait_calculation_execution(calculation_execution_id=calculation_execution_id, boto3_session=boto3_session)\n    response: 'GetCalculationExecutionResponseTypeDef' = client_athena.get_calculation_execution(CalculationExecutionId=calculation_execution_id)\n    return cast(Dict[str, Any], response)",
        "mutated": [
            "def _get_calculation_execution_results(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    _wait_calculation_execution(calculation_execution_id=calculation_execution_id, boto3_session=boto3_session)\n    response: 'GetCalculationExecutionResponseTypeDef' = client_athena.get_calculation_execution(CalculationExecutionId=calculation_execution_id)\n    return cast(Dict[str, Any], response)",
            "def _get_calculation_execution_results(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    _wait_calculation_execution(calculation_execution_id=calculation_execution_id, boto3_session=boto3_session)\n    response: 'GetCalculationExecutionResponseTypeDef' = client_athena.get_calculation_execution(CalculationExecutionId=calculation_execution_id)\n    return cast(Dict[str, Any], response)",
            "def _get_calculation_execution_results(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    _wait_calculation_execution(calculation_execution_id=calculation_execution_id, boto3_session=boto3_session)\n    response: 'GetCalculationExecutionResponseTypeDef' = client_athena.get_calculation_execution(CalculationExecutionId=calculation_execution_id)\n    return cast(Dict[str, Any], response)",
            "def _get_calculation_execution_results(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    _wait_calculation_execution(calculation_execution_id=calculation_execution_id, boto3_session=boto3_session)\n    response: 'GetCalculationExecutionResponseTypeDef' = client_athena.get_calculation_execution(CalculationExecutionId=calculation_execution_id)\n    return cast(Dict[str, Any], response)",
            "def _get_calculation_execution_results(calculation_execution_id: str, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    _wait_calculation_execution(calculation_execution_id=calculation_execution_id, boto3_session=boto3_session)\n    response: 'GetCalculationExecutionResponseTypeDef' = client_athena.get_calculation_execution(CalculationExecutionId=calculation_execution_id)\n    return cast(Dict[str, Any], response)"
        ]
    },
    {
        "func_name": "create_spark_session",
        "original": "def create_spark_session(workgroup: str, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> str:\n    \"\"\"\n    Create session and wait until ready to accept calculations.\n\n    Parameters\n    ----------\n    workgroup : str\n        Athena workgroup name. Must be Spark-enabled.\n    coordinator_dpu_size : int, optional\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\n        processing work and manages other executors in a notebook session. The default is 1.\n    max_concurrent_dpus : int, optional\n        The maximum number of DPUs that can run concurrently. The default is 5.\n    default_executor_dpu_size: int, optional\n        The default number of DPUs to use for executors. The default is 1.\n    additional_configs : Dict[str, Any], optional\n        Contains additional engine parameter mappings in the form of key-value pairs.\n    idle_timeout : int, optional\n         The idle timeout in minutes for the session. The default is 15.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    str\n        Session id\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> df = wr.athena.create_spark_session(workgroup=\"...\", max_concurrent_dpus=10)\n\n    \"\"\"\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    engine_configuration: 'EngineConfigurationTypeDef' = {'CoordinatorDpuSize': coordinator_dpu_size, 'MaxConcurrentDpus': max_concurrent_dpus, 'DefaultExecutorDpuSize': default_executor_dpu_size}\n    if additional_configs:\n        engine_configuration['AdditionalConfigs'] = additional_configs\n    response = client_athena.start_session(WorkGroup=workgroup, EngineConfiguration=engine_configuration, SessionIdleTimeoutInMinutes=idle_timeout)\n    _logger.info('Session info:\\n%s', response)\n    session_id: str = response['SessionId']\n    _wait_session(session_id=session_id, boto3_session=boto3_session)\n    return session_id",
        "mutated": [
            "def create_spark_session(workgroup: str, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n    '\\n    Create session and wait until ready to accept calculations.\\n\\n    Parameters\\n    ----------\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n         The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Session id\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.create_spark_session(workgroup=\"...\", max_concurrent_dpus=10)\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    engine_configuration: 'EngineConfigurationTypeDef' = {'CoordinatorDpuSize': coordinator_dpu_size, 'MaxConcurrentDpus': max_concurrent_dpus, 'DefaultExecutorDpuSize': default_executor_dpu_size}\n    if additional_configs:\n        engine_configuration['AdditionalConfigs'] = additional_configs\n    response = client_athena.start_session(WorkGroup=workgroup, EngineConfiguration=engine_configuration, SessionIdleTimeoutInMinutes=idle_timeout)\n    _logger.info('Session info:\\n%s', response)\n    session_id: str = response['SessionId']\n    _wait_session(session_id=session_id, boto3_session=boto3_session)\n    return session_id",
            "def create_spark_session(workgroup: str, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Create session and wait until ready to accept calculations.\\n\\n    Parameters\\n    ----------\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n         The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Session id\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.create_spark_session(workgroup=\"...\", max_concurrent_dpus=10)\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    engine_configuration: 'EngineConfigurationTypeDef' = {'CoordinatorDpuSize': coordinator_dpu_size, 'MaxConcurrentDpus': max_concurrent_dpus, 'DefaultExecutorDpuSize': default_executor_dpu_size}\n    if additional_configs:\n        engine_configuration['AdditionalConfigs'] = additional_configs\n    response = client_athena.start_session(WorkGroup=workgroup, EngineConfiguration=engine_configuration, SessionIdleTimeoutInMinutes=idle_timeout)\n    _logger.info('Session info:\\n%s', response)\n    session_id: str = response['SessionId']\n    _wait_session(session_id=session_id, boto3_session=boto3_session)\n    return session_id",
            "def create_spark_session(workgroup: str, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Create session and wait until ready to accept calculations.\\n\\n    Parameters\\n    ----------\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n         The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Session id\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.create_spark_session(workgroup=\"...\", max_concurrent_dpus=10)\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    engine_configuration: 'EngineConfigurationTypeDef' = {'CoordinatorDpuSize': coordinator_dpu_size, 'MaxConcurrentDpus': max_concurrent_dpus, 'DefaultExecutorDpuSize': default_executor_dpu_size}\n    if additional_configs:\n        engine_configuration['AdditionalConfigs'] = additional_configs\n    response = client_athena.start_session(WorkGroup=workgroup, EngineConfiguration=engine_configuration, SessionIdleTimeoutInMinutes=idle_timeout)\n    _logger.info('Session info:\\n%s', response)\n    session_id: str = response['SessionId']\n    _wait_session(session_id=session_id, boto3_session=boto3_session)\n    return session_id",
            "def create_spark_session(workgroup: str, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Create session and wait until ready to accept calculations.\\n\\n    Parameters\\n    ----------\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n         The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Session id\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.create_spark_session(workgroup=\"...\", max_concurrent_dpus=10)\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    engine_configuration: 'EngineConfigurationTypeDef' = {'CoordinatorDpuSize': coordinator_dpu_size, 'MaxConcurrentDpus': max_concurrent_dpus, 'DefaultExecutorDpuSize': default_executor_dpu_size}\n    if additional_configs:\n        engine_configuration['AdditionalConfigs'] = additional_configs\n    response = client_athena.start_session(WorkGroup=workgroup, EngineConfiguration=engine_configuration, SessionIdleTimeoutInMinutes=idle_timeout)\n    _logger.info('Session info:\\n%s', response)\n    session_id: str = response['SessionId']\n    _wait_session(session_id=session_id, boto3_session=boto3_session)\n    return session_id",
            "def create_spark_session(workgroup: str, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Create session and wait until ready to accept calculations.\\n\\n    Parameters\\n    ----------\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n         The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Session id\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.create_spark_session(workgroup=\"...\", max_concurrent_dpus=10)\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    engine_configuration: 'EngineConfigurationTypeDef' = {'CoordinatorDpuSize': coordinator_dpu_size, 'MaxConcurrentDpus': max_concurrent_dpus, 'DefaultExecutorDpuSize': default_executor_dpu_size}\n    if additional_configs:\n        engine_configuration['AdditionalConfigs'] = additional_configs\n    response = client_athena.start_session(WorkGroup=workgroup, EngineConfiguration=engine_configuration, SessionIdleTimeoutInMinutes=idle_timeout)\n    _logger.info('Session info:\\n%s', response)\n    session_id: str = response['SessionId']\n    _wait_session(session_id=session_id, boto3_session=boto3_session)\n    return session_id"
        ]
    },
    {
        "func_name": "run_spark_calculation",
        "original": "def run_spark_calculation(code: str, workgroup: str, session_id: Optional[str]=None, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    \"\"\"\n    Execute Spark Calculation and wait for completion.\n\n    Parameters\n    ----------\n    code : str\n        A string that contains the code for the calculation.\n    workgroup : str\n        Athena workgroup name. Must be Spark-enabled.\n    session_id : str, optional\n        The session id. If not passed, a session will be started.\n    coordinator_dpu_size : int, optional\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\n        processing work and manages other executors in a notebook session. The default is 1.\n    max_concurrent_dpus : int, optional\n        The maximum number of DPUs that can run concurrently. The default is 5.\n    default_executor_dpu_size: int, optional\n        The default number of DPUs to use for executors. The default is 1.\n    additional_configs : Dict[str, Any], optional\n        Contains additional engine parameter mappings in the form of key-value pairs.\n    idle_timeout : int, optional\n        The idle timeout in minutes for the session. The default is 15.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    Dict[str, Any]\n        Calculation response\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> df = wr.athena.run_spark_calculation(\n    ...     code=\"print(spark)\",\n    ...     workgroup=\"...\",\n    ... )\n\n    \"\"\"\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    session_id = create_spark_session(workgroup=workgroup, coordinator_dpu_size=coordinator_dpu_size, max_concurrent_dpus=max_concurrent_dpus, default_executor_dpu_size=default_executor_dpu_size, additional_configs=additional_configs, idle_timeout=idle_timeout, boto3_session=boto3_session) if not session_id else session_id\n    response = client_athena.start_calculation_execution(SessionId=session_id, CodeBlock=code)\n    _logger.info('Calculation execution info:\\n%s', response)\n    return _get_calculation_execution_results(calculation_execution_id=response['CalculationExecutionId'], boto3_session=boto3_session)",
        "mutated": [
            "def run_spark_calculation(code: str, workgroup: str, session_id: Optional[str]=None, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n    '\\n    Execute Spark Calculation and wait for completion.\\n\\n    Parameters\\n    ----------\\n    code : str\\n        A string that contains the code for the calculation.\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    session_id : str, optional\\n        The session id. If not passed, a session will be started.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n        The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Calculation response\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.run_spark_calculation(\\n    ...     code=\"print(spark)\",\\n    ...     workgroup=\"...\",\\n    ... )\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    session_id = create_spark_session(workgroup=workgroup, coordinator_dpu_size=coordinator_dpu_size, max_concurrent_dpus=max_concurrent_dpus, default_executor_dpu_size=default_executor_dpu_size, additional_configs=additional_configs, idle_timeout=idle_timeout, boto3_session=boto3_session) if not session_id else session_id\n    response = client_athena.start_calculation_execution(SessionId=session_id, CodeBlock=code)\n    _logger.info('Calculation execution info:\\n%s', response)\n    return _get_calculation_execution_results(calculation_execution_id=response['CalculationExecutionId'], boto3_session=boto3_session)",
            "def run_spark_calculation(code: str, workgroup: str, session_id: Optional[str]=None, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Execute Spark Calculation and wait for completion.\\n\\n    Parameters\\n    ----------\\n    code : str\\n        A string that contains the code for the calculation.\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    session_id : str, optional\\n        The session id. If not passed, a session will be started.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n        The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Calculation response\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.run_spark_calculation(\\n    ...     code=\"print(spark)\",\\n    ...     workgroup=\"...\",\\n    ... )\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    session_id = create_spark_session(workgroup=workgroup, coordinator_dpu_size=coordinator_dpu_size, max_concurrent_dpus=max_concurrent_dpus, default_executor_dpu_size=default_executor_dpu_size, additional_configs=additional_configs, idle_timeout=idle_timeout, boto3_session=boto3_session) if not session_id else session_id\n    response = client_athena.start_calculation_execution(SessionId=session_id, CodeBlock=code)\n    _logger.info('Calculation execution info:\\n%s', response)\n    return _get_calculation_execution_results(calculation_execution_id=response['CalculationExecutionId'], boto3_session=boto3_session)",
            "def run_spark_calculation(code: str, workgroup: str, session_id: Optional[str]=None, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Execute Spark Calculation and wait for completion.\\n\\n    Parameters\\n    ----------\\n    code : str\\n        A string that contains the code for the calculation.\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    session_id : str, optional\\n        The session id. If not passed, a session will be started.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n        The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Calculation response\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.run_spark_calculation(\\n    ...     code=\"print(spark)\",\\n    ...     workgroup=\"...\",\\n    ... )\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    session_id = create_spark_session(workgroup=workgroup, coordinator_dpu_size=coordinator_dpu_size, max_concurrent_dpus=max_concurrent_dpus, default_executor_dpu_size=default_executor_dpu_size, additional_configs=additional_configs, idle_timeout=idle_timeout, boto3_session=boto3_session) if not session_id else session_id\n    response = client_athena.start_calculation_execution(SessionId=session_id, CodeBlock=code)\n    _logger.info('Calculation execution info:\\n%s', response)\n    return _get_calculation_execution_results(calculation_execution_id=response['CalculationExecutionId'], boto3_session=boto3_session)",
            "def run_spark_calculation(code: str, workgroup: str, session_id: Optional[str]=None, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Execute Spark Calculation and wait for completion.\\n\\n    Parameters\\n    ----------\\n    code : str\\n        A string that contains the code for the calculation.\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    session_id : str, optional\\n        The session id. If not passed, a session will be started.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n        The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Calculation response\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.run_spark_calculation(\\n    ...     code=\"print(spark)\",\\n    ...     workgroup=\"...\",\\n    ... )\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    session_id = create_spark_session(workgroup=workgroup, coordinator_dpu_size=coordinator_dpu_size, max_concurrent_dpus=max_concurrent_dpus, default_executor_dpu_size=default_executor_dpu_size, additional_configs=additional_configs, idle_timeout=idle_timeout, boto3_session=boto3_session) if not session_id else session_id\n    response = client_athena.start_calculation_execution(SessionId=session_id, CodeBlock=code)\n    _logger.info('Calculation execution info:\\n%s', response)\n    return _get_calculation_execution_results(calculation_execution_id=response['CalculationExecutionId'], boto3_session=boto3_session)",
            "def run_spark_calculation(code: str, workgroup: str, session_id: Optional[str]=None, coordinator_dpu_size: int=1, max_concurrent_dpus: int=5, default_executor_dpu_size: int=1, additional_configs: Optional[Dict[str, Any]]=None, idle_timeout: int=15, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Execute Spark Calculation and wait for completion.\\n\\n    Parameters\\n    ----------\\n    code : str\\n        A string that contains the code for the calculation.\\n    workgroup : str\\n        Athena workgroup name. Must be Spark-enabled.\\n    session_id : str, optional\\n        The session id. If not passed, a session will be started.\\n    coordinator_dpu_size : int, optional\\n        The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates\\n        processing work and manages other executors in a notebook session. The default is 1.\\n    max_concurrent_dpus : int, optional\\n        The maximum number of DPUs that can run concurrently. The default is 5.\\n    default_executor_dpu_size: int, optional\\n        The default number of DPUs to use for executors. The default is 1.\\n    additional_configs : Dict[str, Any], optional\\n        Contains additional engine parameter mappings in the form of key-value pairs.\\n    idle_timeout : int, optional\\n        The idle timeout in minutes for the session. The default is 15.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Calculation response\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> df = wr.athena.run_spark_calculation(\\n    ...     code=\"print(spark)\",\\n    ...     workgroup=\"...\",\\n    ... )\\n\\n    '\n    client_athena = _utils.client(service_name='athena', session=boto3_session)\n    session_id = create_spark_session(workgroup=workgroup, coordinator_dpu_size=coordinator_dpu_size, max_concurrent_dpus=max_concurrent_dpus, default_executor_dpu_size=default_executor_dpu_size, additional_configs=additional_configs, idle_timeout=idle_timeout, boto3_session=boto3_session) if not session_id else session_id\n    response = client_athena.start_calculation_execution(SessionId=session_id, CodeBlock=code)\n    _logger.info('Calculation execution info:\\n%s', response)\n    return _get_calculation_execution_results(calculation_execution_id=response['CalculationExecutionId'], boto3_session=boto3_session)"
        ]
    }
]