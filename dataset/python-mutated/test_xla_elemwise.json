[
    {
        "func_name": "func",
        "original": "@jit.xla_trace(without_host=True)\ndef func(inps, doup):\n    if backward:\n        gm.attach(inps)\n        with gm:\n            oup = felemwise(*inps, **kwargs)\n            gm.backward(oup, doup)\n            return [oup, *[inp.grad for inp in inps]]\n    else:\n        oup = felemwise(*inps, **kwargs)\n        return [oup]",
        "mutated": [
            "@jit.xla_trace(without_host=True)\ndef func(inps, doup):\n    if False:\n        i = 10\n    if backward:\n        gm.attach(inps)\n        with gm:\n            oup = felemwise(*inps, **kwargs)\n            gm.backward(oup, doup)\n            return [oup, *[inp.grad for inp in inps]]\n    else:\n        oup = felemwise(*inps, **kwargs)\n        return [oup]",
            "@jit.xla_trace(without_host=True)\ndef func(inps, doup):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if backward:\n        gm.attach(inps)\n        with gm:\n            oup = felemwise(*inps, **kwargs)\n            gm.backward(oup, doup)\n            return [oup, *[inp.grad for inp in inps]]\n    else:\n        oup = felemwise(*inps, **kwargs)\n        return [oup]",
            "@jit.xla_trace(without_host=True)\ndef func(inps, doup):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if backward:\n        gm.attach(inps)\n        with gm:\n            oup = felemwise(*inps, **kwargs)\n            gm.backward(oup, doup)\n            return [oup, *[inp.grad for inp in inps]]\n    else:\n        oup = felemwise(*inps, **kwargs)\n        return [oup]",
            "@jit.xla_trace(without_host=True)\ndef func(inps, doup):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if backward:\n        gm.attach(inps)\n        with gm:\n            oup = felemwise(*inps, **kwargs)\n            gm.backward(oup, doup)\n            return [oup, *[inp.grad for inp in inps]]\n    else:\n        oup = felemwise(*inps, **kwargs)\n        return [oup]",
            "@jit.xla_trace(without_host=True)\ndef func(inps, doup):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if backward:\n        gm.attach(inps)\n        with gm:\n            oup = felemwise(*inps, **kwargs)\n            gm.backward(oup, doup)\n            return [oup, *[inp.grad for inp in inps]]\n    else:\n        oup = felemwise(*inps, **kwargs)\n        return [oup]"
        ]
    },
    {
        "func_name": "tester",
        "original": "def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    else:\n        inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n    gm = GradManager()\n\n    @jit.xla_trace(without_host=True)\n    def func(inps, doup):\n        if backward:\n            gm.attach(inps)\n            with gm:\n                oup = felemwise(*inps, **kwargs)\n                gm.backward(oup, doup)\n                return [oup, *[inp.grad for inp in inps]]\n        else:\n            oup = felemwise(*inps, **kwargs)\n            return [oup]\n    mge_rsts = func(inps, doup)\n    xla_rsts = func(inps, doup)\n    for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)",
        "mutated": [
            "def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n    if False:\n        i = 10\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    else:\n        inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n    gm = GradManager()\n\n    @jit.xla_trace(without_host=True)\n    def func(inps, doup):\n        if backward:\n            gm.attach(inps)\n            with gm:\n                oup = felemwise(*inps, **kwargs)\n                gm.backward(oup, doup)\n                return [oup, *[inp.grad for inp in inps]]\n        else:\n            oup = felemwise(*inps, **kwargs)\n            return [oup]\n    mge_rsts = func(inps, doup)\n    xla_rsts = func(inps, doup)\n    for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)",
            "def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    else:\n        inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n    gm = GradManager()\n\n    @jit.xla_trace(without_host=True)\n    def func(inps, doup):\n        if backward:\n            gm.attach(inps)\n            with gm:\n                oup = felemwise(*inps, **kwargs)\n                gm.backward(oup, doup)\n                return [oup, *[inp.grad for inp in inps]]\n        else:\n            oup = felemwise(*inps, **kwargs)\n            return [oup]\n    mge_rsts = func(inps, doup)\n    xla_rsts = func(inps, doup)\n    for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)",
            "def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    else:\n        inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n    gm = GradManager()\n\n    @jit.xla_trace(without_host=True)\n    def func(inps, doup):\n        if backward:\n            gm.attach(inps)\n            with gm:\n                oup = felemwise(*inps, **kwargs)\n                gm.backward(oup, doup)\n                return [oup, *[inp.grad for inp in inps]]\n        else:\n            oup = felemwise(*inps, **kwargs)\n            return [oup]\n    mge_rsts = func(inps, doup)\n    xla_rsts = func(inps, doup)\n    for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)",
            "def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    else:\n        inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n    gm = GradManager()\n\n    @jit.xla_trace(without_host=True)\n    def func(inps, doup):\n        if backward:\n            gm.attach(inps)\n            with gm:\n                oup = felemwise(*inps, **kwargs)\n                gm.backward(oup, doup)\n                return [oup, *[inp.grad for inp in inps]]\n        else:\n            oup = felemwise(*inps, **kwargs)\n            return [oup]\n    mge_rsts = func(inps, doup)\n    xla_rsts = func(inps, doup)\n    for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)",
            "def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    else:\n        inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n    doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n    gm = GradManager()\n\n    @jit.xla_trace(without_host=True)\n    def func(inps, doup):\n        if backward:\n            gm.attach(inps)\n            with gm:\n                oup = felemwise(*inps, **kwargs)\n                gm.backward(oup, doup)\n                return [oup, *[inp.grad for inp in inps]]\n        else:\n            oup = felemwise(*inps, **kwargs)\n            return [oup]\n    mge_rsts = func(inps, doup)\n    xla_rsts = func(inps, doup)\n    for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)"
        ]
    },
    {
        "func_name": "test_elemwise",
        "original": "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_elemwise():\n    np.random.seed(123)\n    mge.random.seed(123)\n\n    def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        else:\n            inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n        gm = GradManager()\n\n        @jit.xla_trace(without_host=True)\n        def func(inps, doup):\n            if backward:\n                gm.attach(inps)\n                with gm:\n                    oup = felemwise(*inps, **kwargs)\n                    gm.backward(oup, doup)\n                    return [oup, *[inp.grad for inp in inps]]\n            else:\n                oup = felemwise(*inps, **kwargs)\n                return [oup]\n        mge_rsts = func(inps, doup)\n        xla_rsts = func(inps, doup)\n        for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n            np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)\n    tester(F.neg, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.abs, (2, 32, 16), dtype=np.float32, atol=1e-05)\n    tester(F.sin, (1, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cos, (4, 16, 3), dtype=np.float32, atol=1e-05)\n    tester(F.tan, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.sinh, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cosh, (3, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.tanh, (4, 6, 3, 1), dtype=np.float32, atol=0.0005)\n    tester(F.asin, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acos, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atan, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.asinh, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acosh, (4, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atanh, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.exp, (2, 8), dtype=np.float32, atol=1e-05)\n    tester(F.sqrt, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.square, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.log, (8, 8, 16), dtype=np.float32, atol=1e-05)\n    tester(F.log1p, (8, 1, 16), dtype=np.float32, atol=1e-05)\n    tester(F.expm1, (6, 8, 2), dtype=np.float32, atol=1e-05)\n    tester(F.floor, (4, 16, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.ceil, (4, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.round, (1, 4, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.clip, (4, 16, 1), dtype=np.float32, atol=1e-05, lower=-1.0, upper=1.0)\n    tester(F.relu, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.gelu, (4, 16, 12, 12), dtype=np.float32, atol=2e-05)\n    tester(F.sigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hsigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hswish, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.relu6, (12, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (1, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (12, 16, 1), dtype=np.float32, atol=1e-05, negative_slope=0.5)\n    tester(F.silu, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.logsigmoid, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.softplus, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.add, (4, 16, 12, 12), (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.sub, (4, 16, 12, 12), (4, 16, 1, 1), dtype=np.float32, atol=1e-05)\n    tester(F.mul, (4, 16, 12, 12), (1, 1, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.div, (4, 16, 1, 1), (4, 16, 12, 12), atol=0.0005)\n    tester(F.floor_div, (4, 16, 12, 12), (4, 16, 1, 1), backward=False, atol=5e-05)\n    tester(F.pow, (4, 1, 12, 12), (1, 16, 12, 12), dtype=np.float32, atol=5e-05)\n    tester(F.prelu, (4, 16, 12, 12), (1,), dtype=np.float32, atol=1e-05)\n    tester(F.prelu, (16, 5, 12), (1, 5, 1), dtype=np.float32, atol=1e-05)\n    tester(F.logaddexp, (16, 5, 12), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.maximum, (1, 5, 1), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.minimum, (1, 5, 12), (16, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.left_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.right_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.equal, (4, 16, 12, 12), (1, 1), backward=False)\n    tester(F.not_equal, (4, 16, 12, 12), (4, 16, 1, 1), backward=False)\n    tester(F.greater, (4, 16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.greater_equal, (16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less, (4, 16, 12, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less_equal, (1, 1, 12, 12), (4, 16, 12, 12), backward=False)",
        "mutated": [
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_elemwise():\n    if False:\n        i = 10\n    np.random.seed(123)\n    mge.random.seed(123)\n\n    def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        else:\n            inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n        gm = GradManager()\n\n        @jit.xla_trace(without_host=True)\n        def func(inps, doup):\n            if backward:\n                gm.attach(inps)\n                with gm:\n                    oup = felemwise(*inps, **kwargs)\n                    gm.backward(oup, doup)\n                    return [oup, *[inp.grad for inp in inps]]\n            else:\n                oup = felemwise(*inps, **kwargs)\n                return [oup]\n        mge_rsts = func(inps, doup)\n        xla_rsts = func(inps, doup)\n        for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n            np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)\n    tester(F.neg, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.abs, (2, 32, 16), dtype=np.float32, atol=1e-05)\n    tester(F.sin, (1, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cos, (4, 16, 3), dtype=np.float32, atol=1e-05)\n    tester(F.tan, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.sinh, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cosh, (3, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.tanh, (4, 6, 3, 1), dtype=np.float32, atol=0.0005)\n    tester(F.asin, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acos, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atan, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.asinh, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acosh, (4, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atanh, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.exp, (2, 8), dtype=np.float32, atol=1e-05)\n    tester(F.sqrt, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.square, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.log, (8, 8, 16), dtype=np.float32, atol=1e-05)\n    tester(F.log1p, (8, 1, 16), dtype=np.float32, atol=1e-05)\n    tester(F.expm1, (6, 8, 2), dtype=np.float32, atol=1e-05)\n    tester(F.floor, (4, 16, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.ceil, (4, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.round, (1, 4, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.clip, (4, 16, 1), dtype=np.float32, atol=1e-05, lower=-1.0, upper=1.0)\n    tester(F.relu, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.gelu, (4, 16, 12, 12), dtype=np.float32, atol=2e-05)\n    tester(F.sigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hsigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hswish, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.relu6, (12, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (1, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (12, 16, 1), dtype=np.float32, atol=1e-05, negative_slope=0.5)\n    tester(F.silu, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.logsigmoid, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.softplus, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.add, (4, 16, 12, 12), (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.sub, (4, 16, 12, 12), (4, 16, 1, 1), dtype=np.float32, atol=1e-05)\n    tester(F.mul, (4, 16, 12, 12), (1, 1, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.div, (4, 16, 1, 1), (4, 16, 12, 12), atol=0.0005)\n    tester(F.floor_div, (4, 16, 12, 12), (4, 16, 1, 1), backward=False, atol=5e-05)\n    tester(F.pow, (4, 1, 12, 12), (1, 16, 12, 12), dtype=np.float32, atol=5e-05)\n    tester(F.prelu, (4, 16, 12, 12), (1,), dtype=np.float32, atol=1e-05)\n    tester(F.prelu, (16, 5, 12), (1, 5, 1), dtype=np.float32, atol=1e-05)\n    tester(F.logaddexp, (16, 5, 12), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.maximum, (1, 5, 1), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.minimum, (1, 5, 12), (16, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.left_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.right_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.equal, (4, 16, 12, 12), (1, 1), backward=False)\n    tester(F.not_equal, (4, 16, 12, 12), (4, 16, 1, 1), backward=False)\n    tester(F.greater, (4, 16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.greater_equal, (16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less, (4, 16, 12, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less_equal, (1, 1, 12, 12), (4, 16, 12, 12), backward=False)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_elemwise():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np.random.seed(123)\n    mge.random.seed(123)\n\n    def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        else:\n            inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n        gm = GradManager()\n\n        @jit.xla_trace(without_host=True)\n        def func(inps, doup):\n            if backward:\n                gm.attach(inps)\n                with gm:\n                    oup = felemwise(*inps, **kwargs)\n                    gm.backward(oup, doup)\n                    return [oup, *[inp.grad for inp in inps]]\n            else:\n                oup = felemwise(*inps, **kwargs)\n                return [oup]\n        mge_rsts = func(inps, doup)\n        xla_rsts = func(inps, doup)\n        for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n            np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)\n    tester(F.neg, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.abs, (2, 32, 16), dtype=np.float32, atol=1e-05)\n    tester(F.sin, (1, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cos, (4, 16, 3), dtype=np.float32, atol=1e-05)\n    tester(F.tan, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.sinh, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cosh, (3, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.tanh, (4, 6, 3, 1), dtype=np.float32, atol=0.0005)\n    tester(F.asin, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acos, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atan, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.asinh, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acosh, (4, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atanh, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.exp, (2, 8), dtype=np.float32, atol=1e-05)\n    tester(F.sqrt, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.square, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.log, (8, 8, 16), dtype=np.float32, atol=1e-05)\n    tester(F.log1p, (8, 1, 16), dtype=np.float32, atol=1e-05)\n    tester(F.expm1, (6, 8, 2), dtype=np.float32, atol=1e-05)\n    tester(F.floor, (4, 16, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.ceil, (4, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.round, (1, 4, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.clip, (4, 16, 1), dtype=np.float32, atol=1e-05, lower=-1.0, upper=1.0)\n    tester(F.relu, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.gelu, (4, 16, 12, 12), dtype=np.float32, atol=2e-05)\n    tester(F.sigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hsigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hswish, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.relu6, (12, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (1, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (12, 16, 1), dtype=np.float32, atol=1e-05, negative_slope=0.5)\n    tester(F.silu, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.logsigmoid, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.softplus, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.add, (4, 16, 12, 12), (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.sub, (4, 16, 12, 12), (4, 16, 1, 1), dtype=np.float32, atol=1e-05)\n    tester(F.mul, (4, 16, 12, 12), (1, 1, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.div, (4, 16, 1, 1), (4, 16, 12, 12), atol=0.0005)\n    tester(F.floor_div, (4, 16, 12, 12), (4, 16, 1, 1), backward=False, atol=5e-05)\n    tester(F.pow, (4, 1, 12, 12), (1, 16, 12, 12), dtype=np.float32, atol=5e-05)\n    tester(F.prelu, (4, 16, 12, 12), (1,), dtype=np.float32, atol=1e-05)\n    tester(F.prelu, (16, 5, 12), (1, 5, 1), dtype=np.float32, atol=1e-05)\n    tester(F.logaddexp, (16, 5, 12), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.maximum, (1, 5, 1), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.minimum, (1, 5, 12), (16, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.left_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.right_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.equal, (4, 16, 12, 12), (1, 1), backward=False)\n    tester(F.not_equal, (4, 16, 12, 12), (4, 16, 1, 1), backward=False)\n    tester(F.greater, (4, 16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.greater_equal, (16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less, (4, 16, 12, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less_equal, (1, 1, 12, 12), (4, 16, 12, 12), backward=False)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_elemwise():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np.random.seed(123)\n    mge.random.seed(123)\n\n    def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        else:\n            inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n        gm = GradManager()\n\n        @jit.xla_trace(without_host=True)\n        def func(inps, doup):\n            if backward:\n                gm.attach(inps)\n                with gm:\n                    oup = felemwise(*inps, **kwargs)\n                    gm.backward(oup, doup)\n                    return [oup, *[inp.grad for inp in inps]]\n            else:\n                oup = felemwise(*inps, **kwargs)\n                return [oup]\n        mge_rsts = func(inps, doup)\n        xla_rsts = func(inps, doup)\n        for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n            np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)\n    tester(F.neg, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.abs, (2, 32, 16), dtype=np.float32, atol=1e-05)\n    tester(F.sin, (1, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cos, (4, 16, 3), dtype=np.float32, atol=1e-05)\n    tester(F.tan, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.sinh, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cosh, (3, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.tanh, (4, 6, 3, 1), dtype=np.float32, atol=0.0005)\n    tester(F.asin, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acos, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atan, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.asinh, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acosh, (4, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atanh, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.exp, (2, 8), dtype=np.float32, atol=1e-05)\n    tester(F.sqrt, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.square, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.log, (8, 8, 16), dtype=np.float32, atol=1e-05)\n    tester(F.log1p, (8, 1, 16), dtype=np.float32, atol=1e-05)\n    tester(F.expm1, (6, 8, 2), dtype=np.float32, atol=1e-05)\n    tester(F.floor, (4, 16, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.ceil, (4, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.round, (1, 4, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.clip, (4, 16, 1), dtype=np.float32, atol=1e-05, lower=-1.0, upper=1.0)\n    tester(F.relu, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.gelu, (4, 16, 12, 12), dtype=np.float32, atol=2e-05)\n    tester(F.sigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hsigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hswish, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.relu6, (12, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (1, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (12, 16, 1), dtype=np.float32, atol=1e-05, negative_slope=0.5)\n    tester(F.silu, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.logsigmoid, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.softplus, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.add, (4, 16, 12, 12), (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.sub, (4, 16, 12, 12), (4, 16, 1, 1), dtype=np.float32, atol=1e-05)\n    tester(F.mul, (4, 16, 12, 12), (1, 1, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.div, (4, 16, 1, 1), (4, 16, 12, 12), atol=0.0005)\n    tester(F.floor_div, (4, 16, 12, 12), (4, 16, 1, 1), backward=False, atol=5e-05)\n    tester(F.pow, (4, 1, 12, 12), (1, 16, 12, 12), dtype=np.float32, atol=5e-05)\n    tester(F.prelu, (4, 16, 12, 12), (1,), dtype=np.float32, atol=1e-05)\n    tester(F.prelu, (16, 5, 12), (1, 5, 1), dtype=np.float32, atol=1e-05)\n    tester(F.logaddexp, (16, 5, 12), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.maximum, (1, 5, 1), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.minimum, (1, 5, 12), (16, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.left_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.right_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.equal, (4, 16, 12, 12), (1, 1), backward=False)\n    tester(F.not_equal, (4, 16, 12, 12), (4, 16, 1, 1), backward=False)\n    tester(F.greater, (4, 16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.greater_equal, (16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less, (4, 16, 12, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less_equal, (1, 1, 12, 12), (4, 16, 12, 12), backward=False)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_elemwise():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np.random.seed(123)\n    mge.random.seed(123)\n\n    def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        else:\n            inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n        gm = GradManager()\n\n        @jit.xla_trace(without_host=True)\n        def func(inps, doup):\n            if backward:\n                gm.attach(inps)\n                with gm:\n                    oup = felemwise(*inps, **kwargs)\n                    gm.backward(oup, doup)\n                    return [oup, *[inp.grad for inp in inps]]\n            else:\n                oup = felemwise(*inps, **kwargs)\n                return [oup]\n        mge_rsts = func(inps, doup)\n        xla_rsts = func(inps, doup)\n        for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n            np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)\n    tester(F.neg, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.abs, (2, 32, 16), dtype=np.float32, atol=1e-05)\n    tester(F.sin, (1, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cos, (4, 16, 3), dtype=np.float32, atol=1e-05)\n    tester(F.tan, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.sinh, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cosh, (3, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.tanh, (4, 6, 3, 1), dtype=np.float32, atol=0.0005)\n    tester(F.asin, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acos, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atan, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.asinh, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acosh, (4, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atanh, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.exp, (2, 8), dtype=np.float32, atol=1e-05)\n    tester(F.sqrt, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.square, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.log, (8, 8, 16), dtype=np.float32, atol=1e-05)\n    tester(F.log1p, (8, 1, 16), dtype=np.float32, atol=1e-05)\n    tester(F.expm1, (6, 8, 2), dtype=np.float32, atol=1e-05)\n    tester(F.floor, (4, 16, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.ceil, (4, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.round, (1, 4, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.clip, (4, 16, 1), dtype=np.float32, atol=1e-05, lower=-1.0, upper=1.0)\n    tester(F.relu, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.gelu, (4, 16, 12, 12), dtype=np.float32, atol=2e-05)\n    tester(F.sigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hsigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hswish, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.relu6, (12, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (1, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (12, 16, 1), dtype=np.float32, atol=1e-05, negative_slope=0.5)\n    tester(F.silu, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.logsigmoid, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.softplus, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.add, (4, 16, 12, 12), (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.sub, (4, 16, 12, 12), (4, 16, 1, 1), dtype=np.float32, atol=1e-05)\n    tester(F.mul, (4, 16, 12, 12), (1, 1, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.div, (4, 16, 1, 1), (4, 16, 12, 12), atol=0.0005)\n    tester(F.floor_div, (4, 16, 12, 12), (4, 16, 1, 1), backward=False, atol=5e-05)\n    tester(F.pow, (4, 1, 12, 12), (1, 16, 12, 12), dtype=np.float32, atol=5e-05)\n    tester(F.prelu, (4, 16, 12, 12), (1,), dtype=np.float32, atol=1e-05)\n    tester(F.prelu, (16, 5, 12), (1, 5, 1), dtype=np.float32, atol=1e-05)\n    tester(F.logaddexp, (16, 5, 12), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.maximum, (1, 5, 1), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.minimum, (1, 5, 12), (16, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.left_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.right_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.equal, (4, 16, 12, 12), (1, 1), backward=False)\n    tester(F.not_equal, (4, 16, 12, 12), (4, 16, 1, 1), backward=False)\n    tester(F.greater, (4, 16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.greater_equal, (16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less, (4, 16, 12, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less_equal, (1, 1, 12, 12), (4, 16, 12, 12), backward=False)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_elemwise():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np.random.seed(123)\n    mge.random.seed(123)\n\n    def tester(felemwise, *inp_shapes, backward=True, dtype=None, atol=1e-05, **kwargs):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inps = [tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        else:\n            inps = [tensor(0.1 * np.random.randn(*inp_shape), dtype=dtype) for inp_shape in inp_shapes]\n        doup = tensor(0.1 * np.random.randn(*felemwise(*inps, **kwargs).shape), dtype=dtype)\n        gm = GradManager()\n\n        @jit.xla_trace(without_host=True)\n        def func(inps, doup):\n            if backward:\n                gm.attach(inps)\n                with gm:\n                    oup = felemwise(*inps, **kwargs)\n                    gm.backward(oup, doup)\n                    return [oup, *[inp.grad for inp in inps]]\n            else:\n                oup = felemwise(*inps, **kwargs)\n                return [oup]\n        mge_rsts = func(inps, doup)\n        xla_rsts = func(inps, doup)\n        for (mge_rst, xla_rst) in zip(mge_rsts, xla_rsts):\n            np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy(), atol=atol)\n    tester(F.neg, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.abs, (2, 32, 16), dtype=np.float32, atol=1e-05)\n    tester(F.sin, (1, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cos, (4, 16, 3), dtype=np.float32, atol=1e-05)\n    tester(F.tan, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.sinh, (4, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.cosh, (3, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.tanh, (4, 6, 3, 1), dtype=np.float32, atol=0.0005)\n    tester(F.asin, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acos, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atan, (4, 16, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.asinh, (4, 1, 3, 1), dtype=np.float32, atol=1e-05)\n    tester(F.acosh, (4, 1), dtype=np.float32, atol=1e-05)\n    tester(F.atanh, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.exp, (2, 8), dtype=np.float32, atol=1e-05)\n    tester(F.sqrt, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.square, (32,), dtype=np.float32, atol=1e-05)\n    tester(F.log, (8, 8, 16), dtype=np.float32, atol=1e-05)\n    tester(F.log1p, (8, 1, 16), dtype=np.float32, atol=1e-05)\n    tester(F.expm1, (6, 8, 2), dtype=np.float32, atol=1e-05)\n    tester(F.floor, (4, 16, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.ceil, (4, 1, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.round, (1, 4, 1), backward=False, dtype=np.float32, atol=1e-05)\n    tester(F.clip, (4, 16, 1), dtype=np.float32, atol=1e-05, lower=-1.0, upper=1.0)\n    tester(F.relu, (1,), dtype=np.float32, atol=1e-05)\n    tester(F.gelu, (4, 16, 12, 12), dtype=np.float32, atol=2e-05)\n    tester(F.sigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hsigmoid, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.hswish, (4, 16, 16, 12), dtype=np.float32, atol=1e-05)\n    tester(F.relu6, (12, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (1, 16, 1), dtype=np.float32, atol=1e-05)\n    tester(F.leaky_relu, (12, 16, 1), dtype=np.float32, atol=1e-05, negative_slope=0.5)\n    tester(F.silu, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.logsigmoid, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.softplus, (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.add, (4, 16, 12, 12), (4, 16, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.sub, (4, 16, 12, 12), (4, 16, 1, 1), dtype=np.float32, atol=1e-05)\n    tester(F.mul, (4, 16, 12, 12), (1, 1, 12, 12), dtype=np.float32, atol=1e-05)\n    tester(F.div, (4, 16, 1, 1), (4, 16, 12, 12), atol=0.0005)\n    tester(F.floor_div, (4, 16, 12, 12), (4, 16, 1, 1), backward=False, atol=5e-05)\n    tester(F.pow, (4, 1, 12, 12), (1, 16, 12, 12), dtype=np.float32, atol=5e-05)\n    tester(F.prelu, (4, 16, 12, 12), (1,), dtype=np.float32, atol=1e-05)\n    tester(F.prelu, (16, 5, 12), (1, 5, 1), dtype=np.float32, atol=1e-05)\n    tester(F.logaddexp, (16, 5, 12), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.maximum, (1, 5, 1), (1, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.minimum, (1, 5, 12), (16, 5, 12), dtype=np.float32, atol=1e-05)\n    tester(F.left_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.right_shift, (4, 16, 12, 12), (1, 1, 12, 12), backward=False, dtype=np.int32)\n    tester(F.equal, (4, 16, 12, 12), (1, 1), backward=False)\n    tester(F.not_equal, (4, 16, 12, 12), (4, 16, 1, 1), backward=False)\n    tester(F.greater, (4, 16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.greater_equal, (16, 1, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less, (4, 16, 12, 1), (4, 16, 12, 12), backward=False)\n    tester(F.less_equal, (1, 1, 12, 12), (4, 16, 12, 12), backward=False)"
        ]
    },
    {
        "func_name": "func",
        "original": "@jit.xla_trace(without_host=True)\ndef func(inp):\n    oup = test_func(inp)\n    return oup",
        "mutated": [
            "@jit.xla_trace(without_host=True)\ndef func(inp):\n    if False:\n        i = 10\n    oup = test_func(inp)\n    return oup",
            "@jit.xla_trace(without_host=True)\ndef func(inp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    oup = test_func(inp)\n    return oup",
            "@jit.xla_trace(without_host=True)\ndef func(inp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    oup = test_func(inp)\n    return oup",
            "@jit.xla_trace(without_host=True)\ndef func(inp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    oup = test_func(inp)\n    return oup",
            "@jit.xla_trace(without_host=True)\ndef func(inp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    oup = test_func(inp)\n    return oup"
        ]
    },
    {
        "func_name": "tester",
        "original": "def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n    else:\n        nr_elem = int(np.prod(inp_shape))\n        inp = np.random.randn(nr_elem)\n        idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n        inp[idx] = inf_or_nan\n        inp = tensor(inp, dtype=dtype)\n\n    @jit.xla_trace(without_host=True)\n    def func(inp):\n        oup = test_func(inp)\n        return oup\n    mge_rst = func(inp)\n    xla_rst = func(inp)\n    np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())",
        "mutated": [
            "def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n    if False:\n        i = 10\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n    else:\n        nr_elem = int(np.prod(inp_shape))\n        inp = np.random.randn(nr_elem)\n        idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n        inp[idx] = inf_or_nan\n        inp = tensor(inp, dtype=dtype)\n\n    @jit.xla_trace(without_host=True)\n    def func(inp):\n        oup = test_func(inp)\n        return oup\n    mge_rst = func(inp)\n    xla_rst = func(inp)\n    np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())",
            "def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n    else:\n        nr_elem = int(np.prod(inp_shape))\n        inp = np.random.randn(nr_elem)\n        idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n        inp[idx] = inf_or_nan\n        inp = tensor(inp, dtype=dtype)\n\n    @jit.xla_trace(without_host=True)\n    def func(inp):\n        oup = test_func(inp)\n        return oup\n    mge_rst = func(inp)\n    xla_rst = func(inp)\n    np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())",
            "def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n    else:\n        nr_elem = int(np.prod(inp_shape))\n        inp = np.random.randn(nr_elem)\n        idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n        inp[idx] = inf_or_nan\n        inp = tensor(inp, dtype=dtype)\n\n    @jit.xla_trace(without_host=True)\n    def func(inp):\n        oup = test_func(inp)\n        return oup\n    mge_rst = func(inp)\n    xla_rst = func(inp)\n    np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())",
            "def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n    else:\n        nr_elem = int(np.prod(inp_shape))\n        inp = np.random.randn(nr_elem)\n        idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n        inp[idx] = inf_or_nan\n        inp = tensor(inp, dtype=dtype)\n\n    @jit.xla_trace(without_host=True)\n    def func(inp):\n        oup = test_func(inp)\n        return oup\n    mge_rst = func(inp)\n    xla_rst = func(inp)\n    np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())",
            "def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dtype = dtype or np.float32\n    if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n        inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n    else:\n        nr_elem = int(np.prod(inp_shape))\n        inp = np.random.randn(nr_elem)\n        idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n        inp[idx] = inf_or_nan\n        inp = tensor(inp, dtype=dtype)\n\n    @jit.xla_trace(without_host=True)\n    def func(inp):\n        oup = test_func(inp)\n        return oup\n    mge_rst = func(inp)\n    xla_rst = func(inp)\n    np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())"
        ]
    },
    {
        "func_name": "test_is_inf_nan",
        "original": "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_is_inf_nan():\n\n    def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n        else:\n            nr_elem = int(np.prod(inp_shape))\n            inp = np.random.randn(nr_elem)\n            idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n            inp[idx] = inf_or_nan\n            inp = tensor(inp, dtype=dtype)\n\n        @jit.xla_trace(without_host=True)\n        def func(inp):\n            oup = test_func(inp)\n            return oup\n        mge_rst = func(inp)\n        xla_rst = func(inp)\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())\n    tester(F.isinf, np.inf, (16, 1), np.float32)\n    tester(F.isinf, np.inf, (2, 32), np.int32)\n    tester(F.isnan, np.nan, (1, 16), np.float32)\n    tester(F.isnan, np.nan, (1,), np.float32)\n    tester(F.isnan, np.nan, (32,), np.int32)",
        "mutated": [
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_is_inf_nan():\n    if False:\n        i = 10\n\n    def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n        else:\n            nr_elem = int(np.prod(inp_shape))\n            inp = np.random.randn(nr_elem)\n            idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n            inp[idx] = inf_or_nan\n            inp = tensor(inp, dtype=dtype)\n\n        @jit.xla_trace(without_host=True)\n        def func(inp):\n            oup = test_func(inp)\n            return oup\n        mge_rst = func(inp)\n        xla_rst = func(inp)\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())\n    tester(F.isinf, np.inf, (16, 1), np.float32)\n    tester(F.isinf, np.inf, (2, 32), np.int32)\n    tester(F.isnan, np.nan, (1, 16), np.float32)\n    tester(F.isnan, np.nan, (1,), np.float32)\n    tester(F.isnan, np.nan, (32,), np.int32)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_is_inf_nan():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n        else:\n            nr_elem = int(np.prod(inp_shape))\n            inp = np.random.randn(nr_elem)\n            idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n            inp[idx] = inf_or_nan\n            inp = tensor(inp, dtype=dtype)\n\n        @jit.xla_trace(without_host=True)\n        def func(inp):\n            oup = test_func(inp)\n            return oup\n        mge_rst = func(inp)\n        xla_rst = func(inp)\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())\n    tester(F.isinf, np.inf, (16, 1), np.float32)\n    tester(F.isinf, np.inf, (2, 32), np.int32)\n    tester(F.isnan, np.nan, (1, 16), np.float32)\n    tester(F.isnan, np.nan, (1,), np.float32)\n    tester(F.isnan, np.nan, (32,), np.int32)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_is_inf_nan():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n        else:\n            nr_elem = int(np.prod(inp_shape))\n            inp = np.random.randn(nr_elem)\n            idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n            inp[idx] = inf_or_nan\n            inp = tensor(inp, dtype=dtype)\n\n        @jit.xla_trace(without_host=True)\n        def func(inp):\n            oup = test_func(inp)\n            return oup\n        mge_rst = func(inp)\n        xla_rst = func(inp)\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())\n    tester(F.isinf, np.inf, (16, 1), np.float32)\n    tester(F.isinf, np.inf, (2, 32), np.int32)\n    tester(F.isnan, np.nan, (1, 16), np.float32)\n    tester(F.isnan, np.nan, (1,), np.float32)\n    tester(F.isnan, np.nan, (32,), np.int32)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_is_inf_nan():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n        else:\n            nr_elem = int(np.prod(inp_shape))\n            inp = np.random.randn(nr_elem)\n            idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n            inp[idx] = inf_or_nan\n            inp = tensor(inp, dtype=dtype)\n\n        @jit.xla_trace(without_host=True)\n        def func(inp):\n            oup = test_func(inp)\n            return oup\n        mge_rst = func(inp)\n        xla_rst = func(inp)\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())\n    tester(F.isinf, np.inf, (16, 1), np.float32)\n    tester(F.isinf, np.inf, (2, 32), np.int32)\n    tester(F.isnan, np.nan, (1, 16), np.float32)\n    tester(F.isnan, np.nan, (1,), np.float32)\n    tester(F.isnan, np.nan, (32,), np.int32)",
            "@pytest.mark.skipif(int(platform.python_version_tuple()[1]) < 8, reason='need py38')\n@pytest.mark.skipif(platform.system() != 'Linux', reason='only support linux now')\n@pytest.mark.skipif(not is_cuda_available(), reason='only support cuda now')\ndef test_is_inf_nan():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def tester(test_func, inf_or_nan, inp_shape, dtype=None):\n        dtype = dtype or np.float32\n        if dtype in [np.int16, np.int32, np.uint16, np.uint32]:\n            inp = tensor(np.random.randint(0, 10, size=inp_shape), dtype=dtype)\n        else:\n            nr_elem = int(np.prod(inp_shape))\n            inp = np.random.randn(nr_elem)\n            idx = np.random.randint(0, nr_elem, size=(nr_elem,))\n            inp[idx] = inf_or_nan\n            inp = tensor(inp, dtype=dtype)\n\n        @jit.xla_trace(without_host=True)\n        def func(inp):\n            oup = test_func(inp)\n            return oup\n        mge_rst = func(inp)\n        xla_rst = func(inp)\n        np.testing.assert_allclose(mge_rst.numpy(), xla_rst.numpy())\n    tester(F.isinf, np.inf, (16, 1), np.float32)\n    tester(F.isinf, np.inf, (2, 32), np.int32)\n    tester(F.isnan, np.nan, (1, 16), np.float32)\n    tester(F.isnan, np.nan, (1,), np.float32)\n    tester(F.isnan, np.nan, (32,), np.int32)"
        ]
    }
]