[
    {
        "func_name": "_get_frame_groupby_type",
        "original": "def _get_frame_groupby_type(dtype, index_dtype):\n    \"\"\"\n    Get the Numba type corresponding to a row of grouped data. Models the\n    column as a Record-like data structure containing GroupTypes. See\n    numba.np.numpy_support.from_struct_dtype for details.\n\n    Parameters\n    ----------\n    level : np.dtype\n        A numpy structured array dtype associating field names\n        to scalar dtypes\n    index_dtype : np.dtype\n        A numpy scalar dtype associated with the index of the\n        incoming grouped data\n    \"\"\"\n    fields = []\n    offset = 0\n    sizes = [val[0].itemsize for val in dtype.fields.values()]\n    for (i, (name, info)) in enumerate(dtype.fields.items()):\n        elemdtype = info[0]\n        title = info[2] if len(info) == 3 else None\n        ty = numpy_support.from_dtype(elemdtype)\n        indexty = numpy_support.from_dtype(index_dtype)\n        groupty = GroupType(ty, indexty)\n        infos = {'type': groupty, 'offset': offset, 'title': title}\n        fields.append((name, infos))\n        offset += _get_extensionty_size(groupty)\n        if i < len(sizes) - 1:\n            alignment = offset % 8\n            if alignment != 0:\n                offset += 8 - alignment\n    _is_aligned_struct = True\n    return Row(fields, offset, _is_aligned_struct)",
        "mutated": [
            "def _get_frame_groupby_type(dtype, index_dtype):\n    if False:\n        i = 10\n    '\\n    Get the Numba type corresponding to a row of grouped data. Models the\\n    column as a Record-like data structure containing GroupTypes. See\\n    numba.np.numpy_support.from_struct_dtype for details.\\n\\n    Parameters\\n    ----------\\n    level : np.dtype\\n        A numpy structured array dtype associating field names\\n        to scalar dtypes\\n    index_dtype : np.dtype\\n        A numpy scalar dtype associated with the index of the\\n        incoming grouped data\\n    '\n    fields = []\n    offset = 0\n    sizes = [val[0].itemsize for val in dtype.fields.values()]\n    for (i, (name, info)) in enumerate(dtype.fields.items()):\n        elemdtype = info[0]\n        title = info[2] if len(info) == 3 else None\n        ty = numpy_support.from_dtype(elemdtype)\n        indexty = numpy_support.from_dtype(index_dtype)\n        groupty = GroupType(ty, indexty)\n        infos = {'type': groupty, 'offset': offset, 'title': title}\n        fields.append((name, infos))\n        offset += _get_extensionty_size(groupty)\n        if i < len(sizes) - 1:\n            alignment = offset % 8\n            if alignment != 0:\n                offset += 8 - alignment\n    _is_aligned_struct = True\n    return Row(fields, offset, _is_aligned_struct)",
            "def _get_frame_groupby_type(dtype, index_dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Get the Numba type corresponding to a row of grouped data. Models the\\n    column as a Record-like data structure containing GroupTypes. See\\n    numba.np.numpy_support.from_struct_dtype for details.\\n\\n    Parameters\\n    ----------\\n    level : np.dtype\\n        A numpy structured array dtype associating field names\\n        to scalar dtypes\\n    index_dtype : np.dtype\\n        A numpy scalar dtype associated with the index of the\\n        incoming grouped data\\n    '\n    fields = []\n    offset = 0\n    sizes = [val[0].itemsize for val in dtype.fields.values()]\n    for (i, (name, info)) in enumerate(dtype.fields.items()):\n        elemdtype = info[0]\n        title = info[2] if len(info) == 3 else None\n        ty = numpy_support.from_dtype(elemdtype)\n        indexty = numpy_support.from_dtype(index_dtype)\n        groupty = GroupType(ty, indexty)\n        infos = {'type': groupty, 'offset': offset, 'title': title}\n        fields.append((name, infos))\n        offset += _get_extensionty_size(groupty)\n        if i < len(sizes) - 1:\n            alignment = offset % 8\n            if alignment != 0:\n                offset += 8 - alignment\n    _is_aligned_struct = True\n    return Row(fields, offset, _is_aligned_struct)",
            "def _get_frame_groupby_type(dtype, index_dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Get the Numba type corresponding to a row of grouped data. Models the\\n    column as a Record-like data structure containing GroupTypes. See\\n    numba.np.numpy_support.from_struct_dtype for details.\\n\\n    Parameters\\n    ----------\\n    level : np.dtype\\n        A numpy structured array dtype associating field names\\n        to scalar dtypes\\n    index_dtype : np.dtype\\n        A numpy scalar dtype associated with the index of the\\n        incoming grouped data\\n    '\n    fields = []\n    offset = 0\n    sizes = [val[0].itemsize for val in dtype.fields.values()]\n    for (i, (name, info)) in enumerate(dtype.fields.items()):\n        elemdtype = info[0]\n        title = info[2] if len(info) == 3 else None\n        ty = numpy_support.from_dtype(elemdtype)\n        indexty = numpy_support.from_dtype(index_dtype)\n        groupty = GroupType(ty, indexty)\n        infos = {'type': groupty, 'offset': offset, 'title': title}\n        fields.append((name, infos))\n        offset += _get_extensionty_size(groupty)\n        if i < len(sizes) - 1:\n            alignment = offset % 8\n            if alignment != 0:\n                offset += 8 - alignment\n    _is_aligned_struct = True\n    return Row(fields, offset, _is_aligned_struct)",
            "def _get_frame_groupby_type(dtype, index_dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Get the Numba type corresponding to a row of grouped data. Models the\\n    column as a Record-like data structure containing GroupTypes. See\\n    numba.np.numpy_support.from_struct_dtype for details.\\n\\n    Parameters\\n    ----------\\n    level : np.dtype\\n        A numpy structured array dtype associating field names\\n        to scalar dtypes\\n    index_dtype : np.dtype\\n        A numpy scalar dtype associated with the index of the\\n        incoming grouped data\\n    '\n    fields = []\n    offset = 0\n    sizes = [val[0].itemsize for val in dtype.fields.values()]\n    for (i, (name, info)) in enumerate(dtype.fields.items()):\n        elemdtype = info[0]\n        title = info[2] if len(info) == 3 else None\n        ty = numpy_support.from_dtype(elemdtype)\n        indexty = numpy_support.from_dtype(index_dtype)\n        groupty = GroupType(ty, indexty)\n        infos = {'type': groupty, 'offset': offset, 'title': title}\n        fields.append((name, infos))\n        offset += _get_extensionty_size(groupty)\n        if i < len(sizes) - 1:\n            alignment = offset % 8\n            if alignment != 0:\n                offset += 8 - alignment\n    _is_aligned_struct = True\n    return Row(fields, offset, _is_aligned_struct)",
            "def _get_frame_groupby_type(dtype, index_dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Get the Numba type corresponding to a row of grouped data. Models the\\n    column as a Record-like data structure containing GroupTypes. See\\n    numba.np.numpy_support.from_struct_dtype for details.\\n\\n    Parameters\\n    ----------\\n    level : np.dtype\\n        A numpy structured array dtype associating field names\\n        to scalar dtypes\\n    index_dtype : np.dtype\\n        A numpy scalar dtype associated with the index of the\\n        incoming grouped data\\n    '\n    fields = []\n    offset = 0\n    sizes = [val[0].itemsize for val in dtype.fields.values()]\n    for (i, (name, info)) in enumerate(dtype.fields.items()):\n        elemdtype = info[0]\n        title = info[2] if len(info) == 3 else None\n        ty = numpy_support.from_dtype(elemdtype)\n        indexty = numpy_support.from_dtype(index_dtype)\n        groupty = GroupType(ty, indexty)\n        infos = {'type': groupty, 'offset': offset, 'title': title}\n        fields.append((name, infos))\n        offset += _get_extensionty_size(groupty)\n        if i < len(sizes) - 1:\n            alignment = offset % 8\n            if alignment != 0:\n                offset += 8 - alignment\n    _is_aligned_struct = True\n    return Row(fields, offset, _is_aligned_struct)"
        ]
    },
    {
        "func_name": "_groupby_apply_kernel_string_from_template",
        "original": "def _groupby_apply_kernel_string_from_template(frame, args):\n    \"\"\"\n    Function to write numba kernels for `Groupby.apply` as a string.\n    Workaround until numba supports functions that use `*args`\n    \"\"\"\n    frame = _supported_cols_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES)\n    input_columns = ', '.join([f'input_col_{i}' for i in range(len(frame))])\n    extra_args = ', '.join([f'extra_arg_{i}' for i in range(len(args))])\n    initializers = []\n    for (i, colname) in enumerate(frame.keys()):\n        initializers.append(group_initializer_template.format(idx=i, name=colname))\n    return groupby_apply_kernel_template.format(input_columns=input_columns, extra_args=extra_args, group_initializers='\\n'.join(initializers))",
        "mutated": [
            "def _groupby_apply_kernel_string_from_template(frame, args):\n    if False:\n        i = 10\n    '\\n    Function to write numba kernels for `Groupby.apply` as a string.\\n    Workaround until numba supports functions that use `*args`\\n    '\n    frame = _supported_cols_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES)\n    input_columns = ', '.join([f'input_col_{i}' for i in range(len(frame))])\n    extra_args = ', '.join([f'extra_arg_{i}' for i in range(len(args))])\n    initializers = []\n    for (i, colname) in enumerate(frame.keys()):\n        initializers.append(group_initializer_template.format(idx=i, name=colname))\n    return groupby_apply_kernel_template.format(input_columns=input_columns, extra_args=extra_args, group_initializers='\\n'.join(initializers))",
            "def _groupby_apply_kernel_string_from_template(frame, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Function to write numba kernels for `Groupby.apply` as a string.\\n    Workaround until numba supports functions that use `*args`\\n    '\n    frame = _supported_cols_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES)\n    input_columns = ', '.join([f'input_col_{i}' for i in range(len(frame))])\n    extra_args = ', '.join([f'extra_arg_{i}' for i in range(len(args))])\n    initializers = []\n    for (i, colname) in enumerate(frame.keys()):\n        initializers.append(group_initializer_template.format(idx=i, name=colname))\n    return groupby_apply_kernel_template.format(input_columns=input_columns, extra_args=extra_args, group_initializers='\\n'.join(initializers))",
            "def _groupby_apply_kernel_string_from_template(frame, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Function to write numba kernels for `Groupby.apply` as a string.\\n    Workaround until numba supports functions that use `*args`\\n    '\n    frame = _supported_cols_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES)\n    input_columns = ', '.join([f'input_col_{i}' for i in range(len(frame))])\n    extra_args = ', '.join([f'extra_arg_{i}' for i in range(len(args))])\n    initializers = []\n    for (i, colname) in enumerate(frame.keys()):\n        initializers.append(group_initializer_template.format(idx=i, name=colname))\n    return groupby_apply_kernel_template.format(input_columns=input_columns, extra_args=extra_args, group_initializers='\\n'.join(initializers))",
            "def _groupby_apply_kernel_string_from_template(frame, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Function to write numba kernels for `Groupby.apply` as a string.\\n    Workaround until numba supports functions that use `*args`\\n    '\n    frame = _supported_cols_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES)\n    input_columns = ', '.join([f'input_col_{i}' for i in range(len(frame))])\n    extra_args = ', '.join([f'extra_arg_{i}' for i in range(len(args))])\n    initializers = []\n    for (i, colname) in enumerate(frame.keys()):\n        initializers.append(group_initializer_template.format(idx=i, name=colname))\n    return groupby_apply_kernel_template.format(input_columns=input_columns, extra_args=extra_args, group_initializers='\\n'.join(initializers))",
            "def _groupby_apply_kernel_string_from_template(frame, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Function to write numba kernels for `Groupby.apply` as a string.\\n    Workaround until numba supports functions that use `*args`\\n    '\n    frame = _supported_cols_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES)\n    input_columns = ', '.join([f'input_col_{i}' for i in range(len(frame))])\n    extra_args = ', '.join([f'extra_arg_{i}' for i in range(len(args))])\n    initializers = []\n    for (i, colname) in enumerate(frame.keys()):\n        initializers.append(group_initializer_template.format(idx=i, name=colname))\n    return groupby_apply_kernel_template.format(input_columns=input_columns, extra_args=extra_args, group_initializers='\\n'.join(initializers))"
        ]
    },
    {
        "func_name": "_get_groupby_apply_kernel",
        "original": "def _get_groupby_apply_kernel(frame, func, args):\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    return_type = _get_udf_return_type(dataframe_group_type, func, args)\n    global_exec_context = {'cuda': cuda, 'Group': Group, 'dataframe_group_type': dataframe_group_type, 'types': types}\n    kernel_string = _groupby_apply_kernel_string_from_template(frame, args)\n    kernel = _get_kernel(kernel_string, global_exec_context, None, func)\n    return (kernel, return_type)",
        "mutated": [
            "def _get_groupby_apply_kernel(frame, func, args):\n    if False:\n        i = 10\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    return_type = _get_udf_return_type(dataframe_group_type, func, args)\n    global_exec_context = {'cuda': cuda, 'Group': Group, 'dataframe_group_type': dataframe_group_type, 'types': types}\n    kernel_string = _groupby_apply_kernel_string_from_template(frame, args)\n    kernel = _get_kernel(kernel_string, global_exec_context, None, func)\n    return (kernel, return_type)",
            "def _get_groupby_apply_kernel(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    return_type = _get_udf_return_type(dataframe_group_type, func, args)\n    global_exec_context = {'cuda': cuda, 'Group': Group, 'dataframe_group_type': dataframe_group_type, 'types': types}\n    kernel_string = _groupby_apply_kernel_string_from_template(frame, args)\n    kernel = _get_kernel(kernel_string, global_exec_context, None, func)\n    return (kernel, return_type)",
            "def _get_groupby_apply_kernel(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    return_type = _get_udf_return_type(dataframe_group_type, func, args)\n    global_exec_context = {'cuda': cuda, 'Group': Group, 'dataframe_group_type': dataframe_group_type, 'types': types}\n    kernel_string = _groupby_apply_kernel_string_from_template(frame, args)\n    kernel = _get_kernel(kernel_string, global_exec_context, None, func)\n    return (kernel, return_type)",
            "def _get_groupby_apply_kernel(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    return_type = _get_udf_return_type(dataframe_group_type, func, args)\n    global_exec_context = {'cuda': cuda, 'Group': Group, 'dataframe_group_type': dataframe_group_type, 'types': types}\n    kernel_string = _groupby_apply_kernel_string_from_template(frame, args)\n    kernel = _get_kernel(kernel_string, global_exec_context, None, func)\n    return (kernel, return_type)",
            "def _get_groupby_apply_kernel(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    return_type = _get_udf_return_type(dataframe_group_type, func, args)\n    global_exec_context = {'cuda': cuda, 'Group': Group, 'dataframe_group_type': dataframe_group_type, 'types': types}\n    kernel_string = _groupby_apply_kernel_string_from_template(frame, args)\n    kernel = _get_kernel(kernel_string, global_exec_context, None, func)\n    return (kernel, return_type)"
        ]
    },
    {
        "func_name": "jit_groupby_apply",
        "original": "@_cudf_nvtx_annotate\ndef jit_groupby_apply(offsets, grouped_values, function, *args):\n    \"\"\"\n    Main entrypoint for JIT Groupby.apply via Numba.\n\n    Parameters\n    ----------\n    offsets : list\n        A list of integers denoting the indices of the group\n        boundaries in grouped_values\n    grouped_values : DataFrame\n        A DataFrame representing the source data\n        sorted by group keys\n    function : callable\n        The user-defined function to execute\n    \"\"\"\n    (kernel, return_type) = _compile_or_get(grouped_values, function, args, kernel_getter=_get_groupby_apply_kernel, suffix='__GROUPBY_APPLY_UDF')\n    offsets = cp.asarray(offsets)\n    ngroups = len(offsets) - 1\n    output = cudf.core.column.column_empty(ngroups, dtype=return_type)\n    launch_args = [offsets, output, grouped_values.index]\n    launch_args += list(_supported_cols_from_frame(grouped_values, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).values())\n    launch_args += list(args)\n    max_group_size = cp.diff(offsets).max()\n    if max_group_size >= 256:\n        blocklim = 256\n    else:\n        blocklim = (max_group_size + 32 - 1) // 32 * 32\n    if kernel.specialized:\n        specialized = kernel\n    else:\n        specialized = kernel.specialize(*launch_args)\n    ctx = get_context()\n    (kern_def,) = specialized.overloads.values()\n    (grid, tpb) = ctx.get_max_potential_block_size(func=kern_def._codelibrary.get_cufunc(), b2d_func=0, memsize=0, blocksizelimit=int(blocklim))\n    with _CUDFNumbaConfig():\n        specialized[ngroups, tpb](*launch_args)\n    return output",
        "mutated": [
            "@_cudf_nvtx_annotate\ndef jit_groupby_apply(offsets, grouped_values, function, *args):\n    if False:\n        i = 10\n    '\\n    Main entrypoint for JIT Groupby.apply via Numba.\\n\\n    Parameters\\n    ----------\\n    offsets : list\\n        A list of integers denoting the indices of the group\\n        boundaries in grouped_values\\n    grouped_values : DataFrame\\n        A DataFrame representing the source data\\n        sorted by group keys\\n    function : callable\\n        The user-defined function to execute\\n    '\n    (kernel, return_type) = _compile_or_get(grouped_values, function, args, kernel_getter=_get_groupby_apply_kernel, suffix='__GROUPBY_APPLY_UDF')\n    offsets = cp.asarray(offsets)\n    ngroups = len(offsets) - 1\n    output = cudf.core.column.column_empty(ngroups, dtype=return_type)\n    launch_args = [offsets, output, grouped_values.index]\n    launch_args += list(_supported_cols_from_frame(grouped_values, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).values())\n    launch_args += list(args)\n    max_group_size = cp.diff(offsets).max()\n    if max_group_size >= 256:\n        blocklim = 256\n    else:\n        blocklim = (max_group_size + 32 - 1) // 32 * 32\n    if kernel.specialized:\n        specialized = kernel\n    else:\n        specialized = kernel.specialize(*launch_args)\n    ctx = get_context()\n    (kern_def,) = specialized.overloads.values()\n    (grid, tpb) = ctx.get_max_potential_block_size(func=kern_def._codelibrary.get_cufunc(), b2d_func=0, memsize=0, blocksizelimit=int(blocklim))\n    with _CUDFNumbaConfig():\n        specialized[ngroups, tpb](*launch_args)\n    return output",
            "@_cudf_nvtx_annotate\ndef jit_groupby_apply(offsets, grouped_values, function, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Main entrypoint for JIT Groupby.apply via Numba.\\n\\n    Parameters\\n    ----------\\n    offsets : list\\n        A list of integers denoting the indices of the group\\n        boundaries in grouped_values\\n    grouped_values : DataFrame\\n        A DataFrame representing the source data\\n        sorted by group keys\\n    function : callable\\n        The user-defined function to execute\\n    '\n    (kernel, return_type) = _compile_or_get(grouped_values, function, args, kernel_getter=_get_groupby_apply_kernel, suffix='__GROUPBY_APPLY_UDF')\n    offsets = cp.asarray(offsets)\n    ngroups = len(offsets) - 1\n    output = cudf.core.column.column_empty(ngroups, dtype=return_type)\n    launch_args = [offsets, output, grouped_values.index]\n    launch_args += list(_supported_cols_from_frame(grouped_values, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).values())\n    launch_args += list(args)\n    max_group_size = cp.diff(offsets).max()\n    if max_group_size >= 256:\n        blocklim = 256\n    else:\n        blocklim = (max_group_size + 32 - 1) // 32 * 32\n    if kernel.specialized:\n        specialized = kernel\n    else:\n        specialized = kernel.specialize(*launch_args)\n    ctx = get_context()\n    (kern_def,) = specialized.overloads.values()\n    (grid, tpb) = ctx.get_max_potential_block_size(func=kern_def._codelibrary.get_cufunc(), b2d_func=0, memsize=0, blocksizelimit=int(blocklim))\n    with _CUDFNumbaConfig():\n        specialized[ngroups, tpb](*launch_args)\n    return output",
            "@_cudf_nvtx_annotate\ndef jit_groupby_apply(offsets, grouped_values, function, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Main entrypoint for JIT Groupby.apply via Numba.\\n\\n    Parameters\\n    ----------\\n    offsets : list\\n        A list of integers denoting the indices of the group\\n        boundaries in grouped_values\\n    grouped_values : DataFrame\\n        A DataFrame representing the source data\\n        sorted by group keys\\n    function : callable\\n        The user-defined function to execute\\n    '\n    (kernel, return_type) = _compile_or_get(grouped_values, function, args, kernel_getter=_get_groupby_apply_kernel, suffix='__GROUPBY_APPLY_UDF')\n    offsets = cp.asarray(offsets)\n    ngroups = len(offsets) - 1\n    output = cudf.core.column.column_empty(ngroups, dtype=return_type)\n    launch_args = [offsets, output, grouped_values.index]\n    launch_args += list(_supported_cols_from_frame(grouped_values, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).values())\n    launch_args += list(args)\n    max_group_size = cp.diff(offsets).max()\n    if max_group_size >= 256:\n        blocklim = 256\n    else:\n        blocklim = (max_group_size + 32 - 1) // 32 * 32\n    if kernel.specialized:\n        specialized = kernel\n    else:\n        specialized = kernel.specialize(*launch_args)\n    ctx = get_context()\n    (kern_def,) = specialized.overloads.values()\n    (grid, tpb) = ctx.get_max_potential_block_size(func=kern_def._codelibrary.get_cufunc(), b2d_func=0, memsize=0, blocksizelimit=int(blocklim))\n    with _CUDFNumbaConfig():\n        specialized[ngroups, tpb](*launch_args)\n    return output",
            "@_cudf_nvtx_annotate\ndef jit_groupby_apply(offsets, grouped_values, function, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Main entrypoint for JIT Groupby.apply via Numba.\\n\\n    Parameters\\n    ----------\\n    offsets : list\\n        A list of integers denoting the indices of the group\\n        boundaries in grouped_values\\n    grouped_values : DataFrame\\n        A DataFrame representing the source data\\n        sorted by group keys\\n    function : callable\\n        The user-defined function to execute\\n    '\n    (kernel, return_type) = _compile_or_get(grouped_values, function, args, kernel_getter=_get_groupby_apply_kernel, suffix='__GROUPBY_APPLY_UDF')\n    offsets = cp.asarray(offsets)\n    ngroups = len(offsets) - 1\n    output = cudf.core.column.column_empty(ngroups, dtype=return_type)\n    launch_args = [offsets, output, grouped_values.index]\n    launch_args += list(_supported_cols_from_frame(grouped_values, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).values())\n    launch_args += list(args)\n    max_group_size = cp.diff(offsets).max()\n    if max_group_size >= 256:\n        blocklim = 256\n    else:\n        blocklim = (max_group_size + 32 - 1) // 32 * 32\n    if kernel.specialized:\n        specialized = kernel\n    else:\n        specialized = kernel.specialize(*launch_args)\n    ctx = get_context()\n    (kern_def,) = specialized.overloads.values()\n    (grid, tpb) = ctx.get_max_potential_block_size(func=kern_def._codelibrary.get_cufunc(), b2d_func=0, memsize=0, blocksizelimit=int(blocklim))\n    with _CUDFNumbaConfig():\n        specialized[ngroups, tpb](*launch_args)\n    return output",
            "@_cudf_nvtx_annotate\ndef jit_groupby_apply(offsets, grouped_values, function, *args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Main entrypoint for JIT Groupby.apply via Numba.\\n\\n    Parameters\\n    ----------\\n    offsets : list\\n        A list of integers denoting the indices of the group\\n        boundaries in grouped_values\\n    grouped_values : DataFrame\\n        A DataFrame representing the source data\\n        sorted by group keys\\n    function : callable\\n        The user-defined function to execute\\n    '\n    (kernel, return_type) = _compile_or_get(grouped_values, function, args, kernel_getter=_get_groupby_apply_kernel, suffix='__GROUPBY_APPLY_UDF')\n    offsets = cp.asarray(offsets)\n    ngroups = len(offsets) - 1\n    output = cudf.core.column.column_empty(ngroups, dtype=return_type)\n    launch_args = [offsets, output, grouped_values.index]\n    launch_args += list(_supported_cols_from_frame(grouped_values, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).values())\n    launch_args += list(args)\n    max_group_size = cp.diff(offsets).max()\n    if max_group_size >= 256:\n        blocklim = 256\n    else:\n        blocklim = (max_group_size + 32 - 1) // 32 * 32\n    if kernel.specialized:\n        specialized = kernel\n    else:\n        specialized = kernel.specialize(*launch_args)\n    ctx = get_context()\n    (kern_def,) = specialized.overloads.values()\n    (grid, tpb) = ctx.get_max_potential_block_size(func=kern_def._codelibrary.get_cufunc(), b2d_func=0, memsize=0, blocksizelimit=int(blocklim))\n    with _CUDFNumbaConfig():\n        specialized[ngroups, tpb](*launch_args)\n    return output"
        ]
    },
    {
        "func_name": "_can_be_jitted",
        "original": "def _can_be_jitted(frame, func, args):\n    \"\"\"\n    Determine if this UDF is supported through the JIT engine\n    by attempting to compile just the function to PTX using the\n    target set of types\n    \"\"\"\n    if not hasattr(func, '__code__'):\n        return False\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    try:\n        _get_udf_return_type(dataframe_group_type, func, args)\n        return True\n    except TypingError:\n        return False",
        "mutated": [
            "def _can_be_jitted(frame, func, args):\n    if False:\n        i = 10\n    '\\n    Determine if this UDF is supported through the JIT engine\\n    by attempting to compile just the function to PTX using the\\n    target set of types\\n    '\n    if not hasattr(func, '__code__'):\n        return False\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    try:\n        _get_udf_return_type(dataframe_group_type, func, args)\n        return True\n    except TypingError:\n        return False",
            "def _can_be_jitted(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Determine if this UDF is supported through the JIT engine\\n    by attempting to compile just the function to PTX using the\\n    target set of types\\n    '\n    if not hasattr(func, '__code__'):\n        return False\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    try:\n        _get_udf_return_type(dataframe_group_type, func, args)\n        return True\n    except TypingError:\n        return False",
            "def _can_be_jitted(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Determine if this UDF is supported through the JIT engine\\n    by attempting to compile just the function to PTX using the\\n    target set of types\\n    '\n    if not hasattr(func, '__code__'):\n        return False\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    try:\n        _get_udf_return_type(dataframe_group_type, func, args)\n        return True\n    except TypingError:\n        return False",
            "def _can_be_jitted(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Determine if this UDF is supported through the JIT engine\\n    by attempting to compile just the function to PTX using the\\n    target set of types\\n    '\n    if not hasattr(func, '__code__'):\n        return False\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    try:\n        _get_udf_return_type(dataframe_group_type, func, args)\n        return True\n    except TypingError:\n        return False",
            "def _can_be_jitted(frame, func, args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Determine if this UDF is supported through the JIT engine\\n    by attempting to compile just the function to PTX using the\\n    target set of types\\n    '\n    if not hasattr(func, '__code__'):\n        return False\n    np_field_types = np.dtype(list(_supported_dtypes_from_frame(frame, supported_types=SUPPORTED_GROUPBY_NUMPY_TYPES).items()))\n    dataframe_group_type = _get_frame_groupby_type(np_field_types, frame.index.dtype)\n    try:\n        _get_udf_return_type(dataframe_group_type, func, args)\n        return True\n    except TypingError:\n        return False"
        ]
    }
]