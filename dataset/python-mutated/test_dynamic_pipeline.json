[
    {
        "func_name": "test_dynamic_resume_reexecution",
        "original": "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id, 'tags': [{'key': RESUME_RETRY_TAG, 'value': 'true'}]}}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
        "mutated": [
            "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id, 'tags': [{'key': RESUME_RETRY_TAG, 'value': 'true'}]}}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id, 'tags': [{'key': RESUME_RETRY_TAG, 'value': 'true'}]}}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id, 'tags': [{'key': RESUME_RETRY_TAG, 'value': 'true'}]}}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id, 'tags': [{'key': RESUME_RETRY_TAG, 'value': 'true'}]}}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_resume_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id, 'tags': [{'key': RESUME_RETRY_TAG, 'value': 'true'}]}}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')"
        ]
    },
    {
        "func_name": "test_dynamic_full_reexecution",
        "original": "def test_dynamic_full_reexecution(graphql_context: WorkspaceRequestContext):\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': None}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
        "mutated": [
            "def test_dynamic_full_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': None}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_full_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': None}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_full_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': None}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_full_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': None}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_full_reexecution(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': None}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')"
        ]
    },
    {
        "func_name": "test_dynamic_subset",
        "original": "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': ['multiply_inputs[2]', 'multiply_by_two[2]', 'sum_numbers', 'double_total']}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
        "mutated": [
            "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': ['multiply_inputs[2]', 'multiply_by_two[2]', 'sum_numbers', 'double_total']}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': ['multiply_inputs[2]', 'multiply_by_two[2]', 'sum_numbers', 'double_total']}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': ['multiply_inputs[2]', 'multiply_by_two[2]', 'sum_numbers', 'double_total']}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': ['multiply_inputs[2]', 'multiply_by_two[2]', 'sum_numbers', 'double_total']}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')",
            "def test_dynamic_subset(graphql_context: WorkspaceRequestContext):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_EXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}}})\n    assert not result.errors\n    assert result.data\n    assert result.data['launchPipelineExecution']['__typename'] == 'LaunchRunSuccess'\n    assert result.data['launchPipelineExecution']['run']['pipeline']['name'] == 'dynamic_job'\n    parent_run_id = result.data['launchPipelineExecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, parent_run_id)['pipelineRunLogs']['messages']\n    assert step_did_succeed(logs, 'emit')\n    assert step_did_succeed(logs, 'multiply_inputs[0]')\n    assert step_did_succeed(logs, 'multiply_inputs[1]')\n    assert step_did_fail(logs, 'multiply_inputs[2]')\n    assert step_did_succeed(logs, 'multiply_by_two[0]')\n    assert step_did_succeed(logs, 'multiply_by_two[1]')\n    retry_one = execute_dagster_graphql_and_finish_runs(graphql_context, LAUNCH_PIPELINE_REEXECUTION_MUTATION, variables={'executionParams': {'selector': selector, 'runConfigData': {'ops': {'multiply_inputs': {'inputs': {'should_fail': {'value': True}}}}}, 'executionMetadata': {'rootRunId': parent_run_id, 'parentRunId': parent_run_id}, 'stepKeys': ['multiply_inputs[2]', 'multiply_by_two[2]', 'sum_numbers', 'double_total']}})\n    assert not retry_one.errors\n    assert retry_one.data\n    assert retry_one.data['launchPipelineReexecution']['__typename'] == 'LaunchRunSuccess', retry_one.data['launchPipelineReexecution'].get('message')\n    run_id = retry_one.data['launchPipelineReexecution']['run']['runId']\n    logs = get_all_logs_for_finished_run_via_subscription(graphql_context, run_id)['pipelineRunLogs']['messages']\n    assert step_did_not_run(logs, 'emit')\n    assert step_did_not_run(logs, 'multiply_inputs[0]')\n    assert step_did_not_run(logs, 'multiply_inputs[1]')\n    assert step_did_succeed(logs, 'multiply_inputs[2]')\n    assert step_did_not_run(logs, 'multiply_by_two[0]')\n    assert step_did_not_run(logs, 'multiply_by_two[1]')\n    assert step_did_succeed(logs, 'multiply_by_two[2]')\n    assert step_did_succeed(logs, 'double_total')"
        ]
    },
    {
        "func_name": "test_dynamic_dep_fields",
        "original": "def test_dynamic_dep_fields(graphql_context):\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql(graphql_context, DEP_QUERY, variables={'selector': selector})\n    assert not result.errors\n    ops = {op['name']: op for op in result.data['pipelineOrError']['solids']}\n    assert ops['emit_ten']['isDynamicMapped'] is False\n    assert ops['emit_ten']['outputs'][0]['definition']['isDynamic'] is False\n    assert ops['emit']['isDynamicMapped'] is False\n    assert ops['emit']['outputs'][0]['definition']['isDynamic'] is True\n    assert ops['multiply_inputs']['isDynamicMapped'] is True\n    assert ops['multiply_by_two']['isDynamicMapped'] is True\n    assert ops['sum_numbers']['isDynamicMapped'] is False\n    assert ops['sum_numbers']['inputs'][0]['isDynamicCollect'] is True\n    assert ops['double_total']['isDynamicMapped'] is False\n    assert ops['double_total']['inputs'][0]['isDynamicCollect'] is False",
        "mutated": [
            "def test_dynamic_dep_fields(graphql_context):\n    if False:\n        i = 10\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql(graphql_context, DEP_QUERY, variables={'selector': selector})\n    assert not result.errors\n    ops = {op['name']: op for op in result.data['pipelineOrError']['solids']}\n    assert ops['emit_ten']['isDynamicMapped'] is False\n    assert ops['emit_ten']['outputs'][0]['definition']['isDynamic'] is False\n    assert ops['emit']['isDynamicMapped'] is False\n    assert ops['emit']['outputs'][0]['definition']['isDynamic'] is True\n    assert ops['multiply_inputs']['isDynamicMapped'] is True\n    assert ops['multiply_by_two']['isDynamicMapped'] is True\n    assert ops['sum_numbers']['isDynamicMapped'] is False\n    assert ops['sum_numbers']['inputs'][0]['isDynamicCollect'] is True\n    assert ops['double_total']['isDynamicMapped'] is False\n    assert ops['double_total']['inputs'][0]['isDynamicCollect'] is False",
            "def test_dynamic_dep_fields(graphql_context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql(graphql_context, DEP_QUERY, variables={'selector': selector})\n    assert not result.errors\n    ops = {op['name']: op for op in result.data['pipelineOrError']['solids']}\n    assert ops['emit_ten']['isDynamicMapped'] is False\n    assert ops['emit_ten']['outputs'][0]['definition']['isDynamic'] is False\n    assert ops['emit']['isDynamicMapped'] is False\n    assert ops['emit']['outputs'][0]['definition']['isDynamic'] is True\n    assert ops['multiply_inputs']['isDynamicMapped'] is True\n    assert ops['multiply_by_two']['isDynamicMapped'] is True\n    assert ops['sum_numbers']['isDynamicMapped'] is False\n    assert ops['sum_numbers']['inputs'][0]['isDynamicCollect'] is True\n    assert ops['double_total']['isDynamicMapped'] is False\n    assert ops['double_total']['inputs'][0]['isDynamicCollect'] is False",
            "def test_dynamic_dep_fields(graphql_context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql(graphql_context, DEP_QUERY, variables={'selector': selector})\n    assert not result.errors\n    ops = {op['name']: op for op in result.data['pipelineOrError']['solids']}\n    assert ops['emit_ten']['isDynamicMapped'] is False\n    assert ops['emit_ten']['outputs'][0]['definition']['isDynamic'] is False\n    assert ops['emit']['isDynamicMapped'] is False\n    assert ops['emit']['outputs'][0]['definition']['isDynamic'] is True\n    assert ops['multiply_inputs']['isDynamicMapped'] is True\n    assert ops['multiply_by_two']['isDynamicMapped'] is True\n    assert ops['sum_numbers']['isDynamicMapped'] is False\n    assert ops['sum_numbers']['inputs'][0]['isDynamicCollect'] is True\n    assert ops['double_total']['isDynamicMapped'] is False\n    assert ops['double_total']['inputs'][0]['isDynamicCollect'] is False",
            "def test_dynamic_dep_fields(graphql_context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql(graphql_context, DEP_QUERY, variables={'selector': selector})\n    assert not result.errors\n    ops = {op['name']: op for op in result.data['pipelineOrError']['solids']}\n    assert ops['emit_ten']['isDynamicMapped'] is False\n    assert ops['emit_ten']['outputs'][0]['definition']['isDynamic'] is False\n    assert ops['emit']['isDynamicMapped'] is False\n    assert ops['emit']['outputs'][0]['definition']['isDynamic'] is True\n    assert ops['multiply_inputs']['isDynamicMapped'] is True\n    assert ops['multiply_by_two']['isDynamicMapped'] is True\n    assert ops['sum_numbers']['isDynamicMapped'] is False\n    assert ops['sum_numbers']['inputs'][0]['isDynamicCollect'] is True\n    assert ops['double_total']['isDynamicMapped'] is False\n    assert ops['double_total']['inputs'][0]['isDynamicCollect'] is False",
            "def test_dynamic_dep_fields(graphql_context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    selector = infer_job_selector(graphql_context, 'dynamic_job')\n    result = execute_dagster_graphql(graphql_context, DEP_QUERY, variables={'selector': selector})\n    assert not result.errors\n    ops = {op['name']: op for op in result.data['pipelineOrError']['solids']}\n    assert ops['emit_ten']['isDynamicMapped'] is False\n    assert ops['emit_ten']['outputs'][0]['definition']['isDynamic'] is False\n    assert ops['emit']['isDynamicMapped'] is False\n    assert ops['emit']['outputs'][0]['definition']['isDynamic'] is True\n    assert ops['multiply_inputs']['isDynamicMapped'] is True\n    assert ops['multiply_by_two']['isDynamicMapped'] is True\n    assert ops['sum_numbers']['isDynamicMapped'] is False\n    assert ops['sum_numbers']['inputs'][0]['isDynamicCollect'] is True\n    assert ops['double_total']['isDynamicMapped'] is False\n    assert ops['double_total']['inputs'][0]['isDynamicCollect'] is False"
        ]
    }
]