[
    {
        "func_name": "train",
        "original": "def train(args, model_path, forecaster, train_loader, records):\n    \"\"\"\n    train stage will record throughput.\n    \"\"\"\n    if args.training_processes:\n        forecaster.num_processes = args.training_processes\n    epochs = args.training_epochs\n    forecaster.use_ipex = True if args.ipex else False\n    start_time = time.time()\n    forecaster.fit(train_loader, epochs=epochs)\n    training_time = time.time() - start_time\n    if args.framework == 'tensorflow':\n        training_sample_num = epochs * sum([x.shape[0] for (x, _) in train_loader])\n    else:\n        training_sample_num = epochs * len(train_loader.dataset)\n    forecaster.save(model_path)\n    records['training_time'] = training_time\n    records['training_sample_num'] = training_sample_num\n    records['train_throughput'] = training_sample_num / training_time",
        "mutated": [
            "def train(args, model_path, forecaster, train_loader, records):\n    if False:\n        i = 10\n    '\\n    train stage will record throughput.\\n    '\n    if args.training_processes:\n        forecaster.num_processes = args.training_processes\n    epochs = args.training_epochs\n    forecaster.use_ipex = True if args.ipex else False\n    start_time = time.time()\n    forecaster.fit(train_loader, epochs=epochs)\n    training_time = time.time() - start_time\n    if args.framework == 'tensorflow':\n        training_sample_num = epochs * sum([x.shape[0] for (x, _) in train_loader])\n    else:\n        training_sample_num = epochs * len(train_loader.dataset)\n    forecaster.save(model_path)\n    records['training_time'] = training_time\n    records['training_sample_num'] = training_sample_num\n    records['train_throughput'] = training_sample_num / training_time",
            "def train(args, model_path, forecaster, train_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    train stage will record throughput.\\n    '\n    if args.training_processes:\n        forecaster.num_processes = args.training_processes\n    epochs = args.training_epochs\n    forecaster.use_ipex = True if args.ipex else False\n    start_time = time.time()\n    forecaster.fit(train_loader, epochs=epochs)\n    training_time = time.time() - start_time\n    if args.framework == 'tensorflow':\n        training_sample_num = epochs * sum([x.shape[0] for (x, _) in train_loader])\n    else:\n        training_sample_num = epochs * len(train_loader.dataset)\n    forecaster.save(model_path)\n    records['training_time'] = training_time\n    records['training_sample_num'] = training_sample_num\n    records['train_throughput'] = training_sample_num / training_time",
            "def train(args, model_path, forecaster, train_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    train stage will record throughput.\\n    '\n    if args.training_processes:\n        forecaster.num_processes = args.training_processes\n    epochs = args.training_epochs\n    forecaster.use_ipex = True if args.ipex else False\n    start_time = time.time()\n    forecaster.fit(train_loader, epochs=epochs)\n    training_time = time.time() - start_time\n    if args.framework == 'tensorflow':\n        training_sample_num = epochs * sum([x.shape[0] for (x, _) in train_loader])\n    else:\n        training_sample_num = epochs * len(train_loader.dataset)\n    forecaster.save(model_path)\n    records['training_time'] = training_time\n    records['training_sample_num'] = training_sample_num\n    records['train_throughput'] = training_sample_num / training_time",
            "def train(args, model_path, forecaster, train_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    train stage will record throughput.\\n    '\n    if args.training_processes:\n        forecaster.num_processes = args.training_processes\n    epochs = args.training_epochs\n    forecaster.use_ipex = True if args.ipex else False\n    start_time = time.time()\n    forecaster.fit(train_loader, epochs=epochs)\n    training_time = time.time() - start_time\n    if args.framework == 'tensorflow':\n        training_sample_num = epochs * sum([x.shape[0] for (x, _) in train_loader])\n    else:\n        training_sample_num = epochs * len(train_loader.dataset)\n    forecaster.save(model_path)\n    records['training_time'] = training_time\n    records['training_sample_num'] = training_sample_num\n    records['train_throughput'] = training_sample_num / training_time",
            "def train(args, model_path, forecaster, train_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    train stage will record throughput.\\n    '\n    if args.training_processes:\n        forecaster.num_processes = args.training_processes\n    epochs = args.training_epochs\n    forecaster.use_ipex = True if args.ipex else False\n    start_time = time.time()\n    forecaster.fit(train_loader, epochs=epochs)\n    training_time = time.time() - start_time\n    if args.framework == 'tensorflow':\n        training_sample_num = epochs * sum([x.shape[0] for (x, _) in train_loader])\n    else:\n        training_sample_num = epochs * len(train_loader.dataset)\n    forecaster.save(model_path)\n    records['training_time'] = training_time\n    records['training_sample_num'] = training_sample_num\n    records['train_throughput'] = training_sample_num / training_time"
        ]
    },
    {
        "func_name": "throughput",
        "original": "def throughput(args, model_path, forecaster, train_loader, test_loader, records):\n    \"\"\"\n    throughput stage will record inference throughput.\n    \"\"\"\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    if args.framework == 'tensorflow':\n        inference_sample_num = sum([x.shape[0] for (x, _) in test_loader])\n    else:\n        inference_sample_num = len(test_loader.dataset)\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        st = time.time()\n        yhat = forecaster.predict(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['torch_infer_throughput'] = inference_sample_num / total_time\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_onnx(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['onnx_infer_throughput'] = inference_sample_num / total_time\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_openvino(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['openvino_infer_throughput'] = inference_sample_num / total_time\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_jit(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['jit_infer_throughput'] = inference_sample_num / total_time",
        "mutated": [
            "def throughput(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n    '\\n    throughput stage will record inference throughput.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    if args.framework == 'tensorflow':\n        inference_sample_num = sum([x.shape[0] for (x, _) in test_loader])\n    else:\n        inference_sample_num = len(test_loader.dataset)\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        st = time.time()\n        yhat = forecaster.predict(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['torch_infer_throughput'] = inference_sample_num / total_time\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_onnx(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['onnx_infer_throughput'] = inference_sample_num / total_time\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_openvino(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['openvino_infer_throughput'] = inference_sample_num / total_time\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_jit(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['jit_infer_throughput'] = inference_sample_num / total_time",
            "def throughput(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    throughput stage will record inference throughput.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    if args.framework == 'tensorflow':\n        inference_sample_num = sum([x.shape[0] for (x, _) in test_loader])\n    else:\n        inference_sample_num = len(test_loader.dataset)\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        st = time.time()\n        yhat = forecaster.predict(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['torch_infer_throughput'] = inference_sample_num / total_time\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_onnx(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['onnx_infer_throughput'] = inference_sample_num / total_time\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_openvino(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['openvino_infer_throughput'] = inference_sample_num / total_time\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_jit(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['jit_infer_throughput'] = inference_sample_num / total_time",
            "def throughput(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    throughput stage will record inference throughput.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    if args.framework == 'tensorflow':\n        inference_sample_num = sum([x.shape[0] for (x, _) in test_loader])\n    else:\n        inference_sample_num = len(test_loader.dataset)\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        st = time.time()\n        yhat = forecaster.predict(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['torch_infer_throughput'] = inference_sample_num / total_time\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_onnx(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['onnx_infer_throughput'] = inference_sample_num / total_time\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_openvino(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['openvino_infer_throughput'] = inference_sample_num / total_time\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_jit(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['jit_infer_throughput'] = inference_sample_num / total_time",
            "def throughput(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    throughput stage will record inference throughput.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    if args.framework == 'tensorflow':\n        inference_sample_num = sum([x.shape[0] for (x, _) in test_loader])\n    else:\n        inference_sample_num = len(test_loader.dataset)\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        st = time.time()\n        yhat = forecaster.predict(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['torch_infer_throughput'] = inference_sample_num / total_time\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_onnx(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['onnx_infer_throughput'] = inference_sample_num / total_time\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_openvino(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['openvino_infer_throughput'] = inference_sample_num / total_time\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_jit(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['jit_infer_throughput'] = inference_sample_num / total_time",
            "def throughput(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    throughput stage will record inference throughput.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    if args.framework == 'tensorflow':\n        inference_sample_num = sum([x.shape[0] for (x, _) in test_loader])\n    else:\n        inference_sample_num = len(test_loader.dataset)\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        st = time.time()\n        yhat = forecaster.predict(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['torch_infer_throughput'] = inference_sample_num / total_time\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_onnx(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['onnx_infer_throughput'] = inference_sample_num / total_time\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_openvino(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['openvino_infer_throughput'] = inference_sample_num / total_time\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        st = time.time()\n        yhat = forecaster.predict_with_jit(test_loader, quantize=args.quantize)\n        total_time = time.time() - st\n        records['jit_infer_throughput'] = inference_sample_num / total_time"
        ]
    },
    {
        "func_name": "latency",
        "original": "def latency(args, model_path, forecaster, train_loader, test_loader, records):\n    \"\"\"\n    latency stage will record inference latency.\n    \"\"\"\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    (latency, latency_onnx, latency_vino, latency_jit) = ([], [], [], [])\n    latency_trim_portion = 0.1\n    latency_percentile = [50, 90, 95, 99]\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        if args.model == 'autoformer':\n            for (x, y, x_, y_) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict((x.numpy(), y.numpy(), x_.numpy(), y_.numpy()))\n                latency.append(time.time() - st)\n        else:\n            for (x, y) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict(x.numpy(), quantize=args.quantize)\n                latency.append(time.time() - st)\n        records['torch_latency'] = stats.trim_mean(latency, latency_trim_portion)\n        records['torch_percentile_latency'] = np.percentile(latency, latency_percentile)\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_onnx(x.numpy(), quantize=args.quantize)\n            latency_onnx.append(time.time() - st)\n        records['onnx_latency'] = stats.trim_mean(latency_onnx, latency_trim_portion)\n        records['onnx_percentile_latency'] = np.percentile(latency_onnx, latency_percentile)\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_openvino(x.numpy(), quantize=args.quantize)\n            latency_vino.append(time.time() - st)\n        records['openvino_latency'] = stats.trim_mean(latency_vino, latency_trim_portion)\n        records['openvino_percentile_latency'] = np.percentile(latency_vino, latency_percentile)\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_jit(x.numpy(), quantize=args.quantize)\n            latency_jit.append(time.time() - st)\n        records['jit_latency'] = stats.trim_mean(latency_jit, latency_trim_portion)\n        records['jit_percentile_latency'] = np.percentile(latency_jit, latency_percentile)",
        "mutated": [
            "def latency(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n    '\\n    latency stage will record inference latency.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    (latency, latency_onnx, latency_vino, latency_jit) = ([], [], [], [])\n    latency_trim_portion = 0.1\n    latency_percentile = [50, 90, 95, 99]\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        if args.model == 'autoformer':\n            for (x, y, x_, y_) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict((x.numpy(), y.numpy(), x_.numpy(), y_.numpy()))\n                latency.append(time.time() - st)\n        else:\n            for (x, y) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict(x.numpy(), quantize=args.quantize)\n                latency.append(time.time() - st)\n        records['torch_latency'] = stats.trim_mean(latency, latency_trim_portion)\n        records['torch_percentile_latency'] = np.percentile(latency, latency_percentile)\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_onnx(x.numpy(), quantize=args.quantize)\n            latency_onnx.append(time.time() - st)\n        records['onnx_latency'] = stats.trim_mean(latency_onnx, latency_trim_portion)\n        records['onnx_percentile_latency'] = np.percentile(latency_onnx, latency_percentile)\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_openvino(x.numpy(), quantize=args.quantize)\n            latency_vino.append(time.time() - st)\n        records['openvino_latency'] = stats.trim_mean(latency_vino, latency_trim_portion)\n        records['openvino_percentile_latency'] = np.percentile(latency_vino, latency_percentile)\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_jit(x.numpy(), quantize=args.quantize)\n            latency_jit.append(time.time() - st)\n        records['jit_latency'] = stats.trim_mean(latency_jit, latency_trim_portion)\n        records['jit_percentile_latency'] = np.percentile(latency_jit, latency_percentile)",
            "def latency(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    latency stage will record inference latency.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    (latency, latency_onnx, latency_vino, latency_jit) = ([], [], [], [])\n    latency_trim_portion = 0.1\n    latency_percentile = [50, 90, 95, 99]\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        if args.model == 'autoformer':\n            for (x, y, x_, y_) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict((x.numpy(), y.numpy(), x_.numpy(), y_.numpy()))\n                latency.append(time.time() - st)\n        else:\n            for (x, y) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict(x.numpy(), quantize=args.quantize)\n                latency.append(time.time() - st)\n        records['torch_latency'] = stats.trim_mean(latency, latency_trim_portion)\n        records['torch_percentile_latency'] = np.percentile(latency, latency_percentile)\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_onnx(x.numpy(), quantize=args.quantize)\n            latency_onnx.append(time.time() - st)\n        records['onnx_latency'] = stats.trim_mean(latency_onnx, latency_trim_portion)\n        records['onnx_percentile_latency'] = np.percentile(latency_onnx, latency_percentile)\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_openvino(x.numpy(), quantize=args.quantize)\n            latency_vino.append(time.time() - st)\n        records['openvino_latency'] = stats.trim_mean(latency_vino, latency_trim_portion)\n        records['openvino_percentile_latency'] = np.percentile(latency_vino, latency_percentile)\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_jit(x.numpy(), quantize=args.quantize)\n            latency_jit.append(time.time() - st)\n        records['jit_latency'] = stats.trim_mean(latency_jit, latency_trim_portion)\n        records['jit_percentile_latency'] = np.percentile(latency_jit, latency_percentile)",
            "def latency(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    latency stage will record inference latency.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    (latency, latency_onnx, latency_vino, latency_jit) = ([], [], [], [])\n    latency_trim_portion = 0.1\n    latency_percentile = [50, 90, 95, 99]\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        if args.model == 'autoformer':\n            for (x, y, x_, y_) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict((x.numpy(), y.numpy(), x_.numpy(), y_.numpy()))\n                latency.append(time.time() - st)\n        else:\n            for (x, y) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict(x.numpy(), quantize=args.quantize)\n                latency.append(time.time() - st)\n        records['torch_latency'] = stats.trim_mean(latency, latency_trim_portion)\n        records['torch_percentile_latency'] = np.percentile(latency, latency_percentile)\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_onnx(x.numpy(), quantize=args.quantize)\n            latency_onnx.append(time.time() - st)\n        records['onnx_latency'] = stats.trim_mean(latency_onnx, latency_trim_portion)\n        records['onnx_percentile_latency'] = np.percentile(latency_onnx, latency_percentile)\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_openvino(x.numpy(), quantize=args.quantize)\n            latency_vino.append(time.time() - st)\n        records['openvino_latency'] = stats.trim_mean(latency_vino, latency_trim_portion)\n        records['openvino_percentile_latency'] = np.percentile(latency_vino, latency_percentile)\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_jit(x.numpy(), quantize=args.quantize)\n            latency_jit.append(time.time() - st)\n        records['jit_latency'] = stats.trim_mean(latency_jit, latency_trim_portion)\n        records['jit_percentile_latency'] = np.percentile(latency_jit, latency_percentile)",
            "def latency(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    latency stage will record inference latency.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    (latency, latency_onnx, latency_vino, latency_jit) = ([], [], [], [])\n    latency_trim_portion = 0.1\n    latency_percentile = [50, 90, 95, 99]\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        if args.model == 'autoformer':\n            for (x, y, x_, y_) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict((x.numpy(), y.numpy(), x_.numpy(), y_.numpy()))\n                latency.append(time.time() - st)\n        else:\n            for (x, y) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict(x.numpy(), quantize=args.quantize)\n                latency.append(time.time() - st)\n        records['torch_latency'] = stats.trim_mean(latency, latency_trim_portion)\n        records['torch_percentile_latency'] = np.percentile(latency, latency_percentile)\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_onnx(x.numpy(), quantize=args.quantize)\n            latency_onnx.append(time.time() - st)\n        records['onnx_latency'] = stats.trim_mean(latency_onnx, latency_trim_portion)\n        records['onnx_percentile_latency'] = np.percentile(latency_onnx, latency_percentile)\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_openvino(x.numpy(), quantize=args.quantize)\n            latency_vino.append(time.time() - st)\n        records['openvino_latency'] = stats.trim_mean(latency_vino, latency_trim_portion)\n        records['openvino_percentile_latency'] = np.percentile(latency_vino, latency_percentile)\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_jit(x.numpy(), quantize=args.quantize)\n            latency_jit.append(time.time() - st)\n        records['jit_latency'] = stats.trim_mean(latency_jit, latency_trim_portion)\n        records['jit_percentile_latency'] = np.percentile(latency_jit, latency_percentile)",
            "def latency(args, model_path, forecaster, train_loader, test_loader, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    latency stage will record inference latency.\\n    '\n    try:\n        forecaster.load(model_path)\n    except:\n        forecaster.fit(train_loader, epochs=1)\n    (latency, latency_onnx, latency_vino, latency_jit) = ([], [], [], [])\n    latency_trim_portion = 0.1\n    latency_percentile = [50, 90, 95, 99]\n    if args.quantize:\n        import onnxruntime\n        sess_options = onnxruntime.SessionOptions()\n        if args.cores:\n            sess_options.intra_op_num_threads = args.cores\n            sess_options.inter_op_num_threads = args.cores\n        forecaster.quantize(test_loader, framework=args.quantize_type, sess_options=sess_options, thread_num=args.cores if args.cores else None)\n        print('QUANTIZATION DONE')\n    if 'torch' in args.inference_framework:\n        import torch\n        if args.model == 'autoformer':\n            for (x, y, x_, y_) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict((x.numpy(), y.numpy(), x_.numpy(), y_.numpy()))\n                latency.append(time.time() - st)\n        else:\n            for (x, y) in test_loader:\n                st = time.time()\n                yhat = forecaster.predict(x.numpy(), quantize=args.quantize)\n                latency.append(time.time() - st)\n        records['torch_latency'] = stats.trim_mean(latency, latency_trim_portion)\n        records['torch_percentile_latency'] = np.percentile(latency, latency_percentile)\n    if 'onnx' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_onnx(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_onnx(x.numpy(), quantize=args.quantize)\n            latency_onnx.append(time.time() - st)\n        records['onnx_latency'] = stats.trim_mean(latency_onnx, latency_trim_portion)\n        records['onnx_percentile_latency'] = np.percentile(latency_onnx, latency_percentile)\n    if 'openvino' in args.inference_framework:\n        if args.cores and (not args.quantize):\n            forecaster.build_openvino(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_openvino(x.numpy(), quantize=args.quantize)\n            latency_vino.append(time.time() - st)\n        records['openvino_latency'] = stats.trim_mean(latency_vino, latency_trim_portion)\n        records['openvino_percentile_latency'] = np.percentile(latency_vino, latency_percentile)\n    if 'jit' in args.inference_framework:\n        if args.cores:\n            forecaster.build_jit(thread_num=args.cores)\n        for (x, y) in test_loader:\n            st = time.time()\n            yhat = forecaster.predict_with_jit(x.numpy(), quantize=args.quantize)\n            latency_jit.append(time.time() - st)\n        records['jit_latency'] = stats.trim_mean(latency_jit, latency_trim_portion)\n        records['jit_percentile_latency'] = np.percentile(latency_jit, latency_percentile)"
        ]
    },
    {
        "func_name": "accuracy",
        "original": "def accuracy(args, records, forecaster, train_loader, val_loader, test_loader):\n    \"\"\"\n    evaluate stage will record model accuracy.\n    \"\"\"\n    if args.framework == 'torch':\n        forecaster.fit(train_loader, validation_data=val_loader, epochs=args.training_epochs, validation_mode='best_epoch')\n    else:\n        forecaster.fit(train_loader, epochs=args.training_epochs)\n    metrics = forecaster.evaluate(test_loader, multioutput='uniform_average')\n    for i in range(len(metrics)):\n        records[args.metrics[i]] = metrics[i]",
        "mutated": [
            "def accuracy(args, records, forecaster, train_loader, val_loader, test_loader):\n    if False:\n        i = 10\n    '\\n    evaluate stage will record model accuracy.\\n    '\n    if args.framework == 'torch':\n        forecaster.fit(train_loader, validation_data=val_loader, epochs=args.training_epochs, validation_mode='best_epoch')\n    else:\n        forecaster.fit(train_loader, epochs=args.training_epochs)\n    metrics = forecaster.evaluate(test_loader, multioutput='uniform_average')\n    for i in range(len(metrics)):\n        records[args.metrics[i]] = metrics[i]",
            "def accuracy(args, records, forecaster, train_loader, val_loader, test_loader):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    evaluate stage will record model accuracy.\\n    '\n    if args.framework == 'torch':\n        forecaster.fit(train_loader, validation_data=val_loader, epochs=args.training_epochs, validation_mode='best_epoch')\n    else:\n        forecaster.fit(train_loader, epochs=args.training_epochs)\n    metrics = forecaster.evaluate(test_loader, multioutput='uniform_average')\n    for i in range(len(metrics)):\n        records[args.metrics[i]] = metrics[i]",
            "def accuracy(args, records, forecaster, train_loader, val_loader, test_loader):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    evaluate stage will record model accuracy.\\n    '\n    if args.framework == 'torch':\n        forecaster.fit(train_loader, validation_data=val_loader, epochs=args.training_epochs, validation_mode='best_epoch')\n    else:\n        forecaster.fit(train_loader, epochs=args.training_epochs)\n    metrics = forecaster.evaluate(test_loader, multioutput='uniform_average')\n    for i in range(len(metrics)):\n        records[args.metrics[i]] = metrics[i]",
            "def accuracy(args, records, forecaster, train_loader, val_loader, test_loader):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    evaluate stage will record model accuracy.\\n    '\n    if args.framework == 'torch':\n        forecaster.fit(train_loader, validation_data=val_loader, epochs=args.training_epochs, validation_mode='best_epoch')\n    else:\n        forecaster.fit(train_loader, epochs=args.training_epochs)\n    metrics = forecaster.evaluate(test_loader, multioutput='uniform_average')\n    for i in range(len(metrics)):\n        records[args.metrics[i]] = metrics[i]",
            "def accuracy(args, records, forecaster, train_loader, val_loader, test_loader):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    evaluate stage will record model accuracy.\\n    '\n    if args.framework == 'torch':\n        forecaster.fit(train_loader, validation_data=val_loader, epochs=args.training_epochs, validation_mode='best_epoch')\n    else:\n        forecaster.fit(train_loader, epochs=args.training_epochs)\n    metrics = forecaster.evaluate(test_loader, multioutput='uniform_average')\n    for i in range(len(metrics)):\n        records[args.metrics[i]] = metrics[i]"
        ]
    },
    {
        "func_name": "result",
        "original": "def result(args, records):\n    \"\"\"\n    print benchmark information\n    \"\"\"\n    print('>>>>>>>>>>>>> test-run information >>>>>>>>>>>>>')\n    print('\\x1b[1m\\tModel\\x1b[0m: \\x1b[0;31m' + args.model + '\\x1b[0m')\n    print('\\x1b[1m\\tStage\\x1b[0m: \\x1b[0;31m' + args.stage + '\\x1b[0m')\n    print('\\x1b[1m\\tDataset\\x1b[0m: \\x1b[0;31m' + args.dataset + '\\x1b[0m')\n    if args.cores:\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + args.core + '\\x1b[0m')\n    else:\n        core_num = psutil.cpu_count(logical=False) * int(subprocess.getoutput('cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'))\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + core_num + '\\x1b[0m')\n    print('\\x1b[1m\\tLookback\\x1b[0m: \\x1b[0;31m' + args.lookback + '\\x1b[0m')\n    print('\\x1b[1m\\tHorizon\\x1b[0m: \\x1b[0;31m' + args.horizon + '\\x1b[0m')\n    if args.stage == 'train':\n        print('\\n>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n        print(f\"\\x1b[1m\\tavg throughput\\x1b[0m: \\x1b[0;34m{records['train_throughput']}\\x1b[0m\")\n        print('>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n    elif args.stage == 'latency':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n            print('avg latency: {}ms'.format(records[framework + '_latency'] * 1000))\n            print('p50 latency: {}ms'.format(records[framework + '_percentile_latency'][0] * 1000))\n            print('p90 latency: {}ms'.format(records[framework + '_percentile_latency'][1] * 1000))\n            print('p95 latency: {}ms'.format(records[framework + '_percentile_latency'][2] * 1000))\n            print('p99 latency: {}ms'.format(records[framework + '_percentile_latency'][3] * 1000))\n            print('>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'throughput':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n            print('avg throughput: {}'.format(records[framework + '_infer_throughput']))\n            print('>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'accuracy':\n        print('\\n>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')\n        for metric in args.metrics:\n            print('{}: {}'.format(metric, records[metric]))\n        print('>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')",
        "mutated": [
            "def result(args, records):\n    if False:\n        i = 10\n    '\\n    print benchmark information\\n    '\n    print('>>>>>>>>>>>>> test-run information >>>>>>>>>>>>>')\n    print('\\x1b[1m\\tModel\\x1b[0m: \\x1b[0;31m' + args.model + '\\x1b[0m')\n    print('\\x1b[1m\\tStage\\x1b[0m: \\x1b[0;31m' + args.stage + '\\x1b[0m')\n    print('\\x1b[1m\\tDataset\\x1b[0m: \\x1b[0;31m' + args.dataset + '\\x1b[0m')\n    if args.cores:\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + args.core + '\\x1b[0m')\n    else:\n        core_num = psutil.cpu_count(logical=False) * int(subprocess.getoutput('cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'))\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + core_num + '\\x1b[0m')\n    print('\\x1b[1m\\tLookback\\x1b[0m: \\x1b[0;31m' + args.lookback + '\\x1b[0m')\n    print('\\x1b[1m\\tHorizon\\x1b[0m: \\x1b[0;31m' + args.horizon + '\\x1b[0m')\n    if args.stage == 'train':\n        print('\\n>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n        print(f\"\\x1b[1m\\tavg throughput\\x1b[0m: \\x1b[0;34m{records['train_throughput']}\\x1b[0m\")\n        print('>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n    elif args.stage == 'latency':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n            print('avg latency: {}ms'.format(records[framework + '_latency'] * 1000))\n            print('p50 latency: {}ms'.format(records[framework + '_percentile_latency'][0] * 1000))\n            print('p90 latency: {}ms'.format(records[framework + '_percentile_latency'][1] * 1000))\n            print('p95 latency: {}ms'.format(records[framework + '_percentile_latency'][2] * 1000))\n            print('p99 latency: {}ms'.format(records[framework + '_percentile_latency'][3] * 1000))\n            print('>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'throughput':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n            print('avg throughput: {}'.format(records[framework + '_infer_throughput']))\n            print('>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'accuracy':\n        print('\\n>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')\n        for metric in args.metrics:\n            print('{}: {}'.format(metric, records[metric]))\n        print('>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')",
            "def result(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    print benchmark information\\n    '\n    print('>>>>>>>>>>>>> test-run information >>>>>>>>>>>>>')\n    print('\\x1b[1m\\tModel\\x1b[0m: \\x1b[0;31m' + args.model + '\\x1b[0m')\n    print('\\x1b[1m\\tStage\\x1b[0m: \\x1b[0;31m' + args.stage + '\\x1b[0m')\n    print('\\x1b[1m\\tDataset\\x1b[0m: \\x1b[0;31m' + args.dataset + '\\x1b[0m')\n    if args.cores:\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + args.core + '\\x1b[0m')\n    else:\n        core_num = psutil.cpu_count(logical=False) * int(subprocess.getoutput('cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'))\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + core_num + '\\x1b[0m')\n    print('\\x1b[1m\\tLookback\\x1b[0m: \\x1b[0;31m' + args.lookback + '\\x1b[0m')\n    print('\\x1b[1m\\tHorizon\\x1b[0m: \\x1b[0;31m' + args.horizon + '\\x1b[0m')\n    if args.stage == 'train':\n        print('\\n>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n        print(f\"\\x1b[1m\\tavg throughput\\x1b[0m: \\x1b[0;34m{records['train_throughput']}\\x1b[0m\")\n        print('>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n    elif args.stage == 'latency':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n            print('avg latency: {}ms'.format(records[framework + '_latency'] * 1000))\n            print('p50 latency: {}ms'.format(records[framework + '_percentile_latency'][0] * 1000))\n            print('p90 latency: {}ms'.format(records[framework + '_percentile_latency'][1] * 1000))\n            print('p95 latency: {}ms'.format(records[framework + '_percentile_latency'][2] * 1000))\n            print('p99 latency: {}ms'.format(records[framework + '_percentile_latency'][3] * 1000))\n            print('>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'throughput':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n            print('avg throughput: {}'.format(records[framework + '_infer_throughput']))\n            print('>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'accuracy':\n        print('\\n>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')\n        for metric in args.metrics:\n            print('{}: {}'.format(metric, records[metric]))\n        print('>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')",
            "def result(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    print benchmark information\\n    '\n    print('>>>>>>>>>>>>> test-run information >>>>>>>>>>>>>')\n    print('\\x1b[1m\\tModel\\x1b[0m: \\x1b[0;31m' + args.model + '\\x1b[0m')\n    print('\\x1b[1m\\tStage\\x1b[0m: \\x1b[0;31m' + args.stage + '\\x1b[0m')\n    print('\\x1b[1m\\tDataset\\x1b[0m: \\x1b[0;31m' + args.dataset + '\\x1b[0m')\n    if args.cores:\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + args.core + '\\x1b[0m')\n    else:\n        core_num = psutil.cpu_count(logical=False) * int(subprocess.getoutput('cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'))\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + core_num + '\\x1b[0m')\n    print('\\x1b[1m\\tLookback\\x1b[0m: \\x1b[0;31m' + args.lookback + '\\x1b[0m')\n    print('\\x1b[1m\\tHorizon\\x1b[0m: \\x1b[0;31m' + args.horizon + '\\x1b[0m')\n    if args.stage == 'train':\n        print('\\n>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n        print(f\"\\x1b[1m\\tavg throughput\\x1b[0m: \\x1b[0;34m{records['train_throughput']}\\x1b[0m\")\n        print('>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n    elif args.stage == 'latency':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n            print('avg latency: {}ms'.format(records[framework + '_latency'] * 1000))\n            print('p50 latency: {}ms'.format(records[framework + '_percentile_latency'][0] * 1000))\n            print('p90 latency: {}ms'.format(records[framework + '_percentile_latency'][1] * 1000))\n            print('p95 latency: {}ms'.format(records[framework + '_percentile_latency'][2] * 1000))\n            print('p99 latency: {}ms'.format(records[framework + '_percentile_latency'][3] * 1000))\n            print('>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'throughput':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n            print('avg throughput: {}'.format(records[framework + '_infer_throughput']))\n            print('>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'accuracy':\n        print('\\n>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')\n        for metric in args.metrics:\n            print('{}: {}'.format(metric, records[metric]))\n        print('>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')",
            "def result(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    print benchmark information\\n    '\n    print('>>>>>>>>>>>>> test-run information >>>>>>>>>>>>>')\n    print('\\x1b[1m\\tModel\\x1b[0m: \\x1b[0;31m' + args.model + '\\x1b[0m')\n    print('\\x1b[1m\\tStage\\x1b[0m: \\x1b[0;31m' + args.stage + '\\x1b[0m')\n    print('\\x1b[1m\\tDataset\\x1b[0m: \\x1b[0;31m' + args.dataset + '\\x1b[0m')\n    if args.cores:\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + args.core + '\\x1b[0m')\n    else:\n        core_num = psutil.cpu_count(logical=False) * int(subprocess.getoutput('cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'))\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + core_num + '\\x1b[0m')\n    print('\\x1b[1m\\tLookback\\x1b[0m: \\x1b[0;31m' + args.lookback + '\\x1b[0m')\n    print('\\x1b[1m\\tHorizon\\x1b[0m: \\x1b[0;31m' + args.horizon + '\\x1b[0m')\n    if args.stage == 'train':\n        print('\\n>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n        print(f\"\\x1b[1m\\tavg throughput\\x1b[0m: \\x1b[0;34m{records['train_throughput']}\\x1b[0m\")\n        print('>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n    elif args.stage == 'latency':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n            print('avg latency: {}ms'.format(records[framework + '_latency'] * 1000))\n            print('p50 latency: {}ms'.format(records[framework + '_percentile_latency'][0] * 1000))\n            print('p90 latency: {}ms'.format(records[framework + '_percentile_latency'][1] * 1000))\n            print('p95 latency: {}ms'.format(records[framework + '_percentile_latency'][2] * 1000))\n            print('p99 latency: {}ms'.format(records[framework + '_percentile_latency'][3] * 1000))\n            print('>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'throughput':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n            print('avg throughput: {}'.format(records[framework + '_infer_throughput']))\n            print('>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'accuracy':\n        print('\\n>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')\n        for metric in args.metrics:\n            print('{}: {}'.format(metric, records[metric]))\n        print('>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')",
            "def result(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    print benchmark information\\n    '\n    print('>>>>>>>>>>>>> test-run information >>>>>>>>>>>>>')\n    print('\\x1b[1m\\tModel\\x1b[0m: \\x1b[0;31m' + args.model + '\\x1b[0m')\n    print('\\x1b[1m\\tStage\\x1b[0m: \\x1b[0;31m' + args.stage + '\\x1b[0m')\n    print('\\x1b[1m\\tDataset\\x1b[0m: \\x1b[0;31m' + args.dataset + '\\x1b[0m')\n    if args.cores:\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + args.core + '\\x1b[0m')\n    else:\n        core_num = psutil.cpu_count(logical=False) * int(subprocess.getoutput('cat /proc/cpuinfo | grep \"physical id\" | sort -u | wc -l'))\n        print('\\x1b[1m\\tCores\\x1b[0m: \\x1b[0;31m' + core_num + '\\x1b[0m')\n    print('\\x1b[1m\\tLookback\\x1b[0m: \\x1b[0;31m' + args.lookback + '\\x1b[0m')\n    print('\\x1b[1m\\tHorizon\\x1b[0m: \\x1b[0;31m' + args.horizon + '\\x1b[0m')\n    if args.stage == 'train':\n        print('\\n>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n        print(f\"\\x1b[1m\\tavg throughput\\x1b[0m: \\x1b[0;34m{records['train_throughput']}\\x1b[0m\")\n        print('>>>>>>>>>>>>> train result >>>>>>>>>>>>>')\n    elif args.stage == 'latency':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n            print('avg latency: {}ms'.format(records[framework + '_latency'] * 1000))\n            print('p50 latency: {}ms'.format(records[framework + '_percentile_latency'][0] * 1000))\n            print('p90 latency: {}ms'.format(records[framework + '_percentile_latency'][1] * 1000))\n            print('p95 latency: {}ms'.format(records[framework + '_percentile_latency'][2] * 1000))\n            print('p99 latency: {}ms'.format(records[framework + '_percentile_latency'][3] * 1000))\n            print('>>>>>>>>>>>>> {} latency result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'throughput':\n        for framework in args.inference_framework:\n            print('\\n>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n            print('avg throughput: {}'.format(records[framework + '_infer_throughput']))\n            print('>>>>>>>>>>>>> {} throughput result >>>>>>>>>>>>>'.format(framework))\n    elif args.stage == 'accuracy':\n        print('\\n>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')\n        for metric in args.metrics:\n            print('{}: {}'.format(metric, records[metric]))\n        print('>>>>>>>>>>>>> accuracy result >>>>>>>>>>>>>')"
        ]
    },
    {
        "func_name": "experiment",
        "original": "def experiment(args, records):\n    path = os.path.abspath(os.path.dirname(__file__))\n    model_path = os.path.join(path, args.ckpt)\n    if args.framework == 'tensorflow':\n        import tensorflow as tf\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(args.cores)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path, exist_ok=True)\n    (train_loader, val_loader, test_loader) = generate_data(args)\n    forecaster = generate_forecaster(args)\n    if args.stage == 'train':\n        train(args, model_path, forecaster, train_loader, records)\n    elif args.stage == 'latency':\n        latency(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'throughput':\n        throughput(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'accuracy':\n        accuracy(args, records, forecaster, train_loader, val_loader, test_loader)\n    get_CPU_info()\n    check_nano_env()\n    result(args, records)",
        "mutated": [
            "def experiment(args, records):\n    if False:\n        i = 10\n    path = os.path.abspath(os.path.dirname(__file__))\n    model_path = os.path.join(path, args.ckpt)\n    if args.framework == 'tensorflow':\n        import tensorflow as tf\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(args.cores)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path, exist_ok=True)\n    (train_loader, val_loader, test_loader) = generate_data(args)\n    forecaster = generate_forecaster(args)\n    if args.stage == 'train':\n        train(args, model_path, forecaster, train_loader, records)\n    elif args.stage == 'latency':\n        latency(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'throughput':\n        throughput(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'accuracy':\n        accuracy(args, records, forecaster, train_loader, val_loader, test_loader)\n    get_CPU_info()\n    check_nano_env()\n    result(args, records)",
            "def experiment(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    path = os.path.abspath(os.path.dirname(__file__))\n    model_path = os.path.join(path, args.ckpt)\n    if args.framework == 'tensorflow':\n        import tensorflow as tf\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(args.cores)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path, exist_ok=True)\n    (train_loader, val_loader, test_loader) = generate_data(args)\n    forecaster = generate_forecaster(args)\n    if args.stage == 'train':\n        train(args, model_path, forecaster, train_loader, records)\n    elif args.stage == 'latency':\n        latency(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'throughput':\n        throughput(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'accuracy':\n        accuracy(args, records, forecaster, train_loader, val_loader, test_loader)\n    get_CPU_info()\n    check_nano_env()\n    result(args, records)",
            "def experiment(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    path = os.path.abspath(os.path.dirname(__file__))\n    model_path = os.path.join(path, args.ckpt)\n    if args.framework == 'tensorflow':\n        import tensorflow as tf\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(args.cores)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path, exist_ok=True)\n    (train_loader, val_loader, test_loader) = generate_data(args)\n    forecaster = generate_forecaster(args)\n    if args.stage == 'train':\n        train(args, model_path, forecaster, train_loader, records)\n    elif args.stage == 'latency':\n        latency(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'throughput':\n        throughput(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'accuracy':\n        accuracy(args, records, forecaster, train_loader, val_loader, test_loader)\n    get_CPU_info()\n    check_nano_env()\n    result(args, records)",
            "def experiment(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    path = os.path.abspath(os.path.dirname(__file__))\n    model_path = os.path.join(path, args.ckpt)\n    if args.framework == 'tensorflow':\n        import tensorflow as tf\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(args.cores)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path, exist_ok=True)\n    (train_loader, val_loader, test_loader) = generate_data(args)\n    forecaster = generate_forecaster(args)\n    if args.stage == 'train':\n        train(args, model_path, forecaster, train_loader, records)\n    elif args.stage == 'latency':\n        latency(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'throughput':\n        throughput(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'accuracy':\n        accuracy(args, records, forecaster, train_loader, val_loader, test_loader)\n    get_CPU_info()\n    check_nano_env()\n    result(args, records)",
            "def experiment(args, records):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    path = os.path.abspath(os.path.dirname(__file__))\n    model_path = os.path.join(path, args.ckpt)\n    if args.framework == 'tensorflow':\n        import tensorflow as tf\n        tf.config.threading.set_inter_op_parallelism_threads(1)\n        tf.config.threading.set_intra_op_parallelism_threads(args.cores)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path, exist_ok=True)\n    (train_loader, val_loader, test_loader) = generate_data(args)\n    forecaster = generate_forecaster(args)\n    if args.stage == 'train':\n        train(args, model_path, forecaster, train_loader, records)\n    elif args.stage == 'latency':\n        latency(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'throughput':\n        throughput(args, model_path, forecaster, train_loader, test_loader, records)\n    elif args.stage == 'accuracy':\n        accuracy(args, records, forecaster, train_loader, val_loader, test_loader)\n    get_CPU_info()\n    check_nano_env()\n    result(args, records)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    parser = argparse.ArgumentParser(description='Benchmarking Parameters')\n    parser.add_argument('-m', '--model', type=str, default='tcn', metavar='', help='model name, choose from tcn/lstm/seq2seq/nbeats/autoformer, default to \"tcn\".')\n    parser.add_argument('-s', '--stage', type=str, default='train', metavar='', help='stage name, choose from train/latency/throughput/accuracy, default to \"train\".')\n    parser.add_argument('-d', '--dataset', type=str, default='tsinghua_electricity', metavar='', help='dataset name, choose from nyc_taxi/tsinghua_electricity/synthetic_dataset, default to \"tsinghua_electricity\".')\n    parser.add_argument('-f', '--framework', type=str, default='torch', metavar='', help='framework name, choose from torch/tensorflow, default to \"torch\".')\n    parser.add_argument('-c', '--cores', type=int, default=0, metavar='', help='core number, default to all physical cores.')\n    parser.add_argument('-l', '--lookback', type=int, metavar='lookback', required=True, help='required, the history time steps (i.e. lookback).')\n    parser.add_argument('-o', '--horizon', type=int, metavar='horizon', required=True, help='required, the output time steps (i.e. horizon).')\n    parser.add_argument('--training_processes', type=int, default=1, metavar='', help='number of processes when training, default to 1.')\n    parser.add_argument('--training_batchsize', type=int, default=32, metavar='', help='batch size when training, default to 32.')\n    parser.add_argument('--training_epochs', type=int, default=1, metavar='', help='number of epochs when training, default to 1.')\n    parser.add_argument('--inference_batchsize', type=int, default=1, metavar='', help='batch size when infering, default to 1.')\n    parser.add_argument('--quantize', action='store_true', help='if use the quantized model to predict, default to False.tensorflow will support quantize later.')\n    parser.add_argument('--inference_framework', nargs='+', default=['torch'], metavar='', help='predict without/with accelerator, choose from torch/onnx/openvino/jit, default to \"torch\" (i.e. predict without accelerator).')\n    parser.add_argument('--ipex', action='store_true', help='if use ipex as accelerator for trainer, default to False.')\n    parser.add_argument('--quantize_type', type=str, default='pytorch_fx', metavar='', help='quantize framework, choose from pytorch_fx/pytorch_ipex/onnxrt_qlinearops/openvino, default to \"pytorch_fx\".')\n    parser.add_argument('--ckpt', type=str, default='checkpoints/tcn', metavar='', help='checkpoint path of a trained model, e.g. \"checkpoints/tcn\", default to \"checkpoints/tcn\".')\n    parser.add_argument('--metrics', type=str, nargs='+', default=['mse', 'mae'], metavar='', help='evaluation metrics of a trained model, e.g. \"mse\"/\"mae\", default to \"mse, mae\".')\n    parser.add_argument('--normalization', action='store_true', help='if to use normalization trick to alleviate distribution shift.')\n    args = parser.parse_args()\n    records = vars(args)\n    models = ['tcn', 'lstm', 'seq2seq', 'nbeats', 'autoformer']\n    stages = ['train', 'latency', 'throughput', 'accuracy']\n    datasets = ['tsinghua_electricity', 'nyc_taxi', 'synthetic_dataset']\n    frameworks = ['torch', 'tensorflow']\n    quantize_types = ['pytorch_fx', 'pytorch_ipex', 'onnxrt_qlinearops', 'openvino']\n    quantize_torch_types = ['pytorch_fx', 'pytorch_ipex']\n    invalidInputError(args.model in models, f\"-m/--model argument should be one of {models}, but get '{args.model}'\")\n    invalidInputError(args.stage in stages, f\"-s/--stage argument should be one of {stages}, but get '{args.stage}'\")\n    invalidInputError(args.dataset in datasets, f\"-d/--dataset argument should be one of {datasets}, but get '{{args.dataset}}'\")\n    invalidInputError(args.framework in frameworks, f\"-f/--framework argument should be one of {frameworks}, but get '{{args.framework}}'\")\n    invalidInputError(args.quantize_type in quantize_types, f\"--quantize_type argument should be one of {quantize_types}, but get '{{args.quantize_type}}'\")\n    if args.quantize and 'torch' in args.inference_framework:\n        invalidInputError(args.quantize_type in quantize_torch_types, f\"if inference framework is 'torch', then --quantize_type argument should be one of {{quantize_torch_types}}, but get '{{args.quantize_type}}'\")\n    if 'onnx' in args.inference_framework:\n        args.quantize_type = 'onnxrt_qlinearops'\n    elif 'openvino' in args.inference_framework:\n        args.quantize_type = 'openvino'\n    if args.framework == 'torch':\n        import torch\n        if args.cores:\n            torch.set_num_threads(args.cores)\n        experiment(args, records)\n    elif args.cores:\n        new_experiment = spawn_new_process(experiment)\n        new_experiment(args, records, env_var={'OMP_NUM_THREADS': str(args.cores)})\n    else:\n        experiment(args, records)",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    parser = argparse.ArgumentParser(description='Benchmarking Parameters')\n    parser.add_argument('-m', '--model', type=str, default='tcn', metavar='', help='model name, choose from tcn/lstm/seq2seq/nbeats/autoformer, default to \"tcn\".')\n    parser.add_argument('-s', '--stage', type=str, default='train', metavar='', help='stage name, choose from train/latency/throughput/accuracy, default to \"train\".')\n    parser.add_argument('-d', '--dataset', type=str, default='tsinghua_electricity', metavar='', help='dataset name, choose from nyc_taxi/tsinghua_electricity/synthetic_dataset, default to \"tsinghua_electricity\".')\n    parser.add_argument('-f', '--framework', type=str, default='torch', metavar='', help='framework name, choose from torch/tensorflow, default to \"torch\".')\n    parser.add_argument('-c', '--cores', type=int, default=0, metavar='', help='core number, default to all physical cores.')\n    parser.add_argument('-l', '--lookback', type=int, metavar='lookback', required=True, help='required, the history time steps (i.e. lookback).')\n    parser.add_argument('-o', '--horizon', type=int, metavar='horizon', required=True, help='required, the output time steps (i.e. horizon).')\n    parser.add_argument('--training_processes', type=int, default=1, metavar='', help='number of processes when training, default to 1.')\n    parser.add_argument('--training_batchsize', type=int, default=32, metavar='', help='batch size when training, default to 32.')\n    parser.add_argument('--training_epochs', type=int, default=1, metavar='', help='number of epochs when training, default to 1.')\n    parser.add_argument('--inference_batchsize', type=int, default=1, metavar='', help='batch size when infering, default to 1.')\n    parser.add_argument('--quantize', action='store_true', help='if use the quantized model to predict, default to False.tensorflow will support quantize later.')\n    parser.add_argument('--inference_framework', nargs='+', default=['torch'], metavar='', help='predict without/with accelerator, choose from torch/onnx/openvino/jit, default to \"torch\" (i.e. predict without accelerator).')\n    parser.add_argument('--ipex', action='store_true', help='if use ipex as accelerator for trainer, default to False.')\n    parser.add_argument('--quantize_type', type=str, default='pytorch_fx', metavar='', help='quantize framework, choose from pytorch_fx/pytorch_ipex/onnxrt_qlinearops/openvino, default to \"pytorch_fx\".')\n    parser.add_argument('--ckpt', type=str, default='checkpoints/tcn', metavar='', help='checkpoint path of a trained model, e.g. \"checkpoints/tcn\", default to \"checkpoints/tcn\".')\n    parser.add_argument('--metrics', type=str, nargs='+', default=['mse', 'mae'], metavar='', help='evaluation metrics of a trained model, e.g. \"mse\"/\"mae\", default to \"mse, mae\".')\n    parser.add_argument('--normalization', action='store_true', help='if to use normalization trick to alleviate distribution shift.')\n    args = parser.parse_args()\n    records = vars(args)\n    models = ['tcn', 'lstm', 'seq2seq', 'nbeats', 'autoformer']\n    stages = ['train', 'latency', 'throughput', 'accuracy']\n    datasets = ['tsinghua_electricity', 'nyc_taxi', 'synthetic_dataset']\n    frameworks = ['torch', 'tensorflow']\n    quantize_types = ['pytorch_fx', 'pytorch_ipex', 'onnxrt_qlinearops', 'openvino']\n    quantize_torch_types = ['pytorch_fx', 'pytorch_ipex']\n    invalidInputError(args.model in models, f\"-m/--model argument should be one of {models}, but get '{args.model}'\")\n    invalidInputError(args.stage in stages, f\"-s/--stage argument should be one of {stages}, but get '{args.stage}'\")\n    invalidInputError(args.dataset in datasets, f\"-d/--dataset argument should be one of {datasets}, but get '{{args.dataset}}'\")\n    invalidInputError(args.framework in frameworks, f\"-f/--framework argument should be one of {frameworks}, but get '{{args.framework}}'\")\n    invalidInputError(args.quantize_type in quantize_types, f\"--quantize_type argument should be one of {quantize_types}, but get '{{args.quantize_type}}'\")\n    if args.quantize and 'torch' in args.inference_framework:\n        invalidInputError(args.quantize_type in quantize_torch_types, f\"if inference framework is 'torch', then --quantize_type argument should be one of {{quantize_torch_types}}, but get '{{args.quantize_type}}'\")\n    if 'onnx' in args.inference_framework:\n        args.quantize_type = 'onnxrt_qlinearops'\n    elif 'openvino' in args.inference_framework:\n        args.quantize_type = 'openvino'\n    if args.framework == 'torch':\n        import torch\n        if args.cores:\n            torch.set_num_threads(args.cores)\n        experiment(args, records)\n    elif args.cores:\n        new_experiment = spawn_new_process(experiment)\n        new_experiment(args, records, env_var={'OMP_NUM_THREADS': str(args.cores)})\n    else:\n        experiment(args, records)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = argparse.ArgumentParser(description='Benchmarking Parameters')\n    parser.add_argument('-m', '--model', type=str, default='tcn', metavar='', help='model name, choose from tcn/lstm/seq2seq/nbeats/autoformer, default to \"tcn\".')\n    parser.add_argument('-s', '--stage', type=str, default='train', metavar='', help='stage name, choose from train/latency/throughput/accuracy, default to \"train\".')\n    parser.add_argument('-d', '--dataset', type=str, default='tsinghua_electricity', metavar='', help='dataset name, choose from nyc_taxi/tsinghua_electricity/synthetic_dataset, default to \"tsinghua_electricity\".')\n    parser.add_argument('-f', '--framework', type=str, default='torch', metavar='', help='framework name, choose from torch/tensorflow, default to \"torch\".')\n    parser.add_argument('-c', '--cores', type=int, default=0, metavar='', help='core number, default to all physical cores.')\n    parser.add_argument('-l', '--lookback', type=int, metavar='lookback', required=True, help='required, the history time steps (i.e. lookback).')\n    parser.add_argument('-o', '--horizon', type=int, metavar='horizon', required=True, help='required, the output time steps (i.e. horizon).')\n    parser.add_argument('--training_processes', type=int, default=1, metavar='', help='number of processes when training, default to 1.')\n    parser.add_argument('--training_batchsize', type=int, default=32, metavar='', help='batch size when training, default to 32.')\n    parser.add_argument('--training_epochs', type=int, default=1, metavar='', help='number of epochs when training, default to 1.')\n    parser.add_argument('--inference_batchsize', type=int, default=1, metavar='', help='batch size when infering, default to 1.')\n    parser.add_argument('--quantize', action='store_true', help='if use the quantized model to predict, default to False.tensorflow will support quantize later.')\n    parser.add_argument('--inference_framework', nargs='+', default=['torch'], metavar='', help='predict without/with accelerator, choose from torch/onnx/openvino/jit, default to \"torch\" (i.e. predict without accelerator).')\n    parser.add_argument('--ipex', action='store_true', help='if use ipex as accelerator for trainer, default to False.')\n    parser.add_argument('--quantize_type', type=str, default='pytorch_fx', metavar='', help='quantize framework, choose from pytorch_fx/pytorch_ipex/onnxrt_qlinearops/openvino, default to \"pytorch_fx\".')\n    parser.add_argument('--ckpt', type=str, default='checkpoints/tcn', metavar='', help='checkpoint path of a trained model, e.g. \"checkpoints/tcn\", default to \"checkpoints/tcn\".')\n    parser.add_argument('--metrics', type=str, nargs='+', default=['mse', 'mae'], metavar='', help='evaluation metrics of a trained model, e.g. \"mse\"/\"mae\", default to \"mse, mae\".')\n    parser.add_argument('--normalization', action='store_true', help='if to use normalization trick to alleviate distribution shift.')\n    args = parser.parse_args()\n    records = vars(args)\n    models = ['tcn', 'lstm', 'seq2seq', 'nbeats', 'autoformer']\n    stages = ['train', 'latency', 'throughput', 'accuracy']\n    datasets = ['tsinghua_electricity', 'nyc_taxi', 'synthetic_dataset']\n    frameworks = ['torch', 'tensorflow']\n    quantize_types = ['pytorch_fx', 'pytorch_ipex', 'onnxrt_qlinearops', 'openvino']\n    quantize_torch_types = ['pytorch_fx', 'pytorch_ipex']\n    invalidInputError(args.model in models, f\"-m/--model argument should be one of {models}, but get '{args.model}'\")\n    invalidInputError(args.stage in stages, f\"-s/--stage argument should be one of {stages}, but get '{args.stage}'\")\n    invalidInputError(args.dataset in datasets, f\"-d/--dataset argument should be one of {datasets}, but get '{{args.dataset}}'\")\n    invalidInputError(args.framework in frameworks, f\"-f/--framework argument should be one of {frameworks}, but get '{{args.framework}}'\")\n    invalidInputError(args.quantize_type in quantize_types, f\"--quantize_type argument should be one of {quantize_types}, but get '{{args.quantize_type}}'\")\n    if args.quantize and 'torch' in args.inference_framework:\n        invalidInputError(args.quantize_type in quantize_torch_types, f\"if inference framework is 'torch', then --quantize_type argument should be one of {{quantize_torch_types}}, but get '{{args.quantize_type}}'\")\n    if 'onnx' in args.inference_framework:\n        args.quantize_type = 'onnxrt_qlinearops'\n    elif 'openvino' in args.inference_framework:\n        args.quantize_type = 'openvino'\n    if args.framework == 'torch':\n        import torch\n        if args.cores:\n            torch.set_num_threads(args.cores)\n        experiment(args, records)\n    elif args.cores:\n        new_experiment = spawn_new_process(experiment)\n        new_experiment(args, records, env_var={'OMP_NUM_THREADS': str(args.cores)})\n    else:\n        experiment(args, records)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = argparse.ArgumentParser(description='Benchmarking Parameters')\n    parser.add_argument('-m', '--model', type=str, default='tcn', metavar='', help='model name, choose from tcn/lstm/seq2seq/nbeats/autoformer, default to \"tcn\".')\n    parser.add_argument('-s', '--stage', type=str, default='train', metavar='', help='stage name, choose from train/latency/throughput/accuracy, default to \"train\".')\n    parser.add_argument('-d', '--dataset', type=str, default='tsinghua_electricity', metavar='', help='dataset name, choose from nyc_taxi/tsinghua_electricity/synthetic_dataset, default to \"tsinghua_electricity\".')\n    parser.add_argument('-f', '--framework', type=str, default='torch', metavar='', help='framework name, choose from torch/tensorflow, default to \"torch\".')\n    parser.add_argument('-c', '--cores', type=int, default=0, metavar='', help='core number, default to all physical cores.')\n    parser.add_argument('-l', '--lookback', type=int, metavar='lookback', required=True, help='required, the history time steps (i.e. lookback).')\n    parser.add_argument('-o', '--horizon', type=int, metavar='horizon', required=True, help='required, the output time steps (i.e. horizon).')\n    parser.add_argument('--training_processes', type=int, default=1, metavar='', help='number of processes when training, default to 1.')\n    parser.add_argument('--training_batchsize', type=int, default=32, metavar='', help='batch size when training, default to 32.')\n    parser.add_argument('--training_epochs', type=int, default=1, metavar='', help='number of epochs when training, default to 1.')\n    parser.add_argument('--inference_batchsize', type=int, default=1, metavar='', help='batch size when infering, default to 1.')\n    parser.add_argument('--quantize', action='store_true', help='if use the quantized model to predict, default to False.tensorflow will support quantize later.')\n    parser.add_argument('--inference_framework', nargs='+', default=['torch'], metavar='', help='predict without/with accelerator, choose from torch/onnx/openvino/jit, default to \"torch\" (i.e. predict without accelerator).')\n    parser.add_argument('--ipex', action='store_true', help='if use ipex as accelerator for trainer, default to False.')\n    parser.add_argument('--quantize_type', type=str, default='pytorch_fx', metavar='', help='quantize framework, choose from pytorch_fx/pytorch_ipex/onnxrt_qlinearops/openvino, default to \"pytorch_fx\".')\n    parser.add_argument('--ckpt', type=str, default='checkpoints/tcn', metavar='', help='checkpoint path of a trained model, e.g. \"checkpoints/tcn\", default to \"checkpoints/tcn\".')\n    parser.add_argument('--metrics', type=str, nargs='+', default=['mse', 'mae'], metavar='', help='evaluation metrics of a trained model, e.g. \"mse\"/\"mae\", default to \"mse, mae\".')\n    parser.add_argument('--normalization', action='store_true', help='if to use normalization trick to alleviate distribution shift.')\n    args = parser.parse_args()\n    records = vars(args)\n    models = ['tcn', 'lstm', 'seq2seq', 'nbeats', 'autoformer']\n    stages = ['train', 'latency', 'throughput', 'accuracy']\n    datasets = ['tsinghua_electricity', 'nyc_taxi', 'synthetic_dataset']\n    frameworks = ['torch', 'tensorflow']\n    quantize_types = ['pytorch_fx', 'pytorch_ipex', 'onnxrt_qlinearops', 'openvino']\n    quantize_torch_types = ['pytorch_fx', 'pytorch_ipex']\n    invalidInputError(args.model in models, f\"-m/--model argument should be one of {models}, but get '{args.model}'\")\n    invalidInputError(args.stage in stages, f\"-s/--stage argument should be one of {stages}, but get '{args.stage}'\")\n    invalidInputError(args.dataset in datasets, f\"-d/--dataset argument should be one of {datasets}, but get '{{args.dataset}}'\")\n    invalidInputError(args.framework in frameworks, f\"-f/--framework argument should be one of {frameworks}, but get '{{args.framework}}'\")\n    invalidInputError(args.quantize_type in quantize_types, f\"--quantize_type argument should be one of {quantize_types}, but get '{{args.quantize_type}}'\")\n    if args.quantize and 'torch' in args.inference_framework:\n        invalidInputError(args.quantize_type in quantize_torch_types, f\"if inference framework is 'torch', then --quantize_type argument should be one of {{quantize_torch_types}}, but get '{{args.quantize_type}}'\")\n    if 'onnx' in args.inference_framework:\n        args.quantize_type = 'onnxrt_qlinearops'\n    elif 'openvino' in args.inference_framework:\n        args.quantize_type = 'openvino'\n    if args.framework == 'torch':\n        import torch\n        if args.cores:\n            torch.set_num_threads(args.cores)\n        experiment(args, records)\n    elif args.cores:\n        new_experiment = spawn_new_process(experiment)\n        new_experiment(args, records, env_var={'OMP_NUM_THREADS': str(args.cores)})\n    else:\n        experiment(args, records)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = argparse.ArgumentParser(description='Benchmarking Parameters')\n    parser.add_argument('-m', '--model', type=str, default='tcn', metavar='', help='model name, choose from tcn/lstm/seq2seq/nbeats/autoformer, default to \"tcn\".')\n    parser.add_argument('-s', '--stage', type=str, default='train', metavar='', help='stage name, choose from train/latency/throughput/accuracy, default to \"train\".')\n    parser.add_argument('-d', '--dataset', type=str, default='tsinghua_electricity', metavar='', help='dataset name, choose from nyc_taxi/tsinghua_electricity/synthetic_dataset, default to \"tsinghua_electricity\".')\n    parser.add_argument('-f', '--framework', type=str, default='torch', metavar='', help='framework name, choose from torch/tensorflow, default to \"torch\".')\n    parser.add_argument('-c', '--cores', type=int, default=0, metavar='', help='core number, default to all physical cores.')\n    parser.add_argument('-l', '--lookback', type=int, metavar='lookback', required=True, help='required, the history time steps (i.e. lookback).')\n    parser.add_argument('-o', '--horizon', type=int, metavar='horizon', required=True, help='required, the output time steps (i.e. horizon).')\n    parser.add_argument('--training_processes', type=int, default=1, metavar='', help='number of processes when training, default to 1.')\n    parser.add_argument('--training_batchsize', type=int, default=32, metavar='', help='batch size when training, default to 32.')\n    parser.add_argument('--training_epochs', type=int, default=1, metavar='', help='number of epochs when training, default to 1.')\n    parser.add_argument('--inference_batchsize', type=int, default=1, metavar='', help='batch size when infering, default to 1.')\n    parser.add_argument('--quantize', action='store_true', help='if use the quantized model to predict, default to False.tensorflow will support quantize later.')\n    parser.add_argument('--inference_framework', nargs='+', default=['torch'], metavar='', help='predict without/with accelerator, choose from torch/onnx/openvino/jit, default to \"torch\" (i.e. predict without accelerator).')\n    parser.add_argument('--ipex', action='store_true', help='if use ipex as accelerator for trainer, default to False.')\n    parser.add_argument('--quantize_type', type=str, default='pytorch_fx', metavar='', help='quantize framework, choose from pytorch_fx/pytorch_ipex/onnxrt_qlinearops/openvino, default to \"pytorch_fx\".')\n    parser.add_argument('--ckpt', type=str, default='checkpoints/tcn', metavar='', help='checkpoint path of a trained model, e.g. \"checkpoints/tcn\", default to \"checkpoints/tcn\".')\n    parser.add_argument('--metrics', type=str, nargs='+', default=['mse', 'mae'], metavar='', help='evaluation metrics of a trained model, e.g. \"mse\"/\"mae\", default to \"mse, mae\".')\n    parser.add_argument('--normalization', action='store_true', help='if to use normalization trick to alleviate distribution shift.')\n    args = parser.parse_args()\n    records = vars(args)\n    models = ['tcn', 'lstm', 'seq2seq', 'nbeats', 'autoformer']\n    stages = ['train', 'latency', 'throughput', 'accuracy']\n    datasets = ['tsinghua_electricity', 'nyc_taxi', 'synthetic_dataset']\n    frameworks = ['torch', 'tensorflow']\n    quantize_types = ['pytorch_fx', 'pytorch_ipex', 'onnxrt_qlinearops', 'openvino']\n    quantize_torch_types = ['pytorch_fx', 'pytorch_ipex']\n    invalidInputError(args.model in models, f\"-m/--model argument should be one of {models}, but get '{args.model}'\")\n    invalidInputError(args.stage in stages, f\"-s/--stage argument should be one of {stages}, but get '{args.stage}'\")\n    invalidInputError(args.dataset in datasets, f\"-d/--dataset argument should be one of {datasets}, but get '{{args.dataset}}'\")\n    invalidInputError(args.framework in frameworks, f\"-f/--framework argument should be one of {frameworks}, but get '{{args.framework}}'\")\n    invalidInputError(args.quantize_type in quantize_types, f\"--quantize_type argument should be one of {quantize_types}, but get '{{args.quantize_type}}'\")\n    if args.quantize and 'torch' in args.inference_framework:\n        invalidInputError(args.quantize_type in quantize_torch_types, f\"if inference framework is 'torch', then --quantize_type argument should be one of {{quantize_torch_types}}, but get '{{args.quantize_type}}'\")\n    if 'onnx' in args.inference_framework:\n        args.quantize_type = 'onnxrt_qlinearops'\n    elif 'openvino' in args.inference_framework:\n        args.quantize_type = 'openvino'\n    if args.framework == 'torch':\n        import torch\n        if args.cores:\n            torch.set_num_threads(args.cores)\n        experiment(args, records)\n    elif args.cores:\n        new_experiment = spawn_new_process(experiment)\n        new_experiment(args, records, env_var={'OMP_NUM_THREADS': str(args.cores)})\n    else:\n        experiment(args, records)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = argparse.ArgumentParser(description='Benchmarking Parameters')\n    parser.add_argument('-m', '--model', type=str, default='tcn', metavar='', help='model name, choose from tcn/lstm/seq2seq/nbeats/autoformer, default to \"tcn\".')\n    parser.add_argument('-s', '--stage', type=str, default='train', metavar='', help='stage name, choose from train/latency/throughput/accuracy, default to \"train\".')\n    parser.add_argument('-d', '--dataset', type=str, default='tsinghua_electricity', metavar='', help='dataset name, choose from nyc_taxi/tsinghua_electricity/synthetic_dataset, default to \"tsinghua_electricity\".')\n    parser.add_argument('-f', '--framework', type=str, default='torch', metavar='', help='framework name, choose from torch/tensorflow, default to \"torch\".')\n    parser.add_argument('-c', '--cores', type=int, default=0, metavar='', help='core number, default to all physical cores.')\n    parser.add_argument('-l', '--lookback', type=int, metavar='lookback', required=True, help='required, the history time steps (i.e. lookback).')\n    parser.add_argument('-o', '--horizon', type=int, metavar='horizon', required=True, help='required, the output time steps (i.e. horizon).')\n    parser.add_argument('--training_processes', type=int, default=1, metavar='', help='number of processes when training, default to 1.')\n    parser.add_argument('--training_batchsize', type=int, default=32, metavar='', help='batch size when training, default to 32.')\n    parser.add_argument('--training_epochs', type=int, default=1, metavar='', help='number of epochs when training, default to 1.')\n    parser.add_argument('--inference_batchsize', type=int, default=1, metavar='', help='batch size when infering, default to 1.')\n    parser.add_argument('--quantize', action='store_true', help='if use the quantized model to predict, default to False.tensorflow will support quantize later.')\n    parser.add_argument('--inference_framework', nargs='+', default=['torch'], metavar='', help='predict without/with accelerator, choose from torch/onnx/openvino/jit, default to \"torch\" (i.e. predict without accelerator).')\n    parser.add_argument('--ipex', action='store_true', help='if use ipex as accelerator for trainer, default to False.')\n    parser.add_argument('--quantize_type', type=str, default='pytorch_fx', metavar='', help='quantize framework, choose from pytorch_fx/pytorch_ipex/onnxrt_qlinearops/openvino, default to \"pytorch_fx\".')\n    parser.add_argument('--ckpt', type=str, default='checkpoints/tcn', metavar='', help='checkpoint path of a trained model, e.g. \"checkpoints/tcn\", default to \"checkpoints/tcn\".')\n    parser.add_argument('--metrics', type=str, nargs='+', default=['mse', 'mae'], metavar='', help='evaluation metrics of a trained model, e.g. \"mse\"/\"mae\", default to \"mse, mae\".')\n    parser.add_argument('--normalization', action='store_true', help='if to use normalization trick to alleviate distribution shift.')\n    args = parser.parse_args()\n    records = vars(args)\n    models = ['tcn', 'lstm', 'seq2seq', 'nbeats', 'autoformer']\n    stages = ['train', 'latency', 'throughput', 'accuracy']\n    datasets = ['tsinghua_electricity', 'nyc_taxi', 'synthetic_dataset']\n    frameworks = ['torch', 'tensorflow']\n    quantize_types = ['pytorch_fx', 'pytorch_ipex', 'onnxrt_qlinearops', 'openvino']\n    quantize_torch_types = ['pytorch_fx', 'pytorch_ipex']\n    invalidInputError(args.model in models, f\"-m/--model argument should be one of {models}, but get '{args.model}'\")\n    invalidInputError(args.stage in stages, f\"-s/--stage argument should be one of {stages}, but get '{args.stage}'\")\n    invalidInputError(args.dataset in datasets, f\"-d/--dataset argument should be one of {datasets}, but get '{{args.dataset}}'\")\n    invalidInputError(args.framework in frameworks, f\"-f/--framework argument should be one of {frameworks}, but get '{{args.framework}}'\")\n    invalidInputError(args.quantize_type in quantize_types, f\"--quantize_type argument should be one of {quantize_types}, but get '{{args.quantize_type}}'\")\n    if args.quantize and 'torch' in args.inference_framework:\n        invalidInputError(args.quantize_type in quantize_torch_types, f\"if inference framework is 'torch', then --quantize_type argument should be one of {{quantize_torch_types}}, but get '{{args.quantize_type}}'\")\n    if 'onnx' in args.inference_framework:\n        args.quantize_type = 'onnxrt_qlinearops'\n    elif 'openvino' in args.inference_framework:\n        args.quantize_type = 'openvino'\n    if args.framework == 'torch':\n        import torch\n        if args.cores:\n            torch.set_num_threads(args.cores)\n        experiment(args, records)\n    elif args.cores:\n        new_experiment = spawn_new_process(experiment)\n        new_experiment(args, records, env_var={'OMP_NUM_THREADS': str(args.cores)})\n    else:\n        experiment(args, records)"
        ]
    }
]