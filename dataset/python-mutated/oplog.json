[
    {
        "func_name": "get_latest_ts",
        "original": "def get_latest_ts(client):\n    row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.DESCENDING)])\n    return row.get('ts')",
        "mutated": [
            "def get_latest_ts(client):\n    if False:\n        i = 10\n    row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.DESCENDING)])\n    return row.get('ts')",
            "def get_latest_ts(client):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.DESCENDING)])\n    return row.get('ts')",
            "def get_latest_ts(client):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.DESCENDING)])\n    return row.get('ts')",
            "def get_latest_ts(client):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.DESCENDING)])\n    return row.get('ts')",
            "def get_latest_ts(client):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.DESCENDING)])\n    return row.get('ts')"
        ]
    },
    {
        "func_name": "oplog_has_aged_out",
        "original": "def oplog_has_aged_out(client, state, tap_stream_id):\n    earliest_ts_row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.ASCENDING)])\n    earliest_ts = earliest_ts_row.get('ts')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    if not stream_state or not stream_state.get('oplog_ts_time'):\n        return False\n    bookmarked_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    return bookmarked_ts < earliest_ts",
        "mutated": [
            "def oplog_has_aged_out(client, state, tap_stream_id):\n    if False:\n        i = 10\n    earliest_ts_row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.ASCENDING)])\n    earliest_ts = earliest_ts_row.get('ts')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    if not stream_state or not stream_state.get('oplog_ts_time'):\n        return False\n    bookmarked_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    return bookmarked_ts < earliest_ts",
            "def oplog_has_aged_out(client, state, tap_stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    earliest_ts_row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.ASCENDING)])\n    earliest_ts = earliest_ts_row.get('ts')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    if not stream_state or not stream_state.get('oplog_ts_time'):\n        return False\n    bookmarked_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    return bookmarked_ts < earliest_ts",
            "def oplog_has_aged_out(client, state, tap_stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    earliest_ts_row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.ASCENDING)])\n    earliest_ts = earliest_ts_row.get('ts')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    if not stream_state or not stream_state.get('oplog_ts_time'):\n        return False\n    bookmarked_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    return bookmarked_ts < earliest_ts",
            "def oplog_has_aged_out(client, state, tap_stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    earliest_ts_row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.ASCENDING)])\n    earliest_ts = earliest_ts_row.get('ts')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    if not stream_state or not stream_state.get('oplog_ts_time'):\n        return False\n    bookmarked_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    return bookmarked_ts < earliest_ts",
            "def oplog_has_aged_out(client, state, tap_stream_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    earliest_ts_row = client.local.oplog.rs.find_one(sort=[('$natural', pymongo.ASCENDING)])\n    earliest_ts = earliest_ts_row.get('ts')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    if not stream_state or not stream_state.get('oplog_ts_time'):\n        return False\n    bookmarked_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    return bookmarked_ts < earliest_ts"
        ]
    },
    {
        "func_name": "update_bookmarks",
        "original": "def update_bookmarks(state, tap_stream_id, ts):\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_time', ts.time)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_inc', ts.inc)\n    return state",
        "mutated": [
            "def update_bookmarks(state, tap_stream_id, ts):\n    if False:\n        i = 10\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_time', ts.time)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_inc', ts.inc)\n    return state",
            "def update_bookmarks(state, tap_stream_id, ts):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_time', ts.time)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_inc', ts.inc)\n    return state",
            "def update_bookmarks(state, tap_stream_id, ts):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_time', ts.time)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_inc', ts.inc)\n    return state",
            "def update_bookmarks(state, tap_stream_id, ts):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_time', ts.time)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_inc', ts.inc)\n    return state",
            "def update_bookmarks(state, tap_stream_id, ts):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_time', ts.time)\n    state = singer.write_bookmark(state, tap_stream_id, 'oplog_ts_inc', ts.inc)\n    return state"
        ]
    },
    {
        "func_name": "write_schema",
        "original": "def write_schema(schema, row, stream):\n    schema_build_start_time = time.time()\n    if common.row_to_schema(schema, row):\n        singer.write_message(singer.SchemaMessage(stream=common.calculate_destination_stream_name(stream), schema=schema, key_properties=['_id']))\n        common.SCHEMA_COUNT[stream['tap_stream_id']] += 1\n    common.SCHEMA_TIMES[stream['tap_stream_id']] += time.time() - schema_build_start_time",
        "mutated": [
            "def write_schema(schema, row, stream):\n    if False:\n        i = 10\n    schema_build_start_time = time.time()\n    if common.row_to_schema(schema, row):\n        singer.write_message(singer.SchemaMessage(stream=common.calculate_destination_stream_name(stream), schema=schema, key_properties=['_id']))\n        common.SCHEMA_COUNT[stream['tap_stream_id']] += 1\n    common.SCHEMA_TIMES[stream['tap_stream_id']] += time.time() - schema_build_start_time",
            "def write_schema(schema, row, stream):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    schema_build_start_time = time.time()\n    if common.row_to_schema(schema, row):\n        singer.write_message(singer.SchemaMessage(stream=common.calculate_destination_stream_name(stream), schema=schema, key_properties=['_id']))\n        common.SCHEMA_COUNT[stream['tap_stream_id']] += 1\n    common.SCHEMA_TIMES[stream['tap_stream_id']] += time.time() - schema_build_start_time",
            "def write_schema(schema, row, stream):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    schema_build_start_time = time.time()\n    if common.row_to_schema(schema, row):\n        singer.write_message(singer.SchemaMessage(stream=common.calculate_destination_stream_name(stream), schema=schema, key_properties=['_id']))\n        common.SCHEMA_COUNT[stream['tap_stream_id']] += 1\n    common.SCHEMA_TIMES[stream['tap_stream_id']] += time.time() - schema_build_start_time",
            "def write_schema(schema, row, stream):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    schema_build_start_time = time.time()\n    if common.row_to_schema(schema, row):\n        singer.write_message(singer.SchemaMessage(stream=common.calculate_destination_stream_name(stream), schema=schema, key_properties=['_id']))\n        common.SCHEMA_COUNT[stream['tap_stream_id']] += 1\n    common.SCHEMA_TIMES[stream['tap_stream_id']] += time.time() - schema_build_start_time",
            "def write_schema(schema, row, stream):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    schema_build_start_time = time.time()\n    if common.row_to_schema(schema, row):\n        singer.write_message(singer.SchemaMessage(stream=common.calculate_destination_stream_name(stream), schema=schema, key_properties=['_id']))\n        common.SCHEMA_COUNT[stream['tap_stream_id']] += 1\n    common.SCHEMA_TIMES[stream['tap_stream_id']] += time.time() - schema_build_start_time"
        ]
    },
    {
        "func_name": "transform_projection",
        "original": "def transform_projection(projection):\n    base_projection = {'ts': 1, 'ns': 1, 'op': 1, 'o2': 1}\n    new_projection = {}\n    if projection is None:\n        new_projection = base_projection\n        new_projection['o'] = 1\n        return new_projection\n    temp_projection = {k: v for (k, v) in projection.items() if k != '_id'}\n    is_whitelist = sum([v for (k, v) in temp_projection.items()]) > 0\n    if not temp_projection:\n        new_projection = base_projection\n        new_projection['o._id'] = 1\n        return new_projection\n    if is_whitelist:\n        new_projection = base_projection\n        for (field, value) in temp_projection.items():\n            new_projection['o.' + field] = value\n        new_projection['o._id'] = 1\n        return new_projection\n    for (field, value) in temp_projection.items():\n        new_projection['o.' + field] = value\n    return new_projection",
        "mutated": [
            "def transform_projection(projection):\n    if False:\n        i = 10\n    base_projection = {'ts': 1, 'ns': 1, 'op': 1, 'o2': 1}\n    new_projection = {}\n    if projection is None:\n        new_projection = base_projection\n        new_projection['o'] = 1\n        return new_projection\n    temp_projection = {k: v for (k, v) in projection.items() if k != '_id'}\n    is_whitelist = sum([v for (k, v) in temp_projection.items()]) > 0\n    if not temp_projection:\n        new_projection = base_projection\n        new_projection['o._id'] = 1\n        return new_projection\n    if is_whitelist:\n        new_projection = base_projection\n        for (field, value) in temp_projection.items():\n            new_projection['o.' + field] = value\n        new_projection['o._id'] = 1\n        return new_projection\n    for (field, value) in temp_projection.items():\n        new_projection['o.' + field] = value\n    return new_projection",
            "def transform_projection(projection):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    base_projection = {'ts': 1, 'ns': 1, 'op': 1, 'o2': 1}\n    new_projection = {}\n    if projection is None:\n        new_projection = base_projection\n        new_projection['o'] = 1\n        return new_projection\n    temp_projection = {k: v for (k, v) in projection.items() if k != '_id'}\n    is_whitelist = sum([v for (k, v) in temp_projection.items()]) > 0\n    if not temp_projection:\n        new_projection = base_projection\n        new_projection['o._id'] = 1\n        return new_projection\n    if is_whitelist:\n        new_projection = base_projection\n        for (field, value) in temp_projection.items():\n            new_projection['o.' + field] = value\n        new_projection['o._id'] = 1\n        return new_projection\n    for (field, value) in temp_projection.items():\n        new_projection['o.' + field] = value\n    return new_projection",
            "def transform_projection(projection):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    base_projection = {'ts': 1, 'ns': 1, 'op': 1, 'o2': 1}\n    new_projection = {}\n    if projection is None:\n        new_projection = base_projection\n        new_projection['o'] = 1\n        return new_projection\n    temp_projection = {k: v for (k, v) in projection.items() if k != '_id'}\n    is_whitelist = sum([v for (k, v) in temp_projection.items()]) > 0\n    if not temp_projection:\n        new_projection = base_projection\n        new_projection['o._id'] = 1\n        return new_projection\n    if is_whitelist:\n        new_projection = base_projection\n        for (field, value) in temp_projection.items():\n            new_projection['o.' + field] = value\n        new_projection['o._id'] = 1\n        return new_projection\n    for (field, value) in temp_projection.items():\n        new_projection['o.' + field] = value\n    return new_projection",
            "def transform_projection(projection):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    base_projection = {'ts': 1, 'ns': 1, 'op': 1, 'o2': 1}\n    new_projection = {}\n    if projection is None:\n        new_projection = base_projection\n        new_projection['o'] = 1\n        return new_projection\n    temp_projection = {k: v for (k, v) in projection.items() if k != '_id'}\n    is_whitelist = sum([v for (k, v) in temp_projection.items()]) > 0\n    if not temp_projection:\n        new_projection = base_projection\n        new_projection['o._id'] = 1\n        return new_projection\n    if is_whitelist:\n        new_projection = base_projection\n        for (field, value) in temp_projection.items():\n            new_projection['o.' + field] = value\n        new_projection['o._id'] = 1\n        return new_projection\n    for (field, value) in temp_projection.items():\n        new_projection['o.' + field] = value\n    return new_projection",
            "def transform_projection(projection):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    base_projection = {'ts': 1, 'ns': 1, 'op': 1, 'o2': 1}\n    new_projection = {}\n    if projection is None:\n        new_projection = base_projection\n        new_projection['o'] = 1\n        return new_projection\n    temp_projection = {k: v for (k, v) in projection.items() if k != '_id'}\n    is_whitelist = sum([v for (k, v) in temp_projection.items()]) > 0\n    if not temp_projection:\n        new_projection = base_projection\n        new_projection['o._id'] = 1\n        return new_projection\n    if is_whitelist:\n        new_projection = base_projection\n        for (field, value) in temp_projection.items():\n            new_projection['o.' + field] = value\n        new_projection['o._id'] = 1\n        return new_projection\n    for (field, value) in temp_projection.items():\n        new_projection['o.' + field] = value\n    return new_projection"
        ]
    },
    {
        "func_name": "flush_buffer",
        "original": "def flush_buffer(client, update_buffer, stream_projection, db_name, collection_name):\n    query = {'_id': {'$in': list(update_buffer)}}\n    with client[db_name][collection_name].find(query, stream_projection) as cursor:\n        for row in cursor:\n            yield row",
        "mutated": [
            "def flush_buffer(client, update_buffer, stream_projection, db_name, collection_name):\n    if False:\n        i = 10\n    query = {'_id': {'$in': list(update_buffer)}}\n    with client[db_name][collection_name].find(query, stream_projection) as cursor:\n        for row in cursor:\n            yield row",
            "def flush_buffer(client, update_buffer, stream_projection, db_name, collection_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    query = {'_id': {'$in': list(update_buffer)}}\n    with client[db_name][collection_name].find(query, stream_projection) as cursor:\n        for row in cursor:\n            yield row",
            "def flush_buffer(client, update_buffer, stream_projection, db_name, collection_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    query = {'_id': {'$in': list(update_buffer)}}\n    with client[db_name][collection_name].find(query, stream_projection) as cursor:\n        for row in cursor:\n            yield row",
            "def flush_buffer(client, update_buffer, stream_projection, db_name, collection_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    query = {'_id': {'$in': list(update_buffer)}}\n    with client[db_name][collection_name].find(query, stream_projection) as cursor:\n        for row in cursor:\n            yield row",
            "def flush_buffer(client, update_buffer, stream_projection, db_name, collection_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    query = {'_id': {'$in': list(update_buffer)}}\n    with client[db_name][collection_name].find(query, stream_projection) as cursor:\n        for row in cursor:\n            yield row"
        ]
    },
    {
        "func_name": "sync_collection",
        "original": "def sync_collection(client, stream, state, stream_projection, logger=None, max_oplog_ts=None):\n    if logger is None:\n        logger = LOGGER\n    tap_stream_id = stream['tap_stream_id']\n    logger.info(f'Starting oplog sync for {tap_stream_id}')\n    md_map = metadata.to_map(stream['metadata'])\n    database_name = metadata.get(md_map, (), 'database-name')\n    collection_name = stream.get('table_name')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    oplog_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    version = common.get_stream_version(tap_stream_id, state)\n    activate_version_message = singer.ActivateVersionMessage(stream=common.calculate_destination_stream_name(stream), version=version)\n    singer.write_message(activate_version_message)\n    time_extracted = utils.now()\n    rows_saved = 0\n    start_time = time.time()\n    oplog_query = {'ts': {'$gte': oplog_ts}, 'ns': {'$eq': '{}.{}'.format(database_name, collection_name)}}\n    projection = transform_projection(stream_projection)\n    oplog_replay = stream_projection is None\n    logger.info(f'Querying {tap_stream_id} with:\\n\\tFind Parameters: {oplog_query}\\n\\tProjection: {projection}\\n\\toplog_replay: {oplog_replay}')\n    update_buffer = set()\n    schema = {'type': 'object', 'properties': {}}\n    with client.local.oplog.rs.find(oplog_query, projection, sort=[('$natural', pymongo.ASCENDING)], oplog_replay=oplog_replay) as cursor:\n        for row in cursor:\n            if row.get('ts') and row.get('ts') < oplog_ts:\n                raise common.MongoAssertionException('Mongo is not honoring the query param')\n            if row.get('ts') and row.get('ts') < timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc']):\n                raise common.MongoAssertionException('Mongo is not honoring the sort ascending param')\n            row_op = row['op']\n            if row_op == 'i':\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            elif row_op == 'u':\n                update_buffer.add(row['o2']['_id'])\n            elif row_op == 'd':\n                if row['o']['_id'] in update_buffer:\n                    update_buffer.remove(row['o']['_id'])\n                row['o'][SDC_DELETED_AT] = row['ts']\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            state = update_bookmarks(state, tap_stream_id, row['ts'])\n            if len(update_buffer) >= MAX_UPDATE_BUFFER_LENGTH:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n            if rows_saved % common.UPDATE_BOOKMARK_PERIOD == 0:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n                singer.write_message(singer.StateMessage(value=state))\n        for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n            write_schema(schema, buffered_row, stream)\n            record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n            singer.write_message(record_message)\n            rows_saved += 1\n    bookmarked_ts = timestamp.Timestamp(state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_time'), state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_inc'))\n    actual_max_ts = max(bookmarked_ts, max_oplog_ts)\n    state = update_bookmarks(state, tap_stream_id, actual_max_ts)\n    singer.write_message(singer.StateMessage(value=state))\n    common.COUNTS[tap_stream_id] += rows_saved\n    common.TIMES[tap_stream_id] += time.time() - start_time\n    logger.info('Synced %s records for %s', rows_saved, tap_stream_id)",
        "mutated": [
            "def sync_collection(client, stream, state, stream_projection, logger=None, max_oplog_ts=None):\n    if False:\n        i = 10\n    if logger is None:\n        logger = LOGGER\n    tap_stream_id = stream['tap_stream_id']\n    logger.info(f'Starting oplog sync for {tap_stream_id}')\n    md_map = metadata.to_map(stream['metadata'])\n    database_name = metadata.get(md_map, (), 'database-name')\n    collection_name = stream.get('table_name')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    oplog_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    version = common.get_stream_version(tap_stream_id, state)\n    activate_version_message = singer.ActivateVersionMessage(stream=common.calculate_destination_stream_name(stream), version=version)\n    singer.write_message(activate_version_message)\n    time_extracted = utils.now()\n    rows_saved = 0\n    start_time = time.time()\n    oplog_query = {'ts': {'$gte': oplog_ts}, 'ns': {'$eq': '{}.{}'.format(database_name, collection_name)}}\n    projection = transform_projection(stream_projection)\n    oplog_replay = stream_projection is None\n    logger.info(f'Querying {tap_stream_id} with:\\n\\tFind Parameters: {oplog_query}\\n\\tProjection: {projection}\\n\\toplog_replay: {oplog_replay}')\n    update_buffer = set()\n    schema = {'type': 'object', 'properties': {}}\n    with client.local.oplog.rs.find(oplog_query, projection, sort=[('$natural', pymongo.ASCENDING)], oplog_replay=oplog_replay) as cursor:\n        for row in cursor:\n            if row.get('ts') and row.get('ts') < oplog_ts:\n                raise common.MongoAssertionException('Mongo is not honoring the query param')\n            if row.get('ts') and row.get('ts') < timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc']):\n                raise common.MongoAssertionException('Mongo is not honoring the sort ascending param')\n            row_op = row['op']\n            if row_op == 'i':\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            elif row_op == 'u':\n                update_buffer.add(row['o2']['_id'])\n            elif row_op == 'd':\n                if row['o']['_id'] in update_buffer:\n                    update_buffer.remove(row['o']['_id'])\n                row['o'][SDC_DELETED_AT] = row['ts']\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            state = update_bookmarks(state, tap_stream_id, row['ts'])\n            if len(update_buffer) >= MAX_UPDATE_BUFFER_LENGTH:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n            if rows_saved % common.UPDATE_BOOKMARK_PERIOD == 0:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n                singer.write_message(singer.StateMessage(value=state))\n        for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n            write_schema(schema, buffered_row, stream)\n            record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n            singer.write_message(record_message)\n            rows_saved += 1\n    bookmarked_ts = timestamp.Timestamp(state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_time'), state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_inc'))\n    actual_max_ts = max(bookmarked_ts, max_oplog_ts)\n    state = update_bookmarks(state, tap_stream_id, actual_max_ts)\n    singer.write_message(singer.StateMessage(value=state))\n    common.COUNTS[tap_stream_id] += rows_saved\n    common.TIMES[tap_stream_id] += time.time() - start_time\n    logger.info('Synced %s records for %s', rows_saved, tap_stream_id)",
            "def sync_collection(client, stream, state, stream_projection, logger=None, max_oplog_ts=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if logger is None:\n        logger = LOGGER\n    tap_stream_id = stream['tap_stream_id']\n    logger.info(f'Starting oplog sync for {tap_stream_id}')\n    md_map = metadata.to_map(stream['metadata'])\n    database_name = metadata.get(md_map, (), 'database-name')\n    collection_name = stream.get('table_name')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    oplog_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    version = common.get_stream_version(tap_stream_id, state)\n    activate_version_message = singer.ActivateVersionMessage(stream=common.calculate_destination_stream_name(stream), version=version)\n    singer.write_message(activate_version_message)\n    time_extracted = utils.now()\n    rows_saved = 0\n    start_time = time.time()\n    oplog_query = {'ts': {'$gte': oplog_ts}, 'ns': {'$eq': '{}.{}'.format(database_name, collection_name)}}\n    projection = transform_projection(stream_projection)\n    oplog_replay = stream_projection is None\n    logger.info(f'Querying {tap_stream_id} with:\\n\\tFind Parameters: {oplog_query}\\n\\tProjection: {projection}\\n\\toplog_replay: {oplog_replay}')\n    update_buffer = set()\n    schema = {'type': 'object', 'properties': {}}\n    with client.local.oplog.rs.find(oplog_query, projection, sort=[('$natural', pymongo.ASCENDING)], oplog_replay=oplog_replay) as cursor:\n        for row in cursor:\n            if row.get('ts') and row.get('ts') < oplog_ts:\n                raise common.MongoAssertionException('Mongo is not honoring the query param')\n            if row.get('ts') and row.get('ts') < timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc']):\n                raise common.MongoAssertionException('Mongo is not honoring the sort ascending param')\n            row_op = row['op']\n            if row_op == 'i':\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            elif row_op == 'u':\n                update_buffer.add(row['o2']['_id'])\n            elif row_op == 'd':\n                if row['o']['_id'] in update_buffer:\n                    update_buffer.remove(row['o']['_id'])\n                row['o'][SDC_DELETED_AT] = row['ts']\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            state = update_bookmarks(state, tap_stream_id, row['ts'])\n            if len(update_buffer) >= MAX_UPDATE_BUFFER_LENGTH:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n            if rows_saved % common.UPDATE_BOOKMARK_PERIOD == 0:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n                singer.write_message(singer.StateMessage(value=state))\n        for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n            write_schema(schema, buffered_row, stream)\n            record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n            singer.write_message(record_message)\n            rows_saved += 1\n    bookmarked_ts = timestamp.Timestamp(state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_time'), state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_inc'))\n    actual_max_ts = max(bookmarked_ts, max_oplog_ts)\n    state = update_bookmarks(state, tap_stream_id, actual_max_ts)\n    singer.write_message(singer.StateMessage(value=state))\n    common.COUNTS[tap_stream_id] += rows_saved\n    common.TIMES[tap_stream_id] += time.time() - start_time\n    logger.info('Synced %s records for %s', rows_saved, tap_stream_id)",
            "def sync_collection(client, stream, state, stream_projection, logger=None, max_oplog_ts=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if logger is None:\n        logger = LOGGER\n    tap_stream_id = stream['tap_stream_id']\n    logger.info(f'Starting oplog sync for {tap_stream_id}')\n    md_map = metadata.to_map(stream['metadata'])\n    database_name = metadata.get(md_map, (), 'database-name')\n    collection_name = stream.get('table_name')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    oplog_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    version = common.get_stream_version(tap_stream_id, state)\n    activate_version_message = singer.ActivateVersionMessage(stream=common.calculate_destination_stream_name(stream), version=version)\n    singer.write_message(activate_version_message)\n    time_extracted = utils.now()\n    rows_saved = 0\n    start_time = time.time()\n    oplog_query = {'ts': {'$gte': oplog_ts}, 'ns': {'$eq': '{}.{}'.format(database_name, collection_name)}}\n    projection = transform_projection(stream_projection)\n    oplog_replay = stream_projection is None\n    logger.info(f'Querying {tap_stream_id} with:\\n\\tFind Parameters: {oplog_query}\\n\\tProjection: {projection}\\n\\toplog_replay: {oplog_replay}')\n    update_buffer = set()\n    schema = {'type': 'object', 'properties': {}}\n    with client.local.oplog.rs.find(oplog_query, projection, sort=[('$natural', pymongo.ASCENDING)], oplog_replay=oplog_replay) as cursor:\n        for row in cursor:\n            if row.get('ts') and row.get('ts') < oplog_ts:\n                raise common.MongoAssertionException('Mongo is not honoring the query param')\n            if row.get('ts') and row.get('ts') < timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc']):\n                raise common.MongoAssertionException('Mongo is not honoring the sort ascending param')\n            row_op = row['op']\n            if row_op == 'i':\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            elif row_op == 'u':\n                update_buffer.add(row['o2']['_id'])\n            elif row_op == 'd':\n                if row['o']['_id'] in update_buffer:\n                    update_buffer.remove(row['o']['_id'])\n                row['o'][SDC_DELETED_AT] = row['ts']\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            state = update_bookmarks(state, tap_stream_id, row['ts'])\n            if len(update_buffer) >= MAX_UPDATE_BUFFER_LENGTH:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n            if rows_saved % common.UPDATE_BOOKMARK_PERIOD == 0:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n                singer.write_message(singer.StateMessage(value=state))\n        for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n            write_schema(schema, buffered_row, stream)\n            record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n            singer.write_message(record_message)\n            rows_saved += 1\n    bookmarked_ts = timestamp.Timestamp(state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_time'), state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_inc'))\n    actual_max_ts = max(bookmarked_ts, max_oplog_ts)\n    state = update_bookmarks(state, tap_stream_id, actual_max_ts)\n    singer.write_message(singer.StateMessage(value=state))\n    common.COUNTS[tap_stream_id] += rows_saved\n    common.TIMES[tap_stream_id] += time.time() - start_time\n    logger.info('Synced %s records for %s', rows_saved, tap_stream_id)",
            "def sync_collection(client, stream, state, stream_projection, logger=None, max_oplog_ts=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if logger is None:\n        logger = LOGGER\n    tap_stream_id = stream['tap_stream_id']\n    logger.info(f'Starting oplog sync for {tap_stream_id}')\n    md_map = metadata.to_map(stream['metadata'])\n    database_name = metadata.get(md_map, (), 'database-name')\n    collection_name = stream.get('table_name')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    oplog_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    version = common.get_stream_version(tap_stream_id, state)\n    activate_version_message = singer.ActivateVersionMessage(stream=common.calculate_destination_stream_name(stream), version=version)\n    singer.write_message(activate_version_message)\n    time_extracted = utils.now()\n    rows_saved = 0\n    start_time = time.time()\n    oplog_query = {'ts': {'$gte': oplog_ts}, 'ns': {'$eq': '{}.{}'.format(database_name, collection_name)}}\n    projection = transform_projection(stream_projection)\n    oplog_replay = stream_projection is None\n    logger.info(f'Querying {tap_stream_id} with:\\n\\tFind Parameters: {oplog_query}\\n\\tProjection: {projection}\\n\\toplog_replay: {oplog_replay}')\n    update_buffer = set()\n    schema = {'type': 'object', 'properties': {}}\n    with client.local.oplog.rs.find(oplog_query, projection, sort=[('$natural', pymongo.ASCENDING)], oplog_replay=oplog_replay) as cursor:\n        for row in cursor:\n            if row.get('ts') and row.get('ts') < oplog_ts:\n                raise common.MongoAssertionException('Mongo is not honoring the query param')\n            if row.get('ts') and row.get('ts') < timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc']):\n                raise common.MongoAssertionException('Mongo is not honoring the sort ascending param')\n            row_op = row['op']\n            if row_op == 'i':\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            elif row_op == 'u':\n                update_buffer.add(row['o2']['_id'])\n            elif row_op == 'd':\n                if row['o']['_id'] in update_buffer:\n                    update_buffer.remove(row['o']['_id'])\n                row['o'][SDC_DELETED_AT] = row['ts']\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            state = update_bookmarks(state, tap_stream_id, row['ts'])\n            if len(update_buffer) >= MAX_UPDATE_BUFFER_LENGTH:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n            if rows_saved % common.UPDATE_BOOKMARK_PERIOD == 0:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n                singer.write_message(singer.StateMessage(value=state))\n        for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n            write_schema(schema, buffered_row, stream)\n            record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n            singer.write_message(record_message)\n            rows_saved += 1\n    bookmarked_ts = timestamp.Timestamp(state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_time'), state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_inc'))\n    actual_max_ts = max(bookmarked_ts, max_oplog_ts)\n    state = update_bookmarks(state, tap_stream_id, actual_max_ts)\n    singer.write_message(singer.StateMessage(value=state))\n    common.COUNTS[tap_stream_id] += rows_saved\n    common.TIMES[tap_stream_id] += time.time() - start_time\n    logger.info('Synced %s records for %s', rows_saved, tap_stream_id)",
            "def sync_collection(client, stream, state, stream_projection, logger=None, max_oplog_ts=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if logger is None:\n        logger = LOGGER\n    tap_stream_id = stream['tap_stream_id']\n    logger.info(f'Starting oplog sync for {tap_stream_id}')\n    md_map = metadata.to_map(stream['metadata'])\n    database_name = metadata.get(md_map, (), 'database-name')\n    collection_name = stream.get('table_name')\n    stream_state = state.get('bookmarks', {}).get(tap_stream_id)\n    oplog_ts = timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc'])\n    version = common.get_stream_version(tap_stream_id, state)\n    activate_version_message = singer.ActivateVersionMessage(stream=common.calculate_destination_stream_name(stream), version=version)\n    singer.write_message(activate_version_message)\n    time_extracted = utils.now()\n    rows_saved = 0\n    start_time = time.time()\n    oplog_query = {'ts': {'$gte': oplog_ts}, 'ns': {'$eq': '{}.{}'.format(database_name, collection_name)}}\n    projection = transform_projection(stream_projection)\n    oplog_replay = stream_projection is None\n    logger.info(f'Querying {tap_stream_id} with:\\n\\tFind Parameters: {oplog_query}\\n\\tProjection: {projection}\\n\\toplog_replay: {oplog_replay}')\n    update_buffer = set()\n    schema = {'type': 'object', 'properties': {}}\n    with client.local.oplog.rs.find(oplog_query, projection, sort=[('$natural', pymongo.ASCENDING)], oplog_replay=oplog_replay) as cursor:\n        for row in cursor:\n            if row.get('ts') and row.get('ts') < oplog_ts:\n                raise common.MongoAssertionException('Mongo is not honoring the query param')\n            if row.get('ts') and row.get('ts') < timestamp.Timestamp(stream_state['oplog_ts_time'], stream_state['oplog_ts_inc']):\n                raise common.MongoAssertionException('Mongo is not honoring the sort ascending param')\n            row_op = row['op']\n            if row_op == 'i':\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            elif row_op == 'u':\n                update_buffer.add(row['o2']['_id'])\n            elif row_op == 'd':\n                if row['o']['_id'] in update_buffer:\n                    update_buffer.remove(row['o']['_id'])\n                row['o'][SDC_DELETED_AT] = row['ts']\n                write_schema(schema, row['o'], stream)\n                record_message = common.row_to_singer_record(stream, row['o'], version, time_extracted)\n                singer.write_message(record_message)\n                rows_saved += 1\n            state = update_bookmarks(state, tap_stream_id, row['ts'])\n            if len(update_buffer) >= MAX_UPDATE_BUFFER_LENGTH:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n            if rows_saved % common.UPDATE_BOOKMARK_PERIOD == 0:\n                for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n                    write_schema(schema, buffered_row, stream)\n                    record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n                    singer.write_message(record_message)\n                    rows_saved += 1\n                update_buffer = set()\n                singer.write_message(singer.StateMessage(value=state))\n        for buffered_row in flush_buffer(client, update_buffer, stream_projection, database_name, collection_name):\n            write_schema(schema, buffered_row, stream)\n            record_message = common.row_to_singer_record(stream, buffered_row, version, time_extracted)\n            singer.write_message(record_message)\n            rows_saved += 1\n    bookmarked_ts = timestamp.Timestamp(state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_time'), state.get('bookmarks', {}).get(tap_stream_id, {}).get('oplog_ts_inc'))\n    actual_max_ts = max(bookmarked_ts, max_oplog_ts)\n    state = update_bookmarks(state, tap_stream_id, actual_max_ts)\n    singer.write_message(singer.StateMessage(value=state))\n    common.COUNTS[tap_stream_id] += rows_saved\n    common.TIMES[tap_stream_id] += time.time() - start_time\n    logger.info('Synced %s records for %s', rows_saved, tap_stream_id)"
        ]
    }
]