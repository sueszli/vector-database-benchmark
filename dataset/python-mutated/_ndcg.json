[
    {
        "func_name": "dcg",
        "original": "def dcg(outputs: torch.Tensor, targets: torch.Tensor, gain_function='exp_rank') -> torch.Tensor:\n    \"\"\"\n    Computes Discounted cumulative gain (DCG)\n    DCG@topk for the specified values of `k`.\n    Graded relevance as a measure of  usefulness,\n    or gain, from examining a set of items.\n    Gain may be reduced at lower ranks.\n    Reference:\n    https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n\n    Args:\n        outputs: model outputs, logits\n            with shape [batch_size; slate_length]\n        targets: ground truth, labels\n            with shape [batch_size; slate_length]\n        gain_function:\n            String indicates the gain function for the ground truth labels.\n            Two options available:\n            - `exp_rank`: torch.pow(2, x) - 1\n            - `linear_rank`: x\n            On the default, `exp_rank` is used\n            to emphasize on retrieving the relevant documents.\n\n    Returns:\n        dcg_score (torch.Tensor):\n            The discounted gains tensor\n\n    Raises:\n        ValueError: gain function can be either `pow_rank` or `rank`\n\n    Examples:\n\n    .. code-block:: python\n\n        from catalyst import metrics\n        metrics.dcg(\n            outputs = torch.tensor([\n                [3, 2, 1, 0],\n            ]),\n            targets = torch.Tensor([\n                [2.0, 2.0, 1.0, 0.0],\n            ]),\n            gain_function=\"linear_rank\",\n        )\n        # tensor([[2.0000, 2.0000, 0.6309, 0.0000]])\n\n    .. code-block:: python\n\n        from catalyst import metrics\n        metrics.dcg(\n            outputs = torch.tensor([\n                [3, 2, 1, 0],\n            ]),\n            targets = torch.Tensor([\n                [2.0, 2.0, 1.0, 0.0],\n            ]),\n            gain_function=\"linear_rank\",\n        ).sum()\n        # tensor(4.6309)\n\n    .. code-block:: python\n\n        from catalyst import metrics\n        metrics.dcg(\n            outputs = torch.tensor([\n                [3, 2, 1, 0],\n            ]),\n            targets = torch.Tensor([\n                [2.0, 2.0, 1.0, 0.0],\n            ]),\n            gain_function=\"exp_rank\",\n        )\n        # tensor([[3.0000, 1.8928, 0.5000, 0.0000]])\n\n    .. code-block:: python\n\n        from catalyst import metrics\n        metrics.dcg(\n            outputs = torch.tensor([\n                [3, 2, 1, 0],\n            ]),\n            targets = torch.Tensor([\n                [2.0, 2.0, 1.0, 0.0],\n            ]),\n            gain_function=\"exp_rank\",\n        ).sum()\n        # tensor(5.3928)\n    \"\"\"\n    targets_sort_by_outputs = process_recsys_components(outputs, targets)\n    target_device = targets_sort_by_outputs.device\n    if gain_function == 'exp_rank':\n        gain_function = lambda x: torch.pow(2, x) - 1\n        gains = gain_function(targets_sort_by_outputs)\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 2.0)\n        discounted_gains = gains * discounts\n    elif gain_function == 'linear_rank':\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 1.0)\n        discounts[0] = 1\n        discounted_gains = targets_sort_by_outputs * discounts\n    else:\n        raise ValueError('gain function can be either exp_rank or linear_rank')\n    dcg_score = discounted_gains\n    return dcg_score",
        "mutated": [
            "def dcg(outputs: torch.Tensor, targets: torch.Tensor, gain_function='exp_rank') -> torch.Tensor:\n    if False:\n        i = 10\n    '\\n    Computes Discounted cumulative gain (DCG)\\n    DCG@topk for the specified values of `k`.\\n    Graded relevance as a measure of  usefulness,\\n    or gain, from examining a set of items.\\n    Gain may be reduced at lower ranks.\\n    Reference:\\n    https://en.wikipedia.org/wiki/Discounted_cumulative_gain\\n\\n    Args:\\n        outputs: model outputs, logits\\n            with shape [batch_size; slate_length]\\n        targets: ground truth, labels\\n            with shape [batch_size; slate_length]\\n        gain_function:\\n            String indicates the gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n\\n    Returns:\\n        dcg_score (torch.Tensor):\\n            The discounted gains tensor\\n\\n    Raises:\\n        ValueError: gain function can be either `pow_rank` or `rank`\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        )\\n        # tensor([[2.0000, 2.0000, 0.6309, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        ).sum()\\n        # tensor(4.6309)\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        )\\n        # tensor([[3.0000, 1.8928, 0.5000, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        ).sum()\\n        # tensor(5.3928)\\n    '\n    targets_sort_by_outputs = process_recsys_components(outputs, targets)\n    target_device = targets_sort_by_outputs.device\n    if gain_function == 'exp_rank':\n        gain_function = lambda x: torch.pow(2, x) - 1\n        gains = gain_function(targets_sort_by_outputs)\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 2.0)\n        discounted_gains = gains * discounts\n    elif gain_function == 'linear_rank':\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 1.0)\n        discounts[0] = 1\n        discounted_gains = targets_sort_by_outputs * discounts\n    else:\n        raise ValueError('gain function can be either exp_rank or linear_rank')\n    dcg_score = discounted_gains\n    return dcg_score",
            "def dcg(outputs: torch.Tensor, targets: torch.Tensor, gain_function='exp_rank') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Computes Discounted cumulative gain (DCG)\\n    DCG@topk for the specified values of `k`.\\n    Graded relevance as a measure of  usefulness,\\n    or gain, from examining a set of items.\\n    Gain may be reduced at lower ranks.\\n    Reference:\\n    https://en.wikipedia.org/wiki/Discounted_cumulative_gain\\n\\n    Args:\\n        outputs: model outputs, logits\\n            with shape [batch_size; slate_length]\\n        targets: ground truth, labels\\n            with shape [batch_size; slate_length]\\n        gain_function:\\n            String indicates the gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n\\n    Returns:\\n        dcg_score (torch.Tensor):\\n            The discounted gains tensor\\n\\n    Raises:\\n        ValueError: gain function can be either `pow_rank` or `rank`\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        )\\n        # tensor([[2.0000, 2.0000, 0.6309, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        ).sum()\\n        # tensor(4.6309)\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        )\\n        # tensor([[3.0000, 1.8928, 0.5000, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        ).sum()\\n        # tensor(5.3928)\\n    '\n    targets_sort_by_outputs = process_recsys_components(outputs, targets)\n    target_device = targets_sort_by_outputs.device\n    if gain_function == 'exp_rank':\n        gain_function = lambda x: torch.pow(2, x) - 1\n        gains = gain_function(targets_sort_by_outputs)\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 2.0)\n        discounted_gains = gains * discounts\n    elif gain_function == 'linear_rank':\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 1.0)\n        discounts[0] = 1\n        discounted_gains = targets_sort_by_outputs * discounts\n    else:\n        raise ValueError('gain function can be either exp_rank or linear_rank')\n    dcg_score = discounted_gains\n    return dcg_score",
            "def dcg(outputs: torch.Tensor, targets: torch.Tensor, gain_function='exp_rank') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Computes Discounted cumulative gain (DCG)\\n    DCG@topk for the specified values of `k`.\\n    Graded relevance as a measure of  usefulness,\\n    or gain, from examining a set of items.\\n    Gain may be reduced at lower ranks.\\n    Reference:\\n    https://en.wikipedia.org/wiki/Discounted_cumulative_gain\\n\\n    Args:\\n        outputs: model outputs, logits\\n            with shape [batch_size; slate_length]\\n        targets: ground truth, labels\\n            with shape [batch_size; slate_length]\\n        gain_function:\\n            String indicates the gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n\\n    Returns:\\n        dcg_score (torch.Tensor):\\n            The discounted gains tensor\\n\\n    Raises:\\n        ValueError: gain function can be either `pow_rank` or `rank`\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        )\\n        # tensor([[2.0000, 2.0000, 0.6309, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        ).sum()\\n        # tensor(4.6309)\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        )\\n        # tensor([[3.0000, 1.8928, 0.5000, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        ).sum()\\n        # tensor(5.3928)\\n    '\n    targets_sort_by_outputs = process_recsys_components(outputs, targets)\n    target_device = targets_sort_by_outputs.device\n    if gain_function == 'exp_rank':\n        gain_function = lambda x: torch.pow(2, x) - 1\n        gains = gain_function(targets_sort_by_outputs)\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 2.0)\n        discounted_gains = gains * discounts\n    elif gain_function == 'linear_rank':\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 1.0)\n        discounts[0] = 1\n        discounted_gains = targets_sort_by_outputs * discounts\n    else:\n        raise ValueError('gain function can be either exp_rank or linear_rank')\n    dcg_score = discounted_gains\n    return dcg_score",
            "def dcg(outputs: torch.Tensor, targets: torch.Tensor, gain_function='exp_rank') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Computes Discounted cumulative gain (DCG)\\n    DCG@topk for the specified values of `k`.\\n    Graded relevance as a measure of  usefulness,\\n    or gain, from examining a set of items.\\n    Gain may be reduced at lower ranks.\\n    Reference:\\n    https://en.wikipedia.org/wiki/Discounted_cumulative_gain\\n\\n    Args:\\n        outputs: model outputs, logits\\n            with shape [batch_size; slate_length]\\n        targets: ground truth, labels\\n            with shape [batch_size; slate_length]\\n        gain_function:\\n            String indicates the gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n\\n    Returns:\\n        dcg_score (torch.Tensor):\\n            The discounted gains tensor\\n\\n    Raises:\\n        ValueError: gain function can be either `pow_rank` or `rank`\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        )\\n        # tensor([[2.0000, 2.0000, 0.6309, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        ).sum()\\n        # tensor(4.6309)\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        )\\n        # tensor([[3.0000, 1.8928, 0.5000, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        ).sum()\\n        # tensor(5.3928)\\n    '\n    targets_sort_by_outputs = process_recsys_components(outputs, targets)\n    target_device = targets_sort_by_outputs.device\n    if gain_function == 'exp_rank':\n        gain_function = lambda x: torch.pow(2, x) - 1\n        gains = gain_function(targets_sort_by_outputs)\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 2.0)\n        discounted_gains = gains * discounts\n    elif gain_function == 'linear_rank':\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 1.0)\n        discounts[0] = 1\n        discounted_gains = targets_sort_by_outputs * discounts\n    else:\n        raise ValueError('gain function can be either exp_rank or linear_rank')\n    dcg_score = discounted_gains\n    return dcg_score",
            "def dcg(outputs: torch.Tensor, targets: torch.Tensor, gain_function='exp_rank') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Computes Discounted cumulative gain (DCG)\\n    DCG@topk for the specified values of `k`.\\n    Graded relevance as a measure of  usefulness,\\n    or gain, from examining a set of items.\\n    Gain may be reduced at lower ranks.\\n    Reference:\\n    https://en.wikipedia.org/wiki/Discounted_cumulative_gain\\n\\n    Args:\\n        outputs: model outputs, logits\\n            with shape [batch_size; slate_length]\\n        targets: ground truth, labels\\n            with shape [batch_size; slate_length]\\n        gain_function:\\n            String indicates the gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n\\n    Returns:\\n        dcg_score (torch.Tensor):\\n            The discounted gains tensor\\n\\n    Raises:\\n        ValueError: gain function can be either `pow_rank` or `rank`\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        )\\n        # tensor([[2.0000, 2.0000, 0.6309, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"linear_rank\",\\n        ).sum()\\n        # tensor(4.6309)\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        )\\n        # tensor([[3.0000, 1.8928, 0.5000, 0.0000]])\\n\\n    .. code-block:: python\\n\\n        from catalyst import metrics\\n        metrics.dcg(\\n            outputs = torch.tensor([\\n                [3, 2, 1, 0],\\n            ]),\\n            targets = torch.Tensor([\\n                [2.0, 2.0, 1.0, 0.0],\\n            ]),\\n            gain_function=\"exp_rank\",\\n        ).sum()\\n        # tensor(5.3928)\\n    '\n    targets_sort_by_outputs = process_recsys_components(outputs, targets)\n    target_device = targets_sort_by_outputs.device\n    if gain_function == 'exp_rank':\n        gain_function = lambda x: torch.pow(2, x) - 1\n        gains = gain_function(targets_sort_by_outputs)\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 2.0)\n        discounted_gains = gains * discounts\n    elif gain_function == 'linear_rank':\n        discounts = torch.tensor(1) / torch.log2(torch.arange(targets_sort_by_outputs.shape[1], dtype=torch.float, device=target_device) + 1.0)\n        discounts[0] = 1\n        discounted_gains = targets_sort_by_outputs * discounts\n    else:\n        raise ValueError('gain function can be either exp_rank or linear_rank')\n    dcg_score = discounted_gains\n    return dcg_score"
        ]
    },
    {
        "func_name": "ndcg",
        "original": "def ndcg(outputs: torch.Tensor, targets: torch.Tensor, topk: List[int], gain_function='exp_rank') -> List[torch.Tensor]:\n    \"\"\"\n    Computes nDCG@topk for the specified values of `topk`.\n\n    Args:\n        outputs (torch.Tensor): model outputs, logits\n            with shape [batch_size; slate_size]\n        targets (torch.Tensor): ground truth, labels\n            with shape [batch_size; slate_size]\n        gain_function:\n            callable, gain function for the ground truth labels.\n            Two options available:\n            - `exp_rank`: torch.pow(2, x) - 1\n            - `linear_rank`: x\n            On the default, `exp_rank` is used\n            to emphasize on retrieving the relevant documents.\n        topk (List[int]):\n            Parameter fro evaluation on top-k items\n\n    Returns:\n        results (Tuple[float]):\n            tuple with computed ndcg@topk\n\n    Examples:\n\n    .. code-block:: python\n\n        import torch\n        from catalyst import metrics\n        metrics.ndcg(\n            outputs = torch.tensor([\n                [0.5, 0.2, 0.1],\n                [0.5, 0.2, 0.1],\n            ]),\n            targets = torch.Tensor([\n                [1.0, 0.0, 1.0],\n                [1.0, 0.0, 1.0],\n            ]),\n            topk=[2],\n            gain_function=\"exp_rank\",\n        )\n        # [tensor(0.6131)]\n\n    .. code-block:: python\n\n        import torch\n        from catalyst import metrics\n        metrics.ndcg(\n            outputs = torch.tensor([\n                [0.5, 0.2, 0.1],\n                [0.5, 0.2, 0.1],\n            ]),\n            targets = torch.Tensor([\n                [1.0, 0.0, 1.0],\n                [1.0, 0.0, 1.0],\n            ]),\n            topk=[2],\n            gain_function=\"exp_rank\",\n        )\n        # [tensor(0.5000)]\n    \"\"\"\n    results = []\n    for k in topk:\n        ideal_dcgs = dcg(targets, targets, gain_function)[:, :k]\n        predicted_dcgs = dcg(outputs, targets, gain_function)[:, :k]\n        ideal_dcgs_score = torch.sum(ideal_dcgs, dim=1)\n        predicted_dcgs_score = torch.sum(predicted_dcgs, dim=1)\n        ndcg_score = predicted_dcgs_score / ideal_dcgs_score\n        idcg_mask = ideal_dcgs_score == 0\n        ndcg_score[idcg_mask] = 0.0\n        results.append(torch.mean(ndcg_score))\n    return results",
        "mutated": [
            "def ndcg(outputs: torch.Tensor, targets: torch.Tensor, topk: List[int], gain_function='exp_rank') -> List[torch.Tensor]:\n    if False:\n        i = 10\n    '\\n    Computes nDCG@topk for the specified values of `topk`.\\n\\n    Args:\\n        outputs (torch.Tensor): model outputs, logits\\n            with shape [batch_size; slate_size]\\n        targets (torch.Tensor): ground truth, labels\\n            with shape [batch_size; slate_size]\\n        gain_function:\\n            callable, gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n        topk (List[int]):\\n            Parameter fro evaluation on top-k items\\n\\n    Returns:\\n        results (Tuple[float]):\\n            tuple with computed ndcg@topk\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.6131)]\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.5000)]\\n    '\n    results = []\n    for k in topk:\n        ideal_dcgs = dcg(targets, targets, gain_function)[:, :k]\n        predicted_dcgs = dcg(outputs, targets, gain_function)[:, :k]\n        ideal_dcgs_score = torch.sum(ideal_dcgs, dim=1)\n        predicted_dcgs_score = torch.sum(predicted_dcgs, dim=1)\n        ndcg_score = predicted_dcgs_score / ideal_dcgs_score\n        idcg_mask = ideal_dcgs_score == 0\n        ndcg_score[idcg_mask] = 0.0\n        results.append(torch.mean(ndcg_score))\n    return results",
            "def ndcg(outputs: torch.Tensor, targets: torch.Tensor, topk: List[int], gain_function='exp_rank') -> List[torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Computes nDCG@topk for the specified values of `topk`.\\n\\n    Args:\\n        outputs (torch.Tensor): model outputs, logits\\n            with shape [batch_size; slate_size]\\n        targets (torch.Tensor): ground truth, labels\\n            with shape [batch_size; slate_size]\\n        gain_function:\\n            callable, gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n        topk (List[int]):\\n            Parameter fro evaluation on top-k items\\n\\n    Returns:\\n        results (Tuple[float]):\\n            tuple with computed ndcg@topk\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.6131)]\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.5000)]\\n    '\n    results = []\n    for k in topk:\n        ideal_dcgs = dcg(targets, targets, gain_function)[:, :k]\n        predicted_dcgs = dcg(outputs, targets, gain_function)[:, :k]\n        ideal_dcgs_score = torch.sum(ideal_dcgs, dim=1)\n        predicted_dcgs_score = torch.sum(predicted_dcgs, dim=1)\n        ndcg_score = predicted_dcgs_score / ideal_dcgs_score\n        idcg_mask = ideal_dcgs_score == 0\n        ndcg_score[idcg_mask] = 0.0\n        results.append(torch.mean(ndcg_score))\n    return results",
            "def ndcg(outputs: torch.Tensor, targets: torch.Tensor, topk: List[int], gain_function='exp_rank') -> List[torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Computes nDCG@topk for the specified values of `topk`.\\n\\n    Args:\\n        outputs (torch.Tensor): model outputs, logits\\n            with shape [batch_size; slate_size]\\n        targets (torch.Tensor): ground truth, labels\\n            with shape [batch_size; slate_size]\\n        gain_function:\\n            callable, gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n        topk (List[int]):\\n            Parameter fro evaluation on top-k items\\n\\n    Returns:\\n        results (Tuple[float]):\\n            tuple with computed ndcg@topk\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.6131)]\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.5000)]\\n    '\n    results = []\n    for k in topk:\n        ideal_dcgs = dcg(targets, targets, gain_function)[:, :k]\n        predicted_dcgs = dcg(outputs, targets, gain_function)[:, :k]\n        ideal_dcgs_score = torch.sum(ideal_dcgs, dim=1)\n        predicted_dcgs_score = torch.sum(predicted_dcgs, dim=1)\n        ndcg_score = predicted_dcgs_score / ideal_dcgs_score\n        idcg_mask = ideal_dcgs_score == 0\n        ndcg_score[idcg_mask] = 0.0\n        results.append(torch.mean(ndcg_score))\n    return results",
            "def ndcg(outputs: torch.Tensor, targets: torch.Tensor, topk: List[int], gain_function='exp_rank') -> List[torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Computes nDCG@topk for the specified values of `topk`.\\n\\n    Args:\\n        outputs (torch.Tensor): model outputs, logits\\n            with shape [batch_size; slate_size]\\n        targets (torch.Tensor): ground truth, labels\\n            with shape [batch_size; slate_size]\\n        gain_function:\\n            callable, gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n        topk (List[int]):\\n            Parameter fro evaluation on top-k items\\n\\n    Returns:\\n        results (Tuple[float]):\\n            tuple with computed ndcg@topk\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.6131)]\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.5000)]\\n    '\n    results = []\n    for k in topk:\n        ideal_dcgs = dcg(targets, targets, gain_function)[:, :k]\n        predicted_dcgs = dcg(outputs, targets, gain_function)[:, :k]\n        ideal_dcgs_score = torch.sum(ideal_dcgs, dim=1)\n        predicted_dcgs_score = torch.sum(predicted_dcgs, dim=1)\n        ndcg_score = predicted_dcgs_score / ideal_dcgs_score\n        idcg_mask = ideal_dcgs_score == 0\n        ndcg_score[idcg_mask] = 0.0\n        results.append(torch.mean(ndcg_score))\n    return results",
            "def ndcg(outputs: torch.Tensor, targets: torch.Tensor, topk: List[int], gain_function='exp_rank') -> List[torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Computes nDCG@topk for the specified values of `topk`.\\n\\n    Args:\\n        outputs (torch.Tensor): model outputs, logits\\n            with shape [batch_size; slate_size]\\n        targets (torch.Tensor): ground truth, labels\\n            with shape [batch_size; slate_size]\\n        gain_function:\\n            callable, gain function for the ground truth labels.\\n            Two options available:\\n            - `exp_rank`: torch.pow(2, x) - 1\\n            - `linear_rank`: x\\n            On the default, `exp_rank` is used\\n            to emphasize on retrieving the relevant documents.\\n        topk (List[int]):\\n            Parameter fro evaluation on top-k items\\n\\n    Returns:\\n        results (Tuple[float]):\\n            tuple with computed ndcg@topk\\n\\n    Examples:\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.6131)]\\n\\n    .. code-block:: python\\n\\n        import torch\\n        from catalyst import metrics\\n        metrics.ndcg(\\n            outputs = torch.tensor([\\n                [0.5, 0.2, 0.1],\\n                [0.5, 0.2, 0.1],\\n            ]),\\n            targets = torch.Tensor([\\n                [1.0, 0.0, 1.0],\\n                [1.0, 0.0, 1.0],\\n            ]),\\n            topk=[2],\\n            gain_function=\"exp_rank\",\\n        )\\n        # [tensor(0.5000)]\\n    '\n    results = []\n    for k in topk:\n        ideal_dcgs = dcg(targets, targets, gain_function)[:, :k]\n        predicted_dcgs = dcg(outputs, targets, gain_function)[:, :k]\n        ideal_dcgs_score = torch.sum(ideal_dcgs, dim=1)\n        predicted_dcgs_score = torch.sum(predicted_dcgs, dim=1)\n        ndcg_score = predicted_dcgs_score / ideal_dcgs_score\n        idcg_mask = ideal_dcgs_score == 0\n        ndcg_score[idcg_mask] = 0.0\n        results.append(torch.mean(ndcg_score))\n    return results"
        ]
    }
]