[
    {
        "func_name": "bias",
        "original": "def bias(x, y, axis=1):\n    \"\"\"Elementwise summation with broadcasting.\n\n    Computes a elementwise summation of two input variables, with the shape of\n    the latter variable broadcasted to match the shape of the former. ``axis``\n    is the first axis of the first variable along which the second variable is\n    applied.\n\n    The term \"broadcasting\" here comes from Caffe's bias layer so the\n    \"broadcasting\" with the following arguments::\n\n           x : 100 x 3 x 40 x 5 x 6\n           y : 3 x 40\n        axis : 1\n\n    is equivalent to the following numpy broadcasting::\n\n        x : 100 x  3 x 40 x 5 x 6\n        y :  (1 x) 3 x 40 x 1 x 1\n\n    Note that the axis of ``x`` to which we apply ``y`` is specified by the\n    argument ``axis``, whose meaning is different from numpy's ``axis``.\n\n    Args:\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\n            Input variable to be summed.\n        y (:class:`~chainer.Variable` or :ref:`ndarray`):\n            Input variable to sum, broadcasted.\n        axis (int): The first axis of ``x`` along which ``y`` is applied.\n\n    Returns:\n        ~chainer.Variable: Output variable.\n\n    \"\"\"\n    x_shape = x.shape\n    y_shape = y.shape\n    if chainer.is_debug():\n        assert x_shape[axis:axis + len(y_shape)] == y_shape\n    y1_shape = tuple([1] * axis + list(y_shape) + [1] * (len(x_shape) - axis - len(y_shape)))\n    y1 = reshape.reshape(y, y1_shape)\n    y2 = broadcast.broadcast_to(y1, x_shape)\n    return x + y2",
        "mutated": [
            "def bias(x, y, axis=1):\n    if False:\n        i = 10\n    'Elementwise summation with broadcasting.\\n\\n    Computes a elementwise summation of two input variables, with the shape of\\n    the latter variable broadcasted to match the shape of the former. ``axis``\\n    is the first axis of the first variable along which the second variable is\\n    applied.\\n\\n    The term \"broadcasting\" here comes from Caffe\\'s bias layer so the\\n    \"broadcasting\" with the following arguments::\\n\\n           x : 100 x 3 x 40 x 5 x 6\\n           y : 3 x 40\\n        axis : 1\\n\\n    is equivalent to the following numpy broadcasting::\\n\\n        x : 100 x  3 x 40 x 5 x 6\\n        y :  (1 x) 3 x 40 x 1 x 1\\n\\n    Note that the axis of ``x`` to which we apply ``y`` is specified by the\\n    argument ``axis``, whose meaning is different from numpy\\'s ``axis``.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to be summed.\\n        y (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to sum, broadcasted.\\n        axis (int): The first axis of ``x`` along which ``y`` is applied.\\n\\n    Returns:\\n        ~chainer.Variable: Output variable.\\n\\n    '\n    x_shape = x.shape\n    y_shape = y.shape\n    if chainer.is_debug():\n        assert x_shape[axis:axis + len(y_shape)] == y_shape\n    y1_shape = tuple([1] * axis + list(y_shape) + [1] * (len(x_shape) - axis - len(y_shape)))\n    y1 = reshape.reshape(y, y1_shape)\n    y2 = broadcast.broadcast_to(y1, x_shape)\n    return x + y2",
            "def bias(x, y, axis=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Elementwise summation with broadcasting.\\n\\n    Computes a elementwise summation of two input variables, with the shape of\\n    the latter variable broadcasted to match the shape of the former. ``axis``\\n    is the first axis of the first variable along which the second variable is\\n    applied.\\n\\n    The term \"broadcasting\" here comes from Caffe\\'s bias layer so the\\n    \"broadcasting\" with the following arguments::\\n\\n           x : 100 x 3 x 40 x 5 x 6\\n           y : 3 x 40\\n        axis : 1\\n\\n    is equivalent to the following numpy broadcasting::\\n\\n        x : 100 x  3 x 40 x 5 x 6\\n        y :  (1 x) 3 x 40 x 1 x 1\\n\\n    Note that the axis of ``x`` to which we apply ``y`` is specified by the\\n    argument ``axis``, whose meaning is different from numpy\\'s ``axis``.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to be summed.\\n        y (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to sum, broadcasted.\\n        axis (int): The first axis of ``x`` along which ``y`` is applied.\\n\\n    Returns:\\n        ~chainer.Variable: Output variable.\\n\\n    '\n    x_shape = x.shape\n    y_shape = y.shape\n    if chainer.is_debug():\n        assert x_shape[axis:axis + len(y_shape)] == y_shape\n    y1_shape = tuple([1] * axis + list(y_shape) + [1] * (len(x_shape) - axis - len(y_shape)))\n    y1 = reshape.reshape(y, y1_shape)\n    y2 = broadcast.broadcast_to(y1, x_shape)\n    return x + y2",
            "def bias(x, y, axis=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Elementwise summation with broadcasting.\\n\\n    Computes a elementwise summation of two input variables, with the shape of\\n    the latter variable broadcasted to match the shape of the former. ``axis``\\n    is the first axis of the first variable along which the second variable is\\n    applied.\\n\\n    The term \"broadcasting\" here comes from Caffe\\'s bias layer so the\\n    \"broadcasting\" with the following arguments::\\n\\n           x : 100 x 3 x 40 x 5 x 6\\n           y : 3 x 40\\n        axis : 1\\n\\n    is equivalent to the following numpy broadcasting::\\n\\n        x : 100 x  3 x 40 x 5 x 6\\n        y :  (1 x) 3 x 40 x 1 x 1\\n\\n    Note that the axis of ``x`` to which we apply ``y`` is specified by the\\n    argument ``axis``, whose meaning is different from numpy\\'s ``axis``.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to be summed.\\n        y (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to sum, broadcasted.\\n        axis (int): The first axis of ``x`` along which ``y`` is applied.\\n\\n    Returns:\\n        ~chainer.Variable: Output variable.\\n\\n    '\n    x_shape = x.shape\n    y_shape = y.shape\n    if chainer.is_debug():\n        assert x_shape[axis:axis + len(y_shape)] == y_shape\n    y1_shape = tuple([1] * axis + list(y_shape) + [1] * (len(x_shape) - axis - len(y_shape)))\n    y1 = reshape.reshape(y, y1_shape)\n    y2 = broadcast.broadcast_to(y1, x_shape)\n    return x + y2",
            "def bias(x, y, axis=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Elementwise summation with broadcasting.\\n\\n    Computes a elementwise summation of two input variables, with the shape of\\n    the latter variable broadcasted to match the shape of the former. ``axis``\\n    is the first axis of the first variable along which the second variable is\\n    applied.\\n\\n    The term \"broadcasting\" here comes from Caffe\\'s bias layer so the\\n    \"broadcasting\" with the following arguments::\\n\\n           x : 100 x 3 x 40 x 5 x 6\\n           y : 3 x 40\\n        axis : 1\\n\\n    is equivalent to the following numpy broadcasting::\\n\\n        x : 100 x  3 x 40 x 5 x 6\\n        y :  (1 x) 3 x 40 x 1 x 1\\n\\n    Note that the axis of ``x`` to which we apply ``y`` is specified by the\\n    argument ``axis``, whose meaning is different from numpy\\'s ``axis``.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to be summed.\\n        y (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to sum, broadcasted.\\n        axis (int): The first axis of ``x`` along which ``y`` is applied.\\n\\n    Returns:\\n        ~chainer.Variable: Output variable.\\n\\n    '\n    x_shape = x.shape\n    y_shape = y.shape\n    if chainer.is_debug():\n        assert x_shape[axis:axis + len(y_shape)] == y_shape\n    y1_shape = tuple([1] * axis + list(y_shape) + [1] * (len(x_shape) - axis - len(y_shape)))\n    y1 = reshape.reshape(y, y1_shape)\n    y2 = broadcast.broadcast_to(y1, x_shape)\n    return x + y2",
            "def bias(x, y, axis=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Elementwise summation with broadcasting.\\n\\n    Computes a elementwise summation of two input variables, with the shape of\\n    the latter variable broadcasted to match the shape of the former. ``axis``\\n    is the first axis of the first variable along which the second variable is\\n    applied.\\n\\n    The term \"broadcasting\" here comes from Caffe\\'s bias layer so the\\n    \"broadcasting\" with the following arguments::\\n\\n           x : 100 x 3 x 40 x 5 x 6\\n           y : 3 x 40\\n        axis : 1\\n\\n    is equivalent to the following numpy broadcasting::\\n\\n        x : 100 x  3 x 40 x 5 x 6\\n        y :  (1 x) 3 x 40 x 1 x 1\\n\\n    Note that the axis of ``x`` to which we apply ``y`` is specified by the\\n    argument ``axis``, whose meaning is different from numpy\\'s ``axis``.\\n\\n    Args:\\n        x (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to be summed.\\n        y (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Input variable to sum, broadcasted.\\n        axis (int): The first axis of ``x`` along which ``y`` is applied.\\n\\n    Returns:\\n        ~chainer.Variable: Output variable.\\n\\n    '\n    x_shape = x.shape\n    y_shape = y.shape\n    if chainer.is_debug():\n        assert x_shape[axis:axis + len(y_shape)] == y_shape\n    y1_shape = tuple([1] * axis + list(y_shape) + [1] * (len(x_shape) - axis - len(y_shape)))\n    y1 = reshape.reshape(y, y1_shape)\n    y2 = broadcast.broadcast_to(y1, x_shape)\n    return x + y2"
        ]
    }
]