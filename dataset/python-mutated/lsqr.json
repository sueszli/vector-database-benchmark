[
    {
        "func_name": "_sym_ortho",
        "original": "def _sym_ortho(a, b):\n    \"\"\"\n    Stable implementation of Givens rotation.\n\n    Notes\n    -----\n    The routine 'SymOrtho' was added for numerical stability. This is\n    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of\n    ``1/eps`` in some important places (see, for example text following\n    \"Compute the next plane rotation Qk\" in minres.py).\n\n    References\n    ----------\n    .. [1] S.-C. Choi, \"Iterative Methods for Singular Linear Equations\n           and Least-Squares Problems\", Dissertation,\n           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf\n\n    \"\"\"\n    if b == 0:\n        return (np.sign(a), 0, abs(a))\n    elif a == 0:\n        return (0, np.sign(b), abs(b))\n    elif abs(b) > abs(a):\n        tau = a / b\n        s = np.sign(b) / sqrt(1 + tau * tau)\n        c = s * tau\n        r = b / s\n    else:\n        tau = b / a\n        c = np.sign(a) / sqrt(1 + tau * tau)\n        s = c * tau\n        r = a / c\n    return (c, s, r)",
        "mutated": [
            "def _sym_ortho(a, b):\n    if False:\n        i = 10\n    '\\n    Stable implementation of Givens rotation.\\n\\n    Notes\\n    -----\\n    The routine \\'SymOrtho\\' was added for numerical stability. This is\\n    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of\\n    ``1/eps`` in some important places (see, for example text following\\n    \"Compute the next plane rotation Qk\" in minres.py).\\n\\n    References\\n    ----------\\n    .. [1] S.-C. Choi, \"Iterative Methods for Singular Linear Equations\\n           and Least-Squares Problems\", Dissertation,\\n           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf\\n\\n    '\n    if b == 0:\n        return (np.sign(a), 0, abs(a))\n    elif a == 0:\n        return (0, np.sign(b), abs(b))\n    elif abs(b) > abs(a):\n        tau = a / b\n        s = np.sign(b) / sqrt(1 + tau * tau)\n        c = s * tau\n        r = b / s\n    else:\n        tau = b / a\n        c = np.sign(a) / sqrt(1 + tau * tau)\n        s = c * tau\n        r = a / c\n    return (c, s, r)",
            "def _sym_ortho(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Stable implementation of Givens rotation.\\n\\n    Notes\\n    -----\\n    The routine \\'SymOrtho\\' was added for numerical stability. This is\\n    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of\\n    ``1/eps`` in some important places (see, for example text following\\n    \"Compute the next plane rotation Qk\" in minres.py).\\n\\n    References\\n    ----------\\n    .. [1] S.-C. Choi, \"Iterative Methods for Singular Linear Equations\\n           and Least-Squares Problems\", Dissertation,\\n           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf\\n\\n    '\n    if b == 0:\n        return (np.sign(a), 0, abs(a))\n    elif a == 0:\n        return (0, np.sign(b), abs(b))\n    elif abs(b) > abs(a):\n        tau = a / b\n        s = np.sign(b) / sqrt(1 + tau * tau)\n        c = s * tau\n        r = b / s\n    else:\n        tau = b / a\n        c = np.sign(a) / sqrt(1 + tau * tau)\n        s = c * tau\n        r = a / c\n    return (c, s, r)",
            "def _sym_ortho(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Stable implementation of Givens rotation.\\n\\n    Notes\\n    -----\\n    The routine \\'SymOrtho\\' was added for numerical stability. This is\\n    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of\\n    ``1/eps`` in some important places (see, for example text following\\n    \"Compute the next plane rotation Qk\" in minres.py).\\n\\n    References\\n    ----------\\n    .. [1] S.-C. Choi, \"Iterative Methods for Singular Linear Equations\\n           and Least-Squares Problems\", Dissertation,\\n           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf\\n\\n    '\n    if b == 0:\n        return (np.sign(a), 0, abs(a))\n    elif a == 0:\n        return (0, np.sign(b), abs(b))\n    elif abs(b) > abs(a):\n        tau = a / b\n        s = np.sign(b) / sqrt(1 + tau * tau)\n        c = s * tau\n        r = b / s\n    else:\n        tau = b / a\n        c = np.sign(a) / sqrt(1 + tau * tau)\n        s = c * tau\n        r = a / c\n    return (c, s, r)",
            "def _sym_ortho(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Stable implementation of Givens rotation.\\n\\n    Notes\\n    -----\\n    The routine \\'SymOrtho\\' was added for numerical stability. This is\\n    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of\\n    ``1/eps`` in some important places (see, for example text following\\n    \"Compute the next plane rotation Qk\" in minres.py).\\n\\n    References\\n    ----------\\n    .. [1] S.-C. Choi, \"Iterative Methods for Singular Linear Equations\\n           and Least-Squares Problems\", Dissertation,\\n           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf\\n\\n    '\n    if b == 0:\n        return (np.sign(a), 0, abs(a))\n    elif a == 0:\n        return (0, np.sign(b), abs(b))\n    elif abs(b) > abs(a):\n        tau = a / b\n        s = np.sign(b) / sqrt(1 + tau * tau)\n        c = s * tau\n        r = b / s\n    else:\n        tau = b / a\n        c = np.sign(a) / sqrt(1 + tau * tau)\n        s = c * tau\n        r = a / c\n    return (c, s, r)",
            "def _sym_ortho(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Stable implementation of Givens rotation.\\n\\n    Notes\\n    -----\\n    The routine \\'SymOrtho\\' was added for numerical stability. This is\\n    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of\\n    ``1/eps`` in some important places (see, for example text following\\n    \"Compute the next plane rotation Qk\" in minres.py).\\n\\n    References\\n    ----------\\n    .. [1] S.-C. Choi, \"Iterative Methods for Singular Linear Equations\\n           and Least-Squares Problems\", Dissertation,\\n           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf\\n\\n    '\n    if b == 0:\n        return (np.sign(a), 0, abs(a))\n    elif a == 0:\n        return (0, np.sign(b), abs(b))\n    elif abs(b) > abs(a):\n        tau = a / b\n        s = np.sign(b) / sqrt(1 + tau * tau)\n        c = s * tau\n        r = b / s\n    else:\n        tau = b / a\n        c = np.sign(a) / sqrt(1 + tau * tau)\n        s = c * tau\n        r = a / c\n    return (c, s, r)"
        ]
    },
    {
        "func_name": "lsqr",
        "original": "def lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None):\n    \"\"\"Find the least-squares solution to a large, sparse, linear system\n    of equations.\n\n    The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\n    ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\n\n    The matrix A may be square or rectangular (over-determined or\n    under-determined), and may have any rank.\n\n    ::\n\n      1. Unsymmetric equations --    solve  Ax = b\n\n      2. Linear least squares  --    solve  Ax = b\n                                     in the least-squares sense\n\n      3. Damped least squares  --    solve  (   A    )*x = (    b    )\n                                            ( damp*I )     ( damp*x0 )\n                                     in the least-squares sense\n\n    Parameters\n    ----------\n    A : {sparse matrix, ndarray, LinearOperator}\n        Representation of an m-by-n matrix.\n        Alternatively, ``A`` can be a linear operator which can\n        produce ``Ax`` and ``A^T x`` using, e.g.,\n        ``scipy.sparse.linalg.LinearOperator``.\n    b : array_like, shape (m,)\n        Right-hand side vector ``b``.\n    damp : float\n        Damping coefficient. Default is 0.\n    atol, btol : float, optional\n        Stopping tolerances. `lsqr` continues iterations until a\n        certain backward error estimate is smaller than some quantity\n        depending on atol and btol.  Let ``r = b - Ax`` be the\n        residual vector for the current approximate solution ``x``.\n        If ``Ax = b`` seems to be consistent, `lsqr` terminates\n        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\n        Otherwise, `lsqr` terminates when ``norm(A^H r) <=\n        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\n        the final ``norm(r)`` should be accurate to about 6\n        digits. (The final ``x`` will usually have fewer correct digits,\n        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\n        or `btol` is None, a default value of 1.0e-6 will be used.\n        Ideally, they should be estimates of the relative error in the\n        entries of ``A`` and ``b`` respectively.  For example, if the entries\n        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\n        the algorithm from doing unnecessary work beyond the\n        uncertainty of the input data.\n    conlim : float, optional\n        Another stopping tolerance.  lsqr terminates if an estimate of\n        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\n        b``, `conlim` could be as large as 1.0e+12 (say).  For\n        least-squares problems, conlim should be less than 1.0e+8.\n        Maximum precision can be obtained by setting ``atol = btol =\n        conlim = zero``, but the number of iterations may then be\n        excessive. Default is 1e8.\n    iter_lim : int, optional\n        Explicit limitation on number of iterations (for safety).\n    show : bool, optional\n        Display an iteration log. Default is False.\n    calc_var : bool, optional\n        Whether to estimate diagonals of ``(A'A + damp^2*I)^{-1}``.\n    x0 : array_like, shape (n,), optional\n        Initial guess of x, if None zeros are used. Default is None.\n\n        .. versionadded:: 1.0.0\n\n    Returns\n    -------\n    x : ndarray of float\n        The final solution.\n    istop : int\n        Gives the reason for termination.\n        1 means x is an approximate solution to Ax = b.\n        2 means x approximately solves the least-squares problem.\n    itn : int\n        Iteration number upon termination.\n    r1norm : float\n        ``norm(r)``, where ``r = b - Ax``.\n    r2norm : float\n        ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\n        if ``damp == 0``.\n    anorm : float\n        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\n    acond : float\n        Estimate of ``cond(Abar)``.\n    arnorm : float\n        Estimate of ``norm(A'@r - damp^2*(x - x0))``.\n    xnorm : float\n        ``norm(x)``\n    var : ndarray of float\n        If ``calc_var`` is True, estimates all diagonals of\n        ``(A'A)^{-1}`` (if ``damp == 0``) or more generally ``(A'A +\n        damp^2*I)^{-1}``.  This is well defined if A has full column\n        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\n        < n`` and ``damp = 0.``)\n\n    Notes\n    -----\n    LSQR uses an iterative method to approximate the solution.  The\n    number of iterations required to reach a certain accuracy depends\n    strongly on the scaling of the problem.  Poor scaling of the rows\n    or columns of A should therefore be avoided where possible.\n\n    For example, in problem 1 the solution is unaltered by\n    row-scaling.  If a row of A is very small or large compared to\n    the other rows of A, the corresponding row of ( A  b ) should be\n    scaled up or down.\n\n    In problems 1 and 2, the solution x is easily recovered\n    following column-scaling.  Unless better information is known,\n    the nonzero columns of A should be scaled so that they all have\n    the same Euclidean norm (e.g., 1.0).\n\n    In problem 3, there is no freedom to re-scale if damp is\n    nonzero.  However, the value of damp should be assigned only\n    after attention has been paid to the scaling of A.\n\n    The parameter damp is intended to help regularize\n    ill-conditioned systems, by preventing the true solution from\n    being very large.  Another aid to regularization is provided by\n    the parameter acond, which may be used to terminate iterations\n    before the computed solution becomes very large.\n\n    If some initial estimate ``x0`` is known and if ``damp == 0``,\n    one could proceed as follows:\n\n      1. Compute a residual vector ``r0 = b - A@x0``.\n      2. Use LSQR to solve the system  ``A@dx = r0``.\n      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\n\n    This requires that ``x0`` be available before and after the call\n    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\n    to solve A@x = b and k2 iterations to solve A@dx = r0.\n    If x0 is \"good\", norm(r0) will be smaller than norm(b).\n    If the same stopping tolerances atol and btol are used for each\n    system, k1 and k2 will be similar, but the final solution x0 + dx\n    should be more accurate.  The only way to reduce the total work\n    is to use a larger stopping tolerance for the second system.\n    If some value btol is suitable for A@x = b, the larger value\n    btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\n\n    Preconditioning is another way to reduce the number of iterations.\n    If it is possible to solve a related system ``M@x = b``\n    efficiently, where M approximates A in some helpful way (e.g. M -\n    A has low rank or its elements are small relative to those of A),\n    LSQR may converge more rapidly on the system ``A@M(inverse)@z =\n    b``, after which x can be recovered by solving M@x = z.\n\n    If A is symmetric, LSQR should not be used!\n\n    Alternatives are the symmetric conjugate-gradient method (cg)\n    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\n    applies to any symmetric A and will converge more rapidly than\n    LSQR.  If A is positive definite, there are other implementations\n    of symmetric cg that require slightly less work per iteration than\n    SYMMLQ (but will take the same number of iterations).\n\n    References\n    ----------\n    .. [1] C. C. Paige and M. A. Saunders (1982a).\n           \"LSQR: An algorithm for sparse linear equations and\n           sparse least squares\", ACM TOMS 8(1), 43-71.\n    .. [2] C. C. Paige and M. A. Saunders (1982b).\n           \"Algorithm 583.  LSQR: Sparse linear equations and least\n           squares problems\", ACM TOMS 8(2), 195-209.\n    .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\n           systems using LSQR and CRAIG\", BIT 35, 588-604.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import csc_matrix\n    >>> from scipy.sparse.linalg import lsqr\n    >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\n\n    The first example has the trivial solution ``[0, 0]``\n\n    >>> b = np.array([0., 0., 0.], dtype=float)\n    >>> x, istop, itn, normr = lsqr(A, b)[:4]\n    >>> istop\n    0\n    >>> x\n    array([ 0.,  0.])\n\n    The stopping code `istop=0` returned indicates that a vector of zeros was\n    found as a solution. The returned solution `x` indeed contains\n    ``[0., 0.]``. The next example has a non-trivial solution:\n\n    >>> b = np.array([1., 0., -1.], dtype=float)\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\n    >>> istop\n    1\n    >>> x\n    array([ 1., -1.])\n    >>> itn\n    1\n    >>> r1norm\n    4.440892098500627e-16\n\n    As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\n    limits. The given solution ``[1., -1.]`` obviously solves the equation. The\n    remaining return values include information about the number of iterations\n    (`itn=1`) and the remaining difference of left and right side of the solved\n    equation.\n    The final example demonstrates the behavior in the case where there is no\n    solution for the equation:\n\n    >>> b = np.array([1., 0.01, -1.], dtype=float)\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\n    >>> istop\n    2\n    >>> x\n    array([ 1.00333333, -0.99666667])\n    >>> A.dot(x)-b\n    array([ 0.00333333, -0.00333333,  0.00333333])\n    >>> r1norm\n    0.005773502691896255\n\n    `istop` indicates that the system is inconsistent and thus `x` is rather an\n    approximate solution to the corresponding least-squares problem. `r1norm`\n    contains the norm of the minimal residual that was found.\n    \"\"\"\n    A = aslinearoperator(A)\n    b = np.atleast_1d(b)\n    if b.ndim > 1:\n        b = b.squeeze()\n    (m, n) = A.shape\n    if iter_lim is None:\n        iter_lim = 2 * n\n    var = np.zeros(n)\n    msg = ('The exact solution is  x = 0                              ', 'Ax - b is small enough, given atol, btol                  ', 'The least-squares solution is good enough, given atol     ', 'The estimate of cond(Abar) has exceeded conlim            ', 'Ax - b is small enough for this machine                   ', 'The least-squares solution is good enough for this machine', 'Cond(Abar) seems to be too large for this machine         ', 'The iteration limit has been reached                      ')\n    if show:\n        print(' ')\n        print('LSQR            Least-squares solution of  Ax = b')\n        str1 = f'The matrix A has {m} rows and {n} columns'\n        str2 = f'damp = {damp:20.14e}   calc_var = {calc_var:8g}'\n        str3 = f'atol = {atol:8.2e}                 conlim = {conlim:8.2e}'\n        str4 = f'btol = {btol:8.2e}               iter_lim = {iter_lim:8g}'\n        print(str1)\n        print(str2)\n        print(str3)\n        print(str4)\n    itn = 0\n    istop = 0\n    ctol = 0\n    if conlim > 0:\n        ctol = 1 / conlim\n    anorm = 0\n    acond = 0\n    dampsq = damp ** 2\n    ddnorm = 0\n    res2 = 0\n    xnorm = 0\n    xxnorm = 0\n    z = 0\n    cs2 = -1\n    sn2 = 0\n    u = b\n    bnorm = np.linalg.norm(b)\n    if x0 is None:\n        x = np.zeros(n)\n        beta = bnorm.copy()\n    else:\n        x = np.asarray(x0)\n        u = u - A.matvec(x)\n        beta = np.linalg.norm(u)\n    if beta > 0:\n        u = 1 / beta * u\n        v = A.rmatvec(u)\n        alfa = np.linalg.norm(v)\n    else:\n        v = x.copy()\n        alfa = 0\n    if alfa > 0:\n        v = 1 / alfa * v\n    w = v.copy()\n    rhobar = alfa\n    phibar = beta\n    rnorm = beta\n    r1norm = rnorm\n    r2norm = rnorm\n    arnorm = alfa * beta\n    if arnorm == 0:\n        if show:\n            print(msg[0])\n        return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)\n    head1 = '   Itn      x[0]       r1norm     r2norm '\n    head2 = ' Compatible    LS      Norm A   Cond A'\n    if show:\n        print(' ')\n        print(head1, head2)\n        test1 = 1\n        test2 = alfa / beta\n        str1 = f'{itn:6g} {x[0]:12.5e}'\n        str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n        str3 = f'  {test1:8.1e} {test2:8.1e}'\n        print(str1, str2, str3)\n    while itn < iter_lim:\n        itn = itn + 1\n        u = A.matvec(v) - alfa * u\n        beta = np.linalg.norm(u)\n        if beta > 0:\n            u = 1 / beta * u\n            anorm = sqrt(anorm ** 2 + alfa ** 2 + beta ** 2 + dampsq)\n            v = A.rmatvec(u) - beta * v\n            alfa = np.linalg.norm(v)\n            if alfa > 0:\n                v = 1 / alfa * v\n        if damp > 0:\n            rhobar1 = sqrt(rhobar ** 2 + dampsq)\n            cs1 = rhobar / rhobar1\n            sn1 = damp / rhobar1\n            psi = sn1 * phibar\n            phibar = cs1 * phibar\n        else:\n            rhobar1 = rhobar\n            psi = 0.0\n        (cs, sn, rho) = _sym_ortho(rhobar1, beta)\n        theta = sn * alfa\n        rhobar = -cs * alfa\n        phi = cs * phibar\n        phibar = sn * phibar\n        tau = sn * phi\n        t1 = phi / rho\n        t2 = -theta / rho\n        dk = 1 / rho * w\n        x = x + t1 * w\n        w = v + t2 * w\n        ddnorm = ddnorm + np.linalg.norm(dk) ** 2\n        if calc_var:\n            var = var + dk ** 2\n        delta = sn2 * rho\n        gambar = -cs2 * rho\n        rhs = phi - delta * z\n        zbar = rhs / gambar\n        xnorm = sqrt(xxnorm + zbar ** 2)\n        gamma = sqrt(gambar ** 2 + theta ** 2)\n        cs2 = gambar / gamma\n        sn2 = theta / gamma\n        z = rhs / gamma\n        xxnorm = xxnorm + z ** 2\n        acond = anorm * sqrt(ddnorm)\n        res1 = phibar ** 2\n        res2 = res2 + psi ** 2\n        rnorm = sqrt(res1 + res2)\n        arnorm = alfa * abs(tau)\n        if damp > 0:\n            r1sq = rnorm ** 2 - dampsq * xxnorm\n            r1norm = sqrt(abs(r1sq))\n            if r1sq < 0:\n                r1norm = -r1norm\n        else:\n            r1norm = rnorm\n        r2norm = rnorm\n        test1 = rnorm / bnorm\n        test2 = arnorm / (anorm * rnorm + eps)\n        test3 = 1 / (acond + eps)\n        t1 = test1 / (1 + anorm * xnorm / bnorm)\n        rtol = btol + atol * anorm * xnorm / bnorm\n        if itn >= iter_lim:\n            istop = 7\n        if 1 + test3 <= 1:\n            istop = 6\n        if 1 + test2 <= 1:\n            istop = 5\n        if 1 + t1 <= 1:\n            istop = 4\n        if test3 <= ctol:\n            istop = 3\n        if test2 <= atol:\n            istop = 2\n        if test1 <= rtol:\n            istop = 1\n        if show:\n            prnt = False\n            if n <= 40:\n                prnt = True\n            if itn <= 10:\n                prnt = True\n            if itn >= iter_lim - 10:\n                prnt = True\n            if test3 <= 2 * ctol:\n                prnt = True\n            if test2 <= 10 * atol:\n                prnt = True\n            if test1 <= 10 * rtol:\n                prnt = True\n            if istop != 0:\n                prnt = True\n            if prnt:\n                str1 = f'{itn:6g} {x[0]:12.5e}'\n                str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n                str3 = f'  {test1:8.1e} {test2:8.1e}'\n                str4 = f' {anorm:8.1e} {acond:8.1e}'\n                print(str1, str2, str3, str4)\n        if istop != 0:\n            break\n    if show:\n        print(' ')\n        print('LSQR finished')\n        print(msg[istop])\n        print(' ')\n        str1 = f'istop ={istop:8g}   r1norm ={r1norm:8.1e}'\n        str2 = f'anorm ={anorm:8.1e}   arnorm ={arnorm:8.1e}'\n        str3 = f'itn   ={itn:8g}   r2norm ={r2norm:8.1e}'\n        str4 = f'acond ={acond:8.1e}   xnorm  ={xnorm:8.1e}'\n        print(str1 + '   ' + str2)\n        print(str3 + '   ' + str4)\n        print(' ')\n    return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)",
        "mutated": [
            "def lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None):\n    if False:\n        i = 10\n    'Find the least-squares solution to a large, sparse, linear system\\n    of equations.\\n\\n    The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\\n    ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\\n\\n    The matrix A may be square or rectangular (over-determined or\\n    under-determined), and may have any rank.\\n\\n    ::\\n\\n      1. Unsymmetric equations --    solve  Ax = b\\n\\n      2. Linear least squares  --    solve  Ax = b\\n                                     in the least-squares sense\\n\\n      3. Damped least squares  --    solve  (   A    )*x = (    b    )\\n                                            ( damp*I )     ( damp*x0 )\\n                                     in the least-squares sense\\n\\n    Parameters\\n    ----------\\n    A : {sparse matrix, ndarray, LinearOperator}\\n        Representation of an m-by-n matrix.\\n        Alternatively, ``A`` can be a linear operator which can\\n        produce ``Ax`` and ``A^T x`` using, e.g.,\\n        ``scipy.sparse.linalg.LinearOperator``.\\n    b : array_like, shape (m,)\\n        Right-hand side vector ``b``.\\n    damp : float\\n        Damping coefficient. Default is 0.\\n    atol, btol : float, optional\\n        Stopping tolerances. `lsqr` continues iterations until a\\n        certain backward error estimate is smaller than some quantity\\n        depending on atol and btol.  Let ``r = b - Ax`` be the\\n        residual vector for the current approximate solution ``x``.\\n        If ``Ax = b`` seems to be consistent, `lsqr` terminates\\n        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\\n        Otherwise, `lsqr` terminates when ``norm(A^H r) <=\\n        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\\n        the final ``norm(r)`` should be accurate to about 6\\n        digits. (The final ``x`` will usually have fewer correct digits,\\n        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\\n        or `btol` is None, a default value of 1.0e-6 will be used.\\n        Ideally, they should be estimates of the relative error in the\\n        entries of ``A`` and ``b`` respectively.  For example, if the entries\\n        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\\n        the algorithm from doing unnecessary work beyond the\\n        uncertainty of the input data.\\n    conlim : float, optional\\n        Another stopping tolerance.  lsqr terminates if an estimate of\\n        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\\n        b``, `conlim` could be as large as 1.0e+12 (say).  For\\n        least-squares problems, conlim should be less than 1.0e+8.\\n        Maximum precision can be obtained by setting ``atol = btol =\\n        conlim = zero``, but the number of iterations may then be\\n        excessive. Default is 1e8.\\n    iter_lim : int, optional\\n        Explicit limitation on number of iterations (for safety).\\n    show : bool, optional\\n        Display an iteration log. Default is False.\\n    calc_var : bool, optional\\n        Whether to estimate diagonals of ``(A\\'A + damp^2*I)^{-1}``.\\n    x0 : array_like, shape (n,), optional\\n        Initial guess of x, if None zeros are used. Default is None.\\n\\n        .. versionadded:: 1.0.0\\n\\n    Returns\\n    -------\\n    x : ndarray of float\\n        The final solution.\\n    istop : int\\n        Gives the reason for termination.\\n        1 means x is an approximate solution to Ax = b.\\n        2 means x approximately solves the least-squares problem.\\n    itn : int\\n        Iteration number upon termination.\\n    r1norm : float\\n        ``norm(r)``, where ``r = b - Ax``.\\n    r2norm : float\\n        ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\\n        if ``damp == 0``.\\n    anorm : float\\n        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\\n    acond : float\\n        Estimate of ``cond(Abar)``.\\n    arnorm : float\\n        Estimate of ``norm(A\\'@r - damp^2*(x - x0))``.\\n    xnorm : float\\n        ``norm(x)``\\n    var : ndarray of float\\n        If ``calc_var`` is True, estimates all diagonals of\\n        ``(A\\'A)^{-1}`` (if ``damp == 0``) or more generally ``(A\\'A +\\n        damp^2*I)^{-1}``.  This is well defined if A has full column\\n        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\\n        < n`` and ``damp = 0.``)\\n\\n    Notes\\n    -----\\n    LSQR uses an iterative method to approximate the solution.  The\\n    number of iterations required to reach a certain accuracy depends\\n    strongly on the scaling of the problem.  Poor scaling of the rows\\n    or columns of A should therefore be avoided where possible.\\n\\n    For example, in problem 1 the solution is unaltered by\\n    row-scaling.  If a row of A is very small or large compared to\\n    the other rows of A, the corresponding row of ( A  b ) should be\\n    scaled up or down.\\n\\n    In problems 1 and 2, the solution x is easily recovered\\n    following column-scaling.  Unless better information is known,\\n    the nonzero columns of A should be scaled so that they all have\\n    the same Euclidean norm (e.g., 1.0).\\n\\n    In problem 3, there is no freedom to re-scale if damp is\\n    nonzero.  However, the value of damp should be assigned only\\n    after attention has been paid to the scaling of A.\\n\\n    The parameter damp is intended to help regularize\\n    ill-conditioned systems, by preventing the true solution from\\n    being very large.  Another aid to regularization is provided by\\n    the parameter acond, which may be used to terminate iterations\\n    before the computed solution becomes very large.\\n\\n    If some initial estimate ``x0`` is known and if ``damp == 0``,\\n    one could proceed as follows:\\n\\n      1. Compute a residual vector ``r0 = b - A@x0``.\\n      2. Use LSQR to solve the system  ``A@dx = r0``.\\n      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\\n\\n    This requires that ``x0`` be available before and after the call\\n    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\\n    to solve A@x = b and k2 iterations to solve A@dx = r0.\\n    If x0 is \"good\", norm(r0) will be smaller than norm(b).\\n    If the same stopping tolerances atol and btol are used for each\\n    system, k1 and k2 will be similar, but the final solution x0 + dx\\n    should be more accurate.  The only way to reduce the total work\\n    is to use a larger stopping tolerance for the second system.\\n    If some value btol is suitable for A@x = b, the larger value\\n    btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\\n\\n    Preconditioning is another way to reduce the number of iterations.\\n    If it is possible to solve a related system ``M@x = b``\\n    efficiently, where M approximates A in some helpful way (e.g. M -\\n    A has low rank or its elements are small relative to those of A),\\n    LSQR may converge more rapidly on the system ``A@M(inverse)@z =\\n    b``, after which x can be recovered by solving M@x = z.\\n\\n    If A is symmetric, LSQR should not be used!\\n\\n    Alternatives are the symmetric conjugate-gradient method (cg)\\n    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\\n    applies to any symmetric A and will converge more rapidly than\\n    LSQR.  If A is positive definite, there are other implementations\\n    of symmetric cg that require slightly less work per iteration than\\n    SYMMLQ (but will take the same number of iterations).\\n\\n    References\\n    ----------\\n    .. [1] C. C. Paige and M. A. Saunders (1982a).\\n           \"LSQR: An algorithm for sparse linear equations and\\n           sparse least squares\", ACM TOMS 8(1), 43-71.\\n    .. [2] C. C. Paige and M. A. Saunders (1982b).\\n           \"Algorithm 583.  LSQR: Sparse linear equations and least\\n           squares problems\", ACM TOMS 8(2), 195-209.\\n    .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\\n           systems using LSQR and CRAIG\", BIT 35, 588-604.\\n\\n    Examples\\n    --------\\n    >>> import numpy as np\\n    >>> from scipy.sparse import csc_matrix\\n    >>> from scipy.sparse.linalg import lsqr\\n    >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\\n\\n    The first example has the trivial solution ``[0, 0]``\\n\\n    >>> b = np.array([0., 0., 0.], dtype=float)\\n    >>> x, istop, itn, normr = lsqr(A, b)[:4]\\n    >>> istop\\n    0\\n    >>> x\\n    array([ 0.,  0.])\\n\\n    The stopping code `istop=0` returned indicates that a vector of zeros was\\n    found as a solution. The returned solution `x` indeed contains\\n    ``[0., 0.]``. The next example has a non-trivial solution:\\n\\n    >>> b = np.array([1., 0., -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    1\\n    >>> x\\n    array([ 1., -1.])\\n    >>> itn\\n    1\\n    >>> r1norm\\n    4.440892098500627e-16\\n\\n    As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\\n    limits. The given solution ``[1., -1.]`` obviously solves the equation. The\\n    remaining return values include information about the number of iterations\\n    (`itn=1`) and the remaining difference of left and right side of the solved\\n    equation.\\n    The final example demonstrates the behavior in the case where there is no\\n    solution for the equation:\\n\\n    >>> b = np.array([1., 0.01, -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    2\\n    >>> x\\n    array([ 1.00333333, -0.99666667])\\n    >>> A.dot(x)-b\\n    array([ 0.00333333, -0.00333333,  0.00333333])\\n    >>> r1norm\\n    0.005773502691896255\\n\\n    `istop` indicates that the system is inconsistent and thus `x` is rather an\\n    approximate solution to the corresponding least-squares problem. `r1norm`\\n    contains the norm of the minimal residual that was found.\\n    '\n    A = aslinearoperator(A)\n    b = np.atleast_1d(b)\n    if b.ndim > 1:\n        b = b.squeeze()\n    (m, n) = A.shape\n    if iter_lim is None:\n        iter_lim = 2 * n\n    var = np.zeros(n)\n    msg = ('The exact solution is  x = 0                              ', 'Ax - b is small enough, given atol, btol                  ', 'The least-squares solution is good enough, given atol     ', 'The estimate of cond(Abar) has exceeded conlim            ', 'Ax - b is small enough for this machine                   ', 'The least-squares solution is good enough for this machine', 'Cond(Abar) seems to be too large for this machine         ', 'The iteration limit has been reached                      ')\n    if show:\n        print(' ')\n        print('LSQR            Least-squares solution of  Ax = b')\n        str1 = f'The matrix A has {m} rows and {n} columns'\n        str2 = f'damp = {damp:20.14e}   calc_var = {calc_var:8g}'\n        str3 = f'atol = {atol:8.2e}                 conlim = {conlim:8.2e}'\n        str4 = f'btol = {btol:8.2e}               iter_lim = {iter_lim:8g}'\n        print(str1)\n        print(str2)\n        print(str3)\n        print(str4)\n    itn = 0\n    istop = 0\n    ctol = 0\n    if conlim > 0:\n        ctol = 1 / conlim\n    anorm = 0\n    acond = 0\n    dampsq = damp ** 2\n    ddnorm = 0\n    res2 = 0\n    xnorm = 0\n    xxnorm = 0\n    z = 0\n    cs2 = -1\n    sn2 = 0\n    u = b\n    bnorm = np.linalg.norm(b)\n    if x0 is None:\n        x = np.zeros(n)\n        beta = bnorm.copy()\n    else:\n        x = np.asarray(x0)\n        u = u - A.matvec(x)\n        beta = np.linalg.norm(u)\n    if beta > 0:\n        u = 1 / beta * u\n        v = A.rmatvec(u)\n        alfa = np.linalg.norm(v)\n    else:\n        v = x.copy()\n        alfa = 0\n    if alfa > 0:\n        v = 1 / alfa * v\n    w = v.copy()\n    rhobar = alfa\n    phibar = beta\n    rnorm = beta\n    r1norm = rnorm\n    r2norm = rnorm\n    arnorm = alfa * beta\n    if arnorm == 0:\n        if show:\n            print(msg[0])\n        return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)\n    head1 = '   Itn      x[0]       r1norm     r2norm '\n    head2 = ' Compatible    LS      Norm A   Cond A'\n    if show:\n        print(' ')\n        print(head1, head2)\n        test1 = 1\n        test2 = alfa / beta\n        str1 = f'{itn:6g} {x[0]:12.5e}'\n        str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n        str3 = f'  {test1:8.1e} {test2:8.1e}'\n        print(str1, str2, str3)\n    while itn < iter_lim:\n        itn = itn + 1\n        u = A.matvec(v) - alfa * u\n        beta = np.linalg.norm(u)\n        if beta > 0:\n            u = 1 / beta * u\n            anorm = sqrt(anorm ** 2 + alfa ** 2 + beta ** 2 + dampsq)\n            v = A.rmatvec(u) - beta * v\n            alfa = np.linalg.norm(v)\n            if alfa > 0:\n                v = 1 / alfa * v\n        if damp > 0:\n            rhobar1 = sqrt(rhobar ** 2 + dampsq)\n            cs1 = rhobar / rhobar1\n            sn1 = damp / rhobar1\n            psi = sn1 * phibar\n            phibar = cs1 * phibar\n        else:\n            rhobar1 = rhobar\n            psi = 0.0\n        (cs, sn, rho) = _sym_ortho(rhobar1, beta)\n        theta = sn * alfa\n        rhobar = -cs * alfa\n        phi = cs * phibar\n        phibar = sn * phibar\n        tau = sn * phi\n        t1 = phi / rho\n        t2 = -theta / rho\n        dk = 1 / rho * w\n        x = x + t1 * w\n        w = v + t2 * w\n        ddnorm = ddnorm + np.linalg.norm(dk) ** 2\n        if calc_var:\n            var = var + dk ** 2\n        delta = sn2 * rho\n        gambar = -cs2 * rho\n        rhs = phi - delta * z\n        zbar = rhs / gambar\n        xnorm = sqrt(xxnorm + zbar ** 2)\n        gamma = sqrt(gambar ** 2 + theta ** 2)\n        cs2 = gambar / gamma\n        sn2 = theta / gamma\n        z = rhs / gamma\n        xxnorm = xxnorm + z ** 2\n        acond = anorm * sqrt(ddnorm)\n        res1 = phibar ** 2\n        res2 = res2 + psi ** 2\n        rnorm = sqrt(res1 + res2)\n        arnorm = alfa * abs(tau)\n        if damp > 0:\n            r1sq = rnorm ** 2 - dampsq * xxnorm\n            r1norm = sqrt(abs(r1sq))\n            if r1sq < 0:\n                r1norm = -r1norm\n        else:\n            r1norm = rnorm\n        r2norm = rnorm\n        test1 = rnorm / bnorm\n        test2 = arnorm / (anorm * rnorm + eps)\n        test3 = 1 / (acond + eps)\n        t1 = test1 / (1 + anorm * xnorm / bnorm)\n        rtol = btol + atol * anorm * xnorm / bnorm\n        if itn >= iter_lim:\n            istop = 7\n        if 1 + test3 <= 1:\n            istop = 6\n        if 1 + test2 <= 1:\n            istop = 5\n        if 1 + t1 <= 1:\n            istop = 4\n        if test3 <= ctol:\n            istop = 3\n        if test2 <= atol:\n            istop = 2\n        if test1 <= rtol:\n            istop = 1\n        if show:\n            prnt = False\n            if n <= 40:\n                prnt = True\n            if itn <= 10:\n                prnt = True\n            if itn >= iter_lim - 10:\n                prnt = True\n            if test3 <= 2 * ctol:\n                prnt = True\n            if test2 <= 10 * atol:\n                prnt = True\n            if test1 <= 10 * rtol:\n                prnt = True\n            if istop != 0:\n                prnt = True\n            if prnt:\n                str1 = f'{itn:6g} {x[0]:12.5e}'\n                str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n                str3 = f'  {test1:8.1e} {test2:8.1e}'\n                str4 = f' {anorm:8.1e} {acond:8.1e}'\n                print(str1, str2, str3, str4)\n        if istop != 0:\n            break\n    if show:\n        print(' ')\n        print('LSQR finished')\n        print(msg[istop])\n        print(' ')\n        str1 = f'istop ={istop:8g}   r1norm ={r1norm:8.1e}'\n        str2 = f'anorm ={anorm:8.1e}   arnorm ={arnorm:8.1e}'\n        str3 = f'itn   ={itn:8g}   r2norm ={r2norm:8.1e}'\n        str4 = f'acond ={acond:8.1e}   xnorm  ={xnorm:8.1e}'\n        print(str1 + '   ' + str2)\n        print(str3 + '   ' + str4)\n        print(' ')\n    return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)",
            "def lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Find the least-squares solution to a large, sparse, linear system\\n    of equations.\\n\\n    The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\\n    ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\\n\\n    The matrix A may be square or rectangular (over-determined or\\n    under-determined), and may have any rank.\\n\\n    ::\\n\\n      1. Unsymmetric equations --    solve  Ax = b\\n\\n      2. Linear least squares  --    solve  Ax = b\\n                                     in the least-squares sense\\n\\n      3. Damped least squares  --    solve  (   A    )*x = (    b    )\\n                                            ( damp*I )     ( damp*x0 )\\n                                     in the least-squares sense\\n\\n    Parameters\\n    ----------\\n    A : {sparse matrix, ndarray, LinearOperator}\\n        Representation of an m-by-n matrix.\\n        Alternatively, ``A`` can be a linear operator which can\\n        produce ``Ax`` and ``A^T x`` using, e.g.,\\n        ``scipy.sparse.linalg.LinearOperator``.\\n    b : array_like, shape (m,)\\n        Right-hand side vector ``b``.\\n    damp : float\\n        Damping coefficient. Default is 0.\\n    atol, btol : float, optional\\n        Stopping tolerances. `lsqr` continues iterations until a\\n        certain backward error estimate is smaller than some quantity\\n        depending on atol and btol.  Let ``r = b - Ax`` be the\\n        residual vector for the current approximate solution ``x``.\\n        If ``Ax = b`` seems to be consistent, `lsqr` terminates\\n        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\\n        Otherwise, `lsqr` terminates when ``norm(A^H r) <=\\n        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\\n        the final ``norm(r)`` should be accurate to about 6\\n        digits. (The final ``x`` will usually have fewer correct digits,\\n        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\\n        or `btol` is None, a default value of 1.0e-6 will be used.\\n        Ideally, they should be estimates of the relative error in the\\n        entries of ``A`` and ``b`` respectively.  For example, if the entries\\n        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\\n        the algorithm from doing unnecessary work beyond the\\n        uncertainty of the input data.\\n    conlim : float, optional\\n        Another stopping tolerance.  lsqr terminates if an estimate of\\n        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\\n        b``, `conlim` could be as large as 1.0e+12 (say).  For\\n        least-squares problems, conlim should be less than 1.0e+8.\\n        Maximum precision can be obtained by setting ``atol = btol =\\n        conlim = zero``, but the number of iterations may then be\\n        excessive. Default is 1e8.\\n    iter_lim : int, optional\\n        Explicit limitation on number of iterations (for safety).\\n    show : bool, optional\\n        Display an iteration log. Default is False.\\n    calc_var : bool, optional\\n        Whether to estimate diagonals of ``(A\\'A + damp^2*I)^{-1}``.\\n    x0 : array_like, shape (n,), optional\\n        Initial guess of x, if None zeros are used. Default is None.\\n\\n        .. versionadded:: 1.0.0\\n\\n    Returns\\n    -------\\n    x : ndarray of float\\n        The final solution.\\n    istop : int\\n        Gives the reason for termination.\\n        1 means x is an approximate solution to Ax = b.\\n        2 means x approximately solves the least-squares problem.\\n    itn : int\\n        Iteration number upon termination.\\n    r1norm : float\\n        ``norm(r)``, where ``r = b - Ax``.\\n    r2norm : float\\n        ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\\n        if ``damp == 0``.\\n    anorm : float\\n        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\\n    acond : float\\n        Estimate of ``cond(Abar)``.\\n    arnorm : float\\n        Estimate of ``norm(A\\'@r - damp^2*(x - x0))``.\\n    xnorm : float\\n        ``norm(x)``\\n    var : ndarray of float\\n        If ``calc_var`` is True, estimates all diagonals of\\n        ``(A\\'A)^{-1}`` (if ``damp == 0``) or more generally ``(A\\'A +\\n        damp^2*I)^{-1}``.  This is well defined if A has full column\\n        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\\n        < n`` and ``damp = 0.``)\\n\\n    Notes\\n    -----\\n    LSQR uses an iterative method to approximate the solution.  The\\n    number of iterations required to reach a certain accuracy depends\\n    strongly on the scaling of the problem.  Poor scaling of the rows\\n    or columns of A should therefore be avoided where possible.\\n\\n    For example, in problem 1 the solution is unaltered by\\n    row-scaling.  If a row of A is very small or large compared to\\n    the other rows of A, the corresponding row of ( A  b ) should be\\n    scaled up or down.\\n\\n    In problems 1 and 2, the solution x is easily recovered\\n    following column-scaling.  Unless better information is known,\\n    the nonzero columns of A should be scaled so that they all have\\n    the same Euclidean norm (e.g., 1.0).\\n\\n    In problem 3, there is no freedom to re-scale if damp is\\n    nonzero.  However, the value of damp should be assigned only\\n    after attention has been paid to the scaling of A.\\n\\n    The parameter damp is intended to help regularize\\n    ill-conditioned systems, by preventing the true solution from\\n    being very large.  Another aid to regularization is provided by\\n    the parameter acond, which may be used to terminate iterations\\n    before the computed solution becomes very large.\\n\\n    If some initial estimate ``x0`` is known and if ``damp == 0``,\\n    one could proceed as follows:\\n\\n      1. Compute a residual vector ``r0 = b - A@x0``.\\n      2. Use LSQR to solve the system  ``A@dx = r0``.\\n      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\\n\\n    This requires that ``x0`` be available before and after the call\\n    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\\n    to solve A@x = b and k2 iterations to solve A@dx = r0.\\n    If x0 is \"good\", norm(r0) will be smaller than norm(b).\\n    If the same stopping tolerances atol and btol are used for each\\n    system, k1 and k2 will be similar, but the final solution x0 + dx\\n    should be more accurate.  The only way to reduce the total work\\n    is to use a larger stopping tolerance for the second system.\\n    If some value btol is suitable for A@x = b, the larger value\\n    btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\\n\\n    Preconditioning is another way to reduce the number of iterations.\\n    If it is possible to solve a related system ``M@x = b``\\n    efficiently, where M approximates A in some helpful way (e.g. M -\\n    A has low rank or its elements are small relative to those of A),\\n    LSQR may converge more rapidly on the system ``A@M(inverse)@z =\\n    b``, after which x can be recovered by solving M@x = z.\\n\\n    If A is symmetric, LSQR should not be used!\\n\\n    Alternatives are the symmetric conjugate-gradient method (cg)\\n    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\\n    applies to any symmetric A and will converge more rapidly than\\n    LSQR.  If A is positive definite, there are other implementations\\n    of symmetric cg that require slightly less work per iteration than\\n    SYMMLQ (but will take the same number of iterations).\\n\\n    References\\n    ----------\\n    .. [1] C. C. Paige and M. A. Saunders (1982a).\\n           \"LSQR: An algorithm for sparse linear equations and\\n           sparse least squares\", ACM TOMS 8(1), 43-71.\\n    .. [2] C. C. Paige and M. A. Saunders (1982b).\\n           \"Algorithm 583.  LSQR: Sparse linear equations and least\\n           squares problems\", ACM TOMS 8(2), 195-209.\\n    .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\\n           systems using LSQR and CRAIG\", BIT 35, 588-604.\\n\\n    Examples\\n    --------\\n    >>> import numpy as np\\n    >>> from scipy.sparse import csc_matrix\\n    >>> from scipy.sparse.linalg import lsqr\\n    >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\\n\\n    The first example has the trivial solution ``[0, 0]``\\n\\n    >>> b = np.array([0., 0., 0.], dtype=float)\\n    >>> x, istop, itn, normr = lsqr(A, b)[:4]\\n    >>> istop\\n    0\\n    >>> x\\n    array([ 0.,  0.])\\n\\n    The stopping code `istop=0` returned indicates that a vector of zeros was\\n    found as a solution. The returned solution `x` indeed contains\\n    ``[0., 0.]``. The next example has a non-trivial solution:\\n\\n    >>> b = np.array([1., 0., -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    1\\n    >>> x\\n    array([ 1., -1.])\\n    >>> itn\\n    1\\n    >>> r1norm\\n    4.440892098500627e-16\\n\\n    As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\\n    limits. The given solution ``[1., -1.]`` obviously solves the equation. The\\n    remaining return values include information about the number of iterations\\n    (`itn=1`) and the remaining difference of left and right side of the solved\\n    equation.\\n    The final example demonstrates the behavior in the case where there is no\\n    solution for the equation:\\n\\n    >>> b = np.array([1., 0.01, -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    2\\n    >>> x\\n    array([ 1.00333333, -0.99666667])\\n    >>> A.dot(x)-b\\n    array([ 0.00333333, -0.00333333,  0.00333333])\\n    >>> r1norm\\n    0.005773502691896255\\n\\n    `istop` indicates that the system is inconsistent and thus `x` is rather an\\n    approximate solution to the corresponding least-squares problem. `r1norm`\\n    contains the norm of the minimal residual that was found.\\n    '\n    A = aslinearoperator(A)\n    b = np.atleast_1d(b)\n    if b.ndim > 1:\n        b = b.squeeze()\n    (m, n) = A.shape\n    if iter_lim is None:\n        iter_lim = 2 * n\n    var = np.zeros(n)\n    msg = ('The exact solution is  x = 0                              ', 'Ax - b is small enough, given atol, btol                  ', 'The least-squares solution is good enough, given atol     ', 'The estimate of cond(Abar) has exceeded conlim            ', 'Ax - b is small enough for this machine                   ', 'The least-squares solution is good enough for this machine', 'Cond(Abar) seems to be too large for this machine         ', 'The iteration limit has been reached                      ')\n    if show:\n        print(' ')\n        print('LSQR            Least-squares solution of  Ax = b')\n        str1 = f'The matrix A has {m} rows and {n} columns'\n        str2 = f'damp = {damp:20.14e}   calc_var = {calc_var:8g}'\n        str3 = f'atol = {atol:8.2e}                 conlim = {conlim:8.2e}'\n        str4 = f'btol = {btol:8.2e}               iter_lim = {iter_lim:8g}'\n        print(str1)\n        print(str2)\n        print(str3)\n        print(str4)\n    itn = 0\n    istop = 0\n    ctol = 0\n    if conlim > 0:\n        ctol = 1 / conlim\n    anorm = 0\n    acond = 0\n    dampsq = damp ** 2\n    ddnorm = 0\n    res2 = 0\n    xnorm = 0\n    xxnorm = 0\n    z = 0\n    cs2 = -1\n    sn2 = 0\n    u = b\n    bnorm = np.linalg.norm(b)\n    if x0 is None:\n        x = np.zeros(n)\n        beta = bnorm.copy()\n    else:\n        x = np.asarray(x0)\n        u = u - A.matvec(x)\n        beta = np.linalg.norm(u)\n    if beta > 0:\n        u = 1 / beta * u\n        v = A.rmatvec(u)\n        alfa = np.linalg.norm(v)\n    else:\n        v = x.copy()\n        alfa = 0\n    if alfa > 0:\n        v = 1 / alfa * v\n    w = v.copy()\n    rhobar = alfa\n    phibar = beta\n    rnorm = beta\n    r1norm = rnorm\n    r2norm = rnorm\n    arnorm = alfa * beta\n    if arnorm == 0:\n        if show:\n            print(msg[0])\n        return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)\n    head1 = '   Itn      x[0]       r1norm     r2norm '\n    head2 = ' Compatible    LS      Norm A   Cond A'\n    if show:\n        print(' ')\n        print(head1, head2)\n        test1 = 1\n        test2 = alfa / beta\n        str1 = f'{itn:6g} {x[0]:12.5e}'\n        str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n        str3 = f'  {test1:8.1e} {test2:8.1e}'\n        print(str1, str2, str3)\n    while itn < iter_lim:\n        itn = itn + 1\n        u = A.matvec(v) - alfa * u\n        beta = np.linalg.norm(u)\n        if beta > 0:\n            u = 1 / beta * u\n            anorm = sqrt(anorm ** 2 + alfa ** 2 + beta ** 2 + dampsq)\n            v = A.rmatvec(u) - beta * v\n            alfa = np.linalg.norm(v)\n            if alfa > 0:\n                v = 1 / alfa * v\n        if damp > 0:\n            rhobar1 = sqrt(rhobar ** 2 + dampsq)\n            cs1 = rhobar / rhobar1\n            sn1 = damp / rhobar1\n            psi = sn1 * phibar\n            phibar = cs1 * phibar\n        else:\n            rhobar1 = rhobar\n            psi = 0.0\n        (cs, sn, rho) = _sym_ortho(rhobar1, beta)\n        theta = sn * alfa\n        rhobar = -cs * alfa\n        phi = cs * phibar\n        phibar = sn * phibar\n        tau = sn * phi\n        t1 = phi / rho\n        t2 = -theta / rho\n        dk = 1 / rho * w\n        x = x + t1 * w\n        w = v + t2 * w\n        ddnorm = ddnorm + np.linalg.norm(dk) ** 2\n        if calc_var:\n            var = var + dk ** 2\n        delta = sn2 * rho\n        gambar = -cs2 * rho\n        rhs = phi - delta * z\n        zbar = rhs / gambar\n        xnorm = sqrt(xxnorm + zbar ** 2)\n        gamma = sqrt(gambar ** 2 + theta ** 2)\n        cs2 = gambar / gamma\n        sn2 = theta / gamma\n        z = rhs / gamma\n        xxnorm = xxnorm + z ** 2\n        acond = anorm * sqrt(ddnorm)\n        res1 = phibar ** 2\n        res2 = res2 + psi ** 2\n        rnorm = sqrt(res1 + res2)\n        arnorm = alfa * abs(tau)\n        if damp > 0:\n            r1sq = rnorm ** 2 - dampsq * xxnorm\n            r1norm = sqrt(abs(r1sq))\n            if r1sq < 0:\n                r1norm = -r1norm\n        else:\n            r1norm = rnorm\n        r2norm = rnorm\n        test1 = rnorm / bnorm\n        test2 = arnorm / (anorm * rnorm + eps)\n        test3 = 1 / (acond + eps)\n        t1 = test1 / (1 + anorm * xnorm / bnorm)\n        rtol = btol + atol * anorm * xnorm / bnorm\n        if itn >= iter_lim:\n            istop = 7\n        if 1 + test3 <= 1:\n            istop = 6\n        if 1 + test2 <= 1:\n            istop = 5\n        if 1 + t1 <= 1:\n            istop = 4\n        if test3 <= ctol:\n            istop = 3\n        if test2 <= atol:\n            istop = 2\n        if test1 <= rtol:\n            istop = 1\n        if show:\n            prnt = False\n            if n <= 40:\n                prnt = True\n            if itn <= 10:\n                prnt = True\n            if itn >= iter_lim - 10:\n                prnt = True\n            if test3 <= 2 * ctol:\n                prnt = True\n            if test2 <= 10 * atol:\n                prnt = True\n            if test1 <= 10 * rtol:\n                prnt = True\n            if istop != 0:\n                prnt = True\n            if prnt:\n                str1 = f'{itn:6g} {x[0]:12.5e}'\n                str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n                str3 = f'  {test1:8.1e} {test2:8.1e}'\n                str4 = f' {anorm:8.1e} {acond:8.1e}'\n                print(str1, str2, str3, str4)\n        if istop != 0:\n            break\n    if show:\n        print(' ')\n        print('LSQR finished')\n        print(msg[istop])\n        print(' ')\n        str1 = f'istop ={istop:8g}   r1norm ={r1norm:8.1e}'\n        str2 = f'anorm ={anorm:8.1e}   arnorm ={arnorm:8.1e}'\n        str3 = f'itn   ={itn:8g}   r2norm ={r2norm:8.1e}'\n        str4 = f'acond ={acond:8.1e}   xnorm  ={xnorm:8.1e}'\n        print(str1 + '   ' + str2)\n        print(str3 + '   ' + str4)\n        print(' ')\n    return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)",
            "def lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Find the least-squares solution to a large, sparse, linear system\\n    of equations.\\n\\n    The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\\n    ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\\n\\n    The matrix A may be square or rectangular (over-determined or\\n    under-determined), and may have any rank.\\n\\n    ::\\n\\n      1. Unsymmetric equations --    solve  Ax = b\\n\\n      2. Linear least squares  --    solve  Ax = b\\n                                     in the least-squares sense\\n\\n      3. Damped least squares  --    solve  (   A    )*x = (    b    )\\n                                            ( damp*I )     ( damp*x0 )\\n                                     in the least-squares sense\\n\\n    Parameters\\n    ----------\\n    A : {sparse matrix, ndarray, LinearOperator}\\n        Representation of an m-by-n matrix.\\n        Alternatively, ``A`` can be a linear operator which can\\n        produce ``Ax`` and ``A^T x`` using, e.g.,\\n        ``scipy.sparse.linalg.LinearOperator``.\\n    b : array_like, shape (m,)\\n        Right-hand side vector ``b``.\\n    damp : float\\n        Damping coefficient. Default is 0.\\n    atol, btol : float, optional\\n        Stopping tolerances. `lsqr` continues iterations until a\\n        certain backward error estimate is smaller than some quantity\\n        depending on atol and btol.  Let ``r = b - Ax`` be the\\n        residual vector for the current approximate solution ``x``.\\n        If ``Ax = b`` seems to be consistent, `lsqr` terminates\\n        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\\n        Otherwise, `lsqr` terminates when ``norm(A^H r) <=\\n        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\\n        the final ``norm(r)`` should be accurate to about 6\\n        digits. (The final ``x`` will usually have fewer correct digits,\\n        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\\n        or `btol` is None, a default value of 1.0e-6 will be used.\\n        Ideally, they should be estimates of the relative error in the\\n        entries of ``A`` and ``b`` respectively.  For example, if the entries\\n        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\\n        the algorithm from doing unnecessary work beyond the\\n        uncertainty of the input data.\\n    conlim : float, optional\\n        Another stopping tolerance.  lsqr terminates if an estimate of\\n        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\\n        b``, `conlim` could be as large as 1.0e+12 (say).  For\\n        least-squares problems, conlim should be less than 1.0e+8.\\n        Maximum precision can be obtained by setting ``atol = btol =\\n        conlim = zero``, but the number of iterations may then be\\n        excessive. Default is 1e8.\\n    iter_lim : int, optional\\n        Explicit limitation on number of iterations (for safety).\\n    show : bool, optional\\n        Display an iteration log. Default is False.\\n    calc_var : bool, optional\\n        Whether to estimate diagonals of ``(A\\'A + damp^2*I)^{-1}``.\\n    x0 : array_like, shape (n,), optional\\n        Initial guess of x, if None zeros are used. Default is None.\\n\\n        .. versionadded:: 1.0.0\\n\\n    Returns\\n    -------\\n    x : ndarray of float\\n        The final solution.\\n    istop : int\\n        Gives the reason for termination.\\n        1 means x is an approximate solution to Ax = b.\\n        2 means x approximately solves the least-squares problem.\\n    itn : int\\n        Iteration number upon termination.\\n    r1norm : float\\n        ``norm(r)``, where ``r = b - Ax``.\\n    r2norm : float\\n        ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\\n        if ``damp == 0``.\\n    anorm : float\\n        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\\n    acond : float\\n        Estimate of ``cond(Abar)``.\\n    arnorm : float\\n        Estimate of ``norm(A\\'@r - damp^2*(x - x0))``.\\n    xnorm : float\\n        ``norm(x)``\\n    var : ndarray of float\\n        If ``calc_var`` is True, estimates all diagonals of\\n        ``(A\\'A)^{-1}`` (if ``damp == 0``) or more generally ``(A\\'A +\\n        damp^2*I)^{-1}``.  This is well defined if A has full column\\n        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\\n        < n`` and ``damp = 0.``)\\n\\n    Notes\\n    -----\\n    LSQR uses an iterative method to approximate the solution.  The\\n    number of iterations required to reach a certain accuracy depends\\n    strongly on the scaling of the problem.  Poor scaling of the rows\\n    or columns of A should therefore be avoided where possible.\\n\\n    For example, in problem 1 the solution is unaltered by\\n    row-scaling.  If a row of A is very small or large compared to\\n    the other rows of A, the corresponding row of ( A  b ) should be\\n    scaled up or down.\\n\\n    In problems 1 and 2, the solution x is easily recovered\\n    following column-scaling.  Unless better information is known,\\n    the nonzero columns of A should be scaled so that they all have\\n    the same Euclidean norm (e.g., 1.0).\\n\\n    In problem 3, there is no freedom to re-scale if damp is\\n    nonzero.  However, the value of damp should be assigned only\\n    after attention has been paid to the scaling of A.\\n\\n    The parameter damp is intended to help regularize\\n    ill-conditioned systems, by preventing the true solution from\\n    being very large.  Another aid to regularization is provided by\\n    the parameter acond, which may be used to terminate iterations\\n    before the computed solution becomes very large.\\n\\n    If some initial estimate ``x0`` is known and if ``damp == 0``,\\n    one could proceed as follows:\\n\\n      1. Compute a residual vector ``r0 = b - A@x0``.\\n      2. Use LSQR to solve the system  ``A@dx = r0``.\\n      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\\n\\n    This requires that ``x0`` be available before and after the call\\n    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\\n    to solve A@x = b and k2 iterations to solve A@dx = r0.\\n    If x0 is \"good\", norm(r0) will be smaller than norm(b).\\n    If the same stopping tolerances atol and btol are used for each\\n    system, k1 and k2 will be similar, but the final solution x0 + dx\\n    should be more accurate.  The only way to reduce the total work\\n    is to use a larger stopping tolerance for the second system.\\n    If some value btol is suitable for A@x = b, the larger value\\n    btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\\n\\n    Preconditioning is another way to reduce the number of iterations.\\n    If it is possible to solve a related system ``M@x = b``\\n    efficiently, where M approximates A in some helpful way (e.g. M -\\n    A has low rank or its elements are small relative to those of A),\\n    LSQR may converge more rapidly on the system ``A@M(inverse)@z =\\n    b``, after which x can be recovered by solving M@x = z.\\n\\n    If A is symmetric, LSQR should not be used!\\n\\n    Alternatives are the symmetric conjugate-gradient method (cg)\\n    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\\n    applies to any symmetric A and will converge more rapidly than\\n    LSQR.  If A is positive definite, there are other implementations\\n    of symmetric cg that require slightly less work per iteration than\\n    SYMMLQ (but will take the same number of iterations).\\n\\n    References\\n    ----------\\n    .. [1] C. C. Paige and M. A. Saunders (1982a).\\n           \"LSQR: An algorithm for sparse linear equations and\\n           sparse least squares\", ACM TOMS 8(1), 43-71.\\n    .. [2] C. C. Paige and M. A. Saunders (1982b).\\n           \"Algorithm 583.  LSQR: Sparse linear equations and least\\n           squares problems\", ACM TOMS 8(2), 195-209.\\n    .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\\n           systems using LSQR and CRAIG\", BIT 35, 588-604.\\n\\n    Examples\\n    --------\\n    >>> import numpy as np\\n    >>> from scipy.sparse import csc_matrix\\n    >>> from scipy.sparse.linalg import lsqr\\n    >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\\n\\n    The first example has the trivial solution ``[0, 0]``\\n\\n    >>> b = np.array([0., 0., 0.], dtype=float)\\n    >>> x, istop, itn, normr = lsqr(A, b)[:4]\\n    >>> istop\\n    0\\n    >>> x\\n    array([ 0.,  0.])\\n\\n    The stopping code `istop=0` returned indicates that a vector of zeros was\\n    found as a solution. The returned solution `x` indeed contains\\n    ``[0., 0.]``. The next example has a non-trivial solution:\\n\\n    >>> b = np.array([1., 0., -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    1\\n    >>> x\\n    array([ 1., -1.])\\n    >>> itn\\n    1\\n    >>> r1norm\\n    4.440892098500627e-16\\n\\n    As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\\n    limits. The given solution ``[1., -1.]`` obviously solves the equation. The\\n    remaining return values include information about the number of iterations\\n    (`itn=1`) and the remaining difference of left and right side of the solved\\n    equation.\\n    The final example demonstrates the behavior in the case where there is no\\n    solution for the equation:\\n\\n    >>> b = np.array([1., 0.01, -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    2\\n    >>> x\\n    array([ 1.00333333, -0.99666667])\\n    >>> A.dot(x)-b\\n    array([ 0.00333333, -0.00333333,  0.00333333])\\n    >>> r1norm\\n    0.005773502691896255\\n\\n    `istop` indicates that the system is inconsistent and thus `x` is rather an\\n    approximate solution to the corresponding least-squares problem. `r1norm`\\n    contains the norm of the minimal residual that was found.\\n    '\n    A = aslinearoperator(A)\n    b = np.atleast_1d(b)\n    if b.ndim > 1:\n        b = b.squeeze()\n    (m, n) = A.shape\n    if iter_lim is None:\n        iter_lim = 2 * n\n    var = np.zeros(n)\n    msg = ('The exact solution is  x = 0                              ', 'Ax - b is small enough, given atol, btol                  ', 'The least-squares solution is good enough, given atol     ', 'The estimate of cond(Abar) has exceeded conlim            ', 'Ax - b is small enough for this machine                   ', 'The least-squares solution is good enough for this machine', 'Cond(Abar) seems to be too large for this machine         ', 'The iteration limit has been reached                      ')\n    if show:\n        print(' ')\n        print('LSQR            Least-squares solution of  Ax = b')\n        str1 = f'The matrix A has {m} rows and {n} columns'\n        str2 = f'damp = {damp:20.14e}   calc_var = {calc_var:8g}'\n        str3 = f'atol = {atol:8.2e}                 conlim = {conlim:8.2e}'\n        str4 = f'btol = {btol:8.2e}               iter_lim = {iter_lim:8g}'\n        print(str1)\n        print(str2)\n        print(str3)\n        print(str4)\n    itn = 0\n    istop = 0\n    ctol = 0\n    if conlim > 0:\n        ctol = 1 / conlim\n    anorm = 0\n    acond = 0\n    dampsq = damp ** 2\n    ddnorm = 0\n    res2 = 0\n    xnorm = 0\n    xxnorm = 0\n    z = 0\n    cs2 = -1\n    sn2 = 0\n    u = b\n    bnorm = np.linalg.norm(b)\n    if x0 is None:\n        x = np.zeros(n)\n        beta = bnorm.copy()\n    else:\n        x = np.asarray(x0)\n        u = u - A.matvec(x)\n        beta = np.linalg.norm(u)\n    if beta > 0:\n        u = 1 / beta * u\n        v = A.rmatvec(u)\n        alfa = np.linalg.norm(v)\n    else:\n        v = x.copy()\n        alfa = 0\n    if alfa > 0:\n        v = 1 / alfa * v\n    w = v.copy()\n    rhobar = alfa\n    phibar = beta\n    rnorm = beta\n    r1norm = rnorm\n    r2norm = rnorm\n    arnorm = alfa * beta\n    if arnorm == 0:\n        if show:\n            print(msg[0])\n        return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)\n    head1 = '   Itn      x[0]       r1norm     r2norm '\n    head2 = ' Compatible    LS      Norm A   Cond A'\n    if show:\n        print(' ')\n        print(head1, head2)\n        test1 = 1\n        test2 = alfa / beta\n        str1 = f'{itn:6g} {x[0]:12.5e}'\n        str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n        str3 = f'  {test1:8.1e} {test2:8.1e}'\n        print(str1, str2, str3)\n    while itn < iter_lim:\n        itn = itn + 1\n        u = A.matvec(v) - alfa * u\n        beta = np.linalg.norm(u)\n        if beta > 0:\n            u = 1 / beta * u\n            anorm = sqrt(anorm ** 2 + alfa ** 2 + beta ** 2 + dampsq)\n            v = A.rmatvec(u) - beta * v\n            alfa = np.linalg.norm(v)\n            if alfa > 0:\n                v = 1 / alfa * v\n        if damp > 0:\n            rhobar1 = sqrt(rhobar ** 2 + dampsq)\n            cs1 = rhobar / rhobar1\n            sn1 = damp / rhobar1\n            psi = sn1 * phibar\n            phibar = cs1 * phibar\n        else:\n            rhobar1 = rhobar\n            psi = 0.0\n        (cs, sn, rho) = _sym_ortho(rhobar1, beta)\n        theta = sn * alfa\n        rhobar = -cs * alfa\n        phi = cs * phibar\n        phibar = sn * phibar\n        tau = sn * phi\n        t1 = phi / rho\n        t2 = -theta / rho\n        dk = 1 / rho * w\n        x = x + t1 * w\n        w = v + t2 * w\n        ddnorm = ddnorm + np.linalg.norm(dk) ** 2\n        if calc_var:\n            var = var + dk ** 2\n        delta = sn2 * rho\n        gambar = -cs2 * rho\n        rhs = phi - delta * z\n        zbar = rhs / gambar\n        xnorm = sqrt(xxnorm + zbar ** 2)\n        gamma = sqrt(gambar ** 2 + theta ** 2)\n        cs2 = gambar / gamma\n        sn2 = theta / gamma\n        z = rhs / gamma\n        xxnorm = xxnorm + z ** 2\n        acond = anorm * sqrt(ddnorm)\n        res1 = phibar ** 2\n        res2 = res2 + psi ** 2\n        rnorm = sqrt(res1 + res2)\n        arnorm = alfa * abs(tau)\n        if damp > 0:\n            r1sq = rnorm ** 2 - dampsq * xxnorm\n            r1norm = sqrt(abs(r1sq))\n            if r1sq < 0:\n                r1norm = -r1norm\n        else:\n            r1norm = rnorm\n        r2norm = rnorm\n        test1 = rnorm / bnorm\n        test2 = arnorm / (anorm * rnorm + eps)\n        test3 = 1 / (acond + eps)\n        t1 = test1 / (1 + anorm * xnorm / bnorm)\n        rtol = btol + atol * anorm * xnorm / bnorm\n        if itn >= iter_lim:\n            istop = 7\n        if 1 + test3 <= 1:\n            istop = 6\n        if 1 + test2 <= 1:\n            istop = 5\n        if 1 + t1 <= 1:\n            istop = 4\n        if test3 <= ctol:\n            istop = 3\n        if test2 <= atol:\n            istop = 2\n        if test1 <= rtol:\n            istop = 1\n        if show:\n            prnt = False\n            if n <= 40:\n                prnt = True\n            if itn <= 10:\n                prnt = True\n            if itn >= iter_lim - 10:\n                prnt = True\n            if test3 <= 2 * ctol:\n                prnt = True\n            if test2 <= 10 * atol:\n                prnt = True\n            if test1 <= 10 * rtol:\n                prnt = True\n            if istop != 0:\n                prnt = True\n            if prnt:\n                str1 = f'{itn:6g} {x[0]:12.5e}'\n                str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n                str3 = f'  {test1:8.1e} {test2:8.1e}'\n                str4 = f' {anorm:8.1e} {acond:8.1e}'\n                print(str1, str2, str3, str4)\n        if istop != 0:\n            break\n    if show:\n        print(' ')\n        print('LSQR finished')\n        print(msg[istop])\n        print(' ')\n        str1 = f'istop ={istop:8g}   r1norm ={r1norm:8.1e}'\n        str2 = f'anorm ={anorm:8.1e}   arnorm ={arnorm:8.1e}'\n        str3 = f'itn   ={itn:8g}   r2norm ={r2norm:8.1e}'\n        str4 = f'acond ={acond:8.1e}   xnorm  ={xnorm:8.1e}'\n        print(str1 + '   ' + str2)\n        print(str3 + '   ' + str4)\n        print(' ')\n    return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)",
            "def lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Find the least-squares solution to a large, sparse, linear system\\n    of equations.\\n\\n    The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\\n    ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\\n\\n    The matrix A may be square or rectangular (over-determined or\\n    under-determined), and may have any rank.\\n\\n    ::\\n\\n      1. Unsymmetric equations --    solve  Ax = b\\n\\n      2. Linear least squares  --    solve  Ax = b\\n                                     in the least-squares sense\\n\\n      3. Damped least squares  --    solve  (   A    )*x = (    b    )\\n                                            ( damp*I )     ( damp*x0 )\\n                                     in the least-squares sense\\n\\n    Parameters\\n    ----------\\n    A : {sparse matrix, ndarray, LinearOperator}\\n        Representation of an m-by-n matrix.\\n        Alternatively, ``A`` can be a linear operator which can\\n        produce ``Ax`` and ``A^T x`` using, e.g.,\\n        ``scipy.sparse.linalg.LinearOperator``.\\n    b : array_like, shape (m,)\\n        Right-hand side vector ``b``.\\n    damp : float\\n        Damping coefficient. Default is 0.\\n    atol, btol : float, optional\\n        Stopping tolerances. `lsqr` continues iterations until a\\n        certain backward error estimate is smaller than some quantity\\n        depending on atol and btol.  Let ``r = b - Ax`` be the\\n        residual vector for the current approximate solution ``x``.\\n        If ``Ax = b`` seems to be consistent, `lsqr` terminates\\n        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\\n        Otherwise, `lsqr` terminates when ``norm(A^H r) <=\\n        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\\n        the final ``norm(r)`` should be accurate to about 6\\n        digits. (The final ``x`` will usually have fewer correct digits,\\n        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\\n        or `btol` is None, a default value of 1.0e-6 will be used.\\n        Ideally, they should be estimates of the relative error in the\\n        entries of ``A`` and ``b`` respectively.  For example, if the entries\\n        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\\n        the algorithm from doing unnecessary work beyond the\\n        uncertainty of the input data.\\n    conlim : float, optional\\n        Another stopping tolerance.  lsqr terminates if an estimate of\\n        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\\n        b``, `conlim` could be as large as 1.0e+12 (say).  For\\n        least-squares problems, conlim should be less than 1.0e+8.\\n        Maximum precision can be obtained by setting ``atol = btol =\\n        conlim = zero``, but the number of iterations may then be\\n        excessive. Default is 1e8.\\n    iter_lim : int, optional\\n        Explicit limitation on number of iterations (for safety).\\n    show : bool, optional\\n        Display an iteration log. Default is False.\\n    calc_var : bool, optional\\n        Whether to estimate diagonals of ``(A\\'A + damp^2*I)^{-1}``.\\n    x0 : array_like, shape (n,), optional\\n        Initial guess of x, if None zeros are used. Default is None.\\n\\n        .. versionadded:: 1.0.0\\n\\n    Returns\\n    -------\\n    x : ndarray of float\\n        The final solution.\\n    istop : int\\n        Gives the reason for termination.\\n        1 means x is an approximate solution to Ax = b.\\n        2 means x approximately solves the least-squares problem.\\n    itn : int\\n        Iteration number upon termination.\\n    r1norm : float\\n        ``norm(r)``, where ``r = b - Ax``.\\n    r2norm : float\\n        ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\\n        if ``damp == 0``.\\n    anorm : float\\n        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\\n    acond : float\\n        Estimate of ``cond(Abar)``.\\n    arnorm : float\\n        Estimate of ``norm(A\\'@r - damp^2*(x - x0))``.\\n    xnorm : float\\n        ``norm(x)``\\n    var : ndarray of float\\n        If ``calc_var`` is True, estimates all diagonals of\\n        ``(A\\'A)^{-1}`` (if ``damp == 0``) or more generally ``(A\\'A +\\n        damp^2*I)^{-1}``.  This is well defined if A has full column\\n        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\\n        < n`` and ``damp = 0.``)\\n\\n    Notes\\n    -----\\n    LSQR uses an iterative method to approximate the solution.  The\\n    number of iterations required to reach a certain accuracy depends\\n    strongly on the scaling of the problem.  Poor scaling of the rows\\n    or columns of A should therefore be avoided where possible.\\n\\n    For example, in problem 1 the solution is unaltered by\\n    row-scaling.  If a row of A is very small or large compared to\\n    the other rows of A, the corresponding row of ( A  b ) should be\\n    scaled up or down.\\n\\n    In problems 1 and 2, the solution x is easily recovered\\n    following column-scaling.  Unless better information is known,\\n    the nonzero columns of A should be scaled so that they all have\\n    the same Euclidean norm (e.g., 1.0).\\n\\n    In problem 3, there is no freedom to re-scale if damp is\\n    nonzero.  However, the value of damp should be assigned only\\n    after attention has been paid to the scaling of A.\\n\\n    The parameter damp is intended to help regularize\\n    ill-conditioned systems, by preventing the true solution from\\n    being very large.  Another aid to regularization is provided by\\n    the parameter acond, which may be used to terminate iterations\\n    before the computed solution becomes very large.\\n\\n    If some initial estimate ``x0`` is known and if ``damp == 0``,\\n    one could proceed as follows:\\n\\n      1. Compute a residual vector ``r0 = b - A@x0``.\\n      2. Use LSQR to solve the system  ``A@dx = r0``.\\n      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\\n\\n    This requires that ``x0`` be available before and after the call\\n    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\\n    to solve A@x = b and k2 iterations to solve A@dx = r0.\\n    If x0 is \"good\", norm(r0) will be smaller than norm(b).\\n    If the same stopping tolerances atol and btol are used for each\\n    system, k1 and k2 will be similar, but the final solution x0 + dx\\n    should be more accurate.  The only way to reduce the total work\\n    is to use a larger stopping tolerance for the second system.\\n    If some value btol is suitable for A@x = b, the larger value\\n    btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\\n\\n    Preconditioning is another way to reduce the number of iterations.\\n    If it is possible to solve a related system ``M@x = b``\\n    efficiently, where M approximates A in some helpful way (e.g. M -\\n    A has low rank or its elements are small relative to those of A),\\n    LSQR may converge more rapidly on the system ``A@M(inverse)@z =\\n    b``, after which x can be recovered by solving M@x = z.\\n\\n    If A is symmetric, LSQR should not be used!\\n\\n    Alternatives are the symmetric conjugate-gradient method (cg)\\n    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\\n    applies to any symmetric A and will converge more rapidly than\\n    LSQR.  If A is positive definite, there are other implementations\\n    of symmetric cg that require slightly less work per iteration than\\n    SYMMLQ (but will take the same number of iterations).\\n\\n    References\\n    ----------\\n    .. [1] C. C. Paige and M. A. Saunders (1982a).\\n           \"LSQR: An algorithm for sparse linear equations and\\n           sparse least squares\", ACM TOMS 8(1), 43-71.\\n    .. [2] C. C. Paige and M. A. Saunders (1982b).\\n           \"Algorithm 583.  LSQR: Sparse linear equations and least\\n           squares problems\", ACM TOMS 8(2), 195-209.\\n    .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\\n           systems using LSQR and CRAIG\", BIT 35, 588-604.\\n\\n    Examples\\n    --------\\n    >>> import numpy as np\\n    >>> from scipy.sparse import csc_matrix\\n    >>> from scipy.sparse.linalg import lsqr\\n    >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\\n\\n    The first example has the trivial solution ``[0, 0]``\\n\\n    >>> b = np.array([0., 0., 0.], dtype=float)\\n    >>> x, istop, itn, normr = lsqr(A, b)[:4]\\n    >>> istop\\n    0\\n    >>> x\\n    array([ 0.,  0.])\\n\\n    The stopping code `istop=0` returned indicates that a vector of zeros was\\n    found as a solution. The returned solution `x` indeed contains\\n    ``[0., 0.]``. The next example has a non-trivial solution:\\n\\n    >>> b = np.array([1., 0., -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    1\\n    >>> x\\n    array([ 1., -1.])\\n    >>> itn\\n    1\\n    >>> r1norm\\n    4.440892098500627e-16\\n\\n    As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\\n    limits. The given solution ``[1., -1.]`` obviously solves the equation. The\\n    remaining return values include information about the number of iterations\\n    (`itn=1`) and the remaining difference of left and right side of the solved\\n    equation.\\n    The final example demonstrates the behavior in the case where there is no\\n    solution for the equation:\\n\\n    >>> b = np.array([1., 0.01, -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    2\\n    >>> x\\n    array([ 1.00333333, -0.99666667])\\n    >>> A.dot(x)-b\\n    array([ 0.00333333, -0.00333333,  0.00333333])\\n    >>> r1norm\\n    0.005773502691896255\\n\\n    `istop` indicates that the system is inconsistent and thus `x` is rather an\\n    approximate solution to the corresponding least-squares problem. `r1norm`\\n    contains the norm of the minimal residual that was found.\\n    '\n    A = aslinearoperator(A)\n    b = np.atleast_1d(b)\n    if b.ndim > 1:\n        b = b.squeeze()\n    (m, n) = A.shape\n    if iter_lim is None:\n        iter_lim = 2 * n\n    var = np.zeros(n)\n    msg = ('The exact solution is  x = 0                              ', 'Ax - b is small enough, given atol, btol                  ', 'The least-squares solution is good enough, given atol     ', 'The estimate of cond(Abar) has exceeded conlim            ', 'Ax - b is small enough for this machine                   ', 'The least-squares solution is good enough for this machine', 'Cond(Abar) seems to be too large for this machine         ', 'The iteration limit has been reached                      ')\n    if show:\n        print(' ')\n        print('LSQR            Least-squares solution of  Ax = b')\n        str1 = f'The matrix A has {m} rows and {n} columns'\n        str2 = f'damp = {damp:20.14e}   calc_var = {calc_var:8g}'\n        str3 = f'atol = {atol:8.2e}                 conlim = {conlim:8.2e}'\n        str4 = f'btol = {btol:8.2e}               iter_lim = {iter_lim:8g}'\n        print(str1)\n        print(str2)\n        print(str3)\n        print(str4)\n    itn = 0\n    istop = 0\n    ctol = 0\n    if conlim > 0:\n        ctol = 1 / conlim\n    anorm = 0\n    acond = 0\n    dampsq = damp ** 2\n    ddnorm = 0\n    res2 = 0\n    xnorm = 0\n    xxnorm = 0\n    z = 0\n    cs2 = -1\n    sn2 = 0\n    u = b\n    bnorm = np.linalg.norm(b)\n    if x0 is None:\n        x = np.zeros(n)\n        beta = bnorm.copy()\n    else:\n        x = np.asarray(x0)\n        u = u - A.matvec(x)\n        beta = np.linalg.norm(u)\n    if beta > 0:\n        u = 1 / beta * u\n        v = A.rmatvec(u)\n        alfa = np.linalg.norm(v)\n    else:\n        v = x.copy()\n        alfa = 0\n    if alfa > 0:\n        v = 1 / alfa * v\n    w = v.copy()\n    rhobar = alfa\n    phibar = beta\n    rnorm = beta\n    r1norm = rnorm\n    r2norm = rnorm\n    arnorm = alfa * beta\n    if arnorm == 0:\n        if show:\n            print(msg[0])\n        return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)\n    head1 = '   Itn      x[0]       r1norm     r2norm '\n    head2 = ' Compatible    LS      Norm A   Cond A'\n    if show:\n        print(' ')\n        print(head1, head2)\n        test1 = 1\n        test2 = alfa / beta\n        str1 = f'{itn:6g} {x[0]:12.5e}'\n        str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n        str3 = f'  {test1:8.1e} {test2:8.1e}'\n        print(str1, str2, str3)\n    while itn < iter_lim:\n        itn = itn + 1\n        u = A.matvec(v) - alfa * u\n        beta = np.linalg.norm(u)\n        if beta > 0:\n            u = 1 / beta * u\n            anorm = sqrt(anorm ** 2 + alfa ** 2 + beta ** 2 + dampsq)\n            v = A.rmatvec(u) - beta * v\n            alfa = np.linalg.norm(v)\n            if alfa > 0:\n                v = 1 / alfa * v\n        if damp > 0:\n            rhobar1 = sqrt(rhobar ** 2 + dampsq)\n            cs1 = rhobar / rhobar1\n            sn1 = damp / rhobar1\n            psi = sn1 * phibar\n            phibar = cs1 * phibar\n        else:\n            rhobar1 = rhobar\n            psi = 0.0\n        (cs, sn, rho) = _sym_ortho(rhobar1, beta)\n        theta = sn * alfa\n        rhobar = -cs * alfa\n        phi = cs * phibar\n        phibar = sn * phibar\n        tau = sn * phi\n        t1 = phi / rho\n        t2 = -theta / rho\n        dk = 1 / rho * w\n        x = x + t1 * w\n        w = v + t2 * w\n        ddnorm = ddnorm + np.linalg.norm(dk) ** 2\n        if calc_var:\n            var = var + dk ** 2\n        delta = sn2 * rho\n        gambar = -cs2 * rho\n        rhs = phi - delta * z\n        zbar = rhs / gambar\n        xnorm = sqrt(xxnorm + zbar ** 2)\n        gamma = sqrt(gambar ** 2 + theta ** 2)\n        cs2 = gambar / gamma\n        sn2 = theta / gamma\n        z = rhs / gamma\n        xxnorm = xxnorm + z ** 2\n        acond = anorm * sqrt(ddnorm)\n        res1 = phibar ** 2\n        res2 = res2 + psi ** 2\n        rnorm = sqrt(res1 + res2)\n        arnorm = alfa * abs(tau)\n        if damp > 0:\n            r1sq = rnorm ** 2 - dampsq * xxnorm\n            r1norm = sqrt(abs(r1sq))\n            if r1sq < 0:\n                r1norm = -r1norm\n        else:\n            r1norm = rnorm\n        r2norm = rnorm\n        test1 = rnorm / bnorm\n        test2 = arnorm / (anorm * rnorm + eps)\n        test3 = 1 / (acond + eps)\n        t1 = test1 / (1 + anorm * xnorm / bnorm)\n        rtol = btol + atol * anorm * xnorm / bnorm\n        if itn >= iter_lim:\n            istop = 7\n        if 1 + test3 <= 1:\n            istop = 6\n        if 1 + test2 <= 1:\n            istop = 5\n        if 1 + t1 <= 1:\n            istop = 4\n        if test3 <= ctol:\n            istop = 3\n        if test2 <= atol:\n            istop = 2\n        if test1 <= rtol:\n            istop = 1\n        if show:\n            prnt = False\n            if n <= 40:\n                prnt = True\n            if itn <= 10:\n                prnt = True\n            if itn >= iter_lim - 10:\n                prnt = True\n            if test3 <= 2 * ctol:\n                prnt = True\n            if test2 <= 10 * atol:\n                prnt = True\n            if test1 <= 10 * rtol:\n                prnt = True\n            if istop != 0:\n                prnt = True\n            if prnt:\n                str1 = f'{itn:6g} {x[0]:12.5e}'\n                str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n                str3 = f'  {test1:8.1e} {test2:8.1e}'\n                str4 = f' {anorm:8.1e} {acond:8.1e}'\n                print(str1, str2, str3, str4)\n        if istop != 0:\n            break\n    if show:\n        print(' ')\n        print('LSQR finished')\n        print(msg[istop])\n        print(' ')\n        str1 = f'istop ={istop:8g}   r1norm ={r1norm:8.1e}'\n        str2 = f'anorm ={anorm:8.1e}   arnorm ={arnorm:8.1e}'\n        str3 = f'itn   ={itn:8g}   r2norm ={r2norm:8.1e}'\n        str4 = f'acond ={acond:8.1e}   xnorm  ={xnorm:8.1e}'\n        print(str1 + '   ' + str2)\n        print(str3 + '   ' + str4)\n        print(' ')\n    return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)",
            "def lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Find the least-squares solution to a large, sparse, linear system\\n    of equations.\\n\\n    The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\\n    ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\\n\\n    The matrix A may be square or rectangular (over-determined or\\n    under-determined), and may have any rank.\\n\\n    ::\\n\\n      1. Unsymmetric equations --    solve  Ax = b\\n\\n      2. Linear least squares  --    solve  Ax = b\\n                                     in the least-squares sense\\n\\n      3. Damped least squares  --    solve  (   A    )*x = (    b    )\\n                                            ( damp*I )     ( damp*x0 )\\n                                     in the least-squares sense\\n\\n    Parameters\\n    ----------\\n    A : {sparse matrix, ndarray, LinearOperator}\\n        Representation of an m-by-n matrix.\\n        Alternatively, ``A`` can be a linear operator which can\\n        produce ``Ax`` and ``A^T x`` using, e.g.,\\n        ``scipy.sparse.linalg.LinearOperator``.\\n    b : array_like, shape (m,)\\n        Right-hand side vector ``b``.\\n    damp : float\\n        Damping coefficient. Default is 0.\\n    atol, btol : float, optional\\n        Stopping tolerances. `lsqr` continues iterations until a\\n        certain backward error estimate is smaller than some quantity\\n        depending on atol and btol.  Let ``r = b - Ax`` be the\\n        residual vector for the current approximate solution ``x``.\\n        If ``Ax = b`` seems to be consistent, `lsqr` terminates\\n        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\\n        Otherwise, `lsqr` terminates when ``norm(A^H r) <=\\n        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\\n        the final ``norm(r)`` should be accurate to about 6\\n        digits. (The final ``x`` will usually have fewer correct digits,\\n        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\\n        or `btol` is None, a default value of 1.0e-6 will be used.\\n        Ideally, they should be estimates of the relative error in the\\n        entries of ``A`` and ``b`` respectively.  For example, if the entries\\n        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\\n        the algorithm from doing unnecessary work beyond the\\n        uncertainty of the input data.\\n    conlim : float, optional\\n        Another stopping tolerance.  lsqr terminates if an estimate of\\n        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\\n        b``, `conlim` could be as large as 1.0e+12 (say).  For\\n        least-squares problems, conlim should be less than 1.0e+8.\\n        Maximum precision can be obtained by setting ``atol = btol =\\n        conlim = zero``, but the number of iterations may then be\\n        excessive. Default is 1e8.\\n    iter_lim : int, optional\\n        Explicit limitation on number of iterations (for safety).\\n    show : bool, optional\\n        Display an iteration log. Default is False.\\n    calc_var : bool, optional\\n        Whether to estimate diagonals of ``(A\\'A + damp^2*I)^{-1}``.\\n    x0 : array_like, shape (n,), optional\\n        Initial guess of x, if None zeros are used. Default is None.\\n\\n        .. versionadded:: 1.0.0\\n\\n    Returns\\n    -------\\n    x : ndarray of float\\n        The final solution.\\n    istop : int\\n        Gives the reason for termination.\\n        1 means x is an approximate solution to Ax = b.\\n        2 means x approximately solves the least-squares problem.\\n    itn : int\\n        Iteration number upon termination.\\n    r1norm : float\\n        ``norm(r)``, where ``r = b - Ax``.\\n    r2norm : float\\n        ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\\n        if ``damp == 0``.\\n    anorm : float\\n        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\\n    acond : float\\n        Estimate of ``cond(Abar)``.\\n    arnorm : float\\n        Estimate of ``norm(A\\'@r - damp^2*(x - x0))``.\\n    xnorm : float\\n        ``norm(x)``\\n    var : ndarray of float\\n        If ``calc_var`` is True, estimates all diagonals of\\n        ``(A\\'A)^{-1}`` (if ``damp == 0``) or more generally ``(A\\'A +\\n        damp^2*I)^{-1}``.  This is well defined if A has full column\\n        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\\n        < n`` and ``damp = 0.``)\\n\\n    Notes\\n    -----\\n    LSQR uses an iterative method to approximate the solution.  The\\n    number of iterations required to reach a certain accuracy depends\\n    strongly on the scaling of the problem.  Poor scaling of the rows\\n    or columns of A should therefore be avoided where possible.\\n\\n    For example, in problem 1 the solution is unaltered by\\n    row-scaling.  If a row of A is very small or large compared to\\n    the other rows of A, the corresponding row of ( A  b ) should be\\n    scaled up or down.\\n\\n    In problems 1 and 2, the solution x is easily recovered\\n    following column-scaling.  Unless better information is known,\\n    the nonzero columns of A should be scaled so that they all have\\n    the same Euclidean norm (e.g., 1.0).\\n\\n    In problem 3, there is no freedom to re-scale if damp is\\n    nonzero.  However, the value of damp should be assigned only\\n    after attention has been paid to the scaling of A.\\n\\n    The parameter damp is intended to help regularize\\n    ill-conditioned systems, by preventing the true solution from\\n    being very large.  Another aid to regularization is provided by\\n    the parameter acond, which may be used to terminate iterations\\n    before the computed solution becomes very large.\\n\\n    If some initial estimate ``x0`` is known and if ``damp == 0``,\\n    one could proceed as follows:\\n\\n      1. Compute a residual vector ``r0 = b - A@x0``.\\n      2. Use LSQR to solve the system  ``A@dx = r0``.\\n      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\\n\\n    This requires that ``x0`` be available before and after the call\\n    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\\n    to solve A@x = b and k2 iterations to solve A@dx = r0.\\n    If x0 is \"good\", norm(r0) will be smaller than norm(b).\\n    If the same stopping tolerances atol and btol are used for each\\n    system, k1 and k2 will be similar, but the final solution x0 + dx\\n    should be more accurate.  The only way to reduce the total work\\n    is to use a larger stopping tolerance for the second system.\\n    If some value btol is suitable for A@x = b, the larger value\\n    btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\\n\\n    Preconditioning is another way to reduce the number of iterations.\\n    If it is possible to solve a related system ``M@x = b``\\n    efficiently, where M approximates A in some helpful way (e.g. M -\\n    A has low rank or its elements are small relative to those of A),\\n    LSQR may converge more rapidly on the system ``A@M(inverse)@z =\\n    b``, after which x can be recovered by solving M@x = z.\\n\\n    If A is symmetric, LSQR should not be used!\\n\\n    Alternatives are the symmetric conjugate-gradient method (cg)\\n    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\\n    applies to any symmetric A and will converge more rapidly than\\n    LSQR.  If A is positive definite, there are other implementations\\n    of symmetric cg that require slightly less work per iteration than\\n    SYMMLQ (but will take the same number of iterations).\\n\\n    References\\n    ----------\\n    .. [1] C. C. Paige and M. A. Saunders (1982a).\\n           \"LSQR: An algorithm for sparse linear equations and\\n           sparse least squares\", ACM TOMS 8(1), 43-71.\\n    .. [2] C. C. Paige and M. A. Saunders (1982b).\\n           \"Algorithm 583.  LSQR: Sparse linear equations and least\\n           squares problems\", ACM TOMS 8(2), 195-209.\\n    .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\\n           systems using LSQR and CRAIG\", BIT 35, 588-604.\\n\\n    Examples\\n    --------\\n    >>> import numpy as np\\n    >>> from scipy.sparse import csc_matrix\\n    >>> from scipy.sparse.linalg import lsqr\\n    >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\\n\\n    The first example has the trivial solution ``[0, 0]``\\n\\n    >>> b = np.array([0., 0., 0.], dtype=float)\\n    >>> x, istop, itn, normr = lsqr(A, b)[:4]\\n    >>> istop\\n    0\\n    >>> x\\n    array([ 0.,  0.])\\n\\n    The stopping code `istop=0` returned indicates that a vector of zeros was\\n    found as a solution. The returned solution `x` indeed contains\\n    ``[0., 0.]``. The next example has a non-trivial solution:\\n\\n    >>> b = np.array([1., 0., -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    1\\n    >>> x\\n    array([ 1., -1.])\\n    >>> itn\\n    1\\n    >>> r1norm\\n    4.440892098500627e-16\\n\\n    As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\\n    limits. The given solution ``[1., -1.]`` obviously solves the equation. The\\n    remaining return values include information about the number of iterations\\n    (`itn=1`) and the remaining difference of left and right side of the solved\\n    equation.\\n    The final example demonstrates the behavior in the case where there is no\\n    solution for the equation:\\n\\n    >>> b = np.array([1., 0.01, -1.], dtype=float)\\n    >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\\n    >>> istop\\n    2\\n    >>> x\\n    array([ 1.00333333, -0.99666667])\\n    >>> A.dot(x)-b\\n    array([ 0.00333333, -0.00333333,  0.00333333])\\n    >>> r1norm\\n    0.005773502691896255\\n\\n    `istop` indicates that the system is inconsistent and thus `x` is rather an\\n    approximate solution to the corresponding least-squares problem. `r1norm`\\n    contains the norm of the minimal residual that was found.\\n    '\n    A = aslinearoperator(A)\n    b = np.atleast_1d(b)\n    if b.ndim > 1:\n        b = b.squeeze()\n    (m, n) = A.shape\n    if iter_lim is None:\n        iter_lim = 2 * n\n    var = np.zeros(n)\n    msg = ('The exact solution is  x = 0                              ', 'Ax - b is small enough, given atol, btol                  ', 'The least-squares solution is good enough, given atol     ', 'The estimate of cond(Abar) has exceeded conlim            ', 'Ax - b is small enough for this machine                   ', 'The least-squares solution is good enough for this machine', 'Cond(Abar) seems to be too large for this machine         ', 'The iteration limit has been reached                      ')\n    if show:\n        print(' ')\n        print('LSQR            Least-squares solution of  Ax = b')\n        str1 = f'The matrix A has {m} rows and {n} columns'\n        str2 = f'damp = {damp:20.14e}   calc_var = {calc_var:8g}'\n        str3 = f'atol = {atol:8.2e}                 conlim = {conlim:8.2e}'\n        str4 = f'btol = {btol:8.2e}               iter_lim = {iter_lim:8g}'\n        print(str1)\n        print(str2)\n        print(str3)\n        print(str4)\n    itn = 0\n    istop = 0\n    ctol = 0\n    if conlim > 0:\n        ctol = 1 / conlim\n    anorm = 0\n    acond = 0\n    dampsq = damp ** 2\n    ddnorm = 0\n    res2 = 0\n    xnorm = 0\n    xxnorm = 0\n    z = 0\n    cs2 = -1\n    sn2 = 0\n    u = b\n    bnorm = np.linalg.norm(b)\n    if x0 is None:\n        x = np.zeros(n)\n        beta = bnorm.copy()\n    else:\n        x = np.asarray(x0)\n        u = u - A.matvec(x)\n        beta = np.linalg.norm(u)\n    if beta > 0:\n        u = 1 / beta * u\n        v = A.rmatvec(u)\n        alfa = np.linalg.norm(v)\n    else:\n        v = x.copy()\n        alfa = 0\n    if alfa > 0:\n        v = 1 / alfa * v\n    w = v.copy()\n    rhobar = alfa\n    phibar = beta\n    rnorm = beta\n    r1norm = rnorm\n    r2norm = rnorm\n    arnorm = alfa * beta\n    if arnorm == 0:\n        if show:\n            print(msg[0])\n        return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)\n    head1 = '   Itn      x[0]       r1norm     r2norm '\n    head2 = ' Compatible    LS      Norm A   Cond A'\n    if show:\n        print(' ')\n        print(head1, head2)\n        test1 = 1\n        test2 = alfa / beta\n        str1 = f'{itn:6g} {x[0]:12.5e}'\n        str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n        str3 = f'  {test1:8.1e} {test2:8.1e}'\n        print(str1, str2, str3)\n    while itn < iter_lim:\n        itn = itn + 1\n        u = A.matvec(v) - alfa * u\n        beta = np.linalg.norm(u)\n        if beta > 0:\n            u = 1 / beta * u\n            anorm = sqrt(anorm ** 2 + alfa ** 2 + beta ** 2 + dampsq)\n            v = A.rmatvec(u) - beta * v\n            alfa = np.linalg.norm(v)\n            if alfa > 0:\n                v = 1 / alfa * v\n        if damp > 0:\n            rhobar1 = sqrt(rhobar ** 2 + dampsq)\n            cs1 = rhobar / rhobar1\n            sn1 = damp / rhobar1\n            psi = sn1 * phibar\n            phibar = cs1 * phibar\n        else:\n            rhobar1 = rhobar\n            psi = 0.0\n        (cs, sn, rho) = _sym_ortho(rhobar1, beta)\n        theta = sn * alfa\n        rhobar = -cs * alfa\n        phi = cs * phibar\n        phibar = sn * phibar\n        tau = sn * phi\n        t1 = phi / rho\n        t2 = -theta / rho\n        dk = 1 / rho * w\n        x = x + t1 * w\n        w = v + t2 * w\n        ddnorm = ddnorm + np.linalg.norm(dk) ** 2\n        if calc_var:\n            var = var + dk ** 2\n        delta = sn2 * rho\n        gambar = -cs2 * rho\n        rhs = phi - delta * z\n        zbar = rhs / gambar\n        xnorm = sqrt(xxnorm + zbar ** 2)\n        gamma = sqrt(gambar ** 2 + theta ** 2)\n        cs2 = gambar / gamma\n        sn2 = theta / gamma\n        z = rhs / gamma\n        xxnorm = xxnorm + z ** 2\n        acond = anorm * sqrt(ddnorm)\n        res1 = phibar ** 2\n        res2 = res2 + psi ** 2\n        rnorm = sqrt(res1 + res2)\n        arnorm = alfa * abs(tau)\n        if damp > 0:\n            r1sq = rnorm ** 2 - dampsq * xxnorm\n            r1norm = sqrt(abs(r1sq))\n            if r1sq < 0:\n                r1norm = -r1norm\n        else:\n            r1norm = rnorm\n        r2norm = rnorm\n        test1 = rnorm / bnorm\n        test2 = arnorm / (anorm * rnorm + eps)\n        test3 = 1 / (acond + eps)\n        t1 = test1 / (1 + anorm * xnorm / bnorm)\n        rtol = btol + atol * anorm * xnorm / bnorm\n        if itn >= iter_lim:\n            istop = 7\n        if 1 + test3 <= 1:\n            istop = 6\n        if 1 + test2 <= 1:\n            istop = 5\n        if 1 + t1 <= 1:\n            istop = 4\n        if test3 <= ctol:\n            istop = 3\n        if test2 <= atol:\n            istop = 2\n        if test1 <= rtol:\n            istop = 1\n        if show:\n            prnt = False\n            if n <= 40:\n                prnt = True\n            if itn <= 10:\n                prnt = True\n            if itn >= iter_lim - 10:\n                prnt = True\n            if test3 <= 2 * ctol:\n                prnt = True\n            if test2 <= 10 * atol:\n                prnt = True\n            if test1 <= 10 * rtol:\n                prnt = True\n            if istop != 0:\n                prnt = True\n            if prnt:\n                str1 = f'{itn:6g} {x[0]:12.5e}'\n                str2 = f' {r1norm:10.3e} {r2norm:10.3e}'\n                str3 = f'  {test1:8.1e} {test2:8.1e}'\n                str4 = f' {anorm:8.1e} {acond:8.1e}'\n                print(str1, str2, str3, str4)\n        if istop != 0:\n            break\n    if show:\n        print(' ')\n        print('LSQR finished')\n        print(msg[istop])\n        print(' ')\n        str1 = f'istop ={istop:8g}   r1norm ={r1norm:8.1e}'\n        str2 = f'anorm ={anorm:8.1e}   arnorm ={arnorm:8.1e}'\n        str3 = f'itn   ={itn:8g}   r2norm ={r2norm:8.1e}'\n        str4 = f'acond ={acond:8.1e}   xnorm  ={xnorm:8.1e}'\n        print(str1 + '   ' + str2)\n        print(str3 + '   ' + str4)\n        print(' ')\n    return (x, istop, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var)"
        ]
    }
]