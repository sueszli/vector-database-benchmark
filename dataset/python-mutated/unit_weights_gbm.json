[
    {
        "func_name": "check_same",
        "original": "def check_same(data1, data2, min_rows_scale):\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_mse = gbm1_regression.mse()\n    reg2_mse = gbm2_regression.mse()\n    bin1_auc = gbm1_binomial.auc()\n    bin2_auc = gbm2_binomial.auc()\n    mul1_mse = gbm1_multinomial.mse()\n    mul2_mse = gbm2_multinomial.mse()\n    print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n    print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n    print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n    assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n    assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n    assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)",
        "mutated": [
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_mse = gbm1_regression.mse()\n    reg2_mse = gbm2_regression.mse()\n    bin1_auc = gbm1_binomial.auc()\n    bin2_auc = gbm2_binomial.auc()\n    mul1_mse = gbm1_multinomial.mse()\n    mul2_mse = gbm2_multinomial.mse()\n    print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n    print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n    print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n    assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n    assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n    assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_mse = gbm1_regression.mse()\n    reg2_mse = gbm2_regression.mse()\n    bin1_auc = gbm1_binomial.auc()\n    bin2_auc = gbm2_binomial.auc()\n    mul1_mse = gbm1_multinomial.mse()\n    mul2_mse = gbm2_multinomial.mse()\n    print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n    print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n    print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n    assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n    assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n    assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_mse = gbm1_regression.mse()\n    reg2_mse = gbm2_regression.mse()\n    bin1_auc = gbm1_binomial.auc()\n    bin2_auc = gbm2_binomial.auc()\n    mul1_mse = gbm1_multinomial.mse()\n    mul2_mse = gbm2_multinomial.mse()\n    print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n    print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n    print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n    assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n    assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n    assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_mse = gbm1_regression.mse()\n    reg2_mse = gbm2_regression.mse()\n    bin1_auc = gbm1_binomial.auc()\n    bin2_auc = gbm2_binomial.auc()\n    mul1_mse = gbm1_multinomial.mse()\n    mul2_mse = gbm2_multinomial.mse()\n    print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n    print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n    print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n    assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n    assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n    assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_mse = gbm1_regression.mse()\n    reg2_mse = gbm2_regression.mse()\n    bin1_auc = gbm1_binomial.auc()\n    bin2_auc = gbm2_binomial.auc()\n    mul1_mse = gbm1_multinomial.mse()\n    mul2_mse = gbm2_multinomial.mse()\n    print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n    print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n    print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n    assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n    assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n    assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)"
        ]
    },
    {
        "func_name": "weights_check",
        "original": "def weights_check():\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_mse = gbm1_regression.mse()\n        reg2_mse = gbm2_regression.mse()\n        bin1_auc = gbm1_binomial.auc()\n        bin2_auc = gbm2_binomial.auc()\n        mul1_mse = gbm1_multinomial.mse()\n        mul2_mse = gbm2_multinomial.mse()\n        print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n        print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n        print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n        assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n        assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n        assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    random.seed(2222)\n    weight = 3\n    uniform_weights = [[weight]] * 406\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('Checking that using uniform weights is equivalent to no weights:')\n    print()\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]]\n    h2o_zero_weights = h2o.H2OFrame(list(zip(*zero_weights)))\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('Checking that using some zero weights is equivalent to removing those observations:')\n    print()\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1]]\n    h2o_doubled_weights = h2o.H2OFrame(list(zip(*doubled_weights)))\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('Checking that doubling some weights is equivalent to doubling those observations:')\n    print()\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
        "mutated": [
            "def weights_check():\n    if False:\n        i = 10\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_mse = gbm1_regression.mse()\n        reg2_mse = gbm2_regression.mse()\n        bin1_auc = gbm1_binomial.auc()\n        bin2_auc = gbm2_binomial.auc()\n        mul1_mse = gbm1_multinomial.mse()\n        mul2_mse = gbm2_multinomial.mse()\n        print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n        print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n        print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n        assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n        assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n        assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    random.seed(2222)\n    weight = 3\n    uniform_weights = [[weight]] * 406\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('Checking that using uniform weights is equivalent to no weights:')\n    print()\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]]\n    h2o_zero_weights = h2o.H2OFrame(list(zip(*zero_weights)))\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('Checking that using some zero weights is equivalent to removing those observations:')\n    print()\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1]]\n    h2o_doubled_weights = h2o.H2OFrame(list(zip(*doubled_weights)))\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('Checking that doubling some weights is equivalent to doubling those observations:')\n    print()\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_check():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_mse = gbm1_regression.mse()\n        reg2_mse = gbm2_regression.mse()\n        bin1_auc = gbm1_binomial.auc()\n        bin2_auc = gbm2_binomial.auc()\n        mul1_mse = gbm1_multinomial.mse()\n        mul2_mse = gbm2_multinomial.mse()\n        print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n        print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n        print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n        assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n        assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n        assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    random.seed(2222)\n    weight = 3\n    uniform_weights = [[weight]] * 406\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('Checking that using uniform weights is equivalent to no weights:')\n    print()\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]]\n    h2o_zero_weights = h2o.H2OFrame(list(zip(*zero_weights)))\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('Checking that using some zero weights is equivalent to removing those observations:')\n    print()\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1]]\n    h2o_doubled_weights = h2o.H2OFrame(list(zip(*doubled_weights)))\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('Checking that doubling some weights is equivalent to doubling those observations:')\n    print()\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_check():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_mse = gbm1_regression.mse()\n        reg2_mse = gbm2_regression.mse()\n        bin1_auc = gbm1_binomial.auc()\n        bin2_auc = gbm2_binomial.auc()\n        mul1_mse = gbm1_multinomial.mse()\n        mul2_mse = gbm2_multinomial.mse()\n        print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n        print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n        print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n        assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n        assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n        assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    random.seed(2222)\n    weight = 3\n    uniform_weights = [[weight]] * 406\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('Checking that using uniform weights is equivalent to no weights:')\n    print()\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]]\n    h2o_zero_weights = h2o.H2OFrame(list(zip(*zero_weights)))\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('Checking that using some zero weights is equivalent to removing those observations:')\n    print()\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1]]\n    h2o_doubled_weights = h2o.H2OFrame(list(zip(*doubled_weights)))\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('Checking that doubling some weights is equivalent to doubling those observations:')\n    print()\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_check():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_mse = gbm1_regression.mse()\n        reg2_mse = gbm2_regression.mse()\n        bin1_auc = gbm1_binomial.auc()\n        bin2_auc = gbm2_binomial.auc()\n        mul1_mse = gbm1_multinomial.mse()\n        mul2_mse = gbm2_multinomial.mse()\n        print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n        print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n        print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n        assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n        assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n        assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    random.seed(2222)\n    weight = 3\n    uniform_weights = [[weight]] * 406\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('Checking that using uniform weights is equivalent to no weights:')\n    print()\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]]\n    h2o_zero_weights = h2o.H2OFrame(list(zip(*zero_weights)))\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('Checking that using some zero weights is equivalent to removing those observations:')\n    print()\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1]]\n    h2o_doubled_weights = h2o.H2OFrame(list(zip(*doubled_weights)))\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('Checking that doubling some weights is equivalent to doubling those observations:')\n    print()\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_check():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=20, ntrees=5, seed=20, max_depth=4)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, ntrees=5, seed=20, max_depth=4)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=20, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='bernoulli', ntrees=5, seed=20, max_depth=4)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=20, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=20 * min_rows_scale, distribution='multinomial', ntrees=5, seed=20, max_depth=4)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_mse = gbm1_regression.mse()\n        reg2_mse = gbm2_regression.mse()\n        bin1_auc = gbm1_binomial.auc()\n        bin2_auc = gbm2_binomial.auc()\n        mul1_mse = gbm1_multinomial.mse()\n        mul2_mse = gbm2_multinomial.mse()\n        print('MSE (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_mse, reg2_mse))\n        print('AUC (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_auc, bin2_auc))\n        print('MSE (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_mse, mul2_mse))\n        assert abs(reg1_mse - reg2_mse) < 1e-05 * reg1_mse, \"Expected mse's to be the same, but got {0}, and {1}\".format(reg1_mse, reg2_mse)\n        assert abs(bin1_auc - bin2_auc) < 0.003 * bin1_auc, \"Expected auc's to be the same, but got {0}, and {1}\".format(bin1_auc, bin2_auc)\n        assert abs(mul1_mse - mul1_mse) < 1e-06 * mul1_mse, \"Expected auc's to be the same, but got {0}, and {1}\".format(mul1_mse, mul2_mse)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    random.seed(2222)\n    weight = 3\n    uniform_weights = [[weight]] * 406\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('Checking that using uniform weights is equivalent to no weights:')\n    print()\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]]\n    h2o_zero_weights = h2o.H2OFrame(list(zip(*zero_weights)))\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('Checking that using some zero weights is equivalent to removing those observations:')\n    print()\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1]]\n    h2o_doubled_weights = h2o.H2OFrame(list(zip(*doubled_weights)))\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('Checking that doubling some weights is equivalent to doubling those observations:')\n    print()\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)"
        ]
    }
]