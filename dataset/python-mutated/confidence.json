[
    {
        "func_name": "predicted_lddt",
        "original": "def predicted_lddt(plddt_logits: torch.Tensor) -> torch.Tensor:\n    \"\"\"Computes per-residue pLDDT from logits.\n    Args:\n        logits: [num_res, num_bins] output from the PredictedLDDTHead.\n    Returns:\n        plddt: [num_res] per-residue pLDDT.\n    \"\"\"\n    num_bins = plddt_logits.shape[-1]\n    bin_probs = torch.nn.functional.softmax(plddt_logits.float(), dim=-1)\n    bin_width = 1.0 / num_bins\n    bounds = torch.arange(start=0.5 * bin_width, end=1.0, step=bin_width, device=plddt_logits.device)\n    plddt = torch.sum(bin_probs * bounds.view(*(1,) * len(bin_probs.shape[:-1]), *bounds.shape), dim=-1)\n    return plddt",
        "mutated": [
            "def predicted_lddt(plddt_logits: torch.Tensor) -> torch.Tensor:\n    if False:\n        i = 10\n    'Computes per-residue pLDDT from logits.\\n    Args:\\n        logits: [num_res, num_bins] output from the PredictedLDDTHead.\\n    Returns:\\n        plddt: [num_res] per-residue pLDDT.\\n    '\n    num_bins = plddt_logits.shape[-1]\n    bin_probs = torch.nn.functional.softmax(plddt_logits.float(), dim=-1)\n    bin_width = 1.0 / num_bins\n    bounds = torch.arange(start=0.5 * bin_width, end=1.0, step=bin_width, device=plddt_logits.device)\n    plddt = torch.sum(bin_probs * bounds.view(*(1,) * len(bin_probs.shape[:-1]), *bounds.shape), dim=-1)\n    return plddt",
            "def predicted_lddt(plddt_logits: torch.Tensor) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Computes per-residue pLDDT from logits.\\n    Args:\\n        logits: [num_res, num_bins] output from the PredictedLDDTHead.\\n    Returns:\\n        plddt: [num_res] per-residue pLDDT.\\n    '\n    num_bins = plddt_logits.shape[-1]\n    bin_probs = torch.nn.functional.softmax(plddt_logits.float(), dim=-1)\n    bin_width = 1.0 / num_bins\n    bounds = torch.arange(start=0.5 * bin_width, end=1.0, step=bin_width, device=plddt_logits.device)\n    plddt = torch.sum(bin_probs * bounds.view(*(1,) * len(bin_probs.shape[:-1]), *bounds.shape), dim=-1)\n    return plddt",
            "def predicted_lddt(plddt_logits: torch.Tensor) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Computes per-residue pLDDT from logits.\\n    Args:\\n        logits: [num_res, num_bins] output from the PredictedLDDTHead.\\n    Returns:\\n        plddt: [num_res] per-residue pLDDT.\\n    '\n    num_bins = plddt_logits.shape[-1]\n    bin_probs = torch.nn.functional.softmax(plddt_logits.float(), dim=-1)\n    bin_width = 1.0 / num_bins\n    bounds = torch.arange(start=0.5 * bin_width, end=1.0, step=bin_width, device=plddt_logits.device)\n    plddt = torch.sum(bin_probs * bounds.view(*(1,) * len(bin_probs.shape[:-1]), *bounds.shape), dim=-1)\n    return plddt",
            "def predicted_lddt(plddt_logits: torch.Tensor) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Computes per-residue pLDDT from logits.\\n    Args:\\n        logits: [num_res, num_bins] output from the PredictedLDDTHead.\\n    Returns:\\n        plddt: [num_res] per-residue pLDDT.\\n    '\n    num_bins = plddt_logits.shape[-1]\n    bin_probs = torch.nn.functional.softmax(plddt_logits.float(), dim=-1)\n    bin_width = 1.0 / num_bins\n    bounds = torch.arange(start=0.5 * bin_width, end=1.0, step=bin_width, device=plddt_logits.device)\n    plddt = torch.sum(bin_probs * bounds.view(*(1,) * len(bin_probs.shape[:-1]), *bounds.shape), dim=-1)\n    return plddt",
            "def predicted_lddt(plddt_logits: torch.Tensor) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Computes per-residue pLDDT from logits.\\n    Args:\\n        logits: [num_res, num_bins] output from the PredictedLDDTHead.\\n    Returns:\\n        plddt: [num_res] per-residue pLDDT.\\n    '\n    num_bins = plddt_logits.shape[-1]\n    bin_probs = torch.nn.functional.softmax(plddt_logits.float(), dim=-1)\n    bin_width = 1.0 / num_bins\n    bounds = torch.arange(start=0.5 * bin_width, end=1.0, step=bin_width, device=plddt_logits.device)\n    plddt = torch.sum(bin_probs * bounds.view(*(1,) * len(bin_probs.shape[:-1]), *bounds.shape), dim=-1)\n    return plddt"
        ]
    },
    {
        "func_name": "compute_bin_values",
        "original": "def compute_bin_values(breaks: torch.Tensor):\n    \"\"\"Gets the bin centers from the bin edges.\n    Args:\n        breaks: [num_bins - 1] the error bin edges.\n    Returns:\n        bin_centers: [num_bins] the error bin centers.\n    \"\"\"\n    step = breaks[1] - breaks[0]\n    bin_values = breaks + step / 2\n    bin_values = torch.cat([bin_values, (bin_values[-1] + step).unsqueeze(-1)], dim=0)\n    return bin_values",
        "mutated": [
            "def compute_bin_values(breaks: torch.Tensor):\n    if False:\n        i = 10\n    'Gets the bin centers from the bin edges.\\n    Args:\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        bin_centers: [num_bins] the error bin centers.\\n    '\n    step = breaks[1] - breaks[0]\n    bin_values = breaks + step / 2\n    bin_values = torch.cat([bin_values, (bin_values[-1] + step).unsqueeze(-1)], dim=0)\n    return bin_values",
            "def compute_bin_values(breaks: torch.Tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Gets the bin centers from the bin edges.\\n    Args:\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        bin_centers: [num_bins] the error bin centers.\\n    '\n    step = breaks[1] - breaks[0]\n    bin_values = breaks + step / 2\n    bin_values = torch.cat([bin_values, (bin_values[-1] + step).unsqueeze(-1)], dim=0)\n    return bin_values",
            "def compute_bin_values(breaks: torch.Tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Gets the bin centers from the bin edges.\\n    Args:\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        bin_centers: [num_bins] the error bin centers.\\n    '\n    step = breaks[1] - breaks[0]\n    bin_values = breaks + step / 2\n    bin_values = torch.cat([bin_values, (bin_values[-1] + step).unsqueeze(-1)], dim=0)\n    return bin_values",
            "def compute_bin_values(breaks: torch.Tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Gets the bin centers from the bin edges.\\n    Args:\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        bin_centers: [num_bins] the error bin centers.\\n    '\n    step = breaks[1] - breaks[0]\n    bin_values = breaks + step / 2\n    bin_values = torch.cat([bin_values, (bin_values[-1] + step).unsqueeze(-1)], dim=0)\n    return bin_values",
            "def compute_bin_values(breaks: torch.Tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Gets the bin centers from the bin edges.\\n    Args:\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        bin_centers: [num_bins] the error bin centers.\\n    '\n    step = breaks[1] - breaks[0]\n    bin_values = breaks + step / 2\n    bin_values = torch.cat([bin_values, (bin_values[-1] + step).unsqueeze(-1)], dim=0)\n    return bin_values"
        ]
    },
    {
        "func_name": "compute_predicted_aligned_error",
        "original": "def compute_predicted_aligned_error(bin_edges: torch.Tensor, bin_probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Calculates expected aligned distance errors for every pair of residues.\n    Args:\n        alignment_confidence_breaks: [num_bins - 1] the error bin edges.\n        aligned_distance_error_probs: [num_res, num_res, num_bins] the predicted\n        probs for each error bin, for each pair of residues.\n    Returns:\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\n        error for each pair of residues.\n        max_predicted_aligned_error: The maximum predicted error possible.\n    \"\"\"\n    bin_values = compute_bin_values(bin_edges)\n    return torch.sum(bin_probs * bin_values, dim=-1)",
        "mutated": [
            "def compute_predicted_aligned_error(bin_edges: torch.Tensor, bin_probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    if False:\n        i = 10\n    'Calculates expected aligned distance errors for every pair of residues.\\n    Args:\\n        alignment_confidence_breaks: [num_bins - 1] the error bin edges.\\n        aligned_distance_error_probs: [num_res, num_res, num_bins] the predicted\\n        probs for each error bin, for each pair of residues.\\n    Returns:\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_values = compute_bin_values(bin_edges)\n    return torch.sum(bin_probs * bin_values, dim=-1)",
            "def compute_predicted_aligned_error(bin_edges: torch.Tensor, bin_probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Calculates expected aligned distance errors for every pair of residues.\\n    Args:\\n        alignment_confidence_breaks: [num_bins - 1] the error bin edges.\\n        aligned_distance_error_probs: [num_res, num_res, num_bins] the predicted\\n        probs for each error bin, for each pair of residues.\\n    Returns:\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_values = compute_bin_values(bin_edges)\n    return torch.sum(bin_probs * bin_values, dim=-1)",
            "def compute_predicted_aligned_error(bin_edges: torch.Tensor, bin_probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Calculates expected aligned distance errors for every pair of residues.\\n    Args:\\n        alignment_confidence_breaks: [num_bins - 1] the error bin edges.\\n        aligned_distance_error_probs: [num_res, num_res, num_bins] the predicted\\n        probs for each error bin, for each pair of residues.\\n    Returns:\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_values = compute_bin_values(bin_edges)\n    return torch.sum(bin_probs * bin_values, dim=-1)",
            "def compute_predicted_aligned_error(bin_edges: torch.Tensor, bin_probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Calculates expected aligned distance errors for every pair of residues.\\n    Args:\\n        alignment_confidence_breaks: [num_bins - 1] the error bin edges.\\n        aligned_distance_error_probs: [num_res, num_res, num_bins] the predicted\\n        probs for each error bin, for each pair of residues.\\n    Returns:\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_values = compute_bin_values(bin_edges)\n    return torch.sum(bin_probs * bin_values, dim=-1)",
            "def compute_predicted_aligned_error(bin_edges: torch.Tensor, bin_probs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Calculates expected aligned distance errors for every pair of residues.\\n    Args:\\n        alignment_confidence_breaks: [num_bins - 1] the error bin edges.\\n        aligned_distance_error_probs: [num_res, num_res, num_bins] the predicted\\n        probs for each error bin, for each pair of residues.\\n    Returns:\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_values = compute_bin_values(bin_edges)\n    return torch.sum(bin_probs * bin_values, dim=-1)"
        ]
    },
    {
        "func_name": "predicted_aligned_error",
        "original": "def predicted_aligned_error(pae_logits: torch.Tensor, max_bin: int=31, num_bins: int=64, **kwargs) -> Dict[str, torch.Tensor]:\n    \"\"\"Computes aligned confidence metrics from logits.\n    Args:\n        logits: [num_res, num_res, num_bins] the logits output from\n        PredictedAlignedErrorHead.\n        breaks: [num_bins - 1] the error bin edges.\n    Returns:\n        aligned_confidence_probs: [num_res, num_res, num_bins] the predicted\n        aligned error probabilities over bins for each residue pair.\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\n        error for each pair of residues.\n        max_predicted_aligned_error: The maximum predicted error possible.\n    \"\"\"\n    bin_probs = torch.nn.functional.softmax(pae_logits.float(), dim=-1)\n    bin_edges = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n    predicted_aligned_error = compute_predicted_aligned_error(bin_edges=bin_edges, bin_probs=bin_probs)\n    return {'aligned_error_probs_per_bin': bin_probs, 'predicted_aligned_error': predicted_aligned_error}",
        "mutated": [
            "def predicted_aligned_error(pae_logits: torch.Tensor, max_bin: int=31, num_bins: int=64, **kwargs) -> Dict[str, torch.Tensor]:\n    if False:\n        i = 10\n    'Computes aligned confidence metrics from logits.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        aligned_confidence_probs: [num_res, num_res, num_bins] the predicted\\n        aligned error probabilities over bins for each residue pair.\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_probs = torch.nn.functional.softmax(pae_logits.float(), dim=-1)\n    bin_edges = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n    predicted_aligned_error = compute_predicted_aligned_error(bin_edges=bin_edges, bin_probs=bin_probs)\n    return {'aligned_error_probs_per_bin': bin_probs, 'predicted_aligned_error': predicted_aligned_error}",
            "def predicted_aligned_error(pae_logits: torch.Tensor, max_bin: int=31, num_bins: int=64, **kwargs) -> Dict[str, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Computes aligned confidence metrics from logits.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        aligned_confidence_probs: [num_res, num_res, num_bins] the predicted\\n        aligned error probabilities over bins for each residue pair.\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_probs = torch.nn.functional.softmax(pae_logits.float(), dim=-1)\n    bin_edges = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n    predicted_aligned_error = compute_predicted_aligned_error(bin_edges=bin_edges, bin_probs=bin_probs)\n    return {'aligned_error_probs_per_bin': bin_probs, 'predicted_aligned_error': predicted_aligned_error}",
            "def predicted_aligned_error(pae_logits: torch.Tensor, max_bin: int=31, num_bins: int=64, **kwargs) -> Dict[str, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Computes aligned confidence metrics from logits.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        aligned_confidence_probs: [num_res, num_res, num_bins] the predicted\\n        aligned error probabilities over bins for each residue pair.\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_probs = torch.nn.functional.softmax(pae_logits.float(), dim=-1)\n    bin_edges = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n    predicted_aligned_error = compute_predicted_aligned_error(bin_edges=bin_edges, bin_probs=bin_probs)\n    return {'aligned_error_probs_per_bin': bin_probs, 'predicted_aligned_error': predicted_aligned_error}",
            "def predicted_aligned_error(pae_logits: torch.Tensor, max_bin: int=31, num_bins: int=64, **kwargs) -> Dict[str, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Computes aligned confidence metrics from logits.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        aligned_confidence_probs: [num_res, num_res, num_bins] the predicted\\n        aligned error probabilities over bins for each residue pair.\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_probs = torch.nn.functional.softmax(pae_logits.float(), dim=-1)\n    bin_edges = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n    predicted_aligned_error = compute_predicted_aligned_error(bin_edges=bin_edges, bin_probs=bin_probs)\n    return {'aligned_error_probs_per_bin': bin_probs, 'predicted_aligned_error': predicted_aligned_error}",
            "def predicted_aligned_error(pae_logits: torch.Tensor, max_bin: int=31, num_bins: int=64, **kwargs) -> Dict[str, torch.Tensor]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Computes aligned confidence metrics from logits.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins - 1] the error bin edges.\\n    Returns:\\n        aligned_confidence_probs: [num_res, num_res, num_bins] the predicted\\n        aligned error probabilities over bins for each residue pair.\\n        predicted_aligned_error: [num_res, num_res] the expected aligned distance\\n        error for each pair of residues.\\n        max_predicted_aligned_error: The maximum predicted error possible.\\n    '\n    bin_probs = torch.nn.functional.softmax(pae_logits.float(), dim=-1)\n    bin_edges = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n    predicted_aligned_error = compute_predicted_aligned_error(bin_edges=bin_edges, bin_probs=bin_probs)\n    return {'aligned_error_probs_per_bin': bin_probs, 'predicted_aligned_error': predicted_aligned_error}"
        ]
    },
    {
        "func_name": "tm_kernal",
        "original": "def tm_kernal(nres):\n    clipped_n = max(nres, 19)\n    d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n    return lambda x: 1.0 / (1.0 + (x / d0) ** 2)",
        "mutated": [
            "def tm_kernal(nres):\n    if False:\n        i = 10\n    clipped_n = max(nres, 19)\n    d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n    return lambda x: 1.0 / (1.0 + (x / d0) ** 2)",
            "def tm_kernal(nres):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    clipped_n = max(nres, 19)\n    d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n    return lambda x: 1.0 / (1.0 + (x / d0) ** 2)",
            "def tm_kernal(nres):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    clipped_n = max(nres, 19)\n    d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n    return lambda x: 1.0 / (1.0 + (x / d0) ** 2)",
            "def tm_kernal(nres):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    clipped_n = max(nres, 19)\n    d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n    return lambda x: 1.0 / (1.0 + (x / d0) ** 2)",
            "def tm_kernal(nres):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    clipped_n = max(nres, 19)\n    d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n    return lambda x: 1.0 / (1.0 + (x / d0) ** 2)"
        ]
    },
    {
        "func_name": "rmsd_kernal",
        "original": "def rmsd_kernal(eps):\n    return lambda x: 1.0 / (x + eps)",
        "mutated": [
            "def rmsd_kernal(eps):\n    if False:\n        i = 10\n    return lambda x: 1.0 / (x + eps)",
            "def rmsd_kernal(eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return lambda x: 1.0 / (x + eps)",
            "def rmsd_kernal(eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return lambda x: 1.0 / (x + eps)",
            "def rmsd_kernal(eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return lambda x: 1.0 / (x + eps)",
            "def rmsd_kernal(eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return lambda x: 1.0 / (x + eps)"
        ]
    },
    {
        "func_name": "predicted_tm_score",
        "original": "def predicted_tm_score(pae_logits: torch.Tensor, residue_weights: Optional[torch.Tensor]=None, max_bin: int=31, num_bins: int=64, eps: float=1e-08, asym_id: Optional[torch.Tensor]=None, interface: bool=False, **kwargs) -> torch.Tensor:\n    \"\"\"Computes predicted TM alignment or predicted interface TM alignment score.\n    Args:\n        logits: [num_res, num_res, num_bins] the logits output from\n        PredictedAlignedErrorHead.\n        breaks: [num_bins] the error bins.\n        residue_weights: [num_res] the per residue weights to use for the\n        expectation.\n        asym_id: [num_res] the asymmetric unit ID - the chain ID. Only needed for\n        ipTM calculation, i.e. when interface=True.\n        interface: If True, interface predicted TM score is computed.\n    Returns:\n        ptm_score: The predicted TM alignment or the predicted iTM score.\n    \"\"\"\n    pae_logits = pae_logits.float()\n    if residue_weights is None:\n        residue_weights = pae_logits.new_ones(pae_logits.shape[:-2])\n    breaks = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n\n    def tm_kernal(nres):\n        clipped_n = max(nres, 19)\n        d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n        return lambda x: 1.0 / (1.0 + (x / d0) ** 2)\n\n    def rmsd_kernal(eps):\n        return lambda x: 1.0 / (x + eps)\n    bin_centers = compute_bin_values(breaks)\n    probs = torch.nn.functional.softmax(pae_logits, dim=-1)\n    tm_per_bin = tm_kernal(nres=pae_logits.shape[-2])(bin_centers)\n    predicted_tm_term = torch.sum(probs * tm_per_bin, dim=-1)\n    pair_mask = predicted_tm_term.new_ones(predicted_tm_term.shape)\n    if interface:\n        assert asym_id is not None, 'must provide asym_id for iptm calculation.'\n        pair_mask *= asym_id[..., :, None] != asym_id[..., None, :]\n    predicted_tm_term *= pair_mask\n    pair_residue_weights = pair_mask * (residue_weights[None, :] * residue_weights[:, None])\n    normed_residue_mask = pair_residue_weights / (eps + pair_residue_weights.sum(dim=-1, keepdim=True))\n    per_alignment = torch.sum(predicted_tm_term * normed_residue_mask, dim=-1)\n    weighted = per_alignment * residue_weights\n    ret = per_alignment.gather(dim=-1, index=weighted.max(dim=-1, keepdim=True).indices).squeeze(dim=-1)\n    return ret",
        "mutated": [
            "def predicted_tm_score(pae_logits: torch.Tensor, residue_weights: Optional[torch.Tensor]=None, max_bin: int=31, num_bins: int=64, eps: float=1e-08, asym_id: Optional[torch.Tensor]=None, interface: bool=False, **kwargs) -> torch.Tensor:\n    if False:\n        i = 10\n    'Computes predicted TM alignment or predicted interface TM alignment score.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins] the error bins.\\n        residue_weights: [num_res] the per residue weights to use for the\\n        expectation.\\n        asym_id: [num_res] the asymmetric unit ID - the chain ID. Only needed for\\n        ipTM calculation, i.e. when interface=True.\\n        interface: If True, interface predicted TM score is computed.\\n    Returns:\\n        ptm_score: The predicted TM alignment or the predicted iTM score.\\n    '\n    pae_logits = pae_logits.float()\n    if residue_weights is None:\n        residue_weights = pae_logits.new_ones(pae_logits.shape[:-2])\n    breaks = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n\n    def tm_kernal(nres):\n        clipped_n = max(nres, 19)\n        d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n        return lambda x: 1.0 / (1.0 + (x / d0) ** 2)\n\n    def rmsd_kernal(eps):\n        return lambda x: 1.0 / (x + eps)\n    bin_centers = compute_bin_values(breaks)\n    probs = torch.nn.functional.softmax(pae_logits, dim=-1)\n    tm_per_bin = tm_kernal(nres=pae_logits.shape[-2])(bin_centers)\n    predicted_tm_term = torch.sum(probs * tm_per_bin, dim=-1)\n    pair_mask = predicted_tm_term.new_ones(predicted_tm_term.shape)\n    if interface:\n        assert asym_id is not None, 'must provide asym_id for iptm calculation.'\n        pair_mask *= asym_id[..., :, None] != asym_id[..., None, :]\n    predicted_tm_term *= pair_mask\n    pair_residue_weights = pair_mask * (residue_weights[None, :] * residue_weights[:, None])\n    normed_residue_mask = pair_residue_weights / (eps + pair_residue_weights.sum(dim=-1, keepdim=True))\n    per_alignment = torch.sum(predicted_tm_term * normed_residue_mask, dim=-1)\n    weighted = per_alignment * residue_weights\n    ret = per_alignment.gather(dim=-1, index=weighted.max(dim=-1, keepdim=True).indices).squeeze(dim=-1)\n    return ret",
            "def predicted_tm_score(pae_logits: torch.Tensor, residue_weights: Optional[torch.Tensor]=None, max_bin: int=31, num_bins: int=64, eps: float=1e-08, asym_id: Optional[torch.Tensor]=None, interface: bool=False, **kwargs) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Computes predicted TM alignment or predicted interface TM alignment score.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins] the error bins.\\n        residue_weights: [num_res] the per residue weights to use for the\\n        expectation.\\n        asym_id: [num_res] the asymmetric unit ID - the chain ID. Only needed for\\n        ipTM calculation, i.e. when interface=True.\\n        interface: If True, interface predicted TM score is computed.\\n    Returns:\\n        ptm_score: The predicted TM alignment or the predicted iTM score.\\n    '\n    pae_logits = pae_logits.float()\n    if residue_weights is None:\n        residue_weights = pae_logits.new_ones(pae_logits.shape[:-2])\n    breaks = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n\n    def tm_kernal(nres):\n        clipped_n = max(nres, 19)\n        d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n        return lambda x: 1.0 / (1.0 + (x / d0) ** 2)\n\n    def rmsd_kernal(eps):\n        return lambda x: 1.0 / (x + eps)\n    bin_centers = compute_bin_values(breaks)\n    probs = torch.nn.functional.softmax(pae_logits, dim=-1)\n    tm_per_bin = tm_kernal(nres=pae_logits.shape[-2])(bin_centers)\n    predicted_tm_term = torch.sum(probs * tm_per_bin, dim=-1)\n    pair_mask = predicted_tm_term.new_ones(predicted_tm_term.shape)\n    if interface:\n        assert asym_id is not None, 'must provide asym_id for iptm calculation.'\n        pair_mask *= asym_id[..., :, None] != asym_id[..., None, :]\n    predicted_tm_term *= pair_mask\n    pair_residue_weights = pair_mask * (residue_weights[None, :] * residue_weights[:, None])\n    normed_residue_mask = pair_residue_weights / (eps + pair_residue_weights.sum(dim=-1, keepdim=True))\n    per_alignment = torch.sum(predicted_tm_term * normed_residue_mask, dim=-1)\n    weighted = per_alignment * residue_weights\n    ret = per_alignment.gather(dim=-1, index=weighted.max(dim=-1, keepdim=True).indices).squeeze(dim=-1)\n    return ret",
            "def predicted_tm_score(pae_logits: torch.Tensor, residue_weights: Optional[torch.Tensor]=None, max_bin: int=31, num_bins: int=64, eps: float=1e-08, asym_id: Optional[torch.Tensor]=None, interface: bool=False, **kwargs) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Computes predicted TM alignment or predicted interface TM alignment score.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins] the error bins.\\n        residue_weights: [num_res] the per residue weights to use for the\\n        expectation.\\n        asym_id: [num_res] the asymmetric unit ID - the chain ID. Only needed for\\n        ipTM calculation, i.e. when interface=True.\\n        interface: If True, interface predicted TM score is computed.\\n    Returns:\\n        ptm_score: The predicted TM alignment or the predicted iTM score.\\n    '\n    pae_logits = pae_logits.float()\n    if residue_weights is None:\n        residue_weights = pae_logits.new_ones(pae_logits.shape[:-2])\n    breaks = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n\n    def tm_kernal(nres):\n        clipped_n = max(nres, 19)\n        d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n        return lambda x: 1.0 / (1.0 + (x / d0) ** 2)\n\n    def rmsd_kernal(eps):\n        return lambda x: 1.0 / (x + eps)\n    bin_centers = compute_bin_values(breaks)\n    probs = torch.nn.functional.softmax(pae_logits, dim=-1)\n    tm_per_bin = tm_kernal(nres=pae_logits.shape[-2])(bin_centers)\n    predicted_tm_term = torch.sum(probs * tm_per_bin, dim=-1)\n    pair_mask = predicted_tm_term.new_ones(predicted_tm_term.shape)\n    if interface:\n        assert asym_id is not None, 'must provide asym_id for iptm calculation.'\n        pair_mask *= asym_id[..., :, None] != asym_id[..., None, :]\n    predicted_tm_term *= pair_mask\n    pair_residue_weights = pair_mask * (residue_weights[None, :] * residue_weights[:, None])\n    normed_residue_mask = pair_residue_weights / (eps + pair_residue_weights.sum(dim=-1, keepdim=True))\n    per_alignment = torch.sum(predicted_tm_term * normed_residue_mask, dim=-1)\n    weighted = per_alignment * residue_weights\n    ret = per_alignment.gather(dim=-1, index=weighted.max(dim=-1, keepdim=True).indices).squeeze(dim=-1)\n    return ret",
            "def predicted_tm_score(pae_logits: torch.Tensor, residue_weights: Optional[torch.Tensor]=None, max_bin: int=31, num_bins: int=64, eps: float=1e-08, asym_id: Optional[torch.Tensor]=None, interface: bool=False, **kwargs) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Computes predicted TM alignment or predicted interface TM alignment score.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins] the error bins.\\n        residue_weights: [num_res] the per residue weights to use for the\\n        expectation.\\n        asym_id: [num_res] the asymmetric unit ID - the chain ID. Only needed for\\n        ipTM calculation, i.e. when interface=True.\\n        interface: If True, interface predicted TM score is computed.\\n    Returns:\\n        ptm_score: The predicted TM alignment or the predicted iTM score.\\n    '\n    pae_logits = pae_logits.float()\n    if residue_weights is None:\n        residue_weights = pae_logits.new_ones(pae_logits.shape[:-2])\n    breaks = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n\n    def tm_kernal(nres):\n        clipped_n = max(nres, 19)\n        d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n        return lambda x: 1.0 / (1.0 + (x / d0) ** 2)\n\n    def rmsd_kernal(eps):\n        return lambda x: 1.0 / (x + eps)\n    bin_centers = compute_bin_values(breaks)\n    probs = torch.nn.functional.softmax(pae_logits, dim=-1)\n    tm_per_bin = tm_kernal(nres=pae_logits.shape[-2])(bin_centers)\n    predicted_tm_term = torch.sum(probs * tm_per_bin, dim=-1)\n    pair_mask = predicted_tm_term.new_ones(predicted_tm_term.shape)\n    if interface:\n        assert asym_id is not None, 'must provide asym_id for iptm calculation.'\n        pair_mask *= asym_id[..., :, None] != asym_id[..., None, :]\n    predicted_tm_term *= pair_mask\n    pair_residue_weights = pair_mask * (residue_weights[None, :] * residue_weights[:, None])\n    normed_residue_mask = pair_residue_weights / (eps + pair_residue_weights.sum(dim=-1, keepdim=True))\n    per_alignment = torch.sum(predicted_tm_term * normed_residue_mask, dim=-1)\n    weighted = per_alignment * residue_weights\n    ret = per_alignment.gather(dim=-1, index=weighted.max(dim=-1, keepdim=True).indices).squeeze(dim=-1)\n    return ret",
            "def predicted_tm_score(pae_logits: torch.Tensor, residue_weights: Optional[torch.Tensor]=None, max_bin: int=31, num_bins: int=64, eps: float=1e-08, asym_id: Optional[torch.Tensor]=None, interface: bool=False, **kwargs) -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Computes predicted TM alignment or predicted interface TM alignment score.\\n    Args:\\n        logits: [num_res, num_res, num_bins] the logits output from\\n        PredictedAlignedErrorHead.\\n        breaks: [num_bins] the error bins.\\n        residue_weights: [num_res] the per residue weights to use for the\\n        expectation.\\n        asym_id: [num_res] the asymmetric unit ID - the chain ID. Only needed for\\n        ipTM calculation, i.e. when interface=True.\\n        interface: If True, interface predicted TM score is computed.\\n    Returns:\\n        ptm_score: The predicted TM alignment or the predicted iTM score.\\n    '\n    pae_logits = pae_logits.float()\n    if residue_weights is None:\n        residue_weights = pae_logits.new_ones(pae_logits.shape[:-2])\n    breaks = torch.linspace(0, max_bin, steps=num_bins - 1, device=pae_logits.device)\n\n    def tm_kernal(nres):\n        clipped_n = max(nres, 19)\n        d0 = 1.24 * (clipped_n - 15) ** (1.0 / 3.0) - 1.8\n        return lambda x: 1.0 / (1.0 + (x / d0) ** 2)\n\n    def rmsd_kernal(eps):\n        return lambda x: 1.0 / (x + eps)\n    bin_centers = compute_bin_values(breaks)\n    probs = torch.nn.functional.softmax(pae_logits, dim=-1)\n    tm_per_bin = tm_kernal(nres=pae_logits.shape[-2])(bin_centers)\n    predicted_tm_term = torch.sum(probs * tm_per_bin, dim=-1)\n    pair_mask = predicted_tm_term.new_ones(predicted_tm_term.shape)\n    if interface:\n        assert asym_id is not None, 'must provide asym_id for iptm calculation.'\n        pair_mask *= asym_id[..., :, None] != asym_id[..., None, :]\n    predicted_tm_term *= pair_mask\n    pair_residue_weights = pair_mask * (residue_weights[None, :] * residue_weights[:, None])\n    normed_residue_mask = pair_residue_weights / (eps + pair_residue_weights.sum(dim=-1, keepdim=True))\n    per_alignment = torch.sum(predicted_tm_term * normed_residue_mask, dim=-1)\n    weighted = per_alignment * residue_weights\n    ret = per_alignment.gather(dim=-1, index=weighted.max(dim=-1, keepdim=True).indices).squeeze(dim=-1)\n    return ret"
        ]
    }
]