[
    {
        "func_name": "__init__",
        "original": "def __init__(self, in_channels, heads, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(SeparateHead, self).__init__(init_cfg=init_cfg)\n    self.heads = heads\n    self.init_bias = init_bias\n    for head in self.heads:\n        (classes, num_conv) = self.heads[head]\n        conv_layers = []\n        c_in = in_channels\n        for i in range(num_conv - 1):\n            conv_layers.append(ConvModule(c_in, head_conv, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=bias, conv_cfg=conv_cfg, norm_cfg=norm_cfg))\n            c_in = head_conv\n        conv_layers.append(build_conv_layer(conv_cfg, head_conv, classes, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=True))\n        conv_layers = nn.Sequential(*conv_layers)\n        self.__setattr__(head, conv_layers)\n        if init_cfg is None:\n            self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
        "mutated": [
            "def __init__(self, in_channels, heads, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(SeparateHead, self).__init__(init_cfg=init_cfg)\n    self.heads = heads\n    self.init_bias = init_bias\n    for head in self.heads:\n        (classes, num_conv) = self.heads[head]\n        conv_layers = []\n        c_in = in_channels\n        for i in range(num_conv - 1):\n            conv_layers.append(ConvModule(c_in, head_conv, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=bias, conv_cfg=conv_cfg, norm_cfg=norm_cfg))\n            c_in = head_conv\n        conv_layers.append(build_conv_layer(conv_cfg, head_conv, classes, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=True))\n        conv_layers = nn.Sequential(*conv_layers)\n        self.__setattr__(head, conv_layers)\n        if init_cfg is None:\n            self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, heads, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(SeparateHead, self).__init__(init_cfg=init_cfg)\n    self.heads = heads\n    self.init_bias = init_bias\n    for head in self.heads:\n        (classes, num_conv) = self.heads[head]\n        conv_layers = []\n        c_in = in_channels\n        for i in range(num_conv - 1):\n            conv_layers.append(ConvModule(c_in, head_conv, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=bias, conv_cfg=conv_cfg, norm_cfg=norm_cfg))\n            c_in = head_conv\n        conv_layers.append(build_conv_layer(conv_cfg, head_conv, classes, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=True))\n        conv_layers = nn.Sequential(*conv_layers)\n        self.__setattr__(head, conv_layers)\n        if init_cfg is None:\n            self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, heads, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(SeparateHead, self).__init__(init_cfg=init_cfg)\n    self.heads = heads\n    self.init_bias = init_bias\n    for head in self.heads:\n        (classes, num_conv) = self.heads[head]\n        conv_layers = []\n        c_in = in_channels\n        for i in range(num_conv - 1):\n            conv_layers.append(ConvModule(c_in, head_conv, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=bias, conv_cfg=conv_cfg, norm_cfg=norm_cfg))\n            c_in = head_conv\n        conv_layers.append(build_conv_layer(conv_cfg, head_conv, classes, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=True))\n        conv_layers = nn.Sequential(*conv_layers)\n        self.__setattr__(head, conv_layers)\n        if init_cfg is None:\n            self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, heads, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(SeparateHead, self).__init__(init_cfg=init_cfg)\n    self.heads = heads\n    self.init_bias = init_bias\n    for head in self.heads:\n        (classes, num_conv) = self.heads[head]\n        conv_layers = []\n        c_in = in_channels\n        for i in range(num_conv - 1):\n            conv_layers.append(ConvModule(c_in, head_conv, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=bias, conv_cfg=conv_cfg, norm_cfg=norm_cfg))\n            c_in = head_conv\n        conv_layers.append(build_conv_layer(conv_cfg, head_conv, classes, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=True))\n        conv_layers = nn.Sequential(*conv_layers)\n        self.__setattr__(head, conv_layers)\n        if init_cfg is None:\n            self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, heads, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(SeparateHead, self).__init__(init_cfg=init_cfg)\n    self.heads = heads\n    self.init_bias = init_bias\n    for head in self.heads:\n        (classes, num_conv) = self.heads[head]\n        conv_layers = []\n        c_in = in_channels\n        for i in range(num_conv - 1):\n            conv_layers.append(ConvModule(c_in, head_conv, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=bias, conv_cfg=conv_cfg, norm_cfg=norm_cfg))\n            c_in = head_conv\n        conv_layers.append(build_conv_layer(conv_cfg, head_conv, classes, kernel_size=final_kernel, stride=1, padding=final_kernel // 2, bias=True))\n        conv_layers = nn.Sequential(*conv_layers)\n        self.__setattr__(head, conv_layers)\n        if init_cfg is None:\n            self.init_cfg = dict(type='Kaiming', layer='Conv2d')"
        ]
    },
    {
        "func_name": "init_weights",
        "original": "def init_weights(self):\n    \"\"\"Initialize weights.\"\"\"\n    super().init_weights()\n    for head in self.heads:\n        if head == 'heatmap':\n            self.__getattr__(head)[-1].bias.data.fill_(self.init_bias)",
        "mutated": [
            "def init_weights(self):\n    if False:\n        i = 10\n    'Initialize weights.'\n    super().init_weights()\n    for head in self.heads:\n        if head == 'heatmap':\n            self.__getattr__(head)[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initialize weights.'\n    super().init_weights()\n    for head in self.heads:\n        if head == 'heatmap':\n            self.__getattr__(head)[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initialize weights.'\n    super().init_weights()\n    for head in self.heads:\n        if head == 'heatmap':\n            self.__getattr__(head)[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initialize weights.'\n    super().init_weights()\n    for head in self.heads:\n        if head == 'heatmap':\n            self.__getattr__(head)[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initialize weights.'\n    super().init_weights()\n    for head in self.heads:\n        if head == 'heatmap':\n            self.__getattr__(head)[-1].bias.data.fill_(self.init_bias)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, x):\n    \"\"\"Forward function for SepHead.\n\n        Args:\n            x (torch.Tensor): Input feature map with the shape of\n                [B, 512, 128, 128].\n\n        Returns:\n            dict[str: torch.Tensor]: contains the following keys:\n\n                -reg \uff08torch.Tensor): 2D regression value with the\n                    shape of [B, 2, H, W].\n                -height (torch.Tensor): Height value with the\n                    shape of [B, 1, H, W].\n                -dim (torch.Tensor): Size value with the shape\n                    of [B, 3, H, W].\n                -rot (torch.Tensor): Rotation value with the\n                    shape of [B, 2, H, W].\n                -vel (torch.Tensor): Velocity value with the\n                    shape of [B, 2, H, W].\n                -heatmap (torch.Tensor): Heatmap with the shape of\n                    [B, N, H, W].\n        \"\"\"\n    ret_dict = dict()\n    for head in self.heads:\n        ret_dict[head] = self.__getattr__(head)(x)\n    return ret_dict",
        "mutated": [
            "def forward(self, x):\n    if False:\n        i = 10\n    'Forward function for SepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    ret_dict = dict()\n    for head in self.heads:\n        ret_dict[head] = self.__getattr__(head)(x)\n    return ret_dict",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward function for SepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    ret_dict = dict()\n    for head in self.heads:\n        ret_dict[head] = self.__getattr__(head)(x)\n    return ret_dict",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward function for SepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    ret_dict = dict()\n    for head in self.heads:\n        ret_dict[head] = self.__getattr__(head)(x)\n    return ret_dict",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward function for SepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    ret_dict = dict()\n    for head in self.heads:\n        ret_dict[head] = self.__getattr__(head)(x)\n    return ret_dict",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward function for SepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    ret_dict = dict()\n    for head in self.heads:\n        ret_dict[head] = self.__getattr__(head)(x)\n    return ret_dict"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, in_channels, num_cls, heads, dcn_config, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(DCNSeparateHead, self).__init__(init_cfg=init_cfg)\n    if 'heatmap' in heads:\n        heads.pop('heatmap')\n    self.feature_adapt_cls = build_conv_layer(dcn_config)\n    self.feature_adapt_reg = build_conv_layer(dcn_config)\n    cls_head = [ConvModule(in_channels, head_conv, kernel_size=3, padding=1, conv_cfg=conv_cfg, bias=bias, norm_cfg=norm_cfg), build_conv_layer(conv_cfg, head_conv, num_cls, kernel_size=3, stride=1, padding=1, bias=bias)]\n    self.cls_head = nn.Sequential(*cls_head)\n    self.init_bias = init_bias\n    self.task_head = SeparateHead(in_channels, heads, head_conv=head_conv, final_kernel=final_kernel, bias=bias)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
        "mutated": [
            "def __init__(self, in_channels, num_cls, heads, dcn_config, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(DCNSeparateHead, self).__init__(init_cfg=init_cfg)\n    if 'heatmap' in heads:\n        heads.pop('heatmap')\n    self.feature_adapt_cls = build_conv_layer(dcn_config)\n    self.feature_adapt_reg = build_conv_layer(dcn_config)\n    cls_head = [ConvModule(in_channels, head_conv, kernel_size=3, padding=1, conv_cfg=conv_cfg, bias=bias, norm_cfg=norm_cfg), build_conv_layer(conv_cfg, head_conv, num_cls, kernel_size=3, stride=1, padding=1, bias=bias)]\n    self.cls_head = nn.Sequential(*cls_head)\n    self.init_bias = init_bias\n    self.task_head = SeparateHead(in_channels, heads, head_conv=head_conv, final_kernel=final_kernel, bias=bias)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, num_cls, heads, dcn_config, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(DCNSeparateHead, self).__init__(init_cfg=init_cfg)\n    if 'heatmap' in heads:\n        heads.pop('heatmap')\n    self.feature_adapt_cls = build_conv_layer(dcn_config)\n    self.feature_adapt_reg = build_conv_layer(dcn_config)\n    cls_head = [ConvModule(in_channels, head_conv, kernel_size=3, padding=1, conv_cfg=conv_cfg, bias=bias, norm_cfg=norm_cfg), build_conv_layer(conv_cfg, head_conv, num_cls, kernel_size=3, stride=1, padding=1, bias=bias)]\n    self.cls_head = nn.Sequential(*cls_head)\n    self.init_bias = init_bias\n    self.task_head = SeparateHead(in_channels, heads, head_conv=head_conv, final_kernel=final_kernel, bias=bias)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, num_cls, heads, dcn_config, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(DCNSeparateHead, self).__init__(init_cfg=init_cfg)\n    if 'heatmap' in heads:\n        heads.pop('heatmap')\n    self.feature_adapt_cls = build_conv_layer(dcn_config)\n    self.feature_adapt_reg = build_conv_layer(dcn_config)\n    cls_head = [ConvModule(in_channels, head_conv, kernel_size=3, padding=1, conv_cfg=conv_cfg, bias=bias, norm_cfg=norm_cfg), build_conv_layer(conv_cfg, head_conv, num_cls, kernel_size=3, stride=1, padding=1, bias=bias)]\n    self.cls_head = nn.Sequential(*cls_head)\n    self.init_bias = init_bias\n    self.task_head = SeparateHead(in_channels, heads, head_conv=head_conv, final_kernel=final_kernel, bias=bias)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, num_cls, heads, dcn_config, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(DCNSeparateHead, self).__init__(init_cfg=init_cfg)\n    if 'heatmap' in heads:\n        heads.pop('heatmap')\n    self.feature_adapt_cls = build_conv_layer(dcn_config)\n    self.feature_adapt_reg = build_conv_layer(dcn_config)\n    cls_head = [ConvModule(in_channels, head_conv, kernel_size=3, padding=1, conv_cfg=conv_cfg, bias=bias, norm_cfg=norm_cfg), build_conv_layer(conv_cfg, head_conv, num_cls, kernel_size=3, stride=1, padding=1, bias=bias)]\n    self.cls_head = nn.Sequential(*cls_head)\n    self.init_bias = init_bias\n    self.task_head = SeparateHead(in_channels, heads, head_conv=head_conv, final_kernel=final_kernel, bias=bias)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Kaiming', layer='Conv2d')",
            "def __init__(self, in_channels, num_cls, heads, dcn_config, head_conv=64, final_kernel=1, init_bias=-2.19, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', init_cfg=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(DCNSeparateHead, self).__init__(init_cfg=init_cfg)\n    if 'heatmap' in heads:\n        heads.pop('heatmap')\n    self.feature_adapt_cls = build_conv_layer(dcn_config)\n    self.feature_adapt_reg = build_conv_layer(dcn_config)\n    cls_head = [ConvModule(in_channels, head_conv, kernel_size=3, padding=1, conv_cfg=conv_cfg, bias=bias, norm_cfg=norm_cfg), build_conv_layer(conv_cfg, head_conv, num_cls, kernel_size=3, stride=1, padding=1, bias=bias)]\n    self.cls_head = nn.Sequential(*cls_head)\n    self.init_bias = init_bias\n    self.task_head = SeparateHead(in_channels, heads, head_conv=head_conv, final_kernel=final_kernel, bias=bias)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Kaiming', layer='Conv2d')"
        ]
    },
    {
        "func_name": "init_weights",
        "original": "def init_weights(self):\n    \"\"\"Initialize weights.\"\"\"\n    super().init_weights()\n    self.cls_head[-1].bias.data.fill_(self.init_bias)",
        "mutated": [
            "def init_weights(self):\n    if False:\n        i = 10\n    'Initialize weights.'\n    super().init_weights()\n    self.cls_head[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initialize weights.'\n    super().init_weights()\n    self.cls_head[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initialize weights.'\n    super().init_weights()\n    self.cls_head[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initialize weights.'\n    super().init_weights()\n    self.cls_head[-1].bias.data.fill_(self.init_bias)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initialize weights.'\n    super().init_weights()\n    self.cls_head[-1].bias.data.fill_(self.init_bias)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, x):\n    \"\"\"Forward function for DCNSepHead.\n\n        Args:\n            x (torch.Tensor): Input feature map with the shape of\n                [B, 512, 128, 128].\n\n        Returns:\n            dict[str: torch.Tensor]: contains the following keys:\n\n                -reg \uff08torch.Tensor): 2D regression value with the\n                    shape of [B, 2, H, W].\n                -height (torch.Tensor): Height value with the\n                    shape of [B, 1, H, W].\n                -dim (torch.Tensor): Size value with the shape\n                    of [B, 3, H, W].\n                -rot (torch.Tensor): Rotation value with the\n                    shape of [B, 2, H, W].\n                -vel (torch.Tensor): Velocity value with the\n                    shape of [B, 2, H, W].\n                -heatmap (torch.Tensor): Heatmap with the shape of\n                    [B, N, H, W].\n        \"\"\"\n    center_feat = self.feature_adapt_cls(x)\n    reg_feat = self.feature_adapt_reg(x)\n    cls_score = self.cls_head(center_feat)\n    ret = self.task_head(reg_feat)\n    ret['heatmap'] = cls_score\n    return ret",
        "mutated": [
            "def forward(self, x):\n    if False:\n        i = 10\n    'Forward function for DCNSepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    center_feat = self.feature_adapt_cls(x)\n    reg_feat = self.feature_adapt_reg(x)\n    cls_score = self.cls_head(center_feat)\n    ret = self.task_head(reg_feat)\n    ret['heatmap'] = cls_score\n    return ret",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward function for DCNSepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    center_feat = self.feature_adapt_cls(x)\n    reg_feat = self.feature_adapt_reg(x)\n    cls_score = self.cls_head(center_feat)\n    ret = self.task_head(reg_feat)\n    ret['heatmap'] = cls_score\n    return ret",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward function for DCNSepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    center_feat = self.feature_adapt_cls(x)\n    reg_feat = self.feature_adapt_reg(x)\n    cls_score = self.cls_head(center_feat)\n    ret = self.task_head(reg_feat)\n    ret['heatmap'] = cls_score\n    return ret",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward function for DCNSepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    center_feat = self.feature_adapt_cls(x)\n    reg_feat = self.feature_adapt_reg(x)\n    cls_score = self.cls_head(center_feat)\n    ret = self.task_head(reg_feat)\n    ret['heatmap'] = cls_score\n    return ret",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward function for DCNSepHead.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            dict[str: torch.Tensor]: contains the following keys:\\n\\n                -reg \uff08torch.Tensor): 2D regression value with the\\n                    shape of [B, 2, H, W].\\n                -height (torch.Tensor): Height value with the\\n                    shape of [B, 1, H, W].\\n                -dim (torch.Tensor): Size value with the shape\\n                    of [B, 3, H, W].\\n                -rot (torch.Tensor): Rotation value with the\\n                    shape of [B, 2, H, W].\\n                -vel (torch.Tensor): Velocity value with the\\n                    shape of [B, 2, H, W].\\n                -heatmap (torch.Tensor): Heatmap with the shape of\\n                    [B, N, H, W].\\n        '\n    center_feat = self.feature_adapt_cls(x)\n    reg_feat = self.feature_adapt_reg(x)\n    cls_score = self.cls_head(center_feat)\n    ret = self.task_head(reg_feat)\n    ret['heatmap'] = cls_score\n    return ret"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, in_channels=[128], tasks=None, train_cfg=None, test_cfg=None, bbox_coder=None, common_heads=dict(), loss_cls=dict(type='GaussianFocalLoss', reduction='mean'), loss_bbox=dict(type='L1Loss', reduction='none', loss_weight=0.25), separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3), share_conv_channel=64, num_heatmap_convs=2, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', norm_bbox=True, init_cfg=None):\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(CenterHead, self).__init__(init_cfg=init_cfg)\n    num_classes = [len(t['class_names']) for t in tasks]\n    self.class_names = [t['class_names'] for t in tasks]\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.norm_bbox = norm_bbox\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_anchor_per_locs = [n for n in num_classes]\n    self.fp16_enabled = False\n    self.shared_conv = ConvModule(in_channels, share_conv_channel, kernel_size=3, padding=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=bias)\n    self.task_heads = nn.ModuleList()\n    for num_cls in num_classes:\n        heads = copy.deepcopy(common_heads)\n        heads.update(dict(heatmap=(num_cls, num_heatmap_convs)))\n        separate_head.update(in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n        self.task_heads.append(builder.build_head(separate_head))\n    self.with_velocity = 'vel' in common_heads.keys()",
        "mutated": [
            "def __init__(self, in_channels=[128], tasks=None, train_cfg=None, test_cfg=None, bbox_coder=None, common_heads=dict(), loss_cls=dict(type='GaussianFocalLoss', reduction='mean'), loss_bbox=dict(type='L1Loss', reduction='none', loss_weight=0.25), separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3), share_conv_channel=64, num_heatmap_convs=2, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', norm_bbox=True, init_cfg=None):\n    if False:\n        i = 10\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(CenterHead, self).__init__(init_cfg=init_cfg)\n    num_classes = [len(t['class_names']) for t in tasks]\n    self.class_names = [t['class_names'] for t in tasks]\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.norm_bbox = norm_bbox\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_anchor_per_locs = [n for n in num_classes]\n    self.fp16_enabled = False\n    self.shared_conv = ConvModule(in_channels, share_conv_channel, kernel_size=3, padding=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=bias)\n    self.task_heads = nn.ModuleList()\n    for num_cls in num_classes:\n        heads = copy.deepcopy(common_heads)\n        heads.update(dict(heatmap=(num_cls, num_heatmap_convs)))\n        separate_head.update(in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n        self.task_heads.append(builder.build_head(separate_head))\n    self.with_velocity = 'vel' in common_heads.keys()",
            "def __init__(self, in_channels=[128], tasks=None, train_cfg=None, test_cfg=None, bbox_coder=None, common_heads=dict(), loss_cls=dict(type='GaussianFocalLoss', reduction='mean'), loss_bbox=dict(type='L1Loss', reduction='none', loss_weight=0.25), separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3), share_conv_channel=64, num_heatmap_convs=2, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', norm_bbox=True, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(CenterHead, self).__init__(init_cfg=init_cfg)\n    num_classes = [len(t['class_names']) for t in tasks]\n    self.class_names = [t['class_names'] for t in tasks]\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.norm_bbox = norm_bbox\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_anchor_per_locs = [n for n in num_classes]\n    self.fp16_enabled = False\n    self.shared_conv = ConvModule(in_channels, share_conv_channel, kernel_size=3, padding=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=bias)\n    self.task_heads = nn.ModuleList()\n    for num_cls in num_classes:\n        heads = copy.deepcopy(common_heads)\n        heads.update(dict(heatmap=(num_cls, num_heatmap_convs)))\n        separate_head.update(in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n        self.task_heads.append(builder.build_head(separate_head))\n    self.with_velocity = 'vel' in common_heads.keys()",
            "def __init__(self, in_channels=[128], tasks=None, train_cfg=None, test_cfg=None, bbox_coder=None, common_heads=dict(), loss_cls=dict(type='GaussianFocalLoss', reduction='mean'), loss_bbox=dict(type='L1Loss', reduction='none', loss_weight=0.25), separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3), share_conv_channel=64, num_heatmap_convs=2, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', norm_bbox=True, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(CenterHead, self).__init__(init_cfg=init_cfg)\n    num_classes = [len(t['class_names']) for t in tasks]\n    self.class_names = [t['class_names'] for t in tasks]\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.norm_bbox = norm_bbox\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_anchor_per_locs = [n for n in num_classes]\n    self.fp16_enabled = False\n    self.shared_conv = ConvModule(in_channels, share_conv_channel, kernel_size=3, padding=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=bias)\n    self.task_heads = nn.ModuleList()\n    for num_cls in num_classes:\n        heads = copy.deepcopy(common_heads)\n        heads.update(dict(heatmap=(num_cls, num_heatmap_convs)))\n        separate_head.update(in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n        self.task_heads.append(builder.build_head(separate_head))\n    self.with_velocity = 'vel' in common_heads.keys()",
            "def __init__(self, in_channels=[128], tasks=None, train_cfg=None, test_cfg=None, bbox_coder=None, common_heads=dict(), loss_cls=dict(type='GaussianFocalLoss', reduction='mean'), loss_bbox=dict(type='L1Loss', reduction='none', loss_weight=0.25), separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3), share_conv_channel=64, num_heatmap_convs=2, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', norm_bbox=True, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(CenterHead, self).__init__(init_cfg=init_cfg)\n    num_classes = [len(t['class_names']) for t in tasks]\n    self.class_names = [t['class_names'] for t in tasks]\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.norm_bbox = norm_bbox\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_anchor_per_locs = [n for n in num_classes]\n    self.fp16_enabled = False\n    self.shared_conv = ConvModule(in_channels, share_conv_channel, kernel_size=3, padding=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=bias)\n    self.task_heads = nn.ModuleList()\n    for num_cls in num_classes:\n        heads = copy.deepcopy(common_heads)\n        heads.update(dict(heatmap=(num_cls, num_heatmap_convs)))\n        separate_head.update(in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n        self.task_heads.append(builder.build_head(separate_head))\n    self.with_velocity = 'vel' in common_heads.keys()",
            "def __init__(self, in_channels=[128], tasks=None, train_cfg=None, test_cfg=None, bbox_coder=None, common_heads=dict(), loss_cls=dict(type='GaussianFocalLoss', reduction='mean'), loss_bbox=dict(type='L1Loss', reduction='none', loss_weight=0.25), separate_head=dict(type='SeparateHead', init_bias=-2.19, final_kernel=3), share_conv_channel=64, num_heatmap_convs=2, conv_cfg=dict(type='Conv2d'), norm_cfg=dict(type='BN2d'), bias='auto', norm_bbox=True, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert init_cfg is None, 'To prevent abnormal initialization behavior, init_cfg is not allowed to be set'\n    super(CenterHead, self).__init__(init_cfg=init_cfg)\n    num_classes = [len(t['class_names']) for t in tasks]\n    self.class_names = [t['class_names'] for t in tasks]\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.norm_bbox = norm_bbox\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_anchor_per_locs = [n for n in num_classes]\n    self.fp16_enabled = False\n    self.shared_conv = ConvModule(in_channels, share_conv_channel, kernel_size=3, padding=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=bias)\n    self.task_heads = nn.ModuleList()\n    for num_cls in num_classes:\n        heads = copy.deepcopy(common_heads)\n        heads.update(dict(heatmap=(num_cls, num_heatmap_convs)))\n        separate_head.update(in_channels=share_conv_channel, heads=heads, num_cls=num_cls)\n        self.task_heads.append(builder.build_head(separate_head))\n    self.with_velocity = 'vel' in common_heads.keys()"
        ]
    },
    {
        "func_name": "forward_single",
        "original": "def forward_single(self, x):\n    \"\"\"Forward function for CenterPoint.\n\n        Args:\n            x (torch.Tensor): Input feature map with the shape of\n                [B, 512, 128, 128].\n\n        Returns:\n            list[dict]: Output results for tasks.\n        \"\"\"\n    ret_dicts = []\n    x = self.shared_conv(x)\n    for task in self.task_heads:\n        ret_dicts.append(task(x))\n    return ret_dicts",
        "mutated": [
            "def forward_single(self, x):\n    if False:\n        i = 10\n    'Forward function for CenterPoint.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            list[dict]: Output results for tasks.\\n        '\n    ret_dicts = []\n    x = self.shared_conv(x)\n    for task in self.task_heads:\n        ret_dicts.append(task(x))\n    return ret_dicts",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward function for CenterPoint.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            list[dict]: Output results for tasks.\\n        '\n    ret_dicts = []\n    x = self.shared_conv(x)\n    for task in self.task_heads:\n        ret_dicts.append(task(x))\n    return ret_dicts",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward function for CenterPoint.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            list[dict]: Output results for tasks.\\n        '\n    ret_dicts = []\n    x = self.shared_conv(x)\n    for task in self.task_heads:\n        ret_dicts.append(task(x))\n    return ret_dicts",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward function for CenterPoint.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            list[dict]: Output results for tasks.\\n        '\n    ret_dicts = []\n    x = self.shared_conv(x)\n    for task in self.task_heads:\n        ret_dicts.append(task(x))\n    return ret_dicts",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward function for CenterPoint.\\n\\n        Args:\\n            x (torch.Tensor): Input feature map with the shape of\\n                [B, 512, 128, 128].\\n\\n        Returns:\\n            list[dict]: Output results for tasks.\\n        '\n    ret_dicts = []\n    x = self.shared_conv(x)\n    for task in self.task_heads:\n        ret_dicts.append(task(x))\n    return ret_dicts"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, feats):\n    \"\"\"Forward pass.\n\n        Args:\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\n                features produced by FPN.\n\n        Returns:\n            tuple(list[dict]): Output results for tasks.\n        \"\"\"\n    return multi_apply(self.forward_single, feats)",
        "mutated": [
            "def forward(self, feats):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple(list[dict]): Output results for tasks.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple(list[dict]): Output results for tasks.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple(list[dict]): Output results for tasks.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple(list[dict]): Output results for tasks.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple(list[dict]): Output results for tasks.\\n        '\n    return multi_apply(self.forward_single, feats)"
        ]
    },
    {
        "func_name": "_gather_feat",
        "original": "def _gather_feat(self, feat, ind, mask=None):\n    \"\"\"Gather feature map.\n\n        Given feature map and index, return indexed feature map.\n\n        Args:\n            feat (torch.tensor): Feature map with the shape of [B, H*W, 10].\n            ind (torch.Tensor): Index of the ground truth boxes with the\n                shape of [B, max_obj].\n            mask (torch.Tensor, optional): Mask of the feature map with the\n                shape of [B, max_obj]. Default: None.\n\n        Returns:\n            torch.Tensor: Feature map after gathering with the shape\n                of [B, max_obj, 10].\n        \"\"\"\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat",
        "mutated": [
            "def _gather_feat(self, feat, ind, mask=None):\n    if False:\n        i = 10\n    'Gather feature map.\\n\\n        Given feature map and index, return indexed feature map.\\n\\n        Args:\\n            feat (torch.tensor): Feature map with the shape of [B, H*W, 10].\\n            ind (torch.Tensor): Index of the ground truth boxes with the\\n                shape of [B, max_obj].\\n            mask (torch.Tensor, optional): Mask of the feature map with the\\n                shape of [B, max_obj]. Default: None.\\n\\n        Returns:\\n            torch.Tensor: Feature map after gathering with the shape\\n                of [B, max_obj, 10].\\n        '\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat",
            "def _gather_feat(self, feat, ind, mask=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Gather feature map.\\n\\n        Given feature map and index, return indexed feature map.\\n\\n        Args:\\n            feat (torch.tensor): Feature map with the shape of [B, H*W, 10].\\n            ind (torch.Tensor): Index of the ground truth boxes with the\\n                shape of [B, max_obj].\\n            mask (torch.Tensor, optional): Mask of the feature map with the\\n                shape of [B, max_obj]. Default: None.\\n\\n        Returns:\\n            torch.Tensor: Feature map after gathering with the shape\\n                of [B, max_obj, 10].\\n        '\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat",
            "def _gather_feat(self, feat, ind, mask=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Gather feature map.\\n\\n        Given feature map and index, return indexed feature map.\\n\\n        Args:\\n            feat (torch.tensor): Feature map with the shape of [B, H*W, 10].\\n            ind (torch.Tensor): Index of the ground truth boxes with the\\n                shape of [B, max_obj].\\n            mask (torch.Tensor, optional): Mask of the feature map with the\\n                shape of [B, max_obj]. Default: None.\\n\\n        Returns:\\n            torch.Tensor: Feature map after gathering with the shape\\n                of [B, max_obj, 10].\\n        '\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat",
            "def _gather_feat(self, feat, ind, mask=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Gather feature map.\\n\\n        Given feature map and index, return indexed feature map.\\n\\n        Args:\\n            feat (torch.tensor): Feature map with the shape of [B, H*W, 10].\\n            ind (torch.Tensor): Index of the ground truth boxes with the\\n                shape of [B, max_obj].\\n            mask (torch.Tensor, optional): Mask of the feature map with the\\n                shape of [B, max_obj]. Default: None.\\n\\n        Returns:\\n            torch.Tensor: Feature map after gathering with the shape\\n                of [B, max_obj, 10].\\n        '\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat",
            "def _gather_feat(self, feat, ind, mask=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Gather feature map.\\n\\n        Given feature map and index, return indexed feature map.\\n\\n        Args:\\n            feat (torch.tensor): Feature map with the shape of [B, H*W, 10].\\n            ind (torch.Tensor): Index of the ground truth boxes with the\\n                shape of [B, max_obj].\\n            mask (torch.Tensor, optional): Mask of the feature map with the\\n                shape of [B, max_obj]. Default: None.\\n\\n        Returns:\\n            torch.Tensor: Feature map after gathering with the shape\\n                of [B, max_obj, 10].\\n        '\n    dim = feat.size(2)\n    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n    feat = feat.gather(1, ind)\n    if mask is not None:\n        mask = mask.unsqueeze(2).expand_as(feat)\n        feat = feat[mask]\n        feat = feat.view(-1, dim)\n    return feat"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n    \"\"\"Generate targets.\n\n        How each output is transformed:\n\n            Each nested list is transposed so that all same-index elements in\n            each sub-list (1, ..., N) become the new sub-lists.\n                [ [a0, a1, a2, ... ], [b0, b1, b2, ... ], ... ]\n                ==> [ [a0, b0, ... ], [a1, b1, ... ], [a2, b2, ... ] ]\n\n            The new transposed nested list is converted into a list of N\n            tensors generated by concatenating tensors in the new sub-lists.\n                [ tensor0, tensor1, tensor2, ... ]\n\n        Args:\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\n                truth gt boxes.\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\n\n        Returns:\n            Returns:\n                tuple[list[torch.Tensor]]: Tuple of target including\n                    the following results in order.\n\n                    - list[torch.Tensor]: Heatmap scores.\n                    - list[torch.Tensor]: Ground truth boxes.\n                    - list[torch.Tensor]: Indexes indicating the\n                        position of the valid boxes.\n                    - list[torch.Tensor]: Masks indicating which\n                        boxes are valid.\n        \"\"\"\n    (heatmaps, anno_boxes, inds, masks) = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n    heatmaps = list(map(list, zip(*heatmaps)))\n    heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n    anno_boxes = list(map(list, zip(*anno_boxes)))\n    anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n    inds = list(map(list, zip(*inds)))\n    inds = [torch.stack(inds_) for inds_ in inds]\n    masks = list(map(list, zip(*masks)))\n    masks = [torch.stack(masks_) for masks_ in masks]\n    return (heatmaps, anno_boxes, inds, masks)",
        "mutated": [
            "def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n    'Generate targets.\\n\\n        How each output is transformed:\\n\\n            Each nested list is transposed so that all same-index elements in\\n            each sub-list (1, ..., N) become the new sub-lists.\\n                [ [a0, a1, a2, ... ], [b0, b1, b2, ... ], ... ]\\n                ==> [ [a0, b0, ... ], [a1, b1, ... ], [a2, b2, ... ] ]\\n\\n            The new transposed nested list is converted into a list of N\\n            tensors generated by concatenating tensors in the new sub-lists.\\n                [ tensor0, tensor1, tensor2, ... ]\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n\\n        Returns:\\n            Returns:\\n                tuple[list[torch.Tensor]]: Tuple of target including\\n                    the following results in order.\\n\\n                    - list[torch.Tensor]: Heatmap scores.\\n                    - list[torch.Tensor]: Ground truth boxes.\\n                    - list[torch.Tensor]: Indexes indicating the\\n                        position of the valid boxes.\\n                    - list[torch.Tensor]: Masks indicating which\\n                        boxes are valid.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n    heatmaps = list(map(list, zip(*heatmaps)))\n    heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n    anno_boxes = list(map(list, zip(*anno_boxes)))\n    anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n    inds = list(map(list, zip(*inds)))\n    inds = [torch.stack(inds_) for inds_ in inds]\n    masks = list(map(list, zip(*masks)))\n    masks = [torch.stack(masks_) for masks_ in masks]\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets.\\n\\n        How each output is transformed:\\n\\n            Each nested list is transposed so that all same-index elements in\\n            each sub-list (1, ..., N) become the new sub-lists.\\n                [ [a0, a1, a2, ... ], [b0, b1, b2, ... ], ... ]\\n                ==> [ [a0, b0, ... ], [a1, b1, ... ], [a2, b2, ... ] ]\\n\\n            The new transposed nested list is converted into a list of N\\n            tensors generated by concatenating tensors in the new sub-lists.\\n                [ tensor0, tensor1, tensor2, ... ]\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n\\n        Returns:\\n            Returns:\\n                tuple[list[torch.Tensor]]: Tuple of target including\\n                    the following results in order.\\n\\n                    - list[torch.Tensor]: Heatmap scores.\\n                    - list[torch.Tensor]: Ground truth boxes.\\n                    - list[torch.Tensor]: Indexes indicating the\\n                        position of the valid boxes.\\n                    - list[torch.Tensor]: Masks indicating which\\n                        boxes are valid.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n    heatmaps = list(map(list, zip(*heatmaps)))\n    heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n    anno_boxes = list(map(list, zip(*anno_boxes)))\n    anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n    inds = list(map(list, zip(*inds)))\n    inds = [torch.stack(inds_) for inds_ in inds]\n    masks = list(map(list, zip(*masks)))\n    masks = [torch.stack(masks_) for masks_ in masks]\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets.\\n\\n        How each output is transformed:\\n\\n            Each nested list is transposed so that all same-index elements in\\n            each sub-list (1, ..., N) become the new sub-lists.\\n                [ [a0, a1, a2, ... ], [b0, b1, b2, ... ], ... ]\\n                ==> [ [a0, b0, ... ], [a1, b1, ... ], [a2, b2, ... ] ]\\n\\n            The new transposed nested list is converted into a list of N\\n            tensors generated by concatenating tensors in the new sub-lists.\\n                [ tensor0, tensor1, tensor2, ... ]\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n\\n        Returns:\\n            Returns:\\n                tuple[list[torch.Tensor]]: Tuple of target including\\n                    the following results in order.\\n\\n                    - list[torch.Tensor]: Heatmap scores.\\n                    - list[torch.Tensor]: Ground truth boxes.\\n                    - list[torch.Tensor]: Indexes indicating the\\n                        position of the valid boxes.\\n                    - list[torch.Tensor]: Masks indicating which\\n                        boxes are valid.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n    heatmaps = list(map(list, zip(*heatmaps)))\n    heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n    anno_boxes = list(map(list, zip(*anno_boxes)))\n    anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n    inds = list(map(list, zip(*inds)))\n    inds = [torch.stack(inds_) for inds_ in inds]\n    masks = list(map(list, zip(*masks)))\n    masks = [torch.stack(masks_) for masks_ in masks]\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets.\\n\\n        How each output is transformed:\\n\\n            Each nested list is transposed so that all same-index elements in\\n            each sub-list (1, ..., N) become the new sub-lists.\\n                [ [a0, a1, a2, ... ], [b0, b1, b2, ... ], ... ]\\n                ==> [ [a0, b0, ... ], [a1, b1, ... ], [a2, b2, ... ] ]\\n\\n            The new transposed nested list is converted into a list of N\\n            tensors generated by concatenating tensors in the new sub-lists.\\n                [ tensor0, tensor1, tensor2, ... ]\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n\\n        Returns:\\n            Returns:\\n                tuple[list[torch.Tensor]]: Tuple of target including\\n                    the following results in order.\\n\\n                    - list[torch.Tensor]: Heatmap scores.\\n                    - list[torch.Tensor]: Ground truth boxes.\\n                    - list[torch.Tensor]: Indexes indicating the\\n                        position of the valid boxes.\\n                    - list[torch.Tensor]: Masks indicating which\\n                        boxes are valid.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n    heatmaps = list(map(list, zip(*heatmaps)))\n    heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n    anno_boxes = list(map(list, zip(*anno_boxes)))\n    anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n    inds = list(map(list, zip(*inds)))\n    inds = [torch.stack(inds_) for inds_ in inds]\n    masks = list(map(list, zip(*masks)))\n    masks = [torch.stack(masks_) for masks_ in masks]\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets.\\n\\n        How each output is transformed:\\n\\n            Each nested list is transposed so that all same-index elements in\\n            each sub-list (1, ..., N) become the new sub-lists.\\n                [ [a0, a1, a2, ... ], [b0, b1, b2, ... ], ... ]\\n                ==> [ [a0, b0, ... ], [a1, b1, ... ], [a2, b2, ... ] ]\\n\\n            The new transposed nested list is converted into a list of N\\n            tensors generated by concatenating tensors in the new sub-lists.\\n                [ tensor0, tensor1, tensor2, ... ]\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n\\n        Returns:\\n            Returns:\\n                tuple[list[torch.Tensor]]: Tuple of target including\\n                    the following results in order.\\n\\n                    - list[torch.Tensor]: Heatmap scores.\\n                    - list[torch.Tensor]: Ground truth boxes.\\n                    - list[torch.Tensor]: Indexes indicating the\\n                        position of the valid boxes.\\n                    - list[torch.Tensor]: Masks indicating which\\n                        boxes are valid.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = multi_apply(self.get_targets_single, gt_bboxes_3d, gt_labels_3d)\n    heatmaps = list(map(list, zip(*heatmaps)))\n    heatmaps = [torch.stack(hms_) for hms_ in heatmaps]\n    anno_boxes = list(map(list, zip(*anno_boxes)))\n    anno_boxes = [torch.stack(anno_boxes_) for anno_boxes_ in anno_boxes]\n    inds = list(map(list, zip(*inds)))\n    inds = [torch.stack(inds_) for inds_ in inds]\n    masks = list(map(list, zip(*masks)))\n    masks = [torch.stack(masks_) for masks_ in masks]\n    return (heatmaps, anno_boxes, inds, masks)"
        ]
    },
    {
        "func_name": "get_targets_single",
        "original": "def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n    \"\"\"Generate training targets for a single sample.\n\n        Args:\n            gt_bboxes_3d (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes.\n            gt_labels_3d (torch.Tensor): Labels of boxes.\n\n        Returns:\n            tuple[list[torch.Tensor]]: Tuple of target including\n                the following results in order.\n\n                - list[torch.Tensor]: Heatmap scores.\n                - list[torch.Tensor]: Ground truth boxes.\n                - list[torch.Tensor]: Indexes indicating the position\n                    of the valid boxes.\n                - list[torch.Tensor]: Masks indicating which boxes\n                    are valid.\n        \"\"\"\n    device = gt_labels_3d.device\n    gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]), dim=1).to(device)\n    max_objs = self.train_cfg['max_objs'] * self.train_cfg['dense_reg']\n    grid_size = torch.tensor(self.train_cfg['grid_size'])\n    pc_range = torch.tensor(self.train_cfg['point_cloud_range'])\n    voxel_size = torch.tensor(self.train_cfg['voxel_size'])\n    feature_map_size = grid_size[:2] // self.train_cfg['out_size_factor']\n    task_masks = []\n    flag = 0\n    for class_name in self.class_names:\n        task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag) for i in class_name])\n        flag += len(class_name)\n    task_boxes = []\n    task_classes = []\n    flag2 = 0\n    for (idx, mask) in enumerate(task_masks):\n        task_box = []\n        task_class = []\n        for m in mask:\n            task_box.append(gt_bboxes_3d[m])\n            task_class.append(gt_labels_3d[m] + 1 - flag2)\n        task_boxes.append(torch.cat(task_box, axis=0).to(device))\n        task_classes.append(torch.cat(task_class).long().to(device))\n        flag2 += len(mask)\n    draw_gaussian = draw_heatmap_gaussian\n    (heatmaps, anno_boxes, inds, masks) = ([], [], [], [])\n    for (idx, task_head) in enumerate(self.task_heads):\n        heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1], feature_map_size[0]))\n        if self.with_velocity:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 10), dtype=torch.float32)\n        else:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 8), dtype=torch.float32)\n        ind = gt_labels_3d.new_zeros(max_objs, dtype=torch.int64)\n        mask = gt_bboxes_3d.new_zeros(max_objs, dtype=torch.uint8)\n        num_objs = min(task_boxes[idx].shape[0], max_objs)\n        for k in range(num_objs):\n            cls_id = task_classes[idx][k] - 1\n            width = task_boxes[idx][k][3]\n            length = task_boxes[idx][k][4]\n            width = width / voxel_size[0] / self.train_cfg['out_size_factor']\n            length = length / voxel_size[1] / self.train_cfg['out_size_factor']\n            if width > 0 and length > 0:\n                radius = gaussian_radius((length, width), min_overlap=self.train_cfg['gaussian_overlap'])\n                radius = max(self.train_cfg['min_radius'], int(radius))\n                (x, y, z) = (task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2])\n                coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg['out_size_factor']\n                coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg['out_size_factor']\n                center = torch.tensor([coor_x, coor_y], dtype=torch.float32, device=device)\n                center_int = center.to(torch.int32)\n                if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                    continue\n                draw_gaussian(heatmap[cls_id], center_int, radius)\n                new_idx = k\n                (x, y) = (center_int[0], center_int[1])\n                assert y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1]\n                ind[new_idx] = y * feature_map_size[0] + x\n                mask[new_idx] = 1\n                rot = task_boxes[idx][k][6]\n                box_dim = task_boxes[idx][k][3:6]\n                if self.norm_bbox:\n                    box_dim = box_dim.log()\n                if self.with_velocity:\n                    (vx, vy) = task_boxes[idx][k][7:]\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0), vx.unsqueeze(0), vy.unsqueeze(0)])\n                else:\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0)])\n        heatmaps.append(heatmap)\n        anno_boxes.append(anno_box)\n        masks.append(mask)\n        inds.append(ind)\n    return (heatmaps, anno_boxes, inds, masks)",
        "mutated": [
            "def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes.\\n            gt_labels_3d (torch.Tensor): Labels of boxes.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Tuple of target including\\n                the following results in order.\\n\\n                - list[torch.Tensor]: Heatmap scores.\\n                - list[torch.Tensor]: Ground truth boxes.\\n                - list[torch.Tensor]: Indexes indicating the position\\n                    of the valid boxes.\\n                - list[torch.Tensor]: Masks indicating which boxes\\n                    are valid.\\n        '\n    device = gt_labels_3d.device\n    gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]), dim=1).to(device)\n    max_objs = self.train_cfg['max_objs'] * self.train_cfg['dense_reg']\n    grid_size = torch.tensor(self.train_cfg['grid_size'])\n    pc_range = torch.tensor(self.train_cfg['point_cloud_range'])\n    voxel_size = torch.tensor(self.train_cfg['voxel_size'])\n    feature_map_size = grid_size[:2] // self.train_cfg['out_size_factor']\n    task_masks = []\n    flag = 0\n    for class_name in self.class_names:\n        task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag) for i in class_name])\n        flag += len(class_name)\n    task_boxes = []\n    task_classes = []\n    flag2 = 0\n    for (idx, mask) in enumerate(task_masks):\n        task_box = []\n        task_class = []\n        for m in mask:\n            task_box.append(gt_bboxes_3d[m])\n            task_class.append(gt_labels_3d[m] + 1 - flag2)\n        task_boxes.append(torch.cat(task_box, axis=0).to(device))\n        task_classes.append(torch.cat(task_class).long().to(device))\n        flag2 += len(mask)\n    draw_gaussian = draw_heatmap_gaussian\n    (heatmaps, anno_boxes, inds, masks) = ([], [], [], [])\n    for (idx, task_head) in enumerate(self.task_heads):\n        heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1], feature_map_size[0]))\n        if self.with_velocity:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 10), dtype=torch.float32)\n        else:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 8), dtype=torch.float32)\n        ind = gt_labels_3d.new_zeros(max_objs, dtype=torch.int64)\n        mask = gt_bboxes_3d.new_zeros(max_objs, dtype=torch.uint8)\n        num_objs = min(task_boxes[idx].shape[0], max_objs)\n        for k in range(num_objs):\n            cls_id = task_classes[idx][k] - 1\n            width = task_boxes[idx][k][3]\n            length = task_boxes[idx][k][4]\n            width = width / voxel_size[0] / self.train_cfg['out_size_factor']\n            length = length / voxel_size[1] / self.train_cfg['out_size_factor']\n            if width > 0 and length > 0:\n                radius = gaussian_radius((length, width), min_overlap=self.train_cfg['gaussian_overlap'])\n                radius = max(self.train_cfg['min_radius'], int(radius))\n                (x, y, z) = (task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2])\n                coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg['out_size_factor']\n                coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg['out_size_factor']\n                center = torch.tensor([coor_x, coor_y], dtype=torch.float32, device=device)\n                center_int = center.to(torch.int32)\n                if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                    continue\n                draw_gaussian(heatmap[cls_id], center_int, radius)\n                new_idx = k\n                (x, y) = (center_int[0], center_int[1])\n                assert y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1]\n                ind[new_idx] = y * feature_map_size[0] + x\n                mask[new_idx] = 1\n                rot = task_boxes[idx][k][6]\n                box_dim = task_boxes[idx][k][3:6]\n                if self.norm_bbox:\n                    box_dim = box_dim.log()\n                if self.with_velocity:\n                    (vx, vy) = task_boxes[idx][k][7:]\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0), vx.unsqueeze(0), vy.unsqueeze(0)])\n                else:\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0)])\n        heatmaps.append(heatmap)\n        anno_boxes.append(anno_box)\n        masks.append(mask)\n        inds.append(ind)\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes.\\n            gt_labels_3d (torch.Tensor): Labels of boxes.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Tuple of target including\\n                the following results in order.\\n\\n                - list[torch.Tensor]: Heatmap scores.\\n                - list[torch.Tensor]: Ground truth boxes.\\n                - list[torch.Tensor]: Indexes indicating the position\\n                    of the valid boxes.\\n                - list[torch.Tensor]: Masks indicating which boxes\\n                    are valid.\\n        '\n    device = gt_labels_3d.device\n    gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]), dim=1).to(device)\n    max_objs = self.train_cfg['max_objs'] * self.train_cfg['dense_reg']\n    grid_size = torch.tensor(self.train_cfg['grid_size'])\n    pc_range = torch.tensor(self.train_cfg['point_cloud_range'])\n    voxel_size = torch.tensor(self.train_cfg['voxel_size'])\n    feature_map_size = grid_size[:2] // self.train_cfg['out_size_factor']\n    task_masks = []\n    flag = 0\n    for class_name in self.class_names:\n        task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag) for i in class_name])\n        flag += len(class_name)\n    task_boxes = []\n    task_classes = []\n    flag2 = 0\n    for (idx, mask) in enumerate(task_masks):\n        task_box = []\n        task_class = []\n        for m in mask:\n            task_box.append(gt_bboxes_3d[m])\n            task_class.append(gt_labels_3d[m] + 1 - flag2)\n        task_boxes.append(torch.cat(task_box, axis=0).to(device))\n        task_classes.append(torch.cat(task_class).long().to(device))\n        flag2 += len(mask)\n    draw_gaussian = draw_heatmap_gaussian\n    (heatmaps, anno_boxes, inds, masks) = ([], [], [], [])\n    for (idx, task_head) in enumerate(self.task_heads):\n        heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1], feature_map_size[0]))\n        if self.with_velocity:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 10), dtype=torch.float32)\n        else:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 8), dtype=torch.float32)\n        ind = gt_labels_3d.new_zeros(max_objs, dtype=torch.int64)\n        mask = gt_bboxes_3d.new_zeros(max_objs, dtype=torch.uint8)\n        num_objs = min(task_boxes[idx].shape[0], max_objs)\n        for k in range(num_objs):\n            cls_id = task_classes[idx][k] - 1\n            width = task_boxes[idx][k][3]\n            length = task_boxes[idx][k][4]\n            width = width / voxel_size[0] / self.train_cfg['out_size_factor']\n            length = length / voxel_size[1] / self.train_cfg['out_size_factor']\n            if width > 0 and length > 0:\n                radius = gaussian_radius((length, width), min_overlap=self.train_cfg['gaussian_overlap'])\n                radius = max(self.train_cfg['min_radius'], int(radius))\n                (x, y, z) = (task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2])\n                coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg['out_size_factor']\n                coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg['out_size_factor']\n                center = torch.tensor([coor_x, coor_y], dtype=torch.float32, device=device)\n                center_int = center.to(torch.int32)\n                if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                    continue\n                draw_gaussian(heatmap[cls_id], center_int, radius)\n                new_idx = k\n                (x, y) = (center_int[0], center_int[1])\n                assert y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1]\n                ind[new_idx] = y * feature_map_size[0] + x\n                mask[new_idx] = 1\n                rot = task_boxes[idx][k][6]\n                box_dim = task_boxes[idx][k][3:6]\n                if self.norm_bbox:\n                    box_dim = box_dim.log()\n                if self.with_velocity:\n                    (vx, vy) = task_boxes[idx][k][7:]\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0), vx.unsqueeze(0), vy.unsqueeze(0)])\n                else:\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0)])\n        heatmaps.append(heatmap)\n        anno_boxes.append(anno_box)\n        masks.append(mask)\n        inds.append(ind)\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes.\\n            gt_labels_3d (torch.Tensor): Labels of boxes.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Tuple of target including\\n                the following results in order.\\n\\n                - list[torch.Tensor]: Heatmap scores.\\n                - list[torch.Tensor]: Ground truth boxes.\\n                - list[torch.Tensor]: Indexes indicating the position\\n                    of the valid boxes.\\n                - list[torch.Tensor]: Masks indicating which boxes\\n                    are valid.\\n        '\n    device = gt_labels_3d.device\n    gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]), dim=1).to(device)\n    max_objs = self.train_cfg['max_objs'] * self.train_cfg['dense_reg']\n    grid_size = torch.tensor(self.train_cfg['grid_size'])\n    pc_range = torch.tensor(self.train_cfg['point_cloud_range'])\n    voxel_size = torch.tensor(self.train_cfg['voxel_size'])\n    feature_map_size = grid_size[:2] // self.train_cfg['out_size_factor']\n    task_masks = []\n    flag = 0\n    for class_name in self.class_names:\n        task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag) for i in class_name])\n        flag += len(class_name)\n    task_boxes = []\n    task_classes = []\n    flag2 = 0\n    for (idx, mask) in enumerate(task_masks):\n        task_box = []\n        task_class = []\n        for m in mask:\n            task_box.append(gt_bboxes_3d[m])\n            task_class.append(gt_labels_3d[m] + 1 - flag2)\n        task_boxes.append(torch.cat(task_box, axis=0).to(device))\n        task_classes.append(torch.cat(task_class).long().to(device))\n        flag2 += len(mask)\n    draw_gaussian = draw_heatmap_gaussian\n    (heatmaps, anno_boxes, inds, masks) = ([], [], [], [])\n    for (idx, task_head) in enumerate(self.task_heads):\n        heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1], feature_map_size[0]))\n        if self.with_velocity:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 10), dtype=torch.float32)\n        else:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 8), dtype=torch.float32)\n        ind = gt_labels_3d.new_zeros(max_objs, dtype=torch.int64)\n        mask = gt_bboxes_3d.new_zeros(max_objs, dtype=torch.uint8)\n        num_objs = min(task_boxes[idx].shape[0], max_objs)\n        for k in range(num_objs):\n            cls_id = task_classes[idx][k] - 1\n            width = task_boxes[idx][k][3]\n            length = task_boxes[idx][k][4]\n            width = width / voxel_size[0] / self.train_cfg['out_size_factor']\n            length = length / voxel_size[1] / self.train_cfg['out_size_factor']\n            if width > 0 and length > 0:\n                radius = gaussian_radius((length, width), min_overlap=self.train_cfg['gaussian_overlap'])\n                radius = max(self.train_cfg['min_radius'], int(radius))\n                (x, y, z) = (task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2])\n                coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg['out_size_factor']\n                coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg['out_size_factor']\n                center = torch.tensor([coor_x, coor_y], dtype=torch.float32, device=device)\n                center_int = center.to(torch.int32)\n                if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                    continue\n                draw_gaussian(heatmap[cls_id], center_int, radius)\n                new_idx = k\n                (x, y) = (center_int[0], center_int[1])\n                assert y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1]\n                ind[new_idx] = y * feature_map_size[0] + x\n                mask[new_idx] = 1\n                rot = task_boxes[idx][k][6]\n                box_dim = task_boxes[idx][k][3:6]\n                if self.norm_bbox:\n                    box_dim = box_dim.log()\n                if self.with_velocity:\n                    (vx, vy) = task_boxes[idx][k][7:]\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0), vx.unsqueeze(0), vy.unsqueeze(0)])\n                else:\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0)])\n        heatmaps.append(heatmap)\n        anno_boxes.append(anno_box)\n        masks.append(mask)\n        inds.append(ind)\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes.\\n            gt_labels_3d (torch.Tensor): Labels of boxes.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Tuple of target including\\n                the following results in order.\\n\\n                - list[torch.Tensor]: Heatmap scores.\\n                - list[torch.Tensor]: Ground truth boxes.\\n                - list[torch.Tensor]: Indexes indicating the position\\n                    of the valid boxes.\\n                - list[torch.Tensor]: Masks indicating which boxes\\n                    are valid.\\n        '\n    device = gt_labels_3d.device\n    gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]), dim=1).to(device)\n    max_objs = self.train_cfg['max_objs'] * self.train_cfg['dense_reg']\n    grid_size = torch.tensor(self.train_cfg['grid_size'])\n    pc_range = torch.tensor(self.train_cfg['point_cloud_range'])\n    voxel_size = torch.tensor(self.train_cfg['voxel_size'])\n    feature_map_size = grid_size[:2] // self.train_cfg['out_size_factor']\n    task_masks = []\n    flag = 0\n    for class_name in self.class_names:\n        task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag) for i in class_name])\n        flag += len(class_name)\n    task_boxes = []\n    task_classes = []\n    flag2 = 0\n    for (idx, mask) in enumerate(task_masks):\n        task_box = []\n        task_class = []\n        for m in mask:\n            task_box.append(gt_bboxes_3d[m])\n            task_class.append(gt_labels_3d[m] + 1 - flag2)\n        task_boxes.append(torch.cat(task_box, axis=0).to(device))\n        task_classes.append(torch.cat(task_class).long().to(device))\n        flag2 += len(mask)\n    draw_gaussian = draw_heatmap_gaussian\n    (heatmaps, anno_boxes, inds, masks) = ([], [], [], [])\n    for (idx, task_head) in enumerate(self.task_heads):\n        heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1], feature_map_size[0]))\n        if self.with_velocity:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 10), dtype=torch.float32)\n        else:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 8), dtype=torch.float32)\n        ind = gt_labels_3d.new_zeros(max_objs, dtype=torch.int64)\n        mask = gt_bboxes_3d.new_zeros(max_objs, dtype=torch.uint8)\n        num_objs = min(task_boxes[idx].shape[0], max_objs)\n        for k in range(num_objs):\n            cls_id = task_classes[idx][k] - 1\n            width = task_boxes[idx][k][3]\n            length = task_boxes[idx][k][4]\n            width = width / voxel_size[0] / self.train_cfg['out_size_factor']\n            length = length / voxel_size[1] / self.train_cfg['out_size_factor']\n            if width > 0 and length > 0:\n                radius = gaussian_radius((length, width), min_overlap=self.train_cfg['gaussian_overlap'])\n                radius = max(self.train_cfg['min_radius'], int(radius))\n                (x, y, z) = (task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2])\n                coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg['out_size_factor']\n                coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg['out_size_factor']\n                center = torch.tensor([coor_x, coor_y], dtype=torch.float32, device=device)\n                center_int = center.to(torch.int32)\n                if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                    continue\n                draw_gaussian(heatmap[cls_id], center_int, radius)\n                new_idx = k\n                (x, y) = (center_int[0], center_int[1])\n                assert y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1]\n                ind[new_idx] = y * feature_map_size[0] + x\n                mask[new_idx] = 1\n                rot = task_boxes[idx][k][6]\n                box_dim = task_boxes[idx][k][3:6]\n                if self.norm_bbox:\n                    box_dim = box_dim.log()\n                if self.with_velocity:\n                    (vx, vy) = task_boxes[idx][k][7:]\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0), vx.unsqueeze(0), vy.unsqueeze(0)])\n                else:\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0)])\n        heatmaps.append(heatmap)\n        anno_boxes.append(anno_box)\n        masks.append(mask)\n        inds.append(ind)\n    return (heatmaps, anno_boxes, inds, masks)",
            "def get_targets_single(self, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`LiDARInstance3DBoxes`): Ground truth gt boxes.\\n            gt_labels_3d (torch.Tensor): Labels of boxes.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Tuple of target including\\n                the following results in order.\\n\\n                - list[torch.Tensor]: Heatmap scores.\\n                - list[torch.Tensor]: Ground truth boxes.\\n                - list[torch.Tensor]: Indexes indicating the position\\n                    of the valid boxes.\\n                - list[torch.Tensor]: Masks indicating which boxes\\n                    are valid.\\n        '\n    device = gt_labels_3d.device\n    gt_bboxes_3d = torch.cat((gt_bboxes_3d.gravity_center, gt_bboxes_3d.tensor[:, 3:]), dim=1).to(device)\n    max_objs = self.train_cfg['max_objs'] * self.train_cfg['dense_reg']\n    grid_size = torch.tensor(self.train_cfg['grid_size'])\n    pc_range = torch.tensor(self.train_cfg['point_cloud_range'])\n    voxel_size = torch.tensor(self.train_cfg['voxel_size'])\n    feature_map_size = grid_size[:2] // self.train_cfg['out_size_factor']\n    task_masks = []\n    flag = 0\n    for class_name in self.class_names:\n        task_masks.append([torch.where(gt_labels_3d == class_name.index(i) + flag) for i in class_name])\n        flag += len(class_name)\n    task_boxes = []\n    task_classes = []\n    flag2 = 0\n    for (idx, mask) in enumerate(task_masks):\n        task_box = []\n        task_class = []\n        for m in mask:\n            task_box.append(gt_bboxes_3d[m])\n            task_class.append(gt_labels_3d[m] + 1 - flag2)\n        task_boxes.append(torch.cat(task_box, axis=0).to(device))\n        task_classes.append(torch.cat(task_class).long().to(device))\n        flag2 += len(mask)\n    draw_gaussian = draw_heatmap_gaussian\n    (heatmaps, anno_boxes, inds, masks) = ([], [], [], [])\n    for (idx, task_head) in enumerate(self.task_heads):\n        heatmap = gt_bboxes_3d.new_zeros((len(self.class_names[idx]), feature_map_size[1], feature_map_size[0]))\n        if self.with_velocity:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 10), dtype=torch.float32)\n        else:\n            anno_box = gt_bboxes_3d.new_zeros((max_objs, 8), dtype=torch.float32)\n        ind = gt_labels_3d.new_zeros(max_objs, dtype=torch.int64)\n        mask = gt_bboxes_3d.new_zeros(max_objs, dtype=torch.uint8)\n        num_objs = min(task_boxes[idx].shape[0], max_objs)\n        for k in range(num_objs):\n            cls_id = task_classes[idx][k] - 1\n            width = task_boxes[idx][k][3]\n            length = task_boxes[idx][k][4]\n            width = width / voxel_size[0] / self.train_cfg['out_size_factor']\n            length = length / voxel_size[1] / self.train_cfg['out_size_factor']\n            if width > 0 and length > 0:\n                radius = gaussian_radius((length, width), min_overlap=self.train_cfg['gaussian_overlap'])\n                radius = max(self.train_cfg['min_radius'], int(radius))\n                (x, y, z) = (task_boxes[idx][k][0], task_boxes[idx][k][1], task_boxes[idx][k][2])\n                coor_x = (x - pc_range[0]) / voxel_size[0] / self.train_cfg['out_size_factor']\n                coor_y = (y - pc_range[1]) / voxel_size[1] / self.train_cfg['out_size_factor']\n                center = torch.tensor([coor_x, coor_y], dtype=torch.float32, device=device)\n                center_int = center.to(torch.int32)\n                if not (0 <= center_int[0] < feature_map_size[0] and 0 <= center_int[1] < feature_map_size[1]):\n                    continue\n                draw_gaussian(heatmap[cls_id], center_int, radius)\n                new_idx = k\n                (x, y) = (center_int[0], center_int[1])\n                assert y * feature_map_size[0] + x < feature_map_size[0] * feature_map_size[1]\n                ind[new_idx] = y * feature_map_size[0] + x\n                mask[new_idx] = 1\n                rot = task_boxes[idx][k][6]\n                box_dim = task_boxes[idx][k][3:6]\n                if self.norm_bbox:\n                    box_dim = box_dim.log()\n                if self.with_velocity:\n                    (vx, vy) = task_boxes[idx][k][7:]\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0), vx.unsqueeze(0), vy.unsqueeze(0)])\n                else:\n                    anno_box[new_idx] = torch.cat([center - torch.tensor([x, y], device=device), z.unsqueeze(0), box_dim, torch.sin(rot).unsqueeze(0), torch.cos(rot).unsqueeze(0)])\n        heatmaps.append(heatmap)\n        anno_boxes.append(anno_box)\n        masks.append(mask)\n        inds.append(ind)\n    return (heatmaps, anno_boxes, inds, masks)"
        ]
    },
    {
        "func_name": "loss",
        "original": "@force_fp32(apply_to='preds_dicts')\ndef loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n    \"\"\"Loss function for CenterHead.\n\n        Args:\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\n                truth gt boxes.\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\n            preds_dicts (dict): Output of forward function.\n\n        Returns:\n            dict[str:torch.Tensor]: Loss of heatmap and bbox of each task.\n        \"\"\"\n    (heatmaps, anno_boxes, inds, masks) = self.get_targets(gt_bboxes_3d, gt_labels_3d)\n    loss_dict = dict()\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        preds_dict[0]['heatmap'] = clip_sigmoid(preds_dict[0]['heatmap'])\n        num_pos = heatmaps[task_id].eq(1).float().sum().item()\n        loss_heatmap = self.loss_cls(preds_dict[0]['heatmap'], heatmaps[task_id], avg_factor=max(num_pos, 1))\n        target_box = anno_boxes[task_id]\n        if self.with_velocity:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot'], preds_dict[0]['vel']), dim=1)\n        else:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot']), dim=1)\n        ind = inds[task_id]\n        num = masks[task_id].float().sum()\n        pred = preds_dict[0]['anno_box'].permute(0, 2, 3, 1).contiguous()\n        pred = pred.view(pred.size(0), -1, pred.size(3))\n        pred = self._gather_feat(pred, ind)\n        mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n        isnotnan = (~torch.isnan(target_box)).float()\n        mask *= isnotnan\n        code_weights = self.train_cfg.get('code_weights', None)\n        bbox_weights = mask * mask.new_tensor(code_weights)\n        loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=num + 0.0001)\n        loss_dict[f'task{task_id}.loss_heatmap'] = loss_heatmap\n        loss_dict[f'task{task_id}.loss_bbox'] = loss_bbox\n    return loss_dict",
        "mutated": [
            "@force_fp32(apply_to='preds_dicts')\ndef loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n    if False:\n        i = 10\n    'Loss function for CenterHead.\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n            preds_dicts (dict): Output of forward function.\\n\\n        Returns:\\n            dict[str:torch.Tensor]: Loss of heatmap and bbox of each task.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = self.get_targets(gt_bboxes_3d, gt_labels_3d)\n    loss_dict = dict()\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        preds_dict[0]['heatmap'] = clip_sigmoid(preds_dict[0]['heatmap'])\n        num_pos = heatmaps[task_id].eq(1).float().sum().item()\n        loss_heatmap = self.loss_cls(preds_dict[0]['heatmap'], heatmaps[task_id], avg_factor=max(num_pos, 1))\n        target_box = anno_boxes[task_id]\n        if self.with_velocity:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot'], preds_dict[0]['vel']), dim=1)\n        else:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot']), dim=1)\n        ind = inds[task_id]\n        num = masks[task_id].float().sum()\n        pred = preds_dict[0]['anno_box'].permute(0, 2, 3, 1).contiguous()\n        pred = pred.view(pred.size(0), -1, pred.size(3))\n        pred = self._gather_feat(pred, ind)\n        mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n        isnotnan = (~torch.isnan(target_box)).float()\n        mask *= isnotnan\n        code_weights = self.train_cfg.get('code_weights', None)\n        bbox_weights = mask * mask.new_tensor(code_weights)\n        loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=num + 0.0001)\n        loss_dict[f'task{task_id}.loss_heatmap'] = loss_heatmap\n        loss_dict[f'task{task_id}.loss_bbox'] = loss_bbox\n    return loss_dict",
            "@force_fp32(apply_to='preds_dicts')\ndef loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Loss function for CenterHead.\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n            preds_dicts (dict): Output of forward function.\\n\\n        Returns:\\n            dict[str:torch.Tensor]: Loss of heatmap and bbox of each task.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = self.get_targets(gt_bboxes_3d, gt_labels_3d)\n    loss_dict = dict()\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        preds_dict[0]['heatmap'] = clip_sigmoid(preds_dict[0]['heatmap'])\n        num_pos = heatmaps[task_id].eq(1).float().sum().item()\n        loss_heatmap = self.loss_cls(preds_dict[0]['heatmap'], heatmaps[task_id], avg_factor=max(num_pos, 1))\n        target_box = anno_boxes[task_id]\n        if self.with_velocity:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot'], preds_dict[0]['vel']), dim=1)\n        else:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot']), dim=1)\n        ind = inds[task_id]\n        num = masks[task_id].float().sum()\n        pred = preds_dict[0]['anno_box'].permute(0, 2, 3, 1).contiguous()\n        pred = pred.view(pred.size(0), -1, pred.size(3))\n        pred = self._gather_feat(pred, ind)\n        mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n        isnotnan = (~torch.isnan(target_box)).float()\n        mask *= isnotnan\n        code_weights = self.train_cfg.get('code_weights', None)\n        bbox_weights = mask * mask.new_tensor(code_weights)\n        loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=num + 0.0001)\n        loss_dict[f'task{task_id}.loss_heatmap'] = loss_heatmap\n        loss_dict[f'task{task_id}.loss_bbox'] = loss_bbox\n    return loss_dict",
            "@force_fp32(apply_to='preds_dicts')\ndef loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Loss function for CenterHead.\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n            preds_dicts (dict): Output of forward function.\\n\\n        Returns:\\n            dict[str:torch.Tensor]: Loss of heatmap and bbox of each task.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = self.get_targets(gt_bboxes_3d, gt_labels_3d)\n    loss_dict = dict()\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        preds_dict[0]['heatmap'] = clip_sigmoid(preds_dict[0]['heatmap'])\n        num_pos = heatmaps[task_id].eq(1).float().sum().item()\n        loss_heatmap = self.loss_cls(preds_dict[0]['heatmap'], heatmaps[task_id], avg_factor=max(num_pos, 1))\n        target_box = anno_boxes[task_id]\n        if self.with_velocity:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot'], preds_dict[0]['vel']), dim=1)\n        else:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot']), dim=1)\n        ind = inds[task_id]\n        num = masks[task_id].float().sum()\n        pred = preds_dict[0]['anno_box'].permute(0, 2, 3, 1).contiguous()\n        pred = pred.view(pred.size(0), -1, pred.size(3))\n        pred = self._gather_feat(pred, ind)\n        mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n        isnotnan = (~torch.isnan(target_box)).float()\n        mask *= isnotnan\n        code_weights = self.train_cfg.get('code_weights', None)\n        bbox_weights = mask * mask.new_tensor(code_weights)\n        loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=num + 0.0001)\n        loss_dict[f'task{task_id}.loss_heatmap'] = loss_heatmap\n        loss_dict[f'task{task_id}.loss_bbox'] = loss_bbox\n    return loss_dict",
            "@force_fp32(apply_to='preds_dicts')\ndef loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Loss function for CenterHead.\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n            preds_dicts (dict): Output of forward function.\\n\\n        Returns:\\n            dict[str:torch.Tensor]: Loss of heatmap and bbox of each task.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = self.get_targets(gt_bboxes_3d, gt_labels_3d)\n    loss_dict = dict()\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        preds_dict[0]['heatmap'] = clip_sigmoid(preds_dict[0]['heatmap'])\n        num_pos = heatmaps[task_id].eq(1).float().sum().item()\n        loss_heatmap = self.loss_cls(preds_dict[0]['heatmap'], heatmaps[task_id], avg_factor=max(num_pos, 1))\n        target_box = anno_boxes[task_id]\n        if self.with_velocity:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot'], preds_dict[0]['vel']), dim=1)\n        else:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot']), dim=1)\n        ind = inds[task_id]\n        num = masks[task_id].float().sum()\n        pred = preds_dict[0]['anno_box'].permute(0, 2, 3, 1).contiguous()\n        pred = pred.view(pred.size(0), -1, pred.size(3))\n        pred = self._gather_feat(pred, ind)\n        mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n        isnotnan = (~torch.isnan(target_box)).float()\n        mask *= isnotnan\n        code_weights = self.train_cfg.get('code_weights', None)\n        bbox_weights = mask * mask.new_tensor(code_weights)\n        loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=num + 0.0001)\n        loss_dict[f'task{task_id}.loss_heatmap'] = loss_heatmap\n        loss_dict[f'task{task_id}.loss_bbox'] = loss_bbox\n    return loss_dict",
            "@force_fp32(apply_to='preds_dicts')\ndef loss(self, gt_bboxes_3d, gt_labels_3d, preds_dicts, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Loss function for CenterHead.\\n\\n        Args:\\n            gt_bboxes_3d (list[:obj:`LiDARInstance3DBoxes`]): Ground\\n                truth gt boxes.\\n            gt_labels_3d (list[torch.Tensor]): Labels of boxes.\\n            preds_dicts (dict): Output of forward function.\\n\\n        Returns:\\n            dict[str:torch.Tensor]: Loss of heatmap and bbox of each task.\\n        '\n    (heatmaps, anno_boxes, inds, masks) = self.get_targets(gt_bboxes_3d, gt_labels_3d)\n    loss_dict = dict()\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        preds_dict[0]['heatmap'] = clip_sigmoid(preds_dict[0]['heatmap'])\n        num_pos = heatmaps[task_id].eq(1).float().sum().item()\n        loss_heatmap = self.loss_cls(preds_dict[0]['heatmap'], heatmaps[task_id], avg_factor=max(num_pos, 1))\n        target_box = anno_boxes[task_id]\n        if self.with_velocity:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot'], preds_dict[0]['vel']), dim=1)\n        else:\n            preds_dict[0]['anno_box'] = torch.cat((preds_dict[0]['reg'], preds_dict[0]['height'], preds_dict[0]['dim'], preds_dict[0]['rot']), dim=1)\n        ind = inds[task_id]\n        num = masks[task_id].float().sum()\n        pred = preds_dict[0]['anno_box'].permute(0, 2, 3, 1).contiguous()\n        pred = pred.view(pred.size(0), -1, pred.size(3))\n        pred = self._gather_feat(pred, ind)\n        mask = masks[task_id].unsqueeze(2).expand_as(target_box).float()\n        isnotnan = (~torch.isnan(target_box)).float()\n        mask *= isnotnan\n        code_weights = self.train_cfg.get('code_weights', None)\n        bbox_weights = mask * mask.new_tensor(code_weights)\n        loss_bbox = self.loss_bbox(pred, target_box, bbox_weights, avg_factor=num + 0.0001)\n        loss_dict[f'task{task_id}.loss_heatmap'] = loss_heatmap\n        loss_dict[f'task{task_id}.loss_bbox'] = loss_bbox\n    return loss_dict"
        ]
    },
    {
        "func_name": "get_bboxes",
        "original": "def get_bboxes(self, preds_dicts, img_metas, img=None, rescale=False):\n    \"\"\"Generate bboxes from bbox head predictions.\n\n        Args:\n            preds_dicts (tuple[list[dict]]): Prediction results.\n            img_metas (list[dict]): Point cloud and image's meta info.\n\n        Returns:\n            list[dict]: Decoded bbox, scores and labels after nms.\n        \"\"\"\n    rets = []\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        num_class_with_bg = self.num_classes[task_id]\n        batch_size = preds_dict[0]['heatmap'].shape[0]\n        batch_heatmap = preds_dict[0]['heatmap'].sigmoid()\n        batch_reg = preds_dict[0]['reg']\n        batch_hei = preds_dict[0]['height']\n        if self.norm_bbox:\n            batch_dim = torch.exp(preds_dict[0]['dim'])\n        else:\n            batch_dim = preds_dict[0]['dim']\n        batch_rots = preds_dict[0]['rot'][:, 0].unsqueeze(1)\n        batch_rotc = preds_dict[0]['rot'][:, 1].unsqueeze(1)\n        if 'vel' in preds_dict[0]:\n            batch_vel = preds_dict[0]['vel']\n        else:\n            batch_vel = None\n        temp = self.bbox_coder.decode(batch_heatmap, batch_rots, batch_rotc, batch_hei, batch_dim, batch_vel, reg=batch_reg, task_id=task_id)\n        assert self.test_cfg['nms_type'] in ['circle', 'rotate']\n        batch_reg_preds = [box['bboxes'] for box in temp]\n        batch_cls_preds = [box['scores'] for box in temp]\n        batch_cls_labels = [box['labels'] for box in temp]\n        if self.test_cfg['nms_type'] == 'circle':\n            ret_task = []\n            for i in range(batch_size):\n                boxes3d = temp[i]['bboxes']\n                scores = temp[i]['scores']\n                labels = temp[i]['labels']\n                centers = boxes3d[:, [0, 1]]\n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                keep = torch.tensor(circle_nms(boxes.detach().cpu().numpy(), self.test_cfg['min_radius'][task_id], post_max_size=self.test_cfg['post_max_size']), dtype=torch.long, device=boxes.device)\n                boxes3d = boxes3d[keep]\n                scores = scores[keep]\n                labels = labels[keep]\n                ret = dict(bboxes=boxes3d, scores=scores, labels=labels)\n                ret_task.append(ret)\n            rets.append(ret_task)\n        else:\n            rets.append(self.get_task_detections(num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas))\n    num_samples = len(rets[0])\n    ret_list = []\n    for i in range(num_samples):\n        for k in rets[0][i].keys():\n            if k == 'bboxes':\n                bboxes = torch.cat([ret[i][k] for ret in rets])\n                bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 5] * 0.5\n                bboxes = img_metas[i]['box_type_3d'](bboxes, self.bbox_coder.code_size)\n            elif k == 'scores':\n                scores = torch.cat([ret[i][k] for ret in rets])\n            elif k == 'labels':\n                flag = 0\n                for (j, num_class) in enumerate(self.num_classes):\n                    rets[j][i][k] += flag\n                    flag += num_class\n                labels = torch.cat([ret[i][k].int() for ret in rets])\n        ret_list.append([bboxes, scores, labels])\n    return ret_list",
        "mutated": [
            "def get_bboxes(self, preds_dicts, img_metas, img=None, rescale=False):\n    if False:\n        i = 10\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            preds_dicts (tuple[list[dict]]): Prediction results.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n\\n        Returns:\\n            list[dict]: Decoded bbox, scores and labels after nms.\\n        \"\n    rets = []\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        num_class_with_bg = self.num_classes[task_id]\n        batch_size = preds_dict[0]['heatmap'].shape[0]\n        batch_heatmap = preds_dict[0]['heatmap'].sigmoid()\n        batch_reg = preds_dict[0]['reg']\n        batch_hei = preds_dict[0]['height']\n        if self.norm_bbox:\n            batch_dim = torch.exp(preds_dict[0]['dim'])\n        else:\n            batch_dim = preds_dict[0]['dim']\n        batch_rots = preds_dict[0]['rot'][:, 0].unsqueeze(1)\n        batch_rotc = preds_dict[0]['rot'][:, 1].unsqueeze(1)\n        if 'vel' in preds_dict[0]:\n            batch_vel = preds_dict[0]['vel']\n        else:\n            batch_vel = None\n        temp = self.bbox_coder.decode(batch_heatmap, batch_rots, batch_rotc, batch_hei, batch_dim, batch_vel, reg=batch_reg, task_id=task_id)\n        assert self.test_cfg['nms_type'] in ['circle', 'rotate']\n        batch_reg_preds = [box['bboxes'] for box in temp]\n        batch_cls_preds = [box['scores'] for box in temp]\n        batch_cls_labels = [box['labels'] for box in temp]\n        if self.test_cfg['nms_type'] == 'circle':\n            ret_task = []\n            for i in range(batch_size):\n                boxes3d = temp[i]['bboxes']\n                scores = temp[i]['scores']\n                labels = temp[i]['labels']\n                centers = boxes3d[:, [0, 1]]\n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                keep = torch.tensor(circle_nms(boxes.detach().cpu().numpy(), self.test_cfg['min_radius'][task_id], post_max_size=self.test_cfg['post_max_size']), dtype=torch.long, device=boxes.device)\n                boxes3d = boxes3d[keep]\n                scores = scores[keep]\n                labels = labels[keep]\n                ret = dict(bboxes=boxes3d, scores=scores, labels=labels)\n                ret_task.append(ret)\n            rets.append(ret_task)\n        else:\n            rets.append(self.get_task_detections(num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas))\n    num_samples = len(rets[0])\n    ret_list = []\n    for i in range(num_samples):\n        for k in rets[0][i].keys():\n            if k == 'bboxes':\n                bboxes = torch.cat([ret[i][k] for ret in rets])\n                bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 5] * 0.5\n                bboxes = img_metas[i]['box_type_3d'](bboxes, self.bbox_coder.code_size)\n            elif k == 'scores':\n                scores = torch.cat([ret[i][k] for ret in rets])\n            elif k == 'labels':\n                flag = 0\n                for (j, num_class) in enumerate(self.num_classes):\n                    rets[j][i][k] += flag\n                    flag += num_class\n                labels = torch.cat([ret[i][k].int() for ret in rets])\n        ret_list.append([bboxes, scores, labels])\n    return ret_list",
            "def get_bboxes(self, preds_dicts, img_metas, img=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            preds_dicts (tuple[list[dict]]): Prediction results.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n\\n        Returns:\\n            list[dict]: Decoded bbox, scores and labels after nms.\\n        \"\n    rets = []\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        num_class_with_bg = self.num_classes[task_id]\n        batch_size = preds_dict[0]['heatmap'].shape[0]\n        batch_heatmap = preds_dict[0]['heatmap'].sigmoid()\n        batch_reg = preds_dict[0]['reg']\n        batch_hei = preds_dict[0]['height']\n        if self.norm_bbox:\n            batch_dim = torch.exp(preds_dict[0]['dim'])\n        else:\n            batch_dim = preds_dict[0]['dim']\n        batch_rots = preds_dict[0]['rot'][:, 0].unsqueeze(1)\n        batch_rotc = preds_dict[0]['rot'][:, 1].unsqueeze(1)\n        if 'vel' in preds_dict[0]:\n            batch_vel = preds_dict[0]['vel']\n        else:\n            batch_vel = None\n        temp = self.bbox_coder.decode(batch_heatmap, batch_rots, batch_rotc, batch_hei, batch_dim, batch_vel, reg=batch_reg, task_id=task_id)\n        assert self.test_cfg['nms_type'] in ['circle', 'rotate']\n        batch_reg_preds = [box['bboxes'] for box in temp]\n        batch_cls_preds = [box['scores'] for box in temp]\n        batch_cls_labels = [box['labels'] for box in temp]\n        if self.test_cfg['nms_type'] == 'circle':\n            ret_task = []\n            for i in range(batch_size):\n                boxes3d = temp[i]['bboxes']\n                scores = temp[i]['scores']\n                labels = temp[i]['labels']\n                centers = boxes3d[:, [0, 1]]\n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                keep = torch.tensor(circle_nms(boxes.detach().cpu().numpy(), self.test_cfg['min_radius'][task_id], post_max_size=self.test_cfg['post_max_size']), dtype=torch.long, device=boxes.device)\n                boxes3d = boxes3d[keep]\n                scores = scores[keep]\n                labels = labels[keep]\n                ret = dict(bboxes=boxes3d, scores=scores, labels=labels)\n                ret_task.append(ret)\n            rets.append(ret_task)\n        else:\n            rets.append(self.get_task_detections(num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas))\n    num_samples = len(rets[0])\n    ret_list = []\n    for i in range(num_samples):\n        for k in rets[0][i].keys():\n            if k == 'bboxes':\n                bboxes = torch.cat([ret[i][k] for ret in rets])\n                bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 5] * 0.5\n                bboxes = img_metas[i]['box_type_3d'](bboxes, self.bbox_coder.code_size)\n            elif k == 'scores':\n                scores = torch.cat([ret[i][k] for ret in rets])\n            elif k == 'labels':\n                flag = 0\n                for (j, num_class) in enumerate(self.num_classes):\n                    rets[j][i][k] += flag\n                    flag += num_class\n                labels = torch.cat([ret[i][k].int() for ret in rets])\n        ret_list.append([bboxes, scores, labels])\n    return ret_list",
            "def get_bboxes(self, preds_dicts, img_metas, img=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            preds_dicts (tuple[list[dict]]): Prediction results.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n\\n        Returns:\\n            list[dict]: Decoded bbox, scores and labels after nms.\\n        \"\n    rets = []\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        num_class_with_bg = self.num_classes[task_id]\n        batch_size = preds_dict[0]['heatmap'].shape[0]\n        batch_heatmap = preds_dict[0]['heatmap'].sigmoid()\n        batch_reg = preds_dict[0]['reg']\n        batch_hei = preds_dict[0]['height']\n        if self.norm_bbox:\n            batch_dim = torch.exp(preds_dict[0]['dim'])\n        else:\n            batch_dim = preds_dict[0]['dim']\n        batch_rots = preds_dict[0]['rot'][:, 0].unsqueeze(1)\n        batch_rotc = preds_dict[0]['rot'][:, 1].unsqueeze(1)\n        if 'vel' in preds_dict[0]:\n            batch_vel = preds_dict[0]['vel']\n        else:\n            batch_vel = None\n        temp = self.bbox_coder.decode(batch_heatmap, batch_rots, batch_rotc, batch_hei, batch_dim, batch_vel, reg=batch_reg, task_id=task_id)\n        assert self.test_cfg['nms_type'] in ['circle', 'rotate']\n        batch_reg_preds = [box['bboxes'] for box in temp]\n        batch_cls_preds = [box['scores'] for box in temp]\n        batch_cls_labels = [box['labels'] for box in temp]\n        if self.test_cfg['nms_type'] == 'circle':\n            ret_task = []\n            for i in range(batch_size):\n                boxes3d = temp[i]['bboxes']\n                scores = temp[i]['scores']\n                labels = temp[i]['labels']\n                centers = boxes3d[:, [0, 1]]\n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                keep = torch.tensor(circle_nms(boxes.detach().cpu().numpy(), self.test_cfg['min_radius'][task_id], post_max_size=self.test_cfg['post_max_size']), dtype=torch.long, device=boxes.device)\n                boxes3d = boxes3d[keep]\n                scores = scores[keep]\n                labels = labels[keep]\n                ret = dict(bboxes=boxes3d, scores=scores, labels=labels)\n                ret_task.append(ret)\n            rets.append(ret_task)\n        else:\n            rets.append(self.get_task_detections(num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas))\n    num_samples = len(rets[0])\n    ret_list = []\n    for i in range(num_samples):\n        for k in rets[0][i].keys():\n            if k == 'bboxes':\n                bboxes = torch.cat([ret[i][k] for ret in rets])\n                bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 5] * 0.5\n                bboxes = img_metas[i]['box_type_3d'](bboxes, self.bbox_coder.code_size)\n            elif k == 'scores':\n                scores = torch.cat([ret[i][k] for ret in rets])\n            elif k == 'labels':\n                flag = 0\n                for (j, num_class) in enumerate(self.num_classes):\n                    rets[j][i][k] += flag\n                    flag += num_class\n                labels = torch.cat([ret[i][k].int() for ret in rets])\n        ret_list.append([bboxes, scores, labels])\n    return ret_list",
            "def get_bboxes(self, preds_dicts, img_metas, img=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            preds_dicts (tuple[list[dict]]): Prediction results.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n\\n        Returns:\\n            list[dict]: Decoded bbox, scores and labels after nms.\\n        \"\n    rets = []\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        num_class_with_bg = self.num_classes[task_id]\n        batch_size = preds_dict[0]['heatmap'].shape[0]\n        batch_heatmap = preds_dict[0]['heatmap'].sigmoid()\n        batch_reg = preds_dict[0]['reg']\n        batch_hei = preds_dict[0]['height']\n        if self.norm_bbox:\n            batch_dim = torch.exp(preds_dict[0]['dim'])\n        else:\n            batch_dim = preds_dict[0]['dim']\n        batch_rots = preds_dict[0]['rot'][:, 0].unsqueeze(1)\n        batch_rotc = preds_dict[0]['rot'][:, 1].unsqueeze(1)\n        if 'vel' in preds_dict[0]:\n            batch_vel = preds_dict[0]['vel']\n        else:\n            batch_vel = None\n        temp = self.bbox_coder.decode(batch_heatmap, batch_rots, batch_rotc, batch_hei, batch_dim, batch_vel, reg=batch_reg, task_id=task_id)\n        assert self.test_cfg['nms_type'] in ['circle', 'rotate']\n        batch_reg_preds = [box['bboxes'] for box in temp]\n        batch_cls_preds = [box['scores'] for box in temp]\n        batch_cls_labels = [box['labels'] for box in temp]\n        if self.test_cfg['nms_type'] == 'circle':\n            ret_task = []\n            for i in range(batch_size):\n                boxes3d = temp[i]['bboxes']\n                scores = temp[i]['scores']\n                labels = temp[i]['labels']\n                centers = boxes3d[:, [0, 1]]\n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                keep = torch.tensor(circle_nms(boxes.detach().cpu().numpy(), self.test_cfg['min_radius'][task_id], post_max_size=self.test_cfg['post_max_size']), dtype=torch.long, device=boxes.device)\n                boxes3d = boxes3d[keep]\n                scores = scores[keep]\n                labels = labels[keep]\n                ret = dict(bboxes=boxes3d, scores=scores, labels=labels)\n                ret_task.append(ret)\n            rets.append(ret_task)\n        else:\n            rets.append(self.get_task_detections(num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas))\n    num_samples = len(rets[0])\n    ret_list = []\n    for i in range(num_samples):\n        for k in rets[0][i].keys():\n            if k == 'bboxes':\n                bboxes = torch.cat([ret[i][k] for ret in rets])\n                bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 5] * 0.5\n                bboxes = img_metas[i]['box_type_3d'](bboxes, self.bbox_coder.code_size)\n            elif k == 'scores':\n                scores = torch.cat([ret[i][k] for ret in rets])\n            elif k == 'labels':\n                flag = 0\n                for (j, num_class) in enumerate(self.num_classes):\n                    rets[j][i][k] += flag\n                    flag += num_class\n                labels = torch.cat([ret[i][k].int() for ret in rets])\n        ret_list.append([bboxes, scores, labels])\n    return ret_list",
            "def get_bboxes(self, preds_dicts, img_metas, img=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            preds_dicts (tuple[list[dict]]): Prediction results.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n\\n        Returns:\\n            list[dict]: Decoded bbox, scores and labels after nms.\\n        \"\n    rets = []\n    for (task_id, preds_dict) in enumerate(preds_dicts):\n        num_class_with_bg = self.num_classes[task_id]\n        batch_size = preds_dict[0]['heatmap'].shape[0]\n        batch_heatmap = preds_dict[0]['heatmap'].sigmoid()\n        batch_reg = preds_dict[0]['reg']\n        batch_hei = preds_dict[0]['height']\n        if self.norm_bbox:\n            batch_dim = torch.exp(preds_dict[0]['dim'])\n        else:\n            batch_dim = preds_dict[0]['dim']\n        batch_rots = preds_dict[0]['rot'][:, 0].unsqueeze(1)\n        batch_rotc = preds_dict[0]['rot'][:, 1].unsqueeze(1)\n        if 'vel' in preds_dict[0]:\n            batch_vel = preds_dict[0]['vel']\n        else:\n            batch_vel = None\n        temp = self.bbox_coder.decode(batch_heatmap, batch_rots, batch_rotc, batch_hei, batch_dim, batch_vel, reg=batch_reg, task_id=task_id)\n        assert self.test_cfg['nms_type'] in ['circle', 'rotate']\n        batch_reg_preds = [box['bboxes'] for box in temp]\n        batch_cls_preds = [box['scores'] for box in temp]\n        batch_cls_labels = [box['labels'] for box in temp]\n        if self.test_cfg['nms_type'] == 'circle':\n            ret_task = []\n            for i in range(batch_size):\n                boxes3d = temp[i]['bboxes']\n                scores = temp[i]['scores']\n                labels = temp[i]['labels']\n                centers = boxes3d[:, [0, 1]]\n                boxes = torch.cat([centers, scores.view(-1, 1)], dim=1)\n                keep = torch.tensor(circle_nms(boxes.detach().cpu().numpy(), self.test_cfg['min_radius'][task_id], post_max_size=self.test_cfg['post_max_size']), dtype=torch.long, device=boxes.device)\n                boxes3d = boxes3d[keep]\n                scores = scores[keep]\n                labels = labels[keep]\n                ret = dict(bboxes=boxes3d, scores=scores, labels=labels)\n                ret_task.append(ret)\n            rets.append(ret_task)\n        else:\n            rets.append(self.get_task_detections(num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas))\n    num_samples = len(rets[0])\n    ret_list = []\n    for i in range(num_samples):\n        for k in rets[0][i].keys():\n            if k == 'bboxes':\n                bboxes = torch.cat([ret[i][k] for ret in rets])\n                bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 5] * 0.5\n                bboxes = img_metas[i]['box_type_3d'](bboxes, self.bbox_coder.code_size)\n            elif k == 'scores':\n                scores = torch.cat([ret[i][k] for ret in rets])\n            elif k == 'labels':\n                flag = 0\n                for (j, num_class) in enumerate(self.num_classes):\n                    rets[j][i][k] += flag\n                    flag += num_class\n                labels = torch.cat([ret[i][k].int() for ret in rets])\n        ret_list.append([bboxes, scores, labels])\n    return ret_list"
        ]
    },
    {
        "func_name": "get_task_detections",
        "original": "def get_task_detections(self, num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas):\n    \"\"\"Rotate nms for each task.\n\n        Args:\n            num_class_with_bg (int): Number of classes for the current task.\n            batch_cls_preds (list[torch.Tensor]): Prediction score with the\n                shape of [N].\n            batch_reg_preds (list[torch.Tensor]): Prediction bbox with the\n                shape of [N, 9].\n            batch_cls_labels (list[torch.Tensor]): Prediction label with the\n                shape of [N].\n            img_metas (list[dict]): Meta information of each sample.\n\n        Returns:\n            list[dict[str: torch.Tensor]]: contains the following keys:\n\n                -bboxes (torch.Tensor): Prediction bboxes after nms with the\n                    shape of [N, 9].\n                -scores (torch.Tensor): Prediction scores after nms with the\n                    shape of [N].\n                -labels (torch.Tensor): Prediction labels after nms with the\n                    shape of [N].\n        \"\"\"\n    predictions_dicts = []\n    post_center_range = self.test_cfg['post_center_limit_range']\n    if len(post_center_range) > 0:\n        post_center_range = torch.tensor(post_center_range, dtype=batch_reg_preds[0].dtype, device=batch_reg_preds[0].device)\n    for (i, (box_preds, cls_preds, cls_labels)) in enumerate(zip(batch_reg_preds, batch_cls_preds, batch_cls_labels)):\n        if num_class_with_bg == 1:\n            top_scores = cls_preds.squeeze(-1)\n            top_labels = torch.zeros(cls_preds.shape[0], device=cls_preds.device, dtype=torch.long)\n        else:\n            top_labels = cls_labels.long()\n            top_scores = cls_preds.squeeze(-1)\n        if self.test_cfg['score_threshold'] > 0.0:\n            thresh = torch.tensor([self.test_cfg['score_threshold']], device=cls_preds.device).type_as(cls_preds)\n            top_scores_keep = top_scores >= thresh\n            top_scores = top_scores.masked_select(top_scores_keep)\n        if top_scores.shape[0] != 0:\n            if self.test_cfg['score_threshold'] > 0.0:\n                box_preds = box_preds[top_scores_keep]\n                top_labels = top_labels[top_scores_keep]\n            boxes_for_nms = xywhr2xyxyr(img_metas[i]['box_type_3d'](box_preds[:, :], self.bbox_coder.code_size).bev)\n            selected = nms_bev(boxes_for_nms, top_scores, thresh=self.test_cfg['nms_thr'], pre_max_size=self.test_cfg['pre_max_size'], post_max_size=self.test_cfg['post_max_size'])\n        else:\n            selected = []\n        selected_boxes = box_preds[selected]\n        selected_labels = top_labels[selected]\n        selected_scores = top_scores[selected]\n        if selected_boxes.shape[0] != 0:\n            box_preds = selected_boxes\n            scores = selected_scores\n            label_preds = selected_labels\n            final_box_preds = box_preds\n            final_scores = scores\n            final_labels = label_preds\n            if post_center_range is not None:\n                mask = (final_box_preds[:, :3] >= post_center_range[:3]).all(1)\n                mask &= (final_box_preds[:, :3] <= post_center_range[3:]).all(1)\n                predictions_dict = dict(bboxes=final_box_preds[mask], scores=final_scores[mask], labels=final_labels[mask])\n            else:\n                predictions_dict = dict(bboxes=final_box_preds, scores=final_scores, labels=final_labels)\n        else:\n            dtype = batch_reg_preds[0].dtype\n            device = batch_reg_preds[0].device\n            predictions_dict = dict(bboxes=torch.zeros([0, self.bbox_coder.code_size], dtype=dtype, device=device), scores=torch.zeros([0], dtype=dtype, device=device), labels=torch.zeros([0], dtype=top_labels.dtype, device=device))\n        predictions_dicts.append(predictions_dict)\n    return predictions_dicts",
        "mutated": [
            "def get_task_detections(self, num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas):\n    if False:\n        i = 10\n    'Rotate nms for each task.\\n\\n        Args:\\n            num_class_with_bg (int): Number of classes for the current task.\\n            batch_cls_preds (list[torch.Tensor]): Prediction score with the\\n                shape of [N].\\n            batch_reg_preds (list[torch.Tensor]): Prediction bbox with the\\n                shape of [N, 9].\\n            batch_cls_labels (list[torch.Tensor]): Prediction label with the\\n                shape of [N].\\n            img_metas (list[dict]): Meta information of each sample.\\n\\n        Returns:\\n            list[dict[str: torch.Tensor]]: contains the following keys:\\n\\n                -bboxes (torch.Tensor): Prediction bboxes after nms with the\\n                    shape of [N, 9].\\n                -scores (torch.Tensor): Prediction scores after nms with the\\n                    shape of [N].\\n                -labels (torch.Tensor): Prediction labels after nms with the\\n                    shape of [N].\\n        '\n    predictions_dicts = []\n    post_center_range = self.test_cfg['post_center_limit_range']\n    if len(post_center_range) > 0:\n        post_center_range = torch.tensor(post_center_range, dtype=batch_reg_preds[0].dtype, device=batch_reg_preds[0].device)\n    for (i, (box_preds, cls_preds, cls_labels)) in enumerate(zip(batch_reg_preds, batch_cls_preds, batch_cls_labels)):\n        if num_class_with_bg == 1:\n            top_scores = cls_preds.squeeze(-1)\n            top_labels = torch.zeros(cls_preds.shape[0], device=cls_preds.device, dtype=torch.long)\n        else:\n            top_labels = cls_labels.long()\n            top_scores = cls_preds.squeeze(-1)\n        if self.test_cfg['score_threshold'] > 0.0:\n            thresh = torch.tensor([self.test_cfg['score_threshold']], device=cls_preds.device).type_as(cls_preds)\n            top_scores_keep = top_scores >= thresh\n            top_scores = top_scores.masked_select(top_scores_keep)\n        if top_scores.shape[0] != 0:\n            if self.test_cfg['score_threshold'] > 0.0:\n                box_preds = box_preds[top_scores_keep]\n                top_labels = top_labels[top_scores_keep]\n            boxes_for_nms = xywhr2xyxyr(img_metas[i]['box_type_3d'](box_preds[:, :], self.bbox_coder.code_size).bev)\n            selected = nms_bev(boxes_for_nms, top_scores, thresh=self.test_cfg['nms_thr'], pre_max_size=self.test_cfg['pre_max_size'], post_max_size=self.test_cfg['post_max_size'])\n        else:\n            selected = []\n        selected_boxes = box_preds[selected]\n        selected_labels = top_labels[selected]\n        selected_scores = top_scores[selected]\n        if selected_boxes.shape[0] != 0:\n            box_preds = selected_boxes\n            scores = selected_scores\n            label_preds = selected_labels\n            final_box_preds = box_preds\n            final_scores = scores\n            final_labels = label_preds\n            if post_center_range is not None:\n                mask = (final_box_preds[:, :3] >= post_center_range[:3]).all(1)\n                mask &= (final_box_preds[:, :3] <= post_center_range[3:]).all(1)\n                predictions_dict = dict(bboxes=final_box_preds[mask], scores=final_scores[mask], labels=final_labels[mask])\n            else:\n                predictions_dict = dict(bboxes=final_box_preds, scores=final_scores, labels=final_labels)\n        else:\n            dtype = batch_reg_preds[0].dtype\n            device = batch_reg_preds[0].device\n            predictions_dict = dict(bboxes=torch.zeros([0, self.bbox_coder.code_size], dtype=dtype, device=device), scores=torch.zeros([0], dtype=dtype, device=device), labels=torch.zeros([0], dtype=top_labels.dtype, device=device))\n        predictions_dicts.append(predictions_dict)\n    return predictions_dicts",
            "def get_task_detections(self, num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Rotate nms for each task.\\n\\n        Args:\\n            num_class_with_bg (int): Number of classes for the current task.\\n            batch_cls_preds (list[torch.Tensor]): Prediction score with the\\n                shape of [N].\\n            batch_reg_preds (list[torch.Tensor]): Prediction bbox with the\\n                shape of [N, 9].\\n            batch_cls_labels (list[torch.Tensor]): Prediction label with the\\n                shape of [N].\\n            img_metas (list[dict]): Meta information of each sample.\\n\\n        Returns:\\n            list[dict[str: torch.Tensor]]: contains the following keys:\\n\\n                -bboxes (torch.Tensor): Prediction bboxes after nms with the\\n                    shape of [N, 9].\\n                -scores (torch.Tensor): Prediction scores after nms with the\\n                    shape of [N].\\n                -labels (torch.Tensor): Prediction labels after nms with the\\n                    shape of [N].\\n        '\n    predictions_dicts = []\n    post_center_range = self.test_cfg['post_center_limit_range']\n    if len(post_center_range) > 0:\n        post_center_range = torch.tensor(post_center_range, dtype=batch_reg_preds[0].dtype, device=batch_reg_preds[0].device)\n    for (i, (box_preds, cls_preds, cls_labels)) in enumerate(zip(batch_reg_preds, batch_cls_preds, batch_cls_labels)):\n        if num_class_with_bg == 1:\n            top_scores = cls_preds.squeeze(-1)\n            top_labels = torch.zeros(cls_preds.shape[0], device=cls_preds.device, dtype=torch.long)\n        else:\n            top_labels = cls_labels.long()\n            top_scores = cls_preds.squeeze(-1)\n        if self.test_cfg['score_threshold'] > 0.0:\n            thresh = torch.tensor([self.test_cfg['score_threshold']], device=cls_preds.device).type_as(cls_preds)\n            top_scores_keep = top_scores >= thresh\n            top_scores = top_scores.masked_select(top_scores_keep)\n        if top_scores.shape[0] != 0:\n            if self.test_cfg['score_threshold'] > 0.0:\n                box_preds = box_preds[top_scores_keep]\n                top_labels = top_labels[top_scores_keep]\n            boxes_for_nms = xywhr2xyxyr(img_metas[i]['box_type_3d'](box_preds[:, :], self.bbox_coder.code_size).bev)\n            selected = nms_bev(boxes_for_nms, top_scores, thresh=self.test_cfg['nms_thr'], pre_max_size=self.test_cfg['pre_max_size'], post_max_size=self.test_cfg['post_max_size'])\n        else:\n            selected = []\n        selected_boxes = box_preds[selected]\n        selected_labels = top_labels[selected]\n        selected_scores = top_scores[selected]\n        if selected_boxes.shape[0] != 0:\n            box_preds = selected_boxes\n            scores = selected_scores\n            label_preds = selected_labels\n            final_box_preds = box_preds\n            final_scores = scores\n            final_labels = label_preds\n            if post_center_range is not None:\n                mask = (final_box_preds[:, :3] >= post_center_range[:3]).all(1)\n                mask &= (final_box_preds[:, :3] <= post_center_range[3:]).all(1)\n                predictions_dict = dict(bboxes=final_box_preds[mask], scores=final_scores[mask], labels=final_labels[mask])\n            else:\n                predictions_dict = dict(bboxes=final_box_preds, scores=final_scores, labels=final_labels)\n        else:\n            dtype = batch_reg_preds[0].dtype\n            device = batch_reg_preds[0].device\n            predictions_dict = dict(bboxes=torch.zeros([0, self.bbox_coder.code_size], dtype=dtype, device=device), scores=torch.zeros([0], dtype=dtype, device=device), labels=torch.zeros([0], dtype=top_labels.dtype, device=device))\n        predictions_dicts.append(predictions_dict)\n    return predictions_dicts",
            "def get_task_detections(self, num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Rotate nms for each task.\\n\\n        Args:\\n            num_class_with_bg (int): Number of classes for the current task.\\n            batch_cls_preds (list[torch.Tensor]): Prediction score with the\\n                shape of [N].\\n            batch_reg_preds (list[torch.Tensor]): Prediction bbox with the\\n                shape of [N, 9].\\n            batch_cls_labels (list[torch.Tensor]): Prediction label with the\\n                shape of [N].\\n            img_metas (list[dict]): Meta information of each sample.\\n\\n        Returns:\\n            list[dict[str: torch.Tensor]]: contains the following keys:\\n\\n                -bboxes (torch.Tensor): Prediction bboxes after nms with the\\n                    shape of [N, 9].\\n                -scores (torch.Tensor): Prediction scores after nms with the\\n                    shape of [N].\\n                -labels (torch.Tensor): Prediction labels after nms with the\\n                    shape of [N].\\n        '\n    predictions_dicts = []\n    post_center_range = self.test_cfg['post_center_limit_range']\n    if len(post_center_range) > 0:\n        post_center_range = torch.tensor(post_center_range, dtype=batch_reg_preds[0].dtype, device=batch_reg_preds[0].device)\n    for (i, (box_preds, cls_preds, cls_labels)) in enumerate(zip(batch_reg_preds, batch_cls_preds, batch_cls_labels)):\n        if num_class_with_bg == 1:\n            top_scores = cls_preds.squeeze(-1)\n            top_labels = torch.zeros(cls_preds.shape[0], device=cls_preds.device, dtype=torch.long)\n        else:\n            top_labels = cls_labels.long()\n            top_scores = cls_preds.squeeze(-1)\n        if self.test_cfg['score_threshold'] > 0.0:\n            thresh = torch.tensor([self.test_cfg['score_threshold']], device=cls_preds.device).type_as(cls_preds)\n            top_scores_keep = top_scores >= thresh\n            top_scores = top_scores.masked_select(top_scores_keep)\n        if top_scores.shape[0] != 0:\n            if self.test_cfg['score_threshold'] > 0.0:\n                box_preds = box_preds[top_scores_keep]\n                top_labels = top_labels[top_scores_keep]\n            boxes_for_nms = xywhr2xyxyr(img_metas[i]['box_type_3d'](box_preds[:, :], self.bbox_coder.code_size).bev)\n            selected = nms_bev(boxes_for_nms, top_scores, thresh=self.test_cfg['nms_thr'], pre_max_size=self.test_cfg['pre_max_size'], post_max_size=self.test_cfg['post_max_size'])\n        else:\n            selected = []\n        selected_boxes = box_preds[selected]\n        selected_labels = top_labels[selected]\n        selected_scores = top_scores[selected]\n        if selected_boxes.shape[0] != 0:\n            box_preds = selected_boxes\n            scores = selected_scores\n            label_preds = selected_labels\n            final_box_preds = box_preds\n            final_scores = scores\n            final_labels = label_preds\n            if post_center_range is not None:\n                mask = (final_box_preds[:, :3] >= post_center_range[:3]).all(1)\n                mask &= (final_box_preds[:, :3] <= post_center_range[3:]).all(1)\n                predictions_dict = dict(bboxes=final_box_preds[mask], scores=final_scores[mask], labels=final_labels[mask])\n            else:\n                predictions_dict = dict(bboxes=final_box_preds, scores=final_scores, labels=final_labels)\n        else:\n            dtype = batch_reg_preds[0].dtype\n            device = batch_reg_preds[0].device\n            predictions_dict = dict(bboxes=torch.zeros([0, self.bbox_coder.code_size], dtype=dtype, device=device), scores=torch.zeros([0], dtype=dtype, device=device), labels=torch.zeros([0], dtype=top_labels.dtype, device=device))\n        predictions_dicts.append(predictions_dict)\n    return predictions_dicts",
            "def get_task_detections(self, num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Rotate nms for each task.\\n\\n        Args:\\n            num_class_with_bg (int): Number of classes for the current task.\\n            batch_cls_preds (list[torch.Tensor]): Prediction score with the\\n                shape of [N].\\n            batch_reg_preds (list[torch.Tensor]): Prediction bbox with the\\n                shape of [N, 9].\\n            batch_cls_labels (list[torch.Tensor]): Prediction label with the\\n                shape of [N].\\n            img_metas (list[dict]): Meta information of each sample.\\n\\n        Returns:\\n            list[dict[str: torch.Tensor]]: contains the following keys:\\n\\n                -bboxes (torch.Tensor): Prediction bboxes after nms with the\\n                    shape of [N, 9].\\n                -scores (torch.Tensor): Prediction scores after nms with the\\n                    shape of [N].\\n                -labels (torch.Tensor): Prediction labels after nms with the\\n                    shape of [N].\\n        '\n    predictions_dicts = []\n    post_center_range = self.test_cfg['post_center_limit_range']\n    if len(post_center_range) > 0:\n        post_center_range = torch.tensor(post_center_range, dtype=batch_reg_preds[0].dtype, device=batch_reg_preds[0].device)\n    for (i, (box_preds, cls_preds, cls_labels)) in enumerate(zip(batch_reg_preds, batch_cls_preds, batch_cls_labels)):\n        if num_class_with_bg == 1:\n            top_scores = cls_preds.squeeze(-1)\n            top_labels = torch.zeros(cls_preds.shape[0], device=cls_preds.device, dtype=torch.long)\n        else:\n            top_labels = cls_labels.long()\n            top_scores = cls_preds.squeeze(-1)\n        if self.test_cfg['score_threshold'] > 0.0:\n            thresh = torch.tensor([self.test_cfg['score_threshold']], device=cls_preds.device).type_as(cls_preds)\n            top_scores_keep = top_scores >= thresh\n            top_scores = top_scores.masked_select(top_scores_keep)\n        if top_scores.shape[0] != 0:\n            if self.test_cfg['score_threshold'] > 0.0:\n                box_preds = box_preds[top_scores_keep]\n                top_labels = top_labels[top_scores_keep]\n            boxes_for_nms = xywhr2xyxyr(img_metas[i]['box_type_3d'](box_preds[:, :], self.bbox_coder.code_size).bev)\n            selected = nms_bev(boxes_for_nms, top_scores, thresh=self.test_cfg['nms_thr'], pre_max_size=self.test_cfg['pre_max_size'], post_max_size=self.test_cfg['post_max_size'])\n        else:\n            selected = []\n        selected_boxes = box_preds[selected]\n        selected_labels = top_labels[selected]\n        selected_scores = top_scores[selected]\n        if selected_boxes.shape[0] != 0:\n            box_preds = selected_boxes\n            scores = selected_scores\n            label_preds = selected_labels\n            final_box_preds = box_preds\n            final_scores = scores\n            final_labels = label_preds\n            if post_center_range is not None:\n                mask = (final_box_preds[:, :3] >= post_center_range[:3]).all(1)\n                mask &= (final_box_preds[:, :3] <= post_center_range[3:]).all(1)\n                predictions_dict = dict(bboxes=final_box_preds[mask], scores=final_scores[mask], labels=final_labels[mask])\n            else:\n                predictions_dict = dict(bboxes=final_box_preds, scores=final_scores, labels=final_labels)\n        else:\n            dtype = batch_reg_preds[0].dtype\n            device = batch_reg_preds[0].device\n            predictions_dict = dict(bboxes=torch.zeros([0, self.bbox_coder.code_size], dtype=dtype, device=device), scores=torch.zeros([0], dtype=dtype, device=device), labels=torch.zeros([0], dtype=top_labels.dtype, device=device))\n        predictions_dicts.append(predictions_dict)\n    return predictions_dicts",
            "def get_task_detections(self, num_class_with_bg, batch_cls_preds, batch_reg_preds, batch_cls_labels, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Rotate nms for each task.\\n\\n        Args:\\n            num_class_with_bg (int): Number of classes for the current task.\\n            batch_cls_preds (list[torch.Tensor]): Prediction score with the\\n                shape of [N].\\n            batch_reg_preds (list[torch.Tensor]): Prediction bbox with the\\n                shape of [N, 9].\\n            batch_cls_labels (list[torch.Tensor]): Prediction label with the\\n                shape of [N].\\n            img_metas (list[dict]): Meta information of each sample.\\n\\n        Returns:\\n            list[dict[str: torch.Tensor]]: contains the following keys:\\n\\n                -bboxes (torch.Tensor): Prediction bboxes after nms with the\\n                    shape of [N, 9].\\n                -scores (torch.Tensor): Prediction scores after nms with the\\n                    shape of [N].\\n                -labels (torch.Tensor): Prediction labels after nms with the\\n                    shape of [N].\\n        '\n    predictions_dicts = []\n    post_center_range = self.test_cfg['post_center_limit_range']\n    if len(post_center_range) > 0:\n        post_center_range = torch.tensor(post_center_range, dtype=batch_reg_preds[0].dtype, device=batch_reg_preds[0].device)\n    for (i, (box_preds, cls_preds, cls_labels)) in enumerate(zip(batch_reg_preds, batch_cls_preds, batch_cls_labels)):\n        if num_class_with_bg == 1:\n            top_scores = cls_preds.squeeze(-1)\n            top_labels = torch.zeros(cls_preds.shape[0], device=cls_preds.device, dtype=torch.long)\n        else:\n            top_labels = cls_labels.long()\n            top_scores = cls_preds.squeeze(-1)\n        if self.test_cfg['score_threshold'] > 0.0:\n            thresh = torch.tensor([self.test_cfg['score_threshold']], device=cls_preds.device).type_as(cls_preds)\n            top_scores_keep = top_scores >= thresh\n            top_scores = top_scores.masked_select(top_scores_keep)\n        if top_scores.shape[0] != 0:\n            if self.test_cfg['score_threshold'] > 0.0:\n                box_preds = box_preds[top_scores_keep]\n                top_labels = top_labels[top_scores_keep]\n            boxes_for_nms = xywhr2xyxyr(img_metas[i]['box_type_3d'](box_preds[:, :], self.bbox_coder.code_size).bev)\n            selected = nms_bev(boxes_for_nms, top_scores, thresh=self.test_cfg['nms_thr'], pre_max_size=self.test_cfg['pre_max_size'], post_max_size=self.test_cfg['post_max_size'])\n        else:\n            selected = []\n        selected_boxes = box_preds[selected]\n        selected_labels = top_labels[selected]\n        selected_scores = top_scores[selected]\n        if selected_boxes.shape[0] != 0:\n            box_preds = selected_boxes\n            scores = selected_scores\n            label_preds = selected_labels\n            final_box_preds = box_preds\n            final_scores = scores\n            final_labels = label_preds\n            if post_center_range is not None:\n                mask = (final_box_preds[:, :3] >= post_center_range[:3]).all(1)\n                mask &= (final_box_preds[:, :3] <= post_center_range[3:]).all(1)\n                predictions_dict = dict(bboxes=final_box_preds[mask], scores=final_scores[mask], labels=final_labels[mask])\n            else:\n                predictions_dict = dict(bboxes=final_box_preds, scores=final_scores, labels=final_labels)\n        else:\n            dtype = batch_reg_preds[0].dtype\n            device = batch_reg_preds[0].device\n            predictions_dict = dict(bboxes=torch.zeros([0, self.bbox_coder.code_size], dtype=dtype, device=device), scores=torch.zeros([0], dtype=dtype, device=device), labels=torch.zeros([0], dtype=top_labels.dtype, device=device))\n        predictions_dicts.append(predictions_dict)\n    return predictions_dicts"
        ]
    }
]