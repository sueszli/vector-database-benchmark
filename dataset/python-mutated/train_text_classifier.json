[
    {
        "func_name": "main",
        "original": "def main():\n    current_datetime = '{}'.format(datetime.datetime.today())\n    parser = argparse.ArgumentParser(description='Chainer example: Text Classification')\n    parser.add_argument('--batchsize', '-b', type=int, default=64, help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30, help='Number of sweeps over the dataset to train')\n    parser.add_argument('--device', '-d', type=str, default='-1', help='Device specifier. Either ChainerX device specifier or an integer. If non-negative integer, CuPy arrays with specified device id are used. If negative integer, NumPy arrays are used')\n    parser.add_argument('--out', '-o', default='result', help='Directory to output the result')\n    parser.add_argument('--resume', '-r', type=str, help='Resume the training from snapshot')\n    parser.add_argument('--unit', '-u', type=int, default=300, help='Number of units')\n    parser.add_argument('--layer', '-l', type=int, default=1, help='Number of layers of RNN or MLP following CNN')\n    parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate')\n    parser.add_argument('--dataset', '-data', default='imdb.binary', choices=['dbpedia', 'imdb.binary', 'imdb.fine', 'TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj'], help='Name of dataset.')\n    parser.add_argument('--model', '-model', default='cnn', choices=['cnn', 'rnn', 'bow'], help='Name of encoder model type.')\n    parser.add_argument('--char-based', action='store_true')\n    parser.add_argument('--test', dest='test', action='store_true')\n    parser.set_defaults(test=False)\n    group = parser.add_argument_group('deprecated arguments')\n    group.add_argument('--gpu', '-g', dest='device', type=int, nargs='?', const=0, help='GPU ID (negative value indicates CPU)')\n    args = parser.parse_args()\n    print(json.dumps(args.__dict__, indent=2))\n    device = chainer.get_device(args.device)\n    device.use()\n    if args.dataset == 'dbpedia':\n        (train, test, vocab) = text_datasets.get_dbpedia(char_based=args.char_based)\n    elif args.dataset.startswith('imdb.'):\n        (train, test, vocab) = text_datasets.get_imdb(fine_grained=args.dataset.endswith('.fine'), char_based=args.char_based)\n    elif args.dataset in ['TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj']:\n        (train, test, vocab) = text_datasets.get_other_text_dataset(args.dataset, char_based=args.char_based)\n    if args.test:\n        train = train[:100]\n        test = test[:100]\n    print('Device: {}'.format(device))\n    print('# train data: {}'.format(len(train)))\n    print('# test  data: {}'.format(len(test)))\n    print('# vocab: {}'.format(len(vocab)))\n    n_class = len(set([int(d[1]) for d in train]))\n    print('# class: {}'.format(n_class))\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)\n    if args.model == 'rnn':\n        Encoder = nets.RNNEncoder\n    elif args.model == 'cnn':\n        Encoder = nets.CNNEncoder\n    elif args.model == 'bow':\n        Encoder = nets.BOWMLPEncoder\n    encoder = Encoder(n_layers=args.layer, n_vocab=len(vocab), n_units=args.unit, dropout=args.dropout)\n    model = nets.TextClassifier(encoder, n_class)\n    model.to_device(device)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(model)\n    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n    updater = training.updaters.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\n    trainer.extend(extensions.snapshot(filename='snapshot_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n    best_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\n    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=best_trigger)\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n    trainer.extend(extensions.ProgressBar())\n    if not os.path.isdir(args.out):\n        os.mkdir(args.out)\n    vocab_path = os.path.join(args.out, 'vocab.json')\n    with open(vocab_path, 'w') as f:\n        json.dump(vocab, f)\n    model_path = os.path.join(args.out, 'best_model.npz')\n    model_setup = args.__dict__\n    model_setup['vocab_path'] = vocab_path\n    model_setup['model_path'] = model_path\n    model_setup['n_class'] = n_class\n    model_setup['datetime'] = current_datetime\n    with open(os.path.join(args.out, 'args.json'), 'w') as f:\n        json.dump(args.__dict__, f)\n    if args.resume is not None:\n        chainer.serializers.load_npz(args.resume, trainer)\n    trainer.run()",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    current_datetime = '{}'.format(datetime.datetime.today())\n    parser = argparse.ArgumentParser(description='Chainer example: Text Classification')\n    parser.add_argument('--batchsize', '-b', type=int, default=64, help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30, help='Number of sweeps over the dataset to train')\n    parser.add_argument('--device', '-d', type=str, default='-1', help='Device specifier. Either ChainerX device specifier or an integer. If non-negative integer, CuPy arrays with specified device id are used. If negative integer, NumPy arrays are used')\n    parser.add_argument('--out', '-o', default='result', help='Directory to output the result')\n    parser.add_argument('--resume', '-r', type=str, help='Resume the training from snapshot')\n    parser.add_argument('--unit', '-u', type=int, default=300, help='Number of units')\n    parser.add_argument('--layer', '-l', type=int, default=1, help='Number of layers of RNN or MLP following CNN')\n    parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate')\n    parser.add_argument('--dataset', '-data', default='imdb.binary', choices=['dbpedia', 'imdb.binary', 'imdb.fine', 'TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj'], help='Name of dataset.')\n    parser.add_argument('--model', '-model', default='cnn', choices=['cnn', 'rnn', 'bow'], help='Name of encoder model type.')\n    parser.add_argument('--char-based', action='store_true')\n    parser.add_argument('--test', dest='test', action='store_true')\n    parser.set_defaults(test=False)\n    group = parser.add_argument_group('deprecated arguments')\n    group.add_argument('--gpu', '-g', dest='device', type=int, nargs='?', const=0, help='GPU ID (negative value indicates CPU)')\n    args = parser.parse_args()\n    print(json.dumps(args.__dict__, indent=2))\n    device = chainer.get_device(args.device)\n    device.use()\n    if args.dataset == 'dbpedia':\n        (train, test, vocab) = text_datasets.get_dbpedia(char_based=args.char_based)\n    elif args.dataset.startswith('imdb.'):\n        (train, test, vocab) = text_datasets.get_imdb(fine_grained=args.dataset.endswith('.fine'), char_based=args.char_based)\n    elif args.dataset in ['TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj']:\n        (train, test, vocab) = text_datasets.get_other_text_dataset(args.dataset, char_based=args.char_based)\n    if args.test:\n        train = train[:100]\n        test = test[:100]\n    print('Device: {}'.format(device))\n    print('# train data: {}'.format(len(train)))\n    print('# test  data: {}'.format(len(test)))\n    print('# vocab: {}'.format(len(vocab)))\n    n_class = len(set([int(d[1]) for d in train]))\n    print('# class: {}'.format(n_class))\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)\n    if args.model == 'rnn':\n        Encoder = nets.RNNEncoder\n    elif args.model == 'cnn':\n        Encoder = nets.CNNEncoder\n    elif args.model == 'bow':\n        Encoder = nets.BOWMLPEncoder\n    encoder = Encoder(n_layers=args.layer, n_vocab=len(vocab), n_units=args.unit, dropout=args.dropout)\n    model = nets.TextClassifier(encoder, n_class)\n    model.to_device(device)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(model)\n    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n    updater = training.updaters.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\n    trainer.extend(extensions.snapshot(filename='snapshot_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n    best_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\n    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=best_trigger)\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n    trainer.extend(extensions.ProgressBar())\n    if not os.path.isdir(args.out):\n        os.mkdir(args.out)\n    vocab_path = os.path.join(args.out, 'vocab.json')\n    with open(vocab_path, 'w') as f:\n        json.dump(vocab, f)\n    model_path = os.path.join(args.out, 'best_model.npz')\n    model_setup = args.__dict__\n    model_setup['vocab_path'] = vocab_path\n    model_setup['model_path'] = model_path\n    model_setup['n_class'] = n_class\n    model_setup['datetime'] = current_datetime\n    with open(os.path.join(args.out, 'args.json'), 'w') as f:\n        json.dump(args.__dict__, f)\n    if args.resume is not None:\n        chainer.serializers.load_npz(args.resume, trainer)\n    trainer.run()",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    current_datetime = '{}'.format(datetime.datetime.today())\n    parser = argparse.ArgumentParser(description='Chainer example: Text Classification')\n    parser.add_argument('--batchsize', '-b', type=int, default=64, help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30, help='Number of sweeps over the dataset to train')\n    parser.add_argument('--device', '-d', type=str, default='-1', help='Device specifier. Either ChainerX device specifier or an integer. If non-negative integer, CuPy arrays with specified device id are used. If negative integer, NumPy arrays are used')\n    parser.add_argument('--out', '-o', default='result', help='Directory to output the result')\n    parser.add_argument('--resume', '-r', type=str, help='Resume the training from snapshot')\n    parser.add_argument('--unit', '-u', type=int, default=300, help='Number of units')\n    parser.add_argument('--layer', '-l', type=int, default=1, help='Number of layers of RNN or MLP following CNN')\n    parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate')\n    parser.add_argument('--dataset', '-data', default='imdb.binary', choices=['dbpedia', 'imdb.binary', 'imdb.fine', 'TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj'], help='Name of dataset.')\n    parser.add_argument('--model', '-model', default='cnn', choices=['cnn', 'rnn', 'bow'], help='Name of encoder model type.')\n    parser.add_argument('--char-based', action='store_true')\n    parser.add_argument('--test', dest='test', action='store_true')\n    parser.set_defaults(test=False)\n    group = parser.add_argument_group('deprecated arguments')\n    group.add_argument('--gpu', '-g', dest='device', type=int, nargs='?', const=0, help='GPU ID (negative value indicates CPU)')\n    args = parser.parse_args()\n    print(json.dumps(args.__dict__, indent=2))\n    device = chainer.get_device(args.device)\n    device.use()\n    if args.dataset == 'dbpedia':\n        (train, test, vocab) = text_datasets.get_dbpedia(char_based=args.char_based)\n    elif args.dataset.startswith('imdb.'):\n        (train, test, vocab) = text_datasets.get_imdb(fine_grained=args.dataset.endswith('.fine'), char_based=args.char_based)\n    elif args.dataset in ['TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj']:\n        (train, test, vocab) = text_datasets.get_other_text_dataset(args.dataset, char_based=args.char_based)\n    if args.test:\n        train = train[:100]\n        test = test[:100]\n    print('Device: {}'.format(device))\n    print('# train data: {}'.format(len(train)))\n    print('# test  data: {}'.format(len(test)))\n    print('# vocab: {}'.format(len(vocab)))\n    n_class = len(set([int(d[1]) for d in train]))\n    print('# class: {}'.format(n_class))\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)\n    if args.model == 'rnn':\n        Encoder = nets.RNNEncoder\n    elif args.model == 'cnn':\n        Encoder = nets.CNNEncoder\n    elif args.model == 'bow':\n        Encoder = nets.BOWMLPEncoder\n    encoder = Encoder(n_layers=args.layer, n_vocab=len(vocab), n_units=args.unit, dropout=args.dropout)\n    model = nets.TextClassifier(encoder, n_class)\n    model.to_device(device)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(model)\n    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n    updater = training.updaters.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\n    trainer.extend(extensions.snapshot(filename='snapshot_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n    best_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\n    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=best_trigger)\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n    trainer.extend(extensions.ProgressBar())\n    if not os.path.isdir(args.out):\n        os.mkdir(args.out)\n    vocab_path = os.path.join(args.out, 'vocab.json')\n    with open(vocab_path, 'w') as f:\n        json.dump(vocab, f)\n    model_path = os.path.join(args.out, 'best_model.npz')\n    model_setup = args.__dict__\n    model_setup['vocab_path'] = vocab_path\n    model_setup['model_path'] = model_path\n    model_setup['n_class'] = n_class\n    model_setup['datetime'] = current_datetime\n    with open(os.path.join(args.out, 'args.json'), 'w') as f:\n        json.dump(args.__dict__, f)\n    if args.resume is not None:\n        chainer.serializers.load_npz(args.resume, trainer)\n    trainer.run()",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    current_datetime = '{}'.format(datetime.datetime.today())\n    parser = argparse.ArgumentParser(description='Chainer example: Text Classification')\n    parser.add_argument('--batchsize', '-b', type=int, default=64, help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30, help='Number of sweeps over the dataset to train')\n    parser.add_argument('--device', '-d', type=str, default='-1', help='Device specifier. Either ChainerX device specifier or an integer. If non-negative integer, CuPy arrays with specified device id are used. If negative integer, NumPy arrays are used')\n    parser.add_argument('--out', '-o', default='result', help='Directory to output the result')\n    parser.add_argument('--resume', '-r', type=str, help='Resume the training from snapshot')\n    parser.add_argument('--unit', '-u', type=int, default=300, help='Number of units')\n    parser.add_argument('--layer', '-l', type=int, default=1, help='Number of layers of RNN or MLP following CNN')\n    parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate')\n    parser.add_argument('--dataset', '-data', default='imdb.binary', choices=['dbpedia', 'imdb.binary', 'imdb.fine', 'TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj'], help='Name of dataset.')\n    parser.add_argument('--model', '-model', default='cnn', choices=['cnn', 'rnn', 'bow'], help='Name of encoder model type.')\n    parser.add_argument('--char-based', action='store_true')\n    parser.add_argument('--test', dest='test', action='store_true')\n    parser.set_defaults(test=False)\n    group = parser.add_argument_group('deprecated arguments')\n    group.add_argument('--gpu', '-g', dest='device', type=int, nargs='?', const=0, help='GPU ID (negative value indicates CPU)')\n    args = parser.parse_args()\n    print(json.dumps(args.__dict__, indent=2))\n    device = chainer.get_device(args.device)\n    device.use()\n    if args.dataset == 'dbpedia':\n        (train, test, vocab) = text_datasets.get_dbpedia(char_based=args.char_based)\n    elif args.dataset.startswith('imdb.'):\n        (train, test, vocab) = text_datasets.get_imdb(fine_grained=args.dataset.endswith('.fine'), char_based=args.char_based)\n    elif args.dataset in ['TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj']:\n        (train, test, vocab) = text_datasets.get_other_text_dataset(args.dataset, char_based=args.char_based)\n    if args.test:\n        train = train[:100]\n        test = test[:100]\n    print('Device: {}'.format(device))\n    print('# train data: {}'.format(len(train)))\n    print('# test  data: {}'.format(len(test)))\n    print('# vocab: {}'.format(len(vocab)))\n    n_class = len(set([int(d[1]) for d in train]))\n    print('# class: {}'.format(n_class))\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)\n    if args.model == 'rnn':\n        Encoder = nets.RNNEncoder\n    elif args.model == 'cnn':\n        Encoder = nets.CNNEncoder\n    elif args.model == 'bow':\n        Encoder = nets.BOWMLPEncoder\n    encoder = Encoder(n_layers=args.layer, n_vocab=len(vocab), n_units=args.unit, dropout=args.dropout)\n    model = nets.TextClassifier(encoder, n_class)\n    model.to_device(device)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(model)\n    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n    updater = training.updaters.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\n    trainer.extend(extensions.snapshot(filename='snapshot_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n    best_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\n    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=best_trigger)\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n    trainer.extend(extensions.ProgressBar())\n    if not os.path.isdir(args.out):\n        os.mkdir(args.out)\n    vocab_path = os.path.join(args.out, 'vocab.json')\n    with open(vocab_path, 'w') as f:\n        json.dump(vocab, f)\n    model_path = os.path.join(args.out, 'best_model.npz')\n    model_setup = args.__dict__\n    model_setup['vocab_path'] = vocab_path\n    model_setup['model_path'] = model_path\n    model_setup['n_class'] = n_class\n    model_setup['datetime'] = current_datetime\n    with open(os.path.join(args.out, 'args.json'), 'w') as f:\n        json.dump(args.__dict__, f)\n    if args.resume is not None:\n        chainer.serializers.load_npz(args.resume, trainer)\n    trainer.run()",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    current_datetime = '{}'.format(datetime.datetime.today())\n    parser = argparse.ArgumentParser(description='Chainer example: Text Classification')\n    parser.add_argument('--batchsize', '-b', type=int, default=64, help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30, help='Number of sweeps over the dataset to train')\n    parser.add_argument('--device', '-d', type=str, default='-1', help='Device specifier. Either ChainerX device specifier or an integer. If non-negative integer, CuPy arrays with specified device id are used. If negative integer, NumPy arrays are used')\n    parser.add_argument('--out', '-o', default='result', help='Directory to output the result')\n    parser.add_argument('--resume', '-r', type=str, help='Resume the training from snapshot')\n    parser.add_argument('--unit', '-u', type=int, default=300, help='Number of units')\n    parser.add_argument('--layer', '-l', type=int, default=1, help='Number of layers of RNN or MLP following CNN')\n    parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate')\n    parser.add_argument('--dataset', '-data', default='imdb.binary', choices=['dbpedia', 'imdb.binary', 'imdb.fine', 'TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj'], help='Name of dataset.')\n    parser.add_argument('--model', '-model', default='cnn', choices=['cnn', 'rnn', 'bow'], help='Name of encoder model type.')\n    parser.add_argument('--char-based', action='store_true')\n    parser.add_argument('--test', dest='test', action='store_true')\n    parser.set_defaults(test=False)\n    group = parser.add_argument_group('deprecated arguments')\n    group.add_argument('--gpu', '-g', dest='device', type=int, nargs='?', const=0, help='GPU ID (negative value indicates CPU)')\n    args = parser.parse_args()\n    print(json.dumps(args.__dict__, indent=2))\n    device = chainer.get_device(args.device)\n    device.use()\n    if args.dataset == 'dbpedia':\n        (train, test, vocab) = text_datasets.get_dbpedia(char_based=args.char_based)\n    elif args.dataset.startswith('imdb.'):\n        (train, test, vocab) = text_datasets.get_imdb(fine_grained=args.dataset.endswith('.fine'), char_based=args.char_based)\n    elif args.dataset in ['TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj']:\n        (train, test, vocab) = text_datasets.get_other_text_dataset(args.dataset, char_based=args.char_based)\n    if args.test:\n        train = train[:100]\n        test = test[:100]\n    print('Device: {}'.format(device))\n    print('# train data: {}'.format(len(train)))\n    print('# test  data: {}'.format(len(test)))\n    print('# vocab: {}'.format(len(vocab)))\n    n_class = len(set([int(d[1]) for d in train]))\n    print('# class: {}'.format(n_class))\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)\n    if args.model == 'rnn':\n        Encoder = nets.RNNEncoder\n    elif args.model == 'cnn':\n        Encoder = nets.CNNEncoder\n    elif args.model == 'bow':\n        Encoder = nets.BOWMLPEncoder\n    encoder = Encoder(n_layers=args.layer, n_vocab=len(vocab), n_units=args.unit, dropout=args.dropout)\n    model = nets.TextClassifier(encoder, n_class)\n    model.to_device(device)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(model)\n    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n    updater = training.updaters.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\n    trainer.extend(extensions.snapshot(filename='snapshot_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n    best_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\n    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=best_trigger)\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n    trainer.extend(extensions.ProgressBar())\n    if not os.path.isdir(args.out):\n        os.mkdir(args.out)\n    vocab_path = os.path.join(args.out, 'vocab.json')\n    with open(vocab_path, 'w') as f:\n        json.dump(vocab, f)\n    model_path = os.path.join(args.out, 'best_model.npz')\n    model_setup = args.__dict__\n    model_setup['vocab_path'] = vocab_path\n    model_setup['model_path'] = model_path\n    model_setup['n_class'] = n_class\n    model_setup['datetime'] = current_datetime\n    with open(os.path.join(args.out, 'args.json'), 'w') as f:\n        json.dump(args.__dict__, f)\n    if args.resume is not None:\n        chainer.serializers.load_npz(args.resume, trainer)\n    trainer.run()",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    current_datetime = '{}'.format(datetime.datetime.today())\n    parser = argparse.ArgumentParser(description='Chainer example: Text Classification')\n    parser.add_argument('--batchsize', '-b', type=int, default=64, help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30, help='Number of sweeps over the dataset to train')\n    parser.add_argument('--device', '-d', type=str, default='-1', help='Device specifier. Either ChainerX device specifier or an integer. If non-negative integer, CuPy arrays with specified device id are used. If negative integer, NumPy arrays are used')\n    parser.add_argument('--out', '-o', default='result', help='Directory to output the result')\n    parser.add_argument('--resume', '-r', type=str, help='Resume the training from snapshot')\n    parser.add_argument('--unit', '-u', type=int, default=300, help='Number of units')\n    parser.add_argument('--layer', '-l', type=int, default=1, help='Number of layers of RNN or MLP following CNN')\n    parser.add_argument('--dropout', type=float, default=0.4, help='Dropout rate')\n    parser.add_argument('--dataset', '-data', default='imdb.binary', choices=['dbpedia', 'imdb.binary', 'imdb.fine', 'TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj'], help='Name of dataset.')\n    parser.add_argument('--model', '-model', default='cnn', choices=['cnn', 'rnn', 'bow'], help='Name of encoder model type.')\n    parser.add_argument('--char-based', action='store_true')\n    parser.add_argument('--test', dest='test', action='store_true')\n    parser.set_defaults(test=False)\n    group = parser.add_argument_group('deprecated arguments')\n    group.add_argument('--gpu', '-g', dest='device', type=int, nargs='?', const=0, help='GPU ID (negative value indicates CPU)')\n    args = parser.parse_args()\n    print(json.dumps(args.__dict__, indent=2))\n    device = chainer.get_device(args.device)\n    device.use()\n    if args.dataset == 'dbpedia':\n        (train, test, vocab) = text_datasets.get_dbpedia(char_based=args.char_based)\n    elif args.dataset.startswith('imdb.'):\n        (train, test, vocab) = text_datasets.get_imdb(fine_grained=args.dataset.endswith('.fine'), char_based=args.char_based)\n    elif args.dataset in ['TREC', 'stsa.binary', 'stsa.fine', 'custrev', 'mpqa', 'rt-polarity', 'subj']:\n        (train, test, vocab) = text_datasets.get_other_text_dataset(args.dataset, char_based=args.char_based)\n    if args.test:\n        train = train[:100]\n        test = test[:100]\n    print('Device: {}'.format(device))\n    print('# train data: {}'.format(len(train)))\n    print('# test  data: {}'.format(len(test)))\n    print('# vocab: {}'.format(len(vocab)))\n    n_class = len(set([int(d[1]) for d in train]))\n    print('# class: {}'.format(n_class))\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)\n    if args.model == 'rnn':\n        Encoder = nets.RNNEncoder\n    elif args.model == 'cnn':\n        Encoder = nets.CNNEncoder\n    elif args.model == 'bow':\n        Encoder = nets.BOWMLPEncoder\n    encoder = Encoder(n_layers=args.layer, n_vocab=len(vocab), n_units=args.unit, dropout=args.dropout)\n    model = nets.TextClassifier(encoder, n_class)\n    model.to_device(device)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(model)\n    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n    updater = training.updaters.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\n    trainer.extend(extensions.snapshot(filename='snapshot_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n    best_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\n    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=best_trigger)\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n    trainer.extend(extensions.ProgressBar())\n    if not os.path.isdir(args.out):\n        os.mkdir(args.out)\n    vocab_path = os.path.join(args.out, 'vocab.json')\n    with open(vocab_path, 'w') as f:\n        json.dump(vocab, f)\n    model_path = os.path.join(args.out, 'best_model.npz')\n    model_setup = args.__dict__\n    model_setup['vocab_path'] = vocab_path\n    model_setup['model_path'] = model_path\n    model_setup['n_class'] = n_class\n    model_setup['datetime'] = current_datetime\n    with open(os.path.join(args.out, 'args.json'), 'w') as f:\n        json.dump(args.__dict__, f)\n    if args.resume is not None:\n        chainer.serializers.load_npz(args.resume, trainer)\n    trainer.run()"
        ]
    }
]