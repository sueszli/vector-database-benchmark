[
    {
        "func_name": "evaluate_detections",
        "original": "def evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms, device_id, apply_mms=True, nms_threshold=0.5, conf_threshold=0.0, use_07_metric=False):\n    \"\"\"\n    Computes per-class average precision.\n\n    Args:\n        all_boxes:          shape of all_boxes: e.g. 21 classes x 4952 images x 58 rois x 5 coords+score\n        all_gt_infos:       a dictionary that contains all ground truth annoations in the following form:\n                            {'class_A': [{'bbox': array([[ 376.,  210.,  456.,  288.,   10.]], dtype=float32), 'det': [False], 'difficult': [False]}, ... ]}\n                            'class_B': [ <bbox_list> ], <more_class_to_bbox_list_entries> }\n        classes:            a list of class name, e.g. ['__background__', 'avocado', 'orange', 'butter']\n        use_07_metric:      whether to use VOC07's 11 point AP computation (default False)\n        apply_mms:          whether to apply non maximum suppression before computing average precision values\n        nms_threshold:      the threshold for discarding overlapping ROIs in nms\n        conf_threshold:     a minimum value for the score of an ROI. ROIs with lower score will be discarded\n\n    Returns:\n        aps - average precision value per class in a dictionary {classname: ap}\n    \"\"\"\n    if apply_mms:\n        print('Number of rois before non-maximum suppression: %d' % sum([len(all_boxes[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n        (nms_dets, _) = apply_nms_to_test_set_results(all_boxes, nms_threshold, conf_threshold, use_gpu_nms, device_id)\n        print('Number of rois  after non-maximum suppression: %d' % sum([len(nms_dets[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n    else:\n        print('Skipping non-maximum suppression')\n        nms_dets = all_boxes\n    aps = {}\n    for (classIndex, className) in enumerate(classes):\n        if className != '__background__':\n            (rec, prec, ap) = _evaluate_detections(classIndex, nms_dets, all_gt_infos[className], use_07_metric=use_07_metric)\n            aps[className] = ap\n    return aps",
        "mutated": [
            "def evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms, device_id, apply_mms=True, nms_threshold=0.5, conf_threshold=0.0, use_07_metric=False):\n    if False:\n        i = 10\n    \"\\n    Computes per-class average precision.\\n\\n    Args:\\n        all_boxes:          shape of all_boxes: e.g. 21 classes x 4952 images x 58 rois x 5 coords+score\\n        all_gt_infos:       a dictionary that contains all ground truth annoations in the following form:\\n                            {'class_A': [{'bbox': array([[ 376.,  210.,  456.,  288.,   10.]], dtype=float32), 'det': [False], 'difficult': [False]}, ... ]}\\n                            'class_B': [ <bbox_list> ], <more_class_to_bbox_list_entries> }\\n        classes:            a list of class name, e.g. ['__background__', 'avocado', 'orange', 'butter']\\n        use_07_metric:      whether to use VOC07's 11 point AP computation (default False)\\n        apply_mms:          whether to apply non maximum suppression before computing average precision values\\n        nms_threshold:      the threshold for discarding overlapping ROIs in nms\\n        conf_threshold:     a minimum value for the score of an ROI. ROIs with lower score will be discarded\\n\\n    Returns:\\n        aps - average precision value per class in a dictionary {classname: ap}\\n    \"\n    if apply_mms:\n        print('Number of rois before non-maximum suppression: %d' % sum([len(all_boxes[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n        (nms_dets, _) = apply_nms_to_test_set_results(all_boxes, nms_threshold, conf_threshold, use_gpu_nms, device_id)\n        print('Number of rois  after non-maximum suppression: %d' % sum([len(nms_dets[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n    else:\n        print('Skipping non-maximum suppression')\n        nms_dets = all_boxes\n    aps = {}\n    for (classIndex, className) in enumerate(classes):\n        if className != '__background__':\n            (rec, prec, ap) = _evaluate_detections(classIndex, nms_dets, all_gt_infos[className], use_07_metric=use_07_metric)\n            aps[className] = ap\n    return aps",
            "def evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms, device_id, apply_mms=True, nms_threshold=0.5, conf_threshold=0.0, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Computes per-class average precision.\\n\\n    Args:\\n        all_boxes:          shape of all_boxes: e.g. 21 classes x 4952 images x 58 rois x 5 coords+score\\n        all_gt_infos:       a dictionary that contains all ground truth annoations in the following form:\\n                            {'class_A': [{'bbox': array([[ 376.,  210.,  456.,  288.,   10.]], dtype=float32), 'det': [False], 'difficult': [False]}, ... ]}\\n                            'class_B': [ <bbox_list> ], <more_class_to_bbox_list_entries> }\\n        classes:            a list of class name, e.g. ['__background__', 'avocado', 'orange', 'butter']\\n        use_07_metric:      whether to use VOC07's 11 point AP computation (default False)\\n        apply_mms:          whether to apply non maximum suppression before computing average precision values\\n        nms_threshold:      the threshold for discarding overlapping ROIs in nms\\n        conf_threshold:     a minimum value for the score of an ROI. ROIs with lower score will be discarded\\n\\n    Returns:\\n        aps - average precision value per class in a dictionary {classname: ap}\\n    \"\n    if apply_mms:\n        print('Number of rois before non-maximum suppression: %d' % sum([len(all_boxes[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n        (nms_dets, _) = apply_nms_to_test_set_results(all_boxes, nms_threshold, conf_threshold, use_gpu_nms, device_id)\n        print('Number of rois  after non-maximum suppression: %d' % sum([len(nms_dets[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n    else:\n        print('Skipping non-maximum suppression')\n        nms_dets = all_boxes\n    aps = {}\n    for (classIndex, className) in enumerate(classes):\n        if className != '__background__':\n            (rec, prec, ap) = _evaluate_detections(classIndex, nms_dets, all_gt_infos[className], use_07_metric=use_07_metric)\n            aps[className] = ap\n    return aps",
            "def evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms, device_id, apply_mms=True, nms_threshold=0.5, conf_threshold=0.0, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Computes per-class average precision.\\n\\n    Args:\\n        all_boxes:          shape of all_boxes: e.g. 21 classes x 4952 images x 58 rois x 5 coords+score\\n        all_gt_infos:       a dictionary that contains all ground truth annoations in the following form:\\n                            {'class_A': [{'bbox': array([[ 376.,  210.,  456.,  288.,   10.]], dtype=float32), 'det': [False], 'difficult': [False]}, ... ]}\\n                            'class_B': [ <bbox_list> ], <more_class_to_bbox_list_entries> }\\n        classes:            a list of class name, e.g. ['__background__', 'avocado', 'orange', 'butter']\\n        use_07_metric:      whether to use VOC07's 11 point AP computation (default False)\\n        apply_mms:          whether to apply non maximum suppression before computing average precision values\\n        nms_threshold:      the threshold for discarding overlapping ROIs in nms\\n        conf_threshold:     a minimum value for the score of an ROI. ROIs with lower score will be discarded\\n\\n    Returns:\\n        aps - average precision value per class in a dictionary {classname: ap}\\n    \"\n    if apply_mms:\n        print('Number of rois before non-maximum suppression: %d' % sum([len(all_boxes[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n        (nms_dets, _) = apply_nms_to_test_set_results(all_boxes, nms_threshold, conf_threshold, use_gpu_nms, device_id)\n        print('Number of rois  after non-maximum suppression: %d' % sum([len(nms_dets[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n    else:\n        print('Skipping non-maximum suppression')\n        nms_dets = all_boxes\n    aps = {}\n    for (classIndex, className) in enumerate(classes):\n        if className != '__background__':\n            (rec, prec, ap) = _evaluate_detections(classIndex, nms_dets, all_gt_infos[className], use_07_metric=use_07_metric)\n            aps[className] = ap\n    return aps",
            "def evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms, device_id, apply_mms=True, nms_threshold=0.5, conf_threshold=0.0, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Computes per-class average precision.\\n\\n    Args:\\n        all_boxes:          shape of all_boxes: e.g. 21 classes x 4952 images x 58 rois x 5 coords+score\\n        all_gt_infos:       a dictionary that contains all ground truth annoations in the following form:\\n                            {'class_A': [{'bbox': array([[ 376.,  210.,  456.,  288.,   10.]], dtype=float32), 'det': [False], 'difficult': [False]}, ... ]}\\n                            'class_B': [ <bbox_list> ], <more_class_to_bbox_list_entries> }\\n        classes:            a list of class name, e.g. ['__background__', 'avocado', 'orange', 'butter']\\n        use_07_metric:      whether to use VOC07's 11 point AP computation (default False)\\n        apply_mms:          whether to apply non maximum suppression before computing average precision values\\n        nms_threshold:      the threshold for discarding overlapping ROIs in nms\\n        conf_threshold:     a minimum value for the score of an ROI. ROIs with lower score will be discarded\\n\\n    Returns:\\n        aps - average precision value per class in a dictionary {classname: ap}\\n    \"\n    if apply_mms:\n        print('Number of rois before non-maximum suppression: %d' % sum([len(all_boxes[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n        (nms_dets, _) = apply_nms_to_test_set_results(all_boxes, nms_threshold, conf_threshold, use_gpu_nms, device_id)\n        print('Number of rois  after non-maximum suppression: %d' % sum([len(nms_dets[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n    else:\n        print('Skipping non-maximum suppression')\n        nms_dets = all_boxes\n    aps = {}\n    for (classIndex, className) in enumerate(classes):\n        if className != '__background__':\n            (rec, prec, ap) = _evaluate_detections(classIndex, nms_dets, all_gt_infos[className], use_07_metric=use_07_metric)\n            aps[className] = ap\n    return aps",
            "def evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms, device_id, apply_mms=True, nms_threshold=0.5, conf_threshold=0.0, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Computes per-class average precision.\\n\\n    Args:\\n        all_boxes:          shape of all_boxes: e.g. 21 classes x 4952 images x 58 rois x 5 coords+score\\n        all_gt_infos:       a dictionary that contains all ground truth annoations in the following form:\\n                            {'class_A': [{'bbox': array([[ 376.,  210.,  456.,  288.,   10.]], dtype=float32), 'det': [False], 'difficult': [False]}, ... ]}\\n                            'class_B': [ <bbox_list> ], <more_class_to_bbox_list_entries> }\\n        classes:            a list of class name, e.g. ['__background__', 'avocado', 'orange', 'butter']\\n        use_07_metric:      whether to use VOC07's 11 point AP computation (default False)\\n        apply_mms:          whether to apply non maximum suppression before computing average precision values\\n        nms_threshold:      the threshold for discarding overlapping ROIs in nms\\n        conf_threshold:     a minimum value for the score of an ROI. ROIs with lower score will be discarded\\n\\n    Returns:\\n        aps - average precision value per class in a dictionary {classname: ap}\\n    \"\n    if apply_mms:\n        print('Number of rois before non-maximum suppression: %d' % sum([len(all_boxes[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n        (nms_dets, _) = apply_nms_to_test_set_results(all_boxes, nms_threshold, conf_threshold, use_gpu_nms, device_id)\n        print('Number of rois  after non-maximum suppression: %d' % sum([len(nms_dets[i][j]) for i in range(len(all_boxes)) for j in range(len(all_boxes[0]))]))\n    else:\n        print('Skipping non-maximum suppression')\n        nms_dets = all_boxes\n    aps = {}\n    for (classIndex, className) in enumerate(classes):\n        if className != '__background__':\n            (rec, prec, ap) = _evaluate_detections(classIndex, nms_dets, all_gt_infos[className], use_07_metric=use_07_metric)\n            aps[className] = ap\n    return aps"
        ]
    },
    {
        "func_name": "_evaluate_detections",
        "original": "def _evaluate_detections(classIndex, all_boxes, gtInfos, overlapThreshold=0.5, use_07_metric=False):\n    \"\"\"\n    Top level function that does the PASCAL VOC evaluation.\n    \"\"\"\n    num_images = len(all_boxes[0])\n    detBboxes = []\n    detImgIndices = []\n    detConfidences = []\n    for imgIndex in range(num_images):\n        dets = all_boxes[classIndex][imgIndex]\n        if dets != []:\n            for k in range(dets.shape[0]):\n                detImgIndices.append(imgIndex)\n                detConfidences.append(dets[k, -1])\n                detBboxes.append([dets[k, 0] + 1, dets[k, 1] + 1, dets[k, 2] + 1, dets[k, 3] + 1])\n    detBboxes = np.array(detBboxes)\n    detConfidences = np.array(detConfidences)\n    (rec, prec, ap) = _voc_computePrecisionRecallAp(class_recs=gtInfos, confidence=detConfidences, image_ids=detImgIndices, BB=detBboxes, ovthresh=overlapThreshold, use_07_metric=use_07_metric)\n    return (rec, prec, ap)",
        "mutated": [
            "def _evaluate_detections(classIndex, all_boxes, gtInfos, overlapThreshold=0.5, use_07_metric=False):\n    if False:\n        i = 10\n    '\\n    Top level function that does the PASCAL VOC evaluation.\\n    '\n    num_images = len(all_boxes[0])\n    detBboxes = []\n    detImgIndices = []\n    detConfidences = []\n    for imgIndex in range(num_images):\n        dets = all_boxes[classIndex][imgIndex]\n        if dets != []:\n            for k in range(dets.shape[0]):\n                detImgIndices.append(imgIndex)\n                detConfidences.append(dets[k, -1])\n                detBboxes.append([dets[k, 0] + 1, dets[k, 1] + 1, dets[k, 2] + 1, dets[k, 3] + 1])\n    detBboxes = np.array(detBboxes)\n    detConfidences = np.array(detConfidences)\n    (rec, prec, ap) = _voc_computePrecisionRecallAp(class_recs=gtInfos, confidence=detConfidences, image_ids=detImgIndices, BB=detBboxes, ovthresh=overlapThreshold, use_07_metric=use_07_metric)\n    return (rec, prec, ap)",
            "def _evaluate_detections(classIndex, all_boxes, gtInfos, overlapThreshold=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Top level function that does the PASCAL VOC evaluation.\\n    '\n    num_images = len(all_boxes[0])\n    detBboxes = []\n    detImgIndices = []\n    detConfidences = []\n    for imgIndex in range(num_images):\n        dets = all_boxes[classIndex][imgIndex]\n        if dets != []:\n            for k in range(dets.shape[0]):\n                detImgIndices.append(imgIndex)\n                detConfidences.append(dets[k, -1])\n                detBboxes.append([dets[k, 0] + 1, dets[k, 1] + 1, dets[k, 2] + 1, dets[k, 3] + 1])\n    detBboxes = np.array(detBboxes)\n    detConfidences = np.array(detConfidences)\n    (rec, prec, ap) = _voc_computePrecisionRecallAp(class_recs=gtInfos, confidence=detConfidences, image_ids=detImgIndices, BB=detBboxes, ovthresh=overlapThreshold, use_07_metric=use_07_metric)\n    return (rec, prec, ap)",
            "def _evaluate_detections(classIndex, all_boxes, gtInfos, overlapThreshold=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Top level function that does the PASCAL VOC evaluation.\\n    '\n    num_images = len(all_boxes[0])\n    detBboxes = []\n    detImgIndices = []\n    detConfidences = []\n    for imgIndex in range(num_images):\n        dets = all_boxes[classIndex][imgIndex]\n        if dets != []:\n            for k in range(dets.shape[0]):\n                detImgIndices.append(imgIndex)\n                detConfidences.append(dets[k, -1])\n                detBboxes.append([dets[k, 0] + 1, dets[k, 1] + 1, dets[k, 2] + 1, dets[k, 3] + 1])\n    detBboxes = np.array(detBboxes)\n    detConfidences = np.array(detConfidences)\n    (rec, prec, ap) = _voc_computePrecisionRecallAp(class_recs=gtInfos, confidence=detConfidences, image_ids=detImgIndices, BB=detBboxes, ovthresh=overlapThreshold, use_07_metric=use_07_metric)\n    return (rec, prec, ap)",
            "def _evaluate_detections(classIndex, all_boxes, gtInfos, overlapThreshold=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Top level function that does the PASCAL VOC evaluation.\\n    '\n    num_images = len(all_boxes[0])\n    detBboxes = []\n    detImgIndices = []\n    detConfidences = []\n    for imgIndex in range(num_images):\n        dets = all_boxes[classIndex][imgIndex]\n        if dets != []:\n            for k in range(dets.shape[0]):\n                detImgIndices.append(imgIndex)\n                detConfidences.append(dets[k, -1])\n                detBboxes.append([dets[k, 0] + 1, dets[k, 1] + 1, dets[k, 2] + 1, dets[k, 3] + 1])\n    detBboxes = np.array(detBboxes)\n    detConfidences = np.array(detConfidences)\n    (rec, prec, ap) = _voc_computePrecisionRecallAp(class_recs=gtInfos, confidence=detConfidences, image_ids=detImgIndices, BB=detBboxes, ovthresh=overlapThreshold, use_07_metric=use_07_metric)\n    return (rec, prec, ap)",
            "def _evaluate_detections(classIndex, all_boxes, gtInfos, overlapThreshold=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Top level function that does the PASCAL VOC evaluation.\\n    '\n    num_images = len(all_boxes[0])\n    detBboxes = []\n    detImgIndices = []\n    detConfidences = []\n    for imgIndex in range(num_images):\n        dets = all_boxes[classIndex][imgIndex]\n        if dets != []:\n            for k in range(dets.shape[0]):\n                detImgIndices.append(imgIndex)\n                detConfidences.append(dets[k, -1])\n                detBboxes.append([dets[k, 0] + 1, dets[k, 1] + 1, dets[k, 2] + 1, dets[k, 3] + 1])\n    detBboxes = np.array(detBboxes)\n    detConfidences = np.array(detConfidences)\n    (rec, prec, ap) = _voc_computePrecisionRecallAp(class_recs=gtInfos, confidence=detConfidences, image_ids=detImgIndices, BB=detBboxes, ovthresh=overlapThreshold, use_07_metric=use_07_metric)\n    return (rec, prec, ap)"
        ]
    },
    {
        "func_name": "computeAveragePrecision",
        "original": "def computeAveragePrecision(recalls, precisions, use_07_metric=False):\n    \"\"\"\n    Computes VOC AP given precision and recall.\n    \"\"\"\n    if use_07_metric:\n        ap = 0.0\n        for t in np.arange(0.0, 1.1, 0.1):\n            if np.sum(recalls >= t) == 0:\n                p = 0\n            else:\n                p = np.max(precisions[recalls >= t])\n            ap = ap + p / 11.0\n    else:\n        mrecalls = np.concatenate(([0.0], recalls, [1.0]))\n        mprecisions = np.concatenate(([0.0], precisions, [0.0]))\n        for i in range(mprecisions.size - 1, 0, -1):\n            mprecisions[i - 1] = np.maximum(mprecisions[i - 1], mprecisions[i])\n        i = np.where(mrecalls[1:] != mrecalls[:-1])[0]\n        ap = np.sum((mrecalls[i + 1] - mrecalls[i]) * mprecisions[i + 1])\n    return ap",
        "mutated": [
            "def computeAveragePrecision(recalls, precisions, use_07_metric=False):\n    if False:\n        i = 10\n    '\\n    Computes VOC AP given precision and recall.\\n    '\n    if use_07_metric:\n        ap = 0.0\n        for t in np.arange(0.0, 1.1, 0.1):\n            if np.sum(recalls >= t) == 0:\n                p = 0\n            else:\n                p = np.max(precisions[recalls >= t])\n            ap = ap + p / 11.0\n    else:\n        mrecalls = np.concatenate(([0.0], recalls, [1.0]))\n        mprecisions = np.concatenate(([0.0], precisions, [0.0]))\n        for i in range(mprecisions.size - 1, 0, -1):\n            mprecisions[i - 1] = np.maximum(mprecisions[i - 1], mprecisions[i])\n        i = np.where(mrecalls[1:] != mrecalls[:-1])[0]\n        ap = np.sum((mrecalls[i + 1] - mrecalls[i]) * mprecisions[i + 1])\n    return ap",
            "def computeAveragePrecision(recalls, precisions, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Computes VOC AP given precision and recall.\\n    '\n    if use_07_metric:\n        ap = 0.0\n        for t in np.arange(0.0, 1.1, 0.1):\n            if np.sum(recalls >= t) == 0:\n                p = 0\n            else:\n                p = np.max(precisions[recalls >= t])\n            ap = ap + p / 11.0\n    else:\n        mrecalls = np.concatenate(([0.0], recalls, [1.0]))\n        mprecisions = np.concatenate(([0.0], precisions, [0.0]))\n        for i in range(mprecisions.size - 1, 0, -1):\n            mprecisions[i - 1] = np.maximum(mprecisions[i - 1], mprecisions[i])\n        i = np.where(mrecalls[1:] != mrecalls[:-1])[0]\n        ap = np.sum((mrecalls[i + 1] - mrecalls[i]) * mprecisions[i + 1])\n    return ap",
            "def computeAveragePrecision(recalls, precisions, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Computes VOC AP given precision and recall.\\n    '\n    if use_07_metric:\n        ap = 0.0\n        for t in np.arange(0.0, 1.1, 0.1):\n            if np.sum(recalls >= t) == 0:\n                p = 0\n            else:\n                p = np.max(precisions[recalls >= t])\n            ap = ap + p / 11.0\n    else:\n        mrecalls = np.concatenate(([0.0], recalls, [1.0]))\n        mprecisions = np.concatenate(([0.0], precisions, [0.0]))\n        for i in range(mprecisions.size - 1, 0, -1):\n            mprecisions[i - 1] = np.maximum(mprecisions[i - 1], mprecisions[i])\n        i = np.where(mrecalls[1:] != mrecalls[:-1])[0]\n        ap = np.sum((mrecalls[i + 1] - mrecalls[i]) * mprecisions[i + 1])\n    return ap",
            "def computeAveragePrecision(recalls, precisions, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Computes VOC AP given precision and recall.\\n    '\n    if use_07_metric:\n        ap = 0.0\n        for t in np.arange(0.0, 1.1, 0.1):\n            if np.sum(recalls >= t) == 0:\n                p = 0\n            else:\n                p = np.max(precisions[recalls >= t])\n            ap = ap + p / 11.0\n    else:\n        mrecalls = np.concatenate(([0.0], recalls, [1.0]))\n        mprecisions = np.concatenate(([0.0], precisions, [0.0]))\n        for i in range(mprecisions.size - 1, 0, -1):\n            mprecisions[i - 1] = np.maximum(mprecisions[i - 1], mprecisions[i])\n        i = np.where(mrecalls[1:] != mrecalls[:-1])[0]\n        ap = np.sum((mrecalls[i + 1] - mrecalls[i]) * mprecisions[i + 1])\n    return ap",
            "def computeAveragePrecision(recalls, precisions, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Computes VOC AP given precision and recall.\\n    '\n    if use_07_metric:\n        ap = 0.0\n        for t in np.arange(0.0, 1.1, 0.1):\n            if np.sum(recalls >= t) == 0:\n                p = 0\n            else:\n                p = np.max(precisions[recalls >= t])\n            ap = ap + p / 11.0\n    else:\n        mrecalls = np.concatenate(([0.0], recalls, [1.0]))\n        mprecisions = np.concatenate(([0.0], precisions, [0.0]))\n        for i in range(mprecisions.size - 1, 0, -1):\n            mprecisions[i - 1] = np.maximum(mprecisions[i - 1], mprecisions[i])\n        i = np.where(mrecalls[1:] != mrecalls[:-1])[0]\n        ap = np.sum((mrecalls[i + 1] - mrecalls[i]) * mprecisions[i + 1])\n    return ap"
        ]
    },
    {
        "func_name": "_voc_computePrecisionRecallAp",
        "original": "def _voc_computePrecisionRecallAp(class_recs, confidence, image_ids, BB, ovthresh=0.5, use_07_metric=False):\n    \"\"\"\n    Computes precision, recall. and average precision\n    \"\"\"\n    if len(BB) == 0:\n        return (0.0, 0.0, 0.0)\n    sorted_ind = np.argsort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d in range(nd):\n        R = class_recs[image_ids[d]]\n        bb = BB[d, :].astype(float)\n        ovmax = -np.inf\n        BBGT = R['bbox'].astype(float)\n        if BBGT.size > 0:\n            ixmin = np.maximum(BBGT[:, 0], bb[0])\n            iymin = np.maximum(BBGT[:, 1], bb[1])\n            ixmax = np.minimum(BBGT[:, 2], bb[2])\n            iymax = np.minimum(BBGT[:, 3], bb[3])\n            iw = np.maximum(ixmax - ixmin + 1.0, 0.0)\n            ih = np.maximum(iymax - iymin + 1.0, 0.0)\n            inters = iw * ih\n            uni = (bb[2] - bb[0] + 1.0) * (bb[3] - bb[1] + 1.0) + (BBGT[:, 2] - BBGT[:, 0] + 1.0) * (BBGT[:, 3] - BBGT[:, 1] + 1.0) - inters\n            overlaps = inters / uni\n            ovmax = np.max(overlaps)\n            jmax = np.argmax(overlaps)\n        if ovmax > ovthresh:\n            if not R['difficult'][jmax]:\n                if not R['det'][jmax]:\n                    tp[d] = 1.0\n                    R['det'][jmax] = 1\n                else:\n                    fp[d] = 1.0\n        else:\n            fp[d] = 1.0\n    npos = sum([len(cr['bbox']) for cr in class_recs])\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp / float(npos)\n    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n    ap = computeAveragePrecision(rec, prec, use_07_metric)\n    return (rec, prec, ap)",
        "mutated": [
            "def _voc_computePrecisionRecallAp(class_recs, confidence, image_ids, BB, ovthresh=0.5, use_07_metric=False):\n    if False:\n        i = 10\n    '\\n    Computes precision, recall. and average precision\\n    '\n    if len(BB) == 0:\n        return (0.0, 0.0, 0.0)\n    sorted_ind = np.argsort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d in range(nd):\n        R = class_recs[image_ids[d]]\n        bb = BB[d, :].astype(float)\n        ovmax = -np.inf\n        BBGT = R['bbox'].astype(float)\n        if BBGT.size > 0:\n            ixmin = np.maximum(BBGT[:, 0], bb[0])\n            iymin = np.maximum(BBGT[:, 1], bb[1])\n            ixmax = np.minimum(BBGT[:, 2], bb[2])\n            iymax = np.minimum(BBGT[:, 3], bb[3])\n            iw = np.maximum(ixmax - ixmin + 1.0, 0.0)\n            ih = np.maximum(iymax - iymin + 1.0, 0.0)\n            inters = iw * ih\n            uni = (bb[2] - bb[0] + 1.0) * (bb[3] - bb[1] + 1.0) + (BBGT[:, 2] - BBGT[:, 0] + 1.0) * (BBGT[:, 3] - BBGT[:, 1] + 1.0) - inters\n            overlaps = inters / uni\n            ovmax = np.max(overlaps)\n            jmax = np.argmax(overlaps)\n        if ovmax > ovthresh:\n            if not R['difficult'][jmax]:\n                if not R['det'][jmax]:\n                    tp[d] = 1.0\n                    R['det'][jmax] = 1\n                else:\n                    fp[d] = 1.0\n        else:\n            fp[d] = 1.0\n    npos = sum([len(cr['bbox']) for cr in class_recs])\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp / float(npos)\n    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n    ap = computeAveragePrecision(rec, prec, use_07_metric)\n    return (rec, prec, ap)",
            "def _voc_computePrecisionRecallAp(class_recs, confidence, image_ids, BB, ovthresh=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Computes precision, recall. and average precision\\n    '\n    if len(BB) == 0:\n        return (0.0, 0.0, 0.0)\n    sorted_ind = np.argsort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d in range(nd):\n        R = class_recs[image_ids[d]]\n        bb = BB[d, :].astype(float)\n        ovmax = -np.inf\n        BBGT = R['bbox'].astype(float)\n        if BBGT.size > 0:\n            ixmin = np.maximum(BBGT[:, 0], bb[0])\n            iymin = np.maximum(BBGT[:, 1], bb[1])\n            ixmax = np.minimum(BBGT[:, 2], bb[2])\n            iymax = np.minimum(BBGT[:, 3], bb[3])\n            iw = np.maximum(ixmax - ixmin + 1.0, 0.0)\n            ih = np.maximum(iymax - iymin + 1.0, 0.0)\n            inters = iw * ih\n            uni = (bb[2] - bb[0] + 1.0) * (bb[3] - bb[1] + 1.0) + (BBGT[:, 2] - BBGT[:, 0] + 1.0) * (BBGT[:, 3] - BBGT[:, 1] + 1.0) - inters\n            overlaps = inters / uni\n            ovmax = np.max(overlaps)\n            jmax = np.argmax(overlaps)\n        if ovmax > ovthresh:\n            if not R['difficult'][jmax]:\n                if not R['det'][jmax]:\n                    tp[d] = 1.0\n                    R['det'][jmax] = 1\n                else:\n                    fp[d] = 1.0\n        else:\n            fp[d] = 1.0\n    npos = sum([len(cr['bbox']) for cr in class_recs])\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp / float(npos)\n    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n    ap = computeAveragePrecision(rec, prec, use_07_metric)\n    return (rec, prec, ap)",
            "def _voc_computePrecisionRecallAp(class_recs, confidence, image_ids, BB, ovthresh=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Computes precision, recall. and average precision\\n    '\n    if len(BB) == 0:\n        return (0.0, 0.0, 0.0)\n    sorted_ind = np.argsort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d in range(nd):\n        R = class_recs[image_ids[d]]\n        bb = BB[d, :].astype(float)\n        ovmax = -np.inf\n        BBGT = R['bbox'].astype(float)\n        if BBGT.size > 0:\n            ixmin = np.maximum(BBGT[:, 0], bb[0])\n            iymin = np.maximum(BBGT[:, 1], bb[1])\n            ixmax = np.minimum(BBGT[:, 2], bb[2])\n            iymax = np.minimum(BBGT[:, 3], bb[3])\n            iw = np.maximum(ixmax - ixmin + 1.0, 0.0)\n            ih = np.maximum(iymax - iymin + 1.0, 0.0)\n            inters = iw * ih\n            uni = (bb[2] - bb[0] + 1.0) * (bb[3] - bb[1] + 1.0) + (BBGT[:, 2] - BBGT[:, 0] + 1.0) * (BBGT[:, 3] - BBGT[:, 1] + 1.0) - inters\n            overlaps = inters / uni\n            ovmax = np.max(overlaps)\n            jmax = np.argmax(overlaps)\n        if ovmax > ovthresh:\n            if not R['difficult'][jmax]:\n                if not R['det'][jmax]:\n                    tp[d] = 1.0\n                    R['det'][jmax] = 1\n                else:\n                    fp[d] = 1.0\n        else:\n            fp[d] = 1.0\n    npos = sum([len(cr['bbox']) for cr in class_recs])\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp / float(npos)\n    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n    ap = computeAveragePrecision(rec, prec, use_07_metric)\n    return (rec, prec, ap)",
            "def _voc_computePrecisionRecallAp(class_recs, confidence, image_ids, BB, ovthresh=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Computes precision, recall. and average precision\\n    '\n    if len(BB) == 0:\n        return (0.0, 0.0, 0.0)\n    sorted_ind = np.argsort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d in range(nd):\n        R = class_recs[image_ids[d]]\n        bb = BB[d, :].astype(float)\n        ovmax = -np.inf\n        BBGT = R['bbox'].astype(float)\n        if BBGT.size > 0:\n            ixmin = np.maximum(BBGT[:, 0], bb[0])\n            iymin = np.maximum(BBGT[:, 1], bb[1])\n            ixmax = np.minimum(BBGT[:, 2], bb[2])\n            iymax = np.minimum(BBGT[:, 3], bb[3])\n            iw = np.maximum(ixmax - ixmin + 1.0, 0.0)\n            ih = np.maximum(iymax - iymin + 1.0, 0.0)\n            inters = iw * ih\n            uni = (bb[2] - bb[0] + 1.0) * (bb[3] - bb[1] + 1.0) + (BBGT[:, 2] - BBGT[:, 0] + 1.0) * (BBGT[:, 3] - BBGT[:, 1] + 1.0) - inters\n            overlaps = inters / uni\n            ovmax = np.max(overlaps)\n            jmax = np.argmax(overlaps)\n        if ovmax > ovthresh:\n            if not R['difficult'][jmax]:\n                if not R['det'][jmax]:\n                    tp[d] = 1.0\n                    R['det'][jmax] = 1\n                else:\n                    fp[d] = 1.0\n        else:\n            fp[d] = 1.0\n    npos = sum([len(cr['bbox']) for cr in class_recs])\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp / float(npos)\n    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n    ap = computeAveragePrecision(rec, prec, use_07_metric)\n    return (rec, prec, ap)",
            "def _voc_computePrecisionRecallAp(class_recs, confidence, image_ids, BB, ovthresh=0.5, use_07_metric=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Computes precision, recall. and average precision\\n    '\n    if len(BB) == 0:\n        return (0.0, 0.0, 0.0)\n    sorted_ind = np.argsort(-confidence)\n    BB = BB[sorted_ind, :]\n    image_ids = [image_ids[x] for x in sorted_ind]\n    nd = len(image_ids)\n    tp = np.zeros(nd)\n    fp = np.zeros(nd)\n    for d in range(nd):\n        R = class_recs[image_ids[d]]\n        bb = BB[d, :].astype(float)\n        ovmax = -np.inf\n        BBGT = R['bbox'].astype(float)\n        if BBGT.size > 0:\n            ixmin = np.maximum(BBGT[:, 0], bb[0])\n            iymin = np.maximum(BBGT[:, 1], bb[1])\n            ixmax = np.minimum(BBGT[:, 2], bb[2])\n            iymax = np.minimum(BBGT[:, 3], bb[3])\n            iw = np.maximum(ixmax - ixmin + 1.0, 0.0)\n            ih = np.maximum(iymax - iymin + 1.0, 0.0)\n            inters = iw * ih\n            uni = (bb[2] - bb[0] + 1.0) * (bb[3] - bb[1] + 1.0) + (BBGT[:, 2] - BBGT[:, 0] + 1.0) * (BBGT[:, 3] - BBGT[:, 1] + 1.0) - inters\n            overlaps = inters / uni\n            ovmax = np.max(overlaps)\n            jmax = np.argmax(overlaps)\n        if ovmax > ovthresh:\n            if not R['difficult'][jmax]:\n                if not R['det'][jmax]:\n                    tp[d] = 1.0\n                    R['det'][jmax] = 1\n                else:\n                    fp[d] = 1.0\n        else:\n            fp[d] = 1.0\n    npos = sum([len(cr['bbox']) for cr in class_recs])\n    fp = np.cumsum(fp)\n    tp = np.cumsum(tp)\n    rec = tp / float(npos)\n    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n    ap = computeAveragePrecision(rec, prec, use_07_metric)\n    return (rec, prec, ap)"
        ]
    }
]