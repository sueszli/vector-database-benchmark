[
    {
        "func_name": "__init__",
        "original": "def __init__(self, num_classes, seg_in_channels, part_in_channels, seg_conv_channels=None, part_conv_channels=None, merge_conv_channels=None, down_conv_channels=None, shared_fc_channels=None, cls_channels=None, reg_channels=None, dropout_ratio=0.1, roi_feat_size=14, with_corner_loss=True, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d', eps=0.001, momentum=0.01), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, reduction='none', loss_weight=1.0), init_cfg=None):\n    super(PartA2BboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.with_corner_loss = with_corner_loss\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_cls = build_loss(loss_cls)\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    assert down_conv_channels[-1] == shared_fc_channels[0]\n    part_channel_last = part_in_channels\n    part_conv = []\n    for (i, channel) in enumerate(part_conv_channels):\n        part_conv.append(make_sparse_convmodule(part_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_part{i}', conv_type='SubMConv3d'))\n        part_channel_last = channel\n    self.part_conv = SparseSequential(*part_conv)\n    seg_channel_last = seg_in_channels\n    seg_conv = []\n    for (i, channel) in enumerate(seg_conv_channels):\n        seg_conv.append(make_sparse_convmodule(seg_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_seg{i}', conv_type='SubMConv3d'))\n        seg_channel_last = channel\n    self.seg_conv = SparseSequential(*seg_conv)\n    self.conv_down = SparseSequential()\n    merge_conv_channel_last = part_channel_last + seg_channel_last\n    merge_conv = []\n    for (i, channel) in enumerate(merge_conv_channels):\n        merge_conv.append(make_sparse_convmodule(merge_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down0'))\n        merge_conv_channel_last = channel\n    down_conv_channel_last = merge_conv_channel_last\n    conv_down = []\n    for (i, channel) in enumerate(down_conv_channels):\n        conv_down.append(make_sparse_convmodule(down_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down1'))\n        down_conv_channel_last = channel\n    self.conv_down.add_module('merge_conv', SparseSequential(*merge_conv))\n    self.conv_down.add_module('max_pool3d', SparseMaxPool3d(kernel_size=2, stride=2))\n    self.conv_down.add_module('down_conv', SparseSequential(*conv_down))\n    shared_fc_list = []\n    pool_size = roi_feat_size // 2\n    pre_channel = shared_fc_channels[0] * pool_size ** 3\n    for k in range(1, len(shared_fc_channels)):\n        shared_fc_list.append(ConvModule(pre_channel, shared_fc_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = shared_fc_channels[k]\n        if k != len(shared_fc_channels) - 1 and dropout_ratio > 0:\n            shared_fc_list.append(nn.Dropout(dropout_ratio))\n    self.shared_fc = nn.Sequential(*shared_fc_list)\n    channel_in = shared_fc_channels[-1]\n    cls_channel = 1\n    cls_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(cls_channels)):\n        cls_layers.append(ConvModule(pre_channel, cls_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = cls_channels[k]\n    cls_layers.append(ConvModule(pre_channel, cls_channel, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        cls_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_cls = nn.Sequential(*cls_layers)\n    reg_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(reg_channels)):\n        reg_layers.append(ConvModule(pre_channel, reg_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = reg_channels[k]\n    reg_layers.append(ConvModule(pre_channel, self.bbox_coder.code_size, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        reg_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_reg = nn.Sequential(*reg_layers)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Xavier', layer=['Conv2d', 'Conv1d'], distribution='uniform')",
        "mutated": [
            "def __init__(self, num_classes, seg_in_channels, part_in_channels, seg_conv_channels=None, part_conv_channels=None, merge_conv_channels=None, down_conv_channels=None, shared_fc_channels=None, cls_channels=None, reg_channels=None, dropout_ratio=0.1, roi_feat_size=14, with_corner_loss=True, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d', eps=0.001, momentum=0.01), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, reduction='none', loss_weight=1.0), init_cfg=None):\n    if False:\n        i = 10\n    super(PartA2BboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.with_corner_loss = with_corner_loss\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_cls = build_loss(loss_cls)\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    assert down_conv_channels[-1] == shared_fc_channels[0]\n    part_channel_last = part_in_channels\n    part_conv = []\n    for (i, channel) in enumerate(part_conv_channels):\n        part_conv.append(make_sparse_convmodule(part_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_part{i}', conv_type='SubMConv3d'))\n        part_channel_last = channel\n    self.part_conv = SparseSequential(*part_conv)\n    seg_channel_last = seg_in_channels\n    seg_conv = []\n    for (i, channel) in enumerate(seg_conv_channels):\n        seg_conv.append(make_sparse_convmodule(seg_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_seg{i}', conv_type='SubMConv3d'))\n        seg_channel_last = channel\n    self.seg_conv = SparseSequential(*seg_conv)\n    self.conv_down = SparseSequential()\n    merge_conv_channel_last = part_channel_last + seg_channel_last\n    merge_conv = []\n    for (i, channel) in enumerate(merge_conv_channels):\n        merge_conv.append(make_sparse_convmodule(merge_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down0'))\n        merge_conv_channel_last = channel\n    down_conv_channel_last = merge_conv_channel_last\n    conv_down = []\n    for (i, channel) in enumerate(down_conv_channels):\n        conv_down.append(make_sparse_convmodule(down_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down1'))\n        down_conv_channel_last = channel\n    self.conv_down.add_module('merge_conv', SparseSequential(*merge_conv))\n    self.conv_down.add_module('max_pool3d', SparseMaxPool3d(kernel_size=2, stride=2))\n    self.conv_down.add_module('down_conv', SparseSequential(*conv_down))\n    shared_fc_list = []\n    pool_size = roi_feat_size // 2\n    pre_channel = shared_fc_channels[0] * pool_size ** 3\n    for k in range(1, len(shared_fc_channels)):\n        shared_fc_list.append(ConvModule(pre_channel, shared_fc_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = shared_fc_channels[k]\n        if k != len(shared_fc_channels) - 1 and dropout_ratio > 0:\n            shared_fc_list.append(nn.Dropout(dropout_ratio))\n    self.shared_fc = nn.Sequential(*shared_fc_list)\n    channel_in = shared_fc_channels[-1]\n    cls_channel = 1\n    cls_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(cls_channels)):\n        cls_layers.append(ConvModule(pre_channel, cls_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = cls_channels[k]\n    cls_layers.append(ConvModule(pre_channel, cls_channel, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        cls_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_cls = nn.Sequential(*cls_layers)\n    reg_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(reg_channels)):\n        reg_layers.append(ConvModule(pre_channel, reg_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = reg_channels[k]\n    reg_layers.append(ConvModule(pre_channel, self.bbox_coder.code_size, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        reg_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_reg = nn.Sequential(*reg_layers)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Xavier', layer=['Conv2d', 'Conv1d'], distribution='uniform')",
            "def __init__(self, num_classes, seg_in_channels, part_in_channels, seg_conv_channels=None, part_conv_channels=None, merge_conv_channels=None, down_conv_channels=None, shared_fc_channels=None, cls_channels=None, reg_channels=None, dropout_ratio=0.1, roi_feat_size=14, with_corner_loss=True, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d', eps=0.001, momentum=0.01), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, reduction='none', loss_weight=1.0), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(PartA2BboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.with_corner_loss = with_corner_loss\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_cls = build_loss(loss_cls)\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    assert down_conv_channels[-1] == shared_fc_channels[0]\n    part_channel_last = part_in_channels\n    part_conv = []\n    for (i, channel) in enumerate(part_conv_channels):\n        part_conv.append(make_sparse_convmodule(part_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_part{i}', conv_type='SubMConv3d'))\n        part_channel_last = channel\n    self.part_conv = SparseSequential(*part_conv)\n    seg_channel_last = seg_in_channels\n    seg_conv = []\n    for (i, channel) in enumerate(seg_conv_channels):\n        seg_conv.append(make_sparse_convmodule(seg_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_seg{i}', conv_type='SubMConv3d'))\n        seg_channel_last = channel\n    self.seg_conv = SparseSequential(*seg_conv)\n    self.conv_down = SparseSequential()\n    merge_conv_channel_last = part_channel_last + seg_channel_last\n    merge_conv = []\n    for (i, channel) in enumerate(merge_conv_channels):\n        merge_conv.append(make_sparse_convmodule(merge_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down0'))\n        merge_conv_channel_last = channel\n    down_conv_channel_last = merge_conv_channel_last\n    conv_down = []\n    for (i, channel) in enumerate(down_conv_channels):\n        conv_down.append(make_sparse_convmodule(down_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down1'))\n        down_conv_channel_last = channel\n    self.conv_down.add_module('merge_conv', SparseSequential(*merge_conv))\n    self.conv_down.add_module('max_pool3d', SparseMaxPool3d(kernel_size=2, stride=2))\n    self.conv_down.add_module('down_conv', SparseSequential(*conv_down))\n    shared_fc_list = []\n    pool_size = roi_feat_size // 2\n    pre_channel = shared_fc_channels[0] * pool_size ** 3\n    for k in range(1, len(shared_fc_channels)):\n        shared_fc_list.append(ConvModule(pre_channel, shared_fc_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = shared_fc_channels[k]\n        if k != len(shared_fc_channels) - 1 and dropout_ratio > 0:\n            shared_fc_list.append(nn.Dropout(dropout_ratio))\n    self.shared_fc = nn.Sequential(*shared_fc_list)\n    channel_in = shared_fc_channels[-1]\n    cls_channel = 1\n    cls_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(cls_channels)):\n        cls_layers.append(ConvModule(pre_channel, cls_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = cls_channels[k]\n    cls_layers.append(ConvModule(pre_channel, cls_channel, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        cls_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_cls = nn.Sequential(*cls_layers)\n    reg_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(reg_channels)):\n        reg_layers.append(ConvModule(pre_channel, reg_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = reg_channels[k]\n    reg_layers.append(ConvModule(pre_channel, self.bbox_coder.code_size, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        reg_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_reg = nn.Sequential(*reg_layers)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Xavier', layer=['Conv2d', 'Conv1d'], distribution='uniform')",
            "def __init__(self, num_classes, seg_in_channels, part_in_channels, seg_conv_channels=None, part_conv_channels=None, merge_conv_channels=None, down_conv_channels=None, shared_fc_channels=None, cls_channels=None, reg_channels=None, dropout_ratio=0.1, roi_feat_size=14, with_corner_loss=True, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d', eps=0.001, momentum=0.01), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, reduction='none', loss_weight=1.0), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(PartA2BboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.with_corner_loss = with_corner_loss\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_cls = build_loss(loss_cls)\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    assert down_conv_channels[-1] == shared_fc_channels[0]\n    part_channel_last = part_in_channels\n    part_conv = []\n    for (i, channel) in enumerate(part_conv_channels):\n        part_conv.append(make_sparse_convmodule(part_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_part{i}', conv_type='SubMConv3d'))\n        part_channel_last = channel\n    self.part_conv = SparseSequential(*part_conv)\n    seg_channel_last = seg_in_channels\n    seg_conv = []\n    for (i, channel) in enumerate(seg_conv_channels):\n        seg_conv.append(make_sparse_convmodule(seg_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_seg{i}', conv_type='SubMConv3d'))\n        seg_channel_last = channel\n    self.seg_conv = SparseSequential(*seg_conv)\n    self.conv_down = SparseSequential()\n    merge_conv_channel_last = part_channel_last + seg_channel_last\n    merge_conv = []\n    for (i, channel) in enumerate(merge_conv_channels):\n        merge_conv.append(make_sparse_convmodule(merge_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down0'))\n        merge_conv_channel_last = channel\n    down_conv_channel_last = merge_conv_channel_last\n    conv_down = []\n    for (i, channel) in enumerate(down_conv_channels):\n        conv_down.append(make_sparse_convmodule(down_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down1'))\n        down_conv_channel_last = channel\n    self.conv_down.add_module('merge_conv', SparseSequential(*merge_conv))\n    self.conv_down.add_module('max_pool3d', SparseMaxPool3d(kernel_size=2, stride=2))\n    self.conv_down.add_module('down_conv', SparseSequential(*conv_down))\n    shared_fc_list = []\n    pool_size = roi_feat_size // 2\n    pre_channel = shared_fc_channels[0] * pool_size ** 3\n    for k in range(1, len(shared_fc_channels)):\n        shared_fc_list.append(ConvModule(pre_channel, shared_fc_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = shared_fc_channels[k]\n        if k != len(shared_fc_channels) - 1 and dropout_ratio > 0:\n            shared_fc_list.append(nn.Dropout(dropout_ratio))\n    self.shared_fc = nn.Sequential(*shared_fc_list)\n    channel_in = shared_fc_channels[-1]\n    cls_channel = 1\n    cls_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(cls_channels)):\n        cls_layers.append(ConvModule(pre_channel, cls_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = cls_channels[k]\n    cls_layers.append(ConvModule(pre_channel, cls_channel, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        cls_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_cls = nn.Sequential(*cls_layers)\n    reg_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(reg_channels)):\n        reg_layers.append(ConvModule(pre_channel, reg_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = reg_channels[k]\n    reg_layers.append(ConvModule(pre_channel, self.bbox_coder.code_size, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        reg_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_reg = nn.Sequential(*reg_layers)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Xavier', layer=['Conv2d', 'Conv1d'], distribution='uniform')",
            "def __init__(self, num_classes, seg_in_channels, part_in_channels, seg_conv_channels=None, part_conv_channels=None, merge_conv_channels=None, down_conv_channels=None, shared_fc_channels=None, cls_channels=None, reg_channels=None, dropout_ratio=0.1, roi_feat_size=14, with_corner_loss=True, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d', eps=0.001, momentum=0.01), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, reduction='none', loss_weight=1.0), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(PartA2BboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.with_corner_loss = with_corner_loss\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_cls = build_loss(loss_cls)\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    assert down_conv_channels[-1] == shared_fc_channels[0]\n    part_channel_last = part_in_channels\n    part_conv = []\n    for (i, channel) in enumerate(part_conv_channels):\n        part_conv.append(make_sparse_convmodule(part_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_part{i}', conv_type='SubMConv3d'))\n        part_channel_last = channel\n    self.part_conv = SparseSequential(*part_conv)\n    seg_channel_last = seg_in_channels\n    seg_conv = []\n    for (i, channel) in enumerate(seg_conv_channels):\n        seg_conv.append(make_sparse_convmodule(seg_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_seg{i}', conv_type='SubMConv3d'))\n        seg_channel_last = channel\n    self.seg_conv = SparseSequential(*seg_conv)\n    self.conv_down = SparseSequential()\n    merge_conv_channel_last = part_channel_last + seg_channel_last\n    merge_conv = []\n    for (i, channel) in enumerate(merge_conv_channels):\n        merge_conv.append(make_sparse_convmodule(merge_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down0'))\n        merge_conv_channel_last = channel\n    down_conv_channel_last = merge_conv_channel_last\n    conv_down = []\n    for (i, channel) in enumerate(down_conv_channels):\n        conv_down.append(make_sparse_convmodule(down_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down1'))\n        down_conv_channel_last = channel\n    self.conv_down.add_module('merge_conv', SparseSequential(*merge_conv))\n    self.conv_down.add_module('max_pool3d', SparseMaxPool3d(kernel_size=2, stride=2))\n    self.conv_down.add_module('down_conv', SparseSequential(*conv_down))\n    shared_fc_list = []\n    pool_size = roi_feat_size // 2\n    pre_channel = shared_fc_channels[0] * pool_size ** 3\n    for k in range(1, len(shared_fc_channels)):\n        shared_fc_list.append(ConvModule(pre_channel, shared_fc_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = shared_fc_channels[k]\n        if k != len(shared_fc_channels) - 1 and dropout_ratio > 0:\n            shared_fc_list.append(nn.Dropout(dropout_ratio))\n    self.shared_fc = nn.Sequential(*shared_fc_list)\n    channel_in = shared_fc_channels[-1]\n    cls_channel = 1\n    cls_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(cls_channels)):\n        cls_layers.append(ConvModule(pre_channel, cls_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = cls_channels[k]\n    cls_layers.append(ConvModule(pre_channel, cls_channel, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        cls_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_cls = nn.Sequential(*cls_layers)\n    reg_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(reg_channels)):\n        reg_layers.append(ConvModule(pre_channel, reg_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = reg_channels[k]\n    reg_layers.append(ConvModule(pre_channel, self.bbox_coder.code_size, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        reg_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_reg = nn.Sequential(*reg_layers)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Xavier', layer=['Conv2d', 'Conv1d'], distribution='uniform')",
            "def __init__(self, num_classes, seg_in_channels, part_in_channels, seg_conv_channels=None, part_conv_channels=None, merge_conv_channels=None, down_conv_channels=None, shared_fc_channels=None, cls_channels=None, reg_channels=None, dropout_ratio=0.1, roi_feat_size=14, with_corner_loss=True, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d', eps=0.001, momentum=0.01), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, reduction='none', loss_weight=1.0), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(PartA2BboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.with_corner_loss = with_corner_loss\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_cls = build_loss(loss_cls)\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    assert down_conv_channels[-1] == shared_fc_channels[0]\n    part_channel_last = part_in_channels\n    part_conv = []\n    for (i, channel) in enumerate(part_conv_channels):\n        part_conv.append(make_sparse_convmodule(part_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_part{i}', conv_type='SubMConv3d'))\n        part_channel_last = channel\n    self.part_conv = SparseSequential(*part_conv)\n    seg_channel_last = seg_in_channels\n    seg_conv = []\n    for (i, channel) in enumerate(seg_conv_channels):\n        seg_conv.append(make_sparse_convmodule(seg_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key=f'rcnn_seg{i}', conv_type='SubMConv3d'))\n        seg_channel_last = channel\n    self.seg_conv = SparseSequential(*seg_conv)\n    self.conv_down = SparseSequential()\n    merge_conv_channel_last = part_channel_last + seg_channel_last\n    merge_conv = []\n    for (i, channel) in enumerate(merge_conv_channels):\n        merge_conv.append(make_sparse_convmodule(merge_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down0'))\n        merge_conv_channel_last = channel\n    down_conv_channel_last = merge_conv_channel_last\n    conv_down = []\n    for (i, channel) in enumerate(down_conv_channels):\n        conv_down.append(make_sparse_convmodule(down_conv_channel_last, channel, 3, padding=1, norm_cfg=norm_cfg, indice_key='rcnn_down1'))\n        down_conv_channel_last = channel\n    self.conv_down.add_module('merge_conv', SparseSequential(*merge_conv))\n    self.conv_down.add_module('max_pool3d', SparseMaxPool3d(kernel_size=2, stride=2))\n    self.conv_down.add_module('down_conv', SparseSequential(*conv_down))\n    shared_fc_list = []\n    pool_size = roi_feat_size // 2\n    pre_channel = shared_fc_channels[0] * pool_size ** 3\n    for k in range(1, len(shared_fc_channels)):\n        shared_fc_list.append(ConvModule(pre_channel, shared_fc_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = shared_fc_channels[k]\n        if k != len(shared_fc_channels) - 1 and dropout_ratio > 0:\n            shared_fc_list.append(nn.Dropout(dropout_ratio))\n    self.shared_fc = nn.Sequential(*shared_fc_list)\n    channel_in = shared_fc_channels[-1]\n    cls_channel = 1\n    cls_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(cls_channels)):\n        cls_layers.append(ConvModule(pre_channel, cls_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = cls_channels[k]\n    cls_layers.append(ConvModule(pre_channel, cls_channel, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        cls_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_cls = nn.Sequential(*cls_layers)\n    reg_layers = []\n    pre_channel = channel_in\n    for k in range(0, len(reg_channels)):\n        reg_layers.append(ConvModule(pre_channel, reg_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, inplace=True))\n        pre_channel = reg_channels[k]\n    reg_layers.append(ConvModule(pre_channel, self.bbox_coder.code_size, 1, padding=0, conv_cfg=conv_cfg, act_cfg=None))\n    if dropout_ratio >= 0:\n        reg_layers.insert(1, nn.Dropout(dropout_ratio))\n    self.conv_reg = nn.Sequential(*reg_layers)\n    if init_cfg is None:\n        self.init_cfg = dict(type='Xavier', layer=['Conv2d', 'Conv1d'], distribution='uniform')"
        ]
    },
    {
        "func_name": "init_weights",
        "original": "def init_weights(self):\n    super().init_weights()\n    normal_init(self.conv_reg[-1].conv, mean=0, std=0.001)",
        "mutated": [
            "def init_weights(self):\n    if False:\n        i = 10\n    super().init_weights()\n    normal_init(self.conv_reg[-1].conv, mean=0, std=0.001)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().init_weights()\n    normal_init(self.conv_reg[-1].conv, mean=0, std=0.001)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().init_weights()\n    normal_init(self.conv_reg[-1].conv, mean=0, std=0.001)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().init_weights()\n    normal_init(self.conv_reg[-1].conv, mean=0, std=0.001)",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().init_weights()\n    normal_init(self.conv_reg[-1].conv, mean=0, std=0.001)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, seg_feats, part_feats):\n    \"\"\"Forward pass.\n\n        Args:\n            seg_feats (torch.Tensor): Point-wise semantic features.\n            part_feats (torch.Tensor): Point-wise part prediction features.\n\n        Returns:\n            tuple[torch.Tensor]: Score of class and bbox predictions.\n        \"\"\"\n    rcnn_batch_size = part_feats.shape[0]\n    sparse_shape = part_feats.shape[1:4]\n    sparse_idx = part_feats.sum(dim=-1).nonzero(as_tuple=False)\n    part_features = part_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    seg_features = seg_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    coords = sparse_idx.int().contiguous()\n    part_features = SparseConvTensor(part_features, coords, sparse_shape, rcnn_batch_size)\n    seg_features = SparseConvTensor(seg_features, coords, sparse_shape, rcnn_batch_size)\n    x_part = self.part_conv(part_features)\n    x_rpn = self.seg_conv(seg_features)\n    merged_feature = torch.cat((x_rpn.features, x_part.features), dim=1)\n    shared_feature = SparseConvTensor(merged_feature, coords, sparse_shape, rcnn_batch_size)\n    x = self.conv_down(shared_feature)\n    shared_feature = x.dense().view(rcnn_batch_size, -1, 1)\n    shared_feature = self.shared_fc(shared_feature)\n    cls_score = self.conv_cls(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    bbox_pred = self.conv_reg(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    return (cls_score, bbox_pred)",
        "mutated": [
            "def forward(self, seg_feats, part_feats):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            seg_feats (torch.Tensor): Point-wise semantic features.\\n            part_feats (torch.Tensor): Point-wise part prediction features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Score of class and bbox predictions.\\n        '\n    rcnn_batch_size = part_feats.shape[0]\n    sparse_shape = part_feats.shape[1:4]\n    sparse_idx = part_feats.sum(dim=-1).nonzero(as_tuple=False)\n    part_features = part_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    seg_features = seg_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    coords = sparse_idx.int().contiguous()\n    part_features = SparseConvTensor(part_features, coords, sparse_shape, rcnn_batch_size)\n    seg_features = SparseConvTensor(seg_features, coords, sparse_shape, rcnn_batch_size)\n    x_part = self.part_conv(part_features)\n    x_rpn = self.seg_conv(seg_features)\n    merged_feature = torch.cat((x_rpn.features, x_part.features), dim=1)\n    shared_feature = SparseConvTensor(merged_feature, coords, sparse_shape, rcnn_batch_size)\n    x = self.conv_down(shared_feature)\n    shared_feature = x.dense().view(rcnn_batch_size, -1, 1)\n    shared_feature = self.shared_fc(shared_feature)\n    cls_score = self.conv_cls(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    bbox_pred = self.conv_reg(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    return (cls_score, bbox_pred)",
            "def forward(self, seg_feats, part_feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            seg_feats (torch.Tensor): Point-wise semantic features.\\n            part_feats (torch.Tensor): Point-wise part prediction features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Score of class and bbox predictions.\\n        '\n    rcnn_batch_size = part_feats.shape[0]\n    sparse_shape = part_feats.shape[1:4]\n    sparse_idx = part_feats.sum(dim=-1).nonzero(as_tuple=False)\n    part_features = part_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    seg_features = seg_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    coords = sparse_idx.int().contiguous()\n    part_features = SparseConvTensor(part_features, coords, sparse_shape, rcnn_batch_size)\n    seg_features = SparseConvTensor(seg_features, coords, sparse_shape, rcnn_batch_size)\n    x_part = self.part_conv(part_features)\n    x_rpn = self.seg_conv(seg_features)\n    merged_feature = torch.cat((x_rpn.features, x_part.features), dim=1)\n    shared_feature = SparseConvTensor(merged_feature, coords, sparse_shape, rcnn_batch_size)\n    x = self.conv_down(shared_feature)\n    shared_feature = x.dense().view(rcnn_batch_size, -1, 1)\n    shared_feature = self.shared_fc(shared_feature)\n    cls_score = self.conv_cls(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    bbox_pred = self.conv_reg(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    return (cls_score, bbox_pred)",
            "def forward(self, seg_feats, part_feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            seg_feats (torch.Tensor): Point-wise semantic features.\\n            part_feats (torch.Tensor): Point-wise part prediction features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Score of class and bbox predictions.\\n        '\n    rcnn_batch_size = part_feats.shape[0]\n    sparse_shape = part_feats.shape[1:4]\n    sparse_idx = part_feats.sum(dim=-1).nonzero(as_tuple=False)\n    part_features = part_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    seg_features = seg_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    coords = sparse_idx.int().contiguous()\n    part_features = SparseConvTensor(part_features, coords, sparse_shape, rcnn_batch_size)\n    seg_features = SparseConvTensor(seg_features, coords, sparse_shape, rcnn_batch_size)\n    x_part = self.part_conv(part_features)\n    x_rpn = self.seg_conv(seg_features)\n    merged_feature = torch.cat((x_rpn.features, x_part.features), dim=1)\n    shared_feature = SparseConvTensor(merged_feature, coords, sparse_shape, rcnn_batch_size)\n    x = self.conv_down(shared_feature)\n    shared_feature = x.dense().view(rcnn_batch_size, -1, 1)\n    shared_feature = self.shared_fc(shared_feature)\n    cls_score = self.conv_cls(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    bbox_pred = self.conv_reg(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    return (cls_score, bbox_pred)",
            "def forward(self, seg_feats, part_feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            seg_feats (torch.Tensor): Point-wise semantic features.\\n            part_feats (torch.Tensor): Point-wise part prediction features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Score of class and bbox predictions.\\n        '\n    rcnn_batch_size = part_feats.shape[0]\n    sparse_shape = part_feats.shape[1:4]\n    sparse_idx = part_feats.sum(dim=-1).nonzero(as_tuple=False)\n    part_features = part_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    seg_features = seg_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    coords = sparse_idx.int().contiguous()\n    part_features = SparseConvTensor(part_features, coords, sparse_shape, rcnn_batch_size)\n    seg_features = SparseConvTensor(seg_features, coords, sparse_shape, rcnn_batch_size)\n    x_part = self.part_conv(part_features)\n    x_rpn = self.seg_conv(seg_features)\n    merged_feature = torch.cat((x_rpn.features, x_part.features), dim=1)\n    shared_feature = SparseConvTensor(merged_feature, coords, sparse_shape, rcnn_batch_size)\n    x = self.conv_down(shared_feature)\n    shared_feature = x.dense().view(rcnn_batch_size, -1, 1)\n    shared_feature = self.shared_fc(shared_feature)\n    cls_score = self.conv_cls(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    bbox_pred = self.conv_reg(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    return (cls_score, bbox_pred)",
            "def forward(self, seg_feats, part_feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            seg_feats (torch.Tensor): Point-wise semantic features.\\n            part_feats (torch.Tensor): Point-wise part prediction features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Score of class and bbox predictions.\\n        '\n    rcnn_batch_size = part_feats.shape[0]\n    sparse_shape = part_feats.shape[1:4]\n    sparse_idx = part_feats.sum(dim=-1).nonzero(as_tuple=False)\n    part_features = part_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    seg_features = seg_feats[sparse_idx[:, 0], sparse_idx[:, 1], sparse_idx[:, 2], sparse_idx[:, 3]]\n    coords = sparse_idx.int().contiguous()\n    part_features = SparseConvTensor(part_features, coords, sparse_shape, rcnn_batch_size)\n    seg_features = SparseConvTensor(seg_features, coords, sparse_shape, rcnn_batch_size)\n    x_part = self.part_conv(part_features)\n    x_rpn = self.seg_conv(seg_features)\n    merged_feature = torch.cat((x_rpn.features, x_part.features), dim=1)\n    shared_feature = SparseConvTensor(merged_feature, coords, sparse_shape, rcnn_batch_size)\n    x = self.conv_down(shared_feature)\n    shared_feature = x.dense().view(rcnn_batch_size, -1, 1)\n    shared_feature = self.shared_fc(shared_feature)\n    cls_score = self.conv_cls(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    bbox_pred = self.conv_reg(shared_feature).transpose(1, 2).contiguous().squeeze(dim=1)\n    return (cls_score, bbox_pred)"
        ]
    },
    {
        "func_name": "loss",
        "original": "def loss(self, cls_score, bbox_pred, rois, labels, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights):\n    \"\"\"Computing losses.\n\n        Args:\n            cls_score (torch.Tensor): Scores of each roi.\n            bbox_pred (torch.Tensor): Predictions of bboxes.\n            rois (torch.Tensor): Roi bboxes.\n            labels (torch.Tensor): Labels of class.\n            bbox_targets (torch.Tensor): Target of positive bboxes.\n            pos_gt_bboxes (torch.Tensor): Ground truths of positive bboxes.\n            reg_mask (torch.Tensor): Mask for positive bboxes.\n            label_weights (torch.Tensor): Weights of class loss.\n            bbox_weights (torch.Tensor): Weights of bbox loss.\n\n        Returns:\n            dict: Computed losses.\n\n                - loss_cls (torch.Tensor): Loss of classes.\n                - loss_bbox (torch.Tensor): Loss of bboxes.\n                - loss_corner (torch.Tensor): Loss of corners.\n        \"\"\"\n    losses = dict()\n    rcnn_batch_size = cls_score.shape[0]\n    cls_flat = cls_score.view(-1)\n    loss_cls = self.loss_cls(cls_flat, labels, label_weights)\n    losses['loss_cls'] = loss_cls\n    code_size = self.bbox_coder.code_size\n    pos_inds = reg_mask > 0\n    if pos_inds.any() == 0:\n        losses['loss_bbox'] = loss_cls.new_tensor(0)\n        if self.with_corner_loss:\n            losses['loss_corner'] = loss_cls.new_tensor(0)\n    else:\n        pos_bbox_pred = bbox_pred.view(rcnn_batch_size, -1)[pos_inds]\n        bbox_weights_flat = bbox_weights[pos_inds].view(-1, 1).repeat(1, pos_bbox_pred.shape[-1])\n        loss_bbox = self.loss_bbox(pos_bbox_pred.unsqueeze(dim=0), bbox_targets.unsqueeze(dim=0), bbox_weights_flat.unsqueeze(dim=0))\n        losses['loss_bbox'] = loss_bbox\n        if self.with_corner_loss:\n            pos_roi_boxes3d = rois[..., 1:].view(-1, code_size)[pos_inds]\n            pos_roi_boxes3d = pos_roi_boxes3d.view(-1, code_size)\n            batch_anchors = pos_roi_boxes3d.clone().detach()\n            pos_rois_rotation = pos_roi_boxes3d[..., 6].view(-1)\n            roi_xyz = pos_roi_boxes3d[..., 0:3].view(-1, 3)\n            batch_anchors[..., 0:3] = 0\n            pred_boxes3d = self.bbox_coder.decode(batch_anchors, pos_bbox_pred.view(-1, code_size)).view(-1, code_size)\n            pred_boxes3d[..., 0:3] = rotation_3d_in_axis(pred_boxes3d[..., 0:3].unsqueeze(1), pos_rois_rotation, axis=2).squeeze(1)\n            pred_boxes3d[:, 0:3] += roi_xyz\n            loss_corner = self.get_corner_loss_lidar(pred_boxes3d, pos_gt_bboxes)\n            losses['loss_corner'] = loss_corner\n    return losses",
        "mutated": [
            "def loss(self, cls_score, bbox_pred, rois, labels, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights):\n    if False:\n        i = 10\n    'Computing losses.\\n\\n        Args:\\n            cls_score (torch.Tensor): Scores of each roi.\\n            bbox_pred (torch.Tensor): Predictions of bboxes.\\n            rois (torch.Tensor): Roi bboxes.\\n            labels (torch.Tensor): Labels of class.\\n            bbox_targets (torch.Tensor): Target of positive bboxes.\\n            pos_gt_bboxes (torch.Tensor): Ground truths of positive bboxes.\\n            reg_mask (torch.Tensor): Mask for positive bboxes.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n\\n        Returns:\\n            dict: Computed losses.\\n\\n                - loss_cls (torch.Tensor): Loss of classes.\\n                - loss_bbox (torch.Tensor): Loss of bboxes.\\n                - loss_corner (torch.Tensor): Loss of corners.\\n        '\n    losses = dict()\n    rcnn_batch_size = cls_score.shape[0]\n    cls_flat = cls_score.view(-1)\n    loss_cls = self.loss_cls(cls_flat, labels, label_weights)\n    losses['loss_cls'] = loss_cls\n    code_size = self.bbox_coder.code_size\n    pos_inds = reg_mask > 0\n    if pos_inds.any() == 0:\n        losses['loss_bbox'] = loss_cls.new_tensor(0)\n        if self.with_corner_loss:\n            losses['loss_corner'] = loss_cls.new_tensor(0)\n    else:\n        pos_bbox_pred = bbox_pred.view(rcnn_batch_size, -1)[pos_inds]\n        bbox_weights_flat = bbox_weights[pos_inds].view(-1, 1).repeat(1, pos_bbox_pred.shape[-1])\n        loss_bbox = self.loss_bbox(pos_bbox_pred.unsqueeze(dim=0), bbox_targets.unsqueeze(dim=0), bbox_weights_flat.unsqueeze(dim=0))\n        losses['loss_bbox'] = loss_bbox\n        if self.with_corner_loss:\n            pos_roi_boxes3d = rois[..., 1:].view(-1, code_size)[pos_inds]\n            pos_roi_boxes3d = pos_roi_boxes3d.view(-1, code_size)\n            batch_anchors = pos_roi_boxes3d.clone().detach()\n            pos_rois_rotation = pos_roi_boxes3d[..., 6].view(-1)\n            roi_xyz = pos_roi_boxes3d[..., 0:3].view(-1, 3)\n            batch_anchors[..., 0:3] = 0\n            pred_boxes3d = self.bbox_coder.decode(batch_anchors, pos_bbox_pred.view(-1, code_size)).view(-1, code_size)\n            pred_boxes3d[..., 0:3] = rotation_3d_in_axis(pred_boxes3d[..., 0:3].unsqueeze(1), pos_rois_rotation, axis=2).squeeze(1)\n            pred_boxes3d[:, 0:3] += roi_xyz\n            loss_corner = self.get_corner_loss_lidar(pred_boxes3d, pos_gt_bboxes)\n            losses['loss_corner'] = loss_corner\n    return losses",
            "def loss(self, cls_score, bbox_pred, rois, labels, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Computing losses.\\n\\n        Args:\\n            cls_score (torch.Tensor): Scores of each roi.\\n            bbox_pred (torch.Tensor): Predictions of bboxes.\\n            rois (torch.Tensor): Roi bboxes.\\n            labels (torch.Tensor): Labels of class.\\n            bbox_targets (torch.Tensor): Target of positive bboxes.\\n            pos_gt_bboxes (torch.Tensor): Ground truths of positive bboxes.\\n            reg_mask (torch.Tensor): Mask for positive bboxes.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n\\n        Returns:\\n            dict: Computed losses.\\n\\n                - loss_cls (torch.Tensor): Loss of classes.\\n                - loss_bbox (torch.Tensor): Loss of bboxes.\\n                - loss_corner (torch.Tensor): Loss of corners.\\n        '\n    losses = dict()\n    rcnn_batch_size = cls_score.shape[0]\n    cls_flat = cls_score.view(-1)\n    loss_cls = self.loss_cls(cls_flat, labels, label_weights)\n    losses['loss_cls'] = loss_cls\n    code_size = self.bbox_coder.code_size\n    pos_inds = reg_mask > 0\n    if pos_inds.any() == 0:\n        losses['loss_bbox'] = loss_cls.new_tensor(0)\n        if self.with_corner_loss:\n            losses['loss_corner'] = loss_cls.new_tensor(0)\n    else:\n        pos_bbox_pred = bbox_pred.view(rcnn_batch_size, -1)[pos_inds]\n        bbox_weights_flat = bbox_weights[pos_inds].view(-1, 1).repeat(1, pos_bbox_pred.shape[-1])\n        loss_bbox = self.loss_bbox(pos_bbox_pred.unsqueeze(dim=0), bbox_targets.unsqueeze(dim=0), bbox_weights_flat.unsqueeze(dim=0))\n        losses['loss_bbox'] = loss_bbox\n        if self.with_corner_loss:\n            pos_roi_boxes3d = rois[..., 1:].view(-1, code_size)[pos_inds]\n            pos_roi_boxes3d = pos_roi_boxes3d.view(-1, code_size)\n            batch_anchors = pos_roi_boxes3d.clone().detach()\n            pos_rois_rotation = pos_roi_boxes3d[..., 6].view(-1)\n            roi_xyz = pos_roi_boxes3d[..., 0:3].view(-1, 3)\n            batch_anchors[..., 0:3] = 0\n            pred_boxes3d = self.bbox_coder.decode(batch_anchors, pos_bbox_pred.view(-1, code_size)).view(-1, code_size)\n            pred_boxes3d[..., 0:3] = rotation_3d_in_axis(pred_boxes3d[..., 0:3].unsqueeze(1), pos_rois_rotation, axis=2).squeeze(1)\n            pred_boxes3d[:, 0:3] += roi_xyz\n            loss_corner = self.get_corner_loss_lidar(pred_boxes3d, pos_gt_bboxes)\n            losses['loss_corner'] = loss_corner\n    return losses",
            "def loss(self, cls_score, bbox_pred, rois, labels, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Computing losses.\\n\\n        Args:\\n            cls_score (torch.Tensor): Scores of each roi.\\n            bbox_pred (torch.Tensor): Predictions of bboxes.\\n            rois (torch.Tensor): Roi bboxes.\\n            labels (torch.Tensor): Labels of class.\\n            bbox_targets (torch.Tensor): Target of positive bboxes.\\n            pos_gt_bboxes (torch.Tensor): Ground truths of positive bboxes.\\n            reg_mask (torch.Tensor): Mask for positive bboxes.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n\\n        Returns:\\n            dict: Computed losses.\\n\\n                - loss_cls (torch.Tensor): Loss of classes.\\n                - loss_bbox (torch.Tensor): Loss of bboxes.\\n                - loss_corner (torch.Tensor): Loss of corners.\\n        '\n    losses = dict()\n    rcnn_batch_size = cls_score.shape[0]\n    cls_flat = cls_score.view(-1)\n    loss_cls = self.loss_cls(cls_flat, labels, label_weights)\n    losses['loss_cls'] = loss_cls\n    code_size = self.bbox_coder.code_size\n    pos_inds = reg_mask > 0\n    if pos_inds.any() == 0:\n        losses['loss_bbox'] = loss_cls.new_tensor(0)\n        if self.with_corner_loss:\n            losses['loss_corner'] = loss_cls.new_tensor(0)\n    else:\n        pos_bbox_pred = bbox_pred.view(rcnn_batch_size, -1)[pos_inds]\n        bbox_weights_flat = bbox_weights[pos_inds].view(-1, 1).repeat(1, pos_bbox_pred.shape[-1])\n        loss_bbox = self.loss_bbox(pos_bbox_pred.unsqueeze(dim=0), bbox_targets.unsqueeze(dim=0), bbox_weights_flat.unsqueeze(dim=0))\n        losses['loss_bbox'] = loss_bbox\n        if self.with_corner_loss:\n            pos_roi_boxes3d = rois[..., 1:].view(-1, code_size)[pos_inds]\n            pos_roi_boxes3d = pos_roi_boxes3d.view(-1, code_size)\n            batch_anchors = pos_roi_boxes3d.clone().detach()\n            pos_rois_rotation = pos_roi_boxes3d[..., 6].view(-1)\n            roi_xyz = pos_roi_boxes3d[..., 0:3].view(-1, 3)\n            batch_anchors[..., 0:3] = 0\n            pred_boxes3d = self.bbox_coder.decode(batch_anchors, pos_bbox_pred.view(-1, code_size)).view(-1, code_size)\n            pred_boxes3d[..., 0:3] = rotation_3d_in_axis(pred_boxes3d[..., 0:3].unsqueeze(1), pos_rois_rotation, axis=2).squeeze(1)\n            pred_boxes3d[:, 0:3] += roi_xyz\n            loss_corner = self.get_corner_loss_lidar(pred_boxes3d, pos_gt_bboxes)\n            losses['loss_corner'] = loss_corner\n    return losses",
            "def loss(self, cls_score, bbox_pred, rois, labels, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Computing losses.\\n\\n        Args:\\n            cls_score (torch.Tensor): Scores of each roi.\\n            bbox_pred (torch.Tensor): Predictions of bboxes.\\n            rois (torch.Tensor): Roi bboxes.\\n            labels (torch.Tensor): Labels of class.\\n            bbox_targets (torch.Tensor): Target of positive bboxes.\\n            pos_gt_bboxes (torch.Tensor): Ground truths of positive bboxes.\\n            reg_mask (torch.Tensor): Mask for positive bboxes.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n\\n        Returns:\\n            dict: Computed losses.\\n\\n                - loss_cls (torch.Tensor): Loss of classes.\\n                - loss_bbox (torch.Tensor): Loss of bboxes.\\n                - loss_corner (torch.Tensor): Loss of corners.\\n        '\n    losses = dict()\n    rcnn_batch_size = cls_score.shape[0]\n    cls_flat = cls_score.view(-1)\n    loss_cls = self.loss_cls(cls_flat, labels, label_weights)\n    losses['loss_cls'] = loss_cls\n    code_size = self.bbox_coder.code_size\n    pos_inds = reg_mask > 0\n    if pos_inds.any() == 0:\n        losses['loss_bbox'] = loss_cls.new_tensor(0)\n        if self.with_corner_loss:\n            losses['loss_corner'] = loss_cls.new_tensor(0)\n    else:\n        pos_bbox_pred = bbox_pred.view(rcnn_batch_size, -1)[pos_inds]\n        bbox_weights_flat = bbox_weights[pos_inds].view(-1, 1).repeat(1, pos_bbox_pred.shape[-1])\n        loss_bbox = self.loss_bbox(pos_bbox_pred.unsqueeze(dim=0), bbox_targets.unsqueeze(dim=0), bbox_weights_flat.unsqueeze(dim=0))\n        losses['loss_bbox'] = loss_bbox\n        if self.with_corner_loss:\n            pos_roi_boxes3d = rois[..., 1:].view(-1, code_size)[pos_inds]\n            pos_roi_boxes3d = pos_roi_boxes3d.view(-1, code_size)\n            batch_anchors = pos_roi_boxes3d.clone().detach()\n            pos_rois_rotation = pos_roi_boxes3d[..., 6].view(-1)\n            roi_xyz = pos_roi_boxes3d[..., 0:3].view(-1, 3)\n            batch_anchors[..., 0:3] = 0\n            pred_boxes3d = self.bbox_coder.decode(batch_anchors, pos_bbox_pred.view(-1, code_size)).view(-1, code_size)\n            pred_boxes3d[..., 0:3] = rotation_3d_in_axis(pred_boxes3d[..., 0:3].unsqueeze(1), pos_rois_rotation, axis=2).squeeze(1)\n            pred_boxes3d[:, 0:3] += roi_xyz\n            loss_corner = self.get_corner_loss_lidar(pred_boxes3d, pos_gt_bboxes)\n            losses['loss_corner'] = loss_corner\n    return losses",
            "def loss(self, cls_score, bbox_pred, rois, labels, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Computing losses.\\n\\n        Args:\\n            cls_score (torch.Tensor): Scores of each roi.\\n            bbox_pred (torch.Tensor): Predictions of bboxes.\\n            rois (torch.Tensor): Roi bboxes.\\n            labels (torch.Tensor): Labels of class.\\n            bbox_targets (torch.Tensor): Target of positive bboxes.\\n            pos_gt_bboxes (torch.Tensor): Ground truths of positive bboxes.\\n            reg_mask (torch.Tensor): Mask for positive bboxes.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n\\n        Returns:\\n            dict: Computed losses.\\n\\n                - loss_cls (torch.Tensor): Loss of classes.\\n                - loss_bbox (torch.Tensor): Loss of bboxes.\\n                - loss_corner (torch.Tensor): Loss of corners.\\n        '\n    losses = dict()\n    rcnn_batch_size = cls_score.shape[0]\n    cls_flat = cls_score.view(-1)\n    loss_cls = self.loss_cls(cls_flat, labels, label_weights)\n    losses['loss_cls'] = loss_cls\n    code_size = self.bbox_coder.code_size\n    pos_inds = reg_mask > 0\n    if pos_inds.any() == 0:\n        losses['loss_bbox'] = loss_cls.new_tensor(0)\n        if self.with_corner_loss:\n            losses['loss_corner'] = loss_cls.new_tensor(0)\n    else:\n        pos_bbox_pred = bbox_pred.view(rcnn_batch_size, -1)[pos_inds]\n        bbox_weights_flat = bbox_weights[pos_inds].view(-1, 1).repeat(1, pos_bbox_pred.shape[-1])\n        loss_bbox = self.loss_bbox(pos_bbox_pred.unsqueeze(dim=0), bbox_targets.unsqueeze(dim=0), bbox_weights_flat.unsqueeze(dim=0))\n        losses['loss_bbox'] = loss_bbox\n        if self.with_corner_loss:\n            pos_roi_boxes3d = rois[..., 1:].view(-1, code_size)[pos_inds]\n            pos_roi_boxes3d = pos_roi_boxes3d.view(-1, code_size)\n            batch_anchors = pos_roi_boxes3d.clone().detach()\n            pos_rois_rotation = pos_roi_boxes3d[..., 6].view(-1)\n            roi_xyz = pos_roi_boxes3d[..., 0:3].view(-1, 3)\n            batch_anchors[..., 0:3] = 0\n            pred_boxes3d = self.bbox_coder.decode(batch_anchors, pos_bbox_pred.view(-1, code_size)).view(-1, code_size)\n            pred_boxes3d[..., 0:3] = rotation_3d_in_axis(pred_boxes3d[..., 0:3].unsqueeze(1), pos_rois_rotation, axis=2).squeeze(1)\n            pred_boxes3d[:, 0:3] += roi_xyz\n            loss_corner = self.get_corner_loss_lidar(pred_boxes3d, pos_gt_bboxes)\n            losses['loss_corner'] = loss_corner\n    return losses"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, sampling_results, rcnn_train_cfg, concat=True):\n    \"\"\"Generate targets.\n\n        Args:\n            sampling_results (list[:obj:`SamplingResult`]):\n                Sampled results from rois.\n            rcnn_train_cfg (:obj:`ConfigDict`): Training config of rcnn.\n            concat (bool): Whether to concatenate targets between batches.\n\n        Returns:\n            tuple[torch.Tensor]: Targets of boxes and class prediction.\n        \"\"\"\n    pos_bboxes_list = [res.pos_bboxes for res in sampling_results]\n    pos_gt_bboxes_list = [res.pos_gt_bboxes for res in sampling_results]\n    iou_list = [res.iou for res in sampling_results]\n    targets = multi_apply(self._get_target_single, pos_bboxes_list, pos_gt_bboxes_list, iou_list, cfg=rcnn_train_cfg)\n    (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights) = targets\n    if concat:\n        label = torch.cat(label, 0)\n        bbox_targets = torch.cat(bbox_targets, 0)\n        pos_gt_bboxes = torch.cat(pos_gt_bboxes, 0)\n        reg_mask = torch.cat(reg_mask, 0)\n        label_weights = torch.cat(label_weights, 0)\n        label_weights /= torch.clamp(label_weights.sum(), min=1.0)\n        bbox_weights = torch.cat(bbox_weights, 0)\n        bbox_weights /= torch.clamp(bbox_weights.sum(), min=1.0)\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
        "mutated": [
            "def get_targets(self, sampling_results, rcnn_train_cfg, concat=True):\n    if False:\n        i = 10\n    'Generate targets.\\n\\n        Args:\\n            sampling_results (list[:obj:`SamplingResult`]):\\n                Sampled results from rois.\\n            rcnn_train_cfg (:obj:`ConfigDict`): Training config of rcnn.\\n            concat (bool): Whether to concatenate targets between batches.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of boxes and class prediction.\\n        '\n    pos_bboxes_list = [res.pos_bboxes for res in sampling_results]\n    pos_gt_bboxes_list = [res.pos_gt_bboxes for res in sampling_results]\n    iou_list = [res.iou for res in sampling_results]\n    targets = multi_apply(self._get_target_single, pos_bboxes_list, pos_gt_bboxes_list, iou_list, cfg=rcnn_train_cfg)\n    (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights) = targets\n    if concat:\n        label = torch.cat(label, 0)\n        bbox_targets = torch.cat(bbox_targets, 0)\n        pos_gt_bboxes = torch.cat(pos_gt_bboxes, 0)\n        reg_mask = torch.cat(reg_mask, 0)\n        label_weights = torch.cat(label_weights, 0)\n        label_weights /= torch.clamp(label_weights.sum(), min=1.0)\n        bbox_weights = torch.cat(bbox_weights, 0)\n        bbox_weights /= torch.clamp(bbox_weights.sum(), min=1.0)\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def get_targets(self, sampling_results, rcnn_train_cfg, concat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets.\\n\\n        Args:\\n            sampling_results (list[:obj:`SamplingResult`]):\\n                Sampled results from rois.\\n            rcnn_train_cfg (:obj:`ConfigDict`): Training config of rcnn.\\n            concat (bool): Whether to concatenate targets between batches.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of boxes and class prediction.\\n        '\n    pos_bboxes_list = [res.pos_bboxes for res in sampling_results]\n    pos_gt_bboxes_list = [res.pos_gt_bboxes for res in sampling_results]\n    iou_list = [res.iou for res in sampling_results]\n    targets = multi_apply(self._get_target_single, pos_bboxes_list, pos_gt_bboxes_list, iou_list, cfg=rcnn_train_cfg)\n    (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights) = targets\n    if concat:\n        label = torch.cat(label, 0)\n        bbox_targets = torch.cat(bbox_targets, 0)\n        pos_gt_bboxes = torch.cat(pos_gt_bboxes, 0)\n        reg_mask = torch.cat(reg_mask, 0)\n        label_weights = torch.cat(label_weights, 0)\n        label_weights /= torch.clamp(label_weights.sum(), min=1.0)\n        bbox_weights = torch.cat(bbox_weights, 0)\n        bbox_weights /= torch.clamp(bbox_weights.sum(), min=1.0)\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def get_targets(self, sampling_results, rcnn_train_cfg, concat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets.\\n\\n        Args:\\n            sampling_results (list[:obj:`SamplingResult`]):\\n                Sampled results from rois.\\n            rcnn_train_cfg (:obj:`ConfigDict`): Training config of rcnn.\\n            concat (bool): Whether to concatenate targets between batches.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of boxes and class prediction.\\n        '\n    pos_bboxes_list = [res.pos_bboxes for res in sampling_results]\n    pos_gt_bboxes_list = [res.pos_gt_bboxes for res in sampling_results]\n    iou_list = [res.iou for res in sampling_results]\n    targets = multi_apply(self._get_target_single, pos_bboxes_list, pos_gt_bboxes_list, iou_list, cfg=rcnn_train_cfg)\n    (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights) = targets\n    if concat:\n        label = torch.cat(label, 0)\n        bbox_targets = torch.cat(bbox_targets, 0)\n        pos_gt_bboxes = torch.cat(pos_gt_bboxes, 0)\n        reg_mask = torch.cat(reg_mask, 0)\n        label_weights = torch.cat(label_weights, 0)\n        label_weights /= torch.clamp(label_weights.sum(), min=1.0)\n        bbox_weights = torch.cat(bbox_weights, 0)\n        bbox_weights /= torch.clamp(bbox_weights.sum(), min=1.0)\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def get_targets(self, sampling_results, rcnn_train_cfg, concat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets.\\n\\n        Args:\\n            sampling_results (list[:obj:`SamplingResult`]):\\n                Sampled results from rois.\\n            rcnn_train_cfg (:obj:`ConfigDict`): Training config of rcnn.\\n            concat (bool): Whether to concatenate targets between batches.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of boxes and class prediction.\\n        '\n    pos_bboxes_list = [res.pos_bboxes for res in sampling_results]\n    pos_gt_bboxes_list = [res.pos_gt_bboxes for res in sampling_results]\n    iou_list = [res.iou for res in sampling_results]\n    targets = multi_apply(self._get_target_single, pos_bboxes_list, pos_gt_bboxes_list, iou_list, cfg=rcnn_train_cfg)\n    (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights) = targets\n    if concat:\n        label = torch.cat(label, 0)\n        bbox_targets = torch.cat(bbox_targets, 0)\n        pos_gt_bboxes = torch.cat(pos_gt_bboxes, 0)\n        reg_mask = torch.cat(reg_mask, 0)\n        label_weights = torch.cat(label_weights, 0)\n        label_weights /= torch.clamp(label_weights.sum(), min=1.0)\n        bbox_weights = torch.cat(bbox_weights, 0)\n        bbox_weights /= torch.clamp(bbox_weights.sum(), min=1.0)\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def get_targets(self, sampling_results, rcnn_train_cfg, concat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets.\\n\\n        Args:\\n            sampling_results (list[:obj:`SamplingResult`]):\\n                Sampled results from rois.\\n            rcnn_train_cfg (:obj:`ConfigDict`): Training config of rcnn.\\n            concat (bool): Whether to concatenate targets between batches.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of boxes and class prediction.\\n        '\n    pos_bboxes_list = [res.pos_bboxes for res in sampling_results]\n    pos_gt_bboxes_list = [res.pos_gt_bboxes for res in sampling_results]\n    iou_list = [res.iou for res in sampling_results]\n    targets = multi_apply(self._get_target_single, pos_bboxes_list, pos_gt_bboxes_list, iou_list, cfg=rcnn_train_cfg)\n    (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights) = targets\n    if concat:\n        label = torch.cat(label, 0)\n        bbox_targets = torch.cat(bbox_targets, 0)\n        pos_gt_bboxes = torch.cat(pos_gt_bboxes, 0)\n        reg_mask = torch.cat(reg_mask, 0)\n        label_weights = torch.cat(label_weights, 0)\n        label_weights /= torch.clamp(label_weights.sum(), min=1.0)\n        bbox_weights = torch.cat(bbox_weights, 0)\n        bbox_weights /= torch.clamp(bbox_weights.sum(), min=1.0)\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)"
        ]
    },
    {
        "func_name": "_get_target_single",
        "original": "def _get_target_single(self, pos_bboxes, pos_gt_bboxes, ious, cfg):\n    \"\"\"Generate training targets for a single sample.\n\n        Args:\n            pos_bboxes (torch.Tensor): Positive boxes with shape\n                (N, 7).\n            pos_gt_bboxes (torch.Tensor): Ground truth boxes with shape\n                (M, 7).\n            ious (torch.Tensor): IoU between `pos_bboxes` and `pos_gt_bboxes`\n                in shape (N, M).\n            cfg (dict): Training configs.\n\n        Returns:\n            tuple[torch.Tensor]: Target for positive boxes.\n                (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights,\n                bbox_weights)\n        \"\"\"\n    cls_pos_mask = ious > cfg.cls_pos_thr\n    cls_neg_mask = ious < cfg.cls_neg_thr\n    interval_mask = (cls_pos_mask == 0) & (cls_neg_mask == 0)\n    label = (cls_pos_mask > 0).float()\n    label[interval_mask] = ious[interval_mask] * 2 - 0.5\n    label_weights = (label >= 0).float()\n    reg_mask = pos_bboxes.new_zeros(ious.size(0)).long()\n    reg_mask[0:pos_gt_bboxes.size(0)] = 1\n    bbox_weights = (reg_mask > 0).float()\n    if reg_mask.bool().any():\n        pos_gt_bboxes_ct = pos_gt_bboxes.clone().detach()\n        roi_center = pos_bboxes[..., 0:3]\n        roi_ry = pos_bboxes[..., 6] % (2 * np.pi)\n        pos_gt_bboxes_ct[..., 0:3] -= roi_center\n        pos_gt_bboxes_ct[..., 6] -= roi_ry\n        pos_gt_bboxes_ct[..., 0:3] = rotation_3d_in_axis(pos_gt_bboxes_ct[..., 0:3].unsqueeze(1), -roi_ry, axis=2).squeeze(1)\n        ry_label = pos_gt_bboxes_ct[..., 6] % (2 * np.pi)\n        opposite_flag = (ry_label > np.pi * 0.5) & (ry_label < np.pi * 1.5)\n        ry_label[opposite_flag] = (ry_label[opposite_flag] + np.pi) % (2 * np.pi)\n        flag = ry_label > np.pi\n        ry_label[flag] = ry_label[flag] - np.pi * 2\n        ry_label = torch.clamp(ry_label, min=-np.pi / 2, max=np.pi / 2)\n        pos_gt_bboxes_ct[..., 6] = ry_label\n        rois_anchor = pos_bboxes.clone().detach()\n        rois_anchor[:, 0:3] = 0\n        rois_anchor[:, 6] = 0\n        bbox_targets = self.bbox_coder.encode(rois_anchor, pos_gt_bboxes_ct)\n    else:\n        bbox_targets = pos_gt_bboxes.new_empty((0, 7))\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
        "mutated": [
            "def _get_target_single(self, pos_bboxes, pos_gt_bboxes, ious, cfg):\n    if False:\n        i = 10\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            pos_bboxes (torch.Tensor): Positive boxes with shape\\n                (N, 7).\\n            pos_gt_bboxes (torch.Tensor): Ground truth boxes with shape\\n                (M, 7).\\n            ious (torch.Tensor): IoU between `pos_bboxes` and `pos_gt_bboxes`\\n                in shape (N, M).\\n            cfg (dict): Training configs.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Target for positive boxes.\\n                (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights,\\n                bbox_weights)\\n        '\n    cls_pos_mask = ious > cfg.cls_pos_thr\n    cls_neg_mask = ious < cfg.cls_neg_thr\n    interval_mask = (cls_pos_mask == 0) & (cls_neg_mask == 0)\n    label = (cls_pos_mask > 0).float()\n    label[interval_mask] = ious[interval_mask] * 2 - 0.5\n    label_weights = (label >= 0).float()\n    reg_mask = pos_bboxes.new_zeros(ious.size(0)).long()\n    reg_mask[0:pos_gt_bboxes.size(0)] = 1\n    bbox_weights = (reg_mask > 0).float()\n    if reg_mask.bool().any():\n        pos_gt_bboxes_ct = pos_gt_bboxes.clone().detach()\n        roi_center = pos_bboxes[..., 0:3]\n        roi_ry = pos_bboxes[..., 6] % (2 * np.pi)\n        pos_gt_bboxes_ct[..., 0:3] -= roi_center\n        pos_gt_bboxes_ct[..., 6] -= roi_ry\n        pos_gt_bboxes_ct[..., 0:3] = rotation_3d_in_axis(pos_gt_bboxes_ct[..., 0:3].unsqueeze(1), -roi_ry, axis=2).squeeze(1)\n        ry_label = pos_gt_bboxes_ct[..., 6] % (2 * np.pi)\n        opposite_flag = (ry_label > np.pi * 0.5) & (ry_label < np.pi * 1.5)\n        ry_label[opposite_flag] = (ry_label[opposite_flag] + np.pi) % (2 * np.pi)\n        flag = ry_label > np.pi\n        ry_label[flag] = ry_label[flag] - np.pi * 2\n        ry_label = torch.clamp(ry_label, min=-np.pi / 2, max=np.pi / 2)\n        pos_gt_bboxes_ct[..., 6] = ry_label\n        rois_anchor = pos_bboxes.clone().detach()\n        rois_anchor[:, 0:3] = 0\n        rois_anchor[:, 6] = 0\n        bbox_targets = self.bbox_coder.encode(rois_anchor, pos_gt_bboxes_ct)\n    else:\n        bbox_targets = pos_gt_bboxes.new_empty((0, 7))\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def _get_target_single(self, pos_bboxes, pos_gt_bboxes, ious, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            pos_bboxes (torch.Tensor): Positive boxes with shape\\n                (N, 7).\\n            pos_gt_bboxes (torch.Tensor): Ground truth boxes with shape\\n                (M, 7).\\n            ious (torch.Tensor): IoU between `pos_bboxes` and `pos_gt_bboxes`\\n                in shape (N, M).\\n            cfg (dict): Training configs.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Target for positive boxes.\\n                (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights,\\n                bbox_weights)\\n        '\n    cls_pos_mask = ious > cfg.cls_pos_thr\n    cls_neg_mask = ious < cfg.cls_neg_thr\n    interval_mask = (cls_pos_mask == 0) & (cls_neg_mask == 0)\n    label = (cls_pos_mask > 0).float()\n    label[interval_mask] = ious[interval_mask] * 2 - 0.5\n    label_weights = (label >= 0).float()\n    reg_mask = pos_bboxes.new_zeros(ious.size(0)).long()\n    reg_mask[0:pos_gt_bboxes.size(0)] = 1\n    bbox_weights = (reg_mask > 0).float()\n    if reg_mask.bool().any():\n        pos_gt_bboxes_ct = pos_gt_bboxes.clone().detach()\n        roi_center = pos_bboxes[..., 0:3]\n        roi_ry = pos_bboxes[..., 6] % (2 * np.pi)\n        pos_gt_bboxes_ct[..., 0:3] -= roi_center\n        pos_gt_bboxes_ct[..., 6] -= roi_ry\n        pos_gt_bboxes_ct[..., 0:3] = rotation_3d_in_axis(pos_gt_bboxes_ct[..., 0:3].unsqueeze(1), -roi_ry, axis=2).squeeze(1)\n        ry_label = pos_gt_bboxes_ct[..., 6] % (2 * np.pi)\n        opposite_flag = (ry_label > np.pi * 0.5) & (ry_label < np.pi * 1.5)\n        ry_label[opposite_flag] = (ry_label[opposite_flag] + np.pi) % (2 * np.pi)\n        flag = ry_label > np.pi\n        ry_label[flag] = ry_label[flag] - np.pi * 2\n        ry_label = torch.clamp(ry_label, min=-np.pi / 2, max=np.pi / 2)\n        pos_gt_bboxes_ct[..., 6] = ry_label\n        rois_anchor = pos_bboxes.clone().detach()\n        rois_anchor[:, 0:3] = 0\n        rois_anchor[:, 6] = 0\n        bbox_targets = self.bbox_coder.encode(rois_anchor, pos_gt_bboxes_ct)\n    else:\n        bbox_targets = pos_gt_bboxes.new_empty((0, 7))\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def _get_target_single(self, pos_bboxes, pos_gt_bboxes, ious, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            pos_bboxes (torch.Tensor): Positive boxes with shape\\n                (N, 7).\\n            pos_gt_bboxes (torch.Tensor): Ground truth boxes with shape\\n                (M, 7).\\n            ious (torch.Tensor): IoU between `pos_bboxes` and `pos_gt_bboxes`\\n                in shape (N, M).\\n            cfg (dict): Training configs.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Target for positive boxes.\\n                (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights,\\n                bbox_weights)\\n        '\n    cls_pos_mask = ious > cfg.cls_pos_thr\n    cls_neg_mask = ious < cfg.cls_neg_thr\n    interval_mask = (cls_pos_mask == 0) & (cls_neg_mask == 0)\n    label = (cls_pos_mask > 0).float()\n    label[interval_mask] = ious[interval_mask] * 2 - 0.5\n    label_weights = (label >= 0).float()\n    reg_mask = pos_bboxes.new_zeros(ious.size(0)).long()\n    reg_mask[0:pos_gt_bboxes.size(0)] = 1\n    bbox_weights = (reg_mask > 0).float()\n    if reg_mask.bool().any():\n        pos_gt_bboxes_ct = pos_gt_bboxes.clone().detach()\n        roi_center = pos_bboxes[..., 0:3]\n        roi_ry = pos_bboxes[..., 6] % (2 * np.pi)\n        pos_gt_bboxes_ct[..., 0:3] -= roi_center\n        pos_gt_bboxes_ct[..., 6] -= roi_ry\n        pos_gt_bboxes_ct[..., 0:3] = rotation_3d_in_axis(pos_gt_bboxes_ct[..., 0:3].unsqueeze(1), -roi_ry, axis=2).squeeze(1)\n        ry_label = pos_gt_bboxes_ct[..., 6] % (2 * np.pi)\n        opposite_flag = (ry_label > np.pi * 0.5) & (ry_label < np.pi * 1.5)\n        ry_label[opposite_flag] = (ry_label[opposite_flag] + np.pi) % (2 * np.pi)\n        flag = ry_label > np.pi\n        ry_label[flag] = ry_label[flag] - np.pi * 2\n        ry_label = torch.clamp(ry_label, min=-np.pi / 2, max=np.pi / 2)\n        pos_gt_bboxes_ct[..., 6] = ry_label\n        rois_anchor = pos_bboxes.clone().detach()\n        rois_anchor[:, 0:3] = 0\n        rois_anchor[:, 6] = 0\n        bbox_targets = self.bbox_coder.encode(rois_anchor, pos_gt_bboxes_ct)\n    else:\n        bbox_targets = pos_gt_bboxes.new_empty((0, 7))\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def _get_target_single(self, pos_bboxes, pos_gt_bboxes, ious, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            pos_bboxes (torch.Tensor): Positive boxes with shape\\n                (N, 7).\\n            pos_gt_bboxes (torch.Tensor): Ground truth boxes with shape\\n                (M, 7).\\n            ious (torch.Tensor): IoU between `pos_bboxes` and `pos_gt_bboxes`\\n                in shape (N, M).\\n            cfg (dict): Training configs.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Target for positive boxes.\\n                (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights,\\n                bbox_weights)\\n        '\n    cls_pos_mask = ious > cfg.cls_pos_thr\n    cls_neg_mask = ious < cfg.cls_neg_thr\n    interval_mask = (cls_pos_mask == 0) & (cls_neg_mask == 0)\n    label = (cls_pos_mask > 0).float()\n    label[interval_mask] = ious[interval_mask] * 2 - 0.5\n    label_weights = (label >= 0).float()\n    reg_mask = pos_bboxes.new_zeros(ious.size(0)).long()\n    reg_mask[0:pos_gt_bboxes.size(0)] = 1\n    bbox_weights = (reg_mask > 0).float()\n    if reg_mask.bool().any():\n        pos_gt_bboxes_ct = pos_gt_bboxes.clone().detach()\n        roi_center = pos_bboxes[..., 0:3]\n        roi_ry = pos_bboxes[..., 6] % (2 * np.pi)\n        pos_gt_bboxes_ct[..., 0:3] -= roi_center\n        pos_gt_bboxes_ct[..., 6] -= roi_ry\n        pos_gt_bboxes_ct[..., 0:3] = rotation_3d_in_axis(pos_gt_bboxes_ct[..., 0:3].unsqueeze(1), -roi_ry, axis=2).squeeze(1)\n        ry_label = pos_gt_bboxes_ct[..., 6] % (2 * np.pi)\n        opposite_flag = (ry_label > np.pi * 0.5) & (ry_label < np.pi * 1.5)\n        ry_label[opposite_flag] = (ry_label[opposite_flag] + np.pi) % (2 * np.pi)\n        flag = ry_label > np.pi\n        ry_label[flag] = ry_label[flag] - np.pi * 2\n        ry_label = torch.clamp(ry_label, min=-np.pi / 2, max=np.pi / 2)\n        pos_gt_bboxes_ct[..., 6] = ry_label\n        rois_anchor = pos_bboxes.clone().detach()\n        rois_anchor[:, 0:3] = 0\n        rois_anchor[:, 6] = 0\n        bbox_targets = self.bbox_coder.encode(rois_anchor, pos_gt_bboxes_ct)\n    else:\n        bbox_targets = pos_gt_bboxes.new_empty((0, 7))\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)",
            "def _get_target_single(self, pos_bboxes, pos_gt_bboxes, ious, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate training targets for a single sample.\\n\\n        Args:\\n            pos_bboxes (torch.Tensor): Positive boxes with shape\\n                (N, 7).\\n            pos_gt_bboxes (torch.Tensor): Ground truth boxes with shape\\n                (M, 7).\\n            ious (torch.Tensor): IoU between `pos_bboxes` and `pos_gt_bboxes`\\n                in shape (N, M).\\n            cfg (dict): Training configs.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Target for positive boxes.\\n                (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights,\\n                bbox_weights)\\n        '\n    cls_pos_mask = ious > cfg.cls_pos_thr\n    cls_neg_mask = ious < cfg.cls_neg_thr\n    interval_mask = (cls_pos_mask == 0) & (cls_neg_mask == 0)\n    label = (cls_pos_mask > 0).float()\n    label[interval_mask] = ious[interval_mask] * 2 - 0.5\n    label_weights = (label >= 0).float()\n    reg_mask = pos_bboxes.new_zeros(ious.size(0)).long()\n    reg_mask[0:pos_gt_bboxes.size(0)] = 1\n    bbox_weights = (reg_mask > 0).float()\n    if reg_mask.bool().any():\n        pos_gt_bboxes_ct = pos_gt_bboxes.clone().detach()\n        roi_center = pos_bboxes[..., 0:3]\n        roi_ry = pos_bboxes[..., 6] % (2 * np.pi)\n        pos_gt_bboxes_ct[..., 0:3] -= roi_center\n        pos_gt_bboxes_ct[..., 6] -= roi_ry\n        pos_gt_bboxes_ct[..., 0:3] = rotation_3d_in_axis(pos_gt_bboxes_ct[..., 0:3].unsqueeze(1), -roi_ry, axis=2).squeeze(1)\n        ry_label = pos_gt_bboxes_ct[..., 6] % (2 * np.pi)\n        opposite_flag = (ry_label > np.pi * 0.5) & (ry_label < np.pi * 1.5)\n        ry_label[opposite_flag] = (ry_label[opposite_flag] + np.pi) % (2 * np.pi)\n        flag = ry_label > np.pi\n        ry_label[flag] = ry_label[flag] - np.pi * 2\n        ry_label = torch.clamp(ry_label, min=-np.pi / 2, max=np.pi / 2)\n        pos_gt_bboxes_ct[..., 6] = ry_label\n        rois_anchor = pos_bboxes.clone().detach()\n        rois_anchor[:, 0:3] = 0\n        rois_anchor[:, 6] = 0\n        bbox_targets = self.bbox_coder.encode(rois_anchor, pos_gt_bboxes_ct)\n    else:\n        bbox_targets = pos_gt_bboxes.new_empty((0, 7))\n    return (label, bbox_targets, pos_gt_bboxes, reg_mask, label_weights, bbox_weights)"
        ]
    },
    {
        "func_name": "get_corner_loss_lidar",
        "original": "def get_corner_loss_lidar(self, pred_bbox3d, gt_bbox3d, delta=1.0):\n    \"\"\"Calculate corner loss of given boxes.\n\n        Args:\n            pred_bbox3d (torch.FloatTensor): Predicted boxes in shape (N, 7).\n            gt_bbox3d (torch.FloatTensor): Ground truth boxes in shape (N, 7).\n            delta (float, optional): huber loss threshold. Defaults to 1.0\n\n        Returns:\n            torch.FloatTensor: Calculated corner loss in shape (N).\n        \"\"\"\n    assert pred_bbox3d.shape[0] == gt_bbox3d.shape[0]\n    gt_boxes_structure = LiDARInstance3DBoxes(gt_bbox3d)\n    pred_box_corners = LiDARInstance3DBoxes(pred_bbox3d).corners\n    gt_box_corners = gt_boxes_structure.corners\n    gt_bbox3d_flip = gt_boxes_structure.clone()\n    gt_bbox3d_flip.tensor[:, 6] += np.pi\n    gt_box_corners_flip = gt_bbox3d_flip.corners\n    corner_dist = torch.min(torch.norm(pred_box_corners - gt_box_corners, dim=2), torch.norm(pred_box_corners - gt_box_corners_flip, dim=2))\n    abs_error = corner_dist.abs()\n    quadratic = abs_error.clamp(max=delta)\n    linear = abs_error - quadratic\n    corner_loss = 0.5 * quadratic ** 2 + delta * linear\n    return corner_loss.mean(dim=1)",
        "mutated": [
            "def get_corner_loss_lidar(self, pred_bbox3d, gt_bbox3d, delta=1.0):\n    if False:\n        i = 10\n    'Calculate corner loss of given boxes.\\n\\n        Args:\\n            pred_bbox3d (torch.FloatTensor): Predicted boxes in shape (N, 7).\\n            gt_bbox3d (torch.FloatTensor): Ground truth boxes in shape (N, 7).\\n            delta (float, optional): huber loss threshold. Defaults to 1.0\\n\\n        Returns:\\n            torch.FloatTensor: Calculated corner loss in shape (N).\\n        '\n    assert pred_bbox3d.shape[0] == gt_bbox3d.shape[0]\n    gt_boxes_structure = LiDARInstance3DBoxes(gt_bbox3d)\n    pred_box_corners = LiDARInstance3DBoxes(pred_bbox3d).corners\n    gt_box_corners = gt_boxes_structure.corners\n    gt_bbox3d_flip = gt_boxes_structure.clone()\n    gt_bbox3d_flip.tensor[:, 6] += np.pi\n    gt_box_corners_flip = gt_bbox3d_flip.corners\n    corner_dist = torch.min(torch.norm(pred_box_corners - gt_box_corners, dim=2), torch.norm(pred_box_corners - gt_box_corners_flip, dim=2))\n    abs_error = corner_dist.abs()\n    quadratic = abs_error.clamp(max=delta)\n    linear = abs_error - quadratic\n    corner_loss = 0.5 * quadratic ** 2 + delta * linear\n    return corner_loss.mean(dim=1)",
            "def get_corner_loss_lidar(self, pred_bbox3d, gt_bbox3d, delta=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Calculate corner loss of given boxes.\\n\\n        Args:\\n            pred_bbox3d (torch.FloatTensor): Predicted boxes in shape (N, 7).\\n            gt_bbox3d (torch.FloatTensor): Ground truth boxes in shape (N, 7).\\n            delta (float, optional): huber loss threshold. Defaults to 1.0\\n\\n        Returns:\\n            torch.FloatTensor: Calculated corner loss in shape (N).\\n        '\n    assert pred_bbox3d.shape[0] == gt_bbox3d.shape[0]\n    gt_boxes_structure = LiDARInstance3DBoxes(gt_bbox3d)\n    pred_box_corners = LiDARInstance3DBoxes(pred_bbox3d).corners\n    gt_box_corners = gt_boxes_structure.corners\n    gt_bbox3d_flip = gt_boxes_structure.clone()\n    gt_bbox3d_flip.tensor[:, 6] += np.pi\n    gt_box_corners_flip = gt_bbox3d_flip.corners\n    corner_dist = torch.min(torch.norm(pred_box_corners - gt_box_corners, dim=2), torch.norm(pred_box_corners - gt_box_corners_flip, dim=2))\n    abs_error = corner_dist.abs()\n    quadratic = abs_error.clamp(max=delta)\n    linear = abs_error - quadratic\n    corner_loss = 0.5 * quadratic ** 2 + delta * linear\n    return corner_loss.mean(dim=1)",
            "def get_corner_loss_lidar(self, pred_bbox3d, gt_bbox3d, delta=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Calculate corner loss of given boxes.\\n\\n        Args:\\n            pred_bbox3d (torch.FloatTensor): Predicted boxes in shape (N, 7).\\n            gt_bbox3d (torch.FloatTensor): Ground truth boxes in shape (N, 7).\\n            delta (float, optional): huber loss threshold. Defaults to 1.0\\n\\n        Returns:\\n            torch.FloatTensor: Calculated corner loss in shape (N).\\n        '\n    assert pred_bbox3d.shape[0] == gt_bbox3d.shape[0]\n    gt_boxes_structure = LiDARInstance3DBoxes(gt_bbox3d)\n    pred_box_corners = LiDARInstance3DBoxes(pred_bbox3d).corners\n    gt_box_corners = gt_boxes_structure.corners\n    gt_bbox3d_flip = gt_boxes_structure.clone()\n    gt_bbox3d_flip.tensor[:, 6] += np.pi\n    gt_box_corners_flip = gt_bbox3d_flip.corners\n    corner_dist = torch.min(torch.norm(pred_box_corners - gt_box_corners, dim=2), torch.norm(pred_box_corners - gt_box_corners_flip, dim=2))\n    abs_error = corner_dist.abs()\n    quadratic = abs_error.clamp(max=delta)\n    linear = abs_error - quadratic\n    corner_loss = 0.5 * quadratic ** 2 + delta * linear\n    return corner_loss.mean(dim=1)",
            "def get_corner_loss_lidar(self, pred_bbox3d, gt_bbox3d, delta=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Calculate corner loss of given boxes.\\n\\n        Args:\\n            pred_bbox3d (torch.FloatTensor): Predicted boxes in shape (N, 7).\\n            gt_bbox3d (torch.FloatTensor): Ground truth boxes in shape (N, 7).\\n            delta (float, optional): huber loss threshold. Defaults to 1.0\\n\\n        Returns:\\n            torch.FloatTensor: Calculated corner loss in shape (N).\\n        '\n    assert pred_bbox3d.shape[0] == gt_bbox3d.shape[0]\n    gt_boxes_structure = LiDARInstance3DBoxes(gt_bbox3d)\n    pred_box_corners = LiDARInstance3DBoxes(pred_bbox3d).corners\n    gt_box_corners = gt_boxes_structure.corners\n    gt_bbox3d_flip = gt_boxes_structure.clone()\n    gt_bbox3d_flip.tensor[:, 6] += np.pi\n    gt_box_corners_flip = gt_bbox3d_flip.corners\n    corner_dist = torch.min(torch.norm(pred_box_corners - gt_box_corners, dim=2), torch.norm(pred_box_corners - gt_box_corners_flip, dim=2))\n    abs_error = corner_dist.abs()\n    quadratic = abs_error.clamp(max=delta)\n    linear = abs_error - quadratic\n    corner_loss = 0.5 * quadratic ** 2 + delta * linear\n    return corner_loss.mean(dim=1)",
            "def get_corner_loss_lidar(self, pred_bbox3d, gt_bbox3d, delta=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Calculate corner loss of given boxes.\\n\\n        Args:\\n            pred_bbox3d (torch.FloatTensor): Predicted boxes in shape (N, 7).\\n            gt_bbox3d (torch.FloatTensor): Ground truth boxes in shape (N, 7).\\n            delta (float, optional): huber loss threshold. Defaults to 1.0\\n\\n        Returns:\\n            torch.FloatTensor: Calculated corner loss in shape (N).\\n        '\n    assert pred_bbox3d.shape[0] == gt_bbox3d.shape[0]\n    gt_boxes_structure = LiDARInstance3DBoxes(gt_bbox3d)\n    pred_box_corners = LiDARInstance3DBoxes(pred_bbox3d).corners\n    gt_box_corners = gt_boxes_structure.corners\n    gt_bbox3d_flip = gt_boxes_structure.clone()\n    gt_bbox3d_flip.tensor[:, 6] += np.pi\n    gt_box_corners_flip = gt_bbox3d_flip.corners\n    corner_dist = torch.min(torch.norm(pred_box_corners - gt_box_corners, dim=2), torch.norm(pred_box_corners - gt_box_corners_flip, dim=2))\n    abs_error = corner_dist.abs()\n    quadratic = abs_error.clamp(max=delta)\n    linear = abs_error - quadratic\n    corner_loss = 0.5 * quadratic ** 2 + delta * linear\n    return corner_loss.mean(dim=1)"
        ]
    },
    {
        "func_name": "get_bboxes",
        "original": "def get_bboxes(self, rois, cls_score, bbox_pred, class_labels, class_pred, img_metas, cfg=None):\n    \"\"\"Generate bboxes from bbox head predictions.\n\n        Args:\n            rois (torch.Tensor): Roi bounding boxes.\n            cls_score (torch.Tensor): Scores of bounding boxes.\n            bbox_pred (torch.Tensor): Bounding boxes predictions\n            class_labels (torch.Tensor): Label of classes\n            class_pred (torch.Tensor): Score for nms.\n            img_metas (list[dict]): Point cloud and image's meta info.\n            cfg (:obj:`ConfigDict`): Testing config.\n\n        Returns:\n            list[tuple]: Decoded bbox, scores and labels after nms.\n        \"\"\"\n    roi_batch_id = rois[..., 0]\n    roi_boxes = rois[..., 1:]\n    batch_size = int(roi_batch_id.max().item() + 1)\n    roi_ry = roi_boxes[..., 6].view(-1)\n    roi_xyz = roi_boxes[..., 0:3].view(-1, 3)\n    local_roi_boxes = roi_boxes.clone().detach()\n    local_roi_boxes[..., 0:3] = 0\n    rcnn_boxes3d = self.bbox_coder.decode(local_roi_boxes, bbox_pred)\n    rcnn_boxes3d[..., 0:3] = rotation_3d_in_axis(rcnn_boxes3d[..., 0:3].unsqueeze(1), roi_ry, axis=2).squeeze(1)\n    rcnn_boxes3d[:, 0:3] += roi_xyz\n    result_list = []\n    for batch_id in range(batch_size):\n        cur_class_labels = class_labels[batch_id]\n        cur_cls_score = cls_score[roi_batch_id == batch_id].view(-1)\n        cur_box_prob = class_pred[batch_id]\n        cur_rcnn_boxes3d = rcnn_boxes3d[roi_batch_id == batch_id]\n        keep = self.multi_class_nms(cur_box_prob, cur_rcnn_boxes3d, cfg.score_thr, cfg.nms_thr, img_metas[batch_id], cfg.use_rotate_nms)\n        selected_bboxes = cur_rcnn_boxes3d[keep]\n        selected_label_preds = cur_class_labels[keep]\n        selected_scores = cur_cls_score[keep]\n        result_list.append((img_metas[batch_id]['box_type_3d'](selected_bboxes, self.bbox_coder.code_size), selected_scores, selected_label_preds))\n    return result_list",
        "mutated": [
            "def get_bboxes(self, rois, cls_score, bbox_pred, class_labels, class_pred, img_metas, cfg=None):\n    if False:\n        i = 10\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            rois (torch.Tensor): Roi bounding boxes.\\n            cls_score (torch.Tensor): Scores of bounding boxes.\\n            bbox_pred (torch.Tensor): Bounding boxes predictions\\n            class_labels (torch.Tensor): Label of classes\\n            class_pred (torch.Tensor): Score for nms.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n            cfg (:obj:`ConfigDict`): Testing config.\\n\\n        Returns:\\n            list[tuple]: Decoded bbox, scores and labels after nms.\\n        \"\n    roi_batch_id = rois[..., 0]\n    roi_boxes = rois[..., 1:]\n    batch_size = int(roi_batch_id.max().item() + 1)\n    roi_ry = roi_boxes[..., 6].view(-1)\n    roi_xyz = roi_boxes[..., 0:3].view(-1, 3)\n    local_roi_boxes = roi_boxes.clone().detach()\n    local_roi_boxes[..., 0:3] = 0\n    rcnn_boxes3d = self.bbox_coder.decode(local_roi_boxes, bbox_pred)\n    rcnn_boxes3d[..., 0:3] = rotation_3d_in_axis(rcnn_boxes3d[..., 0:3].unsqueeze(1), roi_ry, axis=2).squeeze(1)\n    rcnn_boxes3d[:, 0:3] += roi_xyz\n    result_list = []\n    for batch_id in range(batch_size):\n        cur_class_labels = class_labels[batch_id]\n        cur_cls_score = cls_score[roi_batch_id == batch_id].view(-1)\n        cur_box_prob = class_pred[batch_id]\n        cur_rcnn_boxes3d = rcnn_boxes3d[roi_batch_id == batch_id]\n        keep = self.multi_class_nms(cur_box_prob, cur_rcnn_boxes3d, cfg.score_thr, cfg.nms_thr, img_metas[batch_id], cfg.use_rotate_nms)\n        selected_bboxes = cur_rcnn_boxes3d[keep]\n        selected_label_preds = cur_class_labels[keep]\n        selected_scores = cur_cls_score[keep]\n        result_list.append((img_metas[batch_id]['box_type_3d'](selected_bboxes, self.bbox_coder.code_size), selected_scores, selected_label_preds))\n    return result_list",
            "def get_bboxes(self, rois, cls_score, bbox_pred, class_labels, class_pred, img_metas, cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            rois (torch.Tensor): Roi bounding boxes.\\n            cls_score (torch.Tensor): Scores of bounding boxes.\\n            bbox_pred (torch.Tensor): Bounding boxes predictions\\n            class_labels (torch.Tensor): Label of classes\\n            class_pred (torch.Tensor): Score for nms.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n            cfg (:obj:`ConfigDict`): Testing config.\\n\\n        Returns:\\n            list[tuple]: Decoded bbox, scores and labels after nms.\\n        \"\n    roi_batch_id = rois[..., 0]\n    roi_boxes = rois[..., 1:]\n    batch_size = int(roi_batch_id.max().item() + 1)\n    roi_ry = roi_boxes[..., 6].view(-1)\n    roi_xyz = roi_boxes[..., 0:3].view(-1, 3)\n    local_roi_boxes = roi_boxes.clone().detach()\n    local_roi_boxes[..., 0:3] = 0\n    rcnn_boxes3d = self.bbox_coder.decode(local_roi_boxes, bbox_pred)\n    rcnn_boxes3d[..., 0:3] = rotation_3d_in_axis(rcnn_boxes3d[..., 0:3].unsqueeze(1), roi_ry, axis=2).squeeze(1)\n    rcnn_boxes3d[:, 0:3] += roi_xyz\n    result_list = []\n    for batch_id in range(batch_size):\n        cur_class_labels = class_labels[batch_id]\n        cur_cls_score = cls_score[roi_batch_id == batch_id].view(-1)\n        cur_box_prob = class_pred[batch_id]\n        cur_rcnn_boxes3d = rcnn_boxes3d[roi_batch_id == batch_id]\n        keep = self.multi_class_nms(cur_box_prob, cur_rcnn_boxes3d, cfg.score_thr, cfg.nms_thr, img_metas[batch_id], cfg.use_rotate_nms)\n        selected_bboxes = cur_rcnn_boxes3d[keep]\n        selected_label_preds = cur_class_labels[keep]\n        selected_scores = cur_cls_score[keep]\n        result_list.append((img_metas[batch_id]['box_type_3d'](selected_bboxes, self.bbox_coder.code_size), selected_scores, selected_label_preds))\n    return result_list",
            "def get_bboxes(self, rois, cls_score, bbox_pred, class_labels, class_pred, img_metas, cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            rois (torch.Tensor): Roi bounding boxes.\\n            cls_score (torch.Tensor): Scores of bounding boxes.\\n            bbox_pred (torch.Tensor): Bounding boxes predictions\\n            class_labels (torch.Tensor): Label of classes\\n            class_pred (torch.Tensor): Score for nms.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n            cfg (:obj:`ConfigDict`): Testing config.\\n\\n        Returns:\\n            list[tuple]: Decoded bbox, scores and labels after nms.\\n        \"\n    roi_batch_id = rois[..., 0]\n    roi_boxes = rois[..., 1:]\n    batch_size = int(roi_batch_id.max().item() + 1)\n    roi_ry = roi_boxes[..., 6].view(-1)\n    roi_xyz = roi_boxes[..., 0:3].view(-1, 3)\n    local_roi_boxes = roi_boxes.clone().detach()\n    local_roi_boxes[..., 0:3] = 0\n    rcnn_boxes3d = self.bbox_coder.decode(local_roi_boxes, bbox_pred)\n    rcnn_boxes3d[..., 0:3] = rotation_3d_in_axis(rcnn_boxes3d[..., 0:3].unsqueeze(1), roi_ry, axis=2).squeeze(1)\n    rcnn_boxes3d[:, 0:3] += roi_xyz\n    result_list = []\n    for batch_id in range(batch_size):\n        cur_class_labels = class_labels[batch_id]\n        cur_cls_score = cls_score[roi_batch_id == batch_id].view(-1)\n        cur_box_prob = class_pred[batch_id]\n        cur_rcnn_boxes3d = rcnn_boxes3d[roi_batch_id == batch_id]\n        keep = self.multi_class_nms(cur_box_prob, cur_rcnn_boxes3d, cfg.score_thr, cfg.nms_thr, img_metas[batch_id], cfg.use_rotate_nms)\n        selected_bboxes = cur_rcnn_boxes3d[keep]\n        selected_label_preds = cur_class_labels[keep]\n        selected_scores = cur_cls_score[keep]\n        result_list.append((img_metas[batch_id]['box_type_3d'](selected_bboxes, self.bbox_coder.code_size), selected_scores, selected_label_preds))\n    return result_list",
            "def get_bboxes(self, rois, cls_score, bbox_pred, class_labels, class_pred, img_metas, cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            rois (torch.Tensor): Roi bounding boxes.\\n            cls_score (torch.Tensor): Scores of bounding boxes.\\n            bbox_pred (torch.Tensor): Bounding boxes predictions\\n            class_labels (torch.Tensor): Label of classes\\n            class_pred (torch.Tensor): Score for nms.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n            cfg (:obj:`ConfigDict`): Testing config.\\n\\n        Returns:\\n            list[tuple]: Decoded bbox, scores and labels after nms.\\n        \"\n    roi_batch_id = rois[..., 0]\n    roi_boxes = rois[..., 1:]\n    batch_size = int(roi_batch_id.max().item() + 1)\n    roi_ry = roi_boxes[..., 6].view(-1)\n    roi_xyz = roi_boxes[..., 0:3].view(-1, 3)\n    local_roi_boxes = roi_boxes.clone().detach()\n    local_roi_boxes[..., 0:3] = 0\n    rcnn_boxes3d = self.bbox_coder.decode(local_roi_boxes, bbox_pred)\n    rcnn_boxes3d[..., 0:3] = rotation_3d_in_axis(rcnn_boxes3d[..., 0:3].unsqueeze(1), roi_ry, axis=2).squeeze(1)\n    rcnn_boxes3d[:, 0:3] += roi_xyz\n    result_list = []\n    for batch_id in range(batch_size):\n        cur_class_labels = class_labels[batch_id]\n        cur_cls_score = cls_score[roi_batch_id == batch_id].view(-1)\n        cur_box_prob = class_pred[batch_id]\n        cur_rcnn_boxes3d = rcnn_boxes3d[roi_batch_id == batch_id]\n        keep = self.multi_class_nms(cur_box_prob, cur_rcnn_boxes3d, cfg.score_thr, cfg.nms_thr, img_metas[batch_id], cfg.use_rotate_nms)\n        selected_bboxes = cur_rcnn_boxes3d[keep]\n        selected_label_preds = cur_class_labels[keep]\n        selected_scores = cur_cls_score[keep]\n        result_list.append((img_metas[batch_id]['box_type_3d'](selected_bboxes, self.bbox_coder.code_size), selected_scores, selected_label_preds))\n    return result_list",
            "def get_bboxes(self, rois, cls_score, bbox_pred, class_labels, class_pred, img_metas, cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Generate bboxes from bbox head predictions.\\n\\n        Args:\\n            rois (torch.Tensor): Roi bounding boxes.\\n            cls_score (torch.Tensor): Scores of bounding boxes.\\n            bbox_pred (torch.Tensor): Bounding boxes predictions\\n            class_labels (torch.Tensor): Label of classes\\n            class_pred (torch.Tensor): Score for nms.\\n            img_metas (list[dict]): Point cloud and image's meta info.\\n            cfg (:obj:`ConfigDict`): Testing config.\\n\\n        Returns:\\n            list[tuple]: Decoded bbox, scores and labels after nms.\\n        \"\n    roi_batch_id = rois[..., 0]\n    roi_boxes = rois[..., 1:]\n    batch_size = int(roi_batch_id.max().item() + 1)\n    roi_ry = roi_boxes[..., 6].view(-1)\n    roi_xyz = roi_boxes[..., 0:3].view(-1, 3)\n    local_roi_boxes = roi_boxes.clone().detach()\n    local_roi_boxes[..., 0:3] = 0\n    rcnn_boxes3d = self.bbox_coder.decode(local_roi_boxes, bbox_pred)\n    rcnn_boxes3d[..., 0:3] = rotation_3d_in_axis(rcnn_boxes3d[..., 0:3].unsqueeze(1), roi_ry, axis=2).squeeze(1)\n    rcnn_boxes3d[:, 0:3] += roi_xyz\n    result_list = []\n    for batch_id in range(batch_size):\n        cur_class_labels = class_labels[batch_id]\n        cur_cls_score = cls_score[roi_batch_id == batch_id].view(-1)\n        cur_box_prob = class_pred[batch_id]\n        cur_rcnn_boxes3d = rcnn_boxes3d[roi_batch_id == batch_id]\n        keep = self.multi_class_nms(cur_box_prob, cur_rcnn_boxes3d, cfg.score_thr, cfg.nms_thr, img_metas[batch_id], cfg.use_rotate_nms)\n        selected_bboxes = cur_rcnn_boxes3d[keep]\n        selected_label_preds = cur_class_labels[keep]\n        selected_scores = cur_cls_score[keep]\n        result_list.append((img_metas[batch_id]['box_type_3d'](selected_bboxes, self.bbox_coder.code_size), selected_scores, selected_label_preds))\n    return result_list"
        ]
    },
    {
        "func_name": "multi_class_nms",
        "original": "def multi_class_nms(self, box_probs, box_preds, score_thr, nms_thr, input_meta, use_rotate_nms=True):\n    \"\"\"Multi-class NMS for box head.\n\n        Note:\n            This function has large overlap with the `box3d_multiclass_nms`\n            implemented in `mmdet3d.core.post_processing`. We are considering\n            merging these two functions in the future.\n\n        Args:\n            box_probs (torch.Tensor): Predicted boxes probabitilies in\n                shape (N,).\n            box_preds (torch.Tensor): Predicted boxes in shape (N, 7+C).\n            score_thr (float): Threshold of scores.\n            nms_thr (float): Threshold for NMS.\n            input_meta (dict): Meta information of the current sample.\n            use_rotate_nms (bool, optional): Whether to use rotated nms.\n                Defaults to True.\n\n        Returns:\n            torch.Tensor: Selected indices.\n        \"\"\"\n    if use_rotate_nms:\n        nms_func = nms_bev\n    else:\n        nms_func = nms_normal_bev\n    assert box_probs.shape[1] == self.num_classes, f'box_probs shape: {str(box_probs.shape)}'\n    selected_list = []\n    selected_labels = []\n    boxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](box_preds, self.bbox_coder.code_size).bev)\n    score_thresh = score_thr if isinstance(score_thr, list) else [score_thr for x in range(self.num_classes)]\n    nms_thresh = nms_thr if isinstance(nms_thr, list) else [nms_thr for x in range(self.num_classes)]\n    for k in range(0, self.num_classes):\n        class_scores_keep = box_probs[:, k] >= score_thresh[k]\n        if class_scores_keep.int().sum() > 0:\n            original_idxs = class_scores_keep.nonzero(as_tuple=False).view(-1)\n            cur_boxes_for_nms = boxes_for_nms[class_scores_keep]\n            cur_rank_scores = box_probs[class_scores_keep, k]\n            cur_selected = nms_func(cur_boxes_for_nms, cur_rank_scores, nms_thresh[k])\n            if cur_selected.shape[0] == 0:\n                continue\n            selected_list.append(original_idxs[cur_selected])\n            selected_labels.append(torch.full([cur_selected.shape[0]], k + 1, dtype=torch.int64, device=box_preds.device))\n    keep = torch.cat(selected_list, dim=0) if len(selected_list) > 0 else []\n    return keep",
        "mutated": [
            "def multi_class_nms(self, box_probs, box_preds, score_thr, nms_thr, input_meta, use_rotate_nms=True):\n    if False:\n        i = 10\n    'Multi-class NMS for box head.\\n\\n        Note:\\n            This function has large overlap with the `box3d_multiclass_nms`\\n            implemented in `mmdet3d.core.post_processing`. We are considering\\n            merging these two functions in the future.\\n\\n        Args:\\n            box_probs (torch.Tensor): Predicted boxes probabitilies in\\n                shape (N,).\\n            box_preds (torch.Tensor): Predicted boxes in shape (N, 7+C).\\n            score_thr (float): Threshold of scores.\\n            nms_thr (float): Threshold for NMS.\\n            input_meta (dict): Meta information of the current sample.\\n            use_rotate_nms (bool, optional): Whether to use rotated nms.\\n                Defaults to True.\\n\\n        Returns:\\n            torch.Tensor: Selected indices.\\n        '\n    if use_rotate_nms:\n        nms_func = nms_bev\n    else:\n        nms_func = nms_normal_bev\n    assert box_probs.shape[1] == self.num_classes, f'box_probs shape: {str(box_probs.shape)}'\n    selected_list = []\n    selected_labels = []\n    boxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](box_preds, self.bbox_coder.code_size).bev)\n    score_thresh = score_thr if isinstance(score_thr, list) else [score_thr for x in range(self.num_classes)]\n    nms_thresh = nms_thr if isinstance(nms_thr, list) else [nms_thr for x in range(self.num_classes)]\n    for k in range(0, self.num_classes):\n        class_scores_keep = box_probs[:, k] >= score_thresh[k]\n        if class_scores_keep.int().sum() > 0:\n            original_idxs = class_scores_keep.nonzero(as_tuple=False).view(-1)\n            cur_boxes_for_nms = boxes_for_nms[class_scores_keep]\n            cur_rank_scores = box_probs[class_scores_keep, k]\n            cur_selected = nms_func(cur_boxes_for_nms, cur_rank_scores, nms_thresh[k])\n            if cur_selected.shape[0] == 0:\n                continue\n            selected_list.append(original_idxs[cur_selected])\n            selected_labels.append(torch.full([cur_selected.shape[0]], k + 1, dtype=torch.int64, device=box_preds.device))\n    keep = torch.cat(selected_list, dim=0) if len(selected_list) > 0 else []\n    return keep",
            "def multi_class_nms(self, box_probs, box_preds, score_thr, nms_thr, input_meta, use_rotate_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Multi-class NMS for box head.\\n\\n        Note:\\n            This function has large overlap with the `box3d_multiclass_nms`\\n            implemented in `mmdet3d.core.post_processing`. We are considering\\n            merging these two functions in the future.\\n\\n        Args:\\n            box_probs (torch.Tensor): Predicted boxes probabitilies in\\n                shape (N,).\\n            box_preds (torch.Tensor): Predicted boxes in shape (N, 7+C).\\n            score_thr (float): Threshold of scores.\\n            nms_thr (float): Threshold for NMS.\\n            input_meta (dict): Meta information of the current sample.\\n            use_rotate_nms (bool, optional): Whether to use rotated nms.\\n                Defaults to True.\\n\\n        Returns:\\n            torch.Tensor: Selected indices.\\n        '\n    if use_rotate_nms:\n        nms_func = nms_bev\n    else:\n        nms_func = nms_normal_bev\n    assert box_probs.shape[1] == self.num_classes, f'box_probs shape: {str(box_probs.shape)}'\n    selected_list = []\n    selected_labels = []\n    boxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](box_preds, self.bbox_coder.code_size).bev)\n    score_thresh = score_thr if isinstance(score_thr, list) else [score_thr for x in range(self.num_classes)]\n    nms_thresh = nms_thr if isinstance(nms_thr, list) else [nms_thr for x in range(self.num_classes)]\n    for k in range(0, self.num_classes):\n        class_scores_keep = box_probs[:, k] >= score_thresh[k]\n        if class_scores_keep.int().sum() > 0:\n            original_idxs = class_scores_keep.nonzero(as_tuple=False).view(-1)\n            cur_boxes_for_nms = boxes_for_nms[class_scores_keep]\n            cur_rank_scores = box_probs[class_scores_keep, k]\n            cur_selected = nms_func(cur_boxes_for_nms, cur_rank_scores, nms_thresh[k])\n            if cur_selected.shape[0] == 0:\n                continue\n            selected_list.append(original_idxs[cur_selected])\n            selected_labels.append(torch.full([cur_selected.shape[0]], k + 1, dtype=torch.int64, device=box_preds.device))\n    keep = torch.cat(selected_list, dim=0) if len(selected_list) > 0 else []\n    return keep",
            "def multi_class_nms(self, box_probs, box_preds, score_thr, nms_thr, input_meta, use_rotate_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Multi-class NMS for box head.\\n\\n        Note:\\n            This function has large overlap with the `box3d_multiclass_nms`\\n            implemented in `mmdet3d.core.post_processing`. We are considering\\n            merging these two functions in the future.\\n\\n        Args:\\n            box_probs (torch.Tensor): Predicted boxes probabitilies in\\n                shape (N,).\\n            box_preds (torch.Tensor): Predicted boxes in shape (N, 7+C).\\n            score_thr (float): Threshold of scores.\\n            nms_thr (float): Threshold for NMS.\\n            input_meta (dict): Meta information of the current sample.\\n            use_rotate_nms (bool, optional): Whether to use rotated nms.\\n                Defaults to True.\\n\\n        Returns:\\n            torch.Tensor: Selected indices.\\n        '\n    if use_rotate_nms:\n        nms_func = nms_bev\n    else:\n        nms_func = nms_normal_bev\n    assert box_probs.shape[1] == self.num_classes, f'box_probs shape: {str(box_probs.shape)}'\n    selected_list = []\n    selected_labels = []\n    boxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](box_preds, self.bbox_coder.code_size).bev)\n    score_thresh = score_thr if isinstance(score_thr, list) else [score_thr for x in range(self.num_classes)]\n    nms_thresh = nms_thr if isinstance(nms_thr, list) else [nms_thr for x in range(self.num_classes)]\n    for k in range(0, self.num_classes):\n        class_scores_keep = box_probs[:, k] >= score_thresh[k]\n        if class_scores_keep.int().sum() > 0:\n            original_idxs = class_scores_keep.nonzero(as_tuple=False).view(-1)\n            cur_boxes_for_nms = boxes_for_nms[class_scores_keep]\n            cur_rank_scores = box_probs[class_scores_keep, k]\n            cur_selected = nms_func(cur_boxes_for_nms, cur_rank_scores, nms_thresh[k])\n            if cur_selected.shape[0] == 0:\n                continue\n            selected_list.append(original_idxs[cur_selected])\n            selected_labels.append(torch.full([cur_selected.shape[0]], k + 1, dtype=torch.int64, device=box_preds.device))\n    keep = torch.cat(selected_list, dim=0) if len(selected_list) > 0 else []\n    return keep",
            "def multi_class_nms(self, box_probs, box_preds, score_thr, nms_thr, input_meta, use_rotate_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Multi-class NMS for box head.\\n\\n        Note:\\n            This function has large overlap with the `box3d_multiclass_nms`\\n            implemented in `mmdet3d.core.post_processing`. We are considering\\n            merging these two functions in the future.\\n\\n        Args:\\n            box_probs (torch.Tensor): Predicted boxes probabitilies in\\n                shape (N,).\\n            box_preds (torch.Tensor): Predicted boxes in shape (N, 7+C).\\n            score_thr (float): Threshold of scores.\\n            nms_thr (float): Threshold for NMS.\\n            input_meta (dict): Meta information of the current sample.\\n            use_rotate_nms (bool, optional): Whether to use rotated nms.\\n                Defaults to True.\\n\\n        Returns:\\n            torch.Tensor: Selected indices.\\n        '\n    if use_rotate_nms:\n        nms_func = nms_bev\n    else:\n        nms_func = nms_normal_bev\n    assert box_probs.shape[1] == self.num_classes, f'box_probs shape: {str(box_probs.shape)}'\n    selected_list = []\n    selected_labels = []\n    boxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](box_preds, self.bbox_coder.code_size).bev)\n    score_thresh = score_thr if isinstance(score_thr, list) else [score_thr for x in range(self.num_classes)]\n    nms_thresh = nms_thr if isinstance(nms_thr, list) else [nms_thr for x in range(self.num_classes)]\n    for k in range(0, self.num_classes):\n        class_scores_keep = box_probs[:, k] >= score_thresh[k]\n        if class_scores_keep.int().sum() > 0:\n            original_idxs = class_scores_keep.nonzero(as_tuple=False).view(-1)\n            cur_boxes_for_nms = boxes_for_nms[class_scores_keep]\n            cur_rank_scores = box_probs[class_scores_keep, k]\n            cur_selected = nms_func(cur_boxes_for_nms, cur_rank_scores, nms_thresh[k])\n            if cur_selected.shape[0] == 0:\n                continue\n            selected_list.append(original_idxs[cur_selected])\n            selected_labels.append(torch.full([cur_selected.shape[0]], k + 1, dtype=torch.int64, device=box_preds.device))\n    keep = torch.cat(selected_list, dim=0) if len(selected_list) > 0 else []\n    return keep",
            "def multi_class_nms(self, box_probs, box_preds, score_thr, nms_thr, input_meta, use_rotate_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Multi-class NMS for box head.\\n\\n        Note:\\n            This function has large overlap with the `box3d_multiclass_nms`\\n            implemented in `mmdet3d.core.post_processing`. We are considering\\n            merging these two functions in the future.\\n\\n        Args:\\n            box_probs (torch.Tensor): Predicted boxes probabitilies in\\n                shape (N,).\\n            box_preds (torch.Tensor): Predicted boxes in shape (N, 7+C).\\n            score_thr (float): Threshold of scores.\\n            nms_thr (float): Threshold for NMS.\\n            input_meta (dict): Meta information of the current sample.\\n            use_rotate_nms (bool, optional): Whether to use rotated nms.\\n                Defaults to True.\\n\\n        Returns:\\n            torch.Tensor: Selected indices.\\n        '\n    if use_rotate_nms:\n        nms_func = nms_bev\n    else:\n        nms_func = nms_normal_bev\n    assert box_probs.shape[1] == self.num_classes, f'box_probs shape: {str(box_probs.shape)}'\n    selected_list = []\n    selected_labels = []\n    boxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](box_preds, self.bbox_coder.code_size).bev)\n    score_thresh = score_thr if isinstance(score_thr, list) else [score_thr for x in range(self.num_classes)]\n    nms_thresh = nms_thr if isinstance(nms_thr, list) else [nms_thr for x in range(self.num_classes)]\n    for k in range(0, self.num_classes):\n        class_scores_keep = box_probs[:, k] >= score_thresh[k]\n        if class_scores_keep.int().sum() > 0:\n            original_idxs = class_scores_keep.nonzero(as_tuple=False).view(-1)\n            cur_boxes_for_nms = boxes_for_nms[class_scores_keep]\n            cur_rank_scores = box_probs[class_scores_keep, k]\n            cur_selected = nms_func(cur_boxes_for_nms, cur_rank_scores, nms_thresh[k])\n            if cur_selected.shape[0] == 0:\n                continue\n            selected_list.append(original_idxs[cur_selected])\n            selected_labels.append(torch.full([cur_selected.shape[0]], k + 1, dtype=torch.int64, device=box_preds.device))\n    keep = torch.cat(selected_list, dim=0) if len(selected_list) > 0 else []\n    return keep"
        ]
    }
]