[
    {
        "func_name": "execute_k8s_job",
        "original": "@experimental\ndef execute_k8s_job(context: OpExecutionContext, image: str, command: Optional[List[str]]=None, args: Optional[List[str]]=None, namespace: Optional[str]=None, image_pull_policy: Optional[str]=None, image_pull_secrets: Optional[List[Dict[str, str]]]=None, service_account_name: Optional[str]=None, env_config_maps: Optional[List[str]]=None, env_secrets: Optional[List[str]]=None, env_vars: Optional[List[str]]=None, volume_mounts: Optional[List[Dict[str, Any]]]=None, volumes: Optional[List[Dict[str, Any]]]=None, labels: Optional[Dict[str, str]]=None, resources: Optional[Dict[str, Any]]=None, scheduler_name: Optional[str]=None, load_incluster_config: bool=True, kubeconfig_file: Optional[str]=None, timeout: Optional[int]=None, container_config: Optional[Dict[str, Any]]=None, pod_template_spec_metadata: Optional[Dict[str, Any]]=None, pod_spec_config: Optional[Dict[str, Any]]=None, job_metadata: Optional[Dict[str, Any]]=None, job_spec_config: Optional[Dict[str, Any]]=None, k8s_job_name: Optional[str]=None, merge_behavior: K8sConfigMergeBehavior=K8sConfigMergeBehavior.SHALLOW):\n    \"\"\"This function is a utility for executing a Kubernetes job from within a Dagster op.\n\n    Args:\n        image (str): The image in which to launch the k8s job.\n        command (Optional[List[str]]): The command to run in the container within the launched\n            k8s job. Default: None.\n        args (Optional[List[str]]): The args for the command for the container. Default: None.\n        namespace (Optional[str]): Override the kubernetes namespace in which to run the k8s job.\n            Default: None.\n        image_pull_policy (Optional[str]): Allows the image pull policy to be overridden, e.g. to\n            facilitate local testing with `kind <https://kind.sigs.k8s.io/>`_. Default:\n            ``\"Always\"``. See:\n            https://kubernetes.io/docs/concepts/containers/images/#updating-images.\n        image_pull_secrets (Optional[List[Dict[str, str]]]): Optionally, a list of dicts, each of\n            which corresponds to a Kubernetes ``LocalObjectReference`` (e.g.,\n            ``{'name': 'myRegistryName'}``). This allows you to specify the ```imagePullSecrets`` on\n            a pod basis. Typically, these will be provided through the service account, when needed,\n            and you will not need to pass this argument. See:\n            https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod\n            and https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core\n        service_account_name (Optional[str]): The name of the Kubernetes service account under which\n            to run the Job. Defaults to \"default\"        env_config_maps (Optional[List[str]]): A list of custom ConfigMapEnvSource names from which to\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\n            https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container\n        env_secrets (Optional[List[str]]): A list of custom Secret names from which to\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\n            https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\n        env_vars (Optional[List[str]]): A list of environment variables to inject into the Job.\n            Default: ``[]``. See: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\n        volume_mounts (Optional[List[Permissive]]): A list of volume mounts to include in the job's\n            container. Default: ``[]``. See:\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core\n        volumes (Optional[List[Permissive]]): A list of volumes to include in the Job's Pod. Default: ``[]``. See:\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core\n        labels (Optional[Dict[str, str]]): Additional labels that should be included in the Job's Pod. See:\n            https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n        resources (Optional[Dict[str, Any]]) Compute resource requirements for the container. See:\n            https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n        scheduler_name (Optional[str]): Use a custom Kubernetes scheduler for launched Pods. See:\n            https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/\n        load_incluster_config (bool): Whether the op is running within a k8s cluster. If ``True``,\n            we assume the launcher is running within the target cluster and load config using\n            ``kubernetes.config.load_incluster_config``. Otherwise, we will use the k8s config\n            specified in ``kubeconfig_file`` (using ``kubernetes.config.load_kube_config``) or fall\n            back to the default kubeconfig. Default: True,\n        kubeconfig_file (Optional[str]): The kubeconfig file from which to load config. Defaults to\n            using the default kubeconfig. Default: None.\n        timeout (Optional[int]): Raise an exception if the op takes longer than this timeout in\n            seconds to execute. Default: None.\n        container_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod's main container\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core).\n            Keys can either snake_case or camelCase.Default: None.\n        pod_template_spec_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod's\n            metadata (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\n            Keys can either snake_case or camelCase. Default: None.\n        pod_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod's pod spec\n            (https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec).\n            Keys can either snake_case or camelCase. Default: None.\n        job_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s job's metadata\n            (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\n            Keys can either snake_case or camelCase. Default: None.\n        job_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s job's job spec\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#jobspec-v1-batch).\n            Keys can either snake_case or camelCase.Default: None.\n        k8s_job_name (Optional[str]): Overrides the name of the the k8s job. If not set, will be set\n            to a unique name based on the current run ID and the name of the calling op. If set,\n            make sure that the passed in name is a valid Kubernetes job name that does not\n            already exist in the cluster.\n        merge_behavior (Optional[K8sConfigMergeBehavior]): How raw k8s config set on this op should\n            be merged with any raw k8s config set on the code location that launched the op. By\n            default, the value is K8sConfigMergeBehavior.SHALLOW, meaning that the two dictionaries\n            are shallowly merged - any shared values in the dictionaries will be replaced by the\n            values set on this op. Setting it to DEEP will recursively merge the two dictionaries,\n            appending list fields together andmerging dictionary fields.\n    \"\"\"\n    run_container_context = K8sContainerContext.create_for_run(context.dagster_run, context.instance.run_launcher if isinstance(context.instance.run_launcher, K8sRunLauncher) else None, include_run_tags=False)\n    container_config = container_config.copy() if container_config else {}\n    if command:\n        container_config['command'] = command\n    op_container_context = K8sContainerContext(image_pull_policy=image_pull_policy, image_pull_secrets=image_pull_secrets, service_account_name=service_account_name, env_config_maps=env_config_maps, env_secrets=env_secrets, env_vars=env_vars, volume_mounts=volume_mounts, volumes=volumes, labels=labels, namespace=namespace, resources=resources, scheduler_name=scheduler_name, run_k8s_config=UserDefinedDagsterK8sConfig.from_dict({'container_config': container_config, 'pod_template_spec_metadata': pod_template_spec_metadata, 'pod_spec_config': pod_spec_config, 'job_metadata': job_metadata, 'job_spec_config': job_spec_config, 'merge_behavior': merge_behavior.value}))\n    container_context = run_container_context.merge(op_container_context)\n    namespace = container_context.namespace\n    user_defined_k8s_config = container_context.run_k8s_config\n    k8s_job_config = DagsterK8sJobConfig(job_image=image, dagster_home=None, image_pull_policy=container_context.image_pull_policy, image_pull_secrets=container_context.image_pull_secrets, service_account_name=container_context.service_account_name, instance_config_map=None, postgres_password_secret=None, env_config_maps=container_context.env_config_maps, env_secrets=container_context.env_secrets, env_vars=container_context.env_vars, volume_mounts=container_context.volume_mounts, volumes=container_context.volumes, labels=container_context.labels, resources=container_context.resources)\n    job_name = k8s_job_name or get_k8s_job_name(context.run_id, context.get_step_execution_context().step.key)\n    retry_number = context.retry_number\n    if retry_number > 0:\n        job_name = f'{job_name}-{retry_number}'\n    labels = {'dagster/job': context.dagster_run.job_name, 'dagster/op': context.op.name, 'dagster/run-id': context.dagster_run.run_id}\n    if context.dagster_run.external_job_origin:\n        labels['dagster/code-location'] = context.dagster_run.external_job_origin.external_repository_origin.code_location_origin.location_name\n    job = construct_dagster_k8s_job(job_config=k8s_job_config, args=args, job_name=job_name, pod_name=job_name, component='k8s_job_op', user_defined_k8s_config=user_defined_k8s_config, labels=labels)\n    if load_incluster_config:\n        kubernetes.config.load_incluster_config()\n    else:\n        kubernetes.config.load_kube_config(kubeconfig_file)\n    api_client = DagsterKubernetesClient.production_client()\n    context.log.info(f'Creating Kubernetes job {job_name} in namespace {namespace}...')\n    start_time = time.time()\n    api_client.batch_api.create_namespaced_job(namespace, job)\n    context.log.info('Waiting for Kubernetes job to finish...')\n    timeout = timeout or 0\n    api_client.wait_for_job(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time)\n    restart_policy = user_defined_k8s_config.pod_spec_config.get('restart_policy', 'Never')\n    if restart_policy == 'Never':\n        container_name = container_config.get('name', 'dagster')\n        pods = api_client.wait_for_job_to_have_pods(job_name, namespace, wait_timeout=timeout, start_time=start_time)\n        pod_names = [p.metadata.name for p in pods]\n        if not pod_names:\n            raise Exception('No pod names in job after it started')\n        pod_to_watch = pod_names[0]\n        watch = kubernetes.watch.Watch()\n        api_client.wait_for_pod(pod_to_watch, namespace, wait_timeout=timeout, start_time=start_time)\n        log_stream = watch.stream(api_client.core_api.read_namespaced_pod_log, name=pod_to_watch, namespace=namespace, container=container_name)\n        while True:\n            if timeout and time.time() - start_time > timeout:\n                watch.stop()\n                raise Exception('Timed out waiting for pod to finish')\n            try:\n                log_entry = next(log_stream)\n                print(log_entry)\n            except StopIteration:\n                break\n    else:\n        context.log.info('Pod logs are disabled, because restart_policy is not Never')\n    if job_spec_config and job_spec_config.get('parallelism'):\n        num_pods_to_wait_for = job_spec_config['parallelism']\n    else:\n        num_pods_to_wait_for = DEFAULT_JOB_POD_COUNT\n    api_client.wait_for_running_job_to_succeed(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time, num_pods_to_wait_for=num_pods_to_wait_for)",
        "mutated": [
            "@experimental\ndef execute_k8s_job(context: OpExecutionContext, image: str, command: Optional[List[str]]=None, args: Optional[List[str]]=None, namespace: Optional[str]=None, image_pull_policy: Optional[str]=None, image_pull_secrets: Optional[List[Dict[str, str]]]=None, service_account_name: Optional[str]=None, env_config_maps: Optional[List[str]]=None, env_secrets: Optional[List[str]]=None, env_vars: Optional[List[str]]=None, volume_mounts: Optional[List[Dict[str, Any]]]=None, volumes: Optional[List[Dict[str, Any]]]=None, labels: Optional[Dict[str, str]]=None, resources: Optional[Dict[str, Any]]=None, scheduler_name: Optional[str]=None, load_incluster_config: bool=True, kubeconfig_file: Optional[str]=None, timeout: Optional[int]=None, container_config: Optional[Dict[str, Any]]=None, pod_template_spec_metadata: Optional[Dict[str, Any]]=None, pod_spec_config: Optional[Dict[str, Any]]=None, job_metadata: Optional[Dict[str, Any]]=None, job_spec_config: Optional[Dict[str, Any]]=None, k8s_job_name: Optional[str]=None, merge_behavior: K8sConfigMergeBehavior=K8sConfigMergeBehavior.SHALLOW):\n    if False:\n        i = 10\n    'This function is a utility for executing a Kubernetes job from within a Dagster op.\\n\\n    Args:\\n        image (str): The image in which to launch the k8s job.\\n        command (Optional[List[str]]): The command to run in the container within the launched\\n            k8s job. Default: None.\\n        args (Optional[List[str]]): The args for the command for the container. Default: None.\\n        namespace (Optional[str]): Override the kubernetes namespace in which to run the k8s job.\\n            Default: None.\\n        image_pull_policy (Optional[str]): Allows the image pull policy to be overridden, e.g. to\\n            facilitate local testing with `kind <https://kind.sigs.k8s.io/>`_. Default:\\n            ``\"Always\"``. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#updating-images.\\n        image_pull_secrets (Optional[List[Dict[str, str]]]): Optionally, a list of dicts, each of\\n            which corresponds to a Kubernetes ``LocalObjectReference`` (e.g.,\\n            ``{\\'name\\': \\'myRegistryName\\'}``). This allows you to specify the ```imagePullSecrets`` on\\n            a pod basis. Typically, these will be provided through the service account, when needed,\\n            and you will not need to pass this argument. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod\\n            and https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core\\n        service_account_name (Optional[str]): The name of the Kubernetes service account under which\\n            to run the Job. Defaults to \"default\"        env_config_maps (Optional[List[str]]): A list of custom ConfigMapEnvSource names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container\\n        env_secrets (Optional[List[str]]): A list of custom Secret names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        env_vars (Optional[List[str]]): A list of environment variables to inject into the Job.\\n            Default: ``[]``. See: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        volume_mounts (Optional[List[Permissive]]): A list of volume mounts to include in the job\\'s\\n            container. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core\\n        volumes (Optional[List[Permissive]]): A list of volumes to include in the Job\\'s Pod. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core\\n        labels (Optional[Dict[str, str]]): Additional labels that should be included in the Job\\'s Pod. See:\\n            https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\\n        resources (Optional[Dict[str, Any]]) Compute resource requirements for the container. See:\\n            https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\n        scheduler_name (Optional[str]): Use a custom Kubernetes scheduler for launched Pods. See:\\n            https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/\\n        load_incluster_config (bool): Whether the op is running within a k8s cluster. If ``True``,\\n            we assume the launcher is running within the target cluster and load config using\\n            ``kubernetes.config.load_incluster_config``. Otherwise, we will use the k8s config\\n            specified in ``kubeconfig_file`` (using ``kubernetes.config.load_kube_config``) or fall\\n            back to the default kubeconfig. Default: True,\\n        kubeconfig_file (Optional[str]): The kubeconfig file from which to load config. Defaults to\\n            using the default kubeconfig. Default: None.\\n        timeout (Optional[int]): Raise an exception if the op takes longer than this timeout in\\n            seconds to execute. Default: None.\\n        container_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s main container\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core).\\n            Keys can either snake_case or camelCase.Default: None.\\n        pod_template_spec_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s\\n            metadata (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        pod_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s pod spec\\n            (https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s metadata\\n            (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s job spec\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#jobspec-v1-batch).\\n            Keys can either snake_case or camelCase.Default: None.\\n        k8s_job_name (Optional[str]): Overrides the name of the the k8s job. If not set, will be set\\n            to a unique name based on the current run ID and the name of the calling op. If set,\\n            make sure that the passed in name is a valid Kubernetes job name that does not\\n            already exist in the cluster.\\n        merge_behavior (Optional[K8sConfigMergeBehavior]): How raw k8s config set on this op should\\n            be merged with any raw k8s config set on the code location that launched the op. By\\n            default, the value is K8sConfigMergeBehavior.SHALLOW, meaning that the two dictionaries\\n            are shallowly merged - any shared values in the dictionaries will be replaced by the\\n            values set on this op. Setting it to DEEP will recursively merge the two dictionaries,\\n            appending list fields together andmerging dictionary fields.\\n    '\n    run_container_context = K8sContainerContext.create_for_run(context.dagster_run, context.instance.run_launcher if isinstance(context.instance.run_launcher, K8sRunLauncher) else None, include_run_tags=False)\n    container_config = container_config.copy() if container_config else {}\n    if command:\n        container_config['command'] = command\n    op_container_context = K8sContainerContext(image_pull_policy=image_pull_policy, image_pull_secrets=image_pull_secrets, service_account_name=service_account_name, env_config_maps=env_config_maps, env_secrets=env_secrets, env_vars=env_vars, volume_mounts=volume_mounts, volumes=volumes, labels=labels, namespace=namespace, resources=resources, scheduler_name=scheduler_name, run_k8s_config=UserDefinedDagsterK8sConfig.from_dict({'container_config': container_config, 'pod_template_spec_metadata': pod_template_spec_metadata, 'pod_spec_config': pod_spec_config, 'job_metadata': job_metadata, 'job_spec_config': job_spec_config, 'merge_behavior': merge_behavior.value}))\n    container_context = run_container_context.merge(op_container_context)\n    namespace = container_context.namespace\n    user_defined_k8s_config = container_context.run_k8s_config\n    k8s_job_config = DagsterK8sJobConfig(job_image=image, dagster_home=None, image_pull_policy=container_context.image_pull_policy, image_pull_secrets=container_context.image_pull_secrets, service_account_name=container_context.service_account_name, instance_config_map=None, postgres_password_secret=None, env_config_maps=container_context.env_config_maps, env_secrets=container_context.env_secrets, env_vars=container_context.env_vars, volume_mounts=container_context.volume_mounts, volumes=container_context.volumes, labels=container_context.labels, resources=container_context.resources)\n    job_name = k8s_job_name or get_k8s_job_name(context.run_id, context.get_step_execution_context().step.key)\n    retry_number = context.retry_number\n    if retry_number > 0:\n        job_name = f'{job_name}-{retry_number}'\n    labels = {'dagster/job': context.dagster_run.job_name, 'dagster/op': context.op.name, 'dagster/run-id': context.dagster_run.run_id}\n    if context.dagster_run.external_job_origin:\n        labels['dagster/code-location'] = context.dagster_run.external_job_origin.external_repository_origin.code_location_origin.location_name\n    job = construct_dagster_k8s_job(job_config=k8s_job_config, args=args, job_name=job_name, pod_name=job_name, component='k8s_job_op', user_defined_k8s_config=user_defined_k8s_config, labels=labels)\n    if load_incluster_config:\n        kubernetes.config.load_incluster_config()\n    else:\n        kubernetes.config.load_kube_config(kubeconfig_file)\n    api_client = DagsterKubernetesClient.production_client()\n    context.log.info(f'Creating Kubernetes job {job_name} in namespace {namespace}...')\n    start_time = time.time()\n    api_client.batch_api.create_namespaced_job(namespace, job)\n    context.log.info('Waiting for Kubernetes job to finish...')\n    timeout = timeout or 0\n    api_client.wait_for_job(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time)\n    restart_policy = user_defined_k8s_config.pod_spec_config.get('restart_policy', 'Never')\n    if restart_policy == 'Never':\n        container_name = container_config.get('name', 'dagster')\n        pods = api_client.wait_for_job_to_have_pods(job_name, namespace, wait_timeout=timeout, start_time=start_time)\n        pod_names = [p.metadata.name for p in pods]\n        if not pod_names:\n            raise Exception('No pod names in job after it started')\n        pod_to_watch = pod_names[0]\n        watch = kubernetes.watch.Watch()\n        api_client.wait_for_pod(pod_to_watch, namespace, wait_timeout=timeout, start_time=start_time)\n        log_stream = watch.stream(api_client.core_api.read_namespaced_pod_log, name=pod_to_watch, namespace=namespace, container=container_name)\n        while True:\n            if timeout and time.time() - start_time > timeout:\n                watch.stop()\n                raise Exception('Timed out waiting for pod to finish')\n            try:\n                log_entry = next(log_stream)\n                print(log_entry)\n            except StopIteration:\n                break\n    else:\n        context.log.info('Pod logs are disabled, because restart_policy is not Never')\n    if job_spec_config and job_spec_config.get('parallelism'):\n        num_pods_to_wait_for = job_spec_config['parallelism']\n    else:\n        num_pods_to_wait_for = DEFAULT_JOB_POD_COUNT\n    api_client.wait_for_running_job_to_succeed(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time, num_pods_to_wait_for=num_pods_to_wait_for)",
            "@experimental\ndef execute_k8s_job(context: OpExecutionContext, image: str, command: Optional[List[str]]=None, args: Optional[List[str]]=None, namespace: Optional[str]=None, image_pull_policy: Optional[str]=None, image_pull_secrets: Optional[List[Dict[str, str]]]=None, service_account_name: Optional[str]=None, env_config_maps: Optional[List[str]]=None, env_secrets: Optional[List[str]]=None, env_vars: Optional[List[str]]=None, volume_mounts: Optional[List[Dict[str, Any]]]=None, volumes: Optional[List[Dict[str, Any]]]=None, labels: Optional[Dict[str, str]]=None, resources: Optional[Dict[str, Any]]=None, scheduler_name: Optional[str]=None, load_incluster_config: bool=True, kubeconfig_file: Optional[str]=None, timeout: Optional[int]=None, container_config: Optional[Dict[str, Any]]=None, pod_template_spec_metadata: Optional[Dict[str, Any]]=None, pod_spec_config: Optional[Dict[str, Any]]=None, job_metadata: Optional[Dict[str, Any]]=None, job_spec_config: Optional[Dict[str, Any]]=None, k8s_job_name: Optional[str]=None, merge_behavior: K8sConfigMergeBehavior=K8sConfigMergeBehavior.SHALLOW):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'This function is a utility for executing a Kubernetes job from within a Dagster op.\\n\\n    Args:\\n        image (str): The image in which to launch the k8s job.\\n        command (Optional[List[str]]): The command to run in the container within the launched\\n            k8s job. Default: None.\\n        args (Optional[List[str]]): The args for the command for the container. Default: None.\\n        namespace (Optional[str]): Override the kubernetes namespace in which to run the k8s job.\\n            Default: None.\\n        image_pull_policy (Optional[str]): Allows the image pull policy to be overridden, e.g. to\\n            facilitate local testing with `kind <https://kind.sigs.k8s.io/>`_. Default:\\n            ``\"Always\"``. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#updating-images.\\n        image_pull_secrets (Optional[List[Dict[str, str]]]): Optionally, a list of dicts, each of\\n            which corresponds to a Kubernetes ``LocalObjectReference`` (e.g.,\\n            ``{\\'name\\': \\'myRegistryName\\'}``). This allows you to specify the ```imagePullSecrets`` on\\n            a pod basis. Typically, these will be provided through the service account, when needed,\\n            and you will not need to pass this argument. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod\\n            and https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core\\n        service_account_name (Optional[str]): The name of the Kubernetes service account under which\\n            to run the Job. Defaults to \"default\"        env_config_maps (Optional[List[str]]): A list of custom ConfigMapEnvSource names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container\\n        env_secrets (Optional[List[str]]): A list of custom Secret names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        env_vars (Optional[List[str]]): A list of environment variables to inject into the Job.\\n            Default: ``[]``. See: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        volume_mounts (Optional[List[Permissive]]): A list of volume mounts to include in the job\\'s\\n            container. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core\\n        volumes (Optional[List[Permissive]]): A list of volumes to include in the Job\\'s Pod. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core\\n        labels (Optional[Dict[str, str]]): Additional labels that should be included in the Job\\'s Pod. See:\\n            https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\\n        resources (Optional[Dict[str, Any]]) Compute resource requirements for the container. See:\\n            https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\n        scheduler_name (Optional[str]): Use a custom Kubernetes scheduler for launched Pods. See:\\n            https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/\\n        load_incluster_config (bool): Whether the op is running within a k8s cluster. If ``True``,\\n            we assume the launcher is running within the target cluster and load config using\\n            ``kubernetes.config.load_incluster_config``. Otherwise, we will use the k8s config\\n            specified in ``kubeconfig_file`` (using ``kubernetes.config.load_kube_config``) or fall\\n            back to the default kubeconfig. Default: True,\\n        kubeconfig_file (Optional[str]): The kubeconfig file from which to load config. Defaults to\\n            using the default kubeconfig. Default: None.\\n        timeout (Optional[int]): Raise an exception if the op takes longer than this timeout in\\n            seconds to execute. Default: None.\\n        container_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s main container\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core).\\n            Keys can either snake_case or camelCase.Default: None.\\n        pod_template_spec_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s\\n            metadata (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        pod_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s pod spec\\n            (https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s metadata\\n            (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s job spec\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#jobspec-v1-batch).\\n            Keys can either snake_case or camelCase.Default: None.\\n        k8s_job_name (Optional[str]): Overrides the name of the the k8s job. If not set, will be set\\n            to a unique name based on the current run ID and the name of the calling op. If set,\\n            make sure that the passed in name is a valid Kubernetes job name that does not\\n            already exist in the cluster.\\n        merge_behavior (Optional[K8sConfigMergeBehavior]): How raw k8s config set on this op should\\n            be merged with any raw k8s config set on the code location that launched the op. By\\n            default, the value is K8sConfigMergeBehavior.SHALLOW, meaning that the two dictionaries\\n            are shallowly merged - any shared values in the dictionaries will be replaced by the\\n            values set on this op. Setting it to DEEP will recursively merge the two dictionaries,\\n            appending list fields together andmerging dictionary fields.\\n    '\n    run_container_context = K8sContainerContext.create_for_run(context.dagster_run, context.instance.run_launcher if isinstance(context.instance.run_launcher, K8sRunLauncher) else None, include_run_tags=False)\n    container_config = container_config.copy() if container_config else {}\n    if command:\n        container_config['command'] = command\n    op_container_context = K8sContainerContext(image_pull_policy=image_pull_policy, image_pull_secrets=image_pull_secrets, service_account_name=service_account_name, env_config_maps=env_config_maps, env_secrets=env_secrets, env_vars=env_vars, volume_mounts=volume_mounts, volumes=volumes, labels=labels, namespace=namespace, resources=resources, scheduler_name=scheduler_name, run_k8s_config=UserDefinedDagsterK8sConfig.from_dict({'container_config': container_config, 'pod_template_spec_metadata': pod_template_spec_metadata, 'pod_spec_config': pod_spec_config, 'job_metadata': job_metadata, 'job_spec_config': job_spec_config, 'merge_behavior': merge_behavior.value}))\n    container_context = run_container_context.merge(op_container_context)\n    namespace = container_context.namespace\n    user_defined_k8s_config = container_context.run_k8s_config\n    k8s_job_config = DagsterK8sJobConfig(job_image=image, dagster_home=None, image_pull_policy=container_context.image_pull_policy, image_pull_secrets=container_context.image_pull_secrets, service_account_name=container_context.service_account_name, instance_config_map=None, postgres_password_secret=None, env_config_maps=container_context.env_config_maps, env_secrets=container_context.env_secrets, env_vars=container_context.env_vars, volume_mounts=container_context.volume_mounts, volumes=container_context.volumes, labels=container_context.labels, resources=container_context.resources)\n    job_name = k8s_job_name or get_k8s_job_name(context.run_id, context.get_step_execution_context().step.key)\n    retry_number = context.retry_number\n    if retry_number > 0:\n        job_name = f'{job_name}-{retry_number}'\n    labels = {'dagster/job': context.dagster_run.job_name, 'dagster/op': context.op.name, 'dagster/run-id': context.dagster_run.run_id}\n    if context.dagster_run.external_job_origin:\n        labels['dagster/code-location'] = context.dagster_run.external_job_origin.external_repository_origin.code_location_origin.location_name\n    job = construct_dagster_k8s_job(job_config=k8s_job_config, args=args, job_name=job_name, pod_name=job_name, component='k8s_job_op', user_defined_k8s_config=user_defined_k8s_config, labels=labels)\n    if load_incluster_config:\n        kubernetes.config.load_incluster_config()\n    else:\n        kubernetes.config.load_kube_config(kubeconfig_file)\n    api_client = DagsterKubernetesClient.production_client()\n    context.log.info(f'Creating Kubernetes job {job_name} in namespace {namespace}...')\n    start_time = time.time()\n    api_client.batch_api.create_namespaced_job(namespace, job)\n    context.log.info('Waiting for Kubernetes job to finish...')\n    timeout = timeout or 0\n    api_client.wait_for_job(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time)\n    restart_policy = user_defined_k8s_config.pod_spec_config.get('restart_policy', 'Never')\n    if restart_policy == 'Never':\n        container_name = container_config.get('name', 'dagster')\n        pods = api_client.wait_for_job_to_have_pods(job_name, namespace, wait_timeout=timeout, start_time=start_time)\n        pod_names = [p.metadata.name for p in pods]\n        if not pod_names:\n            raise Exception('No pod names in job after it started')\n        pod_to_watch = pod_names[0]\n        watch = kubernetes.watch.Watch()\n        api_client.wait_for_pod(pod_to_watch, namespace, wait_timeout=timeout, start_time=start_time)\n        log_stream = watch.stream(api_client.core_api.read_namespaced_pod_log, name=pod_to_watch, namespace=namespace, container=container_name)\n        while True:\n            if timeout and time.time() - start_time > timeout:\n                watch.stop()\n                raise Exception('Timed out waiting for pod to finish')\n            try:\n                log_entry = next(log_stream)\n                print(log_entry)\n            except StopIteration:\n                break\n    else:\n        context.log.info('Pod logs are disabled, because restart_policy is not Never')\n    if job_spec_config and job_spec_config.get('parallelism'):\n        num_pods_to_wait_for = job_spec_config['parallelism']\n    else:\n        num_pods_to_wait_for = DEFAULT_JOB_POD_COUNT\n    api_client.wait_for_running_job_to_succeed(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time, num_pods_to_wait_for=num_pods_to_wait_for)",
            "@experimental\ndef execute_k8s_job(context: OpExecutionContext, image: str, command: Optional[List[str]]=None, args: Optional[List[str]]=None, namespace: Optional[str]=None, image_pull_policy: Optional[str]=None, image_pull_secrets: Optional[List[Dict[str, str]]]=None, service_account_name: Optional[str]=None, env_config_maps: Optional[List[str]]=None, env_secrets: Optional[List[str]]=None, env_vars: Optional[List[str]]=None, volume_mounts: Optional[List[Dict[str, Any]]]=None, volumes: Optional[List[Dict[str, Any]]]=None, labels: Optional[Dict[str, str]]=None, resources: Optional[Dict[str, Any]]=None, scheduler_name: Optional[str]=None, load_incluster_config: bool=True, kubeconfig_file: Optional[str]=None, timeout: Optional[int]=None, container_config: Optional[Dict[str, Any]]=None, pod_template_spec_metadata: Optional[Dict[str, Any]]=None, pod_spec_config: Optional[Dict[str, Any]]=None, job_metadata: Optional[Dict[str, Any]]=None, job_spec_config: Optional[Dict[str, Any]]=None, k8s_job_name: Optional[str]=None, merge_behavior: K8sConfigMergeBehavior=K8sConfigMergeBehavior.SHALLOW):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'This function is a utility for executing a Kubernetes job from within a Dagster op.\\n\\n    Args:\\n        image (str): The image in which to launch the k8s job.\\n        command (Optional[List[str]]): The command to run in the container within the launched\\n            k8s job. Default: None.\\n        args (Optional[List[str]]): The args for the command for the container. Default: None.\\n        namespace (Optional[str]): Override the kubernetes namespace in which to run the k8s job.\\n            Default: None.\\n        image_pull_policy (Optional[str]): Allows the image pull policy to be overridden, e.g. to\\n            facilitate local testing with `kind <https://kind.sigs.k8s.io/>`_. Default:\\n            ``\"Always\"``. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#updating-images.\\n        image_pull_secrets (Optional[List[Dict[str, str]]]): Optionally, a list of dicts, each of\\n            which corresponds to a Kubernetes ``LocalObjectReference`` (e.g.,\\n            ``{\\'name\\': \\'myRegistryName\\'}``). This allows you to specify the ```imagePullSecrets`` on\\n            a pod basis. Typically, these will be provided through the service account, when needed,\\n            and you will not need to pass this argument. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod\\n            and https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core\\n        service_account_name (Optional[str]): The name of the Kubernetes service account under which\\n            to run the Job. Defaults to \"default\"        env_config_maps (Optional[List[str]]): A list of custom ConfigMapEnvSource names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container\\n        env_secrets (Optional[List[str]]): A list of custom Secret names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        env_vars (Optional[List[str]]): A list of environment variables to inject into the Job.\\n            Default: ``[]``. See: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        volume_mounts (Optional[List[Permissive]]): A list of volume mounts to include in the job\\'s\\n            container. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core\\n        volumes (Optional[List[Permissive]]): A list of volumes to include in the Job\\'s Pod. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core\\n        labels (Optional[Dict[str, str]]): Additional labels that should be included in the Job\\'s Pod. See:\\n            https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\\n        resources (Optional[Dict[str, Any]]) Compute resource requirements for the container. See:\\n            https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\n        scheduler_name (Optional[str]): Use a custom Kubernetes scheduler for launched Pods. See:\\n            https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/\\n        load_incluster_config (bool): Whether the op is running within a k8s cluster. If ``True``,\\n            we assume the launcher is running within the target cluster and load config using\\n            ``kubernetes.config.load_incluster_config``. Otherwise, we will use the k8s config\\n            specified in ``kubeconfig_file`` (using ``kubernetes.config.load_kube_config``) or fall\\n            back to the default kubeconfig. Default: True,\\n        kubeconfig_file (Optional[str]): The kubeconfig file from which to load config. Defaults to\\n            using the default kubeconfig. Default: None.\\n        timeout (Optional[int]): Raise an exception if the op takes longer than this timeout in\\n            seconds to execute. Default: None.\\n        container_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s main container\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core).\\n            Keys can either snake_case or camelCase.Default: None.\\n        pod_template_spec_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s\\n            metadata (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        pod_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s pod spec\\n            (https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s metadata\\n            (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s job spec\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#jobspec-v1-batch).\\n            Keys can either snake_case or camelCase.Default: None.\\n        k8s_job_name (Optional[str]): Overrides the name of the the k8s job. If not set, will be set\\n            to a unique name based on the current run ID and the name of the calling op. If set,\\n            make sure that the passed in name is a valid Kubernetes job name that does not\\n            already exist in the cluster.\\n        merge_behavior (Optional[K8sConfigMergeBehavior]): How raw k8s config set on this op should\\n            be merged with any raw k8s config set on the code location that launched the op. By\\n            default, the value is K8sConfigMergeBehavior.SHALLOW, meaning that the two dictionaries\\n            are shallowly merged - any shared values in the dictionaries will be replaced by the\\n            values set on this op. Setting it to DEEP will recursively merge the two dictionaries,\\n            appending list fields together andmerging dictionary fields.\\n    '\n    run_container_context = K8sContainerContext.create_for_run(context.dagster_run, context.instance.run_launcher if isinstance(context.instance.run_launcher, K8sRunLauncher) else None, include_run_tags=False)\n    container_config = container_config.copy() if container_config else {}\n    if command:\n        container_config['command'] = command\n    op_container_context = K8sContainerContext(image_pull_policy=image_pull_policy, image_pull_secrets=image_pull_secrets, service_account_name=service_account_name, env_config_maps=env_config_maps, env_secrets=env_secrets, env_vars=env_vars, volume_mounts=volume_mounts, volumes=volumes, labels=labels, namespace=namespace, resources=resources, scheduler_name=scheduler_name, run_k8s_config=UserDefinedDagsterK8sConfig.from_dict({'container_config': container_config, 'pod_template_spec_metadata': pod_template_spec_metadata, 'pod_spec_config': pod_spec_config, 'job_metadata': job_metadata, 'job_spec_config': job_spec_config, 'merge_behavior': merge_behavior.value}))\n    container_context = run_container_context.merge(op_container_context)\n    namespace = container_context.namespace\n    user_defined_k8s_config = container_context.run_k8s_config\n    k8s_job_config = DagsterK8sJobConfig(job_image=image, dagster_home=None, image_pull_policy=container_context.image_pull_policy, image_pull_secrets=container_context.image_pull_secrets, service_account_name=container_context.service_account_name, instance_config_map=None, postgres_password_secret=None, env_config_maps=container_context.env_config_maps, env_secrets=container_context.env_secrets, env_vars=container_context.env_vars, volume_mounts=container_context.volume_mounts, volumes=container_context.volumes, labels=container_context.labels, resources=container_context.resources)\n    job_name = k8s_job_name or get_k8s_job_name(context.run_id, context.get_step_execution_context().step.key)\n    retry_number = context.retry_number\n    if retry_number > 0:\n        job_name = f'{job_name}-{retry_number}'\n    labels = {'dagster/job': context.dagster_run.job_name, 'dagster/op': context.op.name, 'dagster/run-id': context.dagster_run.run_id}\n    if context.dagster_run.external_job_origin:\n        labels['dagster/code-location'] = context.dagster_run.external_job_origin.external_repository_origin.code_location_origin.location_name\n    job = construct_dagster_k8s_job(job_config=k8s_job_config, args=args, job_name=job_name, pod_name=job_name, component='k8s_job_op', user_defined_k8s_config=user_defined_k8s_config, labels=labels)\n    if load_incluster_config:\n        kubernetes.config.load_incluster_config()\n    else:\n        kubernetes.config.load_kube_config(kubeconfig_file)\n    api_client = DagsterKubernetesClient.production_client()\n    context.log.info(f'Creating Kubernetes job {job_name} in namespace {namespace}...')\n    start_time = time.time()\n    api_client.batch_api.create_namespaced_job(namespace, job)\n    context.log.info('Waiting for Kubernetes job to finish...')\n    timeout = timeout or 0\n    api_client.wait_for_job(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time)\n    restart_policy = user_defined_k8s_config.pod_spec_config.get('restart_policy', 'Never')\n    if restart_policy == 'Never':\n        container_name = container_config.get('name', 'dagster')\n        pods = api_client.wait_for_job_to_have_pods(job_name, namespace, wait_timeout=timeout, start_time=start_time)\n        pod_names = [p.metadata.name for p in pods]\n        if not pod_names:\n            raise Exception('No pod names in job after it started')\n        pod_to_watch = pod_names[0]\n        watch = kubernetes.watch.Watch()\n        api_client.wait_for_pod(pod_to_watch, namespace, wait_timeout=timeout, start_time=start_time)\n        log_stream = watch.stream(api_client.core_api.read_namespaced_pod_log, name=pod_to_watch, namespace=namespace, container=container_name)\n        while True:\n            if timeout and time.time() - start_time > timeout:\n                watch.stop()\n                raise Exception('Timed out waiting for pod to finish')\n            try:\n                log_entry = next(log_stream)\n                print(log_entry)\n            except StopIteration:\n                break\n    else:\n        context.log.info('Pod logs are disabled, because restart_policy is not Never')\n    if job_spec_config and job_spec_config.get('parallelism'):\n        num_pods_to_wait_for = job_spec_config['parallelism']\n    else:\n        num_pods_to_wait_for = DEFAULT_JOB_POD_COUNT\n    api_client.wait_for_running_job_to_succeed(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time, num_pods_to_wait_for=num_pods_to_wait_for)",
            "@experimental\ndef execute_k8s_job(context: OpExecutionContext, image: str, command: Optional[List[str]]=None, args: Optional[List[str]]=None, namespace: Optional[str]=None, image_pull_policy: Optional[str]=None, image_pull_secrets: Optional[List[Dict[str, str]]]=None, service_account_name: Optional[str]=None, env_config_maps: Optional[List[str]]=None, env_secrets: Optional[List[str]]=None, env_vars: Optional[List[str]]=None, volume_mounts: Optional[List[Dict[str, Any]]]=None, volumes: Optional[List[Dict[str, Any]]]=None, labels: Optional[Dict[str, str]]=None, resources: Optional[Dict[str, Any]]=None, scheduler_name: Optional[str]=None, load_incluster_config: bool=True, kubeconfig_file: Optional[str]=None, timeout: Optional[int]=None, container_config: Optional[Dict[str, Any]]=None, pod_template_spec_metadata: Optional[Dict[str, Any]]=None, pod_spec_config: Optional[Dict[str, Any]]=None, job_metadata: Optional[Dict[str, Any]]=None, job_spec_config: Optional[Dict[str, Any]]=None, k8s_job_name: Optional[str]=None, merge_behavior: K8sConfigMergeBehavior=K8sConfigMergeBehavior.SHALLOW):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'This function is a utility for executing a Kubernetes job from within a Dagster op.\\n\\n    Args:\\n        image (str): The image in which to launch the k8s job.\\n        command (Optional[List[str]]): The command to run in the container within the launched\\n            k8s job. Default: None.\\n        args (Optional[List[str]]): The args for the command for the container. Default: None.\\n        namespace (Optional[str]): Override the kubernetes namespace in which to run the k8s job.\\n            Default: None.\\n        image_pull_policy (Optional[str]): Allows the image pull policy to be overridden, e.g. to\\n            facilitate local testing with `kind <https://kind.sigs.k8s.io/>`_. Default:\\n            ``\"Always\"``. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#updating-images.\\n        image_pull_secrets (Optional[List[Dict[str, str]]]): Optionally, a list of dicts, each of\\n            which corresponds to a Kubernetes ``LocalObjectReference`` (e.g.,\\n            ``{\\'name\\': \\'myRegistryName\\'}``). This allows you to specify the ```imagePullSecrets`` on\\n            a pod basis. Typically, these will be provided through the service account, when needed,\\n            and you will not need to pass this argument. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod\\n            and https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core\\n        service_account_name (Optional[str]): The name of the Kubernetes service account under which\\n            to run the Job. Defaults to \"default\"        env_config_maps (Optional[List[str]]): A list of custom ConfigMapEnvSource names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container\\n        env_secrets (Optional[List[str]]): A list of custom Secret names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        env_vars (Optional[List[str]]): A list of environment variables to inject into the Job.\\n            Default: ``[]``. See: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        volume_mounts (Optional[List[Permissive]]): A list of volume mounts to include in the job\\'s\\n            container. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core\\n        volumes (Optional[List[Permissive]]): A list of volumes to include in the Job\\'s Pod. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core\\n        labels (Optional[Dict[str, str]]): Additional labels that should be included in the Job\\'s Pod. See:\\n            https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\\n        resources (Optional[Dict[str, Any]]) Compute resource requirements for the container. See:\\n            https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\n        scheduler_name (Optional[str]): Use a custom Kubernetes scheduler for launched Pods. See:\\n            https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/\\n        load_incluster_config (bool): Whether the op is running within a k8s cluster. If ``True``,\\n            we assume the launcher is running within the target cluster and load config using\\n            ``kubernetes.config.load_incluster_config``. Otherwise, we will use the k8s config\\n            specified in ``kubeconfig_file`` (using ``kubernetes.config.load_kube_config``) or fall\\n            back to the default kubeconfig. Default: True,\\n        kubeconfig_file (Optional[str]): The kubeconfig file from which to load config. Defaults to\\n            using the default kubeconfig. Default: None.\\n        timeout (Optional[int]): Raise an exception if the op takes longer than this timeout in\\n            seconds to execute. Default: None.\\n        container_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s main container\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core).\\n            Keys can either snake_case or camelCase.Default: None.\\n        pod_template_spec_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s\\n            metadata (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        pod_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s pod spec\\n            (https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s metadata\\n            (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s job spec\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#jobspec-v1-batch).\\n            Keys can either snake_case or camelCase.Default: None.\\n        k8s_job_name (Optional[str]): Overrides the name of the the k8s job. If not set, will be set\\n            to a unique name based on the current run ID and the name of the calling op. If set,\\n            make sure that the passed in name is a valid Kubernetes job name that does not\\n            already exist in the cluster.\\n        merge_behavior (Optional[K8sConfigMergeBehavior]): How raw k8s config set on this op should\\n            be merged with any raw k8s config set on the code location that launched the op. By\\n            default, the value is K8sConfigMergeBehavior.SHALLOW, meaning that the two dictionaries\\n            are shallowly merged - any shared values in the dictionaries will be replaced by the\\n            values set on this op. Setting it to DEEP will recursively merge the two dictionaries,\\n            appending list fields together andmerging dictionary fields.\\n    '\n    run_container_context = K8sContainerContext.create_for_run(context.dagster_run, context.instance.run_launcher if isinstance(context.instance.run_launcher, K8sRunLauncher) else None, include_run_tags=False)\n    container_config = container_config.copy() if container_config else {}\n    if command:\n        container_config['command'] = command\n    op_container_context = K8sContainerContext(image_pull_policy=image_pull_policy, image_pull_secrets=image_pull_secrets, service_account_name=service_account_name, env_config_maps=env_config_maps, env_secrets=env_secrets, env_vars=env_vars, volume_mounts=volume_mounts, volumes=volumes, labels=labels, namespace=namespace, resources=resources, scheduler_name=scheduler_name, run_k8s_config=UserDefinedDagsterK8sConfig.from_dict({'container_config': container_config, 'pod_template_spec_metadata': pod_template_spec_metadata, 'pod_spec_config': pod_spec_config, 'job_metadata': job_metadata, 'job_spec_config': job_spec_config, 'merge_behavior': merge_behavior.value}))\n    container_context = run_container_context.merge(op_container_context)\n    namespace = container_context.namespace\n    user_defined_k8s_config = container_context.run_k8s_config\n    k8s_job_config = DagsterK8sJobConfig(job_image=image, dagster_home=None, image_pull_policy=container_context.image_pull_policy, image_pull_secrets=container_context.image_pull_secrets, service_account_name=container_context.service_account_name, instance_config_map=None, postgres_password_secret=None, env_config_maps=container_context.env_config_maps, env_secrets=container_context.env_secrets, env_vars=container_context.env_vars, volume_mounts=container_context.volume_mounts, volumes=container_context.volumes, labels=container_context.labels, resources=container_context.resources)\n    job_name = k8s_job_name or get_k8s_job_name(context.run_id, context.get_step_execution_context().step.key)\n    retry_number = context.retry_number\n    if retry_number > 0:\n        job_name = f'{job_name}-{retry_number}'\n    labels = {'dagster/job': context.dagster_run.job_name, 'dagster/op': context.op.name, 'dagster/run-id': context.dagster_run.run_id}\n    if context.dagster_run.external_job_origin:\n        labels['dagster/code-location'] = context.dagster_run.external_job_origin.external_repository_origin.code_location_origin.location_name\n    job = construct_dagster_k8s_job(job_config=k8s_job_config, args=args, job_name=job_name, pod_name=job_name, component='k8s_job_op', user_defined_k8s_config=user_defined_k8s_config, labels=labels)\n    if load_incluster_config:\n        kubernetes.config.load_incluster_config()\n    else:\n        kubernetes.config.load_kube_config(kubeconfig_file)\n    api_client = DagsterKubernetesClient.production_client()\n    context.log.info(f'Creating Kubernetes job {job_name} in namespace {namespace}...')\n    start_time = time.time()\n    api_client.batch_api.create_namespaced_job(namespace, job)\n    context.log.info('Waiting for Kubernetes job to finish...')\n    timeout = timeout or 0\n    api_client.wait_for_job(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time)\n    restart_policy = user_defined_k8s_config.pod_spec_config.get('restart_policy', 'Never')\n    if restart_policy == 'Never':\n        container_name = container_config.get('name', 'dagster')\n        pods = api_client.wait_for_job_to_have_pods(job_name, namespace, wait_timeout=timeout, start_time=start_time)\n        pod_names = [p.metadata.name for p in pods]\n        if not pod_names:\n            raise Exception('No pod names in job after it started')\n        pod_to_watch = pod_names[0]\n        watch = kubernetes.watch.Watch()\n        api_client.wait_for_pod(pod_to_watch, namespace, wait_timeout=timeout, start_time=start_time)\n        log_stream = watch.stream(api_client.core_api.read_namespaced_pod_log, name=pod_to_watch, namespace=namespace, container=container_name)\n        while True:\n            if timeout and time.time() - start_time > timeout:\n                watch.stop()\n                raise Exception('Timed out waiting for pod to finish')\n            try:\n                log_entry = next(log_stream)\n                print(log_entry)\n            except StopIteration:\n                break\n    else:\n        context.log.info('Pod logs are disabled, because restart_policy is not Never')\n    if job_spec_config and job_spec_config.get('parallelism'):\n        num_pods_to_wait_for = job_spec_config['parallelism']\n    else:\n        num_pods_to_wait_for = DEFAULT_JOB_POD_COUNT\n    api_client.wait_for_running_job_to_succeed(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time, num_pods_to_wait_for=num_pods_to_wait_for)",
            "@experimental\ndef execute_k8s_job(context: OpExecutionContext, image: str, command: Optional[List[str]]=None, args: Optional[List[str]]=None, namespace: Optional[str]=None, image_pull_policy: Optional[str]=None, image_pull_secrets: Optional[List[Dict[str, str]]]=None, service_account_name: Optional[str]=None, env_config_maps: Optional[List[str]]=None, env_secrets: Optional[List[str]]=None, env_vars: Optional[List[str]]=None, volume_mounts: Optional[List[Dict[str, Any]]]=None, volumes: Optional[List[Dict[str, Any]]]=None, labels: Optional[Dict[str, str]]=None, resources: Optional[Dict[str, Any]]=None, scheduler_name: Optional[str]=None, load_incluster_config: bool=True, kubeconfig_file: Optional[str]=None, timeout: Optional[int]=None, container_config: Optional[Dict[str, Any]]=None, pod_template_spec_metadata: Optional[Dict[str, Any]]=None, pod_spec_config: Optional[Dict[str, Any]]=None, job_metadata: Optional[Dict[str, Any]]=None, job_spec_config: Optional[Dict[str, Any]]=None, k8s_job_name: Optional[str]=None, merge_behavior: K8sConfigMergeBehavior=K8sConfigMergeBehavior.SHALLOW):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'This function is a utility for executing a Kubernetes job from within a Dagster op.\\n\\n    Args:\\n        image (str): The image in which to launch the k8s job.\\n        command (Optional[List[str]]): The command to run in the container within the launched\\n            k8s job. Default: None.\\n        args (Optional[List[str]]): The args for the command for the container. Default: None.\\n        namespace (Optional[str]): Override the kubernetes namespace in which to run the k8s job.\\n            Default: None.\\n        image_pull_policy (Optional[str]): Allows the image pull policy to be overridden, e.g. to\\n            facilitate local testing with `kind <https://kind.sigs.k8s.io/>`_. Default:\\n            ``\"Always\"``. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#updating-images.\\n        image_pull_secrets (Optional[List[Dict[str, str]]]): Optionally, a list of dicts, each of\\n            which corresponds to a Kubernetes ``LocalObjectReference`` (e.g.,\\n            ``{\\'name\\': \\'myRegistryName\\'}``). This allows you to specify the ```imagePullSecrets`` on\\n            a pod basis. Typically, these will be provided through the service account, when needed,\\n            and you will not need to pass this argument. See:\\n            https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod\\n            and https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podspec-v1-core\\n        service_account_name (Optional[str]): The name of the Kubernetes service account under which\\n            to run the Job. Defaults to \"default\"        env_config_maps (Optional[List[str]]): A list of custom ConfigMapEnvSource names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container\\n        env_secrets (Optional[List[str]]): A list of custom Secret names from which to\\n            draw environment variables (using ``envFrom``) for the Job. Default: ``[]``. See:\\n            https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        env_vars (Optional[List[str]]): A list of environment variables to inject into the Job.\\n            Default: ``[]``. See: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables\\n        volume_mounts (Optional[List[Permissive]]): A list of volume mounts to include in the job\\'s\\n            container. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core\\n        volumes (Optional[List[Permissive]]): A list of volumes to include in the Job\\'s Pod. Default: ``[]``. See:\\n            https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core\\n        labels (Optional[Dict[str, str]]): Additional labels that should be included in the Job\\'s Pod. See:\\n            https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\\n        resources (Optional[Dict[str, Any]]) Compute resource requirements for the container. See:\\n            https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\n        scheduler_name (Optional[str]): Use a custom Kubernetes scheduler for launched Pods. See:\\n            https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/\\n        load_incluster_config (bool): Whether the op is running within a k8s cluster. If ``True``,\\n            we assume the launcher is running within the target cluster and load config using\\n            ``kubernetes.config.load_incluster_config``. Otherwise, we will use the k8s config\\n            specified in ``kubeconfig_file`` (using ``kubernetes.config.load_kube_config``) or fall\\n            back to the default kubeconfig. Default: True,\\n        kubeconfig_file (Optional[str]): The kubeconfig file from which to load config. Defaults to\\n            using the default kubeconfig. Default: None.\\n        timeout (Optional[int]): Raise an exception if the op takes longer than this timeout in\\n            seconds to execute. Default: None.\\n        container_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s main container\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#container-v1-core).\\n            Keys can either snake_case or camelCase.Default: None.\\n        pod_template_spec_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s\\n            metadata (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        pod_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s pod\\'s pod spec\\n            (https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_metadata (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s metadata\\n            (https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/object-meta/#ObjectMeta).\\n            Keys can either snake_case or camelCase. Default: None.\\n        job_spec_config (Optional[Dict[str, Any]]): Raw k8s config for the k8s job\\'s job spec\\n            (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#jobspec-v1-batch).\\n            Keys can either snake_case or camelCase.Default: None.\\n        k8s_job_name (Optional[str]): Overrides the name of the the k8s job. If not set, will be set\\n            to a unique name based on the current run ID and the name of the calling op. If set,\\n            make sure that the passed in name is a valid Kubernetes job name that does not\\n            already exist in the cluster.\\n        merge_behavior (Optional[K8sConfigMergeBehavior]): How raw k8s config set on this op should\\n            be merged with any raw k8s config set on the code location that launched the op. By\\n            default, the value is K8sConfigMergeBehavior.SHALLOW, meaning that the two dictionaries\\n            are shallowly merged - any shared values in the dictionaries will be replaced by the\\n            values set on this op. Setting it to DEEP will recursively merge the two dictionaries,\\n            appending list fields together andmerging dictionary fields.\\n    '\n    run_container_context = K8sContainerContext.create_for_run(context.dagster_run, context.instance.run_launcher if isinstance(context.instance.run_launcher, K8sRunLauncher) else None, include_run_tags=False)\n    container_config = container_config.copy() if container_config else {}\n    if command:\n        container_config['command'] = command\n    op_container_context = K8sContainerContext(image_pull_policy=image_pull_policy, image_pull_secrets=image_pull_secrets, service_account_name=service_account_name, env_config_maps=env_config_maps, env_secrets=env_secrets, env_vars=env_vars, volume_mounts=volume_mounts, volumes=volumes, labels=labels, namespace=namespace, resources=resources, scheduler_name=scheduler_name, run_k8s_config=UserDefinedDagsterK8sConfig.from_dict({'container_config': container_config, 'pod_template_spec_metadata': pod_template_spec_metadata, 'pod_spec_config': pod_spec_config, 'job_metadata': job_metadata, 'job_spec_config': job_spec_config, 'merge_behavior': merge_behavior.value}))\n    container_context = run_container_context.merge(op_container_context)\n    namespace = container_context.namespace\n    user_defined_k8s_config = container_context.run_k8s_config\n    k8s_job_config = DagsterK8sJobConfig(job_image=image, dagster_home=None, image_pull_policy=container_context.image_pull_policy, image_pull_secrets=container_context.image_pull_secrets, service_account_name=container_context.service_account_name, instance_config_map=None, postgres_password_secret=None, env_config_maps=container_context.env_config_maps, env_secrets=container_context.env_secrets, env_vars=container_context.env_vars, volume_mounts=container_context.volume_mounts, volumes=container_context.volumes, labels=container_context.labels, resources=container_context.resources)\n    job_name = k8s_job_name or get_k8s_job_name(context.run_id, context.get_step_execution_context().step.key)\n    retry_number = context.retry_number\n    if retry_number > 0:\n        job_name = f'{job_name}-{retry_number}'\n    labels = {'dagster/job': context.dagster_run.job_name, 'dagster/op': context.op.name, 'dagster/run-id': context.dagster_run.run_id}\n    if context.dagster_run.external_job_origin:\n        labels['dagster/code-location'] = context.dagster_run.external_job_origin.external_repository_origin.code_location_origin.location_name\n    job = construct_dagster_k8s_job(job_config=k8s_job_config, args=args, job_name=job_name, pod_name=job_name, component='k8s_job_op', user_defined_k8s_config=user_defined_k8s_config, labels=labels)\n    if load_incluster_config:\n        kubernetes.config.load_incluster_config()\n    else:\n        kubernetes.config.load_kube_config(kubeconfig_file)\n    api_client = DagsterKubernetesClient.production_client()\n    context.log.info(f'Creating Kubernetes job {job_name} in namespace {namespace}...')\n    start_time = time.time()\n    api_client.batch_api.create_namespaced_job(namespace, job)\n    context.log.info('Waiting for Kubernetes job to finish...')\n    timeout = timeout or 0\n    api_client.wait_for_job(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time)\n    restart_policy = user_defined_k8s_config.pod_spec_config.get('restart_policy', 'Never')\n    if restart_policy == 'Never':\n        container_name = container_config.get('name', 'dagster')\n        pods = api_client.wait_for_job_to_have_pods(job_name, namespace, wait_timeout=timeout, start_time=start_time)\n        pod_names = [p.metadata.name for p in pods]\n        if not pod_names:\n            raise Exception('No pod names in job after it started')\n        pod_to_watch = pod_names[0]\n        watch = kubernetes.watch.Watch()\n        api_client.wait_for_pod(pod_to_watch, namespace, wait_timeout=timeout, start_time=start_time)\n        log_stream = watch.stream(api_client.core_api.read_namespaced_pod_log, name=pod_to_watch, namespace=namespace, container=container_name)\n        while True:\n            if timeout and time.time() - start_time > timeout:\n                watch.stop()\n                raise Exception('Timed out waiting for pod to finish')\n            try:\n                log_entry = next(log_stream)\n                print(log_entry)\n            except StopIteration:\n                break\n    else:\n        context.log.info('Pod logs are disabled, because restart_policy is not Never')\n    if job_spec_config and job_spec_config.get('parallelism'):\n        num_pods_to_wait_for = job_spec_config['parallelism']\n    else:\n        num_pods_to_wait_for = DEFAULT_JOB_POD_COUNT\n    api_client.wait_for_running_job_to_succeed(job_name=job_name, namespace=namespace, wait_timeout=timeout, start_time=start_time, num_pods_to_wait_for=num_pods_to_wait_for)"
        ]
    },
    {
        "func_name": "k8s_job_op",
        "original": "@op(ins={'start_after': In(Nothing)}, config_schema=K8S_JOB_OP_CONFIG)\n@experimental\ndef k8s_job_op(context):\n    \"\"\"An op that runs a Kubernetes job using the k8s API.\n\n    Contrast with the `k8s_job_executor`, which runs each Dagster op in a Dagster job in its\n    own k8s job.\n\n    This op may be useful when:\n      - You need to orchestrate a command that isn't a Dagster op (or isn't written in Python)\n      - You want to run the rest of a Dagster job using a specific executor, and only a single\n        op in k8s.\n\n    For example:\n\n    .. literalinclude:: ../../../../../../python_modules/libraries/dagster-k8s/dagster_k8s_tests/unit_tests/test_example_k8s_job_op.py\n      :start-after: start_marker\n      :end-before: end_marker\n      :language: python\n\n    You can create your own op with the same implementation by calling the `execute_k8s_job` function\n    inside your own op.\n\n    The service account that is used to run this job should have the following RBAC permissions:\n\n    .. literalinclude:: ../../../../../../examples/docs_snippets/docs_snippets/deploying/kubernetes/k8s_job_op_rbac.yaml\n       :language: YAML\n    \"\"\"\n    if 'merge_behavior' in context.op_config:\n        merge_behavior = K8sConfigMergeBehavior(context.op_config.pop('merge_behavior'))\n    else:\n        merge_behavior = K8sConfigMergeBehavior.SHALLOW\n    execute_k8s_job(context, merge_behavior=merge_behavior, **context.op_config)",
        "mutated": [
            "@op(ins={'start_after': In(Nothing)}, config_schema=K8S_JOB_OP_CONFIG)\n@experimental\ndef k8s_job_op(context):\n    if False:\n        i = 10\n    \"An op that runs a Kubernetes job using the k8s API.\\n\\n    Contrast with the `k8s_job_executor`, which runs each Dagster op in a Dagster job in its\\n    own k8s job.\\n\\n    This op may be useful when:\\n      - You need to orchestrate a command that isn't a Dagster op (or isn't written in Python)\\n      - You want to run the rest of a Dagster job using a specific executor, and only a single\\n        op in k8s.\\n\\n    For example:\\n\\n    .. literalinclude:: ../../../../../../python_modules/libraries/dagster-k8s/dagster_k8s_tests/unit_tests/test_example_k8s_job_op.py\\n      :start-after: start_marker\\n      :end-before: end_marker\\n      :language: python\\n\\n    You can create your own op with the same implementation by calling the `execute_k8s_job` function\\n    inside your own op.\\n\\n    The service account that is used to run this job should have the following RBAC permissions:\\n\\n    .. literalinclude:: ../../../../../../examples/docs_snippets/docs_snippets/deploying/kubernetes/k8s_job_op_rbac.yaml\\n       :language: YAML\\n    \"\n    if 'merge_behavior' in context.op_config:\n        merge_behavior = K8sConfigMergeBehavior(context.op_config.pop('merge_behavior'))\n    else:\n        merge_behavior = K8sConfigMergeBehavior.SHALLOW\n    execute_k8s_job(context, merge_behavior=merge_behavior, **context.op_config)",
            "@op(ins={'start_after': In(Nothing)}, config_schema=K8S_JOB_OP_CONFIG)\n@experimental\ndef k8s_job_op(context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"An op that runs a Kubernetes job using the k8s API.\\n\\n    Contrast with the `k8s_job_executor`, which runs each Dagster op in a Dagster job in its\\n    own k8s job.\\n\\n    This op may be useful when:\\n      - You need to orchestrate a command that isn't a Dagster op (or isn't written in Python)\\n      - You want to run the rest of a Dagster job using a specific executor, and only a single\\n        op in k8s.\\n\\n    For example:\\n\\n    .. literalinclude:: ../../../../../../python_modules/libraries/dagster-k8s/dagster_k8s_tests/unit_tests/test_example_k8s_job_op.py\\n      :start-after: start_marker\\n      :end-before: end_marker\\n      :language: python\\n\\n    You can create your own op with the same implementation by calling the `execute_k8s_job` function\\n    inside your own op.\\n\\n    The service account that is used to run this job should have the following RBAC permissions:\\n\\n    .. literalinclude:: ../../../../../../examples/docs_snippets/docs_snippets/deploying/kubernetes/k8s_job_op_rbac.yaml\\n       :language: YAML\\n    \"\n    if 'merge_behavior' in context.op_config:\n        merge_behavior = K8sConfigMergeBehavior(context.op_config.pop('merge_behavior'))\n    else:\n        merge_behavior = K8sConfigMergeBehavior.SHALLOW\n    execute_k8s_job(context, merge_behavior=merge_behavior, **context.op_config)",
            "@op(ins={'start_after': In(Nothing)}, config_schema=K8S_JOB_OP_CONFIG)\n@experimental\ndef k8s_job_op(context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"An op that runs a Kubernetes job using the k8s API.\\n\\n    Contrast with the `k8s_job_executor`, which runs each Dagster op in a Dagster job in its\\n    own k8s job.\\n\\n    This op may be useful when:\\n      - You need to orchestrate a command that isn't a Dagster op (or isn't written in Python)\\n      - You want to run the rest of a Dagster job using a specific executor, and only a single\\n        op in k8s.\\n\\n    For example:\\n\\n    .. literalinclude:: ../../../../../../python_modules/libraries/dagster-k8s/dagster_k8s_tests/unit_tests/test_example_k8s_job_op.py\\n      :start-after: start_marker\\n      :end-before: end_marker\\n      :language: python\\n\\n    You can create your own op with the same implementation by calling the `execute_k8s_job` function\\n    inside your own op.\\n\\n    The service account that is used to run this job should have the following RBAC permissions:\\n\\n    .. literalinclude:: ../../../../../../examples/docs_snippets/docs_snippets/deploying/kubernetes/k8s_job_op_rbac.yaml\\n       :language: YAML\\n    \"\n    if 'merge_behavior' in context.op_config:\n        merge_behavior = K8sConfigMergeBehavior(context.op_config.pop('merge_behavior'))\n    else:\n        merge_behavior = K8sConfigMergeBehavior.SHALLOW\n    execute_k8s_job(context, merge_behavior=merge_behavior, **context.op_config)",
            "@op(ins={'start_after': In(Nothing)}, config_schema=K8S_JOB_OP_CONFIG)\n@experimental\ndef k8s_job_op(context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"An op that runs a Kubernetes job using the k8s API.\\n\\n    Contrast with the `k8s_job_executor`, which runs each Dagster op in a Dagster job in its\\n    own k8s job.\\n\\n    This op may be useful when:\\n      - You need to orchestrate a command that isn't a Dagster op (or isn't written in Python)\\n      - You want to run the rest of a Dagster job using a specific executor, and only a single\\n        op in k8s.\\n\\n    For example:\\n\\n    .. literalinclude:: ../../../../../../python_modules/libraries/dagster-k8s/dagster_k8s_tests/unit_tests/test_example_k8s_job_op.py\\n      :start-after: start_marker\\n      :end-before: end_marker\\n      :language: python\\n\\n    You can create your own op with the same implementation by calling the `execute_k8s_job` function\\n    inside your own op.\\n\\n    The service account that is used to run this job should have the following RBAC permissions:\\n\\n    .. literalinclude:: ../../../../../../examples/docs_snippets/docs_snippets/deploying/kubernetes/k8s_job_op_rbac.yaml\\n       :language: YAML\\n    \"\n    if 'merge_behavior' in context.op_config:\n        merge_behavior = K8sConfigMergeBehavior(context.op_config.pop('merge_behavior'))\n    else:\n        merge_behavior = K8sConfigMergeBehavior.SHALLOW\n    execute_k8s_job(context, merge_behavior=merge_behavior, **context.op_config)",
            "@op(ins={'start_after': In(Nothing)}, config_schema=K8S_JOB_OP_CONFIG)\n@experimental\ndef k8s_job_op(context):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"An op that runs a Kubernetes job using the k8s API.\\n\\n    Contrast with the `k8s_job_executor`, which runs each Dagster op in a Dagster job in its\\n    own k8s job.\\n\\n    This op may be useful when:\\n      - You need to orchestrate a command that isn't a Dagster op (or isn't written in Python)\\n      - You want to run the rest of a Dagster job using a specific executor, and only a single\\n        op in k8s.\\n\\n    For example:\\n\\n    .. literalinclude:: ../../../../../../python_modules/libraries/dagster-k8s/dagster_k8s_tests/unit_tests/test_example_k8s_job_op.py\\n      :start-after: start_marker\\n      :end-before: end_marker\\n      :language: python\\n\\n    You can create your own op with the same implementation by calling the `execute_k8s_job` function\\n    inside your own op.\\n\\n    The service account that is used to run this job should have the following RBAC permissions:\\n\\n    .. literalinclude:: ../../../../../../examples/docs_snippets/docs_snippets/deploying/kubernetes/k8s_job_op_rbac.yaml\\n       :language: YAML\\n    \"\n    if 'merge_behavior' in context.op_config:\n        merge_behavior = K8sConfigMergeBehavior(context.op_config.pop('merge_behavior'))\n    else:\n        merge_behavior = K8sConfigMergeBehavior.SHALLOW\n    execute_k8s_job(context, merge_behavior=merge_behavior, **context.op_config)"
        ]
    }
]