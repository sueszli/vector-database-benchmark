[
    {
        "func_name": "score_estimator",
        "original": "def score_estimator(estimator, df_test):\n    \"\"\"Score an estimator on the test set.\"\"\"\n    y_pred = estimator.predict(df_test)\n    print('MSE: %.3f' % mean_squared_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    print('MAE: %.3f' % mean_absolute_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    mask = y_pred > 0\n    if (~mask).any():\n        (n_masked, n_samples) = ((~mask).sum(), mask.shape[0])\n        print(f'WARNING: Estimator yields invalid, non-positive predictions  for {n_masked} samples out of {n_samples}. These predictions are ignored when computing the Poisson deviance.')\n    print('mean Poisson deviance: %.3f' % mean_poisson_deviance(df_test['Frequency'][mask], y_pred[mask], sample_weight=df_test['Exposure'][mask]))",
        "mutated": [
            "def score_estimator(estimator, df_test):\n    if False:\n        i = 10\n    'Score an estimator on the test set.'\n    y_pred = estimator.predict(df_test)\n    print('MSE: %.3f' % mean_squared_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    print('MAE: %.3f' % mean_absolute_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    mask = y_pred > 0\n    if (~mask).any():\n        (n_masked, n_samples) = ((~mask).sum(), mask.shape[0])\n        print(f'WARNING: Estimator yields invalid, non-positive predictions  for {n_masked} samples out of {n_samples}. These predictions are ignored when computing the Poisson deviance.')\n    print('mean Poisson deviance: %.3f' % mean_poisson_deviance(df_test['Frequency'][mask], y_pred[mask], sample_weight=df_test['Exposure'][mask]))",
            "def score_estimator(estimator, df_test):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Score an estimator on the test set.'\n    y_pred = estimator.predict(df_test)\n    print('MSE: %.3f' % mean_squared_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    print('MAE: %.3f' % mean_absolute_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    mask = y_pred > 0\n    if (~mask).any():\n        (n_masked, n_samples) = ((~mask).sum(), mask.shape[0])\n        print(f'WARNING: Estimator yields invalid, non-positive predictions  for {n_masked} samples out of {n_samples}. These predictions are ignored when computing the Poisson deviance.')\n    print('mean Poisson deviance: %.3f' % mean_poisson_deviance(df_test['Frequency'][mask], y_pred[mask], sample_weight=df_test['Exposure'][mask]))",
            "def score_estimator(estimator, df_test):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Score an estimator on the test set.'\n    y_pred = estimator.predict(df_test)\n    print('MSE: %.3f' % mean_squared_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    print('MAE: %.3f' % mean_absolute_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    mask = y_pred > 0\n    if (~mask).any():\n        (n_masked, n_samples) = ((~mask).sum(), mask.shape[0])\n        print(f'WARNING: Estimator yields invalid, non-positive predictions  for {n_masked} samples out of {n_samples}. These predictions are ignored when computing the Poisson deviance.')\n    print('mean Poisson deviance: %.3f' % mean_poisson_deviance(df_test['Frequency'][mask], y_pred[mask], sample_weight=df_test['Exposure'][mask]))",
            "def score_estimator(estimator, df_test):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Score an estimator on the test set.'\n    y_pred = estimator.predict(df_test)\n    print('MSE: %.3f' % mean_squared_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    print('MAE: %.3f' % mean_absolute_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    mask = y_pred > 0\n    if (~mask).any():\n        (n_masked, n_samples) = ((~mask).sum(), mask.shape[0])\n        print(f'WARNING: Estimator yields invalid, non-positive predictions  for {n_masked} samples out of {n_samples}. These predictions are ignored when computing the Poisson deviance.')\n    print('mean Poisson deviance: %.3f' % mean_poisson_deviance(df_test['Frequency'][mask], y_pred[mask], sample_weight=df_test['Exposure'][mask]))",
            "def score_estimator(estimator, df_test):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Score an estimator on the test set.'\n    y_pred = estimator.predict(df_test)\n    print('MSE: %.3f' % mean_squared_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    print('MAE: %.3f' % mean_absolute_error(df_test['Frequency'], y_pred, sample_weight=df_test['Exposure']))\n    mask = y_pred > 0\n    if (~mask).any():\n        (n_masked, n_samples) = ((~mask).sum(), mask.shape[0])\n        print(f'WARNING: Estimator yields invalid, non-positive predictions  for {n_masked} samples out of {n_samples}. These predictions are ignored when computing the Poisson deviance.')\n    print('mean Poisson deviance: %.3f' % mean_poisson_deviance(df_test['Frequency'][mask], y_pred[mask], sample_weight=df_test['Exposure'][mask]))"
        ]
    },
    {
        "func_name": "_mean_frequency_by_risk_group",
        "original": "def _mean_frequency_by_risk_group(y_true, y_pred, sample_weight=None, n_bins=100):\n    \"\"\"Compare predictions and observations for bins ordered by y_pred.\n\n    We order the samples by ``y_pred`` and split it in bins.\n    In each bin the observed mean is compared with the predicted mean.\n\n    Parameters\n    ----------\n    y_true: array-like of shape (n_samples,)\n        Ground truth (correct) target values.\n    y_pred: array-like of shape (n_samples,)\n        Estimated target values.\n    sample_weight : array-like of shape (n_samples,)\n        Sample weights.\n    n_bins: int\n        Number of bins to use.\n\n    Returns\n    -------\n    bin_centers: ndarray of shape (n_bins,)\n        bin centers\n    y_true_bin: ndarray of shape (n_bins,)\n        average y_pred for each bin\n    y_pred_bin: ndarray of shape (n_bins,)\n        average y_pred for each bin\n    \"\"\"\n    idx_sort = np.argsort(y_pred)\n    bin_centers = np.arange(0, 1, 1 / n_bins) + 0.5 / n_bins\n    y_pred_bin = np.zeros(n_bins)\n    y_true_bin = np.zeros(n_bins)\n    for (n, sl) in enumerate(gen_even_slices(len(y_true), n_bins)):\n        weights = sample_weight[idx_sort][sl]\n        y_pred_bin[n] = np.average(y_pred[idx_sort][sl], weights=weights)\n        y_true_bin[n] = np.average(y_true[idx_sort][sl], weights=weights)\n    return (bin_centers, y_true_bin, y_pred_bin)",
        "mutated": [
            "def _mean_frequency_by_risk_group(y_true, y_pred, sample_weight=None, n_bins=100):\n    if False:\n        i = 10\n    'Compare predictions and observations for bins ordered by y_pred.\\n\\n    We order the samples by ``y_pred`` and split it in bins.\\n    In each bin the observed mean is compared with the predicted mean.\\n\\n    Parameters\\n    ----------\\n    y_true: array-like of shape (n_samples,)\\n        Ground truth (correct) target values.\\n    y_pred: array-like of shape (n_samples,)\\n        Estimated target values.\\n    sample_weight : array-like of shape (n_samples,)\\n        Sample weights.\\n    n_bins: int\\n        Number of bins to use.\\n\\n    Returns\\n    -------\\n    bin_centers: ndarray of shape (n_bins,)\\n        bin centers\\n    y_true_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    y_pred_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    '\n    idx_sort = np.argsort(y_pred)\n    bin_centers = np.arange(0, 1, 1 / n_bins) + 0.5 / n_bins\n    y_pred_bin = np.zeros(n_bins)\n    y_true_bin = np.zeros(n_bins)\n    for (n, sl) in enumerate(gen_even_slices(len(y_true), n_bins)):\n        weights = sample_weight[idx_sort][sl]\n        y_pred_bin[n] = np.average(y_pred[idx_sort][sl], weights=weights)\n        y_true_bin[n] = np.average(y_true[idx_sort][sl], weights=weights)\n    return (bin_centers, y_true_bin, y_pred_bin)",
            "def _mean_frequency_by_risk_group(y_true, y_pred, sample_weight=None, n_bins=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compare predictions and observations for bins ordered by y_pred.\\n\\n    We order the samples by ``y_pred`` and split it in bins.\\n    In each bin the observed mean is compared with the predicted mean.\\n\\n    Parameters\\n    ----------\\n    y_true: array-like of shape (n_samples,)\\n        Ground truth (correct) target values.\\n    y_pred: array-like of shape (n_samples,)\\n        Estimated target values.\\n    sample_weight : array-like of shape (n_samples,)\\n        Sample weights.\\n    n_bins: int\\n        Number of bins to use.\\n\\n    Returns\\n    -------\\n    bin_centers: ndarray of shape (n_bins,)\\n        bin centers\\n    y_true_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    y_pred_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    '\n    idx_sort = np.argsort(y_pred)\n    bin_centers = np.arange(0, 1, 1 / n_bins) + 0.5 / n_bins\n    y_pred_bin = np.zeros(n_bins)\n    y_true_bin = np.zeros(n_bins)\n    for (n, sl) in enumerate(gen_even_slices(len(y_true), n_bins)):\n        weights = sample_weight[idx_sort][sl]\n        y_pred_bin[n] = np.average(y_pred[idx_sort][sl], weights=weights)\n        y_true_bin[n] = np.average(y_true[idx_sort][sl], weights=weights)\n    return (bin_centers, y_true_bin, y_pred_bin)",
            "def _mean_frequency_by_risk_group(y_true, y_pred, sample_weight=None, n_bins=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compare predictions and observations for bins ordered by y_pred.\\n\\n    We order the samples by ``y_pred`` and split it in bins.\\n    In each bin the observed mean is compared with the predicted mean.\\n\\n    Parameters\\n    ----------\\n    y_true: array-like of shape (n_samples,)\\n        Ground truth (correct) target values.\\n    y_pred: array-like of shape (n_samples,)\\n        Estimated target values.\\n    sample_weight : array-like of shape (n_samples,)\\n        Sample weights.\\n    n_bins: int\\n        Number of bins to use.\\n\\n    Returns\\n    -------\\n    bin_centers: ndarray of shape (n_bins,)\\n        bin centers\\n    y_true_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    y_pred_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    '\n    idx_sort = np.argsort(y_pred)\n    bin_centers = np.arange(0, 1, 1 / n_bins) + 0.5 / n_bins\n    y_pred_bin = np.zeros(n_bins)\n    y_true_bin = np.zeros(n_bins)\n    for (n, sl) in enumerate(gen_even_slices(len(y_true), n_bins)):\n        weights = sample_weight[idx_sort][sl]\n        y_pred_bin[n] = np.average(y_pred[idx_sort][sl], weights=weights)\n        y_true_bin[n] = np.average(y_true[idx_sort][sl], weights=weights)\n    return (bin_centers, y_true_bin, y_pred_bin)",
            "def _mean_frequency_by_risk_group(y_true, y_pred, sample_weight=None, n_bins=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compare predictions and observations for bins ordered by y_pred.\\n\\n    We order the samples by ``y_pred`` and split it in bins.\\n    In each bin the observed mean is compared with the predicted mean.\\n\\n    Parameters\\n    ----------\\n    y_true: array-like of shape (n_samples,)\\n        Ground truth (correct) target values.\\n    y_pred: array-like of shape (n_samples,)\\n        Estimated target values.\\n    sample_weight : array-like of shape (n_samples,)\\n        Sample weights.\\n    n_bins: int\\n        Number of bins to use.\\n\\n    Returns\\n    -------\\n    bin_centers: ndarray of shape (n_bins,)\\n        bin centers\\n    y_true_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    y_pred_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    '\n    idx_sort = np.argsort(y_pred)\n    bin_centers = np.arange(0, 1, 1 / n_bins) + 0.5 / n_bins\n    y_pred_bin = np.zeros(n_bins)\n    y_true_bin = np.zeros(n_bins)\n    for (n, sl) in enumerate(gen_even_slices(len(y_true), n_bins)):\n        weights = sample_weight[idx_sort][sl]\n        y_pred_bin[n] = np.average(y_pred[idx_sort][sl], weights=weights)\n        y_true_bin[n] = np.average(y_true[idx_sort][sl], weights=weights)\n    return (bin_centers, y_true_bin, y_pred_bin)",
            "def _mean_frequency_by_risk_group(y_true, y_pred, sample_weight=None, n_bins=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compare predictions and observations for bins ordered by y_pred.\\n\\n    We order the samples by ``y_pred`` and split it in bins.\\n    In each bin the observed mean is compared with the predicted mean.\\n\\n    Parameters\\n    ----------\\n    y_true: array-like of shape (n_samples,)\\n        Ground truth (correct) target values.\\n    y_pred: array-like of shape (n_samples,)\\n        Estimated target values.\\n    sample_weight : array-like of shape (n_samples,)\\n        Sample weights.\\n    n_bins: int\\n        Number of bins to use.\\n\\n    Returns\\n    -------\\n    bin_centers: ndarray of shape (n_bins,)\\n        bin centers\\n    y_true_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    y_pred_bin: ndarray of shape (n_bins,)\\n        average y_pred for each bin\\n    '\n    idx_sort = np.argsort(y_pred)\n    bin_centers = np.arange(0, 1, 1 / n_bins) + 0.5 / n_bins\n    y_pred_bin = np.zeros(n_bins)\n    y_true_bin = np.zeros(n_bins)\n    for (n, sl) in enumerate(gen_even_slices(len(y_true), n_bins)):\n        weights = sample_weight[idx_sort][sl]\n        y_pred_bin[n] = np.average(y_pred[idx_sort][sl], weights=weights)\n        y_true_bin[n] = np.average(y_true[idx_sort][sl], weights=weights)\n    return (bin_centers, y_true_bin, y_pred_bin)"
        ]
    },
    {
        "func_name": "lorenz_curve",
        "original": "def lorenz_curve(y_true, y_pred, exposure):\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_frequencies = y_true[ranking]\n    ranked_exposure = exposure[ranking]\n    cumulated_claims = np.cumsum(ranked_frequencies * ranked_exposure)\n    cumulated_claims /= cumulated_claims[-1]\n    cumulated_exposure = np.cumsum(ranked_exposure)\n    cumulated_exposure /= cumulated_exposure[-1]\n    return (cumulated_exposure, cumulated_claims)",
        "mutated": [
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_frequencies = y_true[ranking]\n    ranked_exposure = exposure[ranking]\n    cumulated_claims = np.cumsum(ranked_frequencies * ranked_exposure)\n    cumulated_claims /= cumulated_claims[-1]\n    cumulated_exposure = np.cumsum(ranked_exposure)\n    cumulated_exposure /= cumulated_exposure[-1]\n    return (cumulated_exposure, cumulated_claims)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_frequencies = y_true[ranking]\n    ranked_exposure = exposure[ranking]\n    cumulated_claims = np.cumsum(ranked_frequencies * ranked_exposure)\n    cumulated_claims /= cumulated_claims[-1]\n    cumulated_exposure = np.cumsum(ranked_exposure)\n    cumulated_exposure /= cumulated_exposure[-1]\n    return (cumulated_exposure, cumulated_claims)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_frequencies = y_true[ranking]\n    ranked_exposure = exposure[ranking]\n    cumulated_claims = np.cumsum(ranked_frequencies * ranked_exposure)\n    cumulated_claims /= cumulated_claims[-1]\n    cumulated_exposure = np.cumsum(ranked_exposure)\n    cumulated_exposure /= cumulated_exposure[-1]\n    return (cumulated_exposure, cumulated_claims)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_frequencies = y_true[ranking]\n    ranked_exposure = exposure[ranking]\n    cumulated_claims = np.cumsum(ranked_frequencies * ranked_exposure)\n    cumulated_claims /= cumulated_claims[-1]\n    cumulated_exposure = np.cumsum(ranked_exposure)\n    cumulated_exposure /= cumulated_exposure[-1]\n    return (cumulated_exposure, cumulated_claims)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_frequencies = y_true[ranking]\n    ranked_exposure = exposure[ranking]\n    cumulated_claims = np.cumsum(ranked_frequencies * ranked_exposure)\n    cumulated_claims /= cumulated_claims[-1]\n    cumulated_exposure = np.cumsum(ranked_exposure)\n    cumulated_exposure /= cumulated_exposure[-1]\n    return (cumulated_exposure, cumulated_claims)"
        ]
    }
]