[
    {
        "func_name": "__init__",
        "original": "def __init__(self, estimator, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', **kwargs):\n    super(PredictionError, self).__init__(estimator, is_fitted=is_fitted, ax=ax, **kwargs)\n    self.colors = {'point': kwargs.pop('point_color', None), 'line': kwargs.pop('line_color', LINE_COLOR)}\n    self.shared_limits = shared_limits\n    self.bestfit = bestfit\n    self.identity = identity\n    self.alpha = alpha",
        "mutated": [
            "def __init__(self, estimator, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', **kwargs):\n    if False:\n        i = 10\n    super(PredictionError, self).__init__(estimator, is_fitted=is_fitted, ax=ax, **kwargs)\n    self.colors = {'point': kwargs.pop('point_color', None), 'line': kwargs.pop('line_color', LINE_COLOR)}\n    self.shared_limits = shared_limits\n    self.bestfit = bestfit\n    self.identity = identity\n    self.alpha = alpha",
            "def __init__(self, estimator, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(PredictionError, self).__init__(estimator, is_fitted=is_fitted, ax=ax, **kwargs)\n    self.colors = {'point': kwargs.pop('point_color', None), 'line': kwargs.pop('line_color', LINE_COLOR)}\n    self.shared_limits = shared_limits\n    self.bestfit = bestfit\n    self.identity = identity\n    self.alpha = alpha",
            "def __init__(self, estimator, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(PredictionError, self).__init__(estimator, is_fitted=is_fitted, ax=ax, **kwargs)\n    self.colors = {'point': kwargs.pop('point_color', None), 'line': kwargs.pop('line_color', LINE_COLOR)}\n    self.shared_limits = shared_limits\n    self.bestfit = bestfit\n    self.identity = identity\n    self.alpha = alpha",
            "def __init__(self, estimator, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(PredictionError, self).__init__(estimator, is_fitted=is_fitted, ax=ax, **kwargs)\n    self.colors = {'point': kwargs.pop('point_color', None), 'line': kwargs.pop('line_color', LINE_COLOR)}\n    self.shared_limits = shared_limits\n    self.bestfit = bestfit\n    self.identity = identity\n    self.alpha = alpha",
            "def __init__(self, estimator, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(PredictionError, self).__init__(estimator, is_fitted=is_fitted, ax=ax, **kwargs)\n    self.colors = {'point': kwargs.pop('point_color', None), 'line': kwargs.pop('line_color', LINE_COLOR)}\n    self.shared_limits = shared_limits\n    self.bestfit = bestfit\n    self.identity = identity\n    self.alpha = alpha"
        ]
    },
    {
        "func_name": "score",
        "original": "def score(self, X, y, **kwargs):\n    \"\"\"\n        The score function is the hook for visual interaction. Pass in test\n        data and the visualizer will create predictions on the data and\n        evaluate them with respect to the test values. The evaluation will\n        then be passed to draw() and the result of the estimator score will\n        be returned.\n\n        Parameters\n        ----------\n        X : array-like\n            X (also X_test) are the dependent variables of test set to predict\n\n        y : array-like\n            y (also y_test) is the independent actual variables to score against\n\n        Returns\n        -------\n        score : float\n        \"\"\"\n    super(PredictionError, self).score(X, y, **kwargs)\n    y_pred = self.predict(X)\n    self.draw(y, y_pred)\n    return self.score_",
        "mutated": [
            "def score(self, X, y, **kwargs):\n    if False:\n        i = 10\n    '\\n        The score function is the hook for visual interaction. Pass in test\\n        data and the visualizer will create predictions on the data and\\n        evaluate them with respect to the test values. The evaluation will\\n        then be passed to draw() and the result of the estimator score will\\n        be returned.\\n\\n        Parameters\\n        ----------\\n        X : array-like\\n            X (also X_test) are the dependent variables of test set to predict\\n\\n        y : array-like\\n            y (also y_test) is the independent actual variables to score against\\n\\n        Returns\\n        -------\\n        score : float\\n        '\n    super(PredictionError, self).score(X, y, **kwargs)\n    y_pred = self.predict(X)\n    self.draw(y, y_pred)\n    return self.score_",
            "def score(self, X, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The score function is the hook for visual interaction. Pass in test\\n        data and the visualizer will create predictions on the data and\\n        evaluate them with respect to the test values. The evaluation will\\n        then be passed to draw() and the result of the estimator score will\\n        be returned.\\n\\n        Parameters\\n        ----------\\n        X : array-like\\n            X (also X_test) are the dependent variables of test set to predict\\n\\n        y : array-like\\n            y (also y_test) is the independent actual variables to score against\\n\\n        Returns\\n        -------\\n        score : float\\n        '\n    super(PredictionError, self).score(X, y, **kwargs)\n    y_pred = self.predict(X)\n    self.draw(y, y_pred)\n    return self.score_",
            "def score(self, X, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The score function is the hook for visual interaction. Pass in test\\n        data and the visualizer will create predictions on the data and\\n        evaluate them with respect to the test values. The evaluation will\\n        then be passed to draw() and the result of the estimator score will\\n        be returned.\\n\\n        Parameters\\n        ----------\\n        X : array-like\\n            X (also X_test) are the dependent variables of test set to predict\\n\\n        y : array-like\\n            y (also y_test) is the independent actual variables to score against\\n\\n        Returns\\n        -------\\n        score : float\\n        '\n    super(PredictionError, self).score(X, y, **kwargs)\n    y_pred = self.predict(X)\n    self.draw(y, y_pred)\n    return self.score_",
            "def score(self, X, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The score function is the hook for visual interaction. Pass in test\\n        data and the visualizer will create predictions on the data and\\n        evaluate them with respect to the test values. The evaluation will\\n        then be passed to draw() and the result of the estimator score will\\n        be returned.\\n\\n        Parameters\\n        ----------\\n        X : array-like\\n            X (also X_test) are the dependent variables of test set to predict\\n\\n        y : array-like\\n            y (also y_test) is the independent actual variables to score against\\n\\n        Returns\\n        -------\\n        score : float\\n        '\n    super(PredictionError, self).score(X, y, **kwargs)\n    y_pred = self.predict(X)\n    self.draw(y, y_pred)\n    return self.score_",
            "def score(self, X, y, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The score function is the hook for visual interaction. Pass in test\\n        data and the visualizer will create predictions on the data and\\n        evaluate them with respect to the test values. The evaluation will\\n        then be passed to draw() and the result of the estimator score will\\n        be returned.\\n\\n        Parameters\\n        ----------\\n        X : array-like\\n            X (also X_test) are the dependent variables of test set to predict\\n\\n        y : array-like\\n            y (also y_test) is the independent actual variables to score against\\n\\n        Returns\\n        -------\\n        score : float\\n        '\n    super(PredictionError, self).score(X, y, **kwargs)\n    y_pred = self.predict(X)\n    self.draw(y, y_pred)\n    return self.score_"
        ]
    },
    {
        "func_name": "draw",
        "original": "def draw(self, y, y_pred):\n    \"\"\"\n        Parameters\n        ----------\n        y : ndarray or Series of length n\n            An array or series of target or class values\n\n        y_pred : ndarray or Series of length n\n            An array or series of predicted target values\n\n        Returns\n        -------\n        ax : matplotlib Axes\n            The axis with the plotted figure\n        \"\"\"\n    try:\n        score_label = self.estimator.scoring\n        score_label = ' '.join(score_label.split('_')).capitalize()\n    except AttributeError:\n        score_label = 'R2'\n    if score_label == 'R2':\n        score_label = '$R^2$'\n    label = '{} $ = {:0.3f}$'.format(score_label, self.score_)\n    self.ax.scatter(y, y_pred, c=self.colors['point'], alpha=self.alpha, label=label)\n    if self.bestfit:\n        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'], label='best fit')\n    if self.shared_limits is True:\n        self.ax.set_xlim(min(min(y), min(y_pred)), max(max(y), max(y_pred)))\n        self.ax.set_ylim(self.ax.get_xlim())\n    return self.ax",
        "mutated": [
            "def draw(self, y, y_pred):\n    if False:\n        i = 10\n    '\\n        Parameters\\n        ----------\\n        y : ndarray or Series of length n\\n            An array or series of target or class values\\n\\n        y_pred : ndarray or Series of length n\\n            An array or series of predicted target values\\n\\n        Returns\\n        -------\\n        ax : matplotlib Axes\\n            The axis with the plotted figure\\n        '\n    try:\n        score_label = self.estimator.scoring\n        score_label = ' '.join(score_label.split('_')).capitalize()\n    except AttributeError:\n        score_label = 'R2'\n    if score_label == 'R2':\n        score_label = '$R^2$'\n    label = '{} $ = {:0.3f}$'.format(score_label, self.score_)\n    self.ax.scatter(y, y_pred, c=self.colors['point'], alpha=self.alpha, label=label)\n    if self.bestfit:\n        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'], label='best fit')\n    if self.shared_limits is True:\n        self.ax.set_xlim(min(min(y), min(y_pred)), max(max(y), max(y_pred)))\n        self.ax.set_ylim(self.ax.get_xlim())\n    return self.ax",
            "def draw(self, y, y_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Parameters\\n        ----------\\n        y : ndarray or Series of length n\\n            An array or series of target or class values\\n\\n        y_pred : ndarray or Series of length n\\n            An array or series of predicted target values\\n\\n        Returns\\n        -------\\n        ax : matplotlib Axes\\n            The axis with the plotted figure\\n        '\n    try:\n        score_label = self.estimator.scoring\n        score_label = ' '.join(score_label.split('_')).capitalize()\n    except AttributeError:\n        score_label = 'R2'\n    if score_label == 'R2':\n        score_label = '$R^2$'\n    label = '{} $ = {:0.3f}$'.format(score_label, self.score_)\n    self.ax.scatter(y, y_pred, c=self.colors['point'], alpha=self.alpha, label=label)\n    if self.bestfit:\n        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'], label='best fit')\n    if self.shared_limits is True:\n        self.ax.set_xlim(min(min(y), min(y_pred)), max(max(y), max(y_pred)))\n        self.ax.set_ylim(self.ax.get_xlim())\n    return self.ax",
            "def draw(self, y, y_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Parameters\\n        ----------\\n        y : ndarray or Series of length n\\n            An array or series of target or class values\\n\\n        y_pred : ndarray or Series of length n\\n            An array or series of predicted target values\\n\\n        Returns\\n        -------\\n        ax : matplotlib Axes\\n            The axis with the plotted figure\\n        '\n    try:\n        score_label = self.estimator.scoring\n        score_label = ' '.join(score_label.split('_')).capitalize()\n    except AttributeError:\n        score_label = 'R2'\n    if score_label == 'R2':\n        score_label = '$R^2$'\n    label = '{} $ = {:0.3f}$'.format(score_label, self.score_)\n    self.ax.scatter(y, y_pred, c=self.colors['point'], alpha=self.alpha, label=label)\n    if self.bestfit:\n        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'], label='best fit')\n    if self.shared_limits is True:\n        self.ax.set_xlim(min(min(y), min(y_pred)), max(max(y), max(y_pred)))\n        self.ax.set_ylim(self.ax.get_xlim())\n    return self.ax",
            "def draw(self, y, y_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Parameters\\n        ----------\\n        y : ndarray or Series of length n\\n            An array or series of target or class values\\n\\n        y_pred : ndarray or Series of length n\\n            An array or series of predicted target values\\n\\n        Returns\\n        -------\\n        ax : matplotlib Axes\\n            The axis with the plotted figure\\n        '\n    try:\n        score_label = self.estimator.scoring\n        score_label = ' '.join(score_label.split('_')).capitalize()\n    except AttributeError:\n        score_label = 'R2'\n    if score_label == 'R2':\n        score_label = '$R^2$'\n    label = '{} $ = {:0.3f}$'.format(score_label, self.score_)\n    self.ax.scatter(y, y_pred, c=self.colors['point'], alpha=self.alpha, label=label)\n    if self.bestfit:\n        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'], label='best fit')\n    if self.shared_limits is True:\n        self.ax.set_xlim(min(min(y), min(y_pred)), max(max(y), max(y_pred)))\n        self.ax.set_ylim(self.ax.get_xlim())\n    return self.ax",
            "def draw(self, y, y_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Parameters\\n        ----------\\n        y : ndarray or Series of length n\\n            An array or series of target or class values\\n\\n        y_pred : ndarray or Series of length n\\n            An array or series of predicted target values\\n\\n        Returns\\n        -------\\n        ax : matplotlib Axes\\n            The axis with the plotted figure\\n        '\n    try:\n        score_label = self.estimator.scoring\n        score_label = ' '.join(score_label.split('_')).capitalize()\n    except AttributeError:\n        score_label = 'R2'\n    if score_label == 'R2':\n        score_label = '$R^2$'\n    label = '{} $ = {:0.3f}$'.format(score_label, self.score_)\n    self.ax.scatter(y, y_pred, c=self.colors['point'], alpha=self.alpha, label=label)\n    if self.bestfit:\n        draw_best_fit(y, y_pred, self.ax, 'linear', ls='--', lw=2, c=self.colors['line'], label='best fit')\n    if self.shared_limits is True:\n        self.ax.set_xlim(min(min(y), min(y_pred)), max(max(y), max(y_pred)))\n        self.ax.set_ylim(self.ax.get_xlim())\n    return self.ax"
        ]
    },
    {
        "func_name": "finalize",
        "original": "def finalize(self, **kwargs):\n    \"\"\"\n        Finalizes the figure by ensuring the aspect ratio is correct and adding\n        the identity line for comparison. Also adds a title, axis labels, and\n        the legend.\n\n        Parameters\n        ----------\n        kwargs: generic keyword arguments.\n\n        Notes\n        -----\n        Generally this method is called from show and not directly by the user.\n        \"\"\"\n    self.set_title('Prediction Error for {}'.format(self.name))\n    if self.shared_limits:\n        ylim = self.ax.get_ylim()\n        xlim = self.ax.get_xlim()\n        bounds = (min(ylim[0], xlim[0]), max(ylim[1], xlim[1]))\n        self.ax.set_xlim(bounds)\n        self.ax.set_ylim(bounds)\n        self.ax.set_aspect('equal', adjustable='box')\n    if self.identity:\n        draw_identity_line(ax=self.ax, ls='--', lw=2, c=self.colors['line'], alpha=0.5, label='identity')\n    self.ax.set_ylabel('$\\\\hat{y}$')\n    self.ax.set_xlabel('$y$')\n    self.ax.legend(loc='best', frameon=True)",
        "mutated": [
            "def finalize(self, **kwargs):\n    if False:\n        i = 10\n    '\\n        Finalizes the figure by ensuring the aspect ratio is correct and adding\\n        the identity line for comparison. Also adds a title, axis labels, and\\n        the legend.\\n\\n        Parameters\\n        ----------\\n        kwargs: generic keyword arguments.\\n\\n        Notes\\n        -----\\n        Generally this method is called from show and not directly by the user.\\n        '\n    self.set_title('Prediction Error for {}'.format(self.name))\n    if self.shared_limits:\n        ylim = self.ax.get_ylim()\n        xlim = self.ax.get_xlim()\n        bounds = (min(ylim[0], xlim[0]), max(ylim[1], xlim[1]))\n        self.ax.set_xlim(bounds)\n        self.ax.set_ylim(bounds)\n        self.ax.set_aspect('equal', adjustable='box')\n    if self.identity:\n        draw_identity_line(ax=self.ax, ls='--', lw=2, c=self.colors['line'], alpha=0.5, label='identity')\n    self.ax.set_ylabel('$\\\\hat{y}$')\n    self.ax.set_xlabel('$y$')\n    self.ax.legend(loc='best', frameon=True)",
            "def finalize(self, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Finalizes the figure by ensuring the aspect ratio is correct and adding\\n        the identity line for comparison. Also adds a title, axis labels, and\\n        the legend.\\n\\n        Parameters\\n        ----------\\n        kwargs: generic keyword arguments.\\n\\n        Notes\\n        -----\\n        Generally this method is called from show and not directly by the user.\\n        '\n    self.set_title('Prediction Error for {}'.format(self.name))\n    if self.shared_limits:\n        ylim = self.ax.get_ylim()\n        xlim = self.ax.get_xlim()\n        bounds = (min(ylim[0], xlim[0]), max(ylim[1], xlim[1]))\n        self.ax.set_xlim(bounds)\n        self.ax.set_ylim(bounds)\n        self.ax.set_aspect('equal', adjustable='box')\n    if self.identity:\n        draw_identity_line(ax=self.ax, ls='--', lw=2, c=self.colors['line'], alpha=0.5, label='identity')\n    self.ax.set_ylabel('$\\\\hat{y}$')\n    self.ax.set_xlabel('$y$')\n    self.ax.legend(loc='best', frameon=True)",
            "def finalize(self, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Finalizes the figure by ensuring the aspect ratio is correct and adding\\n        the identity line for comparison. Also adds a title, axis labels, and\\n        the legend.\\n\\n        Parameters\\n        ----------\\n        kwargs: generic keyword arguments.\\n\\n        Notes\\n        -----\\n        Generally this method is called from show and not directly by the user.\\n        '\n    self.set_title('Prediction Error for {}'.format(self.name))\n    if self.shared_limits:\n        ylim = self.ax.get_ylim()\n        xlim = self.ax.get_xlim()\n        bounds = (min(ylim[0], xlim[0]), max(ylim[1], xlim[1]))\n        self.ax.set_xlim(bounds)\n        self.ax.set_ylim(bounds)\n        self.ax.set_aspect('equal', adjustable='box')\n    if self.identity:\n        draw_identity_line(ax=self.ax, ls='--', lw=2, c=self.colors['line'], alpha=0.5, label='identity')\n    self.ax.set_ylabel('$\\\\hat{y}$')\n    self.ax.set_xlabel('$y$')\n    self.ax.legend(loc='best', frameon=True)",
            "def finalize(self, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Finalizes the figure by ensuring the aspect ratio is correct and adding\\n        the identity line for comparison. Also adds a title, axis labels, and\\n        the legend.\\n\\n        Parameters\\n        ----------\\n        kwargs: generic keyword arguments.\\n\\n        Notes\\n        -----\\n        Generally this method is called from show and not directly by the user.\\n        '\n    self.set_title('Prediction Error for {}'.format(self.name))\n    if self.shared_limits:\n        ylim = self.ax.get_ylim()\n        xlim = self.ax.get_xlim()\n        bounds = (min(ylim[0], xlim[0]), max(ylim[1], xlim[1]))\n        self.ax.set_xlim(bounds)\n        self.ax.set_ylim(bounds)\n        self.ax.set_aspect('equal', adjustable='box')\n    if self.identity:\n        draw_identity_line(ax=self.ax, ls='--', lw=2, c=self.colors['line'], alpha=0.5, label='identity')\n    self.ax.set_ylabel('$\\\\hat{y}$')\n    self.ax.set_xlabel('$y$')\n    self.ax.legend(loc='best', frameon=True)",
            "def finalize(self, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Finalizes the figure by ensuring the aspect ratio is correct and adding\\n        the identity line for comparison. Also adds a title, axis labels, and\\n        the legend.\\n\\n        Parameters\\n        ----------\\n        kwargs: generic keyword arguments.\\n\\n        Notes\\n        -----\\n        Generally this method is called from show and not directly by the user.\\n        '\n    self.set_title('Prediction Error for {}'.format(self.name))\n    if self.shared_limits:\n        ylim = self.ax.get_ylim()\n        xlim = self.ax.get_xlim()\n        bounds = (min(ylim[0], xlim[0]), max(ylim[1], xlim[1]))\n        self.ax.set_xlim(bounds)\n        self.ax.set_ylim(bounds)\n        self.ax.set_aspect('equal', adjustable='box')\n    if self.identity:\n        draw_identity_line(ax=self.ax, ls='--', lw=2, c=self.colors['line'], alpha=0.5, label='identity')\n    self.ax.set_ylabel('$\\\\hat{y}$')\n    self.ax.set_xlabel('$y$')\n    self.ax.legend(loc='best', frameon=True)"
        ]
    },
    {
        "func_name": "prediction_error",
        "original": "def prediction_error(estimator, X_train, y_train, X_test=None, y_test=None, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', show=True, **kwargs):\n    \"\"\"Quickly plot a prediction error visualizer\n\n    Plot the actual targets from the dataset against the\n    predicted values generated by our model(s).\n\n    This helper function is a quick wrapper to utilize the PredictionError\n    ScoreVisualizer for one-off analysis.\n\n    Parameters\n    ----------\n    estimator : the Scikit-Learn estimator (should be a regressor)\n        Should be an instance of a regressor, otherwise will raise a\n        YellowbrickTypeError exception on instantiation.\n        If the estimator is not fitted, it is fit when the visualizer is fitted,\n        unless otherwise specified by ``is_fitted``.\n\n    X_train : ndarray or DataFrame of shape n x m\n        A feature array of n instances with m features the model is trained on.\n        Used to fit the visualizer and also to score the visualizer if test splits are\n        not directly specified.\n\n    y_train : ndarray or Series of length n\n        An array or series of target or class values. Used to fit the visualizer and\n        also to score the visualizer if test splits are not specified.\n\n    X_test : ndarray or DataFrame of shape n x m, default: None\n        An optional feature array of n instances with m features that the model\n        is scored on if specified, using X_train as the training data.\n\n    y_test : ndarray or Series of length n, default: None\n        An optional array or series of target or class values that serve as actual\n        labels for X_test for scoring purposes.\n\n    ax : matplotlib Axes\n        The axes to plot the figure on.\n\n    shared_limits : bool, default: True\n        If shared_limits is True, the range of the X and Y axis limits will\n        be identical, creating a square graphic with a true 45 degree line.\n        In this form, it is easier to diagnose under- or over- prediction,\n        though the figure will become more sparse. To localize points, set\n        shared_limits to False, but note that this will distort the figure\n        and should be accounted for during analysis.\n\n    bestfit : bool, default: True\n        Draw a linear best fit line to estimate the correlation between the\n        predicted and measured value of the target variable. The color of\n        the bestfit line is determined by the ``line_color`` argument.\n\n    identity: bool, default: True\n        Draw the 45 degree identity line, y=x in order to better show the\n        relationship or pattern of the residuals. E.g. to estimate if the\n        model is over- or under- estimating the given values. The color of the\n        identity line is a muted version of the ``line_color`` argument.\n\n    alpha : float, default: 0.75\n        Specify a transparency where 1 is completely opaque and 0 is completely\n        transparent. This property makes densely clustered points more visible.\n\n    is_fitted : bool or str, default='auto'\n        Specify if the wrapped estimator is already fitted. If False, the estimator\n        will be fit when the visualizer is fit, otherwise, the estimator will not be\n        modified. If 'auto' (default), a helper method will check if the estimator\n        is fitted before fitting it again.\n\n    show: bool, default: True\n        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\n        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\n        calls ``finalize()``\n\n    kwargs : dict\n        Keyword arguments that are passed to the base class and may influence\n        the visualization as defined in other Visualizers.\n\n    Returns\n    -------\n    ax : matplotlib Axes\n        Returns the axes that the prediction error plot was drawn on.\n    \"\"\"\n    visualizer = PredictionError(estimator, ax, shared_limits=shared_limits, bestfit=bestfit, identity=identity, alpha=alpha, is_fitted=is_fitted, **kwargs)\n    visualizer.fit(X_train, y_train)\n    if X_test is not None and y_test is not None:\n        visualizer.score(X_test, y_test)\n    elif X_test is not None or y_test is not None:\n        raise YellowbrickValueError('both X_test and y_test are required if one is specified')\n    else:\n        visualizer.score(X_train, y_train)\n    if show:\n        visualizer.show()\n    else:\n        visualizer.finalize()\n    return visualizer",
        "mutated": [
            "def prediction_error(estimator, X_train, y_train, X_test=None, y_test=None, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', show=True, **kwargs):\n    if False:\n        i = 10\n    \"Quickly plot a prediction error visualizer\\n\\n    Plot the actual targets from the dataset against the\\n    predicted values generated by our model(s).\\n\\n    This helper function is a quick wrapper to utilize the PredictionError\\n    ScoreVisualizer for one-off analysis.\\n\\n    Parameters\\n    ----------\\n    estimator : the Scikit-Learn estimator (should be a regressor)\\n        Should be an instance of a regressor, otherwise will raise a\\n        YellowbrickTypeError exception on instantiation.\\n        If the estimator is not fitted, it is fit when the visualizer is fitted,\\n        unless otherwise specified by ``is_fitted``.\\n\\n    X_train : ndarray or DataFrame of shape n x m\\n        A feature array of n instances with m features the model is trained on.\\n        Used to fit the visualizer and also to score the visualizer if test splits are\\n        not directly specified.\\n\\n    y_train : ndarray or Series of length n\\n        An array or series of target or class values. Used to fit the visualizer and\\n        also to score the visualizer if test splits are not specified.\\n\\n    X_test : ndarray or DataFrame of shape n x m, default: None\\n        An optional feature array of n instances with m features that the model\\n        is scored on if specified, using X_train as the training data.\\n\\n    y_test : ndarray or Series of length n, default: None\\n        An optional array or series of target or class values that serve as actual\\n        labels for X_test for scoring purposes.\\n\\n    ax : matplotlib Axes\\n        The axes to plot the figure on.\\n\\n    shared_limits : bool, default: True\\n        If shared_limits is True, the range of the X and Y axis limits will\\n        be identical, creating a square graphic with a true 45 degree line.\\n        In this form, it is easier to diagnose under- or over- prediction,\\n        though the figure will become more sparse. To localize points, set\\n        shared_limits to False, but note that this will distort the figure\\n        and should be accounted for during analysis.\\n\\n    bestfit : bool, default: True\\n        Draw a linear best fit line to estimate the correlation between the\\n        predicted and measured value of the target variable. The color of\\n        the bestfit line is determined by the ``line_color`` argument.\\n\\n    identity: bool, default: True\\n        Draw the 45 degree identity line, y=x in order to better show the\\n        relationship or pattern of the residuals. E.g. to estimate if the\\n        model is over- or under- estimating the given values. The color of the\\n        identity line is a muted version of the ``line_color`` argument.\\n\\n    alpha : float, default: 0.75\\n        Specify a transparency where 1 is completely opaque and 0 is completely\\n        transparent. This property makes densely clustered points more visible.\\n\\n    is_fitted : bool or str, default='auto'\\n        Specify if the wrapped estimator is already fitted. If False, the estimator\\n        will be fit when the visualizer is fit, otherwise, the estimator will not be\\n        modified. If 'auto' (default), a helper method will check if the estimator\\n        is fitted before fitting it again.\\n\\n    show: bool, default: True\\n        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\\n        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\\n        calls ``finalize()``\\n\\n    kwargs : dict\\n        Keyword arguments that are passed to the base class and may influence\\n        the visualization as defined in other Visualizers.\\n\\n    Returns\\n    -------\\n    ax : matplotlib Axes\\n        Returns the axes that the prediction error plot was drawn on.\\n    \"\n    visualizer = PredictionError(estimator, ax, shared_limits=shared_limits, bestfit=bestfit, identity=identity, alpha=alpha, is_fitted=is_fitted, **kwargs)\n    visualizer.fit(X_train, y_train)\n    if X_test is not None and y_test is not None:\n        visualizer.score(X_test, y_test)\n    elif X_test is not None or y_test is not None:\n        raise YellowbrickValueError('both X_test and y_test are required if one is specified')\n    else:\n        visualizer.score(X_train, y_train)\n    if show:\n        visualizer.show()\n    else:\n        visualizer.finalize()\n    return visualizer",
            "def prediction_error(estimator, X_train, y_train, X_test=None, y_test=None, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', show=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Quickly plot a prediction error visualizer\\n\\n    Plot the actual targets from the dataset against the\\n    predicted values generated by our model(s).\\n\\n    This helper function is a quick wrapper to utilize the PredictionError\\n    ScoreVisualizer for one-off analysis.\\n\\n    Parameters\\n    ----------\\n    estimator : the Scikit-Learn estimator (should be a regressor)\\n        Should be an instance of a regressor, otherwise will raise a\\n        YellowbrickTypeError exception on instantiation.\\n        If the estimator is not fitted, it is fit when the visualizer is fitted,\\n        unless otherwise specified by ``is_fitted``.\\n\\n    X_train : ndarray or DataFrame of shape n x m\\n        A feature array of n instances with m features the model is trained on.\\n        Used to fit the visualizer and also to score the visualizer if test splits are\\n        not directly specified.\\n\\n    y_train : ndarray or Series of length n\\n        An array or series of target or class values. Used to fit the visualizer and\\n        also to score the visualizer if test splits are not specified.\\n\\n    X_test : ndarray or DataFrame of shape n x m, default: None\\n        An optional feature array of n instances with m features that the model\\n        is scored on if specified, using X_train as the training data.\\n\\n    y_test : ndarray or Series of length n, default: None\\n        An optional array or series of target or class values that serve as actual\\n        labels for X_test for scoring purposes.\\n\\n    ax : matplotlib Axes\\n        The axes to plot the figure on.\\n\\n    shared_limits : bool, default: True\\n        If shared_limits is True, the range of the X and Y axis limits will\\n        be identical, creating a square graphic with a true 45 degree line.\\n        In this form, it is easier to diagnose under- or over- prediction,\\n        though the figure will become more sparse. To localize points, set\\n        shared_limits to False, but note that this will distort the figure\\n        and should be accounted for during analysis.\\n\\n    bestfit : bool, default: True\\n        Draw a linear best fit line to estimate the correlation between the\\n        predicted and measured value of the target variable. The color of\\n        the bestfit line is determined by the ``line_color`` argument.\\n\\n    identity: bool, default: True\\n        Draw the 45 degree identity line, y=x in order to better show the\\n        relationship or pattern of the residuals. E.g. to estimate if the\\n        model is over- or under- estimating the given values. The color of the\\n        identity line is a muted version of the ``line_color`` argument.\\n\\n    alpha : float, default: 0.75\\n        Specify a transparency where 1 is completely opaque and 0 is completely\\n        transparent. This property makes densely clustered points more visible.\\n\\n    is_fitted : bool or str, default='auto'\\n        Specify if the wrapped estimator is already fitted. If False, the estimator\\n        will be fit when the visualizer is fit, otherwise, the estimator will not be\\n        modified. If 'auto' (default), a helper method will check if the estimator\\n        is fitted before fitting it again.\\n\\n    show: bool, default: True\\n        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\\n        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\\n        calls ``finalize()``\\n\\n    kwargs : dict\\n        Keyword arguments that are passed to the base class and may influence\\n        the visualization as defined in other Visualizers.\\n\\n    Returns\\n    -------\\n    ax : matplotlib Axes\\n        Returns the axes that the prediction error plot was drawn on.\\n    \"\n    visualizer = PredictionError(estimator, ax, shared_limits=shared_limits, bestfit=bestfit, identity=identity, alpha=alpha, is_fitted=is_fitted, **kwargs)\n    visualizer.fit(X_train, y_train)\n    if X_test is not None and y_test is not None:\n        visualizer.score(X_test, y_test)\n    elif X_test is not None or y_test is not None:\n        raise YellowbrickValueError('both X_test and y_test are required if one is specified')\n    else:\n        visualizer.score(X_train, y_train)\n    if show:\n        visualizer.show()\n    else:\n        visualizer.finalize()\n    return visualizer",
            "def prediction_error(estimator, X_train, y_train, X_test=None, y_test=None, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', show=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Quickly plot a prediction error visualizer\\n\\n    Plot the actual targets from the dataset against the\\n    predicted values generated by our model(s).\\n\\n    This helper function is a quick wrapper to utilize the PredictionError\\n    ScoreVisualizer for one-off analysis.\\n\\n    Parameters\\n    ----------\\n    estimator : the Scikit-Learn estimator (should be a regressor)\\n        Should be an instance of a regressor, otherwise will raise a\\n        YellowbrickTypeError exception on instantiation.\\n        If the estimator is not fitted, it is fit when the visualizer is fitted,\\n        unless otherwise specified by ``is_fitted``.\\n\\n    X_train : ndarray or DataFrame of shape n x m\\n        A feature array of n instances with m features the model is trained on.\\n        Used to fit the visualizer and also to score the visualizer if test splits are\\n        not directly specified.\\n\\n    y_train : ndarray or Series of length n\\n        An array or series of target or class values. Used to fit the visualizer and\\n        also to score the visualizer if test splits are not specified.\\n\\n    X_test : ndarray or DataFrame of shape n x m, default: None\\n        An optional feature array of n instances with m features that the model\\n        is scored on if specified, using X_train as the training data.\\n\\n    y_test : ndarray or Series of length n, default: None\\n        An optional array or series of target or class values that serve as actual\\n        labels for X_test for scoring purposes.\\n\\n    ax : matplotlib Axes\\n        The axes to plot the figure on.\\n\\n    shared_limits : bool, default: True\\n        If shared_limits is True, the range of the X and Y axis limits will\\n        be identical, creating a square graphic with a true 45 degree line.\\n        In this form, it is easier to diagnose under- or over- prediction,\\n        though the figure will become more sparse. To localize points, set\\n        shared_limits to False, but note that this will distort the figure\\n        and should be accounted for during analysis.\\n\\n    bestfit : bool, default: True\\n        Draw a linear best fit line to estimate the correlation between the\\n        predicted and measured value of the target variable. The color of\\n        the bestfit line is determined by the ``line_color`` argument.\\n\\n    identity: bool, default: True\\n        Draw the 45 degree identity line, y=x in order to better show the\\n        relationship or pattern of the residuals. E.g. to estimate if the\\n        model is over- or under- estimating the given values. The color of the\\n        identity line is a muted version of the ``line_color`` argument.\\n\\n    alpha : float, default: 0.75\\n        Specify a transparency where 1 is completely opaque and 0 is completely\\n        transparent. This property makes densely clustered points more visible.\\n\\n    is_fitted : bool or str, default='auto'\\n        Specify if the wrapped estimator is already fitted. If False, the estimator\\n        will be fit when the visualizer is fit, otherwise, the estimator will not be\\n        modified. If 'auto' (default), a helper method will check if the estimator\\n        is fitted before fitting it again.\\n\\n    show: bool, default: True\\n        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\\n        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\\n        calls ``finalize()``\\n\\n    kwargs : dict\\n        Keyword arguments that are passed to the base class and may influence\\n        the visualization as defined in other Visualizers.\\n\\n    Returns\\n    -------\\n    ax : matplotlib Axes\\n        Returns the axes that the prediction error plot was drawn on.\\n    \"\n    visualizer = PredictionError(estimator, ax, shared_limits=shared_limits, bestfit=bestfit, identity=identity, alpha=alpha, is_fitted=is_fitted, **kwargs)\n    visualizer.fit(X_train, y_train)\n    if X_test is not None and y_test is not None:\n        visualizer.score(X_test, y_test)\n    elif X_test is not None or y_test is not None:\n        raise YellowbrickValueError('both X_test and y_test are required if one is specified')\n    else:\n        visualizer.score(X_train, y_train)\n    if show:\n        visualizer.show()\n    else:\n        visualizer.finalize()\n    return visualizer",
            "def prediction_error(estimator, X_train, y_train, X_test=None, y_test=None, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', show=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Quickly plot a prediction error visualizer\\n\\n    Plot the actual targets from the dataset against the\\n    predicted values generated by our model(s).\\n\\n    This helper function is a quick wrapper to utilize the PredictionError\\n    ScoreVisualizer for one-off analysis.\\n\\n    Parameters\\n    ----------\\n    estimator : the Scikit-Learn estimator (should be a regressor)\\n        Should be an instance of a regressor, otherwise will raise a\\n        YellowbrickTypeError exception on instantiation.\\n        If the estimator is not fitted, it is fit when the visualizer is fitted,\\n        unless otherwise specified by ``is_fitted``.\\n\\n    X_train : ndarray or DataFrame of shape n x m\\n        A feature array of n instances with m features the model is trained on.\\n        Used to fit the visualizer and also to score the visualizer if test splits are\\n        not directly specified.\\n\\n    y_train : ndarray or Series of length n\\n        An array or series of target or class values. Used to fit the visualizer and\\n        also to score the visualizer if test splits are not specified.\\n\\n    X_test : ndarray or DataFrame of shape n x m, default: None\\n        An optional feature array of n instances with m features that the model\\n        is scored on if specified, using X_train as the training data.\\n\\n    y_test : ndarray or Series of length n, default: None\\n        An optional array or series of target or class values that serve as actual\\n        labels for X_test for scoring purposes.\\n\\n    ax : matplotlib Axes\\n        The axes to plot the figure on.\\n\\n    shared_limits : bool, default: True\\n        If shared_limits is True, the range of the X and Y axis limits will\\n        be identical, creating a square graphic with a true 45 degree line.\\n        In this form, it is easier to diagnose under- or over- prediction,\\n        though the figure will become more sparse. To localize points, set\\n        shared_limits to False, but note that this will distort the figure\\n        and should be accounted for during analysis.\\n\\n    bestfit : bool, default: True\\n        Draw a linear best fit line to estimate the correlation between the\\n        predicted and measured value of the target variable. The color of\\n        the bestfit line is determined by the ``line_color`` argument.\\n\\n    identity: bool, default: True\\n        Draw the 45 degree identity line, y=x in order to better show the\\n        relationship or pattern of the residuals. E.g. to estimate if the\\n        model is over- or under- estimating the given values. The color of the\\n        identity line is a muted version of the ``line_color`` argument.\\n\\n    alpha : float, default: 0.75\\n        Specify a transparency where 1 is completely opaque and 0 is completely\\n        transparent. This property makes densely clustered points more visible.\\n\\n    is_fitted : bool or str, default='auto'\\n        Specify if the wrapped estimator is already fitted. If False, the estimator\\n        will be fit when the visualizer is fit, otherwise, the estimator will not be\\n        modified. If 'auto' (default), a helper method will check if the estimator\\n        is fitted before fitting it again.\\n\\n    show: bool, default: True\\n        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\\n        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\\n        calls ``finalize()``\\n\\n    kwargs : dict\\n        Keyword arguments that are passed to the base class and may influence\\n        the visualization as defined in other Visualizers.\\n\\n    Returns\\n    -------\\n    ax : matplotlib Axes\\n        Returns the axes that the prediction error plot was drawn on.\\n    \"\n    visualizer = PredictionError(estimator, ax, shared_limits=shared_limits, bestfit=bestfit, identity=identity, alpha=alpha, is_fitted=is_fitted, **kwargs)\n    visualizer.fit(X_train, y_train)\n    if X_test is not None and y_test is not None:\n        visualizer.score(X_test, y_test)\n    elif X_test is not None or y_test is not None:\n        raise YellowbrickValueError('both X_test and y_test are required if one is specified')\n    else:\n        visualizer.score(X_train, y_train)\n    if show:\n        visualizer.show()\n    else:\n        visualizer.finalize()\n    return visualizer",
            "def prediction_error(estimator, X_train, y_train, X_test=None, y_test=None, ax=None, shared_limits=True, bestfit=True, identity=True, alpha=0.75, is_fitted='auto', show=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Quickly plot a prediction error visualizer\\n\\n    Plot the actual targets from the dataset against the\\n    predicted values generated by our model(s).\\n\\n    This helper function is a quick wrapper to utilize the PredictionError\\n    ScoreVisualizer for one-off analysis.\\n\\n    Parameters\\n    ----------\\n    estimator : the Scikit-Learn estimator (should be a regressor)\\n        Should be an instance of a regressor, otherwise will raise a\\n        YellowbrickTypeError exception on instantiation.\\n        If the estimator is not fitted, it is fit when the visualizer is fitted,\\n        unless otherwise specified by ``is_fitted``.\\n\\n    X_train : ndarray or DataFrame of shape n x m\\n        A feature array of n instances with m features the model is trained on.\\n        Used to fit the visualizer and also to score the visualizer if test splits are\\n        not directly specified.\\n\\n    y_train : ndarray or Series of length n\\n        An array or series of target or class values. Used to fit the visualizer and\\n        also to score the visualizer if test splits are not specified.\\n\\n    X_test : ndarray or DataFrame of shape n x m, default: None\\n        An optional feature array of n instances with m features that the model\\n        is scored on if specified, using X_train as the training data.\\n\\n    y_test : ndarray or Series of length n, default: None\\n        An optional array or series of target or class values that serve as actual\\n        labels for X_test for scoring purposes.\\n\\n    ax : matplotlib Axes\\n        The axes to plot the figure on.\\n\\n    shared_limits : bool, default: True\\n        If shared_limits is True, the range of the X and Y axis limits will\\n        be identical, creating a square graphic with a true 45 degree line.\\n        In this form, it is easier to diagnose under- or over- prediction,\\n        though the figure will become more sparse. To localize points, set\\n        shared_limits to False, but note that this will distort the figure\\n        and should be accounted for during analysis.\\n\\n    bestfit : bool, default: True\\n        Draw a linear best fit line to estimate the correlation between the\\n        predicted and measured value of the target variable. The color of\\n        the bestfit line is determined by the ``line_color`` argument.\\n\\n    identity: bool, default: True\\n        Draw the 45 degree identity line, y=x in order to better show the\\n        relationship or pattern of the residuals. E.g. to estimate if the\\n        model is over- or under- estimating the given values. The color of the\\n        identity line is a muted version of the ``line_color`` argument.\\n\\n    alpha : float, default: 0.75\\n        Specify a transparency where 1 is completely opaque and 0 is completely\\n        transparent. This property makes densely clustered points more visible.\\n\\n    is_fitted : bool or str, default='auto'\\n        Specify if the wrapped estimator is already fitted. If False, the estimator\\n        will be fit when the visualizer is fit, otherwise, the estimator will not be\\n        modified. If 'auto' (default), a helper method will check if the estimator\\n        is fitted before fitting it again.\\n\\n    show: bool, default: True\\n        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\\n        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\\n        calls ``finalize()``\\n\\n    kwargs : dict\\n        Keyword arguments that are passed to the base class and may influence\\n        the visualization as defined in other Visualizers.\\n\\n    Returns\\n    -------\\n    ax : matplotlib Axes\\n        Returns the axes that the prediction error plot was drawn on.\\n    \"\n    visualizer = PredictionError(estimator, ax, shared_limits=shared_limits, bestfit=bestfit, identity=identity, alpha=alpha, is_fitted=is_fitted, **kwargs)\n    visualizer.fit(X_train, y_train)\n    if X_test is not None and y_test is not None:\n        visualizer.score(X_test, y_test)\n    elif X_test is not None or y_test is not None:\n        raise YellowbrickValueError('both X_test and y_test are required if one is specified')\n    else:\n        visualizer.score(X_train, y_train)\n    if show:\n        visualizer.show()\n    else:\n        visualizer.finalize()\n    return visualizer"
        ]
    }
]