[
    {
        "func_name": "__init__",
        "original": "def __init__(self, num_classes, bbox_coder, train_cfg=None, test_cfg=None, vote_module_cfg=None, vote_aggregation_cfg=None, pred_layer_cfg=None, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, iou_loss=None, init_cfg=None):\n    super(VoteHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = vote_module_cfg['gt_per_seed']\n    self.num_proposal = vote_aggregation_cfg['num_point']\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    if size_class_loss is not None:\n        self.size_class_loss = build_loss(size_class_loss)\n    if semantic_loss is not None:\n        self.semantic_loss = build_loss(semantic_loss)\n    if iou_loss is not None:\n        self.iou_loss = build_loss(iou_loss)\n    else:\n        self.iou_loss = None\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.vote_module = VoteModule(**vote_module_cfg)\n    self.vote_aggregation = build_sa_module(vote_aggregation_cfg)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())",
        "mutated": [
            "def __init__(self, num_classes, bbox_coder, train_cfg=None, test_cfg=None, vote_module_cfg=None, vote_aggregation_cfg=None, pred_layer_cfg=None, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, iou_loss=None, init_cfg=None):\n    if False:\n        i = 10\n    super(VoteHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = vote_module_cfg['gt_per_seed']\n    self.num_proposal = vote_aggregation_cfg['num_point']\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    if size_class_loss is not None:\n        self.size_class_loss = build_loss(size_class_loss)\n    if semantic_loss is not None:\n        self.semantic_loss = build_loss(semantic_loss)\n    if iou_loss is not None:\n        self.iou_loss = build_loss(iou_loss)\n    else:\n        self.iou_loss = None\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.vote_module = VoteModule(**vote_module_cfg)\n    self.vote_aggregation = build_sa_module(vote_aggregation_cfg)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())",
            "def __init__(self, num_classes, bbox_coder, train_cfg=None, test_cfg=None, vote_module_cfg=None, vote_aggregation_cfg=None, pred_layer_cfg=None, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, iou_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(VoteHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = vote_module_cfg['gt_per_seed']\n    self.num_proposal = vote_aggregation_cfg['num_point']\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    if size_class_loss is not None:\n        self.size_class_loss = build_loss(size_class_loss)\n    if semantic_loss is not None:\n        self.semantic_loss = build_loss(semantic_loss)\n    if iou_loss is not None:\n        self.iou_loss = build_loss(iou_loss)\n    else:\n        self.iou_loss = None\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.vote_module = VoteModule(**vote_module_cfg)\n    self.vote_aggregation = build_sa_module(vote_aggregation_cfg)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())",
            "def __init__(self, num_classes, bbox_coder, train_cfg=None, test_cfg=None, vote_module_cfg=None, vote_aggregation_cfg=None, pred_layer_cfg=None, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, iou_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(VoteHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = vote_module_cfg['gt_per_seed']\n    self.num_proposal = vote_aggregation_cfg['num_point']\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    if size_class_loss is not None:\n        self.size_class_loss = build_loss(size_class_loss)\n    if semantic_loss is not None:\n        self.semantic_loss = build_loss(semantic_loss)\n    if iou_loss is not None:\n        self.iou_loss = build_loss(iou_loss)\n    else:\n        self.iou_loss = None\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.vote_module = VoteModule(**vote_module_cfg)\n    self.vote_aggregation = build_sa_module(vote_aggregation_cfg)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())",
            "def __init__(self, num_classes, bbox_coder, train_cfg=None, test_cfg=None, vote_module_cfg=None, vote_aggregation_cfg=None, pred_layer_cfg=None, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, iou_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(VoteHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = vote_module_cfg['gt_per_seed']\n    self.num_proposal = vote_aggregation_cfg['num_point']\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    if size_class_loss is not None:\n        self.size_class_loss = build_loss(size_class_loss)\n    if semantic_loss is not None:\n        self.semantic_loss = build_loss(semantic_loss)\n    if iou_loss is not None:\n        self.iou_loss = build_loss(iou_loss)\n    else:\n        self.iou_loss = None\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.vote_module = VoteModule(**vote_module_cfg)\n    self.vote_aggregation = build_sa_module(vote_aggregation_cfg)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())",
            "def __init__(self, num_classes, bbox_coder, train_cfg=None, test_cfg=None, vote_module_cfg=None, vote_aggregation_cfg=None, pred_layer_cfg=None, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, iou_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(VoteHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = vote_module_cfg['gt_per_seed']\n    self.num_proposal = vote_aggregation_cfg['num_point']\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    if size_class_loss is not None:\n        self.size_class_loss = build_loss(size_class_loss)\n    if semantic_loss is not None:\n        self.semantic_loss = build_loss(semantic_loss)\n    if iou_loss is not None:\n        self.iou_loss = build_loss(iou_loss)\n    else:\n        self.iou_loss = None\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.vote_module = VoteModule(**vote_module_cfg)\n    self.vote_aggregation = build_sa_module(vote_aggregation_cfg)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())"
        ]
    },
    {
        "func_name": "_get_cls_out_channels",
        "original": "def _get_cls_out_channels(self):\n    \"\"\"Return the channel number of classification outputs.\"\"\"\n    return self.num_classes + 2",
        "mutated": [
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 2",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 2",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 2",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 2",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 2"
        ]
    },
    {
        "func_name": "_get_reg_out_channels",
        "original": "def _get_reg_out_channels(self):\n    \"\"\"Return the channel number of regression outputs.\"\"\"\n    return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
        "mutated": [
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n    'Return the channel number of regression outputs.'\n    return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Return the channel number of regression outputs.'\n    return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Return the channel number of regression outputs.'\n    return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Return the channel number of regression outputs.'\n    return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Return the channel number of regression outputs.'\n    return 3 + self.num_dir_bins * 2 + self.num_sizes * 4"
        ]
    },
    {
        "func_name": "_extract_input",
        "original": "def _extract_input(self, feat_dict):\n    \"\"\"Extract inputs from features dictionary.\n\n        Args:\n            feat_dict (dict): Feature dict from backbone.\n\n        Returns:\n            torch.Tensor: Coordinates of input points.\n            torch.Tensor: Features of input points.\n            torch.Tensor: Indices of input points.\n        \"\"\"\n    if 'seed_points' in feat_dict and 'seed_features' in feat_dict and ('seed_indices' in feat_dict):\n        seed_points = feat_dict['seed_points']\n        seed_features = feat_dict['seed_features']\n        seed_indices = feat_dict['seed_indices']\n    else:\n        seed_points = feat_dict['fp_xyz'][-1]\n        seed_features = feat_dict['fp_features'][-1]\n        seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
        "mutated": [
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    if 'seed_points' in feat_dict and 'seed_features' in feat_dict and ('seed_indices' in feat_dict):\n        seed_points = feat_dict['seed_points']\n        seed_features = feat_dict['seed_features']\n        seed_indices = feat_dict['seed_indices']\n    else:\n        seed_points = feat_dict['fp_xyz'][-1]\n        seed_features = feat_dict['fp_features'][-1]\n        seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    if 'seed_points' in feat_dict and 'seed_features' in feat_dict and ('seed_indices' in feat_dict):\n        seed_points = feat_dict['seed_points']\n        seed_features = feat_dict['seed_features']\n        seed_indices = feat_dict['seed_indices']\n    else:\n        seed_points = feat_dict['fp_xyz'][-1]\n        seed_features = feat_dict['fp_features'][-1]\n        seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    if 'seed_points' in feat_dict and 'seed_features' in feat_dict and ('seed_indices' in feat_dict):\n        seed_points = feat_dict['seed_points']\n        seed_features = feat_dict['seed_features']\n        seed_indices = feat_dict['seed_indices']\n    else:\n        seed_points = feat_dict['fp_xyz'][-1]\n        seed_features = feat_dict['fp_features'][-1]\n        seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    if 'seed_points' in feat_dict and 'seed_features' in feat_dict and ('seed_indices' in feat_dict):\n        seed_points = feat_dict['seed_points']\n        seed_features = feat_dict['seed_features']\n        seed_indices = feat_dict['seed_indices']\n    else:\n        seed_points = feat_dict['fp_xyz'][-1]\n        seed_features = feat_dict['fp_features'][-1]\n        seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    if 'seed_points' in feat_dict and 'seed_features' in feat_dict and ('seed_indices' in feat_dict):\n        seed_points = feat_dict['seed_points']\n        seed_features = feat_dict['seed_features']\n        seed_indices = feat_dict['seed_indices']\n    else:\n        seed_points = feat_dict['fp_xyz'][-1]\n        seed_features = feat_dict['fp_features'][-1]\n        seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, feat_dict, sample_mod):\n    \"\"\"Forward pass.\n\n        Note:\n            The forward of VoteHead is divided into 4 steps:\n\n                1. Generate vote_points from seed_points.\n                2. Aggregate vote_points.\n                3. Predict bbox and score.\n                4. Decode predictions.\n\n        Args:\n            feat_dict (dict): Feature dict from backbone.\n            sample_mod (str): Sample mode for vote aggregation layer.\n                valid modes are \"vote\", \"seed\", \"random\" and \"spec\".\n\n        Returns:\n            dict: Predictions of vote head.\n        \"\"\"\n    assert sample_mod in ['vote', 'seed', 'random', 'spec']\n    (seed_points, seed_features, seed_indices) = self._extract_input(feat_dict)\n    (vote_points, vote_features, vote_offset) = self.vote_module(seed_points, seed_features)\n    results = dict(seed_points=seed_points, seed_indices=seed_indices, vote_points=vote_points, vote_features=vote_features, vote_offset=vote_offset)\n    if sample_mod == 'vote':\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features)\n    elif sample_mod == 'seed':\n        sample_indices = furthest_point_sample(seed_points, self.num_proposal)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'random':\n        (batch_size, num_seed) = seed_points.shape[:2]\n        sample_indices = seed_points.new_tensor(torch.randint(0, num_seed, (batch_size, self.num_proposal)), dtype=torch.int32)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'spec':\n        aggregation_inputs = dict(points_xyz=seed_points, features=seed_features, target_xyz=vote_points)\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    vote_aggregation_ret = self.vote_aggregation(**aggregation_inputs)\n    (aggregated_points, features, aggregated_indices) = vote_aggregation_ret\n    results['aggregated_points'] = aggregated_points\n    results['aggregated_features'] = features\n    results['aggregated_indices'] = aggregated_indices\n    (cls_predictions, reg_predictions) = self.conv_pred(features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, aggregated_points)\n    results.update(decode_res)\n    return results",
        "mutated": [
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Note:\\n            The forward of VoteHead is divided into 4 steps:\\n\\n                1. Generate vote_points from seed_points.\\n                2. Aggregate vote_points.\\n                3. Predict bbox and score.\\n                4. Decode predictions.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\", \"random\" and \"spec\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    assert sample_mod in ['vote', 'seed', 'random', 'spec']\n    (seed_points, seed_features, seed_indices) = self._extract_input(feat_dict)\n    (vote_points, vote_features, vote_offset) = self.vote_module(seed_points, seed_features)\n    results = dict(seed_points=seed_points, seed_indices=seed_indices, vote_points=vote_points, vote_features=vote_features, vote_offset=vote_offset)\n    if sample_mod == 'vote':\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features)\n    elif sample_mod == 'seed':\n        sample_indices = furthest_point_sample(seed_points, self.num_proposal)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'random':\n        (batch_size, num_seed) = seed_points.shape[:2]\n        sample_indices = seed_points.new_tensor(torch.randint(0, num_seed, (batch_size, self.num_proposal)), dtype=torch.int32)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'spec':\n        aggregation_inputs = dict(points_xyz=seed_points, features=seed_features, target_xyz=vote_points)\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    vote_aggregation_ret = self.vote_aggregation(**aggregation_inputs)\n    (aggregated_points, features, aggregated_indices) = vote_aggregation_ret\n    results['aggregated_points'] = aggregated_points\n    results['aggregated_features'] = features\n    results['aggregated_indices'] = aggregated_indices\n    (cls_predictions, reg_predictions) = self.conv_pred(features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, aggregated_points)\n    results.update(decode_res)\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Note:\\n            The forward of VoteHead is divided into 4 steps:\\n\\n                1. Generate vote_points from seed_points.\\n                2. Aggregate vote_points.\\n                3. Predict bbox and score.\\n                4. Decode predictions.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\", \"random\" and \"spec\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    assert sample_mod in ['vote', 'seed', 'random', 'spec']\n    (seed_points, seed_features, seed_indices) = self._extract_input(feat_dict)\n    (vote_points, vote_features, vote_offset) = self.vote_module(seed_points, seed_features)\n    results = dict(seed_points=seed_points, seed_indices=seed_indices, vote_points=vote_points, vote_features=vote_features, vote_offset=vote_offset)\n    if sample_mod == 'vote':\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features)\n    elif sample_mod == 'seed':\n        sample_indices = furthest_point_sample(seed_points, self.num_proposal)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'random':\n        (batch_size, num_seed) = seed_points.shape[:2]\n        sample_indices = seed_points.new_tensor(torch.randint(0, num_seed, (batch_size, self.num_proposal)), dtype=torch.int32)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'spec':\n        aggregation_inputs = dict(points_xyz=seed_points, features=seed_features, target_xyz=vote_points)\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    vote_aggregation_ret = self.vote_aggregation(**aggregation_inputs)\n    (aggregated_points, features, aggregated_indices) = vote_aggregation_ret\n    results['aggregated_points'] = aggregated_points\n    results['aggregated_features'] = features\n    results['aggregated_indices'] = aggregated_indices\n    (cls_predictions, reg_predictions) = self.conv_pred(features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, aggregated_points)\n    results.update(decode_res)\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Note:\\n            The forward of VoteHead is divided into 4 steps:\\n\\n                1. Generate vote_points from seed_points.\\n                2. Aggregate vote_points.\\n                3. Predict bbox and score.\\n                4. Decode predictions.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\", \"random\" and \"spec\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    assert sample_mod in ['vote', 'seed', 'random', 'spec']\n    (seed_points, seed_features, seed_indices) = self._extract_input(feat_dict)\n    (vote_points, vote_features, vote_offset) = self.vote_module(seed_points, seed_features)\n    results = dict(seed_points=seed_points, seed_indices=seed_indices, vote_points=vote_points, vote_features=vote_features, vote_offset=vote_offset)\n    if sample_mod == 'vote':\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features)\n    elif sample_mod == 'seed':\n        sample_indices = furthest_point_sample(seed_points, self.num_proposal)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'random':\n        (batch_size, num_seed) = seed_points.shape[:2]\n        sample_indices = seed_points.new_tensor(torch.randint(0, num_seed, (batch_size, self.num_proposal)), dtype=torch.int32)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'spec':\n        aggregation_inputs = dict(points_xyz=seed_points, features=seed_features, target_xyz=vote_points)\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    vote_aggregation_ret = self.vote_aggregation(**aggregation_inputs)\n    (aggregated_points, features, aggregated_indices) = vote_aggregation_ret\n    results['aggregated_points'] = aggregated_points\n    results['aggregated_features'] = features\n    results['aggregated_indices'] = aggregated_indices\n    (cls_predictions, reg_predictions) = self.conv_pred(features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, aggregated_points)\n    results.update(decode_res)\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Note:\\n            The forward of VoteHead is divided into 4 steps:\\n\\n                1. Generate vote_points from seed_points.\\n                2. Aggregate vote_points.\\n                3. Predict bbox and score.\\n                4. Decode predictions.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\", \"random\" and \"spec\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    assert sample_mod in ['vote', 'seed', 'random', 'spec']\n    (seed_points, seed_features, seed_indices) = self._extract_input(feat_dict)\n    (vote_points, vote_features, vote_offset) = self.vote_module(seed_points, seed_features)\n    results = dict(seed_points=seed_points, seed_indices=seed_indices, vote_points=vote_points, vote_features=vote_features, vote_offset=vote_offset)\n    if sample_mod == 'vote':\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features)\n    elif sample_mod == 'seed':\n        sample_indices = furthest_point_sample(seed_points, self.num_proposal)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'random':\n        (batch_size, num_seed) = seed_points.shape[:2]\n        sample_indices = seed_points.new_tensor(torch.randint(0, num_seed, (batch_size, self.num_proposal)), dtype=torch.int32)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'spec':\n        aggregation_inputs = dict(points_xyz=seed_points, features=seed_features, target_xyz=vote_points)\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    vote_aggregation_ret = self.vote_aggregation(**aggregation_inputs)\n    (aggregated_points, features, aggregated_indices) = vote_aggregation_ret\n    results['aggregated_points'] = aggregated_points\n    results['aggregated_features'] = features\n    results['aggregated_indices'] = aggregated_indices\n    (cls_predictions, reg_predictions) = self.conv_pred(features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, aggregated_points)\n    results.update(decode_res)\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Note:\\n            The forward of VoteHead is divided into 4 steps:\\n\\n                1. Generate vote_points from seed_points.\\n                2. Aggregate vote_points.\\n                3. Predict bbox and score.\\n                4. Decode predictions.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\", \"random\" and \"spec\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    assert sample_mod in ['vote', 'seed', 'random', 'spec']\n    (seed_points, seed_features, seed_indices) = self._extract_input(feat_dict)\n    (vote_points, vote_features, vote_offset) = self.vote_module(seed_points, seed_features)\n    results = dict(seed_points=seed_points, seed_indices=seed_indices, vote_points=vote_points, vote_features=vote_features, vote_offset=vote_offset)\n    if sample_mod == 'vote':\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features)\n    elif sample_mod == 'seed':\n        sample_indices = furthest_point_sample(seed_points, self.num_proposal)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'random':\n        (batch_size, num_seed) = seed_points.shape[:2]\n        sample_indices = seed_points.new_tensor(torch.randint(0, num_seed, (batch_size, self.num_proposal)), dtype=torch.int32)\n        aggregation_inputs = dict(points_xyz=vote_points, features=vote_features, indices=sample_indices)\n    elif sample_mod == 'spec':\n        aggregation_inputs = dict(points_xyz=seed_points, features=seed_features, target_xyz=vote_points)\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    vote_aggregation_ret = self.vote_aggregation(**aggregation_inputs)\n    (aggregated_points, features, aggregated_indices) = vote_aggregation_ret\n    results['aggregated_points'] = aggregated_points\n    results['aggregated_features'] = features\n    results['aggregated_indices'] = aggregated_indices\n    (cls_predictions, reg_predictions) = self.conv_pred(features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, aggregated_points)\n    results.update(decode_res)\n    return results"
        ]
    },
    {
        "func_name": "loss",
        "original": "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    \"\"\"Compute loss.\n\n        Args:\n            bbox_preds (dict): Predictions from forward of vote head.\n            points (list[torch.Tensor]): Input points.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each sample.\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\n                semantic mask.\n            pts_instance_mask (list[torch.Tensor]): Point-wise\n                instance mask.\n            img_metas (list[dict]): Contain pcd and img's meta info.\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\n                which bounding.\n            ret_target (Bool): Return targets or not.\n\n        Returns:\n            dict: Losses of Votenet.\n        \"\"\"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    vote_loss = self.vote_module.get_loss(bbox_preds['seed_points'], bbox_preds['vote_points'], bbox_preds['seed_indices'], vote_target_masks, vote_targets)\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores'].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center'], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = vote_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = torch.sum(bbox_preds['dir_res_norm'] * heading_label_one_hot, -1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = vote_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3).contiguous()\n    size_residual_norm = torch.sum(bbox_preds['size_res_norm'] * one_hot_size_targets_expand, 2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(vote_loss=vote_loss, objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    if self.iou_loss:\n        corners_pred = self.bbox_coder.decode_corners(bbox_preds['center'], size_residual_norm, one_hot_size_targets_expand)\n        corners_target = self.bbox_coder.decode_corners(assigned_center_targets, size_res_targets, one_hot_size_targets_expand)\n        iou_loss = self.iou_loss(corners_pred, corners_target, weight=box_loss_weights)\n        losses['iou_loss'] = iou_loss\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
        "mutated": [
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of Votenet.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    vote_loss = self.vote_module.get_loss(bbox_preds['seed_points'], bbox_preds['vote_points'], bbox_preds['seed_indices'], vote_target_masks, vote_targets)\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores'].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center'], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = vote_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = torch.sum(bbox_preds['dir_res_norm'] * heading_label_one_hot, -1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = vote_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3).contiguous()\n    size_residual_norm = torch.sum(bbox_preds['size_res_norm'] * one_hot_size_targets_expand, 2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(vote_loss=vote_loss, objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    if self.iou_loss:\n        corners_pred = self.bbox_coder.decode_corners(bbox_preds['center'], size_residual_norm, one_hot_size_targets_expand)\n        corners_target = self.bbox_coder.decode_corners(assigned_center_targets, size_res_targets, one_hot_size_targets_expand)\n        iou_loss = self.iou_loss(corners_pred, corners_target, weight=box_loss_weights)\n        losses['iou_loss'] = iou_loss\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of Votenet.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    vote_loss = self.vote_module.get_loss(bbox_preds['seed_points'], bbox_preds['vote_points'], bbox_preds['seed_indices'], vote_target_masks, vote_targets)\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores'].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center'], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = vote_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = torch.sum(bbox_preds['dir_res_norm'] * heading_label_one_hot, -1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = vote_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3).contiguous()\n    size_residual_norm = torch.sum(bbox_preds['size_res_norm'] * one_hot_size_targets_expand, 2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(vote_loss=vote_loss, objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    if self.iou_loss:\n        corners_pred = self.bbox_coder.decode_corners(bbox_preds['center'], size_residual_norm, one_hot_size_targets_expand)\n        corners_target = self.bbox_coder.decode_corners(assigned_center_targets, size_res_targets, one_hot_size_targets_expand)\n        iou_loss = self.iou_loss(corners_pred, corners_target, weight=box_loss_weights)\n        losses['iou_loss'] = iou_loss\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of Votenet.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    vote_loss = self.vote_module.get_loss(bbox_preds['seed_points'], bbox_preds['vote_points'], bbox_preds['seed_indices'], vote_target_masks, vote_targets)\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores'].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center'], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = vote_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = torch.sum(bbox_preds['dir_res_norm'] * heading_label_one_hot, -1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = vote_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3).contiguous()\n    size_residual_norm = torch.sum(bbox_preds['size_res_norm'] * one_hot_size_targets_expand, 2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(vote_loss=vote_loss, objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    if self.iou_loss:\n        corners_pred = self.bbox_coder.decode_corners(bbox_preds['center'], size_residual_norm, one_hot_size_targets_expand)\n        corners_target = self.bbox_coder.decode_corners(assigned_center_targets, size_res_targets, one_hot_size_targets_expand)\n        iou_loss = self.iou_loss(corners_pred, corners_target, weight=box_loss_weights)\n        losses['iou_loss'] = iou_loss\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of Votenet.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    vote_loss = self.vote_module.get_loss(bbox_preds['seed_points'], bbox_preds['vote_points'], bbox_preds['seed_indices'], vote_target_masks, vote_targets)\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores'].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center'], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = vote_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = torch.sum(bbox_preds['dir_res_norm'] * heading_label_one_hot, -1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = vote_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3).contiguous()\n    size_residual_norm = torch.sum(bbox_preds['size_res_norm'] * one_hot_size_targets_expand, 2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(vote_loss=vote_loss, objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    if self.iou_loss:\n        corners_pred = self.bbox_coder.decode_corners(bbox_preds['center'], size_residual_norm, one_hot_size_targets_expand)\n        corners_target = self.bbox_coder.decode_corners(assigned_center_targets, size_res_targets, one_hot_size_targets_expand)\n        iou_loss = self.iou_loss(corners_pred, corners_target, weight=box_loss_weights)\n        losses['iou_loss'] = iou_loss\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of Votenet.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    vote_loss = self.vote_module.get_loss(bbox_preds['seed_points'], bbox_preds['vote_points'], bbox_preds['seed_indices'], vote_target_masks, vote_targets)\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores'].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center'], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = vote_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = torch.sum(bbox_preds['dir_res_norm'] * heading_label_one_hot, -1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = vote_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3).contiguous()\n    size_residual_norm = torch.sum(bbox_preds['size_res_norm'] * one_hot_size_targets_expand, 2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(vote_loss=vote_loss, objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    if self.iou_loss:\n        corners_pred = self.bbox_coder.decode_corners(bbox_preds['center'], size_residual_norm, one_hot_size_targets_expand)\n        corners_target = self.bbox_coder.decode_corners(assigned_center_targets, size_res_targets, one_hot_size_targets_expand)\n        iou_loss = self.iou_loss(corners_pred, corners_target, weight=box_loss_weights)\n        losses['iou_loss'] = iou_loss\n    if ret_target:\n        losses['targets'] = targets\n    return losses"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    \"\"\"Generate targets of vote head.\n\n        Args:\n            points (list[torch.Tensor]): Points of each batch.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each batch.\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\n                label of each batch.\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\n                label of each batch.\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\n\n        Returns:\n            tuple[torch.Tensor]: Targets of vote head.\n        \"\"\"\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_num = max(gt_num)\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        center_targets[index] = F.pad(center_targets[index], (0, 0, 0, pad_num))\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    vote_targets = torch.stack(vote_targets)\n    vote_target_masks = torch.stack(vote_target_masks)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    objectness_weights /= torch.sum(objectness_weights) + 1e-06\n    box_loss_weights = objectness_targets.float() / (torch.sum(objectness_targets).float() + 1e-06)\n    valid_gt_weights = valid_gt_masks.float() / (torch.sum(valid_gt_masks.float()) + 1e-06)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
        "mutated": [
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n    'Generate targets of vote head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_num = max(gt_num)\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        center_targets[index] = F.pad(center_targets[index], (0, 0, 0, pad_num))\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    vote_targets = torch.stack(vote_targets)\n    vote_target_masks = torch.stack(vote_target_masks)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    objectness_weights /= torch.sum(objectness_weights) + 1e-06\n    box_loss_weights = objectness_targets.float() / (torch.sum(objectness_targets).float() + 1e-06)\n    valid_gt_weights = valid_gt_masks.float() / (torch.sum(valid_gt_masks.float()) + 1e-06)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets of vote head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_num = max(gt_num)\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        center_targets[index] = F.pad(center_targets[index], (0, 0, 0, pad_num))\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    vote_targets = torch.stack(vote_targets)\n    vote_target_masks = torch.stack(vote_target_masks)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    objectness_weights /= torch.sum(objectness_weights) + 1e-06\n    box_loss_weights = objectness_targets.float() / (torch.sum(objectness_targets).float() + 1e-06)\n    valid_gt_weights = valid_gt_masks.float() / (torch.sum(valid_gt_masks.float()) + 1e-06)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets of vote head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_num = max(gt_num)\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        center_targets[index] = F.pad(center_targets[index], (0, 0, 0, pad_num))\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    vote_targets = torch.stack(vote_targets)\n    vote_target_masks = torch.stack(vote_target_masks)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    objectness_weights /= torch.sum(objectness_weights) + 1e-06\n    box_loss_weights = objectness_targets.float() / (torch.sum(objectness_targets).float() + 1e-06)\n    valid_gt_weights = valid_gt_masks.float() / (torch.sum(valid_gt_masks.float()) + 1e-06)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets of vote head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_num = max(gt_num)\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        center_targets[index] = F.pad(center_targets[index], (0, 0, 0, pad_num))\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    vote_targets = torch.stack(vote_targets)\n    vote_target_masks = torch.stack(vote_target_masks)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    objectness_weights /= torch.sum(objectness_weights) + 1e-06\n    box_loss_weights = objectness_targets.float() / (torch.sum(objectness_targets).float() + 1e-06)\n    valid_gt_weights = valid_gt_masks.float() / (torch.sum(valid_gt_masks.float()) + 1e-06)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets of vote head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_num = max(gt_num)\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        center_targets[index] = F.pad(center_targets[index], (0, 0, 0, pad_num))\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    vote_targets = torch.stack(vote_targets)\n    vote_target_masks = torch.stack(vote_target_masks)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    objectness_weights /= torch.sum(objectness_weights) + 1e-06\n    box_loss_weights = objectness_targets.float() / (torch.sum(objectness_targets).float() + 1e-06)\n    valid_gt_weights = valid_gt_masks.float() / (torch.sum(valid_gt_masks.float()) + 1e-06)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)"
        ]
    },
    {
        "func_name": "get_targets_single",
        "original": "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None):\n    \"\"\"Generate targets of vote head for single batch.\n\n        Args:\n            points (torch.Tensor): Points of each batch.\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\n                boxes of each batch.\n            gt_labels_3d (torch.Tensor): Labels of each batch.\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\n                label of each batch.\n            pts_instance_mask (torch.Tensor): Point-wise instance\n                label of each batch.\n            aggregated_points (torch.Tensor): Aggregated points from\n                vote aggregation layer.\n\n        Returns:\n            tuple[torch.Tensor]: Targets of vote head.\n        \"\"\"\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    num_points = points.shape[0]\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 3 * self.gt_per_seed])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_all(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            vote_target_masks[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                if j == 0:\n                    vote_targets_tmp[column_indices] = votes[column_indices].repeat(1, self.gt_per_seed)\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n    elif pts_semantic_mask is not None:\n        vote_targets = points.new_zeros([num_points, 3])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                vote_targets[indices, :] = center - selected_points\n                vote_target_masks[indices] = 1\n        vote_targets = vote_targets.repeat((1, self.gt_per_seed))\n    else:\n        raise NotImplementedError\n    (center_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    proposal_num = aggregated_points.shape[0]\n    (distance1, _, assignment, _) = chamfer_distance(aggregated_points.unsqueeze(0), center_targets.unsqueeze(0), reduction='none')\n    assignment = assignment.squeeze(0)\n    euclidean_distance1 = torch.sqrt(distance1.squeeze(0) + 1e-06)\n    objectness_targets = points.new_zeros(proposal_num, dtype=torch.long)\n    objectness_targets[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1\n    objectness_masks = points.new_zeros(proposal_num)\n    objectness_masks[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1.0\n    objectness_masks[euclidean_distance1 > self.train_cfg['neg_distance_thr']] = 1.0\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = size_res_targets[assignment]\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment]\n    assigned_center_targets = center_targets[assignment]\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets.long(), objectness_targets, objectness_masks)",
        "mutated": [
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None):\n    if False:\n        i = 10\n    'Generate targets of vote head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    num_points = points.shape[0]\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 3 * self.gt_per_seed])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_all(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            vote_target_masks[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                if j == 0:\n                    vote_targets_tmp[column_indices] = votes[column_indices].repeat(1, self.gt_per_seed)\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n    elif pts_semantic_mask is not None:\n        vote_targets = points.new_zeros([num_points, 3])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                vote_targets[indices, :] = center - selected_points\n                vote_target_masks[indices] = 1\n        vote_targets = vote_targets.repeat((1, self.gt_per_seed))\n    else:\n        raise NotImplementedError\n    (center_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    proposal_num = aggregated_points.shape[0]\n    (distance1, _, assignment, _) = chamfer_distance(aggregated_points.unsqueeze(0), center_targets.unsqueeze(0), reduction='none')\n    assignment = assignment.squeeze(0)\n    euclidean_distance1 = torch.sqrt(distance1.squeeze(0) + 1e-06)\n    objectness_targets = points.new_zeros(proposal_num, dtype=torch.long)\n    objectness_targets[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1\n    objectness_masks = points.new_zeros(proposal_num)\n    objectness_masks[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1.0\n    objectness_masks[euclidean_distance1 > self.train_cfg['neg_distance_thr']] = 1.0\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = size_res_targets[assignment]\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment]\n    assigned_center_targets = center_targets[assignment]\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets.long(), objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets of vote head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    num_points = points.shape[0]\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 3 * self.gt_per_seed])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_all(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            vote_target_masks[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                if j == 0:\n                    vote_targets_tmp[column_indices] = votes[column_indices].repeat(1, self.gt_per_seed)\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n    elif pts_semantic_mask is not None:\n        vote_targets = points.new_zeros([num_points, 3])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                vote_targets[indices, :] = center - selected_points\n                vote_target_masks[indices] = 1\n        vote_targets = vote_targets.repeat((1, self.gt_per_seed))\n    else:\n        raise NotImplementedError\n    (center_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    proposal_num = aggregated_points.shape[0]\n    (distance1, _, assignment, _) = chamfer_distance(aggregated_points.unsqueeze(0), center_targets.unsqueeze(0), reduction='none')\n    assignment = assignment.squeeze(0)\n    euclidean_distance1 = torch.sqrt(distance1.squeeze(0) + 1e-06)\n    objectness_targets = points.new_zeros(proposal_num, dtype=torch.long)\n    objectness_targets[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1\n    objectness_masks = points.new_zeros(proposal_num)\n    objectness_masks[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1.0\n    objectness_masks[euclidean_distance1 > self.train_cfg['neg_distance_thr']] = 1.0\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = size_res_targets[assignment]\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment]\n    assigned_center_targets = center_targets[assignment]\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets.long(), objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets of vote head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    num_points = points.shape[0]\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 3 * self.gt_per_seed])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_all(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            vote_target_masks[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                if j == 0:\n                    vote_targets_tmp[column_indices] = votes[column_indices].repeat(1, self.gt_per_seed)\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n    elif pts_semantic_mask is not None:\n        vote_targets = points.new_zeros([num_points, 3])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                vote_targets[indices, :] = center - selected_points\n                vote_target_masks[indices] = 1\n        vote_targets = vote_targets.repeat((1, self.gt_per_seed))\n    else:\n        raise NotImplementedError\n    (center_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    proposal_num = aggregated_points.shape[0]\n    (distance1, _, assignment, _) = chamfer_distance(aggregated_points.unsqueeze(0), center_targets.unsqueeze(0), reduction='none')\n    assignment = assignment.squeeze(0)\n    euclidean_distance1 = torch.sqrt(distance1.squeeze(0) + 1e-06)\n    objectness_targets = points.new_zeros(proposal_num, dtype=torch.long)\n    objectness_targets[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1\n    objectness_masks = points.new_zeros(proposal_num)\n    objectness_masks[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1.0\n    objectness_masks[euclidean_distance1 > self.train_cfg['neg_distance_thr']] = 1.0\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = size_res_targets[assignment]\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment]\n    assigned_center_targets = center_targets[assignment]\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets.long(), objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets of vote head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    num_points = points.shape[0]\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 3 * self.gt_per_seed])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_all(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            vote_target_masks[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                if j == 0:\n                    vote_targets_tmp[column_indices] = votes[column_indices].repeat(1, self.gt_per_seed)\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n    elif pts_semantic_mask is not None:\n        vote_targets = points.new_zeros([num_points, 3])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                vote_targets[indices, :] = center - selected_points\n                vote_target_masks[indices] = 1\n        vote_targets = vote_targets.repeat((1, self.gt_per_seed))\n    else:\n        raise NotImplementedError\n    (center_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    proposal_num = aggregated_points.shape[0]\n    (distance1, _, assignment, _) = chamfer_distance(aggregated_points.unsqueeze(0), center_targets.unsqueeze(0), reduction='none')\n    assignment = assignment.squeeze(0)\n    euclidean_distance1 = torch.sqrt(distance1.squeeze(0) + 1e-06)\n    objectness_targets = points.new_zeros(proposal_num, dtype=torch.long)\n    objectness_targets[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1\n    objectness_masks = points.new_zeros(proposal_num)\n    objectness_masks[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1.0\n    objectness_masks[euclidean_distance1 > self.train_cfg['neg_distance_thr']] = 1.0\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = size_res_targets[assignment]\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment]\n    assigned_center_targets = center_targets[assignment]\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets.long(), objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets of vote head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of vote head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    num_points = points.shape[0]\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 3 * self.gt_per_seed])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_all(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            vote_target_masks[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                if j == 0:\n                    vote_targets_tmp[column_indices] = votes[column_indices].repeat(1, self.gt_per_seed)\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n    elif pts_semantic_mask is not None:\n        vote_targets = points.new_zeros([num_points, 3])\n        vote_target_masks = points.new_zeros([num_points], dtype=torch.long)\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                vote_targets[indices, :] = center - selected_points\n                vote_target_masks[indices] = 1\n        vote_targets = vote_targets.repeat((1, self.gt_per_seed))\n    else:\n        raise NotImplementedError\n    (center_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    proposal_num = aggregated_points.shape[0]\n    (distance1, _, assignment, _) = chamfer_distance(aggregated_points.unsqueeze(0), center_targets.unsqueeze(0), reduction='none')\n    assignment = assignment.squeeze(0)\n    euclidean_distance1 = torch.sqrt(distance1.squeeze(0) + 1e-06)\n    objectness_targets = points.new_zeros(proposal_num, dtype=torch.long)\n    objectness_targets[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1\n    objectness_masks = points.new_zeros(proposal_num)\n    objectness_masks[euclidean_distance1 < self.train_cfg['pos_distance_thr']] = 1.0\n    objectness_masks[euclidean_distance1 > self.train_cfg['neg_distance_thr']] = 1.0\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = size_res_targets[assignment]\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment]\n    assigned_center_targets = center_targets[assignment]\n    return (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets.long(), objectness_targets, objectness_masks)"
        ]
    },
    {
        "func_name": "get_bboxes",
        "original": "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    \"\"\"Generate bboxes from vote head predictions.\n\n        Args:\n            points (torch.Tensor): Input points.\n            bbox_preds (dict): Predictions from vote head.\n            input_metas (list[dict]): Point cloud and image's meta info.\n            rescale (bool): Whether to rescale bboxes.\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\n                while using vote head in rpn stage.\n\n        Returns:\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\n        \"\"\"\n    obj_scores = F.softmax(bbox_preds['obj_scores'], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    bbox3d = self.bbox_coder.decode(bbox_preds)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
        "mutated": [
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using vote head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores'], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    bbox3d = self.bbox_coder.decode(bbox_preds)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using vote head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores'], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    bbox3d = self.bbox_coder.decode(bbox_preds)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using vote head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores'], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    bbox3d = self.bbox_coder.decode(bbox_preds)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using vote head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores'], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    bbox3d = self.bbox_coder.decode(bbox_preds)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using vote head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores'], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    bbox3d = self.bbox_coder.decode(bbox_preds)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d"
        ]
    },
    {
        "func_name": "multiclass_nms_single",
        "original": "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    \"\"\"Multi-class nms in single batch.\n\n        Args:\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\n            bbox (torch.Tensor): Predicted bounding boxes.\n            points (torch.Tensor): Input points.\n            input_meta (dict): Point cloud and image's meta info.\n\n        Returns:\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\n        \"\"\"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
        "mutated": [
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)"
        ]
    }
]