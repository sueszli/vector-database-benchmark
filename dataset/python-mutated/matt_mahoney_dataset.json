[
    {
        "func_name": "load_matt_mahoney_text8_dataset",
        "original": "def load_matt_mahoney_text8_dataset(path='data'):\n    \"\"\"Load Matt Mahoney's dataset.\n\n    Download a text file from Matt Mahoney's website\n    if not present, and make sure it's the right size.\n    Extract the first file enclosed in a zip file as a list of words.\n    This dataset can be used for Word Embedding.\n\n    Parameters\n    ----------\n    path : str\n        The path that the data is downloaded to, defaults is ``data/mm_test8/``.\n\n    Returns\n    --------\n    list of str\n        The raw text data e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\n\n    Examples\n    --------\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\n    >>> print('Data size', len(words))\n\n    \"\"\"\n    path = os.path.join(path, 'mm_test8')\n    logging.info('Load or Download matt_mahoney_text8 Dataset> {}'.format(path))\n    filename = 'text8.zip'\n    url = 'http://mattmahoney.net/dc/'\n    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\n    with zipfile.ZipFile(os.path.join(path, filename)) as f:\n        word_list = f.read(f.namelist()[0]).split()\n        for (idx, _) in enumerate(word_list):\n            word_list[idx] = word_list[idx].decode()\n    return word_list",
        "mutated": [
            "def load_matt_mahoney_text8_dataset(path='data'):\n    if False:\n        i = 10\n    \"Load Matt Mahoney's dataset.\\n\\n    Download a text file from Matt Mahoney's website\\n    if not present, and make sure it's the right size.\\n    Extract the first file enclosed in a zip file as a list of words.\\n    This dataset can be used for Word Embedding.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/mm_test8/``.\\n\\n    Returns\\n    --------\\n    list of str\\n        The raw text data e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\\n\\n    Examples\\n    --------\\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\\n    >>> print('Data size', len(words))\\n\\n    \"\n    path = os.path.join(path, 'mm_test8')\n    logging.info('Load or Download matt_mahoney_text8 Dataset> {}'.format(path))\n    filename = 'text8.zip'\n    url = 'http://mattmahoney.net/dc/'\n    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\n    with zipfile.ZipFile(os.path.join(path, filename)) as f:\n        word_list = f.read(f.namelist()[0]).split()\n        for (idx, _) in enumerate(word_list):\n            word_list[idx] = word_list[idx].decode()\n    return word_list",
            "def load_matt_mahoney_text8_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Load Matt Mahoney's dataset.\\n\\n    Download a text file from Matt Mahoney's website\\n    if not present, and make sure it's the right size.\\n    Extract the first file enclosed in a zip file as a list of words.\\n    This dataset can be used for Word Embedding.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/mm_test8/``.\\n\\n    Returns\\n    --------\\n    list of str\\n        The raw text data e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\\n\\n    Examples\\n    --------\\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\\n    >>> print('Data size', len(words))\\n\\n    \"\n    path = os.path.join(path, 'mm_test8')\n    logging.info('Load or Download matt_mahoney_text8 Dataset> {}'.format(path))\n    filename = 'text8.zip'\n    url = 'http://mattmahoney.net/dc/'\n    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\n    with zipfile.ZipFile(os.path.join(path, filename)) as f:\n        word_list = f.read(f.namelist()[0]).split()\n        for (idx, _) in enumerate(word_list):\n            word_list[idx] = word_list[idx].decode()\n    return word_list",
            "def load_matt_mahoney_text8_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Load Matt Mahoney's dataset.\\n\\n    Download a text file from Matt Mahoney's website\\n    if not present, and make sure it's the right size.\\n    Extract the first file enclosed in a zip file as a list of words.\\n    This dataset can be used for Word Embedding.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/mm_test8/``.\\n\\n    Returns\\n    --------\\n    list of str\\n        The raw text data e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\\n\\n    Examples\\n    --------\\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\\n    >>> print('Data size', len(words))\\n\\n    \"\n    path = os.path.join(path, 'mm_test8')\n    logging.info('Load or Download matt_mahoney_text8 Dataset> {}'.format(path))\n    filename = 'text8.zip'\n    url = 'http://mattmahoney.net/dc/'\n    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\n    with zipfile.ZipFile(os.path.join(path, filename)) as f:\n        word_list = f.read(f.namelist()[0]).split()\n        for (idx, _) in enumerate(word_list):\n            word_list[idx] = word_list[idx].decode()\n    return word_list",
            "def load_matt_mahoney_text8_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Load Matt Mahoney's dataset.\\n\\n    Download a text file from Matt Mahoney's website\\n    if not present, and make sure it's the right size.\\n    Extract the first file enclosed in a zip file as a list of words.\\n    This dataset can be used for Word Embedding.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/mm_test8/``.\\n\\n    Returns\\n    --------\\n    list of str\\n        The raw text data e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\\n\\n    Examples\\n    --------\\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\\n    >>> print('Data size', len(words))\\n\\n    \"\n    path = os.path.join(path, 'mm_test8')\n    logging.info('Load or Download matt_mahoney_text8 Dataset> {}'.format(path))\n    filename = 'text8.zip'\n    url = 'http://mattmahoney.net/dc/'\n    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\n    with zipfile.ZipFile(os.path.join(path, filename)) as f:\n        word_list = f.read(f.namelist()[0]).split()\n        for (idx, _) in enumerate(word_list):\n            word_list[idx] = word_list[idx].decode()\n    return word_list",
            "def load_matt_mahoney_text8_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Load Matt Mahoney's dataset.\\n\\n    Download a text file from Matt Mahoney's website\\n    if not present, and make sure it's the right size.\\n    Extract the first file enclosed in a zip file as a list of words.\\n    This dataset can be used for Word Embedding.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/mm_test8/``.\\n\\n    Returns\\n    --------\\n    list of str\\n        The raw text data e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\\n\\n    Examples\\n    --------\\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\\n    >>> print('Data size', len(words))\\n\\n    \"\n    path = os.path.join(path, 'mm_test8')\n    logging.info('Load or Download matt_mahoney_text8 Dataset> {}'.format(path))\n    filename = 'text8.zip'\n    url = 'http://mattmahoney.net/dc/'\n    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\n    with zipfile.ZipFile(os.path.join(path, filename)) as f:\n        word_list = f.read(f.namelist()[0]).split()\n        for (idx, _) in enumerate(word_list):\n            word_list[idx] = word_list[idx].decode()\n    return word_list"
        ]
    }
]