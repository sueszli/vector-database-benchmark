[
    {
        "func_name": "load_mtpl2",
        "original": "def load_mtpl2(n_samples=None):\n    \"\"\"Fetch the French Motor Third-Party Liability Claims dataset.\n\n    Parameters\n    ----------\n    n_samples: int, default=None\n      number of samples to select (for faster run time). Full dataset has\n      678013 samples.\n    \"\"\"\n    df_freq = fetch_openml(data_id=41214, as_frame=True, parser='pandas').data\n    df_freq['IDpol'] = df_freq['IDpol'].astype(int)\n    df_freq.set_index('IDpol', inplace=True)\n    df_sev = fetch_openml(data_id=41215, as_frame=True, parser='pandas').data\n    df_sev = df_sev.groupby('IDpol').sum()\n    df = df_freq.join(df_sev, how='left')\n    df['ClaimAmount'].fillna(0, inplace=True)\n    for column_name in df.columns[df.dtypes.values == object]:\n        df[column_name] = df[column_name].str.strip(\"'\")\n    return df.iloc[:n_samples]",
        "mutated": [
            "def load_mtpl2(n_samples=None):\n    if False:\n        i = 10\n    'Fetch the French Motor Third-Party Liability Claims dataset.\\n\\n    Parameters\\n    ----------\\n    n_samples: int, default=None\\n      number of samples to select (for faster run time). Full dataset has\\n      678013 samples.\\n    '\n    df_freq = fetch_openml(data_id=41214, as_frame=True, parser='pandas').data\n    df_freq['IDpol'] = df_freq['IDpol'].astype(int)\n    df_freq.set_index('IDpol', inplace=True)\n    df_sev = fetch_openml(data_id=41215, as_frame=True, parser='pandas').data\n    df_sev = df_sev.groupby('IDpol').sum()\n    df = df_freq.join(df_sev, how='left')\n    df['ClaimAmount'].fillna(0, inplace=True)\n    for column_name in df.columns[df.dtypes.values == object]:\n        df[column_name] = df[column_name].str.strip(\"'\")\n    return df.iloc[:n_samples]",
            "def load_mtpl2(n_samples=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Fetch the French Motor Third-Party Liability Claims dataset.\\n\\n    Parameters\\n    ----------\\n    n_samples: int, default=None\\n      number of samples to select (for faster run time). Full dataset has\\n      678013 samples.\\n    '\n    df_freq = fetch_openml(data_id=41214, as_frame=True, parser='pandas').data\n    df_freq['IDpol'] = df_freq['IDpol'].astype(int)\n    df_freq.set_index('IDpol', inplace=True)\n    df_sev = fetch_openml(data_id=41215, as_frame=True, parser='pandas').data\n    df_sev = df_sev.groupby('IDpol').sum()\n    df = df_freq.join(df_sev, how='left')\n    df['ClaimAmount'].fillna(0, inplace=True)\n    for column_name in df.columns[df.dtypes.values == object]:\n        df[column_name] = df[column_name].str.strip(\"'\")\n    return df.iloc[:n_samples]",
            "def load_mtpl2(n_samples=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Fetch the French Motor Third-Party Liability Claims dataset.\\n\\n    Parameters\\n    ----------\\n    n_samples: int, default=None\\n      number of samples to select (for faster run time). Full dataset has\\n      678013 samples.\\n    '\n    df_freq = fetch_openml(data_id=41214, as_frame=True, parser='pandas').data\n    df_freq['IDpol'] = df_freq['IDpol'].astype(int)\n    df_freq.set_index('IDpol', inplace=True)\n    df_sev = fetch_openml(data_id=41215, as_frame=True, parser='pandas').data\n    df_sev = df_sev.groupby('IDpol').sum()\n    df = df_freq.join(df_sev, how='left')\n    df['ClaimAmount'].fillna(0, inplace=True)\n    for column_name in df.columns[df.dtypes.values == object]:\n        df[column_name] = df[column_name].str.strip(\"'\")\n    return df.iloc[:n_samples]",
            "def load_mtpl2(n_samples=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Fetch the French Motor Third-Party Liability Claims dataset.\\n\\n    Parameters\\n    ----------\\n    n_samples: int, default=None\\n      number of samples to select (for faster run time). Full dataset has\\n      678013 samples.\\n    '\n    df_freq = fetch_openml(data_id=41214, as_frame=True, parser='pandas').data\n    df_freq['IDpol'] = df_freq['IDpol'].astype(int)\n    df_freq.set_index('IDpol', inplace=True)\n    df_sev = fetch_openml(data_id=41215, as_frame=True, parser='pandas').data\n    df_sev = df_sev.groupby('IDpol').sum()\n    df = df_freq.join(df_sev, how='left')\n    df['ClaimAmount'].fillna(0, inplace=True)\n    for column_name in df.columns[df.dtypes.values == object]:\n        df[column_name] = df[column_name].str.strip(\"'\")\n    return df.iloc[:n_samples]",
            "def load_mtpl2(n_samples=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Fetch the French Motor Third-Party Liability Claims dataset.\\n\\n    Parameters\\n    ----------\\n    n_samples: int, default=None\\n      number of samples to select (for faster run time). Full dataset has\\n      678013 samples.\\n    '\n    df_freq = fetch_openml(data_id=41214, as_frame=True, parser='pandas').data\n    df_freq['IDpol'] = df_freq['IDpol'].astype(int)\n    df_freq.set_index('IDpol', inplace=True)\n    df_sev = fetch_openml(data_id=41215, as_frame=True, parser='pandas').data\n    df_sev = df_sev.groupby('IDpol').sum()\n    df = df_freq.join(df_sev, how='left')\n    df['ClaimAmount'].fillna(0, inplace=True)\n    for column_name in df.columns[df.dtypes.values == object]:\n        df[column_name] = df[column_name].str.strip(\"'\")\n    return df.iloc[:n_samples]"
        ]
    },
    {
        "func_name": "plot_obs_pred",
        "original": "def plot_obs_pred(df, feature, weight, observed, predicted, y_label=None, title=None, ax=None, fill_legend=False):\n    \"\"\"Plot observed and predicted - aggregated per feature level.\n\n    Parameters\n    ----------\n    df : DataFrame\n        input data\n    feature: str\n        a column name of df for the feature to be plotted\n    weight : str\n        column name of df with the values of weights or exposure\n    observed : str\n        a column name of df with the observed target\n    predicted : DataFrame\n        a dataframe, with the same index as df, with the predicted target\n    fill_legend : bool, default=False\n        whether to show fill_between legend\n    \"\"\"\n    df_ = df.loc[:, [feature, weight]].copy()\n    df_['observed'] = df[observed] * df[weight]\n    df_['predicted'] = predicted * df[weight]\n    df_ = df_.groupby([feature])[[weight, 'observed', 'predicted']].sum().assign(observed=lambda x: x['observed'] / x[weight]).assign(predicted=lambda x: x['predicted'] / x[weight])\n    ax = df_.loc[:, ['observed', 'predicted']].plot(style='.', ax=ax)\n    y_max = df_.loc[:, ['observed', 'predicted']].values.max() * 0.8\n    p2 = ax.fill_between(df_.index, 0, y_max * df_[weight] / df_[weight].values.max(), color='g', alpha=0.1)\n    if fill_legend:\n        ax.legend([p2], ['{} distribution'.format(feature)])\n    ax.set(ylabel=y_label if y_label is not None else None, title=title if title is not None else 'Train: Observed vs Predicted')",
        "mutated": [
            "def plot_obs_pred(df, feature, weight, observed, predicted, y_label=None, title=None, ax=None, fill_legend=False):\n    if False:\n        i = 10\n    'Plot observed and predicted - aggregated per feature level.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n        input data\\n    feature: str\\n        a column name of df for the feature to be plotted\\n    weight : str\\n        column name of df with the values of weights or exposure\\n    observed : str\\n        a column name of df with the observed target\\n    predicted : DataFrame\\n        a dataframe, with the same index as df, with the predicted target\\n    fill_legend : bool, default=False\\n        whether to show fill_between legend\\n    '\n    df_ = df.loc[:, [feature, weight]].copy()\n    df_['observed'] = df[observed] * df[weight]\n    df_['predicted'] = predicted * df[weight]\n    df_ = df_.groupby([feature])[[weight, 'observed', 'predicted']].sum().assign(observed=lambda x: x['observed'] / x[weight]).assign(predicted=lambda x: x['predicted'] / x[weight])\n    ax = df_.loc[:, ['observed', 'predicted']].plot(style='.', ax=ax)\n    y_max = df_.loc[:, ['observed', 'predicted']].values.max() * 0.8\n    p2 = ax.fill_between(df_.index, 0, y_max * df_[weight] / df_[weight].values.max(), color='g', alpha=0.1)\n    if fill_legend:\n        ax.legend([p2], ['{} distribution'.format(feature)])\n    ax.set(ylabel=y_label if y_label is not None else None, title=title if title is not None else 'Train: Observed vs Predicted')",
            "def plot_obs_pred(df, feature, weight, observed, predicted, y_label=None, title=None, ax=None, fill_legend=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Plot observed and predicted - aggregated per feature level.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n        input data\\n    feature: str\\n        a column name of df for the feature to be plotted\\n    weight : str\\n        column name of df with the values of weights or exposure\\n    observed : str\\n        a column name of df with the observed target\\n    predicted : DataFrame\\n        a dataframe, with the same index as df, with the predicted target\\n    fill_legend : bool, default=False\\n        whether to show fill_between legend\\n    '\n    df_ = df.loc[:, [feature, weight]].copy()\n    df_['observed'] = df[observed] * df[weight]\n    df_['predicted'] = predicted * df[weight]\n    df_ = df_.groupby([feature])[[weight, 'observed', 'predicted']].sum().assign(observed=lambda x: x['observed'] / x[weight]).assign(predicted=lambda x: x['predicted'] / x[weight])\n    ax = df_.loc[:, ['observed', 'predicted']].plot(style='.', ax=ax)\n    y_max = df_.loc[:, ['observed', 'predicted']].values.max() * 0.8\n    p2 = ax.fill_between(df_.index, 0, y_max * df_[weight] / df_[weight].values.max(), color='g', alpha=0.1)\n    if fill_legend:\n        ax.legend([p2], ['{} distribution'.format(feature)])\n    ax.set(ylabel=y_label if y_label is not None else None, title=title if title is not None else 'Train: Observed vs Predicted')",
            "def plot_obs_pred(df, feature, weight, observed, predicted, y_label=None, title=None, ax=None, fill_legend=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Plot observed and predicted - aggregated per feature level.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n        input data\\n    feature: str\\n        a column name of df for the feature to be plotted\\n    weight : str\\n        column name of df with the values of weights or exposure\\n    observed : str\\n        a column name of df with the observed target\\n    predicted : DataFrame\\n        a dataframe, with the same index as df, with the predicted target\\n    fill_legend : bool, default=False\\n        whether to show fill_between legend\\n    '\n    df_ = df.loc[:, [feature, weight]].copy()\n    df_['observed'] = df[observed] * df[weight]\n    df_['predicted'] = predicted * df[weight]\n    df_ = df_.groupby([feature])[[weight, 'observed', 'predicted']].sum().assign(observed=lambda x: x['observed'] / x[weight]).assign(predicted=lambda x: x['predicted'] / x[weight])\n    ax = df_.loc[:, ['observed', 'predicted']].plot(style='.', ax=ax)\n    y_max = df_.loc[:, ['observed', 'predicted']].values.max() * 0.8\n    p2 = ax.fill_between(df_.index, 0, y_max * df_[weight] / df_[weight].values.max(), color='g', alpha=0.1)\n    if fill_legend:\n        ax.legend([p2], ['{} distribution'.format(feature)])\n    ax.set(ylabel=y_label if y_label is not None else None, title=title if title is not None else 'Train: Observed vs Predicted')",
            "def plot_obs_pred(df, feature, weight, observed, predicted, y_label=None, title=None, ax=None, fill_legend=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Plot observed and predicted - aggregated per feature level.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n        input data\\n    feature: str\\n        a column name of df for the feature to be plotted\\n    weight : str\\n        column name of df with the values of weights or exposure\\n    observed : str\\n        a column name of df with the observed target\\n    predicted : DataFrame\\n        a dataframe, with the same index as df, with the predicted target\\n    fill_legend : bool, default=False\\n        whether to show fill_between legend\\n    '\n    df_ = df.loc[:, [feature, weight]].copy()\n    df_['observed'] = df[observed] * df[weight]\n    df_['predicted'] = predicted * df[weight]\n    df_ = df_.groupby([feature])[[weight, 'observed', 'predicted']].sum().assign(observed=lambda x: x['observed'] / x[weight]).assign(predicted=lambda x: x['predicted'] / x[weight])\n    ax = df_.loc[:, ['observed', 'predicted']].plot(style='.', ax=ax)\n    y_max = df_.loc[:, ['observed', 'predicted']].values.max() * 0.8\n    p2 = ax.fill_between(df_.index, 0, y_max * df_[weight] / df_[weight].values.max(), color='g', alpha=0.1)\n    if fill_legend:\n        ax.legend([p2], ['{} distribution'.format(feature)])\n    ax.set(ylabel=y_label if y_label is not None else None, title=title if title is not None else 'Train: Observed vs Predicted')",
            "def plot_obs_pred(df, feature, weight, observed, predicted, y_label=None, title=None, ax=None, fill_legend=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Plot observed and predicted - aggregated per feature level.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n        input data\\n    feature: str\\n        a column name of df for the feature to be plotted\\n    weight : str\\n        column name of df with the values of weights or exposure\\n    observed : str\\n        a column name of df with the observed target\\n    predicted : DataFrame\\n        a dataframe, with the same index as df, with the predicted target\\n    fill_legend : bool, default=False\\n        whether to show fill_between legend\\n    '\n    df_ = df.loc[:, [feature, weight]].copy()\n    df_['observed'] = df[observed] * df[weight]\n    df_['predicted'] = predicted * df[weight]\n    df_ = df_.groupby([feature])[[weight, 'observed', 'predicted']].sum().assign(observed=lambda x: x['observed'] / x[weight]).assign(predicted=lambda x: x['predicted'] / x[weight])\n    ax = df_.loc[:, ['observed', 'predicted']].plot(style='.', ax=ax)\n    y_max = df_.loc[:, ['observed', 'predicted']].values.max() * 0.8\n    p2 = ax.fill_between(df_.index, 0, y_max * df_[weight] / df_[weight].values.max(), color='g', alpha=0.1)\n    if fill_legend:\n        ax.legend([p2], ['{} distribution'.format(feature)])\n    ax.set(ylabel=y_label if y_label is not None else None, title=title if title is not None else 'Train: Observed vs Predicted')"
        ]
    },
    {
        "func_name": "score_estimator",
        "original": "def score_estimator(estimator, X_train, X_test, df_train, df_test, target, weights, tweedie_powers=None):\n    \"\"\"Evaluate an estimator on train and test sets with different metrics\"\"\"\n    metrics = [('D\u00b2 explained', None), ('mean abs. error', mean_absolute_error), ('mean squared error', mean_squared_error)]\n    if tweedie_powers:\n        metrics += [('mean Tweedie dev p={:.4f}'.format(power), partial(mean_tweedie_deviance, power=power)) for power in tweedie_powers]\n    res = []\n    for (subset_label, X, df) in [('train', X_train, df_train), ('test', X_test, df_test)]:\n        (y, _weights) = (df[target], df[weights])\n        for (score_label, metric) in metrics:\n            if isinstance(estimator, tuple) and len(estimator) == 2:\n                (est_freq, est_sev) = estimator\n                y_pred = est_freq.predict(X) * est_sev.predict(X)\n            else:\n                y_pred = estimator.predict(X)\n            if metric is None:\n                if not hasattr(estimator, 'score'):\n                    continue\n                score = estimator.score(X, y, sample_weight=_weights)\n            else:\n                score = metric(y, y_pred, sample_weight=_weights)\n            res.append({'subset': subset_label, 'metric': score_label, 'score': score})\n    res = pd.DataFrame(res).set_index(['metric', 'subset']).score.unstack(-1).round(4).loc[:, ['train', 'test']]\n    return res",
        "mutated": [
            "def score_estimator(estimator, X_train, X_test, df_train, df_test, target, weights, tweedie_powers=None):\n    if False:\n        i = 10\n    'Evaluate an estimator on train and test sets with different metrics'\n    metrics = [('D\u00b2 explained', None), ('mean abs. error', mean_absolute_error), ('mean squared error', mean_squared_error)]\n    if tweedie_powers:\n        metrics += [('mean Tweedie dev p={:.4f}'.format(power), partial(mean_tweedie_deviance, power=power)) for power in tweedie_powers]\n    res = []\n    for (subset_label, X, df) in [('train', X_train, df_train), ('test', X_test, df_test)]:\n        (y, _weights) = (df[target], df[weights])\n        for (score_label, metric) in metrics:\n            if isinstance(estimator, tuple) and len(estimator) == 2:\n                (est_freq, est_sev) = estimator\n                y_pred = est_freq.predict(X) * est_sev.predict(X)\n            else:\n                y_pred = estimator.predict(X)\n            if metric is None:\n                if not hasattr(estimator, 'score'):\n                    continue\n                score = estimator.score(X, y, sample_weight=_weights)\n            else:\n                score = metric(y, y_pred, sample_weight=_weights)\n            res.append({'subset': subset_label, 'metric': score_label, 'score': score})\n    res = pd.DataFrame(res).set_index(['metric', 'subset']).score.unstack(-1).round(4).loc[:, ['train', 'test']]\n    return res",
            "def score_estimator(estimator, X_train, X_test, df_train, df_test, target, weights, tweedie_powers=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Evaluate an estimator on train and test sets with different metrics'\n    metrics = [('D\u00b2 explained', None), ('mean abs. error', mean_absolute_error), ('mean squared error', mean_squared_error)]\n    if tweedie_powers:\n        metrics += [('mean Tweedie dev p={:.4f}'.format(power), partial(mean_tweedie_deviance, power=power)) for power in tweedie_powers]\n    res = []\n    for (subset_label, X, df) in [('train', X_train, df_train), ('test', X_test, df_test)]:\n        (y, _weights) = (df[target], df[weights])\n        for (score_label, metric) in metrics:\n            if isinstance(estimator, tuple) and len(estimator) == 2:\n                (est_freq, est_sev) = estimator\n                y_pred = est_freq.predict(X) * est_sev.predict(X)\n            else:\n                y_pred = estimator.predict(X)\n            if metric is None:\n                if not hasattr(estimator, 'score'):\n                    continue\n                score = estimator.score(X, y, sample_weight=_weights)\n            else:\n                score = metric(y, y_pred, sample_weight=_weights)\n            res.append({'subset': subset_label, 'metric': score_label, 'score': score})\n    res = pd.DataFrame(res).set_index(['metric', 'subset']).score.unstack(-1).round(4).loc[:, ['train', 'test']]\n    return res",
            "def score_estimator(estimator, X_train, X_test, df_train, df_test, target, weights, tweedie_powers=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Evaluate an estimator on train and test sets with different metrics'\n    metrics = [('D\u00b2 explained', None), ('mean abs. error', mean_absolute_error), ('mean squared error', mean_squared_error)]\n    if tweedie_powers:\n        metrics += [('mean Tweedie dev p={:.4f}'.format(power), partial(mean_tweedie_deviance, power=power)) for power in tweedie_powers]\n    res = []\n    for (subset_label, X, df) in [('train', X_train, df_train), ('test', X_test, df_test)]:\n        (y, _weights) = (df[target], df[weights])\n        for (score_label, metric) in metrics:\n            if isinstance(estimator, tuple) and len(estimator) == 2:\n                (est_freq, est_sev) = estimator\n                y_pred = est_freq.predict(X) * est_sev.predict(X)\n            else:\n                y_pred = estimator.predict(X)\n            if metric is None:\n                if not hasattr(estimator, 'score'):\n                    continue\n                score = estimator.score(X, y, sample_weight=_weights)\n            else:\n                score = metric(y, y_pred, sample_weight=_weights)\n            res.append({'subset': subset_label, 'metric': score_label, 'score': score})\n    res = pd.DataFrame(res).set_index(['metric', 'subset']).score.unstack(-1).round(4).loc[:, ['train', 'test']]\n    return res",
            "def score_estimator(estimator, X_train, X_test, df_train, df_test, target, weights, tweedie_powers=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Evaluate an estimator on train and test sets with different metrics'\n    metrics = [('D\u00b2 explained', None), ('mean abs. error', mean_absolute_error), ('mean squared error', mean_squared_error)]\n    if tweedie_powers:\n        metrics += [('mean Tweedie dev p={:.4f}'.format(power), partial(mean_tweedie_deviance, power=power)) for power in tweedie_powers]\n    res = []\n    for (subset_label, X, df) in [('train', X_train, df_train), ('test', X_test, df_test)]:\n        (y, _weights) = (df[target], df[weights])\n        for (score_label, metric) in metrics:\n            if isinstance(estimator, tuple) and len(estimator) == 2:\n                (est_freq, est_sev) = estimator\n                y_pred = est_freq.predict(X) * est_sev.predict(X)\n            else:\n                y_pred = estimator.predict(X)\n            if metric is None:\n                if not hasattr(estimator, 'score'):\n                    continue\n                score = estimator.score(X, y, sample_weight=_weights)\n            else:\n                score = metric(y, y_pred, sample_weight=_weights)\n            res.append({'subset': subset_label, 'metric': score_label, 'score': score})\n    res = pd.DataFrame(res).set_index(['metric', 'subset']).score.unstack(-1).round(4).loc[:, ['train', 'test']]\n    return res",
            "def score_estimator(estimator, X_train, X_test, df_train, df_test, target, weights, tweedie_powers=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Evaluate an estimator on train and test sets with different metrics'\n    metrics = [('D\u00b2 explained', None), ('mean abs. error', mean_absolute_error), ('mean squared error', mean_squared_error)]\n    if tweedie_powers:\n        metrics += [('mean Tweedie dev p={:.4f}'.format(power), partial(mean_tweedie_deviance, power=power)) for power in tweedie_powers]\n    res = []\n    for (subset_label, X, df) in [('train', X_train, df_train), ('test', X_test, df_test)]:\n        (y, _weights) = (df[target], df[weights])\n        for (score_label, metric) in metrics:\n            if isinstance(estimator, tuple) and len(estimator) == 2:\n                (est_freq, est_sev) = estimator\n                y_pred = est_freq.predict(X) * est_sev.predict(X)\n            else:\n                y_pred = estimator.predict(X)\n            if metric is None:\n                if not hasattr(estimator, 'score'):\n                    continue\n                score = estimator.score(X, y, sample_weight=_weights)\n            else:\n                score = metric(y, y_pred, sample_weight=_weights)\n            res.append({'subset': subset_label, 'metric': score_label, 'score': score})\n    res = pd.DataFrame(res).set_index(['metric', 'subset']).score.unstack(-1).round(4).loc[:, ['train', 'test']]\n    return res"
        ]
    },
    {
        "func_name": "lorenz_curve",
        "original": "def lorenz_curve(y_true, y_pred, exposure):\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_exposure = exposure[ranking]\n    ranked_pure_premium = y_true[ranking]\n    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n    cumulated_claim_amount /= cumulated_claim_amount[-1]\n    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n    return (cumulated_samples, cumulated_claim_amount)",
        "mutated": [
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_exposure = exposure[ranking]\n    ranked_pure_premium = y_true[ranking]\n    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n    cumulated_claim_amount /= cumulated_claim_amount[-1]\n    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n    return (cumulated_samples, cumulated_claim_amount)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_exposure = exposure[ranking]\n    ranked_pure_premium = y_true[ranking]\n    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n    cumulated_claim_amount /= cumulated_claim_amount[-1]\n    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n    return (cumulated_samples, cumulated_claim_amount)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_exposure = exposure[ranking]\n    ranked_pure_premium = y_true[ranking]\n    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n    cumulated_claim_amount /= cumulated_claim_amount[-1]\n    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n    return (cumulated_samples, cumulated_claim_amount)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_exposure = exposure[ranking]\n    ranked_pure_premium = y_true[ranking]\n    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n    cumulated_claim_amount /= cumulated_claim_amount[-1]\n    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n    return (cumulated_samples, cumulated_claim_amount)",
            "def lorenz_curve(y_true, y_pred, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (y_true, y_pred) = (np.asarray(y_true), np.asarray(y_pred))\n    exposure = np.asarray(exposure)\n    ranking = np.argsort(y_pred)\n    ranked_exposure = exposure[ranking]\n    ranked_pure_premium = y_true[ranking]\n    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n    cumulated_claim_amount /= cumulated_claim_amount[-1]\n    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n    return (cumulated_samples, cumulated_claim_amount)"
        ]
    }
]