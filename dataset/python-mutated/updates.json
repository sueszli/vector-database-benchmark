[
    {
        "func_name": "__init__",
        "original": "def __init__(self, proj_grad=True, euclidean=False, rnd_init=False, seed=None):\n    \"\"\"Ctor.\"\"\"\n    self.num_players = None\n    self.proj_grad = proj_grad\n    self.rnd_init = rnd_init\n    self.lrs = (None,)\n    self.has_aux = False\n    self.euclidean = euclidean\n    if euclidean:\n        self.update = self.euc_descent_step\n    else:\n        self.update = self.mirror_descent_step\n    self.seed = seed\n    self.random = np.random.RandomState(seed)",
        "mutated": [
            "def __init__(self, proj_grad=True, euclidean=False, rnd_init=False, seed=None):\n    if False:\n        i = 10\n    'Ctor.'\n    self.num_players = None\n    self.proj_grad = proj_grad\n    self.rnd_init = rnd_init\n    self.lrs = (None,)\n    self.has_aux = False\n    self.euclidean = euclidean\n    if euclidean:\n        self.update = self.euc_descent_step\n    else:\n        self.update = self.mirror_descent_step\n    self.seed = seed\n    self.random = np.random.RandomState(seed)",
            "def __init__(self, proj_grad=True, euclidean=False, rnd_init=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Ctor.'\n    self.num_players = None\n    self.proj_grad = proj_grad\n    self.rnd_init = rnd_init\n    self.lrs = (None,)\n    self.has_aux = False\n    self.euclidean = euclidean\n    if euclidean:\n        self.update = self.euc_descent_step\n    else:\n        self.update = self.mirror_descent_step\n    self.seed = seed\n    self.random = np.random.RandomState(seed)",
            "def __init__(self, proj_grad=True, euclidean=False, rnd_init=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Ctor.'\n    self.num_players = None\n    self.proj_grad = proj_grad\n    self.rnd_init = rnd_init\n    self.lrs = (None,)\n    self.has_aux = False\n    self.euclidean = euclidean\n    if euclidean:\n        self.update = self.euc_descent_step\n    else:\n        self.update = self.mirror_descent_step\n    self.seed = seed\n    self.random = np.random.RandomState(seed)",
            "def __init__(self, proj_grad=True, euclidean=False, rnd_init=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Ctor.'\n    self.num_players = None\n    self.proj_grad = proj_grad\n    self.rnd_init = rnd_init\n    self.lrs = (None,)\n    self.has_aux = False\n    self.euclidean = euclidean\n    if euclidean:\n        self.update = self.euc_descent_step\n    else:\n        self.update = self.mirror_descent_step\n    self.seed = seed\n    self.random = np.random.RandomState(seed)",
            "def __init__(self, proj_grad=True, euclidean=False, rnd_init=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Ctor.'\n    self.num_players = None\n    self.proj_grad = proj_grad\n    self.rnd_init = rnd_init\n    self.lrs = (None,)\n    self.has_aux = False\n    self.euclidean = euclidean\n    if euclidean:\n        self.update = self.euc_descent_step\n    else:\n        self.update = self.mirror_descent_step\n    self.seed = seed\n    self.random = np.random.RandomState(seed)"
        ]
    },
    {
        "func_name": "init_vars",
        "original": "def init_vars(self, num_strats, num_players):\n    \"\"\"Initialize solver parameters.\"\"\"\n    self.num_players = num_players\n    if len(num_strats) != num_players:\n        raise ValueError('Must specify num strategies for each player')\n    init_dist = []\n    for num_strats_i in num_strats:\n        if self.rnd_init:\n            init_dist_i = self.random.rand(num_strats_i)\n        else:\n            init_dist_i = np.ones(num_strats_i)\n        init_dist_i /= init_dist_i.sum()\n        init_dist.append(init_dist_i)\n    return (init_dist,)",
        "mutated": [
            "def init_vars(self, num_strats, num_players):\n    if False:\n        i = 10\n    'Initialize solver parameters.'\n    self.num_players = num_players\n    if len(num_strats) != num_players:\n        raise ValueError('Must specify num strategies for each player')\n    init_dist = []\n    for num_strats_i in num_strats:\n        if self.rnd_init:\n            init_dist_i = self.random.rand(num_strats_i)\n        else:\n            init_dist_i = np.ones(num_strats_i)\n        init_dist_i /= init_dist_i.sum()\n        init_dist.append(init_dist_i)\n    return (init_dist,)",
            "def init_vars(self, num_strats, num_players):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initialize solver parameters.'\n    self.num_players = num_players\n    if len(num_strats) != num_players:\n        raise ValueError('Must specify num strategies for each player')\n    init_dist = []\n    for num_strats_i in num_strats:\n        if self.rnd_init:\n            init_dist_i = self.random.rand(num_strats_i)\n        else:\n            init_dist_i = np.ones(num_strats_i)\n        init_dist_i /= init_dist_i.sum()\n        init_dist.append(init_dist_i)\n    return (init_dist,)",
            "def init_vars(self, num_strats, num_players):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initialize solver parameters.'\n    self.num_players = num_players\n    if len(num_strats) != num_players:\n        raise ValueError('Must specify num strategies for each player')\n    init_dist = []\n    for num_strats_i in num_strats:\n        if self.rnd_init:\n            init_dist_i = self.random.rand(num_strats_i)\n        else:\n            init_dist_i = np.ones(num_strats_i)\n        init_dist_i /= init_dist_i.sum()\n        init_dist.append(init_dist_i)\n    return (init_dist,)",
            "def init_vars(self, num_strats, num_players):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initialize solver parameters.'\n    self.num_players = num_players\n    if len(num_strats) != num_players:\n        raise ValueError('Must specify num strategies for each player')\n    init_dist = []\n    for num_strats_i in num_strats:\n        if self.rnd_init:\n            init_dist_i = self.random.rand(num_strats_i)\n        else:\n            init_dist_i = np.ones(num_strats_i)\n        init_dist_i /= init_dist_i.sum()\n        init_dist.append(init_dist_i)\n    return (init_dist,)",
            "def init_vars(self, num_strats, num_players):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initialize solver parameters.'\n    self.num_players = num_players\n    if len(num_strats) != num_players:\n        raise ValueError('Must specify num strategies for each player')\n    init_dist = []\n    for num_strats_i in num_strats:\n        if self.rnd_init:\n            init_dist_i = self.random.rand(num_strats_i)\n        else:\n            init_dist_i = np.ones(num_strats_i)\n        init_dist_i /= init_dist_i.sum()\n        init_dist.append(init_dist_i)\n    return (init_dist,)"
        ]
    },
    {
        "func_name": "compute_gradients",
        "original": "def compute_gradients(self, params, payoff_matrices):\n    \"\"\"Compute and return gradients for all parameters.\n\n    Args:\n      params: e.g., tuple of params (dist,)\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\n        are sorted and arrays should be indexed in the same order\n    Returns:\n      eg., tuple of gradients (grad_dist,)\n    \"\"\"\n    raise NotImplementedError('Should be implemented by specific solver.')",
        "mutated": [
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n    'Compute and return gradients for all parameters.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      eg., tuple of gradients (grad_dist,)\\n    '\n    raise NotImplementedError('Should be implemented by specific solver.')",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute and return gradients for all parameters.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      eg., tuple of gradients (grad_dist,)\\n    '\n    raise NotImplementedError('Should be implemented by specific solver.')",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute and return gradients for all parameters.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      eg., tuple of gradients (grad_dist,)\\n    '\n    raise NotImplementedError('Should be implemented by specific solver.')",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute and return gradients for all parameters.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      eg., tuple of gradients (grad_dist,)\\n    '\n    raise NotImplementedError('Should be implemented by specific solver.')",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute and return gradients for all parameters.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      eg., tuple of gradients (grad_dist,)\\n    '\n    raise NotImplementedError('Should be implemented by specific solver.')"
        ]
    },
    {
        "func_name": "exploitability",
        "original": "def exploitability(self, params, payoff_tensor):\n    \"\"\"Compute and return exploitability that solver is minimizing.\n\n    Args:\n      params: e.g., tuple of params (dist,)\n      payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint\n        action. can also be list of (A1 x ... x An) np.arrays\n    Returns:\n      float, exploitability of current dist\n    \"\"\"\n    return exploitability.unreg_exploitability(params, payoff_tensor)",
        "mutated": [
            "def exploitability(self, params, payoff_tensor):\n    if False:\n        i = 10\n    'Compute and return exploitability that solver is minimizing.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint\\n        action. can also be list of (A1 x ... x An) np.arrays\\n    Returns:\\n      float, exploitability of current dist\\n    '\n    return exploitability.unreg_exploitability(params, payoff_tensor)",
            "def exploitability(self, params, payoff_tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute and return exploitability that solver is minimizing.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint\\n        action. can also be list of (A1 x ... x An) np.arrays\\n    Returns:\\n      float, exploitability of current dist\\n    '\n    return exploitability.unreg_exploitability(params, payoff_tensor)",
            "def exploitability(self, params, payoff_tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute and return exploitability that solver is minimizing.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint\\n        action. can also be list of (A1 x ... x An) np.arrays\\n    Returns:\\n      float, exploitability of current dist\\n    '\n    return exploitability.unreg_exploitability(params, payoff_tensor)",
            "def exploitability(self, params, payoff_tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute and return exploitability that solver is minimizing.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint\\n        action. can also be list of (A1 x ... x An) np.arrays\\n    Returns:\\n      float, exploitability of current dist\\n    '\n    return exploitability.unreg_exploitability(params, payoff_tensor)",
            "def exploitability(self, params, payoff_tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute and return exploitability that solver is minimizing.\\n\\n    Args:\\n      params: e.g., tuple of params (dist,)\\n      payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint\\n        action. can also be list of (A1 x ... x An) np.arrays\\n    Returns:\\n      float, exploitability of current dist\\n    '\n    return exploitability.unreg_exploitability(params, payoff_tensor)"
        ]
    },
    {
        "func_name": "euc_descent_step",
        "original": "def euc_descent_step(self, params, grads, t):\n    \"\"\"Projected gradient descent on exploitability using Euclidean projection.\n\n    Args:\n      params: tuple of variables to be updated (dist,)\n      grads: tuple of variable gradients (grad_dist,)\n      t: int, solver iteration (unused)\n    Returns:\n      new_params: tuple of update params (new_dist,)\n    \"\"\"\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = dist_i - lr_dist * dist_grad_i\n        new_dist_i = simplex.euclidean_projection_onto_simplex(new_dist_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
        "mutated": [
            "def euc_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n    'Projected gradient descent on exploitability using Euclidean projection.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist,)\\n      grads: tuple of variable gradients (grad_dist,)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist,)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = dist_i - lr_dist * dist_grad_i\n        new_dist_i = simplex.euclidean_projection_onto_simplex(new_dist_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def euc_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Projected gradient descent on exploitability using Euclidean projection.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist,)\\n      grads: tuple of variable gradients (grad_dist,)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist,)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = dist_i - lr_dist * dist_grad_i\n        new_dist_i = simplex.euclidean_projection_onto_simplex(new_dist_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def euc_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Projected gradient descent on exploitability using Euclidean projection.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist,)\\n      grads: tuple of variable gradients (grad_dist,)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist,)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = dist_i - lr_dist * dist_grad_i\n        new_dist_i = simplex.euclidean_projection_onto_simplex(new_dist_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def euc_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Projected gradient descent on exploitability using Euclidean projection.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist,)\\n      grads: tuple of variable gradients (grad_dist,)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist,)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = dist_i - lr_dist * dist_grad_i\n        new_dist_i = simplex.euclidean_projection_onto_simplex(new_dist_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def euc_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Projected gradient descent on exploitability using Euclidean projection.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist,)\\n      grads: tuple of variable gradients (grad_dist,)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist,)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = dist_i - lr_dist * dist_grad_i\n        new_dist_i = simplex.euclidean_projection_onto_simplex(new_dist_i)\n        new_params.append(new_dist_i)\n    return (new_params,)"
        ]
    },
    {
        "func_name": "mirror_descent_step",
        "original": "def mirror_descent_step(self, params, grads, t):\n    \"\"\"Entropic mirror descent on exploitability.\n\n    Args:\n      params: tuple of variables to be updated (dist - a list of np.arrays)\n      grads: tuple of variable gradients (grad_dist - a list of np.arrays)\n      t: int, solver iteration (unused)\n    Returns:\n      new_params: tuple of update params (new_dist)\n    \"\"\"\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = np.clip(dist_i, 0, np.inf)\n        new_dist_i = special.softmax(np.log(new_dist_i) - lr_dist * dist_grad_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
        "mutated": [
            "def mirror_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n    'Entropic mirror descent on exploitability.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist - a list of np.arrays)\\n      grads: tuple of variable gradients (grad_dist - a list of np.arrays)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = np.clip(dist_i, 0, np.inf)\n        new_dist_i = special.softmax(np.log(new_dist_i) - lr_dist * dist_grad_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def mirror_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Entropic mirror descent on exploitability.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist - a list of np.arrays)\\n      grads: tuple of variable gradients (grad_dist - a list of np.arrays)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = np.clip(dist_i, 0, np.inf)\n        new_dist_i = special.softmax(np.log(new_dist_i) - lr_dist * dist_grad_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def mirror_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Entropic mirror descent on exploitability.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist - a list of np.arrays)\\n      grads: tuple of variable gradients (grad_dist - a list of np.arrays)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = np.clip(dist_i, 0, np.inf)\n        new_dist_i = special.softmax(np.log(new_dist_i) - lr_dist * dist_grad_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def mirror_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Entropic mirror descent on exploitability.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist - a list of np.arrays)\\n      grads: tuple of variable gradients (grad_dist - a list of np.arrays)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = np.clip(dist_i, 0, np.inf)\n        new_dist_i = special.softmax(np.log(new_dist_i) - lr_dist * dist_grad_i)\n        new_params.append(new_dist_i)\n    return (new_params,)",
            "def mirror_descent_step(self, params, grads, t):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Entropic mirror descent on exploitability.\\n\\n    Args:\\n      params: tuple of variables to be updated (dist - a list of np.arrays)\\n      grads: tuple of variable gradients (grad_dist - a list of np.arrays)\\n      t: int, solver iteration (unused)\\n    Returns:\\n      new_params: tuple of update params (new_dist)\\n    '\n    del t\n    lr_dist = self.lrs[0]\n    new_params = []\n    for (dist_i, dist_grad_i) in zip(params[0], grads[0]):\n        new_dist_i = np.clip(dist_i, 0, np.inf)\n        new_dist_i = special.softmax(np.log(new_dist_i) - lr_dist * dist_grad_i)\n        new_params.append(new_dist_i)\n    return (new_params,)"
        ]
    }
]