[
    {
        "func_name": "_check_arrays",
        "original": "def _check_arrays(X, y=None):\n    if isinstance(X, list):\n        raise ValueError('X must be a numpy array')\n    if not len(X.shape) == 2:\n        raise ValueError('X must be a 2D array. Try X[:, numpy.newaxis]')\n    try:\n        if y is None:\n            return\n    except AttributeError:\n        if not len(y.shape) == 1:\n            raise ValueError('y must be a 1D array.')\n    if not len(y) == X.shape[0]:\n        raise ValueError('X and y must contain thesame number of samples')",
        "mutated": [
            "def _check_arrays(X, y=None):\n    if False:\n        i = 10\n    if isinstance(X, list):\n        raise ValueError('X must be a numpy array')\n    if not len(X.shape) == 2:\n        raise ValueError('X must be a 2D array. Try X[:, numpy.newaxis]')\n    try:\n        if y is None:\n            return\n    except AttributeError:\n        if not len(y.shape) == 1:\n            raise ValueError('y must be a 1D array.')\n    if not len(y) == X.shape[0]:\n        raise ValueError('X and y must contain thesame number of samples')",
            "def _check_arrays(X, y=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(X, list):\n        raise ValueError('X must be a numpy array')\n    if not len(X.shape) == 2:\n        raise ValueError('X must be a 2D array. Try X[:, numpy.newaxis]')\n    try:\n        if y is None:\n            return\n    except AttributeError:\n        if not len(y.shape) == 1:\n            raise ValueError('y must be a 1D array.')\n    if not len(y) == X.shape[0]:\n        raise ValueError('X and y must contain thesame number of samples')",
            "def _check_arrays(X, y=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(X, list):\n        raise ValueError('X must be a numpy array')\n    if not len(X.shape) == 2:\n        raise ValueError('X must be a 2D array. Try X[:, numpy.newaxis]')\n    try:\n        if y is None:\n            return\n    except AttributeError:\n        if not len(y.shape) == 1:\n            raise ValueError('y must be a 1D array.')\n    if not len(y) == X.shape[0]:\n        raise ValueError('X and y must contain thesame number of samples')",
            "def _check_arrays(X, y=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(X, list):\n        raise ValueError('X must be a numpy array')\n    if not len(X.shape) == 2:\n        raise ValueError('X must be a 2D array. Try X[:, numpy.newaxis]')\n    try:\n        if y is None:\n            return\n    except AttributeError:\n        if not len(y.shape) == 1:\n            raise ValueError('y must be a 1D array.')\n    if not len(y) == X.shape[0]:\n        raise ValueError('X and y must contain thesame number of samples')",
            "def _check_arrays(X, y=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(X, list):\n        raise ValueError('X must be a numpy array')\n    if not len(X.shape) == 2:\n        raise ValueError('X must be a 2D array. Try X[:, numpy.newaxis]')\n    try:\n        if y is None:\n            return\n    except AttributeError:\n        if not len(y.shape) == 1:\n            raise ValueError('y must be a 1D array.')\n    if not len(y) == X.shape[0]:\n        raise ValueError('X and y must contain thesame number of samples')"
        ]
    },
    {
        "func_name": "no_information_rate",
        "original": "def no_information_rate(targets, predictions, loss_fn):\n    combinations = np.array(list(product(targets, predictions)))\n    return loss_fn(combinations[:, 0], combinations[:, 1])",
        "mutated": [
            "def no_information_rate(targets, predictions, loss_fn):\n    if False:\n        i = 10\n    combinations = np.array(list(product(targets, predictions)))\n    return loss_fn(combinations[:, 0], combinations[:, 1])",
            "def no_information_rate(targets, predictions, loss_fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    combinations = np.array(list(product(targets, predictions)))\n    return loss_fn(combinations[:, 0], combinations[:, 1])",
            "def no_information_rate(targets, predictions, loss_fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    combinations = np.array(list(product(targets, predictions)))\n    return loss_fn(combinations[:, 0], combinations[:, 1])",
            "def no_information_rate(targets, predictions, loss_fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    combinations = np.array(list(product(targets, predictions)))\n    return loss_fn(combinations[:, 0], combinations[:, 1])",
            "def no_information_rate(targets, predictions, loss_fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    combinations = np.array(list(product(targets, predictions)))\n    return loss_fn(combinations[:, 0], combinations[:, 1])"
        ]
    },
    {
        "func_name": "accuracy",
        "original": "def accuracy(targets, predictions):\n    return np.mean(np.array(targets) == np.array(predictions))",
        "mutated": [
            "def accuracy(targets, predictions):\n    if False:\n        i = 10\n    return np.mean(np.array(targets) == np.array(predictions))",
            "def accuracy(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return np.mean(np.array(targets) == np.array(predictions))",
            "def accuracy(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return np.mean(np.array(targets) == np.array(predictions))",
            "def accuracy(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return np.mean(np.array(targets) == np.array(predictions))",
            "def accuracy(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return np.mean(np.array(targets) == np.array(predictions))"
        ]
    },
    {
        "func_name": "mse",
        "original": "def mse(targets, predictions):\n    return np.mean((np.array(targets) - np.array(predictions)) ** 2)",
        "mutated": [
            "def mse(targets, predictions):\n    if False:\n        i = 10\n    return np.mean((np.array(targets) - np.array(predictions)) ** 2)",
            "def mse(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return np.mean((np.array(targets) - np.array(predictions)) ** 2)",
            "def mse(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return np.mean((np.array(targets) - np.array(predictions)) ** 2)",
            "def mse(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return np.mean((np.array(targets) - np.array(predictions)) ** 2)",
            "def mse(targets, predictions):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return np.mean((np.array(targets) - np.array(predictions)) ** 2)"
        ]
    },
    {
        "func_name": "bootstrap_point632_score",
        "original": "def bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params):\n    \"\"\"\n    Implementation of the .632 [1] and .632+ [2] bootstrap\n    for supervised learning\n\n    References:\n\n    - [1] Efron, Bradley. 1983. \"Estimating the Error Rate\n      of a Prediction Rule: Improvement on Cross-Validation.\"\n      Journal of the American Statistical Association\n      78 (382): 316. doi:10.2307/2288636.\n    - [2] Efron, Bradley, and Robert Tibshirani. 1997.\n      \"Improvements on Cross-Validation: The .632+ Bootstrap Method.\"\n      Journal of the American Statistical Association\n      92 (438): 548. doi:10.2307/2965703.\n\n    Parameters\n    ----------\n    estimator : object\n        An estimator for classification or regression that\n        follows the scikit-learn API and implements \"fit\" and \"predict\"\n        methods.\n\n    X : array-like\n        The data to fit. Can be, for example a list, or an array at least 2d.\n\n    y : array-like, optional, default: None\n        The target variable to try to predict in the case of\n        supervised learning.\n\n    n_splits : int (default=200)\n        Number of bootstrap iterations.\n        Must be larger than 1.\n\n    method : str (default='.632')\n        The bootstrap method, which can be either\n        - 1) '.632' bootstrap (default)\n        - 2) '.632+' bootstrap\n        - 3) 'oob' (regular out-of-bag, no weighting)\n        for comparison studies.\n\n    scoring_func : callable,\n        Score function (or loss function) with signature\n        ``scoring_func(y, y_pred, **kwargs)``.\n        If none, uses classification accuracy if the\n        estimator is a classifier and mean squared error\n        if the estimator is a regressor.\n\n    predict_proba : bool\n        Whether to use the `predict_proba` function for the\n        `estimator` argument. This is to be used in conjunction\n        with `scoring_func` which takes in probability values\n        instead of actual predictions.\n        For example, if the scoring_func is\n        :meth:`sklearn.metrics.roc_auc_score`, then use\n        `predict_proba=True`.\n        Note that this requires `estimator` to have\n        `predict_proba` method implemented.\n\n    random_seed : int (default=None)\n        If int, random_seed is the seed used by\n        the random number generator.\n\n    clone_estimator : bool (default=True)\n        Clones the estimator if true, otherwise fits\n        the original.\n\n    fit_params : additional parameters\n        Additional parameters to be passed to the .fit() function of the\n        estimator when it is fit to the bootstrap samples.\n\n\n    Returns\n    -------\n    scores : array of float, shape=(len(list(n_splits)),)\n        Array of scores of the estimator for each bootstrap\n        replicate.\n\n    Examples\n    --------\n    >>> from sklearn import datasets, linear_model\n    >>> from mlxtend.evaluate import bootstrap_point632_score\n    >>> iris = datasets.load_iris()\n    >>> X = iris.data\n    >>> y = iris.target\n    >>> lr = linear_model.LogisticRegression()\n    >>> scores = bootstrap_point632_score(lr, X, y)\n    >>> acc = np.mean(scores)\n    >>> print('Accuracy:', acc)\n    0.953023146884\n    >>> lower = np.percentile(scores, 2.5)\n    >>> upper = np.percentile(scores, 97.5)\n    >>> print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))\n    95% Confidence interval: [0.90, 0.98]\n\n    For more usage examples, please see\n    https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\n\n    \"\"\"\n    if not isinstance(n_splits, int) or n_splits < 1:\n        raise ValueError('Number of splits must be greater than 1. Got %s.' % n_splits)\n    allowed_methods = ('.632', '.632+', 'oob')\n    if not isinstance(method, str) or method not in allowed_methods:\n        raise ValueError('The `method` must be in %s. Got %s.' % (allowed_methods, method))\n    if hasattr(X, 'values'):\n        X = X.values\n    if hasattr(y, 'values'):\n        y = y.values\n    _check_arrays(X, y)\n    if clone_estimator:\n        cloned_est = clone(estimator)\n    else:\n        cloned_est = estimator\n    if scoring_func is None:\n        if cloned_est._estimator_type == 'classifier':\n            scoring_func = accuracy\n        elif cloned_est._estimator_type == 'regressor':\n            scoring_func = mse\n        else:\n            raise AttributeError('Estimator type undefined.Please provide a scoring_func argument.')\n    if not predict_proba:\n        predict_func = cloned_est.predict\n    else:\n        if not getattr(cloned_est, 'predict_proba', None):\n            raise RuntimeError(f'The estimator {cloned_est} does not support predicting probabilities via `predict_proba` function.')\n        predict_func = cloned_est.predict_proba\n    oob = BootstrapOutOfBag(n_splits=n_splits, random_seed=random_seed)\n    scores = np.empty(dtype=float, shape=(n_splits,))\n    cnt = 0\n    for (train, test) in oob.split(X):\n        cloned_est.fit(X[train], y[train], **fit_params)\n        predicted_test_val = predict_func(X[test])\n        if method in ('.632', '.632+'):\n            predicted_train_val = predict_func(X)\n        if predict_proba:\n            len_uniq = np.unique(y)\n            if len(len_uniq) == 2:\n                predicted_train_val = predicted_train_val[:, 1]\n                predicted_test_val = predicted_test_val[:, 1]\n        test_acc = scoring_func(y[test], predicted_test_val)\n        if method == 'oob':\n            acc = test_acc\n        else:\n            test_err = 1 - test_acc\n            train_err = 1 - scoring_func(y, predicted_train_val)\n            if method == '.632+':\n                gamma = 1 - no_information_rate(y, cloned_est.predict(X), scoring_func)\n                R = (test_err - train_err) / (gamma - train_err)\n                weight = 0.632 / (1 - 0.368 * R)\n            else:\n                weight = 0.632\n            acc = 1 - (weight * test_err + (1.0 - weight) * train_err)\n        scores[cnt] = acc\n        cnt += 1\n    return scores",
        "mutated": [
            "def bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params):\n    if False:\n        i = 10\n    '\\n    Implementation of the .632 [1] and .632+ [2] bootstrap\\n    for supervised learning\\n\\n    References:\\n\\n    - [1] Efron, Bradley. 1983. \"Estimating the Error Rate\\n      of a Prediction Rule: Improvement on Cross-Validation.\"\\n      Journal of the American Statistical Association\\n      78 (382): 316. doi:10.2307/2288636.\\n    - [2] Efron, Bradley, and Robert Tibshirani. 1997.\\n      \"Improvements on Cross-Validation: The .632+ Bootstrap Method.\"\\n      Journal of the American Statistical Association\\n      92 (438): 548. doi:10.2307/2965703.\\n\\n    Parameters\\n    ----------\\n    estimator : object\\n        An estimator for classification or regression that\\n        follows the scikit-learn API and implements \"fit\" and \"predict\"\\n        methods.\\n\\n    X : array-like\\n        The data to fit. Can be, for example a list, or an array at least 2d.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    n_splits : int (default=200)\\n        Number of bootstrap iterations.\\n        Must be larger than 1.\\n\\n    method : str (default=\\'.632\\')\\n        The bootstrap method, which can be either\\n        - 1) \\'.632\\' bootstrap (default)\\n        - 2) \\'.632+\\' bootstrap\\n        - 3) \\'oob\\' (regular out-of-bag, no weighting)\\n        for comparison studies.\\n\\n    scoring_func : callable,\\n        Score function (or loss function) with signature\\n        ``scoring_func(y, y_pred, **kwargs)``.\\n        If none, uses classification accuracy if the\\n        estimator is a classifier and mean squared error\\n        if the estimator is a regressor.\\n\\n    predict_proba : bool\\n        Whether to use the `predict_proba` function for the\\n        `estimator` argument. This is to be used in conjunction\\n        with `scoring_func` which takes in probability values\\n        instead of actual predictions.\\n        For example, if the scoring_func is\\n        :meth:`sklearn.metrics.roc_auc_score`, then use\\n        `predict_proba=True`.\\n        Note that this requires `estimator` to have\\n        `predict_proba` method implemented.\\n\\n    random_seed : int (default=None)\\n        If int, random_seed is the seed used by\\n        the random number generator.\\n\\n    clone_estimator : bool (default=True)\\n        Clones the estimator if true, otherwise fits\\n        the original.\\n\\n    fit_params : additional parameters\\n        Additional parameters to be passed to the .fit() function of the\\n        estimator when it is fit to the bootstrap samples.\\n\\n\\n    Returns\\n    -------\\n    scores : array of float, shape=(len(list(n_splits)),)\\n        Array of scores of the estimator for each bootstrap\\n        replicate.\\n\\n    Examples\\n    --------\\n    >>> from sklearn import datasets, linear_model\\n    >>> from mlxtend.evaluate import bootstrap_point632_score\\n    >>> iris = datasets.load_iris()\\n    >>> X = iris.data\\n    >>> y = iris.target\\n    >>> lr = linear_model.LogisticRegression()\\n    >>> scores = bootstrap_point632_score(lr, X, y)\\n    >>> acc = np.mean(scores)\\n    >>> print(\\'Accuracy:\\', acc)\\n    0.953023146884\\n    >>> lower = np.percentile(scores, 2.5)\\n    >>> upper = np.percentile(scores, 97.5)\\n    >>> print(\\'95%% Confidence interval: [%.2f, %.2f]\\' % (lower, upper))\\n    95% Confidence interval: [0.90, 0.98]\\n\\n    For more usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\\n\\n    '\n    if not isinstance(n_splits, int) or n_splits < 1:\n        raise ValueError('Number of splits must be greater than 1. Got %s.' % n_splits)\n    allowed_methods = ('.632', '.632+', 'oob')\n    if not isinstance(method, str) or method not in allowed_methods:\n        raise ValueError('The `method` must be in %s. Got %s.' % (allowed_methods, method))\n    if hasattr(X, 'values'):\n        X = X.values\n    if hasattr(y, 'values'):\n        y = y.values\n    _check_arrays(X, y)\n    if clone_estimator:\n        cloned_est = clone(estimator)\n    else:\n        cloned_est = estimator\n    if scoring_func is None:\n        if cloned_est._estimator_type == 'classifier':\n            scoring_func = accuracy\n        elif cloned_est._estimator_type == 'regressor':\n            scoring_func = mse\n        else:\n            raise AttributeError('Estimator type undefined.Please provide a scoring_func argument.')\n    if not predict_proba:\n        predict_func = cloned_est.predict\n    else:\n        if not getattr(cloned_est, 'predict_proba', None):\n            raise RuntimeError(f'The estimator {cloned_est} does not support predicting probabilities via `predict_proba` function.')\n        predict_func = cloned_est.predict_proba\n    oob = BootstrapOutOfBag(n_splits=n_splits, random_seed=random_seed)\n    scores = np.empty(dtype=float, shape=(n_splits,))\n    cnt = 0\n    for (train, test) in oob.split(X):\n        cloned_est.fit(X[train], y[train], **fit_params)\n        predicted_test_val = predict_func(X[test])\n        if method in ('.632', '.632+'):\n            predicted_train_val = predict_func(X)\n        if predict_proba:\n            len_uniq = np.unique(y)\n            if len(len_uniq) == 2:\n                predicted_train_val = predicted_train_val[:, 1]\n                predicted_test_val = predicted_test_val[:, 1]\n        test_acc = scoring_func(y[test], predicted_test_val)\n        if method == 'oob':\n            acc = test_acc\n        else:\n            test_err = 1 - test_acc\n            train_err = 1 - scoring_func(y, predicted_train_val)\n            if method == '.632+':\n                gamma = 1 - no_information_rate(y, cloned_est.predict(X), scoring_func)\n                R = (test_err - train_err) / (gamma - train_err)\n                weight = 0.632 / (1 - 0.368 * R)\n            else:\n                weight = 0.632\n            acc = 1 - (weight * test_err + (1.0 - weight) * train_err)\n        scores[cnt] = acc\n        cnt += 1\n    return scores",
            "def bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Implementation of the .632 [1] and .632+ [2] bootstrap\\n    for supervised learning\\n\\n    References:\\n\\n    - [1] Efron, Bradley. 1983. \"Estimating the Error Rate\\n      of a Prediction Rule: Improvement on Cross-Validation.\"\\n      Journal of the American Statistical Association\\n      78 (382): 316. doi:10.2307/2288636.\\n    - [2] Efron, Bradley, and Robert Tibshirani. 1997.\\n      \"Improvements on Cross-Validation: The .632+ Bootstrap Method.\"\\n      Journal of the American Statistical Association\\n      92 (438): 548. doi:10.2307/2965703.\\n\\n    Parameters\\n    ----------\\n    estimator : object\\n        An estimator for classification or regression that\\n        follows the scikit-learn API and implements \"fit\" and \"predict\"\\n        methods.\\n\\n    X : array-like\\n        The data to fit. Can be, for example a list, or an array at least 2d.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    n_splits : int (default=200)\\n        Number of bootstrap iterations.\\n        Must be larger than 1.\\n\\n    method : str (default=\\'.632\\')\\n        The bootstrap method, which can be either\\n        - 1) \\'.632\\' bootstrap (default)\\n        - 2) \\'.632+\\' bootstrap\\n        - 3) \\'oob\\' (regular out-of-bag, no weighting)\\n        for comparison studies.\\n\\n    scoring_func : callable,\\n        Score function (or loss function) with signature\\n        ``scoring_func(y, y_pred, **kwargs)``.\\n        If none, uses classification accuracy if the\\n        estimator is a classifier and mean squared error\\n        if the estimator is a regressor.\\n\\n    predict_proba : bool\\n        Whether to use the `predict_proba` function for the\\n        `estimator` argument. This is to be used in conjunction\\n        with `scoring_func` which takes in probability values\\n        instead of actual predictions.\\n        For example, if the scoring_func is\\n        :meth:`sklearn.metrics.roc_auc_score`, then use\\n        `predict_proba=True`.\\n        Note that this requires `estimator` to have\\n        `predict_proba` method implemented.\\n\\n    random_seed : int (default=None)\\n        If int, random_seed is the seed used by\\n        the random number generator.\\n\\n    clone_estimator : bool (default=True)\\n        Clones the estimator if true, otherwise fits\\n        the original.\\n\\n    fit_params : additional parameters\\n        Additional parameters to be passed to the .fit() function of the\\n        estimator when it is fit to the bootstrap samples.\\n\\n\\n    Returns\\n    -------\\n    scores : array of float, shape=(len(list(n_splits)),)\\n        Array of scores of the estimator for each bootstrap\\n        replicate.\\n\\n    Examples\\n    --------\\n    >>> from sklearn import datasets, linear_model\\n    >>> from mlxtend.evaluate import bootstrap_point632_score\\n    >>> iris = datasets.load_iris()\\n    >>> X = iris.data\\n    >>> y = iris.target\\n    >>> lr = linear_model.LogisticRegression()\\n    >>> scores = bootstrap_point632_score(lr, X, y)\\n    >>> acc = np.mean(scores)\\n    >>> print(\\'Accuracy:\\', acc)\\n    0.953023146884\\n    >>> lower = np.percentile(scores, 2.5)\\n    >>> upper = np.percentile(scores, 97.5)\\n    >>> print(\\'95%% Confidence interval: [%.2f, %.2f]\\' % (lower, upper))\\n    95% Confidence interval: [0.90, 0.98]\\n\\n    For more usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\\n\\n    '\n    if not isinstance(n_splits, int) or n_splits < 1:\n        raise ValueError('Number of splits must be greater than 1. Got %s.' % n_splits)\n    allowed_methods = ('.632', '.632+', 'oob')\n    if not isinstance(method, str) or method not in allowed_methods:\n        raise ValueError('The `method` must be in %s. Got %s.' % (allowed_methods, method))\n    if hasattr(X, 'values'):\n        X = X.values\n    if hasattr(y, 'values'):\n        y = y.values\n    _check_arrays(X, y)\n    if clone_estimator:\n        cloned_est = clone(estimator)\n    else:\n        cloned_est = estimator\n    if scoring_func is None:\n        if cloned_est._estimator_type == 'classifier':\n            scoring_func = accuracy\n        elif cloned_est._estimator_type == 'regressor':\n            scoring_func = mse\n        else:\n            raise AttributeError('Estimator type undefined.Please provide a scoring_func argument.')\n    if not predict_proba:\n        predict_func = cloned_est.predict\n    else:\n        if not getattr(cloned_est, 'predict_proba', None):\n            raise RuntimeError(f'The estimator {cloned_est} does not support predicting probabilities via `predict_proba` function.')\n        predict_func = cloned_est.predict_proba\n    oob = BootstrapOutOfBag(n_splits=n_splits, random_seed=random_seed)\n    scores = np.empty(dtype=float, shape=(n_splits,))\n    cnt = 0\n    for (train, test) in oob.split(X):\n        cloned_est.fit(X[train], y[train], **fit_params)\n        predicted_test_val = predict_func(X[test])\n        if method in ('.632', '.632+'):\n            predicted_train_val = predict_func(X)\n        if predict_proba:\n            len_uniq = np.unique(y)\n            if len(len_uniq) == 2:\n                predicted_train_val = predicted_train_val[:, 1]\n                predicted_test_val = predicted_test_val[:, 1]\n        test_acc = scoring_func(y[test], predicted_test_val)\n        if method == 'oob':\n            acc = test_acc\n        else:\n            test_err = 1 - test_acc\n            train_err = 1 - scoring_func(y, predicted_train_val)\n            if method == '.632+':\n                gamma = 1 - no_information_rate(y, cloned_est.predict(X), scoring_func)\n                R = (test_err - train_err) / (gamma - train_err)\n                weight = 0.632 / (1 - 0.368 * R)\n            else:\n                weight = 0.632\n            acc = 1 - (weight * test_err + (1.0 - weight) * train_err)\n        scores[cnt] = acc\n        cnt += 1\n    return scores",
            "def bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Implementation of the .632 [1] and .632+ [2] bootstrap\\n    for supervised learning\\n\\n    References:\\n\\n    - [1] Efron, Bradley. 1983. \"Estimating the Error Rate\\n      of a Prediction Rule: Improvement on Cross-Validation.\"\\n      Journal of the American Statistical Association\\n      78 (382): 316. doi:10.2307/2288636.\\n    - [2] Efron, Bradley, and Robert Tibshirani. 1997.\\n      \"Improvements on Cross-Validation: The .632+ Bootstrap Method.\"\\n      Journal of the American Statistical Association\\n      92 (438): 548. doi:10.2307/2965703.\\n\\n    Parameters\\n    ----------\\n    estimator : object\\n        An estimator for classification or regression that\\n        follows the scikit-learn API and implements \"fit\" and \"predict\"\\n        methods.\\n\\n    X : array-like\\n        The data to fit. Can be, for example a list, or an array at least 2d.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    n_splits : int (default=200)\\n        Number of bootstrap iterations.\\n        Must be larger than 1.\\n\\n    method : str (default=\\'.632\\')\\n        The bootstrap method, which can be either\\n        - 1) \\'.632\\' bootstrap (default)\\n        - 2) \\'.632+\\' bootstrap\\n        - 3) \\'oob\\' (regular out-of-bag, no weighting)\\n        for comparison studies.\\n\\n    scoring_func : callable,\\n        Score function (or loss function) with signature\\n        ``scoring_func(y, y_pred, **kwargs)``.\\n        If none, uses classification accuracy if the\\n        estimator is a classifier and mean squared error\\n        if the estimator is a regressor.\\n\\n    predict_proba : bool\\n        Whether to use the `predict_proba` function for the\\n        `estimator` argument. This is to be used in conjunction\\n        with `scoring_func` which takes in probability values\\n        instead of actual predictions.\\n        For example, if the scoring_func is\\n        :meth:`sklearn.metrics.roc_auc_score`, then use\\n        `predict_proba=True`.\\n        Note that this requires `estimator` to have\\n        `predict_proba` method implemented.\\n\\n    random_seed : int (default=None)\\n        If int, random_seed is the seed used by\\n        the random number generator.\\n\\n    clone_estimator : bool (default=True)\\n        Clones the estimator if true, otherwise fits\\n        the original.\\n\\n    fit_params : additional parameters\\n        Additional parameters to be passed to the .fit() function of the\\n        estimator when it is fit to the bootstrap samples.\\n\\n\\n    Returns\\n    -------\\n    scores : array of float, shape=(len(list(n_splits)),)\\n        Array of scores of the estimator for each bootstrap\\n        replicate.\\n\\n    Examples\\n    --------\\n    >>> from sklearn import datasets, linear_model\\n    >>> from mlxtend.evaluate import bootstrap_point632_score\\n    >>> iris = datasets.load_iris()\\n    >>> X = iris.data\\n    >>> y = iris.target\\n    >>> lr = linear_model.LogisticRegression()\\n    >>> scores = bootstrap_point632_score(lr, X, y)\\n    >>> acc = np.mean(scores)\\n    >>> print(\\'Accuracy:\\', acc)\\n    0.953023146884\\n    >>> lower = np.percentile(scores, 2.5)\\n    >>> upper = np.percentile(scores, 97.5)\\n    >>> print(\\'95%% Confidence interval: [%.2f, %.2f]\\' % (lower, upper))\\n    95% Confidence interval: [0.90, 0.98]\\n\\n    For more usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\\n\\n    '\n    if not isinstance(n_splits, int) or n_splits < 1:\n        raise ValueError('Number of splits must be greater than 1. Got %s.' % n_splits)\n    allowed_methods = ('.632', '.632+', 'oob')\n    if not isinstance(method, str) or method not in allowed_methods:\n        raise ValueError('The `method` must be in %s. Got %s.' % (allowed_methods, method))\n    if hasattr(X, 'values'):\n        X = X.values\n    if hasattr(y, 'values'):\n        y = y.values\n    _check_arrays(X, y)\n    if clone_estimator:\n        cloned_est = clone(estimator)\n    else:\n        cloned_est = estimator\n    if scoring_func is None:\n        if cloned_est._estimator_type == 'classifier':\n            scoring_func = accuracy\n        elif cloned_est._estimator_type == 'regressor':\n            scoring_func = mse\n        else:\n            raise AttributeError('Estimator type undefined.Please provide a scoring_func argument.')\n    if not predict_proba:\n        predict_func = cloned_est.predict\n    else:\n        if not getattr(cloned_est, 'predict_proba', None):\n            raise RuntimeError(f'The estimator {cloned_est} does not support predicting probabilities via `predict_proba` function.')\n        predict_func = cloned_est.predict_proba\n    oob = BootstrapOutOfBag(n_splits=n_splits, random_seed=random_seed)\n    scores = np.empty(dtype=float, shape=(n_splits,))\n    cnt = 0\n    for (train, test) in oob.split(X):\n        cloned_est.fit(X[train], y[train], **fit_params)\n        predicted_test_val = predict_func(X[test])\n        if method in ('.632', '.632+'):\n            predicted_train_val = predict_func(X)\n        if predict_proba:\n            len_uniq = np.unique(y)\n            if len(len_uniq) == 2:\n                predicted_train_val = predicted_train_val[:, 1]\n                predicted_test_val = predicted_test_val[:, 1]\n        test_acc = scoring_func(y[test], predicted_test_val)\n        if method == 'oob':\n            acc = test_acc\n        else:\n            test_err = 1 - test_acc\n            train_err = 1 - scoring_func(y, predicted_train_val)\n            if method == '.632+':\n                gamma = 1 - no_information_rate(y, cloned_est.predict(X), scoring_func)\n                R = (test_err - train_err) / (gamma - train_err)\n                weight = 0.632 / (1 - 0.368 * R)\n            else:\n                weight = 0.632\n            acc = 1 - (weight * test_err + (1.0 - weight) * train_err)\n        scores[cnt] = acc\n        cnt += 1\n    return scores",
            "def bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Implementation of the .632 [1] and .632+ [2] bootstrap\\n    for supervised learning\\n\\n    References:\\n\\n    - [1] Efron, Bradley. 1983. \"Estimating the Error Rate\\n      of a Prediction Rule: Improvement on Cross-Validation.\"\\n      Journal of the American Statistical Association\\n      78 (382): 316. doi:10.2307/2288636.\\n    - [2] Efron, Bradley, and Robert Tibshirani. 1997.\\n      \"Improvements on Cross-Validation: The .632+ Bootstrap Method.\"\\n      Journal of the American Statistical Association\\n      92 (438): 548. doi:10.2307/2965703.\\n\\n    Parameters\\n    ----------\\n    estimator : object\\n        An estimator for classification or regression that\\n        follows the scikit-learn API and implements \"fit\" and \"predict\"\\n        methods.\\n\\n    X : array-like\\n        The data to fit. Can be, for example a list, or an array at least 2d.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    n_splits : int (default=200)\\n        Number of bootstrap iterations.\\n        Must be larger than 1.\\n\\n    method : str (default=\\'.632\\')\\n        The bootstrap method, which can be either\\n        - 1) \\'.632\\' bootstrap (default)\\n        - 2) \\'.632+\\' bootstrap\\n        - 3) \\'oob\\' (regular out-of-bag, no weighting)\\n        for comparison studies.\\n\\n    scoring_func : callable,\\n        Score function (or loss function) with signature\\n        ``scoring_func(y, y_pred, **kwargs)``.\\n        If none, uses classification accuracy if the\\n        estimator is a classifier and mean squared error\\n        if the estimator is a regressor.\\n\\n    predict_proba : bool\\n        Whether to use the `predict_proba` function for the\\n        `estimator` argument. This is to be used in conjunction\\n        with `scoring_func` which takes in probability values\\n        instead of actual predictions.\\n        For example, if the scoring_func is\\n        :meth:`sklearn.metrics.roc_auc_score`, then use\\n        `predict_proba=True`.\\n        Note that this requires `estimator` to have\\n        `predict_proba` method implemented.\\n\\n    random_seed : int (default=None)\\n        If int, random_seed is the seed used by\\n        the random number generator.\\n\\n    clone_estimator : bool (default=True)\\n        Clones the estimator if true, otherwise fits\\n        the original.\\n\\n    fit_params : additional parameters\\n        Additional parameters to be passed to the .fit() function of the\\n        estimator when it is fit to the bootstrap samples.\\n\\n\\n    Returns\\n    -------\\n    scores : array of float, shape=(len(list(n_splits)),)\\n        Array of scores of the estimator for each bootstrap\\n        replicate.\\n\\n    Examples\\n    --------\\n    >>> from sklearn import datasets, linear_model\\n    >>> from mlxtend.evaluate import bootstrap_point632_score\\n    >>> iris = datasets.load_iris()\\n    >>> X = iris.data\\n    >>> y = iris.target\\n    >>> lr = linear_model.LogisticRegression()\\n    >>> scores = bootstrap_point632_score(lr, X, y)\\n    >>> acc = np.mean(scores)\\n    >>> print(\\'Accuracy:\\', acc)\\n    0.953023146884\\n    >>> lower = np.percentile(scores, 2.5)\\n    >>> upper = np.percentile(scores, 97.5)\\n    >>> print(\\'95%% Confidence interval: [%.2f, %.2f]\\' % (lower, upper))\\n    95% Confidence interval: [0.90, 0.98]\\n\\n    For more usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\\n\\n    '\n    if not isinstance(n_splits, int) or n_splits < 1:\n        raise ValueError('Number of splits must be greater than 1. Got %s.' % n_splits)\n    allowed_methods = ('.632', '.632+', 'oob')\n    if not isinstance(method, str) or method not in allowed_methods:\n        raise ValueError('The `method` must be in %s. Got %s.' % (allowed_methods, method))\n    if hasattr(X, 'values'):\n        X = X.values\n    if hasattr(y, 'values'):\n        y = y.values\n    _check_arrays(X, y)\n    if clone_estimator:\n        cloned_est = clone(estimator)\n    else:\n        cloned_est = estimator\n    if scoring_func is None:\n        if cloned_est._estimator_type == 'classifier':\n            scoring_func = accuracy\n        elif cloned_est._estimator_type == 'regressor':\n            scoring_func = mse\n        else:\n            raise AttributeError('Estimator type undefined.Please provide a scoring_func argument.')\n    if not predict_proba:\n        predict_func = cloned_est.predict\n    else:\n        if not getattr(cloned_est, 'predict_proba', None):\n            raise RuntimeError(f'The estimator {cloned_est} does not support predicting probabilities via `predict_proba` function.')\n        predict_func = cloned_est.predict_proba\n    oob = BootstrapOutOfBag(n_splits=n_splits, random_seed=random_seed)\n    scores = np.empty(dtype=float, shape=(n_splits,))\n    cnt = 0\n    for (train, test) in oob.split(X):\n        cloned_est.fit(X[train], y[train], **fit_params)\n        predicted_test_val = predict_func(X[test])\n        if method in ('.632', '.632+'):\n            predicted_train_val = predict_func(X)\n        if predict_proba:\n            len_uniq = np.unique(y)\n            if len(len_uniq) == 2:\n                predicted_train_val = predicted_train_val[:, 1]\n                predicted_test_val = predicted_test_val[:, 1]\n        test_acc = scoring_func(y[test], predicted_test_val)\n        if method == 'oob':\n            acc = test_acc\n        else:\n            test_err = 1 - test_acc\n            train_err = 1 - scoring_func(y, predicted_train_val)\n            if method == '.632+':\n                gamma = 1 - no_information_rate(y, cloned_est.predict(X), scoring_func)\n                R = (test_err - train_err) / (gamma - train_err)\n                weight = 0.632 / (1 - 0.368 * R)\n            else:\n                weight = 0.632\n            acc = 1 - (weight * test_err + (1.0 - weight) * train_err)\n        scores[cnt] = acc\n        cnt += 1\n    return scores",
            "def bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Implementation of the .632 [1] and .632+ [2] bootstrap\\n    for supervised learning\\n\\n    References:\\n\\n    - [1] Efron, Bradley. 1983. \"Estimating the Error Rate\\n      of a Prediction Rule: Improvement on Cross-Validation.\"\\n      Journal of the American Statistical Association\\n      78 (382): 316. doi:10.2307/2288636.\\n    - [2] Efron, Bradley, and Robert Tibshirani. 1997.\\n      \"Improvements on Cross-Validation: The .632+ Bootstrap Method.\"\\n      Journal of the American Statistical Association\\n      92 (438): 548. doi:10.2307/2965703.\\n\\n    Parameters\\n    ----------\\n    estimator : object\\n        An estimator for classification or regression that\\n        follows the scikit-learn API and implements \"fit\" and \"predict\"\\n        methods.\\n\\n    X : array-like\\n        The data to fit. Can be, for example a list, or an array at least 2d.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    n_splits : int (default=200)\\n        Number of bootstrap iterations.\\n        Must be larger than 1.\\n\\n    method : str (default=\\'.632\\')\\n        The bootstrap method, which can be either\\n        - 1) \\'.632\\' bootstrap (default)\\n        - 2) \\'.632+\\' bootstrap\\n        - 3) \\'oob\\' (regular out-of-bag, no weighting)\\n        for comparison studies.\\n\\n    scoring_func : callable,\\n        Score function (or loss function) with signature\\n        ``scoring_func(y, y_pred, **kwargs)``.\\n        If none, uses classification accuracy if the\\n        estimator is a classifier and mean squared error\\n        if the estimator is a regressor.\\n\\n    predict_proba : bool\\n        Whether to use the `predict_proba` function for the\\n        `estimator` argument. This is to be used in conjunction\\n        with `scoring_func` which takes in probability values\\n        instead of actual predictions.\\n        For example, if the scoring_func is\\n        :meth:`sklearn.metrics.roc_auc_score`, then use\\n        `predict_proba=True`.\\n        Note that this requires `estimator` to have\\n        `predict_proba` method implemented.\\n\\n    random_seed : int (default=None)\\n        If int, random_seed is the seed used by\\n        the random number generator.\\n\\n    clone_estimator : bool (default=True)\\n        Clones the estimator if true, otherwise fits\\n        the original.\\n\\n    fit_params : additional parameters\\n        Additional parameters to be passed to the .fit() function of the\\n        estimator when it is fit to the bootstrap samples.\\n\\n\\n    Returns\\n    -------\\n    scores : array of float, shape=(len(list(n_splits)),)\\n        Array of scores of the estimator for each bootstrap\\n        replicate.\\n\\n    Examples\\n    --------\\n    >>> from sklearn import datasets, linear_model\\n    >>> from mlxtend.evaluate import bootstrap_point632_score\\n    >>> iris = datasets.load_iris()\\n    >>> X = iris.data\\n    >>> y = iris.target\\n    >>> lr = linear_model.LogisticRegression()\\n    >>> scores = bootstrap_point632_score(lr, X, y)\\n    >>> acc = np.mean(scores)\\n    >>> print(\\'Accuracy:\\', acc)\\n    0.953023146884\\n    >>> lower = np.percentile(scores, 2.5)\\n    >>> upper = np.percentile(scores, 97.5)\\n    >>> print(\\'95%% Confidence interval: [%.2f, %.2f]\\' % (lower, upper))\\n    95% Confidence interval: [0.90, 0.98]\\n\\n    For more usage examples, please see\\n    https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\\n\\n    '\n    if not isinstance(n_splits, int) or n_splits < 1:\n        raise ValueError('Number of splits must be greater than 1. Got %s.' % n_splits)\n    allowed_methods = ('.632', '.632+', 'oob')\n    if not isinstance(method, str) or method not in allowed_methods:\n        raise ValueError('The `method` must be in %s. Got %s.' % (allowed_methods, method))\n    if hasattr(X, 'values'):\n        X = X.values\n    if hasattr(y, 'values'):\n        y = y.values\n    _check_arrays(X, y)\n    if clone_estimator:\n        cloned_est = clone(estimator)\n    else:\n        cloned_est = estimator\n    if scoring_func is None:\n        if cloned_est._estimator_type == 'classifier':\n            scoring_func = accuracy\n        elif cloned_est._estimator_type == 'regressor':\n            scoring_func = mse\n        else:\n            raise AttributeError('Estimator type undefined.Please provide a scoring_func argument.')\n    if not predict_proba:\n        predict_func = cloned_est.predict\n    else:\n        if not getattr(cloned_est, 'predict_proba', None):\n            raise RuntimeError(f'The estimator {cloned_est} does not support predicting probabilities via `predict_proba` function.')\n        predict_func = cloned_est.predict_proba\n    oob = BootstrapOutOfBag(n_splits=n_splits, random_seed=random_seed)\n    scores = np.empty(dtype=float, shape=(n_splits,))\n    cnt = 0\n    for (train, test) in oob.split(X):\n        cloned_est.fit(X[train], y[train], **fit_params)\n        predicted_test_val = predict_func(X[test])\n        if method in ('.632', '.632+'):\n            predicted_train_val = predict_func(X)\n        if predict_proba:\n            len_uniq = np.unique(y)\n            if len(len_uniq) == 2:\n                predicted_train_val = predicted_train_val[:, 1]\n                predicted_test_val = predicted_test_val[:, 1]\n        test_acc = scoring_func(y[test], predicted_test_val)\n        if method == 'oob':\n            acc = test_acc\n        else:\n            test_err = 1 - test_acc\n            train_err = 1 - scoring_func(y, predicted_train_val)\n            if method == '.632+':\n                gamma = 1 - no_information_rate(y, cloned_est.predict(X), scoring_func)\n                R = (test_err - train_err) / (gamma - train_err)\n                weight = 0.632 / (1 - 0.368 * R)\n            else:\n                weight = 0.632\n            acc = 1 - (weight * test_err + (1.0 - weight) * train_err)\n        scores[cnt] = acc\n        cnt += 1\n    return scores"
        ]
    }
]