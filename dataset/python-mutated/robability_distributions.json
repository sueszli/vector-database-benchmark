[
    {
        "func_name": "sample",
        "original": "def sample(self, rng: np.random.RandomState, batch_size: int) -> np.ndarray:\n    active_indices = rng.choice(len(self.weights), p=self.weights, size=batch_size)\n    ret = np.empty((batch_size, len(self.distributions)), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        if isinstance(d, _BatchedCategoricalDistributions):\n            active_weights = d.weights[active_indices, :]\n            rnd_quantile = rng.rand(batch_size)\n            cum_probs = np.cumsum(active_weights, axis=-1)\n            assert np.isclose(cum_probs[:, -1], 1).all()\n            cum_probs[:, -1] = 1\n            ret[:, i] = np.sum(cum_probs < rnd_quantile[:, None], axis=-1)\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            ret[:, i] = _truncnorm.rvs(a=(d.low - active_mus) / active_sigmas, b=(d.high - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            samples = _truncnorm.rvs(a=(d.low - d.step / 2 - active_mus) / active_sigmas, b=(d.high + d.step / 2 - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n            ret[:, i] = np.clip(d.low + np.round((samples - d.low) / d.step) * d.step, d.low, d.high)\n        else:\n            assert False\n    return ret",
        "mutated": [
            "def sample(self, rng: np.random.RandomState, batch_size: int) -> np.ndarray:\n    if False:\n        i = 10\n    active_indices = rng.choice(len(self.weights), p=self.weights, size=batch_size)\n    ret = np.empty((batch_size, len(self.distributions)), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        if isinstance(d, _BatchedCategoricalDistributions):\n            active_weights = d.weights[active_indices, :]\n            rnd_quantile = rng.rand(batch_size)\n            cum_probs = np.cumsum(active_weights, axis=-1)\n            assert np.isclose(cum_probs[:, -1], 1).all()\n            cum_probs[:, -1] = 1\n            ret[:, i] = np.sum(cum_probs < rnd_quantile[:, None], axis=-1)\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            ret[:, i] = _truncnorm.rvs(a=(d.low - active_mus) / active_sigmas, b=(d.high - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            samples = _truncnorm.rvs(a=(d.low - d.step / 2 - active_mus) / active_sigmas, b=(d.high + d.step / 2 - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n            ret[:, i] = np.clip(d.low + np.round((samples - d.low) / d.step) * d.step, d.low, d.high)\n        else:\n            assert False\n    return ret",
            "def sample(self, rng: np.random.RandomState, batch_size: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    active_indices = rng.choice(len(self.weights), p=self.weights, size=batch_size)\n    ret = np.empty((batch_size, len(self.distributions)), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        if isinstance(d, _BatchedCategoricalDistributions):\n            active_weights = d.weights[active_indices, :]\n            rnd_quantile = rng.rand(batch_size)\n            cum_probs = np.cumsum(active_weights, axis=-1)\n            assert np.isclose(cum_probs[:, -1], 1).all()\n            cum_probs[:, -1] = 1\n            ret[:, i] = np.sum(cum_probs < rnd_quantile[:, None], axis=-1)\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            ret[:, i] = _truncnorm.rvs(a=(d.low - active_mus) / active_sigmas, b=(d.high - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            samples = _truncnorm.rvs(a=(d.low - d.step / 2 - active_mus) / active_sigmas, b=(d.high + d.step / 2 - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n            ret[:, i] = np.clip(d.low + np.round((samples - d.low) / d.step) * d.step, d.low, d.high)\n        else:\n            assert False\n    return ret",
            "def sample(self, rng: np.random.RandomState, batch_size: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    active_indices = rng.choice(len(self.weights), p=self.weights, size=batch_size)\n    ret = np.empty((batch_size, len(self.distributions)), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        if isinstance(d, _BatchedCategoricalDistributions):\n            active_weights = d.weights[active_indices, :]\n            rnd_quantile = rng.rand(batch_size)\n            cum_probs = np.cumsum(active_weights, axis=-1)\n            assert np.isclose(cum_probs[:, -1], 1).all()\n            cum_probs[:, -1] = 1\n            ret[:, i] = np.sum(cum_probs < rnd_quantile[:, None], axis=-1)\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            ret[:, i] = _truncnorm.rvs(a=(d.low - active_mus) / active_sigmas, b=(d.high - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            samples = _truncnorm.rvs(a=(d.low - d.step / 2 - active_mus) / active_sigmas, b=(d.high + d.step / 2 - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n            ret[:, i] = np.clip(d.low + np.round((samples - d.low) / d.step) * d.step, d.low, d.high)\n        else:\n            assert False\n    return ret",
            "def sample(self, rng: np.random.RandomState, batch_size: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    active_indices = rng.choice(len(self.weights), p=self.weights, size=batch_size)\n    ret = np.empty((batch_size, len(self.distributions)), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        if isinstance(d, _BatchedCategoricalDistributions):\n            active_weights = d.weights[active_indices, :]\n            rnd_quantile = rng.rand(batch_size)\n            cum_probs = np.cumsum(active_weights, axis=-1)\n            assert np.isclose(cum_probs[:, -1], 1).all()\n            cum_probs[:, -1] = 1\n            ret[:, i] = np.sum(cum_probs < rnd_quantile[:, None], axis=-1)\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            ret[:, i] = _truncnorm.rvs(a=(d.low - active_mus) / active_sigmas, b=(d.high - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            samples = _truncnorm.rvs(a=(d.low - d.step / 2 - active_mus) / active_sigmas, b=(d.high + d.step / 2 - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n            ret[:, i] = np.clip(d.low + np.round((samples - d.low) / d.step) * d.step, d.low, d.high)\n        else:\n            assert False\n    return ret",
            "def sample(self, rng: np.random.RandomState, batch_size: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    active_indices = rng.choice(len(self.weights), p=self.weights, size=batch_size)\n    ret = np.empty((batch_size, len(self.distributions)), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        if isinstance(d, _BatchedCategoricalDistributions):\n            active_weights = d.weights[active_indices, :]\n            rnd_quantile = rng.rand(batch_size)\n            cum_probs = np.cumsum(active_weights, axis=-1)\n            assert np.isclose(cum_probs[:, -1], 1).all()\n            cum_probs[:, -1] = 1\n            ret[:, i] = np.sum(cum_probs < rnd_quantile[:, None], axis=-1)\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            ret[:, i] = _truncnorm.rvs(a=(d.low - active_mus) / active_sigmas, b=(d.high - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            active_mus = d.mu[active_indices]\n            active_sigmas = d.sigma[active_indices]\n            samples = _truncnorm.rvs(a=(d.low - d.step / 2 - active_mus) / active_sigmas, b=(d.high + d.step / 2 - active_mus) / active_sigmas, loc=active_mus, scale=active_sigmas, random_state=rng)\n            ret[:, i] = np.clip(d.low + np.round((samples - d.low) / d.step) * d.step, d.low, d.high)\n        else:\n            assert False\n    return ret"
        ]
    },
    {
        "func_name": "log_pdf",
        "original": "def log_pdf(self, x: np.ndarray) -> np.ndarray:\n    (batch_size, n_vars) = x.shape\n    log_pdfs = np.empty((batch_size, len(self.weights), n_vars), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        xi = x[:, i]\n        if isinstance(d, _BatchedCategoricalDistributions):\n            log_pdfs[:, :, i] = np.log(np.take_along_axis(d.weights[None, :, :], xi[:, None, None].astype(np.int64), axis=-1))[:, :, 0]\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            log_pdfs[:, :, i] = _truncnorm.logpdf(x=xi[:, None], a=(d.low - d.mu[None, :]) / d.sigma[None, :], b=(d.high - d.mu[None, :]) / d.sigma[None, :], loc=d.mu[None, :], scale=d.sigma[None, :])\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            lower_limit = d.low - d.step / 2\n            upper_limit = d.high + d.step / 2\n            x_lower = np.maximum(xi - d.step / 2, lower_limit)\n            x_upper = np.minimum(xi + d.step / 2, upper_limit)\n            log_gauss_mass = _truncnorm._log_gauss_mass((x_lower[:, None] - d.mu[None, :]) / d.sigma[None, :], (x_upper[:, None] - d.mu[None, :]) / d.sigma[None, :])\n            log_p_accept = _truncnorm._log_gauss_mass((d.low - d.step / 2 - d.mu[None, :]) / d.sigma[None, :], (d.high + d.step / 2 - d.mu[None, :]) / d.sigma[None, :])\n            log_pdfs[:, :, i] = log_gauss_mass - log_p_accept\n        else:\n            assert False\n    weighted_log_pdf = np.sum(log_pdfs, axis=-1) + np.log(self.weights[None, :])\n    max_ = weighted_log_pdf.max(axis=1)\n    max_[np.isneginf(max_)] = 0\n    with np.errstate(divide='ignore'):\n        return np.log(np.exp(weighted_log_pdf - max_[:, None]).sum(axis=1)) + max_",
        "mutated": [
            "def log_pdf(self, x: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n    (batch_size, n_vars) = x.shape\n    log_pdfs = np.empty((batch_size, len(self.weights), n_vars), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        xi = x[:, i]\n        if isinstance(d, _BatchedCategoricalDistributions):\n            log_pdfs[:, :, i] = np.log(np.take_along_axis(d.weights[None, :, :], xi[:, None, None].astype(np.int64), axis=-1))[:, :, 0]\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            log_pdfs[:, :, i] = _truncnorm.logpdf(x=xi[:, None], a=(d.low - d.mu[None, :]) / d.sigma[None, :], b=(d.high - d.mu[None, :]) / d.sigma[None, :], loc=d.mu[None, :], scale=d.sigma[None, :])\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            lower_limit = d.low - d.step / 2\n            upper_limit = d.high + d.step / 2\n            x_lower = np.maximum(xi - d.step / 2, lower_limit)\n            x_upper = np.minimum(xi + d.step / 2, upper_limit)\n            log_gauss_mass = _truncnorm._log_gauss_mass((x_lower[:, None] - d.mu[None, :]) / d.sigma[None, :], (x_upper[:, None] - d.mu[None, :]) / d.sigma[None, :])\n            log_p_accept = _truncnorm._log_gauss_mass((d.low - d.step / 2 - d.mu[None, :]) / d.sigma[None, :], (d.high + d.step / 2 - d.mu[None, :]) / d.sigma[None, :])\n            log_pdfs[:, :, i] = log_gauss_mass - log_p_accept\n        else:\n            assert False\n    weighted_log_pdf = np.sum(log_pdfs, axis=-1) + np.log(self.weights[None, :])\n    max_ = weighted_log_pdf.max(axis=1)\n    max_[np.isneginf(max_)] = 0\n    with np.errstate(divide='ignore'):\n        return np.log(np.exp(weighted_log_pdf - max_[:, None]).sum(axis=1)) + max_",
            "def log_pdf(self, x: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (batch_size, n_vars) = x.shape\n    log_pdfs = np.empty((batch_size, len(self.weights), n_vars), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        xi = x[:, i]\n        if isinstance(d, _BatchedCategoricalDistributions):\n            log_pdfs[:, :, i] = np.log(np.take_along_axis(d.weights[None, :, :], xi[:, None, None].astype(np.int64), axis=-1))[:, :, 0]\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            log_pdfs[:, :, i] = _truncnorm.logpdf(x=xi[:, None], a=(d.low - d.mu[None, :]) / d.sigma[None, :], b=(d.high - d.mu[None, :]) / d.sigma[None, :], loc=d.mu[None, :], scale=d.sigma[None, :])\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            lower_limit = d.low - d.step / 2\n            upper_limit = d.high + d.step / 2\n            x_lower = np.maximum(xi - d.step / 2, lower_limit)\n            x_upper = np.minimum(xi + d.step / 2, upper_limit)\n            log_gauss_mass = _truncnorm._log_gauss_mass((x_lower[:, None] - d.mu[None, :]) / d.sigma[None, :], (x_upper[:, None] - d.mu[None, :]) / d.sigma[None, :])\n            log_p_accept = _truncnorm._log_gauss_mass((d.low - d.step / 2 - d.mu[None, :]) / d.sigma[None, :], (d.high + d.step / 2 - d.mu[None, :]) / d.sigma[None, :])\n            log_pdfs[:, :, i] = log_gauss_mass - log_p_accept\n        else:\n            assert False\n    weighted_log_pdf = np.sum(log_pdfs, axis=-1) + np.log(self.weights[None, :])\n    max_ = weighted_log_pdf.max(axis=1)\n    max_[np.isneginf(max_)] = 0\n    with np.errstate(divide='ignore'):\n        return np.log(np.exp(weighted_log_pdf - max_[:, None]).sum(axis=1)) + max_",
            "def log_pdf(self, x: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (batch_size, n_vars) = x.shape\n    log_pdfs = np.empty((batch_size, len(self.weights), n_vars), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        xi = x[:, i]\n        if isinstance(d, _BatchedCategoricalDistributions):\n            log_pdfs[:, :, i] = np.log(np.take_along_axis(d.weights[None, :, :], xi[:, None, None].astype(np.int64), axis=-1))[:, :, 0]\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            log_pdfs[:, :, i] = _truncnorm.logpdf(x=xi[:, None], a=(d.low - d.mu[None, :]) / d.sigma[None, :], b=(d.high - d.mu[None, :]) / d.sigma[None, :], loc=d.mu[None, :], scale=d.sigma[None, :])\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            lower_limit = d.low - d.step / 2\n            upper_limit = d.high + d.step / 2\n            x_lower = np.maximum(xi - d.step / 2, lower_limit)\n            x_upper = np.minimum(xi + d.step / 2, upper_limit)\n            log_gauss_mass = _truncnorm._log_gauss_mass((x_lower[:, None] - d.mu[None, :]) / d.sigma[None, :], (x_upper[:, None] - d.mu[None, :]) / d.sigma[None, :])\n            log_p_accept = _truncnorm._log_gauss_mass((d.low - d.step / 2 - d.mu[None, :]) / d.sigma[None, :], (d.high + d.step / 2 - d.mu[None, :]) / d.sigma[None, :])\n            log_pdfs[:, :, i] = log_gauss_mass - log_p_accept\n        else:\n            assert False\n    weighted_log_pdf = np.sum(log_pdfs, axis=-1) + np.log(self.weights[None, :])\n    max_ = weighted_log_pdf.max(axis=1)\n    max_[np.isneginf(max_)] = 0\n    with np.errstate(divide='ignore'):\n        return np.log(np.exp(weighted_log_pdf - max_[:, None]).sum(axis=1)) + max_",
            "def log_pdf(self, x: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (batch_size, n_vars) = x.shape\n    log_pdfs = np.empty((batch_size, len(self.weights), n_vars), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        xi = x[:, i]\n        if isinstance(d, _BatchedCategoricalDistributions):\n            log_pdfs[:, :, i] = np.log(np.take_along_axis(d.weights[None, :, :], xi[:, None, None].astype(np.int64), axis=-1))[:, :, 0]\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            log_pdfs[:, :, i] = _truncnorm.logpdf(x=xi[:, None], a=(d.low - d.mu[None, :]) / d.sigma[None, :], b=(d.high - d.mu[None, :]) / d.sigma[None, :], loc=d.mu[None, :], scale=d.sigma[None, :])\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            lower_limit = d.low - d.step / 2\n            upper_limit = d.high + d.step / 2\n            x_lower = np.maximum(xi - d.step / 2, lower_limit)\n            x_upper = np.minimum(xi + d.step / 2, upper_limit)\n            log_gauss_mass = _truncnorm._log_gauss_mass((x_lower[:, None] - d.mu[None, :]) / d.sigma[None, :], (x_upper[:, None] - d.mu[None, :]) / d.sigma[None, :])\n            log_p_accept = _truncnorm._log_gauss_mass((d.low - d.step / 2 - d.mu[None, :]) / d.sigma[None, :], (d.high + d.step / 2 - d.mu[None, :]) / d.sigma[None, :])\n            log_pdfs[:, :, i] = log_gauss_mass - log_p_accept\n        else:\n            assert False\n    weighted_log_pdf = np.sum(log_pdfs, axis=-1) + np.log(self.weights[None, :])\n    max_ = weighted_log_pdf.max(axis=1)\n    max_[np.isneginf(max_)] = 0\n    with np.errstate(divide='ignore'):\n        return np.log(np.exp(weighted_log_pdf - max_[:, None]).sum(axis=1)) + max_",
            "def log_pdf(self, x: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (batch_size, n_vars) = x.shape\n    log_pdfs = np.empty((batch_size, len(self.weights), n_vars), dtype=np.float64)\n    for (i, d) in enumerate(self.distributions):\n        xi = x[:, i]\n        if isinstance(d, _BatchedCategoricalDistributions):\n            log_pdfs[:, :, i] = np.log(np.take_along_axis(d.weights[None, :, :], xi[:, None, None].astype(np.int64), axis=-1))[:, :, 0]\n        elif isinstance(d, _BatchedTruncNormDistributions):\n            log_pdfs[:, :, i] = _truncnorm.logpdf(x=xi[:, None], a=(d.low - d.mu[None, :]) / d.sigma[None, :], b=(d.high - d.mu[None, :]) / d.sigma[None, :], loc=d.mu[None, :], scale=d.sigma[None, :])\n        elif isinstance(d, _BatchedDiscreteTruncNormDistributions):\n            lower_limit = d.low - d.step / 2\n            upper_limit = d.high + d.step / 2\n            x_lower = np.maximum(xi - d.step / 2, lower_limit)\n            x_upper = np.minimum(xi + d.step / 2, upper_limit)\n            log_gauss_mass = _truncnorm._log_gauss_mass((x_lower[:, None] - d.mu[None, :]) / d.sigma[None, :], (x_upper[:, None] - d.mu[None, :]) / d.sigma[None, :])\n            log_p_accept = _truncnorm._log_gauss_mass((d.low - d.step / 2 - d.mu[None, :]) / d.sigma[None, :], (d.high + d.step / 2 - d.mu[None, :]) / d.sigma[None, :])\n            log_pdfs[:, :, i] = log_gauss_mass - log_p_accept\n        else:\n            assert False\n    weighted_log_pdf = np.sum(log_pdfs, axis=-1) + np.log(self.weights[None, :])\n    max_ = weighted_log_pdf.max(axis=1)\n    max_[np.isneginf(max_)] = 0\n    with np.errstate(divide='ignore'):\n        return np.log(np.exp(weighted_log_pdf - max_[:, None]).sum(axis=1)) + max_"
        ]
    }
]