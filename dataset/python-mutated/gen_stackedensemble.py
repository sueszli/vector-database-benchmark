rest_api_version = 99

def update_param(name, param):
    if False:
        return 10
    if name == 'metalearner_params':
        param['default_value'] = None
        return param
    if name == 'base_models':
        param['type'] = 'list'
        param['default_value'] = None
        return param
    return None
extensions = dict(frame_params=['training_frame', 'validation_frame', 'blending_frame'], validate_frames='\ntraining_frame <- .validate.H2OFrame(training_frame, required=is.null(blending_frame))\nvalidation_frame <- .validate.H2OFrame(validation_frame, required=FALSE)\nblending_frame <- .validate.H2OFrame(blending_frame, required=is.null(training_frame))\nif (is.null(training_frame)) training_frame <- blending_frame  # guarantee presence of default metrics\n', validate_params='\n# Get the base models from model IDs (if any) that will be used for constructing model summary\nif(!is.list(base_models) && is.vector(x)) {\n  base_models <- if (inherits(base_models, "H2OGrid")) list(base_models) else as.list(base_models)\n}\n\n# Get base model IDs that will be passed to REST API later\nif (length(base_models) == 0) stop(\'base_models is empty\')\n\n# If base_models contains models instead of ids, replace with model id\nfor (i in 1:length(base_models)) {\n  if (inherits(base_models[[i]], c(\'H2OModel\', \'H2OGrid\'))) {\n    base_models[[i]] <- h2o.keyof(base_models[[i]])\n  }\n}\n', set_required_params='\nparms$training_frame <- training_frame\nargs <- .verify_dataxy(training_frame, x, y)\nparms$response_column <- args$y\n', skip_default_set_params_for=['training_frame', 'response_column', 'metalearner_params'], set_params='\nif (!missing(metalearner_params))\n    parms$metalearner_params <- as.character(toJSON(metalearner_params, pretty = TRUE))\n', with_model='\n# Convert metalearner_params back to list if not NULL\nif (!missing(metalearner_params)) {\n    model@parameters$metalearner_params <- list(fromJSON(model@parameters$metalearner_params))[[1]] #Need the `[[ ]]` to avoid a nested list\n}\n', module='\n.h2o.fill_stackedensemble <- function(model, parameters, allparams) {\n  # Store base models for the Stacked Ensemble in user-readable form\n  model$base_models <- unlist(lapply(parameters$base_models, function (base_model) base_model$name))\n  \n  if (!is.null(model$metalearner)) {\n    model$metalearner_model <- h2o.getModel(model$metalearner$name)\n  } else {\n    stop(paste("Meta learner didn\'t get to be trained in time.",\n               "Try increasing max_runtime_secs or setting it to 0 (unlimited)."))\n  }\n\n  return(model)\n}\n')
doc = dict(preamble='\nBuilds a Stacked Ensemble\n\nBuild a stacked ensemble (aka. Super Learner) using the H2O base\nlearning algorithms specified by the user.\n', params=dict(x='\n(Optional). A vector containing the names or indices of the predictor variables to use in building the model.\nIf x is missing, then all columns except y are used.  Training frame is used only to compute ensemble training metrics.\n', seed='\nSeed for random numbers; passed through to the metalearner algorithm. Defaults to -1 (time-based random number).\n'), examples='\nlibrary(h2o)\nh2o.init()\n\n# Import a sample binary outcome train/test set\ntrain <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv")\ntest <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv")\n\n# Identify predictors and response\ny <- "response"\nx <- setdiff(names(train), y)\n\n# For binary classification, response should be a factor\ntrain[, y] <- as.factor(train[, y])\ntest[, y] <- as.factor(test[, y])\n\n# Number of CV folds\nnfolds <- 5\n\n# Train & Cross-validate a GBM\nmy_gbm <- h2o.gbm(x = x,\n                  y = y,\n                  training_frame = train,\n                  distribution = "bernoulli",\n                  ntrees = 10,\n                  max_depth = 3,\n                  min_rows = 2,\n                  learn_rate = 0.2,\n                  nfolds = nfolds,\n                  fold_assignment = "Modulo",\n                  keep_cross_validation_predictions = TRUE,\n                  seed = 1)\n\n# Train & Cross-validate a RF\nmy_rf <- h2o.randomForest(x = x,\n                          y = y,\n                          training_frame = train,\n                          ntrees = 50,\n                          nfolds = nfolds,\n                          fold_assignment = "Modulo",\n                          keep_cross_validation_predictions = TRUE,\n                          seed = 1)\n\n# Train a stacked ensemble using the GBM and RF above\nensemble <- h2o.stackedEnsemble(x = x,\n                                y = y,\n                                training_frame = train,\n                                model_id = "my_ensemble_binomial",\n                                base_models = list(my_gbm, my_rf))\n')