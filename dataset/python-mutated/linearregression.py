"""linearregression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SFWk7Ap06ZkvP2HmLhXLiyyqo-ei35M1
"""
from __future__ import absolute_import, division, print_function, unicode_literals
import pathlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from datetime import datetime
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
print(tf.__version__)
dataset_path = keras.utils.get_file('housing.data', 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data')
column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATION', 'B', 'LSTAT', 'MEDV']
raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values='?', comment='\t', sep=' ', skipinitialspace=True)
dataset = raw_dataset.copy()
dataset.tail(n=10)
p = 0.8
trainDataset = dataset.sample(frac=p, random_state=0)
testDataset = dataset.drop(trainDataset.index)
import matplotlib.pyplot as plt
(fig, ax) = plt.subplots()
x = trainDataset['RM']
y = trainDataset['MEDV']
ax.scatter(x, y, edgecolors=(0, 0, 0))
ax.set_xlabel('RM')
ax.set_ylabel('MEDV')
plt.show()
trainInput = trainDataset['RM']
trainTarget = trainDataset['MEDV']
testInput = testDataset['RM']
testTarget = testDataset['MEDV']

def linear_model():
    if False:
        return 10
    model = keras.Sequential([layers.Dense(1, use_bias=True, input_shape=(1,), name='layer')])
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.99, epsilon=1e-05, amsgrad=False, name='Adam')
    model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])
    return model
model = linear_model()
model.summary()
n_epochs = 4000
batch_size = 256
n_idle_epochs = 100
n_epochs_log = 200
n_samples_save = n_epochs_log * trainInput.shape[0]
print('Checkpoint is saved for each {} samples'.format(n_samples_save))
earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=n_idle_epochs, min_delta=0.001)
predictions_list = []

class NEPOCHLogger(tf.keras.callbacks.Callback):

    def __init__(self, per_epoch=100):
        if False:
            i = 10
            return i + 15
        '\n        display: Number of batches to wait before outputting loss\n        '
        self.seen = 0
        self.per_epoch = per_epoch

    def on_epoch_end(self, epoch, logs=None):
        if False:
            return 10
        if epoch % self.per_epoch == 0:
            print('Epoch {}, loss {:.2f}, val_loss {:.2f}, mae {:.2f}, val_mae {:.2f}, mse {:.2f}, val_mse {:.2f}'.format(epoch, logs['loss'], logs['val_loss'], logs['mae'], logs['val_mae'], logs['mse'], logs['val_mse']))
log_display = NEPOCHLogger(per_epoch=n_epochs_log)
import os
checkpoint_path = 'training/cp-{epoch:05d}.ckpt'
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpointCallback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, save_freq=n_samples_save)
model.save_weights(checkpoint_path.format(epoch=0))
logdir = 'logs/fit/' + datetime.now().strftime('%Y%m%d-%H%M%S')
tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)
history = model.fit(trainInput, trainTarget, batch_size=batch_size, epochs=n_epochs, validation_split=0.1, verbose=0, callbacks=[earlyStopping, log_display, tensorboard_callback, checkpointCallback])
print('keys:', history.history.keys())
mae = np.asarray(history.history['mae'])
val_mae = np.asarray(history.history['val_mae'])
num_values = len(mae)
values = np.zeros((num_values, 2), dtype=float)
values[:, 0] = mae
values[:, 1] = val_mae
steps = pd.RangeIndex(start=0, stop=num_values)
data = pd.DataFrame(values, steps, columns=['training-mae', 'val-mae'])
sns.set(style='whitegrid')
sns.lineplot(data=data, palette='tab10', linewidth=2.5)
predictions = model.predict(testInput).flatten()
a = plt.axes(aspect='equal')
plt.scatter(predictions, testTarget, edgecolors=(0, 0, 0))
plt.xlabel('True Values')
plt.ylabel('Predictions')
lims = [0, 50]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims, lims)
checkpoints = []
for f_name in os.listdir(checkpoint_dir):
    if f_name.startswith('cp-'):
        file_with_no_ext = os.path.splitext(f_name)[0]
        checkpoints.append(file_with_no_ext)
checkpoints = list(set(checkpoints))
print('checkpoints:', checkpoints)
count = 0
model_improvement_progress = False
if model_improvement_progress:
    for checkpoint in checkpoints:
        count += 1
        model = linear_model()
        path = os.path.join('training', checkpoint)
        model.load_weights(path)
        layer = model.get_layer('layer')
        (w1, w0) = layer.get_weights()
        w1 = float(w1[0])
        w0 = float(w0[0])
        (fig, ax) = plt.subplots()
        x = testInput
        y = testTarget
        ax.scatter(x, y, edgecolors=(0, 0, 0))
        ax.set_xlabel('RM')
        ax.set_ylabel('MEDV')
        y_hat = w1 * x + w0
        plt.plot(x, y_hat, '-r')