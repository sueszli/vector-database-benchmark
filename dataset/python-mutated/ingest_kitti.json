[
    {
        "func_name": "convert_annot_to_json",
        "original": "def convert_annot_to_json(path, im_path, out_path, difficult):\n    \"\"\"\n    Converts the KITTI annotations to json file.\n\n    Uses the below reference for the KITTI dataset:\n\n    OO representation of label format used in Kitti dataset.\n\n    Description of fields from Kitti dataset dev kit: (link)[]\n    The label files contain the following information, which can be read and\n    written using the matlab tools (readLabels.m, writeLabels.m) provided within\n    this devkit. All values (numerical or strings) are separated via spaces,\n    each row corresponds to one object. The 15 columns represent:\n    #Values    Name      Description\n    ----------------------------------------------------------------------------\n       1    type         Describes the type of object: 'Car', 'Van', 'Truck',\n                         'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\n                         'Misc' or 'DontCare'\n       1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\n                         truncated refers to the object leaving image boundaries\n       1    occluded     Integer (0,1,2,3) indicating occlusion state:\n                         0 = fully visible, 1 = partly occluded\n                         2 = largely occluded, 3 = unknown\n       1    alpha        Observation angle of object, ranging [-pi..pi]\n       4    bbox         2D bounding box of object in the image (0-based index):\n                         contains left, top, right, bottom pixel coordinates\n       3    dimensions   3D object dimensions: height, width, length (in meters)\n       3    location     3D object location x,y,z in camera coordinates (in meters)\n       1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\n       1    score        Only for results: Float, indicating confidence in\n                         detection, needed for p/r curves, higher is better.\n\n    Arguments:\n        path (string): path to KITTI annotation file\n        im_path (string): path to image\n        out_path (string): path to save the json file\n        difficult (bool): include difficult objects\n    \"\"\"\n    with open(path) as f:\n        labels = f.readlines()\n    annot = {'object': []}\n    im = np.array(Image.open(im_path))\n    (h, w, c) = im.shape\n    annot['size'] = {'depth': c, 'height': h, 'width': w}\n    for label in labels:\n        vals = label.split()\n        type = vals[0]\n        truncated = float(vals[1])\n        occluded = int(vals[2])\n        bbox = tuple([float(x) for x in vals[4:8]])\n        bbox_int = tuple([int(math.floor(x)) for x in bbox])\n        if type == 'DontCare':\n            assert truncated == -1\n            assert occluded == -1\n        else:\n            assert occluded in (0, 1, 2, 3)\n        diff = truncated > 0.5 or occluded == 2\n        obj = {'bndbox': {'xmin': bbox_int[0], 'ymin': bbox_int[1], 'xmax': bbox_int[2], 'ymax': bbox_int[3]}, 'difficult': difficult, 'name': type, 'truncated': truncated > 0.5, 'occluded': occluded}\n        if not diff or difficult:\n            annot['object'].append(obj)\n    with open(out_path, 'w') as f:\n        json.dump(annot, f, indent=4)",
        "mutated": [
            "def convert_annot_to_json(path, im_path, out_path, difficult):\n    if False:\n        i = 10\n    \"\\n    Converts the KITTI annotations to json file.\\n\\n    Uses the below reference for the KITTI dataset:\\n\\n    OO representation of label format used in Kitti dataset.\\n\\n    Description of fields from Kitti dataset dev kit: (link)[]\\n    The label files contain the following information, which can be read and\\n    written using the matlab tools (readLabels.m, writeLabels.m) provided within\\n    this devkit. All values (numerical or strings) are separated via spaces,\\n    each row corresponds to one object. The 15 columns represent:\\n    #Values    Name      Description\\n    ----------------------------------------------------------------------------\\n       1    type         Describes the type of object: 'Car', 'Van', 'Truck',\\n                         'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\\n                         'Misc' or 'DontCare'\\n       1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\\n                         truncated refers to the object leaving image boundaries\\n       1    occluded     Integer (0,1,2,3) indicating occlusion state:\\n                         0 = fully visible, 1 = partly occluded\\n                         2 = largely occluded, 3 = unknown\\n       1    alpha        Observation angle of object, ranging [-pi..pi]\\n       4    bbox         2D bounding box of object in the image (0-based index):\\n                         contains left, top, right, bottom pixel coordinates\\n       3    dimensions   3D object dimensions: height, width, length (in meters)\\n       3    location     3D object location x,y,z in camera coordinates (in meters)\\n       1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\\n       1    score        Only for results: Float, indicating confidence in\\n                         detection, needed for p/r curves, higher is better.\\n\\n    Arguments:\\n        path (string): path to KITTI annotation file\\n        im_path (string): path to image\\n        out_path (string): path to save the json file\\n        difficult (bool): include difficult objects\\n    \"\n    with open(path) as f:\n        labels = f.readlines()\n    annot = {'object': []}\n    im = np.array(Image.open(im_path))\n    (h, w, c) = im.shape\n    annot['size'] = {'depth': c, 'height': h, 'width': w}\n    for label in labels:\n        vals = label.split()\n        type = vals[0]\n        truncated = float(vals[1])\n        occluded = int(vals[2])\n        bbox = tuple([float(x) for x in vals[4:8]])\n        bbox_int = tuple([int(math.floor(x)) for x in bbox])\n        if type == 'DontCare':\n            assert truncated == -1\n            assert occluded == -1\n        else:\n            assert occluded in (0, 1, 2, 3)\n        diff = truncated > 0.5 or occluded == 2\n        obj = {'bndbox': {'xmin': bbox_int[0], 'ymin': bbox_int[1], 'xmax': bbox_int[2], 'ymax': bbox_int[3]}, 'difficult': difficult, 'name': type, 'truncated': truncated > 0.5, 'occluded': occluded}\n        if not diff or difficult:\n            annot['object'].append(obj)\n    with open(out_path, 'w') as f:\n        json.dump(annot, f, indent=4)",
            "def convert_annot_to_json(path, im_path, out_path, difficult):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Converts the KITTI annotations to json file.\\n\\n    Uses the below reference for the KITTI dataset:\\n\\n    OO representation of label format used in Kitti dataset.\\n\\n    Description of fields from Kitti dataset dev kit: (link)[]\\n    The label files contain the following information, which can be read and\\n    written using the matlab tools (readLabels.m, writeLabels.m) provided within\\n    this devkit. All values (numerical or strings) are separated via spaces,\\n    each row corresponds to one object. The 15 columns represent:\\n    #Values    Name      Description\\n    ----------------------------------------------------------------------------\\n       1    type         Describes the type of object: 'Car', 'Van', 'Truck',\\n                         'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\\n                         'Misc' or 'DontCare'\\n       1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\\n                         truncated refers to the object leaving image boundaries\\n       1    occluded     Integer (0,1,2,3) indicating occlusion state:\\n                         0 = fully visible, 1 = partly occluded\\n                         2 = largely occluded, 3 = unknown\\n       1    alpha        Observation angle of object, ranging [-pi..pi]\\n       4    bbox         2D bounding box of object in the image (0-based index):\\n                         contains left, top, right, bottom pixel coordinates\\n       3    dimensions   3D object dimensions: height, width, length (in meters)\\n       3    location     3D object location x,y,z in camera coordinates (in meters)\\n       1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\\n       1    score        Only for results: Float, indicating confidence in\\n                         detection, needed for p/r curves, higher is better.\\n\\n    Arguments:\\n        path (string): path to KITTI annotation file\\n        im_path (string): path to image\\n        out_path (string): path to save the json file\\n        difficult (bool): include difficult objects\\n    \"\n    with open(path) as f:\n        labels = f.readlines()\n    annot = {'object': []}\n    im = np.array(Image.open(im_path))\n    (h, w, c) = im.shape\n    annot['size'] = {'depth': c, 'height': h, 'width': w}\n    for label in labels:\n        vals = label.split()\n        type = vals[0]\n        truncated = float(vals[1])\n        occluded = int(vals[2])\n        bbox = tuple([float(x) for x in vals[4:8]])\n        bbox_int = tuple([int(math.floor(x)) for x in bbox])\n        if type == 'DontCare':\n            assert truncated == -1\n            assert occluded == -1\n        else:\n            assert occluded in (0, 1, 2, 3)\n        diff = truncated > 0.5 or occluded == 2\n        obj = {'bndbox': {'xmin': bbox_int[0], 'ymin': bbox_int[1], 'xmax': bbox_int[2], 'ymax': bbox_int[3]}, 'difficult': difficult, 'name': type, 'truncated': truncated > 0.5, 'occluded': occluded}\n        if not diff or difficult:\n            annot['object'].append(obj)\n    with open(out_path, 'w') as f:\n        json.dump(annot, f, indent=4)",
            "def convert_annot_to_json(path, im_path, out_path, difficult):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Converts the KITTI annotations to json file.\\n\\n    Uses the below reference for the KITTI dataset:\\n\\n    OO representation of label format used in Kitti dataset.\\n\\n    Description of fields from Kitti dataset dev kit: (link)[]\\n    The label files contain the following information, which can be read and\\n    written using the matlab tools (readLabels.m, writeLabels.m) provided within\\n    this devkit. All values (numerical or strings) are separated via spaces,\\n    each row corresponds to one object. The 15 columns represent:\\n    #Values    Name      Description\\n    ----------------------------------------------------------------------------\\n       1    type         Describes the type of object: 'Car', 'Van', 'Truck',\\n                         'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\\n                         'Misc' or 'DontCare'\\n       1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\\n                         truncated refers to the object leaving image boundaries\\n       1    occluded     Integer (0,1,2,3) indicating occlusion state:\\n                         0 = fully visible, 1 = partly occluded\\n                         2 = largely occluded, 3 = unknown\\n       1    alpha        Observation angle of object, ranging [-pi..pi]\\n       4    bbox         2D bounding box of object in the image (0-based index):\\n                         contains left, top, right, bottom pixel coordinates\\n       3    dimensions   3D object dimensions: height, width, length (in meters)\\n       3    location     3D object location x,y,z in camera coordinates (in meters)\\n       1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\\n       1    score        Only for results: Float, indicating confidence in\\n                         detection, needed for p/r curves, higher is better.\\n\\n    Arguments:\\n        path (string): path to KITTI annotation file\\n        im_path (string): path to image\\n        out_path (string): path to save the json file\\n        difficult (bool): include difficult objects\\n    \"\n    with open(path) as f:\n        labels = f.readlines()\n    annot = {'object': []}\n    im = np.array(Image.open(im_path))\n    (h, w, c) = im.shape\n    annot['size'] = {'depth': c, 'height': h, 'width': w}\n    for label in labels:\n        vals = label.split()\n        type = vals[0]\n        truncated = float(vals[1])\n        occluded = int(vals[2])\n        bbox = tuple([float(x) for x in vals[4:8]])\n        bbox_int = tuple([int(math.floor(x)) for x in bbox])\n        if type == 'DontCare':\n            assert truncated == -1\n            assert occluded == -1\n        else:\n            assert occluded in (0, 1, 2, 3)\n        diff = truncated > 0.5 or occluded == 2\n        obj = {'bndbox': {'xmin': bbox_int[0], 'ymin': bbox_int[1], 'xmax': bbox_int[2], 'ymax': bbox_int[3]}, 'difficult': difficult, 'name': type, 'truncated': truncated > 0.5, 'occluded': occluded}\n        if not diff or difficult:\n            annot['object'].append(obj)\n    with open(out_path, 'w') as f:\n        json.dump(annot, f, indent=4)",
            "def convert_annot_to_json(path, im_path, out_path, difficult):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Converts the KITTI annotations to json file.\\n\\n    Uses the below reference for the KITTI dataset:\\n\\n    OO representation of label format used in Kitti dataset.\\n\\n    Description of fields from Kitti dataset dev kit: (link)[]\\n    The label files contain the following information, which can be read and\\n    written using the matlab tools (readLabels.m, writeLabels.m) provided within\\n    this devkit. All values (numerical or strings) are separated via spaces,\\n    each row corresponds to one object. The 15 columns represent:\\n    #Values    Name      Description\\n    ----------------------------------------------------------------------------\\n       1    type         Describes the type of object: 'Car', 'Van', 'Truck',\\n                         'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\\n                         'Misc' or 'DontCare'\\n       1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\\n                         truncated refers to the object leaving image boundaries\\n       1    occluded     Integer (0,1,2,3) indicating occlusion state:\\n                         0 = fully visible, 1 = partly occluded\\n                         2 = largely occluded, 3 = unknown\\n       1    alpha        Observation angle of object, ranging [-pi..pi]\\n       4    bbox         2D bounding box of object in the image (0-based index):\\n                         contains left, top, right, bottom pixel coordinates\\n       3    dimensions   3D object dimensions: height, width, length (in meters)\\n       3    location     3D object location x,y,z in camera coordinates (in meters)\\n       1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\\n       1    score        Only for results: Float, indicating confidence in\\n                         detection, needed for p/r curves, higher is better.\\n\\n    Arguments:\\n        path (string): path to KITTI annotation file\\n        im_path (string): path to image\\n        out_path (string): path to save the json file\\n        difficult (bool): include difficult objects\\n    \"\n    with open(path) as f:\n        labels = f.readlines()\n    annot = {'object': []}\n    im = np.array(Image.open(im_path))\n    (h, w, c) = im.shape\n    annot['size'] = {'depth': c, 'height': h, 'width': w}\n    for label in labels:\n        vals = label.split()\n        type = vals[0]\n        truncated = float(vals[1])\n        occluded = int(vals[2])\n        bbox = tuple([float(x) for x in vals[4:8]])\n        bbox_int = tuple([int(math.floor(x)) for x in bbox])\n        if type == 'DontCare':\n            assert truncated == -1\n            assert occluded == -1\n        else:\n            assert occluded in (0, 1, 2, 3)\n        diff = truncated > 0.5 or occluded == 2\n        obj = {'bndbox': {'xmin': bbox_int[0], 'ymin': bbox_int[1], 'xmax': bbox_int[2], 'ymax': bbox_int[3]}, 'difficult': difficult, 'name': type, 'truncated': truncated > 0.5, 'occluded': occluded}\n        if not diff or difficult:\n            annot['object'].append(obj)\n    with open(out_path, 'w') as f:\n        json.dump(annot, f, indent=4)",
            "def convert_annot_to_json(path, im_path, out_path, difficult):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Converts the KITTI annotations to json file.\\n\\n    Uses the below reference for the KITTI dataset:\\n\\n    OO representation of label format used in Kitti dataset.\\n\\n    Description of fields from Kitti dataset dev kit: (link)[]\\n    The label files contain the following information, which can be read and\\n    written using the matlab tools (readLabels.m, writeLabels.m) provided within\\n    this devkit. All values (numerical or strings) are separated via spaces,\\n    each row corresponds to one object. The 15 columns represent:\\n    #Values    Name      Description\\n    ----------------------------------------------------------------------------\\n       1    type         Describes the type of object: 'Car', 'Van', 'Truck',\\n                         'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\\n                         'Misc' or 'DontCare'\\n       1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\\n                         truncated refers to the object leaving image boundaries\\n       1    occluded     Integer (0,1,2,3) indicating occlusion state:\\n                         0 = fully visible, 1 = partly occluded\\n                         2 = largely occluded, 3 = unknown\\n       1    alpha        Observation angle of object, ranging [-pi..pi]\\n       4    bbox         2D bounding box of object in the image (0-based index):\\n                         contains left, top, right, bottom pixel coordinates\\n       3    dimensions   3D object dimensions: height, width, length (in meters)\\n       3    location     3D object location x,y,z in camera coordinates (in meters)\\n       1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\\n       1    score        Only for results: Float, indicating confidence in\\n                         detection, needed for p/r curves, higher is better.\\n\\n    Arguments:\\n        path (string): path to KITTI annotation file\\n        im_path (string): path to image\\n        out_path (string): path to save the json file\\n        difficult (bool): include difficult objects\\n    \"\n    with open(path) as f:\n        labels = f.readlines()\n    annot = {'object': []}\n    im = np.array(Image.open(im_path))\n    (h, w, c) = im.shape\n    annot['size'] = {'depth': c, 'height': h, 'width': w}\n    for label in labels:\n        vals = label.split()\n        type = vals[0]\n        truncated = float(vals[1])\n        occluded = int(vals[2])\n        bbox = tuple([float(x) for x in vals[4:8]])\n        bbox_int = tuple([int(math.floor(x)) for x in bbox])\n        if type == 'DontCare':\n            assert truncated == -1\n            assert occluded == -1\n        else:\n            assert occluded in (0, 1, 2, 3)\n        diff = truncated > 0.5 or occluded == 2\n        obj = {'bndbox': {'xmin': bbox_int[0], 'ymin': bbox_int[1], 'xmax': bbox_int[2], 'ymax': bbox_int[3]}, 'difficult': difficult, 'name': type, 'truncated': truncated > 0.5, 'occluded': occluded}\n        if not diff or difficult:\n            annot['object'].append(obj)\n    with open(out_path, 'w') as f:\n        json.dump(annot, f, indent=4)"
        ]
    },
    {
        "func_name": "ingest_kitti",
        "original": "def ingest_kitti(input_dir, out_dir, train_percent=90, overwrite=False):\n    \"\"\"\n    Ingests the KITTI dataset. Peforms the following ops:\n    0. Unzips the files into output directory.\n    1. Convert annotations to json format\n    2. Split the training data into train and validation sets\n    3. Write manifest file\n    4. Write configuration file\n\n    Arguments:\n        input_dir (string): path to folder with KITTI zip files.\n        out_dir (string): path to unzip KITTI data\n        train_percent (float): percent of data to use for training.\n        overwrite (bool): overwrite existing files\n    \"\"\"\n    data_dir = ensure_dirs_exist(os.path.join(out_dir, 'kitti'))\n    train_manifest = os.path.join(data_dir, 'train.csv')\n    val_manifest = os.path.join(data_dir, 'val.csv')\n    if not overwrite and os.path.exists(train_manifest) and os.path.exists(val_manifest):\n        print('Found existing manfiest files, skipping ingest,\\n              Use --overwrite to rerun ingest anyway.')\n        return (train_manifest, val_manifest)\n    zipfiles = [os.path.join(input_dir, zipfile) for zipfile in ['data_object_image_2.zip', 'data_object_label_2.zip']]\n    for file in zipfiles:\n        with ZipFile(file, 'r') as zf:\n            print('Extracting {} to {}'.format(file, data_dir))\n            zf.extractall(data_dir)\n    img_path = os.path.join(data_dir, 'training', 'image_2')\n    annot_path = os.path.join(data_dir, 'training', 'label_2')\n    images = [os.path.splitext(os.path.basename(im))[0] for im in glob.glob(os.path.join(img_path, '*.png'))]\n    print('Found {} images'.format(len(images)))\n    assert len(images) > 0, 'Did not found any images. Check your input_dir.'\n    annot_save_dir = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json/'))\n    annot_save_dir_difficult = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json-difficult/'))\n    print('Writing annotations to: {} and {}'.format(annot_save_dir, annot_save_dir_difficult))\n    for im in tqdm(images):\n        path = os.path.join(annot_path, im + '.txt')\n        im_path = os.path.join(img_path, im + '.png')\n        assert os.path.exists(im_path)\n        out_path = os.path.join(annot_save_dir, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=False)\n        out_path = os.path.join(annot_save_dir_difficult, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=True)\n    np.random.seed(0)\n    np.random.shuffle(images)\n    train_count = len(images) * train_percent // 100\n    train = images[:train_count]\n    val = images[train_count:]\n    create_manifest(train_manifest, train, annot_save_dir, img_path, data_dir)\n    create_manifest(val_manifest, val, annot_save_dir_difficult, img_path, data_dir)\n    config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'kitti.cfg')\n    with open(config_path, 'w') as f:\n        f.write('manifest = [train:{}, val:{}]\\n'.format(train_manifest, val_manifest))\n        f.write('manifest_root = {}\\n'.format(data_dir))\n        f.write('epochs = 14\\n')\n        f.write('height = 375\\n')\n        f.write('width = 1242\\n')\n        f.write('batch_size = 1\\n')\n    print('Wrote config file to: {}'.format(config_path))",
        "mutated": [
            "def ingest_kitti(input_dir, out_dir, train_percent=90, overwrite=False):\n    if False:\n        i = 10\n    '\\n    Ingests the KITTI dataset. Peforms the following ops:\\n    0. Unzips the files into output directory.\\n    1. Convert annotations to json format\\n    2. Split the training data into train and validation sets\\n    3. Write manifest file\\n    4. Write configuration file\\n\\n    Arguments:\\n        input_dir (string): path to folder with KITTI zip files.\\n        out_dir (string): path to unzip KITTI data\\n        train_percent (float): percent of data to use for training.\\n        overwrite (bool): overwrite existing files\\n    '\n    data_dir = ensure_dirs_exist(os.path.join(out_dir, 'kitti'))\n    train_manifest = os.path.join(data_dir, 'train.csv')\n    val_manifest = os.path.join(data_dir, 'val.csv')\n    if not overwrite and os.path.exists(train_manifest) and os.path.exists(val_manifest):\n        print('Found existing manfiest files, skipping ingest,\\n              Use --overwrite to rerun ingest anyway.')\n        return (train_manifest, val_manifest)\n    zipfiles = [os.path.join(input_dir, zipfile) for zipfile in ['data_object_image_2.zip', 'data_object_label_2.zip']]\n    for file in zipfiles:\n        with ZipFile(file, 'r') as zf:\n            print('Extracting {} to {}'.format(file, data_dir))\n            zf.extractall(data_dir)\n    img_path = os.path.join(data_dir, 'training', 'image_2')\n    annot_path = os.path.join(data_dir, 'training', 'label_2')\n    images = [os.path.splitext(os.path.basename(im))[0] for im in glob.glob(os.path.join(img_path, '*.png'))]\n    print('Found {} images'.format(len(images)))\n    assert len(images) > 0, 'Did not found any images. Check your input_dir.'\n    annot_save_dir = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json/'))\n    annot_save_dir_difficult = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json-difficult/'))\n    print('Writing annotations to: {} and {}'.format(annot_save_dir, annot_save_dir_difficult))\n    for im in tqdm(images):\n        path = os.path.join(annot_path, im + '.txt')\n        im_path = os.path.join(img_path, im + '.png')\n        assert os.path.exists(im_path)\n        out_path = os.path.join(annot_save_dir, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=False)\n        out_path = os.path.join(annot_save_dir_difficult, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=True)\n    np.random.seed(0)\n    np.random.shuffle(images)\n    train_count = len(images) * train_percent // 100\n    train = images[:train_count]\n    val = images[train_count:]\n    create_manifest(train_manifest, train, annot_save_dir, img_path, data_dir)\n    create_manifest(val_manifest, val, annot_save_dir_difficult, img_path, data_dir)\n    config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'kitti.cfg')\n    with open(config_path, 'w') as f:\n        f.write('manifest = [train:{}, val:{}]\\n'.format(train_manifest, val_manifest))\n        f.write('manifest_root = {}\\n'.format(data_dir))\n        f.write('epochs = 14\\n')\n        f.write('height = 375\\n')\n        f.write('width = 1242\\n')\n        f.write('batch_size = 1\\n')\n    print('Wrote config file to: {}'.format(config_path))",
            "def ingest_kitti(input_dir, out_dir, train_percent=90, overwrite=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Ingests the KITTI dataset. Peforms the following ops:\\n    0. Unzips the files into output directory.\\n    1. Convert annotations to json format\\n    2. Split the training data into train and validation sets\\n    3. Write manifest file\\n    4. Write configuration file\\n\\n    Arguments:\\n        input_dir (string): path to folder with KITTI zip files.\\n        out_dir (string): path to unzip KITTI data\\n        train_percent (float): percent of data to use for training.\\n        overwrite (bool): overwrite existing files\\n    '\n    data_dir = ensure_dirs_exist(os.path.join(out_dir, 'kitti'))\n    train_manifest = os.path.join(data_dir, 'train.csv')\n    val_manifest = os.path.join(data_dir, 'val.csv')\n    if not overwrite and os.path.exists(train_manifest) and os.path.exists(val_manifest):\n        print('Found existing manfiest files, skipping ingest,\\n              Use --overwrite to rerun ingest anyway.')\n        return (train_manifest, val_manifest)\n    zipfiles = [os.path.join(input_dir, zipfile) for zipfile in ['data_object_image_2.zip', 'data_object_label_2.zip']]\n    for file in zipfiles:\n        with ZipFile(file, 'r') as zf:\n            print('Extracting {} to {}'.format(file, data_dir))\n            zf.extractall(data_dir)\n    img_path = os.path.join(data_dir, 'training', 'image_2')\n    annot_path = os.path.join(data_dir, 'training', 'label_2')\n    images = [os.path.splitext(os.path.basename(im))[0] for im in glob.glob(os.path.join(img_path, '*.png'))]\n    print('Found {} images'.format(len(images)))\n    assert len(images) > 0, 'Did not found any images. Check your input_dir.'\n    annot_save_dir = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json/'))\n    annot_save_dir_difficult = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json-difficult/'))\n    print('Writing annotations to: {} and {}'.format(annot_save_dir, annot_save_dir_difficult))\n    for im in tqdm(images):\n        path = os.path.join(annot_path, im + '.txt')\n        im_path = os.path.join(img_path, im + '.png')\n        assert os.path.exists(im_path)\n        out_path = os.path.join(annot_save_dir, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=False)\n        out_path = os.path.join(annot_save_dir_difficult, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=True)\n    np.random.seed(0)\n    np.random.shuffle(images)\n    train_count = len(images) * train_percent // 100\n    train = images[:train_count]\n    val = images[train_count:]\n    create_manifest(train_manifest, train, annot_save_dir, img_path, data_dir)\n    create_manifest(val_manifest, val, annot_save_dir_difficult, img_path, data_dir)\n    config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'kitti.cfg')\n    with open(config_path, 'w') as f:\n        f.write('manifest = [train:{}, val:{}]\\n'.format(train_manifest, val_manifest))\n        f.write('manifest_root = {}\\n'.format(data_dir))\n        f.write('epochs = 14\\n')\n        f.write('height = 375\\n')\n        f.write('width = 1242\\n')\n        f.write('batch_size = 1\\n')\n    print('Wrote config file to: {}'.format(config_path))",
            "def ingest_kitti(input_dir, out_dir, train_percent=90, overwrite=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Ingests the KITTI dataset. Peforms the following ops:\\n    0. Unzips the files into output directory.\\n    1. Convert annotations to json format\\n    2. Split the training data into train and validation sets\\n    3. Write manifest file\\n    4. Write configuration file\\n\\n    Arguments:\\n        input_dir (string): path to folder with KITTI zip files.\\n        out_dir (string): path to unzip KITTI data\\n        train_percent (float): percent of data to use for training.\\n        overwrite (bool): overwrite existing files\\n    '\n    data_dir = ensure_dirs_exist(os.path.join(out_dir, 'kitti'))\n    train_manifest = os.path.join(data_dir, 'train.csv')\n    val_manifest = os.path.join(data_dir, 'val.csv')\n    if not overwrite and os.path.exists(train_manifest) and os.path.exists(val_manifest):\n        print('Found existing manfiest files, skipping ingest,\\n              Use --overwrite to rerun ingest anyway.')\n        return (train_manifest, val_manifest)\n    zipfiles = [os.path.join(input_dir, zipfile) for zipfile in ['data_object_image_2.zip', 'data_object_label_2.zip']]\n    for file in zipfiles:\n        with ZipFile(file, 'r') as zf:\n            print('Extracting {} to {}'.format(file, data_dir))\n            zf.extractall(data_dir)\n    img_path = os.path.join(data_dir, 'training', 'image_2')\n    annot_path = os.path.join(data_dir, 'training', 'label_2')\n    images = [os.path.splitext(os.path.basename(im))[0] for im in glob.glob(os.path.join(img_path, '*.png'))]\n    print('Found {} images'.format(len(images)))\n    assert len(images) > 0, 'Did not found any images. Check your input_dir.'\n    annot_save_dir = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json/'))\n    annot_save_dir_difficult = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json-difficult/'))\n    print('Writing annotations to: {} and {}'.format(annot_save_dir, annot_save_dir_difficult))\n    for im in tqdm(images):\n        path = os.path.join(annot_path, im + '.txt')\n        im_path = os.path.join(img_path, im + '.png')\n        assert os.path.exists(im_path)\n        out_path = os.path.join(annot_save_dir, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=False)\n        out_path = os.path.join(annot_save_dir_difficult, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=True)\n    np.random.seed(0)\n    np.random.shuffle(images)\n    train_count = len(images) * train_percent // 100\n    train = images[:train_count]\n    val = images[train_count:]\n    create_manifest(train_manifest, train, annot_save_dir, img_path, data_dir)\n    create_manifest(val_manifest, val, annot_save_dir_difficult, img_path, data_dir)\n    config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'kitti.cfg')\n    with open(config_path, 'w') as f:\n        f.write('manifest = [train:{}, val:{}]\\n'.format(train_manifest, val_manifest))\n        f.write('manifest_root = {}\\n'.format(data_dir))\n        f.write('epochs = 14\\n')\n        f.write('height = 375\\n')\n        f.write('width = 1242\\n')\n        f.write('batch_size = 1\\n')\n    print('Wrote config file to: {}'.format(config_path))",
            "def ingest_kitti(input_dir, out_dir, train_percent=90, overwrite=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Ingests the KITTI dataset. Peforms the following ops:\\n    0. Unzips the files into output directory.\\n    1. Convert annotations to json format\\n    2. Split the training data into train and validation sets\\n    3. Write manifest file\\n    4. Write configuration file\\n\\n    Arguments:\\n        input_dir (string): path to folder with KITTI zip files.\\n        out_dir (string): path to unzip KITTI data\\n        train_percent (float): percent of data to use for training.\\n        overwrite (bool): overwrite existing files\\n    '\n    data_dir = ensure_dirs_exist(os.path.join(out_dir, 'kitti'))\n    train_manifest = os.path.join(data_dir, 'train.csv')\n    val_manifest = os.path.join(data_dir, 'val.csv')\n    if not overwrite and os.path.exists(train_manifest) and os.path.exists(val_manifest):\n        print('Found existing manfiest files, skipping ingest,\\n              Use --overwrite to rerun ingest anyway.')\n        return (train_manifest, val_manifest)\n    zipfiles = [os.path.join(input_dir, zipfile) for zipfile in ['data_object_image_2.zip', 'data_object_label_2.zip']]\n    for file in zipfiles:\n        with ZipFile(file, 'r') as zf:\n            print('Extracting {} to {}'.format(file, data_dir))\n            zf.extractall(data_dir)\n    img_path = os.path.join(data_dir, 'training', 'image_2')\n    annot_path = os.path.join(data_dir, 'training', 'label_2')\n    images = [os.path.splitext(os.path.basename(im))[0] for im in glob.glob(os.path.join(img_path, '*.png'))]\n    print('Found {} images'.format(len(images)))\n    assert len(images) > 0, 'Did not found any images. Check your input_dir.'\n    annot_save_dir = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json/'))\n    annot_save_dir_difficult = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json-difficult/'))\n    print('Writing annotations to: {} and {}'.format(annot_save_dir, annot_save_dir_difficult))\n    for im in tqdm(images):\n        path = os.path.join(annot_path, im + '.txt')\n        im_path = os.path.join(img_path, im + '.png')\n        assert os.path.exists(im_path)\n        out_path = os.path.join(annot_save_dir, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=False)\n        out_path = os.path.join(annot_save_dir_difficult, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=True)\n    np.random.seed(0)\n    np.random.shuffle(images)\n    train_count = len(images) * train_percent // 100\n    train = images[:train_count]\n    val = images[train_count:]\n    create_manifest(train_manifest, train, annot_save_dir, img_path, data_dir)\n    create_manifest(val_manifest, val, annot_save_dir_difficult, img_path, data_dir)\n    config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'kitti.cfg')\n    with open(config_path, 'w') as f:\n        f.write('manifest = [train:{}, val:{}]\\n'.format(train_manifest, val_manifest))\n        f.write('manifest_root = {}\\n'.format(data_dir))\n        f.write('epochs = 14\\n')\n        f.write('height = 375\\n')\n        f.write('width = 1242\\n')\n        f.write('batch_size = 1\\n')\n    print('Wrote config file to: {}'.format(config_path))",
            "def ingest_kitti(input_dir, out_dir, train_percent=90, overwrite=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Ingests the KITTI dataset. Peforms the following ops:\\n    0. Unzips the files into output directory.\\n    1. Convert annotations to json format\\n    2. Split the training data into train and validation sets\\n    3. Write manifest file\\n    4. Write configuration file\\n\\n    Arguments:\\n        input_dir (string): path to folder with KITTI zip files.\\n        out_dir (string): path to unzip KITTI data\\n        train_percent (float): percent of data to use for training.\\n        overwrite (bool): overwrite existing files\\n    '\n    data_dir = ensure_dirs_exist(os.path.join(out_dir, 'kitti'))\n    train_manifest = os.path.join(data_dir, 'train.csv')\n    val_manifest = os.path.join(data_dir, 'val.csv')\n    if not overwrite and os.path.exists(train_manifest) and os.path.exists(val_manifest):\n        print('Found existing manfiest files, skipping ingest,\\n              Use --overwrite to rerun ingest anyway.')\n        return (train_manifest, val_manifest)\n    zipfiles = [os.path.join(input_dir, zipfile) for zipfile in ['data_object_image_2.zip', 'data_object_label_2.zip']]\n    for file in zipfiles:\n        with ZipFile(file, 'r') as zf:\n            print('Extracting {} to {}'.format(file, data_dir))\n            zf.extractall(data_dir)\n    img_path = os.path.join(data_dir, 'training', 'image_2')\n    annot_path = os.path.join(data_dir, 'training', 'label_2')\n    images = [os.path.splitext(os.path.basename(im))[0] for im in glob.glob(os.path.join(img_path, '*.png'))]\n    print('Found {} images'.format(len(images)))\n    assert len(images) > 0, 'Did not found any images. Check your input_dir.'\n    annot_save_dir = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json/'))\n    annot_save_dir_difficult = ensure_dirs_exist(os.path.join(data_dir, 'training', 'label_2-json-difficult/'))\n    print('Writing annotations to: {} and {}'.format(annot_save_dir, annot_save_dir_difficult))\n    for im in tqdm(images):\n        path = os.path.join(annot_path, im + '.txt')\n        im_path = os.path.join(img_path, im + '.png')\n        assert os.path.exists(im_path)\n        out_path = os.path.join(annot_save_dir, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=False)\n        out_path = os.path.join(annot_save_dir_difficult, im + '.json')\n        convert_annot_to_json(path, im_path, out_path, difficult=True)\n    np.random.seed(0)\n    np.random.shuffle(images)\n    train_count = len(images) * train_percent // 100\n    train = images[:train_count]\n    val = images[train_count:]\n    create_manifest(train_manifest, train, annot_save_dir, img_path, data_dir)\n    create_manifest(val_manifest, val, annot_save_dir_difficult, img_path, data_dir)\n    config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'kitti.cfg')\n    with open(config_path, 'w') as f:\n        f.write('manifest = [train:{}, val:{}]\\n'.format(train_manifest, val_manifest))\n        f.write('manifest_root = {}\\n'.format(data_dir))\n        f.write('epochs = 14\\n')\n        f.write('height = 375\\n')\n        f.write('width = 1242\\n')\n        f.write('batch_size = 1\\n')\n    print('Wrote config file to: {}'.format(config_path))"
        ]
    },
    {
        "func_name": "create_manifest",
        "original": "def create_manifest(manifest_path, index_list, annot_dir, image_dir, root_dir):\n    records = [('@FILE', 'FILE')]\n    for tag in index_list:\n        image = os.path.join(image_dir, tag + '.png')\n        annot = os.path.join(annot_dir, tag + '.json')\n        assert os.path.exists(image), 'Path {} not found'.format(image)\n        assert os.path.exists(annot), 'Path {} not found'.format(annot)\n        records.append((os.path.relpath(image, root_dir), os.path.relpath(annot, root_dir)))\n    print('Writing manifest file to: {}'.format(manifest_path))\n    np.savetxt(manifest_path, records, fmt='%s\\t%s')",
        "mutated": [
            "def create_manifest(manifest_path, index_list, annot_dir, image_dir, root_dir):\n    if False:\n        i = 10\n    records = [('@FILE', 'FILE')]\n    for tag in index_list:\n        image = os.path.join(image_dir, tag + '.png')\n        annot = os.path.join(annot_dir, tag + '.json')\n        assert os.path.exists(image), 'Path {} not found'.format(image)\n        assert os.path.exists(annot), 'Path {} not found'.format(annot)\n        records.append((os.path.relpath(image, root_dir), os.path.relpath(annot, root_dir)))\n    print('Writing manifest file to: {}'.format(manifest_path))\n    np.savetxt(manifest_path, records, fmt='%s\\t%s')",
            "def create_manifest(manifest_path, index_list, annot_dir, image_dir, root_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    records = [('@FILE', 'FILE')]\n    for tag in index_list:\n        image = os.path.join(image_dir, tag + '.png')\n        annot = os.path.join(annot_dir, tag + '.json')\n        assert os.path.exists(image), 'Path {} not found'.format(image)\n        assert os.path.exists(annot), 'Path {} not found'.format(annot)\n        records.append((os.path.relpath(image, root_dir), os.path.relpath(annot, root_dir)))\n    print('Writing manifest file to: {}'.format(manifest_path))\n    np.savetxt(manifest_path, records, fmt='%s\\t%s')",
            "def create_manifest(manifest_path, index_list, annot_dir, image_dir, root_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    records = [('@FILE', 'FILE')]\n    for tag in index_list:\n        image = os.path.join(image_dir, tag + '.png')\n        annot = os.path.join(annot_dir, tag + '.json')\n        assert os.path.exists(image), 'Path {} not found'.format(image)\n        assert os.path.exists(annot), 'Path {} not found'.format(annot)\n        records.append((os.path.relpath(image, root_dir), os.path.relpath(annot, root_dir)))\n    print('Writing manifest file to: {}'.format(manifest_path))\n    np.savetxt(manifest_path, records, fmt='%s\\t%s')",
            "def create_manifest(manifest_path, index_list, annot_dir, image_dir, root_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    records = [('@FILE', 'FILE')]\n    for tag in index_list:\n        image = os.path.join(image_dir, tag + '.png')\n        annot = os.path.join(annot_dir, tag + '.json')\n        assert os.path.exists(image), 'Path {} not found'.format(image)\n        assert os.path.exists(annot), 'Path {} not found'.format(annot)\n        records.append((os.path.relpath(image, root_dir), os.path.relpath(annot, root_dir)))\n    print('Writing manifest file to: {}'.format(manifest_path))\n    np.savetxt(manifest_path, records, fmt='%s\\t%s')",
            "def create_manifest(manifest_path, index_list, annot_dir, image_dir, root_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    records = [('@FILE', 'FILE')]\n    for tag in index_list:\n        image = os.path.join(image_dir, tag + '.png')\n        annot = os.path.join(annot_dir, tag + '.json')\n        assert os.path.exists(image), 'Path {} not found'.format(image)\n        assert os.path.exists(annot), 'Path {} not found'.format(annot)\n        records.append((os.path.relpath(image, root_dir), os.path.relpath(annot, root_dir)))\n    print('Writing manifest file to: {}'.format(manifest_path))\n    np.savetxt(manifest_path, records, fmt='%s\\t%s')"
        ]
    }
]