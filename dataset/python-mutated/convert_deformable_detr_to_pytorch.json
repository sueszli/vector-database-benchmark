[
    {
        "func_name": "rename_key",
        "original": "def rename_key(orig_key):\n    if 'backbone.0.body' in orig_key:\n        orig_key = orig_key.replace('backbone.0.body', 'backbone.conv_encoder.model')\n    if 'transformer' in orig_key:\n        orig_key = orig_key.replace('transformer.', '')\n    if 'norm1' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm1', 'self_attn_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm1', 'encoder_attn_layer_norm')\n    if 'norm2' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm2', 'final_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm2', 'self_attn_layer_norm')\n    if 'norm3' in orig_key:\n        orig_key = orig_key.replace('norm3', 'final_layer_norm')\n    if 'linear1' in orig_key:\n        orig_key = orig_key.replace('linear1', 'fc1')\n    if 'linear2' in orig_key:\n        orig_key = orig_key.replace('linear2', 'fc2')\n    if 'query_embed' in orig_key:\n        orig_key = orig_key.replace('query_embed', 'query_position_embeddings')\n    if 'cross_attn' in orig_key:\n        orig_key = orig_key.replace('cross_attn', 'encoder_attn')\n    return orig_key",
        "mutated": [
            "def rename_key(orig_key):\n    if False:\n        i = 10\n    if 'backbone.0.body' in orig_key:\n        orig_key = orig_key.replace('backbone.0.body', 'backbone.conv_encoder.model')\n    if 'transformer' in orig_key:\n        orig_key = orig_key.replace('transformer.', '')\n    if 'norm1' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm1', 'self_attn_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm1', 'encoder_attn_layer_norm')\n    if 'norm2' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm2', 'final_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm2', 'self_attn_layer_norm')\n    if 'norm3' in orig_key:\n        orig_key = orig_key.replace('norm3', 'final_layer_norm')\n    if 'linear1' in orig_key:\n        orig_key = orig_key.replace('linear1', 'fc1')\n    if 'linear2' in orig_key:\n        orig_key = orig_key.replace('linear2', 'fc2')\n    if 'query_embed' in orig_key:\n        orig_key = orig_key.replace('query_embed', 'query_position_embeddings')\n    if 'cross_attn' in orig_key:\n        orig_key = orig_key.replace('cross_attn', 'encoder_attn')\n    return orig_key",
            "def rename_key(orig_key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if 'backbone.0.body' in orig_key:\n        orig_key = orig_key.replace('backbone.0.body', 'backbone.conv_encoder.model')\n    if 'transformer' in orig_key:\n        orig_key = orig_key.replace('transformer.', '')\n    if 'norm1' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm1', 'self_attn_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm1', 'encoder_attn_layer_norm')\n    if 'norm2' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm2', 'final_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm2', 'self_attn_layer_norm')\n    if 'norm3' in orig_key:\n        orig_key = orig_key.replace('norm3', 'final_layer_norm')\n    if 'linear1' in orig_key:\n        orig_key = orig_key.replace('linear1', 'fc1')\n    if 'linear2' in orig_key:\n        orig_key = orig_key.replace('linear2', 'fc2')\n    if 'query_embed' in orig_key:\n        orig_key = orig_key.replace('query_embed', 'query_position_embeddings')\n    if 'cross_attn' in orig_key:\n        orig_key = orig_key.replace('cross_attn', 'encoder_attn')\n    return orig_key",
            "def rename_key(orig_key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if 'backbone.0.body' in orig_key:\n        orig_key = orig_key.replace('backbone.0.body', 'backbone.conv_encoder.model')\n    if 'transformer' in orig_key:\n        orig_key = orig_key.replace('transformer.', '')\n    if 'norm1' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm1', 'self_attn_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm1', 'encoder_attn_layer_norm')\n    if 'norm2' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm2', 'final_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm2', 'self_attn_layer_norm')\n    if 'norm3' in orig_key:\n        orig_key = orig_key.replace('norm3', 'final_layer_norm')\n    if 'linear1' in orig_key:\n        orig_key = orig_key.replace('linear1', 'fc1')\n    if 'linear2' in orig_key:\n        orig_key = orig_key.replace('linear2', 'fc2')\n    if 'query_embed' in orig_key:\n        orig_key = orig_key.replace('query_embed', 'query_position_embeddings')\n    if 'cross_attn' in orig_key:\n        orig_key = orig_key.replace('cross_attn', 'encoder_attn')\n    return orig_key",
            "def rename_key(orig_key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if 'backbone.0.body' in orig_key:\n        orig_key = orig_key.replace('backbone.0.body', 'backbone.conv_encoder.model')\n    if 'transformer' in orig_key:\n        orig_key = orig_key.replace('transformer.', '')\n    if 'norm1' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm1', 'self_attn_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm1', 'encoder_attn_layer_norm')\n    if 'norm2' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm2', 'final_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm2', 'self_attn_layer_norm')\n    if 'norm3' in orig_key:\n        orig_key = orig_key.replace('norm3', 'final_layer_norm')\n    if 'linear1' in orig_key:\n        orig_key = orig_key.replace('linear1', 'fc1')\n    if 'linear2' in orig_key:\n        orig_key = orig_key.replace('linear2', 'fc2')\n    if 'query_embed' in orig_key:\n        orig_key = orig_key.replace('query_embed', 'query_position_embeddings')\n    if 'cross_attn' in orig_key:\n        orig_key = orig_key.replace('cross_attn', 'encoder_attn')\n    return orig_key",
            "def rename_key(orig_key):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if 'backbone.0.body' in orig_key:\n        orig_key = orig_key.replace('backbone.0.body', 'backbone.conv_encoder.model')\n    if 'transformer' in orig_key:\n        orig_key = orig_key.replace('transformer.', '')\n    if 'norm1' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm1', 'self_attn_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm1', 'encoder_attn_layer_norm')\n    if 'norm2' in orig_key:\n        if 'encoder' in orig_key:\n            orig_key = orig_key.replace('norm2', 'final_layer_norm')\n        else:\n            orig_key = orig_key.replace('norm2', 'self_attn_layer_norm')\n    if 'norm3' in orig_key:\n        orig_key = orig_key.replace('norm3', 'final_layer_norm')\n    if 'linear1' in orig_key:\n        orig_key = orig_key.replace('linear1', 'fc1')\n    if 'linear2' in orig_key:\n        orig_key = orig_key.replace('linear2', 'fc2')\n    if 'query_embed' in orig_key:\n        orig_key = orig_key.replace('query_embed', 'query_position_embeddings')\n    if 'cross_attn' in orig_key:\n        orig_key = orig_key.replace('cross_attn', 'encoder_attn')\n    return orig_key"
        ]
    },
    {
        "func_name": "read_in_q_k_v",
        "original": "def read_in_q_k_v(state_dict):\n    for i in range(6):\n        in_proj_weight = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_weight')\n        in_proj_bias = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_bias')\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.weight'] = in_proj_weight[:256, :]\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.bias'] = in_proj_bias[:256]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.weight'] = in_proj_weight[256:512, :]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.bias'] = in_proj_bias[256:512]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.weight'] = in_proj_weight[-256:, :]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.bias'] = in_proj_bias[-256:]",
        "mutated": [
            "def read_in_q_k_v(state_dict):\n    if False:\n        i = 10\n    for i in range(6):\n        in_proj_weight = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_weight')\n        in_proj_bias = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_bias')\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.weight'] = in_proj_weight[:256, :]\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.bias'] = in_proj_bias[:256]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.weight'] = in_proj_weight[256:512, :]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.bias'] = in_proj_bias[256:512]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.weight'] = in_proj_weight[-256:, :]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.bias'] = in_proj_bias[-256:]",
            "def read_in_q_k_v(state_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for i in range(6):\n        in_proj_weight = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_weight')\n        in_proj_bias = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_bias')\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.weight'] = in_proj_weight[:256, :]\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.bias'] = in_proj_bias[:256]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.weight'] = in_proj_weight[256:512, :]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.bias'] = in_proj_bias[256:512]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.weight'] = in_proj_weight[-256:, :]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.bias'] = in_proj_bias[-256:]",
            "def read_in_q_k_v(state_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for i in range(6):\n        in_proj_weight = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_weight')\n        in_proj_bias = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_bias')\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.weight'] = in_proj_weight[:256, :]\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.bias'] = in_proj_bias[:256]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.weight'] = in_proj_weight[256:512, :]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.bias'] = in_proj_bias[256:512]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.weight'] = in_proj_weight[-256:, :]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.bias'] = in_proj_bias[-256:]",
            "def read_in_q_k_v(state_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for i in range(6):\n        in_proj_weight = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_weight')\n        in_proj_bias = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_bias')\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.weight'] = in_proj_weight[:256, :]\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.bias'] = in_proj_bias[:256]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.weight'] = in_proj_weight[256:512, :]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.bias'] = in_proj_bias[256:512]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.weight'] = in_proj_weight[-256:, :]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.bias'] = in_proj_bias[-256:]",
            "def read_in_q_k_v(state_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for i in range(6):\n        in_proj_weight = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_weight')\n        in_proj_bias = state_dict.pop(f'decoder.layers.{i}.self_attn.in_proj_bias')\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.weight'] = in_proj_weight[:256, :]\n        state_dict[f'decoder.layers.{i}.self_attn.q_proj.bias'] = in_proj_bias[:256]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.weight'] = in_proj_weight[256:512, :]\n        state_dict[f'decoder.layers.{i}.self_attn.k_proj.bias'] = in_proj_bias[256:512]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.weight'] = in_proj_weight[-256:, :]\n        state_dict[f'decoder.layers.{i}.self_attn.v_proj.bias'] = in_proj_bias[-256:]"
        ]
    },
    {
        "func_name": "prepare_img",
        "original": "def prepare_img():\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    im = Image.open(requests.get(url, stream=True).raw)\n    return im",
        "mutated": [
            "def prepare_img():\n    if False:\n        i = 10\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    im = Image.open(requests.get(url, stream=True).raw)\n    return im",
            "def prepare_img():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    im = Image.open(requests.get(url, stream=True).raw)\n    return im",
            "def prepare_img():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    im = Image.open(requests.get(url, stream=True).raw)\n    return im",
            "def prepare_img():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    im = Image.open(requests.get(url, stream=True).raw)\n    return im",
            "def prepare_img():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    im = Image.open(requests.get(url, stream=True).raw)\n    return im"
        ]
    },
    {
        "func_name": "convert_deformable_detr_checkpoint",
        "original": "@torch.no_grad()\ndef convert_deformable_detr_checkpoint(checkpoint_path, single_scale, dilation, with_box_refine, two_stage, pytorch_dump_folder_path, push_to_hub):\n    \"\"\"\n    Copy/paste/tweak model's weights to our Deformable DETR structure.\n    \"\"\"\n    config = DeformableDetrConfig()\n    if single_scale:\n        config.num_feature_levels = 1\n    config.dilation = dilation\n    config.with_box_refine = with_box_refine\n    config.two_stage = two_stage\n    config.num_labels = 91\n    repo_id = 'huggingface/label-files'\n    filename = 'coco-detection-id2label.json'\n    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    config.id2label = id2label\n    config.label2id = {v: k for (k, v) in id2label.items()}\n    image_processor = DeformableDetrImageProcessor(format='coco_detection')\n    img = prepare_img()\n    encoding = image_processor(images=img, return_tensors='pt')\n    pixel_values = encoding['pixel_values']\n    logger.info('Converting model...')\n    state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    read_in_q_k_v(state_dict)\n    prefix = 'model.'\n    for key in state_dict.copy().keys():\n        if not key.startswith('class_embed') and (not key.startswith('bbox_embed')):\n            val = state_dict.pop(key)\n            state_dict[prefix + key] = val\n    model = DeformableDetrForObjectDetection(config)\n    model.load_state_dict(state_dict)\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    outputs = model(pixel_values.to(device))\n    expected_logits = torch.tensor([[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]])\n    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.315, 0.5489, 0.5845], [0.5563, 0.758, 0.8518]])\n    if single_scale:\n        expected_logits = torch.tensor([[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.847, -7.7003]])\n        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])\n    if single_scale and dilation:\n        expected_logits = torch.tensor([[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]])\n        expected_boxes = torch.tensor([[0.7665, 0.413, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])\n    if with_box_refine:\n        expected_logits = torch.tensor([[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]])\n        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])\n    if with_box_refine and two_stage:\n        expected_logits = torch.tensor([[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.724], [-6.9315, -4.4735, -6.2298]])\n        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.549, 0.2763, 0.0564]])\n    print('Logits:', outputs.logits[0, :3, :3])\n    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=0.0001)\n    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=0.0001)\n    print('Everything ok!')\n    logger.info(f'Saving PyTorch model and image processor to {pytorch_dump_folder_path}...')\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)\n    image_processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model_name = 'deformable-detr'\n        model_name += '-single-scale' if single_scale else ''\n        model_name += '-dc5' if dilation else ''\n        model_name += '-with-box-refine' if with_box_refine else ''\n        model_name += '-two-stage' if two_stage else ''\n        print('Pushing model to hub...')\n        model.push_to_hub(repo_path_or_name=model_name, organization='nielsr', commit_message='Add model')",
        "mutated": [
            "@torch.no_grad()\ndef convert_deformable_detr_checkpoint(checkpoint_path, single_scale, dilation, with_box_refine, two_stage, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n    \"\\n    Copy/paste/tweak model's weights to our Deformable DETR structure.\\n    \"\n    config = DeformableDetrConfig()\n    if single_scale:\n        config.num_feature_levels = 1\n    config.dilation = dilation\n    config.with_box_refine = with_box_refine\n    config.two_stage = two_stage\n    config.num_labels = 91\n    repo_id = 'huggingface/label-files'\n    filename = 'coco-detection-id2label.json'\n    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    config.id2label = id2label\n    config.label2id = {v: k for (k, v) in id2label.items()}\n    image_processor = DeformableDetrImageProcessor(format='coco_detection')\n    img = prepare_img()\n    encoding = image_processor(images=img, return_tensors='pt')\n    pixel_values = encoding['pixel_values']\n    logger.info('Converting model...')\n    state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    read_in_q_k_v(state_dict)\n    prefix = 'model.'\n    for key in state_dict.copy().keys():\n        if not key.startswith('class_embed') and (not key.startswith('bbox_embed')):\n            val = state_dict.pop(key)\n            state_dict[prefix + key] = val\n    model = DeformableDetrForObjectDetection(config)\n    model.load_state_dict(state_dict)\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    outputs = model(pixel_values.to(device))\n    expected_logits = torch.tensor([[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]])\n    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.315, 0.5489, 0.5845], [0.5563, 0.758, 0.8518]])\n    if single_scale:\n        expected_logits = torch.tensor([[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.847, -7.7003]])\n        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])\n    if single_scale and dilation:\n        expected_logits = torch.tensor([[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]])\n        expected_boxes = torch.tensor([[0.7665, 0.413, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])\n    if with_box_refine:\n        expected_logits = torch.tensor([[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]])\n        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])\n    if with_box_refine and two_stage:\n        expected_logits = torch.tensor([[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.724], [-6.9315, -4.4735, -6.2298]])\n        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.549, 0.2763, 0.0564]])\n    print('Logits:', outputs.logits[0, :3, :3])\n    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=0.0001)\n    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=0.0001)\n    print('Everything ok!')\n    logger.info(f'Saving PyTorch model and image processor to {pytorch_dump_folder_path}...')\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)\n    image_processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model_name = 'deformable-detr'\n        model_name += '-single-scale' if single_scale else ''\n        model_name += '-dc5' if dilation else ''\n        model_name += '-with-box-refine' if with_box_refine else ''\n        model_name += '-two-stage' if two_stage else ''\n        print('Pushing model to hub...')\n        model.push_to_hub(repo_path_or_name=model_name, organization='nielsr', commit_message='Add model')",
            "@torch.no_grad()\ndef convert_deformable_detr_checkpoint(checkpoint_path, single_scale, dilation, with_box_refine, two_stage, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Copy/paste/tweak model's weights to our Deformable DETR structure.\\n    \"\n    config = DeformableDetrConfig()\n    if single_scale:\n        config.num_feature_levels = 1\n    config.dilation = dilation\n    config.with_box_refine = with_box_refine\n    config.two_stage = two_stage\n    config.num_labels = 91\n    repo_id = 'huggingface/label-files'\n    filename = 'coco-detection-id2label.json'\n    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    config.id2label = id2label\n    config.label2id = {v: k for (k, v) in id2label.items()}\n    image_processor = DeformableDetrImageProcessor(format='coco_detection')\n    img = prepare_img()\n    encoding = image_processor(images=img, return_tensors='pt')\n    pixel_values = encoding['pixel_values']\n    logger.info('Converting model...')\n    state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    read_in_q_k_v(state_dict)\n    prefix = 'model.'\n    for key in state_dict.copy().keys():\n        if not key.startswith('class_embed') and (not key.startswith('bbox_embed')):\n            val = state_dict.pop(key)\n            state_dict[prefix + key] = val\n    model = DeformableDetrForObjectDetection(config)\n    model.load_state_dict(state_dict)\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    outputs = model(pixel_values.to(device))\n    expected_logits = torch.tensor([[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]])\n    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.315, 0.5489, 0.5845], [0.5563, 0.758, 0.8518]])\n    if single_scale:\n        expected_logits = torch.tensor([[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.847, -7.7003]])\n        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])\n    if single_scale and dilation:\n        expected_logits = torch.tensor([[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]])\n        expected_boxes = torch.tensor([[0.7665, 0.413, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])\n    if with_box_refine:\n        expected_logits = torch.tensor([[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]])\n        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])\n    if with_box_refine and two_stage:\n        expected_logits = torch.tensor([[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.724], [-6.9315, -4.4735, -6.2298]])\n        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.549, 0.2763, 0.0564]])\n    print('Logits:', outputs.logits[0, :3, :3])\n    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=0.0001)\n    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=0.0001)\n    print('Everything ok!')\n    logger.info(f'Saving PyTorch model and image processor to {pytorch_dump_folder_path}...')\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)\n    image_processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model_name = 'deformable-detr'\n        model_name += '-single-scale' if single_scale else ''\n        model_name += '-dc5' if dilation else ''\n        model_name += '-with-box-refine' if with_box_refine else ''\n        model_name += '-two-stage' if two_stage else ''\n        print('Pushing model to hub...')\n        model.push_to_hub(repo_path_or_name=model_name, organization='nielsr', commit_message='Add model')",
            "@torch.no_grad()\ndef convert_deformable_detr_checkpoint(checkpoint_path, single_scale, dilation, with_box_refine, two_stage, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Copy/paste/tweak model's weights to our Deformable DETR structure.\\n    \"\n    config = DeformableDetrConfig()\n    if single_scale:\n        config.num_feature_levels = 1\n    config.dilation = dilation\n    config.with_box_refine = with_box_refine\n    config.two_stage = two_stage\n    config.num_labels = 91\n    repo_id = 'huggingface/label-files'\n    filename = 'coco-detection-id2label.json'\n    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    config.id2label = id2label\n    config.label2id = {v: k for (k, v) in id2label.items()}\n    image_processor = DeformableDetrImageProcessor(format='coco_detection')\n    img = prepare_img()\n    encoding = image_processor(images=img, return_tensors='pt')\n    pixel_values = encoding['pixel_values']\n    logger.info('Converting model...')\n    state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    read_in_q_k_v(state_dict)\n    prefix = 'model.'\n    for key in state_dict.copy().keys():\n        if not key.startswith('class_embed') and (not key.startswith('bbox_embed')):\n            val = state_dict.pop(key)\n            state_dict[prefix + key] = val\n    model = DeformableDetrForObjectDetection(config)\n    model.load_state_dict(state_dict)\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    outputs = model(pixel_values.to(device))\n    expected_logits = torch.tensor([[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]])\n    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.315, 0.5489, 0.5845], [0.5563, 0.758, 0.8518]])\n    if single_scale:\n        expected_logits = torch.tensor([[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.847, -7.7003]])\n        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])\n    if single_scale and dilation:\n        expected_logits = torch.tensor([[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]])\n        expected_boxes = torch.tensor([[0.7665, 0.413, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])\n    if with_box_refine:\n        expected_logits = torch.tensor([[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]])\n        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])\n    if with_box_refine and two_stage:\n        expected_logits = torch.tensor([[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.724], [-6.9315, -4.4735, -6.2298]])\n        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.549, 0.2763, 0.0564]])\n    print('Logits:', outputs.logits[0, :3, :3])\n    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=0.0001)\n    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=0.0001)\n    print('Everything ok!')\n    logger.info(f'Saving PyTorch model and image processor to {pytorch_dump_folder_path}...')\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)\n    image_processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model_name = 'deformable-detr'\n        model_name += '-single-scale' if single_scale else ''\n        model_name += '-dc5' if dilation else ''\n        model_name += '-with-box-refine' if with_box_refine else ''\n        model_name += '-two-stage' if two_stage else ''\n        print('Pushing model to hub...')\n        model.push_to_hub(repo_path_or_name=model_name, organization='nielsr', commit_message='Add model')",
            "@torch.no_grad()\ndef convert_deformable_detr_checkpoint(checkpoint_path, single_scale, dilation, with_box_refine, two_stage, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Copy/paste/tweak model's weights to our Deformable DETR structure.\\n    \"\n    config = DeformableDetrConfig()\n    if single_scale:\n        config.num_feature_levels = 1\n    config.dilation = dilation\n    config.with_box_refine = with_box_refine\n    config.two_stage = two_stage\n    config.num_labels = 91\n    repo_id = 'huggingface/label-files'\n    filename = 'coco-detection-id2label.json'\n    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    config.id2label = id2label\n    config.label2id = {v: k for (k, v) in id2label.items()}\n    image_processor = DeformableDetrImageProcessor(format='coco_detection')\n    img = prepare_img()\n    encoding = image_processor(images=img, return_tensors='pt')\n    pixel_values = encoding['pixel_values']\n    logger.info('Converting model...')\n    state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    read_in_q_k_v(state_dict)\n    prefix = 'model.'\n    for key in state_dict.copy().keys():\n        if not key.startswith('class_embed') and (not key.startswith('bbox_embed')):\n            val = state_dict.pop(key)\n            state_dict[prefix + key] = val\n    model = DeformableDetrForObjectDetection(config)\n    model.load_state_dict(state_dict)\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    outputs = model(pixel_values.to(device))\n    expected_logits = torch.tensor([[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]])\n    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.315, 0.5489, 0.5845], [0.5563, 0.758, 0.8518]])\n    if single_scale:\n        expected_logits = torch.tensor([[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.847, -7.7003]])\n        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])\n    if single_scale and dilation:\n        expected_logits = torch.tensor([[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]])\n        expected_boxes = torch.tensor([[0.7665, 0.413, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])\n    if with_box_refine:\n        expected_logits = torch.tensor([[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]])\n        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])\n    if with_box_refine and two_stage:\n        expected_logits = torch.tensor([[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.724], [-6.9315, -4.4735, -6.2298]])\n        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.549, 0.2763, 0.0564]])\n    print('Logits:', outputs.logits[0, :3, :3])\n    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=0.0001)\n    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=0.0001)\n    print('Everything ok!')\n    logger.info(f'Saving PyTorch model and image processor to {pytorch_dump_folder_path}...')\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)\n    image_processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model_name = 'deformable-detr'\n        model_name += '-single-scale' if single_scale else ''\n        model_name += '-dc5' if dilation else ''\n        model_name += '-with-box-refine' if with_box_refine else ''\n        model_name += '-two-stage' if two_stage else ''\n        print('Pushing model to hub...')\n        model.push_to_hub(repo_path_or_name=model_name, organization='nielsr', commit_message='Add model')",
            "@torch.no_grad()\ndef convert_deformable_detr_checkpoint(checkpoint_path, single_scale, dilation, with_box_refine, two_stage, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Copy/paste/tweak model's weights to our Deformable DETR structure.\\n    \"\n    config = DeformableDetrConfig()\n    if single_scale:\n        config.num_feature_levels = 1\n    config.dilation = dilation\n    config.with_box_refine = with_box_refine\n    config.two_stage = two_stage\n    config.num_labels = 91\n    repo_id = 'huggingface/label-files'\n    filename = 'coco-detection-id2label.json'\n    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type='dataset')), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    config.id2label = id2label\n    config.label2id = {v: k for (k, v) in id2label.items()}\n    image_processor = DeformableDetrImageProcessor(format='coco_detection')\n    img = prepare_img()\n    encoding = image_processor(images=img, return_tensors='pt')\n    pixel_values = encoding['pixel_values']\n    logger.info('Converting model...')\n    state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    read_in_q_k_v(state_dict)\n    prefix = 'model.'\n    for key in state_dict.copy().keys():\n        if not key.startswith('class_embed') and (not key.startswith('bbox_embed')):\n            val = state_dict.pop(key)\n            state_dict[prefix + key] = val\n    model = DeformableDetrForObjectDetection(config)\n    model.load_state_dict(state_dict)\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    outputs = model(pixel_values.to(device))\n    expected_logits = torch.tensor([[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]])\n    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.315, 0.5489, 0.5845], [0.5563, 0.758, 0.8518]])\n    if single_scale:\n        expected_logits = torch.tensor([[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.847, -7.7003]])\n        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])\n    if single_scale and dilation:\n        expected_logits = torch.tensor([[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]])\n        expected_boxes = torch.tensor([[0.7665, 0.413, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])\n    if with_box_refine:\n        expected_logits = torch.tensor([[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]])\n        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])\n    if with_box_refine and two_stage:\n        expected_logits = torch.tensor([[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.724], [-6.9315, -4.4735, -6.2298]])\n        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.549, 0.2763, 0.0564]])\n    print('Logits:', outputs.logits[0, :3, :3])\n    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=0.0001)\n    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=0.0001)\n    print('Everything ok!')\n    logger.info(f'Saving PyTorch model and image processor to {pytorch_dump_folder_path}...')\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)\n    image_processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model_name = 'deformable-detr'\n        model_name += '-single-scale' if single_scale else ''\n        model_name += '-dc5' if dilation else ''\n        model_name += '-with-box-refine' if with_box_refine else ''\n        model_name += '-two-stage' if two_stage else ''\n        print('Pushing model to hub...')\n        model.push_to_hub(repo_path_or_name=model_name, organization='nielsr', commit_message='Add model')"
        ]
    }
]