[
    {
        "func_name": "_inplace_helper",
        "original": "def _inplace_helper(x, i, v, op):\n    \"\"\"Applies an inplace op on (x, i, v).\n\n  op is one of gen_array_ops.alias_inplace_update,\n  gen_array_ops.alias_inplace_add, or gen_array_ops.alias_inplace_sub.\n\n  If i is None, x and v must be the same shape. Computes\n    x op v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    x[i, :] op v;\n  Otherwise, x and v must have the same rank. Computes\n    x[i, :] op v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n    op: alias_inplace_update, alias_inplace_add, or alias_inplace_sub.\n\n  Returns:\n    Returns x.\n\n  \"\"\"\n    x = ops.convert_to_tensor(x)\n    v = ops.convert_to_tensor(v, x.dtype)\n    if i is None:\n        return array_ops.reshape(op(array_ops.reshape(x, [1, -1]), [0], array_ops.reshape(v, [1, -1])), array_ops.shape(x))\n    i = math_ops.cast(i, dtypes.int32)\n    if i.get_shape().ndims == 0:\n        return op(x, array_ops.reshape(i, [1]), array_ops.expand_dims(v, 0))\n    return op(x, i, v)",
        "mutated": [
            "def _inplace_helper(x, i, v, op):\n    if False:\n        i = 10\n    \"Applies an inplace op on (x, i, v).\\n\\n  op is one of gen_array_ops.alias_inplace_update,\\n  gen_array_ops.alias_inplace_add, or gen_array_ops.alias_inplace_sub.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x op v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] op v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] op v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n    op: alias_inplace_update, alias_inplace_add, or alias_inplace_sub.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    x = ops.convert_to_tensor(x)\n    v = ops.convert_to_tensor(v, x.dtype)\n    if i is None:\n        return array_ops.reshape(op(array_ops.reshape(x, [1, -1]), [0], array_ops.reshape(v, [1, -1])), array_ops.shape(x))\n    i = math_ops.cast(i, dtypes.int32)\n    if i.get_shape().ndims == 0:\n        return op(x, array_ops.reshape(i, [1]), array_ops.expand_dims(v, 0))\n    return op(x, i, v)",
            "def _inplace_helper(x, i, v, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace op on (x, i, v).\\n\\n  op is one of gen_array_ops.alias_inplace_update,\\n  gen_array_ops.alias_inplace_add, or gen_array_ops.alias_inplace_sub.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x op v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] op v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] op v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n    op: alias_inplace_update, alias_inplace_add, or alias_inplace_sub.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    x = ops.convert_to_tensor(x)\n    v = ops.convert_to_tensor(v, x.dtype)\n    if i is None:\n        return array_ops.reshape(op(array_ops.reshape(x, [1, -1]), [0], array_ops.reshape(v, [1, -1])), array_ops.shape(x))\n    i = math_ops.cast(i, dtypes.int32)\n    if i.get_shape().ndims == 0:\n        return op(x, array_ops.reshape(i, [1]), array_ops.expand_dims(v, 0))\n    return op(x, i, v)",
            "def _inplace_helper(x, i, v, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace op on (x, i, v).\\n\\n  op is one of gen_array_ops.alias_inplace_update,\\n  gen_array_ops.alias_inplace_add, or gen_array_ops.alias_inplace_sub.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x op v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] op v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] op v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n    op: alias_inplace_update, alias_inplace_add, or alias_inplace_sub.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    x = ops.convert_to_tensor(x)\n    v = ops.convert_to_tensor(v, x.dtype)\n    if i is None:\n        return array_ops.reshape(op(array_ops.reshape(x, [1, -1]), [0], array_ops.reshape(v, [1, -1])), array_ops.shape(x))\n    i = math_ops.cast(i, dtypes.int32)\n    if i.get_shape().ndims == 0:\n        return op(x, array_ops.reshape(i, [1]), array_ops.expand_dims(v, 0))\n    return op(x, i, v)",
            "def _inplace_helper(x, i, v, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace op on (x, i, v).\\n\\n  op is one of gen_array_ops.alias_inplace_update,\\n  gen_array_ops.alias_inplace_add, or gen_array_ops.alias_inplace_sub.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x op v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] op v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] op v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n    op: alias_inplace_update, alias_inplace_add, or alias_inplace_sub.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    x = ops.convert_to_tensor(x)\n    v = ops.convert_to_tensor(v, x.dtype)\n    if i is None:\n        return array_ops.reshape(op(array_ops.reshape(x, [1, -1]), [0], array_ops.reshape(v, [1, -1])), array_ops.shape(x))\n    i = math_ops.cast(i, dtypes.int32)\n    if i.get_shape().ndims == 0:\n        return op(x, array_ops.reshape(i, [1]), array_ops.expand_dims(v, 0))\n    return op(x, i, v)",
            "def _inplace_helper(x, i, v, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace op on (x, i, v).\\n\\n  op is one of gen_array_ops.alias_inplace_update,\\n  gen_array_ops.alias_inplace_add, or gen_array_ops.alias_inplace_sub.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x op v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] op v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] op v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n    op: alias_inplace_update, alias_inplace_add, or alias_inplace_sub.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    x = ops.convert_to_tensor(x)\n    v = ops.convert_to_tensor(v, x.dtype)\n    if i is None:\n        return array_ops.reshape(op(array_ops.reshape(x, [1, -1]), [0], array_ops.reshape(v, [1, -1])), array_ops.shape(x))\n    i = math_ops.cast(i, dtypes.int32)\n    if i.get_shape().ndims == 0:\n        return op(x, array_ops.reshape(i, [1]), array_ops.expand_dims(v, 0))\n    return op(x, i, v)"
        ]
    },
    {
        "func_name": "alias_inplace_update",
        "original": "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_update(x, i, v):\n    \"\"\"Applies an inplace update on input x at index i with value v. Aliases x.\n\n  If i is None, x and v must be the same shape. Computes\n    x = v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    x[i, :] = v;\n  Otherwise, x and v must have the same rank. Computes\n    x[i, :] = v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n\n  Returns:\n    Returns x.\n\n  \"\"\"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_update)",
        "mutated": [
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_update(x, i, v):\n    if False:\n        i = 10\n    \"Applies an inplace update on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_update)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace update on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_update)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace update on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_update)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace update on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_update)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace update on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_update)"
        ]
    },
    {
        "func_name": "alias_inplace_add",
        "original": "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_add(x, i, v):\n    \"\"\"Applies an inplace add on input x at index i with value v. Aliases x.\n\n  If i is None, x and v must be the same shape. Computes\n    x += v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    x[i, :] += v;\n  Otherwise, x and v must have the same rank. Computes\n    x[i, :] += v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n\n  Returns:\n    Returns x.\n\n  \"\"\"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_add)",
        "mutated": [
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_add(x, i, v):\n    if False:\n        i = 10\n    \"Applies an inplace add on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_add)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace add on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_add)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace add on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_add)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace add on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_add)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace add on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_add)"
        ]
    },
    {
        "func_name": "alias_inplace_sub",
        "original": "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_sub(x, i, v):\n    \"\"\"Applies an inplace sub on input x at index i with value v. Aliases x.\n\n  If i is None, x and v must be the same shape. Computes\n    x -= v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    x[i, :] -= v;\n  Otherwise, x and v must have the same rank. Computes\n    x[i, :] -= v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n\n  Returns:\n    Returns x.\n\n  \"\"\"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_sub)",
        "mutated": [
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_sub(x, i, v):\n    if False:\n        i = 10\n    \"Applies an inplace sub on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_sub)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace sub on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_sub)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace sub on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_sub)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace sub on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_sub)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef alias_inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace sub on input x at index i with value v. Aliases x.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    x -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    x[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    x[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns x.\\n\\n  \"\n    return _inplace_helper(x, i, v, gen_array_ops.inplace_sub)"
        ]
    },
    {
        "func_name": "empty_like",
        "original": "def empty_like(x, init=None):\n    \"\"\"Returns a non-initialized tensor with the same shape and dtype as x.\n\n  Args:\n    x: A Tensor.\n    init: Initialize the returned tensor with the default value of\n      x.dtype(), if True. Otherwise, do not initialize. Defaults to\n      None.\n\n  Returns:\n    A tensor y, whose dtype and shape are the same as those of x.\n    y is guaranteed not to be an alias of x. Upon return, y may contain\n    arbitrary data.\n\n  \"\"\"\n    x = ops.convert_to_tensor(x)\n    return gen_array_ops.empty(array_ops.shape(x), x.dtype, init=init)",
        "mutated": [
            "def empty_like(x, init=None):\n    if False:\n        i = 10\n    'Returns a non-initialized tensor with the same shape and dtype as x.\\n\\n  Args:\\n    x: A Tensor.\\n    init: Initialize the returned tensor with the default value of\\n      x.dtype(), if True. Otherwise, do not initialize. Defaults to\\n      None.\\n\\n  Returns:\\n    A tensor y, whose dtype and shape are the same as those of x.\\n    y is guaranteed not to be an alias of x. Upon return, y may contain\\n    arbitrary data.\\n\\n  '\n    x = ops.convert_to_tensor(x)\n    return gen_array_ops.empty(array_ops.shape(x), x.dtype, init=init)",
            "def empty_like(x, init=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns a non-initialized tensor with the same shape and dtype as x.\\n\\n  Args:\\n    x: A Tensor.\\n    init: Initialize the returned tensor with the default value of\\n      x.dtype(), if True. Otherwise, do not initialize. Defaults to\\n      None.\\n\\n  Returns:\\n    A tensor y, whose dtype and shape are the same as those of x.\\n    y is guaranteed not to be an alias of x. Upon return, y may contain\\n    arbitrary data.\\n\\n  '\n    x = ops.convert_to_tensor(x)\n    return gen_array_ops.empty(array_ops.shape(x), x.dtype, init=init)",
            "def empty_like(x, init=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns a non-initialized tensor with the same shape and dtype as x.\\n\\n  Args:\\n    x: A Tensor.\\n    init: Initialize the returned tensor with the default value of\\n      x.dtype(), if True. Otherwise, do not initialize. Defaults to\\n      None.\\n\\n  Returns:\\n    A tensor y, whose dtype and shape are the same as those of x.\\n    y is guaranteed not to be an alias of x. Upon return, y may contain\\n    arbitrary data.\\n\\n  '\n    x = ops.convert_to_tensor(x)\n    return gen_array_ops.empty(array_ops.shape(x), x.dtype, init=init)",
            "def empty_like(x, init=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns a non-initialized tensor with the same shape and dtype as x.\\n\\n  Args:\\n    x: A Tensor.\\n    init: Initialize the returned tensor with the default value of\\n      x.dtype(), if True. Otherwise, do not initialize. Defaults to\\n      None.\\n\\n  Returns:\\n    A tensor y, whose dtype and shape are the same as those of x.\\n    y is guaranteed not to be an alias of x. Upon return, y may contain\\n    arbitrary data.\\n\\n  '\n    x = ops.convert_to_tensor(x)\n    return gen_array_ops.empty(array_ops.shape(x), x.dtype, init=init)",
            "def empty_like(x, init=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns a non-initialized tensor with the same shape and dtype as x.\\n\\n  Args:\\n    x: A Tensor.\\n    init: Initialize the returned tensor with the default value of\\n      x.dtype(), if True. Otherwise, do not initialize. Defaults to\\n      None.\\n\\n  Returns:\\n    A tensor y, whose dtype and shape are the same as those of x.\\n    y is guaranteed not to be an alias of x. Upon return, y may contain\\n    arbitrary data.\\n\\n  '\n    x = ops.convert_to_tensor(x)\n    return gen_array_ops.empty(array_ops.shape(x), x.dtype, init=init)"
        ]
    },
    {
        "func_name": "inplace_update",
        "original": "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_update(x, i, v):\n    \"\"\"Applies an inplace update on input x at index i with value v.\n\n  Note that this function is not actually inplace - it allocates\n  a copy of x.  The utility is not avoiding memory copies but rather\n  specifying a sparse update.\n\n  If i is None, x and v must be the same shape. Computes\n    y = x; y = v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    y = x; y[i, :] = v;\n  Otherwise, x and v must have the same rank. Computes\n    y = x; y[i, :] = v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n\n  Returns:\n    Returns y, which is guaranteed not to be an alias of x.\n\n  \"\"\"\n    return alias_inplace_update(gen_array_ops.deep_copy(x), i, v)",
        "mutated": [
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_update(x, i, v):\n    if False:\n        i = 10\n    \"Applies an inplace update on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_update(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace update on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_update(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace update on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_update(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace update on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_update(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_update(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace update on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y = v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] = v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] = v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_update(gen_array_ops.deep_copy(x), i, v)"
        ]
    },
    {
        "func_name": "inplace_add",
        "original": "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_add(x, i, v):\n    \"\"\"Applies an inplace add on input x at index i with value v.\n\n  Note that this function is not actually inplace - it allocates\n  a copy of x.  The utility is not avoiding memory copies but rather\n  specifying a sparse update.\n\n  If i is None, x and v must be the same shape. Computes\n    y = x; y += v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    y = x; y[i, :] += v;\n  Otherwise, x and v must have the same rank. Computes\n    y = x; y[i, :] += v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n\n  Returns:\n    Returns y, which is guaranteed not to be an alias of x.\n\n  \"\"\"\n    return alias_inplace_add(gen_array_ops.deep_copy(x), i, v)",
        "mutated": [
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_add(x, i, v):\n    if False:\n        i = 10\n    \"Applies an inplace add on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_add(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace add on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_add(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace add on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_add(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace add on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_add(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_add(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace add on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y += v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] += v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] += v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_add(gen_array_ops.deep_copy(x), i, v)"
        ]
    },
    {
        "func_name": "inplace_sub",
        "original": "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_sub(x, i, v):\n    \"\"\"Applies an inplace sub on input x at index i with value v.\n\n  Note that this function is not actually inplace - it allocates\n  a copy of x.  The utility is not avoiding memory copies but rather\n  specifying a sparse update.\n\n  If i is None, x and v must be the same shape. Computes\n    y = x; y -= v;\n  If i is a scalar, x has a rank 1 higher than v's. Computes\n    y = x; y[i, :] -= v;\n  Otherwise, x and v must have the same rank. Computes\n    y = x; y[i, :] -= v;\n\n  Args:\n    x: A Tensor.\n    i: None, a scalar or a vector.\n    v: A Tensor.\n\n  Returns:\n    Returns y, which is guaranteed not to be an alias of x.\n\n  \"\"\"\n    return alias_inplace_sub(gen_array_ops.deep_copy(x), i, v)",
        "mutated": [
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_sub(x, i, v):\n    if False:\n        i = 10\n    \"Applies an inplace sub on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_sub(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Applies an inplace sub on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_sub(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Applies an inplace sub on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_sub(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Applies an inplace sub on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_sub(gen_array_ops.deep_copy(x), i, v)",
            "@deprecation.deprecated(None, 'Prefer tf.tensor_scatter_nd_sub, which offers the same functionality with well-defined read-write semantics.')\ndef inplace_sub(x, i, v):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Applies an inplace sub on input x at index i with value v.\\n\\n  Note that this function is not actually inplace - it allocates\\n  a copy of x.  The utility is not avoiding memory copies but rather\\n  specifying a sparse update.\\n\\n  If i is None, x and v must be the same shape. Computes\\n    y = x; y -= v;\\n  If i is a scalar, x has a rank 1 higher than v's. Computes\\n    y = x; y[i, :] -= v;\\n  Otherwise, x and v must have the same rank. Computes\\n    y = x; y[i, :] -= v;\\n\\n  Args:\\n    x: A Tensor.\\n    i: None, a scalar or a vector.\\n    v: A Tensor.\\n\\n  Returns:\\n    Returns y, which is guaranteed not to be an alias of x.\\n\\n  \"\n    return alias_inplace_sub(gen_array_ops.deep_copy(x), i, v)"
        ]
    }
]