[
    {
        "func_name": "create_lyft_infos",
        "original": "def create_lyft_infos(root_path, info_prefix, version='v1.01-train', max_sweeps=10):\n    \"\"\"Create info file of lyft dataset.\n\n    Given the raw data, generate its related info file in pkl format.\n\n    Args:\n        root_path (str): Path of the data root.\n        info_prefix (str): Prefix of the info file to be generated.\n        version (str, optional): Version of the data.\n            Default: 'v1.01-train'.\n        max_sweeps (int, optional): Max number of sweeps.\n            Default: 10.\n    \"\"\"\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    available_vers = ['v1.01-train', 'v1.01-test']\n    assert version in available_vers\n    if version == 'v1.01-train':\n        train_scenes = mmcv.list_from_file('data/lyft/train.txt')\n        val_scenes = mmcv.list_from_file('data/lyft/val.txt')\n    elif version == 'v1.01-test':\n        train_scenes = mmcv.list_from_file('data/lyft/test.txt')\n        val_scenes = []\n    else:\n        raise ValueError('unknown')\n    available_scenes = get_available_scenes(lyft)\n    available_scene_names = [s['name'] for s in available_scenes]\n    train_scenes = list(filter(lambda x: x in available_scene_names, train_scenes))\n    val_scenes = list(filter(lambda x: x in available_scene_names, val_scenes))\n    train_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in train_scenes])\n    val_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in val_scenes])\n    test = 'test' in version\n    if test:\n        print(f'test scene: {len(train_scenes)}')\n    else:\n        print(f'train scene: {len(train_scenes)},                 val scene: {len(val_scenes)}')\n    (train_lyft_infos, val_lyft_infos) = _fill_trainval_infos(lyft, train_scenes, val_scenes, test, max_sweeps=max_sweeps)\n    metadata = dict(version=version)\n    if test:\n        print(f'test sample: {len(train_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        info_name = f'{info_prefix}_infos_test'\n        info_path = osp.join(root_path, f'{info_name}.pkl')\n        mmcv.dump(data, info_path)\n    else:\n        print(f'train sample: {len(train_lyft_infos)},                 val sample: {len(val_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        train_info_name = f'{info_prefix}_infos_train'\n        info_path = osp.join(root_path, f'{train_info_name}.pkl')\n        mmcv.dump(data, info_path)\n        data['infos'] = val_lyft_infos\n        val_info_name = f'{info_prefix}_infos_val'\n        info_val_path = osp.join(root_path, f'{val_info_name}.pkl')\n        mmcv.dump(data, info_val_path)",
        "mutated": [
            "def create_lyft_infos(root_path, info_prefix, version='v1.01-train', max_sweeps=10):\n    if False:\n        i = 10\n    \"Create info file of lyft dataset.\\n\\n    Given the raw data, generate its related info file in pkl format.\\n\\n    Args:\\n        root_path (str): Path of the data root.\\n        info_prefix (str): Prefix of the info file to be generated.\\n        version (str, optional): Version of the data.\\n            Default: 'v1.01-train'.\\n        max_sweeps (int, optional): Max number of sweeps.\\n            Default: 10.\\n    \"\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    available_vers = ['v1.01-train', 'v1.01-test']\n    assert version in available_vers\n    if version == 'v1.01-train':\n        train_scenes = mmcv.list_from_file('data/lyft/train.txt')\n        val_scenes = mmcv.list_from_file('data/lyft/val.txt')\n    elif version == 'v1.01-test':\n        train_scenes = mmcv.list_from_file('data/lyft/test.txt')\n        val_scenes = []\n    else:\n        raise ValueError('unknown')\n    available_scenes = get_available_scenes(lyft)\n    available_scene_names = [s['name'] for s in available_scenes]\n    train_scenes = list(filter(lambda x: x in available_scene_names, train_scenes))\n    val_scenes = list(filter(lambda x: x in available_scene_names, val_scenes))\n    train_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in train_scenes])\n    val_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in val_scenes])\n    test = 'test' in version\n    if test:\n        print(f'test scene: {len(train_scenes)}')\n    else:\n        print(f'train scene: {len(train_scenes)},                 val scene: {len(val_scenes)}')\n    (train_lyft_infos, val_lyft_infos) = _fill_trainval_infos(lyft, train_scenes, val_scenes, test, max_sweeps=max_sweeps)\n    metadata = dict(version=version)\n    if test:\n        print(f'test sample: {len(train_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        info_name = f'{info_prefix}_infos_test'\n        info_path = osp.join(root_path, f'{info_name}.pkl')\n        mmcv.dump(data, info_path)\n    else:\n        print(f'train sample: {len(train_lyft_infos)},                 val sample: {len(val_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        train_info_name = f'{info_prefix}_infos_train'\n        info_path = osp.join(root_path, f'{train_info_name}.pkl')\n        mmcv.dump(data, info_path)\n        data['infos'] = val_lyft_infos\n        val_info_name = f'{info_prefix}_infos_val'\n        info_val_path = osp.join(root_path, f'{val_info_name}.pkl')\n        mmcv.dump(data, info_val_path)",
            "def create_lyft_infos(root_path, info_prefix, version='v1.01-train', max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Create info file of lyft dataset.\\n\\n    Given the raw data, generate its related info file in pkl format.\\n\\n    Args:\\n        root_path (str): Path of the data root.\\n        info_prefix (str): Prefix of the info file to be generated.\\n        version (str, optional): Version of the data.\\n            Default: 'v1.01-train'.\\n        max_sweeps (int, optional): Max number of sweeps.\\n            Default: 10.\\n    \"\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    available_vers = ['v1.01-train', 'v1.01-test']\n    assert version in available_vers\n    if version == 'v1.01-train':\n        train_scenes = mmcv.list_from_file('data/lyft/train.txt')\n        val_scenes = mmcv.list_from_file('data/lyft/val.txt')\n    elif version == 'v1.01-test':\n        train_scenes = mmcv.list_from_file('data/lyft/test.txt')\n        val_scenes = []\n    else:\n        raise ValueError('unknown')\n    available_scenes = get_available_scenes(lyft)\n    available_scene_names = [s['name'] for s in available_scenes]\n    train_scenes = list(filter(lambda x: x in available_scene_names, train_scenes))\n    val_scenes = list(filter(lambda x: x in available_scene_names, val_scenes))\n    train_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in train_scenes])\n    val_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in val_scenes])\n    test = 'test' in version\n    if test:\n        print(f'test scene: {len(train_scenes)}')\n    else:\n        print(f'train scene: {len(train_scenes)},                 val scene: {len(val_scenes)}')\n    (train_lyft_infos, val_lyft_infos) = _fill_trainval_infos(lyft, train_scenes, val_scenes, test, max_sweeps=max_sweeps)\n    metadata = dict(version=version)\n    if test:\n        print(f'test sample: {len(train_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        info_name = f'{info_prefix}_infos_test'\n        info_path = osp.join(root_path, f'{info_name}.pkl')\n        mmcv.dump(data, info_path)\n    else:\n        print(f'train sample: {len(train_lyft_infos)},                 val sample: {len(val_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        train_info_name = f'{info_prefix}_infos_train'\n        info_path = osp.join(root_path, f'{train_info_name}.pkl')\n        mmcv.dump(data, info_path)\n        data['infos'] = val_lyft_infos\n        val_info_name = f'{info_prefix}_infos_val'\n        info_val_path = osp.join(root_path, f'{val_info_name}.pkl')\n        mmcv.dump(data, info_val_path)",
            "def create_lyft_infos(root_path, info_prefix, version='v1.01-train', max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Create info file of lyft dataset.\\n\\n    Given the raw data, generate its related info file in pkl format.\\n\\n    Args:\\n        root_path (str): Path of the data root.\\n        info_prefix (str): Prefix of the info file to be generated.\\n        version (str, optional): Version of the data.\\n            Default: 'v1.01-train'.\\n        max_sweeps (int, optional): Max number of sweeps.\\n            Default: 10.\\n    \"\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    available_vers = ['v1.01-train', 'v1.01-test']\n    assert version in available_vers\n    if version == 'v1.01-train':\n        train_scenes = mmcv.list_from_file('data/lyft/train.txt')\n        val_scenes = mmcv.list_from_file('data/lyft/val.txt')\n    elif version == 'v1.01-test':\n        train_scenes = mmcv.list_from_file('data/lyft/test.txt')\n        val_scenes = []\n    else:\n        raise ValueError('unknown')\n    available_scenes = get_available_scenes(lyft)\n    available_scene_names = [s['name'] for s in available_scenes]\n    train_scenes = list(filter(lambda x: x in available_scene_names, train_scenes))\n    val_scenes = list(filter(lambda x: x in available_scene_names, val_scenes))\n    train_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in train_scenes])\n    val_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in val_scenes])\n    test = 'test' in version\n    if test:\n        print(f'test scene: {len(train_scenes)}')\n    else:\n        print(f'train scene: {len(train_scenes)},                 val scene: {len(val_scenes)}')\n    (train_lyft_infos, val_lyft_infos) = _fill_trainval_infos(lyft, train_scenes, val_scenes, test, max_sweeps=max_sweeps)\n    metadata = dict(version=version)\n    if test:\n        print(f'test sample: {len(train_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        info_name = f'{info_prefix}_infos_test'\n        info_path = osp.join(root_path, f'{info_name}.pkl')\n        mmcv.dump(data, info_path)\n    else:\n        print(f'train sample: {len(train_lyft_infos)},                 val sample: {len(val_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        train_info_name = f'{info_prefix}_infos_train'\n        info_path = osp.join(root_path, f'{train_info_name}.pkl')\n        mmcv.dump(data, info_path)\n        data['infos'] = val_lyft_infos\n        val_info_name = f'{info_prefix}_infos_val'\n        info_val_path = osp.join(root_path, f'{val_info_name}.pkl')\n        mmcv.dump(data, info_val_path)",
            "def create_lyft_infos(root_path, info_prefix, version='v1.01-train', max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Create info file of lyft dataset.\\n\\n    Given the raw data, generate its related info file in pkl format.\\n\\n    Args:\\n        root_path (str): Path of the data root.\\n        info_prefix (str): Prefix of the info file to be generated.\\n        version (str, optional): Version of the data.\\n            Default: 'v1.01-train'.\\n        max_sweeps (int, optional): Max number of sweeps.\\n            Default: 10.\\n    \"\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    available_vers = ['v1.01-train', 'v1.01-test']\n    assert version in available_vers\n    if version == 'v1.01-train':\n        train_scenes = mmcv.list_from_file('data/lyft/train.txt')\n        val_scenes = mmcv.list_from_file('data/lyft/val.txt')\n    elif version == 'v1.01-test':\n        train_scenes = mmcv.list_from_file('data/lyft/test.txt')\n        val_scenes = []\n    else:\n        raise ValueError('unknown')\n    available_scenes = get_available_scenes(lyft)\n    available_scene_names = [s['name'] for s in available_scenes]\n    train_scenes = list(filter(lambda x: x in available_scene_names, train_scenes))\n    val_scenes = list(filter(lambda x: x in available_scene_names, val_scenes))\n    train_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in train_scenes])\n    val_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in val_scenes])\n    test = 'test' in version\n    if test:\n        print(f'test scene: {len(train_scenes)}')\n    else:\n        print(f'train scene: {len(train_scenes)},                 val scene: {len(val_scenes)}')\n    (train_lyft_infos, val_lyft_infos) = _fill_trainval_infos(lyft, train_scenes, val_scenes, test, max_sweeps=max_sweeps)\n    metadata = dict(version=version)\n    if test:\n        print(f'test sample: {len(train_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        info_name = f'{info_prefix}_infos_test'\n        info_path = osp.join(root_path, f'{info_name}.pkl')\n        mmcv.dump(data, info_path)\n    else:\n        print(f'train sample: {len(train_lyft_infos)},                 val sample: {len(val_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        train_info_name = f'{info_prefix}_infos_train'\n        info_path = osp.join(root_path, f'{train_info_name}.pkl')\n        mmcv.dump(data, info_path)\n        data['infos'] = val_lyft_infos\n        val_info_name = f'{info_prefix}_infos_val'\n        info_val_path = osp.join(root_path, f'{val_info_name}.pkl')\n        mmcv.dump(data, info_val_path)",
            "def create_lyft_infos(root_path, info_prefix, version='v1.01-train', max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Create info file of lyft dataset.\\n\\n    Given the raw data, generate its related info file in pkl format.\\n\\n    Args:\\n        root_path (str): Path of the data root.\\n        info_prefix (str): Prefix of the info file to be generated.\\n        version (str, optional): Version of the data.\\n            Default: 'v1.01-train'.\\n        max_sweeps (int, optional): Max number of sweeps.\\n            Default: 10.\\n    \"\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    available_vers = ['v1.01-train', 'v1.01-test']\n    assert version in available_vers\n    if version == 'v1.01-train':\n        train_scenes = mmcv.list_from_file('data/lyft/train.txt')\n        val_scenes = mmcv.list_from_file('data/lyft/val.txt')\n    elif version == 'v1.01-test':\n        train_scenes = mmcv.list_from_file('data/lyft/test.txt')\n        val_scenes = []\n    else:\n        raise ValueError('unknown')\n    available_scenes = get_available_scenes(lyft)\n    available_scene_names = [s['name'] for s in available_scenes]\n    train_scenes = list(filter(lambda x: x in available_scene_names, train_scenes))\n    val_scenes = list(filter(lambda x: x in available_scene_names, val_scenes))\n    train_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in train_scenes])\n    val_scenes = set([available_scenes[available_scene_names.index(s)]['token'] for s in val_scenes])\n    test = 'test' in version\n    if test:\n        print(f'test scene: {len(train_scenes)}')\n    else:\n        print(f'train scene: {len(train_scenes)},                 val scene: {len(val_scenes)}')\n    (train_lyft_infos, val_lyft_infos) = _fill_trainval_infos(lyft, train_scenes, val_scenes, test, max_sweeps=max_sweeps)\n    metadata = dict(version=version)\n    if test:\n        print(f'test sample: {len(train_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        info_name = f'{info_prefix}_infos_test'\n        info_path = osp.join(root_path, f'{info_name}.pkl')\n        mmcv.dump(data, info_path)\n    else:\n        print(f'train sample: {len(train_lyft_infos)},                 val sample: {len(val_lyft_infos)}')\n        data = dict(infos=train_lyft_infos, metadata=metadata)\n        train_info_name = f'{info_prefix}_infos_train'\n        info_path = osp.join(root_path, f'{train_info_name}.pkl')\n        mmcv.dump(data, info_path)\n        data['infos'] = val_lyft_infos\n        val_info_name = f'{info_prefix}_infos_val'\n        info_val_path = osp.join(root_path, f'{val_info_name}.pkl')\n        mmcv.dump(data, info_val_path)"
        ]
    },
    {
        "func_name": "_fill_trainval_infos",
        "original": "def _fill_trainval_infos(lyft, train_scenes, val_scenes, test=False, max_sweeps=10):\n    \"\"\"Generate the train/val infos from the raw data.\n\n    Args:\n        lyft (:obj:`LyftDataset`): Dataset class in the Lyft dataset.\n        train_scenes (list[str]): Basic information of training scenes.\n        val_scenes (list[str]): Basic information of validation scenes.\n        test (bool, optional): Whether use the test mode. In the test mode, no\n            annotations can be accessed. Default: False.\n        max_sweeps (int, optional): Max number of sweeps. Default: 10.\n\n    Returns:\n        tuple[list[dict]]: Information of training set and\n            validation set that will be saved to the info file.\n    \"\"\"\n    train_lyft_infos = []\n    val_lyft_infos = []\n    for sample in mmcv.track_iter_progress(lyft.sample):\n        lidar_token = sample['data']['LIDAR_TOP']\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        cs_record = lyft.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n        pose_record = lyft.get('ego_pose', sd_rec['ego_pose_token'])\n        (abs_lidar_path, boxes, _) = lyft.get_sample_data(lidar_token)\n        abs_lidar_path = str(abs_lidar_path)\n        lidar_path = abs_lidar_path.split(f'{os.getcwd()}/')[-1]\n        mmcv.check_file_exist(lidar_path)\n        info = {'lidar_path': lidar_path, 'token': sample['token'], 'sweeps': [], 'cams': dict(), 'lidar2ego_translation': cs_record['translation'], 'lidar2ego_rotation': cs_record['rotation'], 'ego2global_translation': pose_record['translation'], 'ego2global_rotation': pose_record['rotation'], 'timestamp': sample['timestamp']}\n        l2e_r = info['lidar2ego_rotation']\n        l2e_t = info['lidar2ego_translation']\n        e2g_r = info['ego2global_rotation']\n        e2g_t = info['ego2global_translation']\n        l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n        e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n        camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n        for cam in camera_types:\n            cam_token = sample['data'][cam]\n            (cam_path, _, cam_intrinsic) = lyft.get_sample_data(cam_token)\n            cam_info = obtain_sensor2top(lyft, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam)\n            cam_info.update(cam_intrinsic=cam_intrinsic)\n            info['cams'].update({cam: cam_info})\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        sweeps = []\n        while len(sweeps) < max_sweeps:\n            if not sd_rec['prev'] == '':\n                sweep = obtain_sensor2top(lyft, sd_rec['prev'], l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, 'lidar')\n                sweeps.append(sweep)\n                sd_rec = lyft.get('sample_data', sd_rec['prev'])\n            else:\n                break\n        info['sweeps'] = sweeps\n        if not test:\n            annotations = [lyft.get('sample_annotation', token) for token in sample['anns']]\n            locs = np.array([b.center for b in boxes]).reshape(-1, 3)\n            dims = np.array([b.wlh for b in boxes]).reshape(-1, 3)\n            rots = np.array([b.orientation.yaw_pitch_roll[0] for b in boxes]).reshape(-1, 1)\n            names = [b.name for b in boxes]\n            for i in range(len(names)):\n                if names[i] in LyftDataset.NameMapping:\n                    names[i] = LyftDataset.NameMapping[names[i]]\n            names = np.array(names)\n            gt_boxes = np.concatenate([locs, dims[:, [1, 0, 2]], rots], axis=1)\n            assert len(gt_boxes) == len(annotations), f'{len(gt_boxes)}, {len(annotations)}'\n            info['gt_boxes'] = gt_boxes\n            info['gt_names'] = names\n            info['num_lidar_pts'] = np.array([a['num_lidar_pts'] for a in annotations])\n            info['num_radar_pts'] = np.array([a['num_radar_pts'] for a in annotations])\n        if sample['scene_token'] in train_scenes:\n            train_lyft_infos.append(info)\n        else:\n            val_lyft_infos.append(info)\n    return (train_lyft_infos, val_lyft_infos)",
        "mutated": [
            "def _fill_trainval_infos(lyft, train_scenes, val_scenes, test=False, max_sweeps=10):\n    if False:\n        i = 10\n    'Generate the train/val infos from the raw data.\\n\\n    Args:\\n        lyft (:obj:`LyftDataset`): Dataset class in the Lyft dataset.\\n        train_scenes (list[str]): Basic information of training scenes.\\n        val_scenes (list[str]): Basic information of validation scenes.\\n        test (bool, optional): Whether use the test mode. In the test mode, no\\n            annotations can be accessed. Default: False.\\n        max_sweeps (int, optional): Max number of sweeps. Default: 10.\\n\\n    Returns:\\n        tuple[list[dict]]: Information of training set and\\n            validation set that will be saved to the info file.\\n    '\n    train_lyft_infos = []\n    val_lyft_infos = []\n    for sample in mmcv.track_iter_progress(lyft.sample):\n        lidar_token = sample['data']['LIDAR_TOP']\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        cs_record = lyft.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n        pose_record = lyft.get('ego_pose', sd_rec['ego_pose_token'])\n        (abs_lidar_path, boxes, _) = lyft.get_sample_data(lidar_token)\n        abs_lidar_path = str(abs_lidar_path)\n        lidar_path = abs_lidar_path.split(f'{os.getcwd()}/')[-1]\n        mmcv.check_file_exist(lidar_path)\n        info = {'lidar_path': lidar_path, 'token': sample['token'], 'sweeps': [], 'cams': dict(), 'lidar2ego_translation': cs_record['translation'], 'lidar2ego_rotation': cs_record['rotation'], 'ego2global_translation': pose_record['translation'], 'ego2global_rotation': pose_record['rotation'], 'timestamp': sample['timestamp']}\n        l2e_r = info['lidar2ego_rotation']\n        l2e_t = info['lidar2ego_translation']\n        e2g_r = info['ego2global_rotation']\n        e2g_t = info['ego2global_translation']\n        l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n        e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n        camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n        for cam in camera_types:\n            cam_token = sample['data'][cam]\n            (cam_path, _, cam_intrinsic) = lyft.get_sample_data(cam_token)\n            cam_info = obtain_sensor2top(lyft, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam)\n            cam_info.update(cam_intrinsic=cam_intrinsic)\n            info['cams'].update({cam: cam_info})\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        sweeps = []\n        while len(sweeps) < max_sweeps:\n            if not sd_rec['prev'] == '':\n                sweep = obtain_sensor2top(lyft, sd_rec['prev'], l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, 'lidar')\n                sweeps.append(sweep)\n                sd_rec = lyft.get('sample_data', sd_rec['prev'])\n            else:\n                break\n        info['sweeps'] = sweeps\n        if not test:\n            annotations = [lyft.get('sample_annotation', token) for token in sample['anns']]\n            locs = np.array([b.center for b in boxes]).reshape(-1, 3)\n            dims = np.array([b.wlh for b in boxes]).reshape(-1, 3)\n            rots = np.array([b.orientation.yaw_pitch_roll[0] for b in boxes]).reshape(-1, 1)\n            names = [b.name for b in boxes]\n            for i in range(len(names)):\n                if names[i] in LyftDataset.NameMapping:\n                    names[i] = LyftDataset.NameMapping[names[i]]\n            names = np.array(names)\n            gt_boxes = np.concatenate([locs, dims[:, [1, 0, 2]], rots], axis=1)\n            assert len(gt_boxes) == len(annotations), f'{len(gt_boxes)}, {len(annotations)}'\n            info['gt_boxes'] = gt_boxes\n            info['gt_names'] = names\n            info['num_lidar_pts'] = np.array([a['num_lidar_pts'] for a in annotations])\n            info['num_radar_pts'] = np.array([a['num_radar_pts'] for a in annotations])\n        if sample['scene_token'] in train_scenes:\n            train_lyft_infos.append(info)\n        else:\n            val_lyft_infos.append(info)\n    return (train_lyft_infos, val_lyft_infos)",
            "def _fill_trainval_infos(lyft, train_scenes, val_scenes, test=False, max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate the train/val infos from the raw data.\\n\\n    Args:\\n        lyft (:obj:`LyftDataset`): Dataset class in the Lyft dataset.\\n        train_scenes (list[str]): Basic information of training scenes.\\n        val_scenes (list[str]): Basic information of validation scenes.\\n        test (bool, optional): Whether use the test mode. In the test mode, no\\n            annotations can be accessed. Default: False.\\n        max_sweeps (int, optional): Max number of sweeps. Default: 10.\\n\\n    Returns:\\n        tuple[list[dict]]: Information of training set and\\n            validation set that will be saved to the info file.\\n    '\n    train_lyft_infos = []\n    val_lyft_infos = []\n    for sample in mmcv.track_iter_progress(lyft.sample):\n        lidar_token = sample['data']['LIDAR_TOP']\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        cs_record = lyft.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n        pose_record = lyft.get('ego_pose', sd_rec['ego_pose_token'])\n        (abs_lidar_path, boxes, _) = lyft.get_sample_data(lidar_token)\n        abs_lidar_path = str(abs_lidar_path)\n        lidar_path = abs_lidar_path.split(f'{os.getcwd()}/')[-1]\n        mmcv.check_file_exist(lidar_path)\n        info = {'lidar_path': lidar_path, 'token': sample['token'], 'sweeps': [], 'cams': dict(), 'lidar2ego_translation': cs_record['translation'], 'lidar2ego_rotation': cs_record['rotation'], 'ego2global_translation': pose_record['translation'], 'ego2global_rotation': pose_record['rotation'], 'timestamp': sample['timestamp']}\n        l2e_r = info['lidar2ego_rotation']\n        l2e_t = info['lidar2ego_translation']\n        e2g_r = info['ego2global_rotation']\n        e2g_t = info['ego2global_translation']\n        l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n        e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n        camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n        for cam in camera_types:\n            cam_token = sample['data'][cam]\n            (cam_path, _, cam_intrinsic) = lyft.get_sample_data(cam_token)\n            cam_info = obtain_sensor2top(lyft, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam)\n            cam_info.update(cam_intrinsic=cam_intrinsic)\n            info['cams'].update({cam: cam_info})\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        sweeps = []\n        while len(sweeps) < max_sweeps:\n            if not sd_rec['prev'] == '':\n                sweep = obtain_sensor2top(lyft, sd_rec['prev'], l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, 'lidar')\n                sweeps.append(sweep)\n                sd_rec = lyft.get('sample_data', sd_rec['prev'])\n            else:\n                break\n        info['sweeps'] = sweeps\n        if not test:\n            annotations = [lyft.get('sample_annotation', token) for token in sample['anns']]\n            locs = np.array([b.center for b in boxes]).reshape(-1, 3)\n            dims = np.array([b.wlh for b in boxes]).reshape(-1, 3)\n            rots = np.array([b.orientation.yaw_pitch_roll[0] for b in boxes]).reshape(-1, 1)\n            names = [b.name for b in boxes]\n            for i in range(len(names)):\n                if names[i] in LyftDataset.NameMapping:\n                    names[i] = LyftDataset.NameMapping[names[i]]\n            names = np.array(names)\n            gt_boxes = np.concatenate([locs, dims[:, [1, 0, 2]], rots], axis=1)\n            assert len(gt_boxes) == len(annotations), f'{len(gt_boxes)}, {len(annotations)}'\n            info['gt_boxes'] = gt_boxes\n            info['gt_names'] = names\n            info['num_lidar_pts'] = np.array([a['num_lidar_pts'] for a in annotations])\n            info['num_radar_pts'] = np.array([a['num_radar_pts'] for a in annotations])\n        if sample['scene_token'] in train_scenes:\n            train_lyft_infos.append(info)\n        else:\n            val_lyft_infos.append(info)\n    return (train_lyft_infos, val_lyft_infos)",
            "def _fill_trainval_infos(lyft, train_scenes, val_scenes, test=False, max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate the train/val infos from the raw data.\\n\\n    Args:\\n        lyft (:obj:`LyftDataset`): Dataset class in the Lyft dataset.\\n        train_scenes (list[str]): Basic information of training scenes.\\n        val_scenes (list[str]): Basic information of validation scenes.\\n        test (bool, optional): Whether use the test mode. In the test mode, no\\n            annotations can be accessed. Default: False.\\n        max_sweeps (int, optional): Max number of sweeps. Default: 10.\\n\\n    Returns:\\n        tuple[list[dict]]: Information of training set and\\n            validation set that will be saved to the info file.\\n    '\n    train_lyft_infos = []\n    val_lyft_infos = []\n    for sample in mmcv.track_iter_progress(lyft.sample):\n        lidar_token = sample['data']['LIDAR_TOP']\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        cs_record = lyft.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n        pose_record = lyft.get('ego_pose', sd_rec['ego_pose_token'])\n        (abs_lidar_path, boxes, _) = lyft.get_sample_data(lidar_token)\n        abs_lidar_path = str(abs_lidar_path)\n        lidar_path = abs_lidar_path.split(f'{os.getcwd()}/')[-1]\n        mmcv.check_file_exist(lidar_path)\n        info = {'lidar_path': lidar_path, 'token': sample['token'], 'sweeps': [], 'cams': dict(), 'lidar2ego_translation': cs_record['translation'], 'lidar2ego_rotation': cs_record['rotation'], 'ego2global_translation': pose_record['translation'], 'ego2global_rotation': pose_record['rotation'], 'timestamp': sample['timestamp']}\n        l2e_r = info['lidar2ego_rotation']\n        l2e_t = info['lidar2ego_translation']\n        e2g_r = info['ego2global_rotation']\n        e2g_t = info['ego2global_translation']\n        l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n        e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n        camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n        for cam in camera_types:\n            cam_token = sample['data'][cam]\n            (cam_path, _, cam_intrinsic) = lyft.get_sample_data(cam_token)\n            cam_info = obtain_sensor2top(lyft, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam)\n            cam_info.update(cam_intrinsic=cam_intrinsic)\n            info['cams'].update({cam: cam_info})\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        sweeps = []\n        while len(sweeps) < max_sweeps:\n            if not sd_rec['prev'] == '':\n                sweep = obtain_sensor2top(lyft, sd_rec['prev'], l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, 'lidar')\n                sweeps.append(sweep)\n                sd_rec = lyft.get('sample_data', sd_rec['prev'])\n            else:\n                break\n        info['sweeps'] = sweeps\n        if not test:\n            annotations = [lyft.get('sample_annotation', token) for token in sample['anns']]\n            locs = np.array([b.center for b in boxes]).reshape(-1, 3)\n            dims = np.array([b.wlh for b in boxes]).reshape(-1, 3)\n            rots = np.array([b.orientation.yaw_pitch_roll[0] for b in boxes]).reshape(-1, 1)\n            names = [b.name for b in boxes]\n            for i in range(len(names)):\n                if names[i] in LyftDataset.NameMapping:\n                    names[i] = LyftDataset.NameMapping[names[i]]\n            names = np.array(names)\n            gt_boxes = np.concatenate([locs, dims[:, [1, 0, 2]], rots], axis=1)\n            assert len(gt_boxes) == len(annotations), f'{len(gt_boxes)}, {len(annotations)}'\n            info['gt_boxes'] = gt_boxes\n            info['gt_names'] = names\n            info['num_lidar_pts'] = np.array([a['num_lidar_pts'] for a in annotations])\n            info['num_radar_pts'] = np.array([a['num_radar_pts'] for a in annotations])\n        if sample['scene_token'] in train_scenes:\n            train_lyft_infos.append(info)\n        else:\n            val_lyft_infos.append(info)\n    return (train_lyft_infos, val_lyft_infos)",
            "def _fill_trainval_infos(lyft, train_scenes, val_scenes, test=False, max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate the train/val infos from the raw data.\\n\\n    Args:\\n        lyft (:obj:`LyftDataset`): Dataset class in the Lyft dataset.\\n        train_scenes (list[str]): Basic information of training scenes.\\n        val_scenes (list[str]): Basic information of validation scenes.\\n        test (bool, optional): Whether use the test mode. In the test mode, no\\n            annotations can be accessed. Default: False.\\n        max_sweeps (int, optional): Max number of sweeps. Default: 10.\\n\\n    Returns:\\n        tuple[list[dict]]: Information of training set and\\n            validation set that will be saved to the info file.\\n    '\n    train_lyft_infos = []\n    val_lyft_infos = []\n    for sample in mmcv.track_iter_progress(lyft.sample):\n        lidar_token = sample['data']['LIDAR_TOP']\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        cs_record = lyft.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n        pose_record = lyft.get('ego_pose', sd_rec['ego_pose_token'])\n        (abs_lidar_path, boxes, _) = lyft.get_sample_data(lidar_token)\n        abs_lidar_path = str(abs_lidar_path)\n        lidar_path = abs_lidar_path.split(f'{os.getcwd()}/')[-1]\n        mmcv.check_file_exist(lidar_path)\n        info = {'lidar_path': lidar_path, 'token': sample['token'], 'sweeps': [], 'cams': dict(), 'lidar2ego_translation': cs_record['translation'], 'lidar2ego_rotation': cs_record['rotation'], 'ego2global_translation': pose_record['translation'], 'ego2global_rotation': pose_record['rotation'], 'timestamp': sample['timestamp']}\n        l2e_r = info['lidar2ego_rotation']\n        l2e_t = info['lidar2ego_translation']\n        e2g_r = info['ego2global_rotation']\n        e2g_t = info['ego2global_translation']\n        l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n        e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n        camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n        for cam in camera_types:\n            cam_token = sample['data'][cam]\n            (cam_path, _, cam_intrinsic) = lyft.get_sample_data(cam_token)\n            cam_info = obtain_sensor2top(lyft, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam)\n            cam_info.update(cam_intrinsic=cam_intrinsic)\n            info['cams'].update({cam: cam_info})\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        sweeps = []\n        while len(sweeps) < max_sweeps:\n            if not sd_rec['prev'] == '':\n                sweep = obtain_sensor2top(lyft, sd_rec['prev'], l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, 'lidar')\n                sweeps.append(sweep)\n                sd_rec = lyft.get('sample_data', sd_rec['prev'])\n            else:\n                break\n        info['sweeps'] = sweeps\n        if not test:\n            annotations = [lyft.get('sample_annotation', token) for token in sample['anns']]\n            locs = np.array([b.center for b in boxes]).reshape(-1, 3)\n            dims = np.array([b.wlh for b in boxes]).reshape(-1, 3)\n            rots = np.array([b.orientation.yaw_pitch_roll[0] for b in boxes]).reshape(-1, 1)\n            names = [b.name for b in boxes]\n            for i in range(len(names)):\n                if names[i] in LyftDataset.NameMapping:\n                    names[i] = LyftDataset.NameMapping[names[i]]\n            names = np.array(names)\n            gt_boxes = np.concatenate([locs, dims[:, [1, 0, 2]], rots], axis=1)\n            assert len(gt_boxes) == len(annotations), f'{len(gt_boxes)}, {len(annotations)}'\n            info['gt_boxes'] = gt_boxes\n            info['gt_names'] = names\n            info['num_lidar_pts'] = np.array([a['num_lidar_pts'] for a in annotations])\n            info['num_radar_pts'] = np.array([a['num_radar_pts'] for a in annotations])\n        if sample['scene_token'] in train_scenes:\n            train_lyft_infos.append(info)\n        else:\n            val_lyft_infos.append(info)\n    return (train_lyft_infos, val_lyft_infos)",
            "def _fill_trainval_infos(lyft, train_scenes, val_scenes, test=False, max_sweeps=10):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate the train/val infos from the raw data.\\n\\n    Args:\\n        lyft (:obj:`LyftDataset`): Dataset class in the Lyft dataset.\\n        train_scenes (list[str]): Basic information of training scenes.\\n        val_scenes (list[str]): Basic information of validation scenes.\\n        test (bool, optional): Whether use the test mode. In the test mode, no\\n            annotations can be accessed. Default: False.\\n        max_sweeps (int, optional): Max number of sweeps. Default: 10.\\n\\n    Returns:\\n        tuple[list[dict]]: Information of training set and\\n            validation set that will be saved to the info file.\\n    '\n    train_lyft_infos = []\n    val_lyft_infos = []\n    for sample in mmcv.track_iter_progress(lyft.sample):\n        lidar_token = sample['data']['LIDAR_TOP']\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        cs_record = lyft.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n        pose_record = lyft.get('ego_pose', sd_rec['ego_pose_token'])\n        (abs_lidar_path, boxes, _) = lyft.get_sample_data(lidar_token)\n        abs_lidar_path = str(abs_lidar_path)\n        lidar_path = abs_lidar_path.split(f'{os.getcwd()}/')[-1]\n        mmcv.check_file_exist(lidar_path)\n        info = {'lidar_path': lidar_path, 'token': sample['token'], 'sweeps': [], 'cams': dict(), 'lidar2ego_translation': cs_record['translation'], 'lidar2ego_rotation': cs_record['rotation'], 'ego2global_translation': pose_record['translation'], 'ego2global_rotation': pose_record['rotation'], 'timestamp': sample['timestamp']}\n        l2e_r = info['lidar2ego_rotation']\n        l2e_t = info['lidar2ego_translation']\n        e2g_r = info['ego2global_rotation']\n        e2g_t = info['ego2global_translation']\n        l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n        e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n        camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n        for cam in camera_types:\n            cam_token = sample['data'][cam]\n            (cam_path, _, cam_intrinsic) = lyft.get_sample_data(cam_token)\n            cam_info = obtain_sensor2top(lyft, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam)\n            cam_info.update(cam_intrinsic=cam_intrinsic)\n            info['cams'].update({cam: cam_info})\n        sd_rec = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n        sweeps = []\n        while len(sweeps) < max_sweeps:\n            if not sd_rec['prev'] == '':\n                sweep = obtain_sensor2top(lyft, sd_rec['prev'], l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, 'lidar')\n                sweeps.append(sweep)\n                sd_rec = lyft.get('sample_data', sd_rec['prev'])\n            else:\n                break\n        info['sweeps'] = sweeps\n        if not test:\n            annotations = [lyft.get('sample_annotation', token) for token in sample['anns']]\n            locs = np.array([b.center for b in boxes]).reshape(-1, 3)\n            dims = np.array([b.wlh for b in boxes]).reshape(-1, 3)\n            rots = np.array([b.orientation.yaw_pitch_roll[0] for b in boxes]).reshape(-1, 1)\n            names = [b.name for b in boxes]\n            for i in range(len(names)):\n                if names[i] in LyftDataset.NameMapping:\n                    names[i] = LyftDataset.NameMapping[names[i]]\n            names = np.array(names)\n            gt_boxes = np.concatenate([locs, dims[:, [1, 0, 2]], rots], axis=1)\n            assert len(gt_boxes) == len(annotations), f'{len(gt_boxes)}, {len(annotations)}'\n            info['gt_boxes'] = gt_boxes\n            info['gt_names'] = names\n            info['num_lidar_pts'] = np.array([a['num_lidar_pts'] for a in annotations])\n            info['num_radar_pts'] = np.array([a['num_radar_pts'] for a in annotations])\n        if sample['scene_token'] in train_scenes:\n            train_lyft_infos.append(info)\n        else:\n            val_lyft_infos.append(info)\n    return (train_lyft_infos, val_lyft_infos)"
        ]
    },
    {
        "func_name": "export_2d_annotation",
        "original": "def export_2d_annotation(root_path, info_path, version):\n    \"\"\"Export 2d annotation from the info file and raw data.\n\n    Args:\n        root_path (str): Root path of the raw data.\n        info_path (str): Path of the info file.\n        version (str): Dataset version.\n    \"\"\"\n    warning.warn('DeprecationWarning: 2D annotations are not used on the Lyft dataset. The function export_2d_annotation will be deprecated.')\n    camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n    lyft_infos = mmcv.load(info_path)['infos']\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    cat2Ids = [dict(id=lyft_categories.index(cat_name), name=cat_name) for cat_name in lyft_categories]\n    coco_ann_id = 0\n    coco_2d_dict = dict(annotations=[], images=[], categories=cat2Ids)\n    for info in mmcv.track_iter_progress(lyft_infos):\n        for cam in camera_types:\n            cam_info = info['cams'][cam]\n            coco_infos = get_2d_boxes(lyft, cam_info['sample_data_token'], visibilities=['', '1', '2', '3', '4'])\n            (height, width, _) = mmcv.imread(cam_info['data_path']).shape\n            coco_2d_dict['images'].append(dict(file_name=cam_info['data_path'], id=cam_info['sample_data_token'], width=width, height=height))\n            for coco_info in coco_infos:\n                if coco_info is None:\n                    continue\n                coco_info['segmentation'] = []\n                coco_info['id'] = coco_ann_id\n                coco_2d_dict['annotations'].append(coco_info)\n                coco_ann_id += 1\n    mmcv.dump(coco_2d_dict, f'{info_path[:-4]}.coco.json')",
        "mutated": [
            "def export_2d_annotation(root_path, info_path, version):\n    if False:\n        i = 10\n    'Export 2d annotation from the info file and raw data.\\n\\n    Args:\\n        root_path (str): Root path of the raw data.\\n        info_path (str): Path of the info file.\\n        version (str): Dataset version.\\n    '\n    warning.warn('DeprecationWarning: 2D annotations are not used on the Lyft dataset. The function export_2d_annotation will be deprecated.')\n    camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n    lyft_infos = mmcv.load(info_path)['infos']\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    cat2Ids = [dict(id=lyft_categories.index(cat_name), name=cat_name) for cat_name in lyft_categories]\n    coco_ann_id = 0\n    coco_2d_dict = dict(annotations=[], images=[], categories=cat2Ids)\n    for info in mmcv.track_iter_progress(lyft_infos):\n        for cam in camera_types:\n            cam_info = info['cams'][cam]\n            coco_infos = get_2d_boxes(lyft, cam_info['sample_data_token'], visibilities=['', '1', '2', '3', '4'])\n            (height, width, _) = mmcv.imread(cam_info['data_path']).shape\n            coco_2d_dict['images'].append(dict(file_name=cam_info['data_path'], id=cam_info['sample_data_token'], width=width, height=height))\n            for coco_info in coco_infos:\n                if coco_info is None:\n                    continue\n                coco_info['segmentation'] = []\n                coco_info['id'] = coco_ann_id\n                coco_2d_dict['annotations'].append(coco_info)\n                coco_ann_id += 1\n    mmcv.dump(coco_2d_dict, f'{info_path[:-4]}.coco.json')",
            "def export_2d_annotation(root_path, info_path, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Export 2d annotation from the info file and raw data.\\n\\n    Args:\\n        root_path (str): Root path of the raw data.\\n        info_path (str): Path of the info file.\\n        version (str): Dataset version.\\n    '\n    warning.warn('DeprecationWarning: 2D annotations are not used on the Lyft dataset. The function export_2d_annotation will be deprecated.')\n    camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n    lyft_infos = mmcv.load(info_path)['infos']\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    cat2Ids = [dict(id=lyft_categories.index(cat_name), name=cat_name) for cat_name in lyft_categories]\n    coco_ann_id = 0\n    coco_2d_dict = dict(annotations=[], images=[], categories=cat2Ids)\n    for info in mmcv.track_iter_progress(lyft_infos):\n        for cam in camera_types:\n            cam_info = info['cams'][cam]\n            coco_infos = get_2d_boxes(lyft, cam_info['sample_data_token'], visibilities=['', '1', '2', '3', '4'])\n            (height, width, _) = mmcv.imread(cam_info['data_path']).shape\n            coco_2d_dict['images'].append(dict(file_name=cam_info['data_path'], id=cam_info['sample_data_token'], width=width, height=height))\n            for coco_info in coco_infos:\n                if coco_info is None:\n                    continue\n                coco_info['segmentation'] = []\n                coco_info['id'] = coco_ann_id\n                coco_2d_dict['annotations'].append(coco_info)\n                coco_ann_id += 1\n    mmcv.dump(coco_2d_dict, f'{info_path[:-4]}.coco.json')",
            "def export_2d_annotation(root_path, info_path, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Export 2d annotation from the info file and raw data.\\n\\n    Args:\\n        root_path (str): Root path of the raw data.\\n        info_path (str): Path of the info file.\\n        version (str): Dataset version.\\n    '\n    warning.warn('DeprecationWarning: 2D annotations are not used on the Lyft dataset. The function export_2d_annotation will be deprecated.')\n    camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n    lyft_infos = mmcv.load(info_path)['infos']\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    cat2Ids = [dict(id=lyft_categories.index(cat_name), name=cat_name) for cat_name in lyft_categories]\n    coco_ann_id = 0\n    coco_2d_dict = dict(annotations=[], images=[], categories=cat2Ids)\n    for info in mmcv.track_iter_progress(lyft_infos):\n        for cam in camera_types:\n            cam_info = info['cams'][cam]\n            coco_infos = get_2d_boxes(lyft, cam_info['sample_data_token'], visibilities=['', '1', '2', '3', '4'])\n            (height, width, _) = mmcv.imread(cam_info['data_path']).shape\n            coco_2d_dict['images'].append(dict(file_name=cam_info['data_path'], id=cam_info['sample_data_token'], width=width, height=height))\n            for coco_info in coco_infos:\n                if coco_info is None:\n                    continue\n                coco_info['segmentation'] = []\n                coco_info['id'] = coco_ann_id\n                coco_2d_dict['annotations'].append(coco_info)\n                coco_ann_id += 1\n    mmcv.dump(coco_2d_dict, f'{info_path[:-4]}.coco.json')",
            "def export_2d_annotation(root_path, info_path, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Export 2d annotation from the info file and raw data.\\n\\n    Args:\\n        root_path (str): Root path of the raw data.\\n        info_path (str): Path of the info file.\\n        version (str): Dataset version.\\n    '\n    warning.warn('DeprecationWarning: 2D annotations are not used on the Lyft dataset. The function export_2d_annotation will be deprecated.')\n    camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n    lyft_infos = mmcv.load(info_path)['infos']\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    cat2Ids = [dict(id=lyft_categories.index(cat_name), name=cat_name) for cat_name in lyft_categories]\n    coco_ann_id = 0\n    coco_2d_dict = dict(annotations=[], images=[], categories=cat2Ids)\n    for info in mmcv.track_iter_progress(lyft_infos):\n        for cam in camera_types:\n            cam_info = info['cams'][cam]\n            coco_infos = get_2d_boxes(lyft, cam_info['sample_data_token'], visibilities=['', '1', '2', '3', '4'])\n            (height, width, _) = mmcv.imread(cam_info['data_path']).shape\n            coco_2d_dict['images'].append(dict(file_name=cam_info['data_path'], id=cam_info['sample_data_token'], width=width, height=height))\n            for coco_info in coco_infos:\n                if coco_info is None:\n                    continue\n                coco_info['segmentation'] = []\n                coco_info['id'] = coco_ann_id\n                coco_2d_dict['annotations'].append(coco_info)\n                coco_ann_id += 1\n    mmcv.dump(coco_2d_dict, f'{info_path[:-4]}.coco.json')",
            "def export_2d_annotation(root_path, info_path, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Export 2d annotation from the info file and raw data.\\n\\n    Args:\\n        root_path (str): Root path of the raw data.\\n        info_path (str): Path of the info file.\\n        version (str): Dataset version.\\n    '\n    warning.warn('DeprecationWarning: 2D annotations are not used on the Lyft dataset. The function export_2d_annotation will be deprecated.')\n    camera_types = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n    lyft_infos = mmcv.load(info_path)['infos']\n    lyft = Lyft(data_path=osp.join(root_path, version), json_path=osp.join(root_path, version, version), verbose=True)\n    cat2Ids = [dict(id=lyft_categories.index(cat_name), name=cat_name) for cat_name in lyft_categories]\n    coco_ann_id = 0\n    coco_2d_dict = dict(annotations=[], images=[], categories=cat2Ids)\n    for info in mmcv.track_iter_progress(lyft_infos):\n        for cam in camera_types:\n            cam_info = info['cams'][cam]\n            coco_infos = get_2d_boxes(lyft, cam_info['sample_data_token'], visibilities=['', '1', '2', '3', '4'])\n            (height, width, _) = mmcv.imread(cam_info['data_path']).shape\n            coco_2d_dict['images'].append(dict(file_name=cam_info['data_path'], id=cam_info['sample_data_token'], width=width, height=height))\n            for coco_info in coco_infos:\n                if coco_info is None:\n                    continue\n                coco_info['segmentation'] = []\n                coco_info['id'] = coco_ann_id\n                coco_2d_dict['annotations'].append(coco_info)\n                coco_ann_id += 1\n    mmcv.dump(coco_2d_dict, f'{info_path[:-4]}.coco.json')"
        ]
    }
]