[
    {
        "func_name": "_skip_datasets_with_zero_weight",
        "original": "def _skip_datasets_with_zero_weight(datasets, weights):\n    datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n    return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])",
        "mutated": [
            "def _skip_datasets_with_zero_weight(datasets, weights):\n    if False:\n        i = 10\n    datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n    return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])",
            "def _skip_datasets_with_zero_weight(datasets, weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n    return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])",
            "def _skip_datasets_with_zero_weight(datasets, weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n    return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])",
            "def _skip_datasets_with_zero_weight(datasets, weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n    return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])",
            "def _skip_datasets_with_zero_weight(datasets, weights):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n    return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])"
        ]
    },
    {
        "func_name": "select_dataset_constant_logits",
        "original": "def select_dataset_constant_logits(seed):\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
        "mutated": [
            "def select_dataset_constant_logits(seed):\n    if False:\n        i = 10\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_constant_logits(seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_constant_logits(seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_constant_logits(seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_constant_logits(seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])"
        ]
    },
    {
        "func_name": "select_dataset_varying_logits",
        "original": "def select_dataset_varying_logits(logits, seed):\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
        "mutated": [
            "def select_dataset_varying_logits(logits, seed):\n    if False:\n        i = 10\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_varying_logits(logits, seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_varying_logits(logits, seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_varying_logits(logits, seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])",
            "def select_dataset_varying_logits(logits, seed):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])"
        ]
    },
    {
        "func_name": "_sample_from_datasets",
        "original": "def _sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False, rerandomize_each_iteration=None):\n    \"\"\"See `Dataset.sample_from_datasets()` for details.\"\"\"\n\n    def _skip_datasets_with_zero_weight(datasets, weights):\n        datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n        return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])\n    if not datasets:\n        raise ValueError('Invalid `datasets`. `datasets` should not be empty.')\n    if not isinstance(weights, data_types.DatasetV2):\n        if weights is None:\n            logits = [[1.0] * len(datasets)]\n        else:\n            if isinstance(weights, tensor.Tensor):\n                if not weights.shape.is_compatible_with([len(datasets)]):\n                    raise ValueError(f'Invalid `weights`. The shape of `weights` should be compatible with `[len(datasets)]` but is {weights.shape}.')\n            elif len(datasets) != len(weights):\n                raise ValueError(f'Invalid `weights`. `weights` should have the same length as `datasets` but got `len(weights)={len(weights)}` vs. `len(datasets)={len(datasets)}`.')\n            if not isinstance(weights, tensor.Tensor):\n                (datasets, weights) = _skip_datasets_with_zero_weight(datasets, weights)\n            weights = ops.convert_to_tensor(weights, name='weights')\n            if weights.dtype not in (dtypes.float32, dtypes.float64):\n                raise TypeError(f'Invalid `weights`. `weights` type must be either `tf.float32` or `tf.float64` but is {weights.dtype}.')\n            logits = array_ops.expand_dims(math_ops.log(weights, name='logits'), 0)\n        if len(datasets) == 1:\n            return datasets[0]\n\n        def select_dataset_constant_logits(seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        selector_input = map_op._MapDataset(dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2), select_dataset_constant_logits, use_inter_op_parallelism=False)\n    else:\n        logits_ds = weights.map(lambda *p: math_ops.log(p, name='logits'))\n\n        def select_dataset_varying_logits(logits, seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        logits_and_seeds = dataset_ops.Dataset.zip((logits_ds, dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2)))\n        selector_input = map_op._MapDataset(logits_and_seeds, select_dataset_varying_logits, use_inter_op_parallelism=False)\n    return directed_interleave_op._directed_interleave(selector_input, datasets, stop_on_empty_dataset)",
        "mutated": [
            "def _sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False, rerandomize_each_iteration=None):\n    if False:\n        i = 10\n    'See `Dataset.sample_from_datasets()` for details.'\n\n    def _skip_datasets_with_zero_weight(datasets, weights):\n        datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n        return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])\n    if not datasets:\n        raise ValueError('Invalid `datasets`. `datasets` should not be empty.')\n    if not isinstance(weights, data_types.DatasetV2):\n        if weights is None:\n            logits = [[1.0] * len(datasets)]\n        else:\n            if isinstance(weights, tensor.Tensor):\n                if not weights.shape.is_compatible_with([len(datasets)]):\n                    raise ValueError(f'Invalid `weights`. The shape of `weights` should be compatible with `[len(datasets)]` but is {weights.shape}.')\n            elif len(datasets) != len(weights):\n                raise ValueError(f'Invalid `weights`. `weights` should have the same length as `datasets` but got `len(weights)={len(weights)}` vs. `len(datasets)={len(datasets)}`.')\n            if not isinstance(weights, tensor.Tensor):\n                (datasets, weights) = _skip_datasets_with_zero_weight(datasets, weights)\n            weights = ops.convert_to_tensor(weights, name='weights')\n            if weights.dtype not in (dtypes.float32, dtypes.float64):\n                raise TypeError(f'Invalid `weights`. `weights` type must be either `tf.float32` or `tf.float64` but is {weights.dtype}.')\n            logits = array_ops.expand_dims(math_ops.log(weights, name='logits'), 0)\n        if len(datasets) == 1:\n            return datasets[0]\n\n        def select_dataset_constant_logits(seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        selector_input = map_op._MapDataset(dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2), select_dataset_constant_logits, use_inter_op_parallelism=False)\n    else:\n        logits_ds = weights.map(lambda *p: math_ops.log(p, name='logits'))\n\n        def select_dataset_varying_logits(logits, seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        logits_and_seeds = dataset_ops.Dataset.zip((logits_ds, dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2)))\n        selector_input = map_op._MapDataset(logits_and_seeds, select_dataset_varying_logits, use_inter_op_parallelism=False)\n    return directed_interleave_op._directed_interleave(selector_input, datasets, stop_on_empty_dataset)",
            "def _sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False, rerandomize_each_iteration=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'See `Dataset.sample_from_datasets()` for details.'\n\n    def _skip_datasets_with_zero_weight(datasets, weights):\n        datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n        return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])\n    if not datasets:\n        raise ValueError('Invalid `datasets`. `datasets` should not be empty.')\n    if not isinstance(weights, data_types.DatasetV2):\n        if weights is None:\n            logits = [[1.0] * len(datasets)]\n        else:\n            if isinstance(weights, tensor.Tensor):\n                if not weights.shape.is_compatible_with([len(datasets)]):\n                    raise ValueError(f'Invalid `weights`. The shape of `weights` should be compatible with `[len(datasets)]` but is {weights.shape}.')\n            elif len(datasets) != len(weights):\n                raise ValueError(f'Invalid `weights`. `weights` should have the same length as `datasets` but got `len(weights)={len(weights)}` vs. `len(datasets)={len(datasets)}`.')\n            if not isinstance(weights, tensor.Tensor):\n                (datasets, weights) = _skip_datasets_with_zero_weight(datasets, weights)\n            weights = ops.convert_to_tensor(weights, name='weights')\n            if weights.dtype not in (dtypes.float32, dtypes.float64):\n                raise TypeError(f'Invalid `weights`. `weights` type must be either `tf.float32` or `tf.float64` but is {weights.dtype}.')\n            logits = array_ops.expand_dims(math_ops.log(weights, name='logits'), 0)\n        if len(datasets) == 1:\n            return datasets[0]\n\n        def select_dataset_constant_logits(seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        selector_input = map_op._MapDataset(dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2), select_dataset_constant_logits, use_inter_op_parallelism=False)\n    else:\n        logits_ds = weights.map(lambda *p: math_ops.log(p, name='logits'))\n\n        def select_dataset_varying_logits(logits, seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        logits_and_seeds = dataset_ops.Dataset.zip((logits_ds, dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2)))\n        selector_input = map_op._MapDataset(logits_and_seeds, select_dataset_varying_logits, use_inter_op_parallelism=False)\n    return directed_interleave_op._directed_interleave(selector_input, datasets, stop_on_empty_dataset)",
            "def _sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False, rerandomize_each_iteration=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'See `Dataset.sample_from_datasets()` for details.'\n\n    def _skip_datasets_with_zero_weight(datasets, weights):\n        datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n        return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])\n    if not datasets:\n        raise ValueError('Invalid `datasets`. `datasets` should not be empty.')\n    if not isinstance(weights, data_types.DatasetV2):\n        if weights is None:\n            logits = [[1.0] * len(datasets)]\n        else:\n            if isinstance(weights, tensor.Tensor):\n                if not weights.shape.is_compatible_with([len(datasets)]):\n                    raise ValueError(f'Invalid `weights`. The shape of `weights` should be compatible with `[len(datasets)]` but is {weights.shape}.')\n            elif len(datasets) != len(weights):\n                raise ValueError(f'Invalid `weights`. `weights` should have the same length as `datasets` but got `len(weights)={len(weights)}` vs. `len(datasets)={len(datasets)}`.')\n            if not isinstance(weights, tensor.Tensor):\n                (datasets, weights) = _skip_datasets_with_zero_weight(datasets, weights)\n            weights = ops.convert_to_tensor(weights, name='weights')\n            if weights.dtype not in (dtypes.float32, dtypes.float64):\n                raise TypeError(f'Invalid `weights`. `weights` type must be either `tf.float32` or `tf.float64` but is {weights.dtype}.')\n            logits = array_ops.expand_dims(math_ops.log(weights, name='logits'), 0)\n        if len(datasets) == 1:\n            return datasets[0]\n\n        def select_dataset_constant_logits(seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        selector_input = map_op._MapDataset(dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2), select_dataset_constant_logits, use_inter_op_parallelism=False)\n    else:\n        logits_ds = weights.map(lambda *p: math_ops.log(p, name='logits'))\n\n        def select_dataset_varying_logits(logits, seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        logits_and_seeds = dataset_ops.Dataset.zip((logits_ds, dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2)))\n        selector_input = map_op._MapDataset(logits_and_seeds, select_dataset_varying_logits, use_inter_op_parallelism=False)\n    return directed_interleave_op._directed_interleave(selector_input, datasets, stop_on_empty_dataset)",
            "def _sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False, rerandomize_each_iteration=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'See `Dataset.sample_from_datasets()` for details.'\n\n    def _skip_datasets_with_zero_weight(datasets, weights):\n        datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n        return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])\n    if not datasets:\n        raise ValueError('Invalid `datasets`. `datasets` should not be empty.')\n    if not isinstance(weights, data_types.DatasetV2):\n        if weights is None:\n            logits = [[1.0] * len(datasets)]\n        else:\n            if isinstance(weights, tensor.Tensor):\n                if not weights.shape.is_compatible_with([len(datasets)]):\n                    raise ValueError(f'Invalid `weights`. The shape of `weights` should be compatible with `[len(datasets)]` but is {weights.shape}.')\n            elif len(datasets) != len(weights):\n                raise ValueError(f'Invalid `weights`. `weights` should have the same length as `datasets` but got `len(weights)={len(weights)}` vs. `len(datasets)={len(datasets)}`.')\n            if not isinstance(weights, tensor.Tensor):\n                (datasets, weights) = _skip_datasets_with_zero_weight(datasets, weights)\n            weights = ops.convert_to_tensor(weights, name='weights')\n            if weights.dtype not in (dtypes.float32, dtypes.float64):\n                raise TypeError(f'Invalid `weights`. `weights` type must be either `tf.float32` or `tf.float64` but is {weights.dtype}.')\n            logits = array_ops.expand_dims(math_ops.log(weights, name='logits'), 0)\n        if len(datasets) == 1:\n            return datasets[0]\n\n        def select_dataset_constant_logits(seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        selector_input = map_op._MapDataset(dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2), select_dataset_constant_logits, use_inter_op_parallelism=False)\n    else:\n        logits_ds = weights.map(lambda *p: math_ops.log(p, name='logits'))\n\n        def select_dataset_varying_logits(logits, seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        logits_and_seeds = dataset_ops.Dataset.zip((logits_ds, dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2)))\n        selector_input = map_op._MapDataset(logits_and_seeds, select_dataset_varying_logits, use_inter_op_parallelism=False)\n    return directed_interleave_op._directed_interleave(selector_input, datasets, stop_on_empty_dataset)",
            "def _sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False, rerandomize_each_iteration=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'See `Dataset.sample_from_datasets()` for details.'\n\n    def _skip_datasets_with_zero_weight(datasets, weights):\n        datasets_and_weights = [(dataset, weight) for (dataset, weight) in zip(datasets, weights) if weight > 0]\n        return zip(*datasets_and_weights) if datasets_and_weights else ([datasets[0].take(0)], [1.0])\n    if not datasets:\n        raise ValueError('Invalid `datasets`. `datasets` should not be empty.')\n    if not isinstance(weights, data_types.DatasetV2):\n        if weights is None:\n            logits = [[1.0] * len(datasets)]\n        else:\n            if isinstance(weights, tensor.Tensor):\n                if not weights.shape.is_compatible_with([len(datasets)]):\n                    raise ValueError(f'Invalid `weights`. The shape of `weights` should be compatible with `[len(datasets)]` but is {weights.shape}.')\n            elif len(datasets) != len(weights):\n                raise ValueError(f'Invalid `weights`. `weights` should have the same length as `datasets` but got `len(weights)={len(weights)}` vs. `len(datasets)={len(datasets)}`.')\n            if not isinstance(weights, tensor.Tensor):\n                (datasets, weights) = _skip_datasets_with_zero_weight(datasets, weights)\n            weights = ops.convert_to_tensor(weights, name='weights')\n            if weights.dtype not in (dtypes.float32, dtypes.float64):\n                raise TypeError(f'Invalid `weights`. `weights` type must be either `tf.float32` or `tf.float64` but is {weights.dtype}.')\n            logits = array_ops.expand_dims(math_ops.log(weights, name='logits'), 0)\n        if len(datasets) == 1:\n            return datasets[0]\n\n        def select_dataset_constant_logits(seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        selector_input = map_op._MapDataset(dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2), select_dataset_constant_logits, use_inter_op_parallelism=False)\n    else:\n        logits_ds = weights.map(lambda *p: math_ops.log(p, name='logits'))\n\n        def select_dataset_varying_logits(logits, seed):\n            return array_ops.squeeze(gen_stateless_random_ops.stateless_multinomial(logits, 1, seed=seed), axis=[0, 1])\n        logits_and_seeds = dataset_ops.Dataset.zip((logits_ds, dataset_ops.Dataset.random(seed=seed, rerandomize_each_iteration=rerandomize_each_iteration).batch(2)))\n        selector_input = map_op._MapDataset(logits_and_seeds, select_dataset_varying_logits, use_inter_op_parallelism=False)\n    return directed_interleave_op._directed_interleave(selector_input, datasets, stop_on_empty_dataset)"
        ]
    }
]