[
    {
        "func_name": "clear_duplicate_counts",
        "original": "def clear_duplicate_counts(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    \"\"\"This is a preparatory migration for our Analytics tables.\n\n    The backstory is that Django's unique_together indexes do not properly\n    handle the subgroup=None corner case (allowing duplicate rows that have a\n    subgroup of None), which meant that in race conditions, rather than updating\n    an existing row for the property/(realm, stream, user)/time with subgroup=None, Django would\n    create a duplicate row.\n\n    In the next migration, we'll add a proper constraint to fix this bug, but\n    we need to fix any existing problematic rows before we can add that constraint.\n\n    We fix this in an appropriate fashion for each type of CountStat object; mainly\n    this means deleting the extra rows, but for LoggingCountStat objects, we need to\n    additionally combine the sums.\n    \"\"\"\n    count_tables = dict(realm=apps.get_model('analytics', 'RealmCount'), user=apps.get_model('analytics', 'UserCount'), stream=apps.get_model('analytics', 'StreamCount'), installation=apps.get_model('analytics', 'InstallationCount'))\n    for (name, count_table) in count_tables.items():\n        value = [name, 'property', 'end_time']\n        if name == 'installation':\n            value = ['property', 'end_time']\n        counts = count_table.objects.filter(subgroup=None).values(*value).annotate(Count('id'), Sum('value')).filter(id__count__gt=1)\n        for count in counts:\n            count.pop('id__count')\n            total_value = count.pop('value__sum')\n            duplicate_counts = list(count_table.objects.filter(**count))\n            first_count = duplicate_counts[0]\n            if count['property'] in ['invites_sent::day', 'active_users_log:is_bot:day']:\n                first_count.value = total_value\n                first_count.save()\n            to_cleanup = duplicate_counts[1:]\n            for duplicate_count in to_cleanup:\n                duplicate_count.delete()",
        "mutated": [
            "def clear_duplicate_counts(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n    \"This is a preparatory migration for our Analytics tables.\\n\\n    The backstory is that Django's unique_together indexes do not properly\\n    handle the subgroup=None corner case (allowing duplicate rows that have a\\n    subgroup of None), which meant that in race conditions, rather than updating\\n    an existing row for the property/(realm, stream, user)/time with subgroup=None, Django would\\n    create a duplicate row.\\n\\n    In the next migration, we'll add a proper constraint to fix this bug, but\\n    we need to fix any existing problematic rows before we can add that constraint.\\n\\n    We fix this in an appropriate fashion for each type of CountStat object; mainly\\n    this means deleting the extra rows, but for LoggingCountStat objects, we need to\\n    additionally combine the sums.\\n    \"\n    count_tables = dict(realm=apps.get_model('analytics', 'RealmCount'), user=apps.get_model('analytics', 'UserCount'), stream=apps.get_model('analytics', 'StreamCount'), installation=apps.get_model('analytics', 'InstallationCount'))\n    for (name, count_table) in count_tables.items():\n        value = [name, 'property', 'end_time']\n        if name == 'installation':\n            value = ['property', 'end_time']\n        counts = count_table.objects.filter(subgroup=None).values(*value).annotate(Count('id'), Sum('value')).filter(id__count__gt=1)\n        for count in counts:\n            count.pop('id__count')\n            total_value = count.pop('value__sum')\n            duplicate_counts = list(count_table.objects.filter(**count))\n            first_count = duplicate_counts[0]\n            if count['property'] in ['invites_sent::day', 'active_users_log:is_bot:day']:\n                first_count.value = total_value\n                first_count.save()\n            to_cleanup = duplicate_counts[1:]\n            for duplicate_count in to_cleanup:\n                duplicate_count.delete()",
            "def clear_duplicate_counts(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"This is a preparatory migration for our Analytics tables.\\n\\n    The backstory is that Django's unique_together indexes do not properly\\n    handle the subgroup=None corner case (allowing duplicate rows that have a\\n    subgroup of None), which meant that in race conditions, rather than updating\\n    an existing row for the property/(realm, stream, user)/time with subgroup=None, Django would\\n    create a duplicate row.\\n\\n    In the next migration, we'll add a proper constraint to fix this bug, but\\n    we need to fix any existing problematic rows before we can add that constraint.\\n\\n    We fix this in an appropriate fashion for each type of CountStat object; mainly\\n    this means deleting the extra rows, but for LoggingCountStat objects, we need to\\n    additionally combine the sums.\\n    \"\n    count_tables = dict(realm=apps.get_model('analytics', 'RealmCount'), user=apps.get_model('analytics', 'UserCount'), stream=apps.get_model('analytics', 'StreamCount'), installation=apps.get_model('analytics', 'InstallationCount'))\n    for (name, count_table) in count_tables.items():\n        value = [name, 'property', 'end_time']\n        if name == 'installation':\n            value = ['property', 'end_time']\n        counts = count_table.objects.filter(subgroup=None).values(*value).annotate(Count('id'), Sum('value')).filter(id__count__gt=1)\n        for count in counts:\n            count.pop('id__count')\n            total_value = count.pop('value__sum')\n            duplicate_counts = list(count_table.objects.filter(**count))\n            first_count = duplicate_counts[0]\n            if count['property'] in ['invites_sent::day', 'active_users_log:is_bot:day']:\n                first_count.value = total_value\n                first_count.save()\n            to_cleanup = duplicate_counts[1:]\n            for duplicate_count in to_cleanup:\n                duplicate_count.delete()",
            "def clear_duplicate_counts(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"This is a preparatory migration for our Analytics tables.\\n\\n    The backstory is that Django's unique_together indexes do not properly\\n    handle the subgroup=None corner case (allowing duplicate rows that have a\\n    subgroup of None), which meant that in race conditions, rather than updating\\n    an existing row for the property/(realm, stream, user)/time with subgroup=None, Django would\\n    create a duplicate row.\\n\\n    In the next migration, we'll add a proper constraint to fix this bug, but\\n    we need to fix any existing problematic rows before we can add that constraint.\\n\\n    We fix this in an appropriate fashion for each type of CountStat object; mainly\\n    this means deleting the extra rows, but for LoggingCountStat objects, we need to\\n    additionally combine the sums.\\n    \"\n    count_tables = dict(realm=apps.get_model('analytics', 'RealmCount'), user=apps.get_model('analytics', 'UserCount'), stream=apps.get_model('analytics', 'StreamCount'), installation=apps.get_model('analytics', 'InstallationCount'))\n    for (name, count_table) in count_tables.items():\n        value = [name, 'property', 'end_time']\n        if name == 'installation':\n            value = ['property', 'end_time']\n        counts = count_table.objects.filter(subgroup=None).values(*value).annotate(Count('id'), Sum('value')).filter(id__count__gt=1)\n        for count in counts:\n            count.pop('id__count')\n            total_value = count.pop('value__sum')\n            duplicate_counts = list(count_table.objects.filter(**count))\n            first_count = duplicate_counts[0]\n            if count['property'] in ['invites_sent::day', 'active_users_log:is_bot:day']:\n                first_count.value = total_value\n                first_count.save()\n            to_cleanup = duplicate_counts[1:]\n            for duplicate_count in to_cleanup:\n                duplicate_count.delete()",
            "def clear_duplicate_counts(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"This is a preparatory migration for our Analytics tables.\\n\\n    The backstory is that Django's unique_together indexes do not properly\\n    handle the subgroup=None corner case (allowing duplicate rows that have a\\n    subgroup of None), which meant that in race conditions, rather than updating\\n    an existing row for the property/(realm, stream, user)/time with subgroup=None, Django would\\n    create a duplicate row.\\n\\n    In the next migration, we'll add a proper constraint to fix this bug, but\\n    we need to fix any existing problematic rows before we can add that constraint.\\n\\n    We fix this in an appropriate fashion for each type of CountStat object; mainly\\n    this means deleting the extra rows, but for LoggingCountStat objects, we need to\\n    additionally combine the sums.\\n    \"\n    count_tables = dict(realm=apps.get_model('analytics', 'RealmCount'), user=apps.get_model('analytics', 'UserCount'), stream=apps.get_model('analytics', 'StreamCount'), installation=apps.get_model('analytics', 'InstallationCount'))\n    for (name, count_table) in count_tables.items():\n        value = [name, 'property', 'end_time']\n        if name == 'installation':\n            value = ['property', 'end_time']\n        counts = count_table.objects.filter(subgroup=None).values(*value).annotate(Count('id'), Sum('value')).filter(id__count__gt=1)\n        for count in counts:\n            count.pop('id__count')\n            total_value = count.pop('value__sum')\n            duplicate_counts = list(count_table.objects.filter(**count))\n            first_count = duplicate_counts[0]\n            if count['property'] in ['invites_sent::day', 'active_users_log:is_bot:day']:\n                first_count.value = total_value\n                first_count.save()\n            to_cleanup = duplicate_counts[1:]\n            for duplicate_count in to_cleanup:\n                duplicate_count.delete()",
            "def clear_duplicate_counts(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"This is a preparatory migration for our Analytics tables.\\n\\n    The backstory is that Django's unique_together indexes do not properly\\n    handle the subgroup=None corner case (allowing duplicate rows that have a\\n    subgroup of None), which meant that in race conditions, rather than updating\\n    an existing row for the property/(realm, stream, user)/time with subgroup=None, Django would\\n    create a duplicate row.\\n\\n    In the next migration, we'll add a proper constraint to fix this bug, but\\n    we need to fix any existing problematic rows before we can add that constraint.\\n\\n    We fix this in an appropriate fashion for each type of CountStat object; mainly\\n    this means deleting the extra rows, but for LoggingCountStat objects, we need to\\n    additionally combine the sums.\\n    \"\n    count_tables = dict(realm=apps.get_model('analytics', 'RealmCount'), user=apps.get_model('analytics', 'UserCount'), stream=apps.get_model('analytics', 'StreamCount'), installation=apps.get_model('analytics', 'InstallationCount'))\n    for (name, count_table) in count_tables.items():\n        value = [name, 'property', 'end_time']\n        if name == 'installation':\n            value = ['property', 'end_time']\n        counts = count_table.objects.filter(subgroup=None).values(*value).annotate(Count('id'), Sum('value')).filter(id__count__gt=1)\n        for count in counts:\n            count.pop('id__count')\n            total_value = count.pop('value__sum')\n            duplicate_counts = list(count_table.objects.filter(**count))\n            first_count = duplicate_counts[0]\n            if count['property'] in ['invites_sent::day', 'active_users_log:is_bot:day']:\n                first_count.value = total_value\n                first_count.save()\n            to_cleanup = duplicate_counts[1:]\n            for duplicate_count in to_cleanup:\n                duplicate_count.delete()"
        ]
    }
]