[
    {
        "func_name": "api_request",
        "original": "def api_request(method: str, path: str, base_url: str='http://localhost:8080/api/v1', **kwargs) -> dict:\n    response = requests.request(method=method, url=f'{base_url}/{path}', auth=(AIRFLOW_WWW_USER_USERNAME, AIRFLOW_WWW_USER_PASSWORD), headers={'Content-Type': 'application/json'}, **kwargs)\n    response.raise_for_status()\n    return response.json()",
        "mutated": [
            "def api_request(method: str, path: str, base_url: str='http://localhost:8080/api/v1', **kwargs) -> dict:\n    if False:\n        i = 10\n    response = requests.request(method=method, url=f'{base_url}/{path}', auth=(AIRFLOW_WWW_USER_USERNAME, AIRFLOW_WWW_USER_PASSWORD), headers={'Content-Type': 'application/json'}, **kwargs)\n    response.raise_for_status()\n    return response.json()",
            "def api_request(method: str, path: str, base_url: str='http://localhost:8080/api/v1', **kwargs) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    response = requests.request(method=method, url=f'{base_url}/{path}', auth=(AIRFLOW_WWW_USER_USERNAME, AIRFLOW_WWW_USER_PASSWORD), headers={'Content-Type': 'application/json'}, **kwargs)\n    response.raise_for_status()\n    return response.json()",
            "def api_request(method: str, path: str, base_url: str='http://localhost:8080/api/v1', **kwargs) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    response = requests.request(method=method, url=f'{base_url}/{path}', auth=(AIRFLOW_WWW_USER_USERNAME, AIRFLOW_WWW_USER_PASSWORD), headers={'Content-Type': 'application/json'}, **kwargs)\n    response.raise_for_status()\n    return response.json()",
            "def api_request(method: str, path: str, base_url: str='http://localhost:8080/api/v1', **kwargs) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    response = requests.request(method=method, url=f'{base_url}/{path}', auth=(AIRFLOW_WWW_USER_USERNAME, AIRFLOW_WWW_USER_PASSWORD), headers={'Content-Type': 'application/json'}, **kwargs)\n    response.raise_for_status()\n    return response.json()",
            "def api_request(method: str, path: str, base_url: str='http://localhost:8080/api/v1', **kwargs) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    response = requests.request(method=method, url=f'{base_url}/{path}', auth=(AIRFLOW_WWW_USER_USERNAME, AIRFLOW_WWW_USER_PASSWORD), headers={'Content-Type': 'application/json'}, **kwargs)\n    response.raise_for_status()\n    return response.json()"
        ]
    },
    {
        "func_name": "wait_for_container",
        "original": "def wait_for_container(container_id: str, timeout: int=300):\n    container_name = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .Name }}']).decode().strip()\n    print(f'Waiting for container: {container_name} [{container_id}] for {timeout} more seconds.')\n    waiting_done = False\n    start_time = monotonic()\n    while not waiting_done:\n        container_state = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .State.Status }}']).decode().strip()\n        if container_state in ('running', 'restarting'):\n            health_status = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ if .State.Health }}{{ .State.Health.Status }}{{ else }}no-check{{ end }}']).decode().strip()\n            current_time = monotonic()\n            print(f'{container_name}: container_state={container_state}, health_status={health_status}. Waiting for {int(timeout - (current_time - start_time))} more seconds')\n            if health_status == 'healthy' or health_status == 'no-check':\n                waiting_done = True\n        else:\n            print(f'{container_name}: container_state={container_state}')\n            waiting_done = True\n        if timeout != 0 and monotonic() - start_time > timeout:\n            raise Exception(f'Timeout. The operation takes longer than the maximum waiting time ({timeout}s)')\n        sleep(1)",
        "mutated": [
            "def wait_for_container(container_id: str, timeout: int=300):\n    if False:\n        i = 10\n    container_name = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .Name }}']).decode().strip()\n    print(f'Waiting for container: {container_name} [{container_id}] for {timeout} more seconds.')\n    waiting_done = False\n    start_time = monotonic()\n    while not waiting_done:\n        container_state = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .State.Status }}']).decode().strip()\n        if container_state in ('running', 'restarting'):\n            health_status = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ if .State.Health }}{{ .State.Health.Status }}{{ else }}no-check{{ end }}']).decode().strip()\n            current_time = monotonic()\n            print(f'{container_name}: container_state={container_state}, health_status={health_status}. Waiting for {int(timeout - (current_time - start_time))} more seconds')\n            if health_status == 'healthy' or health_status == 'no-check':\n                waiting_done = True\n        else:\n            print(f'{container_name}: container_state={container_state}')\n            waiting_done = True\n        if timeout != 0 and monotonic() - start_time > timeout:\n            raise Exception(f'Timeout. The operation takes longer than the maximum waiting time ({timeout}s)')\n        sleep(1)",
            "def wait_for_container(container_id: str, timeout: int=300):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    container_name = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .Name }}']).decode().strip()\n    print(f'Waiting for container: {container_name} [{container_id}] for {timeout} more seconds.')\n    waiting_done = False\n    start_time = monotonic()\n    while not waiting_done:\n        container_state = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .State.Status }}']).decode().strip()\n        if container_state in ('running', 'restarting'):\n            health_status = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ if .State.Health }}{{ .State.Health.Status }}{{ else }}no-check{{ end }}']).decode().strip()\n            current_time = monotonic()\n            print(f'{container_name}: container_state={container_state}, health_status={health_status}. Waiting for {int(timeout - (current_time - start_time))} more seconds')\n            if health_status == 'healthy' or health_status == 'no-check':\n                waiting_done = True\n        else:\n            print(f'{container_name}: container_state={container_state}')\n            waiting_done = True\n        if timeout != 0 and monotonic() - start_time > timeout:\n            raise Exception(f'Timeout. The operation takes longer than the maximum waiting time ({timeout}s)')\n        sleep(1)",
            "def wait_for_container(container_id: str, timeout: int=300):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    container_name = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .Name }}']).decode().strip()\n    print(f'Waiting for container: {container_name} [{container_id}] for {timeout} more seconds.')\n    waiting_done = False\n    start_time = monotonic()\n    while not waiting_done:\n        container_state = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .State.Status }}']).decode().strip()\n        if container_state in ('running', 'restarting'):\n            health_status = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ if .State.Health }}{{ .State.Health.Status }}{{ else }}no-check{{ end }}']).decode().strip()\n            current_time = monotonic()\n            print(f'{container_name}: container_state={container_state}, health_status={health_status}. Waiting for {int(timeout - (current_time - start_time))} more seconds')\n            if health_status == 'healthy' or health_status == 'no-check':\n                waiting_done = True\n        else:\n            print(f'{container_name}: container_state={container_state}')\n            waiting_done = True\n        if timeout != 0 and monotonic() - start_time > timeout:\n            raise Exception(f'Timeout. The operation takes longer than the maximum waiting time ({timeout}s)')\n        sleep(1)",
            "def wait_for_container(container_id: str, timeout: int=300):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    container_name = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .Name }}']).decode().strip()\n    print(f'Waiting for container: {container_name} [{container_id}] for {timeout} more seconds.')\n    waiting_done = False\n    start_time = monotonic()\n    while not waiting_done:\n        container_state = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .State.Status }}']).decode().strip()\n        if container_state in ('running', 'restarting'):\n            health_status = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ if .State.Health }}{{ .State.Health.Status }}{{ else }}no-check{{ end }}']).decode().strip()\n            current_time = monotonic()\n            print(f'{container_name}: container_state={container_state}, health_status={health_status}. Waiting for {int(timeout - (current_time - start_time))} more seconds')\n            if health_status == 'healthy' or health_status == 'no-check':\n                waiting_done = True\n        else:\n            print(f'{container_name}: container_state={container_state}')\n            waiting_done = True\n        if timeout != 0 and monotonic() - start_time > timeout:\n            raise Exception(f'Timeout. The operation takes longer than the maximum waiting time ({timeout}s)')\n        sleep(1)",
            "def wait_for_container(container_id: str, timeout: int=300):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    container_name = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .Name }}']).decode().strip()\n    print(f'Waiting for container: {container_name} [{container_id}] for {timeout} more seconds.')\n    waiting_done = False\n    start_time = monotonic()\n    while not waiting_done:\n        container_state = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ .State.Status }}']).decode().strip()\n        if container_state in ('running', 'restarting'):\n            health_status = subprocess.check_output(['docker', 'inspect', container_id, '--format', '{{ if .State.Health }}{{ .State.Health.Status }}{{ else }}no-check{{ end }}']).decode().strip()\n            current_time = monotonic()\n            print(f'{container_name}: container_state={container_state}, health_status={health_status}. Waiting for {int(timeout - (current_time - start_time))} more seconds')\n            if health_status == 'healthy' or health_status == 'no-check':\n                waiting_done = True\n        else:\n            print(f'{container_name}: container_state={container_state}')\n            waiting_done = True\n        if timeout != 0 and monotonic() - start_time > timeout:\n            raise Exception(f'Timeout. The operation takes longer than the maximum waiting time ({timeout}s)')\n        sleep(1)"
        ]
    },
    {
        "func_name": "wait_for_terminal_dag_state",
        "original": "def wait_for_terminal_dag_state(dag_id, dag_run_id):\n    print(f' Simplified representation of DAG {dag_id} '.center(72, '='))\n    pprint(api_request('GET', f'dags/{DAG_ID}/details'))\n    for _ in range(400):\n        dag_state = api_request('GET', f'dags/{dag_id}/dagRuns/{dag_run_id}').get('state')\n        print(f'Waiting for DAG Run: dag_state={dag_state}')\n        sleep(1)\n        if dag_state in ('success', 'failed'):\n            break",
        "mutated": [
            "def wait_for_terminal_dag_state(dag_id, dag_run_id):\n    if False:\n        i = 10\n    print(f' Simplified representation of DAG {dag_id} '.center(72, '='))\n    pprint(api_request('GET', f'dags/{DAG_ID}/details'))\n    for _ in range(400):\n        dag_state = api_request('GET', f'dags/{dag_id}/dagRuns/{dag_run_id}').get('state')\n        print(f'Waiting for DAG Run: dag_state={dag_state}')\n        sleep(1)\n        if dag_state in ('success', 'failed'):\n            break",
            "def wait_for_terminal_dag_state(dag_id, dag_run_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    print(f' Simplified representation of DAG {dag_id} '.center(72, '='))\n    pprint(api_request('GET', f'dags/{DAG_ID}/details'))\n    for _ in range(400):\n        dag_state = api_request('GET', f'dags/{dag_id}/dagRuns/{dag_run_id}').get('state')\n        print(f'Waiting for DAG Run: dag_state={dag_state}')\n        sleep(1)\n        if dag_state in ('success', 'failed'):\n            break",
            "def wait_for_terminal_dag_state(dag_id, dag_run_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    print(f' Simplified representation of DAG {dag_id} '.center(72, '='))\n    pprint(api_request('GET', f'dags/{DAG_ID}/details'))\n    for _ in range(400):\n        dag_state = api_request('GET', f'dags/{dag_id}/dagRuns/{dag_run_id}').get('state')\n        print(f'Waiting for DAG Run: dag_state={dag_state}')\n        sleep(1)\n        if dag_state in ('success', 'failed'):\n            break",
            "def wait_for_terminal_dag_state(dag_id, dag_run_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    print(f' Simplified representation of DAG {dag_id} '.center(72, '='))\n    pprint(api_request('GET', f'dags/{DAG_ID}/details'))\n    for _ in range(400):\n        dag_state = api_request('GET', f'dags/{dag_id}/dagRuns/{dag_run_id}').get('state')\n        print(f'Waiting for DAG Run: dag_state={dag_state}')\n        sleep(1)\n        if dag_state in ('success', 'failed'):\n            break",
            "def wait_for_terminal_dag_state(dag_id, dag_run_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    print(f' Simplified representation of DAG {dag_id} '.center(72, '='))\n    pprint(api_request('GET', f'dags/{DAG_ID}/details'))\n    for _ in range(400):\n        dag_state = api_request('GET', f'dags/{dag_id}/dagRuns/{dag_run_id}').get('state')\n        print(f'Waiting for DAG Run: dag_state={dag_state}')\n        sleep(1)\n        if dag_state in ('success', 'failed'):\n            break"
        ]
    },
    {
        "func_name": "test_trigger_dag_and_wait_for_result",
        "original": "def test_trigger_dag_and_wait_for_result(tmp_path_factory, monkeypatch):\n    \"\"\"Simple test which reproduce setup docker-compose environment and trigger example dag.\"\"\"\n    tmp_dir = tmp_path_factory.mktemp('airflow-quick-start')\n    monkeypatch.chdir(tmp_dir)\n    monkeypatch.setenv('AIRFLOW_IMAGE_NAME', docker_image)\n    compose_file_path = SOURCE_ROOT / 'docs' / 'apache-airflow' / 'howto' / 'docker-compose' / 'docker-compose.yaml'\n    copyfile(compose_file_path, tmp_dir / 'docker-compose.yaml')\n    for subdir in ('dags', 'logs', 'plugins'):\n        (tmp_dir / subdir).mkdir()\n    dot_env_file = tmp_dir / '.env'\n    dot_env_file.write_text(f'AIRFLOW_UID={os.getuid()}\\n')\n    print(' .env file content '.center(72, '='))\n    print(dot_env_file.read_text())\n    compose_command = ['docker', 'compose']\n    success = run_command([*compose_command, 'version'], check=False)\n    if not success:\n        print('ERROR: `docker compose` not available. Make sure compose plugin is installed')\n        sys.exit(1)\n    compose_command.extend(['--project-name', 'quick-start'])\n    run_command([*compose_command, 'config'])\n    run_command([*compose_command, 'down', '--volumes', '--remove-orphans'])\n    run_command([*compose_command, 'up', '-d', '--wait'])\n    api_request('PATCH', path=f'dags/{DAG_ID}', json={'is_paused': False})\n    api_request('POST', path=f'dags/{DAG_ID}/dagRuns', json={'dag_run_id': DAG_RUN_ID})\n    try:\n        wait_for_terminal_dag_state(dag_id=DAG_ID, dag_run_id=DAG_RUN_ID)\n        dag_state = api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}').get('state')\n        assert dag_state == 'success'\n    except Exception:\n        print('HTTP: GET health')\n        pprint(api_request('GET', 'health'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances'))\n        print(f'Current working directory: {os.getcwd()}')\n        run_command(['docker', 'version'])\n        run_command([*compose_command, 'version'])\n        run_command(['docker', 'ps'])\n        run_command([*compose_command, 'logs'])\n        ps_output = run_command([*compose_command, 'ps', '--format', 'json'], return_output=True)\n        container_names = [container['Name'] for container in json.loads(ps_output)]\n        for container in container_names:\n            print(f'Health check for {container}')\n            result = run_command(['docker', 'inspect', '--format', '{{json .State}}', container], return_output=True)\n            pprint(json.loads(result))\n        raise\n    finally:\n        if not os.environ.get('SKIP_DOCKER_COMPOSE_DELETION'):\n            run_command([*compose_command, 'down', '--volumes'])\n            print('Docker compose instance deleted')\n        else:\n            print('Skipping docker-compose deletion')\n            print()\n            print('You can run inspect your docker-compose by running commands starting with:')\n            print(' '.join([shlex.quote(arg) for arg in compose_command]))",
        "mutated": [
            "def test_trigger_dag_and_wait_for_result(tmp_path_factory, monkeypatch):\n    if False:\n        i = 10\n    'Simple test which reproduce setup docker-compose environment and trigger example dag.'\n    tmp_dir = tmp_path_factory.mktemp('airflow-quick-start')\n    monkeypatch.chdir(tmp_dir)\n    monkeypatch.setenv('AIRFLOW_IMAGE_NAME', docker_image)\n    compose_file_path = SOURCE_ROOT / 'docs' / 'apache-airflow' / 'howto' / 'docker-compose' / 'docker-compose.yaml'\n    copyfile(compose_file_path, tmp_dir / 'docker-compose.yaml')\n    for subdir in ('dags', 'logs', 'plugins'):\n        (tmp_dir / subdir).mkdir()\n    dot_env_file = tmp_dir / '.env'\n    dot_env_file.write_text(f'AIRFLOW_UID={os.getuid()}\\n')\n    print(' .env file content '.center(72, '='))\n    print(dot_env_file.read_text())\n    compose_command = ['docker', 'compose']\n    success = run_command([*compose_command, 'version'], check=False)\n    if not success:\n        print('ERROR: `docker compose` not available. Make sure compose plugin is installed')\n        sys.exit(1)\n    compose_command.extend(['--project-name', 'quick-start'])\n    run_command([*compose_command, 'config'])\n    run_command([*compose_command, 'down', '--volumes', '--remove-orphans'])\n    run_command([*compose_command, 'up', '-d', '--wait'])\n    api_request('PATCH', path=f'dags/{DAG_ID}', json={'is_paused': False})\n    api_request('POST', path=f'dags/{DAG_ID}/dagRuns', json={'dag_run_id': DAG_RUN_ID})\n    try:\n        wait_for_terminal_dag_state(dag_id=DAG_ID, dag_run_id=DAG_RUN_ID)\n        dag_state = api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}').get('state')\n        assert dag_state == 'success'\n    except Exception:\n        print('HTTP: GET health')\n        pprint(api_request('GET', 'health'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances'))\n        print(f'Current working directory: {os.getcwd()}')\n        run_command(['docker', 'version'])\n        run_command([*compose_command, 'version'])\n        run_command(['docker', 'ps'])\n        run_command([*compose_command, 'logs'])\n        ps_output = run_command([*compose_command, 'ps', '--format', 'json'], return_output=True)\n        container_names = [container['Name'] for container in json.loads(ps_output)]\n        for container in container_names:\n            print(f'Health check for {container}')\n            result = run_command(['docker', 'inspect', '--format', '{{json .State}}', container], return_output=True)\n            pprint(json.loads(result))\n        raise\n    finally:\n        if not os.environ.get('SKIP_DOCKER_COMPOSE_DELETION'):\n            run_command([*compose_command, 'down', '--volumes'])\n            print('Docker compose instance deleted')\n        else:\n            print('Skipping docker-compose deletion')\n            print()\n            print('You can run inspect your docker-compose by running commands starting with:')\n            print(' '.join([shlex.quote(arg) for arg in compose_command]))",
            "def test_trigger_dag_and_wait_for_result(tmp_path_factory, monkeypatch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Simple test which reproduce setup docker-compose environment and trigger example dag.'\n    tmp_dir = tmp_path_factory.mktemp('airflow-quick-start')\n    monkeypatch.chdir(tmp_dir)\n    monkeypatch.setenv('AIRFLOW_IMAGE_NAME', docker_image)\n    compose_file_path = SOURCE_ROOT / 'docs' / 'apache-airflow' / 'howto' / 'docker-compose' / 'docker-compose.yaml'\n    copyfile(compose_file_path, tmp_dir / 'docker-compose.yaml')\n    for subdir in ('dags', 'logs', 'plugins'):\n        (tmp_dir / subdir).mkdir()\n    dot_env_file = tmp_dir / '.env'\n    dot_env_file.write_text(f'AIRFLOW_UID={os.getuid()}\\n')\n    print(' .env file content '.center(72, '='))\n    print(dot_env_file.read_text())\n    compose_command = ['docker', 'compose']\n    success = run_command([*compose_command, 'version'], check=False)\n    if not success:\n        print('ERROR: `docker compose` not available. Make sure compose plugin is installed')\n        sys.exit(1)\n    compose_command.extend(['--project-name', 'quick-start'])\n    run_command([*compose_command, 'config'])\n    run_command([*compose_command, 'down', '--volumes', '--remove-orphans'])\n    run_command([*compose_command, 'up', '-d', '--wait'])\n    api_request('PATCH', path=f'dags/{DAG_ID}', json={'is_paused': False})\n    api_request('POST', path=f'dags/{DAG_ID}/dagRuns', json={'dag_run_id': DAG_RUN_ID})\n    try:\n        wait_for_terminal_dag_state(dag_id=DAG_ID, dag_run_id=DAG_RUN_ID)\n        dag_state = api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}').get('state')\n        assert dag_state == 'success'\n    except Exception:\n        print('HTTP: GET health')\n        pprint(api_request('GET', 'health'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances'))\n        print(f'Current working directory: {os.getcwd()}')\n        run_command(['docker', 'version'])\n        run_command([*compose_command, 'version'])\n        run_command(['docker', 'ps'])\n        run_command([*compose_command, 'logs'])\n        ps_output = run_command([*compose_command, 'ps', '--format', 'json'], return_output=True)\n        container_names = [container['Name'] for container in json.loads(ps_output)]\n        for container in container_names:\n            print(f'Health check for {container}')\n            result = run_command(['docker', 'inspect', '--format', '{{json .State}}', container], return_output=True)\n            pprint(json.loads(result))\n        raise\n    finally:\n        if not os.environ.get('SKIP_DOCKER_COMPOSE_DELETION'):\n            run_command([*compose_command, 'down', '--volumes'])\n            print('Docker compose instance deleted')\n        else:\n            print('Skipping docker-compose deletion')\n            print()\n            print('You can run inspect your docker-compose by running commands starting with:')\n            print(' '.join([shlex.quote(arg) for arg in compose_command]))",
            "def test_trigger_dag_and_wait_for_result(tmp_path_factory, monkeypatch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Simple test which reproduce setup docker-compose environment and trigger example dag.'\n    tmp_dir = tmp_path_factory.mktemp('airflow-quick-start')\n    monkeypatch.chdir(tmp_dir)\n    monkeypatch.setenv('AIRFLOW_IMAGE_NAME', docker_image)\n    compose_file_path = SOURCE_ROOT / 'docs' / 'apache-airflow' / 'howto' / 'docker-compose' / 'docker-compose.yaml'\n    copyfile(compose_file_path, tmp_dir / 'docker-compose.yaml')\n    for subdir in ('dags', 'logs', 'plugins'):\n        (tmp_dir / subdir).mkdir()\n    dot_env_file = tmp_dir / '.env'\n    dot_env_file.write_text(f'AIRFLOW_UID={os.getuid()}\\n')\n    print(' .env file content '.center(72, '='))\n    print(dot_env_file.read_text())\n    compose_command = ['docker', 'compose']\n    success = run_command([*compose_command, 'version'], check=False)\n    if not success:\n        print('ERROR: `docker compose` not available. Make sure compose plugin is installed')\n        sys.exit(1)\n    compose_command.extend(['--project-name', 'quick-start'])\n    run_command([*compose_command, 'config'])\n    run_command([*compose_command, 'down', '--volumes', '--remove-orphans'])\n    run_command([*compose_command, 'up', '-d', '--wait'])\n    api_request('PATCH', path=f'dags/{DAG_ID}', json={'is_paused': False})\n    api_request('POST', path=f'dags/{DAG_ID}/dagRuns', json={'dag_run_id': DAG_RUN_ID})\n    try:\n        wait_for_terminal_dag_state(dag_id=DAG_ID, dag_run_id=DAG_RUN_ID)\n        dag_state = api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}').get('state')\n        assert dag_state == 'success'\n    except Exception:\n        print('HTTP: GET health')\n        pprint(api_request('GET', 'health'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances'))\n        print(f'Current working directory: {os.getcwd()}')\n        run_command(['docker', 'version'])\n        run_command([*compose_command, 'version'])\n        run_command(['docker', 'ps'])\n        run_command([*compose_command, 'logs'])\n        ps_output = run_command([*compose_command, 'ps', '--format', 'json'], return_output=True)\n        container_names = [container['Name'] for container in json.loads(ps_output)]\n        for container in container_names:\n            print(f'Health check for {container}')\n            result = run_command(['docker', 'inspect', '--format', '{{json .State}}', container], return_output=True)\n            pprint(json.loads(result))\n        raise\n    finally:\n        if not os.environ.get('SKIP_DOCKER_COMPOSE_DELETION'):\n            run_command([*compose_command, 'down', '--volumes'])\n            print('Docker compose instance deleted')\n        else:\n            print('Skipping docker-compose deletion')\n            print()\n            print('You can run inspect your docker-compose by running commands starting with:')\n            print(' '.join([shlex.quote(arg) for arg in compose_command]))",
            "def test_trigger_dag_and_wait_for_result(tmp_path_factory, monkeypatch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Simple test which reproduce setup docker-compose environment and trigger example dag.'\n    tmp_dir = tmp_path_factory.mktemp('airflow-quick-start')\n    monkeypatch.chdir(tmp_dir)\n    monkeypatch.setenv('AIRFLOW_IMAGE_NAME', docker_image)\n    compose_file_path = SOURCE_ROOT / 'docs' / 'apache-airflow' / 'howto' / 'docker-compose' / 'docker-compose.yaml'\n    copyfile(compose_file_path, tmp_dir / 'docker-compose.yaml')\n    for subdir in ('dags', 'logs', 'plugins'):\n        (tmp_dir / subdir).mkdir()\n    dot_env_file = tmp_dir / '.env'\n    dot_env_file.write_text(f'AIRFLOW_UID={os.getuid()}\\n')\n    print(' .env file content '.center(72, '='))\n    print(dot_env_file.read_text())\n    compose_command = ['docker', 'compose']\n    success = run_command([*compose_command, 'version'], check=False)\n    if not success:\n        print('ERROR: `docker compose` not available. Make sure compose plugin is installed')\n        sys.exit(1)\n    compose_command.extend(['--project-name', 'quick-start'])\n    run_command([*compose_command, 'config'])\n    run_command([*compose_command, 'down', '--volumes', '--remove-orphans'])\n    run_command([*compose_command, 'up', '-d', '--wait'])\n    api_request('PATCH', path=f'dags/{DAG_ID}', json={'is_paused': False})\n    api_request('POST', path=f'dags/{DAG_ID}/dagRuns', json={'dag_run_id': DAG_RUN_ID})\n    try:\n        wait_for_terminal_dag_state(dag_id=DAG_ID, dag_run_id=DAG_RUN_ID)\n        dag_state = api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}').get('state')\n        assert dag_state == 'success'\n    except Exception:\n        print('HTTP: GET health')\n        pprint(api_request('GET', 'health'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances'))\n        print(f'Current working directory: {os.getcwd()}')\n        run_command(['docker', 'version'])\n        run_command([*compose_command, 'version'])\n        run_command(['docker', 'ps'])\n        run_command([*compose_command, 'logs'])\n        ps_output = run_command([*compose_command, 'ps', '--format', 'json'], return_output=True)\n        container_names = [container['Name'] for container in json.loads(ps_output)]\n        for container in container_names:\n            print(f'Health check for {container}')\n            result = run_command(['docker', 'inspect', '--format', '{{json .State}}', container], return_output=True)\n            pprint(json.loads(result))\n        raise\n    finally:\n        if not os.environ.get('SKIP_DOCKER_COMPOSE_DELETION'):\n            run_command([*compose_command, 'down', '--volumes'])\n            print('Docker compose instance deleted')\n        else:\n            print('Skipping docker-compose deletion')\n            print()\n            print('You can run inspect your docker-compose by running commands starting with:')\n            print(' '.join([shlex.quote(arg) for arg in compose_command]))",
            "def test_trigger_dag_and_wait_for_result(tmp_path_factory, monkeypatch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Simple test which reproduce setup docker-compose environment and trigger example dag.'\n    tmp_dir = tmp_path_factory.mktemp('airflow-quick-start')\n    monkeypatch.chdir(tmp_dir)\n    monkeypatch.setenv('AIRFLOW_IMAGE_NAME', docker_image)\n    compose_file_path = SOURCE_ROOT / 'docs' / 'apache-airflow' / 'howto' / 'docker-compose' / 'docker-compose.yaml'\n    copyfile(compose_file_path, tmp_dir / 'docker-compose.yaml')\n    for subdir in ('dags', 'logs', 'plugins'):\n        (tmp_dir / subdir).mkdir()\n    dot_env_file = tmp_dir / '.env'\n    dot_env_file.write_text(f'AIRFLOW_UID={os.getuid()}\\n')\n    print(' .env file content '.center(72, '='))\n    print(dot_env_file.read_text())\n    compose_command = ['docker', 'compose']\n    success = run_command([*compose_command, 'version'], check=False)\n    if not success:\n        print('ERROR: `docker compose` not available. Make sure compose plugin is installed')\n        sys.exit(1)\n    compose_command.extend(['--project-name', 'quick-start'])\n    run_command([*compose_command, 'config'])\n    run_command([*compose_command, 'down', '--volumes', '--remove-orphans'])\n    run_command([*compose_command, 'up', '-d', '--wait'])\n    api_request('PATCH', path=f'dags/{DAG_ID}', json={'is_paused': False})\n    api_request('POST', path=f'dags/{DAG_ID}/dagRuns', json={'dag_run_id': DAG_RUN_ID})\n    try:\n        wait_for_terminal_dag_state(dag_id=DAG_ID, dag_run_id=DAG_RUN_ID)\n        dag_state = api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}').get('state')\n        assert dag_state == 'success'\n    except Exception:\n        print('HTTP: GET health')\n        pprint(api_request('GET', 'health'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns'))\n        print(f'HTTP: GET dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances')\n        pprint(api_request('GET', f'dags/{DAG_ID}/dagRuns/{DAG_RUN_ID}/taskInstances'))\n        print(f'Current working directory: {os.getcwd()}')\n        run_command(['docker', 'version'])\n        run_command([*compose_command, 'version'])\n        run_command(['docker', 'ps'])\n        run_command([*compose_command, 'logs'])\n        ps_output = run_command([*compose_command, 'ps', '--format', 'json'], return_output=True)\n        container_names = [container['Name'] for container in json.loads(ps_output)]\n        for container in container_names:\n            print(f'Health check for {container}')\n            result = run_command(['docker', 'inspect', '--format', '{{json .State}}', container], return_output=True)\n            pprint(json.loads(result))\n        raise\n    finally:\n        if not os.environ.get('SKIP_DOCKER_COMPOSE_DELETION'):\n            run_command([*compose_command, 'down', '--volumes'])\n            print('Docker compose instance deleted')\n        else:\n            print('Skipping docker-compose deletion')\n            print()\n            print('You can run inspect your docker-compose by running commands starting with:')\n            print(' '.join([shlex.quote(arg) for arg in compose_command]))"
        ]
    }
]