[
    {
        "func_name": "beat_extraction",
        "original": "def beat_extraction(short_features, window_size, plot=False):\n    \"\"\"\n    This function extracts an estimate of the beat rate for a musical signal.\n    ARGUMENTS:\n     - short_features:     a np array (n_feats x numOfShortTermWindows)\n     - window_size:        window size in seconds\n    RETURNS:\n     - bpm:            estimates of beats per minute\n     - ratio:          a confidence measure\n    \"\"\"\n    selected_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n    max_beat_time = int(round(2.0 / window_size))\n    hist_all = np.zeros((max_beat_time,))\n    for (ii, i) in enumerate(selected_features):\n        dif_threshold = 2.0 * np.abs(short_features[i, 0:-1] - short_features[i, 1:]).mean()\n        if dif_threshold <= 0:\n            dif_threshold = 1e-16\n        [pos1, _] = utilities.peakdet(short_features[i, :], dif_threshold)\n        position_diffs = []\n        for j in range(len(pos1) - 1):\n            position_diffs.append(pos1[j + 1] - pos1[j])\n        (histogram_times, histogram_edges) = np.histogram(position_diffs, np.arange(0.5, max_beat_time + 1.5))\n        hist_centers = (histogram_edges[0:-1] + histogram_edges[1:]) / 2.0\n        histogram_times = histogram_times.astype(float) / short_features.shape[1]\n        hist_all += histogram_times\n        if plot:\n            plt.subplot(9, 2, ii + 1)\n            plt.plot(short_features[i, :], 'k')\n            for k in pos1:\n                plt.plot(k, short_features[i, k], 'k*')\n            f1 = plt.gca()\n            f1.axes.get_xaxis().set_ticks([])\n            f1.axes.get_yaxis().set_ticks([])\n    if plot:\n        plt.show(block=False)\n        plt.figure()\n    max_indices = np.argmax(hist_all)\n    bpms = 60 / (hist_centers * window_size)\n    bpm = bpms[max_indices]\n    ratio = hist_all[max_indices] / (hist_all.sum() + eps)\n    if plot:\n        hist_all = hist_all[bpms < 500]\n        bpms = bpms[bpms < 500]\n        plt.plot(bpms, hist_all, 'k')\n        plt.xlabel('Beats per minute')\n        plt.ylabel('Freq Count')\n        plt.show(block=True)\n    return (bpm, ratio)",
        "mutated": [
            "def beat_extraction(short_features, window_size, plot=False):\n    if False:\n        i = 10\n    '\\n    This function extracts an estimate of the beat rate for a musical signal.\\n    ARGUMENTS:\\n     - short_features:     a np array (n_feats x numOfShortTermWindows)\\n     - window_size:        window size in seconds\\n    RETURNS:\\n     - bpm:            estimates of beats per minute\\n     - ratio:          a confidence measure\\n    '\n    selected_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n    max_beat_time = int(round(2.0 / window_size))\n    hist_all = np.zeros((max_beat_time,))\n    for (ii, i) in enumerate(selected_features):\n        dif_threshold = 2.0 * np.abs(short_features[i, 0:-1] - short_features[i, 1:]).mean()\n        if dif_threshold <= 0:\n            dif_threshold = 1e-16\n        [pos1, _] = utilities.peakdet(short_features[i, :], dif_threshold)\n        position_diffs = []\n        for j in range(len(pos1) - 1):\n            position_diffs.append(pos1[j + 1] - pos1[j])\n        (histogram_times, histogram_edges) = np.histogram(position_diffs, np.arange(0.5, max_beat_time + 1.5))\n        hist_centers = (histogram_edges[0:-1] + histogram_edges[1:]) / 2.0\n        histogram_times = histogram_times.astype(float) / short_features.shape[1]\n        hist_all += histogram_times\n        if plot:\n            plt.subplot(9, 2, ii + 1)\n            plt.plot(short_features[i, :], 'k')\n            for k in pos1:\n                plt.plot(k, short_features[i, k], 'k*')\n            f1 = plt.gca()\n            f1.axes.get_xaxis().set_ticks([])\n            f1.axes.get_yaxis().set_ticks([])\n    if plot:\n        plt.show(block=False)\n        plt.figure()\n    max_indices = np.argmax(hist_all)\n    bpms = 60 / (hist_centers * window_size)\n    bpm = bpms[max_indices]\n    ratio = hist_all[max_indices] / (hist_all.sum() + eps)\n    if plot:\n        hist_all = hist_all[bpms < 500]\n        bpms = bpms[bpms < 500]\n        plt.plot(bpms, hist_all, 'k')\n        plt.xlabel('Beats per minute')\n        plt.ylabel('Freq Count')\n        plt.show(block=True)\n    return (bpm, ratio)",
            "def beat_extraction(short_features, window_size, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    This function extracts an estimate of the beat rate for a musical signal.\\n    ARGUMENTS:\\n     - short_features:     a np array (n_feats x numOfShortTermWindows)\\n     - window_size:        window size in seconds\\n    RETURNS:\\n     - bpm:            estimates of beats per minute\\n     - ratio:          a confidence measure\\n    '\n    selected_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n    max_beat_time = int(round(2.0 / window_size))\n    hist_all = np.zeros((max_beat_time,))\n    for (ii, i) in enumerate(selected_features):\n        dif_threshold = 2.0 * np.abs(short_features[i, 0:-1] - short_features[i, 1:]).mean()\n        if dif_threshold <= 0:\n            dif_threshold = 1e-16\n        [pos1, _] = utilities.peakdet(short_features[i, :], dif_threshold)\n        position_diffs = []\n        for j in range(len(pos1) - 1):\n            position_diffs.append(pos1[j + 1] - pos1[j])\n        (histogram_times, histogram_edges) = np.histogram(position_diffs, np.arange(0.5, max_beat_time + 1.5))\n        hist_centers = (histogram_edges[0:-1] + histogram_edges[1:]) / 2.0\n        histogram_times = histogram_times.astype(float) / short_features.shape[1]\n        hist_all += histogram_times\n        if plot:\n            plt.subplot(9, 2, ii + 1)\n            plt.plot(short_features[i, :], 'k')\n            for k in pos1:\n                plt.plot(k, short_features[i, k], 'k*')\n            f1 = plt.gca()\n            f1.axes.get_xaxis().set_ticks([])\n            f1.axes.get_yaxis().set_ticks([])\n    if plot:\n        plt.show(block=False)\n        plt.figure()\n    max_indices = np.argmax(hist_all)\n    bpms = 60 / (hist_centers * window_size)\n    bpm = bpms[max_indices]\n    ratio = hist_all[max_indices] / (hist_all.sum() + eps)\n    if plot:\n        hist_all = hist_all[bpms < 500]\n        bpms = bpms[bpms < 500]\n        plt.plot(bpms, hist_all, 'k')\n        plt.xlabel('Beats per minute')\n        plt.ylabel('Freq Count')\n        plt.show(block=True)\n    return (bpm, ratio)",
            "def beat_extraction(short_features, window_size, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    This function extracts an estimate of the beat rate for a musical signal.\\n    ARGUMENTS:\\n     - short_features:     a np array (n_feats x numOfShortTermWindows)\\n     - window_size:        window size in seconds\\n    RETURNS:\\n     - bpm:            estimates of beats per minute\\n     - ratio:          a confidence measure\\n    '\n    selected_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n    max_beat_time = int(round(2.0 / window_size))\n    hist_all = np.zeros((max_beat_time,))\n    for (ii, i) in enumerate(selected_features):\n        dif_threshold = 2.0 * np.abs(short_features[i, 0:-1] - short_features[i, 1:]).mean()\n        if dif_threshold <= 0:\n            dif_threshold = 1e-16\n        [pos1, _] = utilities.peakdet(short_features[i, :], dif_threshold)\n        position_diffs = []\n        for j in range(len(pos1) - 1):\n            position_diffs.append(pos1[j + 1] - pos1[j])\n        (histogram_times, histogram_edges) = np.histogram(position_diffs, np.arange(0.5, max_beat_time + 1.5))\n        hist_centers = (histogram_edges[0:-1] + histogram_edges[1:]) / 2.0\n        histogram_times = histogram_times.astype(float) / short_features.shape[1]\n        hist_all += histogram_times\n        if plot:\n            plt.subplot(9, 2, ii + 1)\n            plt.plot(short_features[i, :], 'k')\n            for k in pos1:\n                plt.plot(k, short_features[i, k], 'k*')\n            f1 = plt.gca()\n            f1.axes.get_xaxis().set_ticks([])\n            f1.axes.get_yaxis().set_ticks([])\n    if plot:\n        plt.show(block=False)\n        plt.figure()\n    max_indices = np.argmax(hist_all)\n    bpms = 60 / (hist_centers * window_size)\n    bpm = bpms[max_indices]\n    ratio = hist_all[max_indices] / (hist_all.sum() + eps)\n    if plot:\n        hist_all = hist_all[bpms < 500]\n        bpms = bpms[bpms < 500]\n        plt.plot(bpms, hist_all, 'k')\n        plt.xlabel('Beats per minute')\n        plt.ylabel('Freq Count')\n        plt.show(block=True)\n    return (bpm, ratio)",
            "def beat_extraction(short_features, window_size, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    This function extracts an estimate of the beat rate for a musical signal.\\n    ARGUMENTS:\\n     - short_features:     a np array (n_feats x numOfShortTermWindows)\\n     - window_size:        window size in seconds\\n    RETURNS:\\n     - bpm:            estimates of beats per minute\\n     - ratio:          a confidence measure\\n    '\n    selected_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n    max_beat_time = int(round(2.0 / window_size))\n    hist_all = np.zeros((max_beat_time,))\n    for (ii, i) in enumerate(selected_features):\n        dif_threshold = 2.0 * np.abs(short_features[i, 0:-1] - short_features[i, 1:]).mean()\n        if dif_threshold <= 0:\n            dif_threshold = 1e-16\n        [pos1, _] = utilities.peakdet(short_features[i, :], dif_threshold)\n        position_diffs = []\n        for j in range(len(pos1) - 1):\n            position_diffs.append(pos1[j + 1] - pos1[j])\n        (histogram_times, histogram_edges) = np.histogram(position_diffs, np.arange(0.5, max_beat_time + 1.5))\n        hist_centers = (histogram_edges[0:-1] + histogram_edges[1:]) / 2.0\n        histogram_times = histogram_times.astype(float) / short_features.shape[1]\n        hist_all += histogram_times\n        if plot:\n            plt.subplot(9, 2, ii + 1)\n            plt.plot(short_features[i, :], 'k')\n            for k in pos1:\n                plt.plot(k, short_features[i, k], 'k*')\n            f1 = plt.gca()\n            f1.axes.get_xaxis().set_ticks([])\n            f1.axes.get_yaxis().set_ticks([])\n    if plot:\n        plt.show(block=False)\n        plt.figure()\n    max_indices = np.argmax(hist_all)\n    bpms = 60 / (hist_centers * window_size)\n    bpm = bpms[max_indices]\n    ratio = hist_all[max_indices] / (hist_all.sum() + eps)\n    if plot:\n        hist_all = hist_all[bpms < 500]\n        bpms = bpms[bpms < 500]\n        plt.plot(bpms, hist_all, 'k')\n        plt.xlabel('Beats per minute')\n        plt.ylabel('Freq Count')\n        plt.show(block=True)\n    return (bpm, ratio)",
            "def beat_extraction(short_features, window_size, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    This function extracts an estimate of the beat rate for a musical signal.\\n    ARGUMENTS:\\n     - short_features:     a np array (n_feats x numOfShortTermWindows)\\n     - window_size:        window size in seconds\\n    RETURNS:\\n     - bpm:            estimates of beats per minute\\n     - ratio:          a confidence measure\\n    '\n    selected_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n    max_beat_time = int(round(2.0 / window_size))\n    hist_all = np.zeros((max_beat_time,))\n    for (ii, i) in enumerate(selected_features):\n        dif_threshold = 2.0 * np.abs(short_features[i, 0:-1] - short_features[i, 1:]).mean()\n        if dif_threshold <= 0:\n            dif_threshold = 1e-16\n        [pos1, _] = utilities.peakdet(short_features[i, :], dif_threshold)\n        position_diffs = []\n        for j in range(len(pos1) - 1):\n            position_diffs.append(pos1[j + 1] - pos1[j])\n        (histogram_times, histogram_edges) = np.histogram(position_diffs, np.arange(0.5, max_beat_time + 1.5))\n        hist_centers = (histogram_edges[0:-1] + histogram_edges[1:]) / 2.0\n        histogram_times = histogram_times.astype(float) / short_features.shape[1]\n        hist_all += histogram_times\n        if plot:\n            plt.subplot(9, 2, ii + 1)\n            plt.plot(short_features[i, :], 'k')\n            for k in pos1:\n                plt.plot(k, short_features[i, k], 'k*')\n            f1 = plt.gca()\n            f1.axes.get_xaxis().set_ticks([])\n            f1.axes.get_yaxis().set_ticks([])\n    if plot:\n        plt.show(block=False)\n        plt.figure()\n    max_indices = np.argmax(hist_all)\n    bpms = 60 / (hist_centers * window_size)\n    bpm = bpms[max_indices]\n    ratio = hist_all[max_indices] / (hist_all.sum() + eps)\n    if plot:\n        hist_all = hist_all[bpms < 500]\n        bpms = bpms[bpms < 500]\n        plt.plot(bpms, hist_all, 'k')\n        plt.xlabel('Beats per minute')\n        plt.ylabel('Freq Count')\n        plt.show(block=True)\n    return (bpm, ratio)"
        ]
    },
    {
        "func_name": "mid_feature_extraction",
        "original": "def mid_feature_extraction(signal, sampling_rate, mid_window, mid_step, short_window, short_step):\n    \"\"\"\n    Mid-term feature extraction\n    \"\"\"\n    (short_features, short_feature_names) = ShortTermFeatures.feature_extraction(signal, sampling_rate, short_window, short_step)\n    n_stats = 2\n    n_feats = len(short_features)\n    mid_window_ratio = round((mid_window - (short_window - short_step)) / short_step)\n    mt_step_ratio = int(round(mid_step / short_step))\n    (mid_features, mid_feature_names) = ([], [])\n    for i in range(n_stats * n_feats):\n        mid_features.append([])\n        mid_feature_names.append('')\n    for i in range(n_feats):\n        cur_position = 0\n        num_short_features = len(short_features[i])\n        mid_feature_names[i] = short_feature_names[i] + '_' + 'mean'\n        mid_feature_names[i + n_feats] = short_feature_names[i] + '_' + 'std'\n        while cur_position < num_short_features:\n            end = cur_position + mid_window_ratio\n            if end > num_short_features:\n                end = num_short_features\n            cur_st_feats = short_features[i][cur_position:end]\n            mid_features[i].append(np.mean(cur_st_feats))\n            mid_features[i + n_feats].append(np.std(cur_st_feats))\n            cur_position += mt_step_ratio\n    mid_features = np.array(mid_features)\n    mid_features = np.nan_to_num(mid_features)\n    return (mid_features, short_features, mid_feature_names)",
        "mutated": [
            "def mid_feature_extraction(signal, sampling_rate, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n    '\\n    Mid-term feature extraction\\n    '\n    (short_features, short_feature_names) = ShortTermFeatures.feature_extraction(signal, sampling_rate, short_window, short_step)\n    n_stats = 2\n    n_feats = len(short_features)\n    mid_window_ratio = round((mid_window - (short_window - short_step)) / short_step)\n    mt_step_ratio = int(round(mid_step / short_step))\n    (mid_features, mid_feature_names) = ([], [])\n    for i in range(n_stats * n_feats):\n        mid_features.append([])\n        mid_feature_names.append('')\n    for i in range(n_feats):\n        cur_position = 0\n        num_short_features = len(short_features[i])\n        mid_feature_names[i] = short_feature_names[i] + '_' + 'mean'\n        mid_feature_names[i + n_feats] = short_feature_names[i] + '_' + 'std'\n        while cur_position < num_short_features:\n            end = cur_position + mid_window_ratio\n            if end > num_short_features:\n                end = num_short_features\n            cur_st_feats = short_features[i][cur_position:end]\n            mid_features[i].append(np.mean(cur_st_feats))\n            mid_features[i + n_feats].append(np.std(cur_st_feats))\n            cur_position += mt_step_ratio\n    mid_features = np.array(mid_features)\n    mid_features = np.nan_to_num(mid_features)\n    return (mid_features, short_features, mid_feature_names)",
            "def mid_feature_extraction(signal, sampling_rate, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Mid-term feature extraction\\n    '\n    (short_features, short_feature_names) = ShortTermFeatures.feature_extraction(signal, sampling_rate, short_window, short_step)\n    n_stats = 2\n    n_feats = len(short_features)\n    mid_window_ratio = round((mid_window - (short_window - short_step)) / short_step)\n    mt_step_ratio = int(round(mid_step / short_step))\n    (mid_features, mid_feature_names) = ([], [])\n    for i in range(n_stats * n_feats):\n        mid_features.append([])\n        mid_feature_names.append('')\n    for i in range(n_feats):\n        cur_position = 0\n        num_short_features = len(short_features[i])\n        mid_feature_names[i] = short_feature_names[i] + '_' + 'mean'\n        mid_feature_names[i + n_feats] = short_feature_names[i] + '_' + 'std'\n        while cur_position < num_short_features:\n            end = cur_position + mid_window_ratio\n            if end > num_short_features:\n                end = num_short_features\n            cur_st_feats = short_features[i][cur_position:end]\n            mid_features[i].append(np.mean(cur_st_feats))\n            mid_features[i + n_feats].append(np.std(cur_st_feats))\n            cur_position += mt_step_ratio\n    mid_features = np.array(mid_features)\n    mid_features = np.nan_to_num(mid_features)\n    return (mid_features, short_features, mid_feature_names)",
            "def mid_feature_extraction(signal, sampling_rate, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Mid-term feature extraction\\n    '\n    (short_features, short_feature_names) = ShortTermFeatures.feature_extraction(signal, sampling_rate, short_window, short_step)\n    n_stats = 2\n    n_feats = len(short_features)\n    mid_window_ratio = round((mid_window - (short_window - short_step)) / short_step)\n    mt_step_ratio = int(round(mid_step / short_step))\n    (mid_features, mid_feature_names) = ([], [])\n    for i in range(n_stats * n_feats):\n        mid_features.append([])\n        mid_feature_names.append('')\n    for i in range(n_feats):\n        cur_position = 0\n        num_short_features = len(short_features[i])\n        mid_feature_names[i] = short_feature_names[i] + '_' + 'mean'\n        mid_feature_names[i + n_feats] = short_feature_names[i] + '_' + 'std'\n        while cur_position < num_short_features:\n            end = cur_position + mid_window_ratio\n            if end > num_short_features:\n                end = num_short_features\n            cur_st_feats = short_features[i][cur_position:end]\n            mid_features[i].append(np.mean(cur_st_feats))\n            mid_features[i + n_feats].append(np.std(cur_st_feats))\n            cur_position += mt_step_ratio\n    mid_features = np.array(mid_features)\n    mid_features = np.nan_to_num(mid_features)\n    return (mid_features, short_features, mid_feature_names)",
            "def mid_feature_extraction(signal, sampling_rate, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Mid-term feature extraction\\n    '\n    (short_features, short_feature_names) = ShortTermFeatures.feature_extraction(signal, sampling_rate, short_window, short_step)\n    n_stats = 2\n    n_feats = len(short_features)\n    mid_window_ratio = round((mid_window - (short_window - short_step)) / short_step)\n    mt_step_ratio = int(round(mid_step / short_step))\n    (mid_features, mid_feature_names) = ([], [])\n    for i in range(n_stats * n_feats):\n        mid_features.append([])\n        mid_feature_names.append('')\n    for i in range(n_feats):\n        cur_position = 0\n        num_short_features = len(short_features[i])\n        mid_feature_names[i] = short_feature_names[i] + '_' + 'mean'\n        mid_feature_names[i + n_feats] = short_feature_names[i] + '_' + 'std'\n        while cur_position < num_short_features:\n            end = cur_position + mid_window_ratio\n            if end > num_short_features:\n                end = num_short_features\n            cur_st_feats = short_features[i][cur_position:end]\n            mid_features[i].append(np.mean(cur_st_feats))\n            mid_features[i + n_feats].append(np.std(cur_st_feats))\n            cur_position += mt_step_ratio\n    mid_features = np.array(mid_features)\n    mid_features = np.nan_to_num(mid_features)\n    return (mid_features, short_features, mid_feature_names)",
            "def mid_feature_extraction(signal, sampling_rate, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Mid-term feature extraction\\n    '\n    (short_features, short_feature_names) = ShortTermFeatures.feature_extraction(signal, sampling_rate, short_window, short_step)\n    n_stats = 2\n    n_feats = len(short_features)\n    mid_window_ratio = round((mid_window - (short_window - short_step)) / short_step)\n    mt_step_ratio = int(round(mid_step / short_step))\n    (mid_features, mid_feature_names) = ([], [])\n    for i in range(n_stats * n_feats):\n        mid_features.append([])\n        mid_feature_names.append('')\n    for i in range(n_feats):\n        cur_position = 0\n        num_short_features = len(short_features[i])\n        mid_feature_names[i] = short_feature_names[i] + '_' + 'mean'\n        mid_feature_names[i + n_feats] = short_feature_names[i] + '_' + 'std'\n        while cur_position < num_short_features:\n            end = cur_position + mid_window_ratio\n            if end > num_short_features:\n                end = num_short_features\n            cur_st_feats = short_features[i][cur_position:end]\n            mid_features[i].append(np.mean(cur_st_feats))\n            mid_features[i + n_feats].append(np.std(cur_st_feats))\n            cur_position += mt_step_ratio\n    mid_features = np.array(mid_features)\n    mid_features = np.nan_to_num(mid_features)\n    return (mid_features, short_features, mid_feature_names)"
        ]
    },
    {
        "func_name": "directory_feature_extraction",
        "original": "def directory_feature_extraction(folder_path, mid_window, mid_step, short_window, short_step, compute_beat=True):\n    \"\"\"\n    This function extracts the mid-term features of the WAVE files of a \n    particular folder.\n\n    The resulting feature vector is extracted by long-term averaging the\n    mid-term features.\n    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\n\n    ARGUMENTS:\n        - folder_path:        the path of the WAVE directory\n        - mid_window, mid_step:    mid-term window and step (in seconds)\n        - short_window, short_step:    short-term window and step (in seconds)\n    \"\"\"\n    mid_term_features = np.array([])\n    process_times = []\n    types = ('*.wav', '*.aif', '*.aiff', '*.mp3', '*.au', '*.ogg')\n    wav_file_list = []\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    (wav_file_list2, mid_feature_names) = ([], [])\n    for (i, file_path) in enumerate(wav_file_list):\n        print('Analyzing file {0:d} of {1:d}: {2:s}'.format(i + 1, len(wav_file_list), file_path))\n        if os.stat(file_path).st_size == 0:\n            print('   (EMPTY FILE -- SKIPPING)')\n            continue\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        t1 = time.time()\n        signal = audioBasicIO.stereo_to_mono(signal)\n        if signal.shape[0] < float(sampling_rate) / 5:\n            print('  (AUDIO FILE TOO SMALL - SKIPPING)')\n            continue\n        wav_file_list2.append(file_path)\n        if compute_beat:\n            (mid_features, short_features, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n            (beat, beat_conf) = beat_extraction(short_features, short_step)\n        else:\n            (mid_features, _, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_features = np.transpose(mid_features)\n        mid_features = mid_features.mean(axis=0)\n        if not np.isnan(mid_features).any() and (not np.isinf(mid_features).any()):\n            if compute_beat:\n                mid_features = np.append(mid_features, beat)\n                mid_features = np.append(mid_features, beat_conf)\n                mid_feature_names += ['bpm', 'ratio']\n            if len(mid_term_features) == 0:\n                mid_term_features = mid_features\n            else:\n                mid_term_features = np.vstack((mid_term_features, mid_features))\n            t2 = time.time()\n            duration = float(len(signal)) / sampling_rate\n            process_times.append((t2 - t1) / duration)\n    if len(process_times) > 0:\n        print('Feature extraction complexity ratio: {0:.1f} x realtime'.format(1.0 / np.mean(np.array(process_times))))\n    return (mid_term_features, wav_file_list2, mid_feature_names)",
        "mutated": [
            "def directory_feature_extraction(folder_path, mid_window, mid_step, short_window, short_step, compute_beat=True):\n    if False:\n        i = 10\n    '\\n    This function extracts the mid-term features of the WAVE files of a \\n    particular folder.\\n\\n    The resulting feature vector is extracted by long-term averaging the\\n    mid-term features.\\n    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\\n\\n    ARGUMENTS:\\n        - folder_path:        the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    '\n    mid_term_features = np.array([])\n    process_times = []\n    types = ('*.wav', '*.aif', '*.aiff', '*.mp3', '*.au', '*.ogg')\n    wav_file_list = []\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    (wav_file_list2, mid_feature_names) = ([], [])\n    for (i, file_path) in enumerate(wav_file_list):\n        print('Analyzing file {0:d} of {1:d}: {2:s}'.format(i + 1, len(wav_file_list), file_path))\n        if os.stat(file_path).st_size == 0:\n            print('   (EMPTY FILE -- SKIPPING)')\n            continue\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        t1 = time.time()\n        signal = audioBasicIO.stereo_to_mono(signal)\n        if signal.shape[0] < float(sampling_rate) / 5:\n            print('  (AUDIO FILE TOO SMALL - SKIPPING)')\n            continue\n        wav_file_list2.append(file_path)\n        if compute_beat:\n            (mid_features, short_features, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n            (beat, beat_conf) = beat_extraction(short_features, short_step)\n        else:\n            (mid_features, _, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_features = np.transpose(mid_features)\n        mid_features = mid_features.mean(axis=0)\n        if not np.isnan(mid_features).any() and (not np.isinf(mid_features).any()):\n            if compute_beat:\n                mid_features = np.append(mid_features, beat)\n                mid_features = np.append(mid_features, beat_conf)\n                mid_feature_names += ['bpm', 'ratio']\n            if len(mid_term_features) == 0:\n                mid_term_features = mid_features\n            else:\n                mid_term_features = np.vstack((mid_term_features, mid_features))\n            t2 = time.time()\n            duration = float(len(signal)) / sampling_rate\n            process_times.append((t2 - t1) / duration)\n    if len(process_times) > 0:\n        print('Feature extraction complexity ratio: {0:.1f} x realtime'.format(1.0 / np.mean(np.array(process_times))))\n    return (mid_term_features, wav_file_list2, mid_feature_names)",
            "def directory_feature_extraction(folder_path, mid_window, mid_step, short_window, short_step, compute_beat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    This function extracts the mid-term features of the WAVE files of a \\n    particular folder.\\n\\n    The resulting feature vector is extracted by long-term averaging the\\n    mid-term features.\\n    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\\n\\n    ARGUMENTS:\\n        - folder_path:        the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    '\n    mid_term_features = np.array([])\n    process_times = []\n    types = ('*.wav', '*.aif', '*.aiff', '*.mp3', '*.au', '*.ogg')\n    wav_file_list = []\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    (wav_file_list2, mid_feature_names) = ([], [])\n    for (i, file_path) in enumerate(wav_file_list):\n        print('Analyzing file {0:d} of {1:d}: {2:s}'.format(i + 1, len(wav_file_list), file_path))\n        if os.stat(file_path).st_size == 0:\n            print('   (EMPTY FILE -- SKIPPING)')\n            continue\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        t1 = time.time()\n        signal = audioBasicIO.stereo_to_mono(signal)\n        if signal.shape[0] < float(sampling_rate) / 5:\n            print('  (AUDIO FILE TOO SMALL - SKIPPING)')\n            continue\n        wav_file_list2.append(file_path)\n        if compute_beat:\n            (mid_features, short_features, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n            (beat, beat_conf) = beat_extraction(short_features, short_step)\n        else:\n            (mid_features, _, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_features = np.transpose(mid_features)\n        mid_features = mid_features.mean(axis=0)\n        if not np.isnan(mid_features).any() and (not np.isinf(mid_features).any()):\n            if compute_beat:\n                mid_features = np.append(mid_features, beat)\n                mid_features = np.append(mid_features, beat_conf)\n                mid_feature_names += ['bpm', 'ratio']\n            if len(mid_term_features) == 0:\n                mid_term_features = mid_features\n            else:\n                mid_term_features = np.vstack((mid_term_features, mid_features))\n            t2 = time.time()\n            duration = float(len(signal)) / sampling_rate\n            process_times.append((t2 - t1) / duration)\n    if len(process_times) > 0:\n        print('Feature extraction complexity ratio: {0:.1f} x realtime'.format(1.0 / np.mean(np.array(process_times))))\n    return (mid_term_features, wav_file_list2, mid_feature_names)",
            "def directory_feature_extraction(folder_path, mid_window, mid_step, short_window, short_step, compute_beat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    This function extracts the mid-term features of the WAVE files of a \\n    particular folder.\\n\\n    The resulting feature vector is extracted by long-term averaging the\\n    mid-term features.\\n    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\\n\\n    ARGUMENTS:\\n        - folder_path:        the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    '\n    mid_term_features = np.array([])\n    process_times = []\n    types = ('*.wav', '*.aif', '*.aiff', '*.mp3', '*.au', '*.ogg')\n    wav_file_list = []\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    (wav_file_list2, mid_feature_names) = ([], [])\n    for (i, file_path) in enumerate(wav_file_list):\n        print('Analyzing file {0:d} of {1:d}: {2:s}'.format(i + 1, len(wav_file_list), file_path))\n        if os.stat(file_path).st_size == 0:\n            print('   (EMPTY FILE -- SKIPPING)')\n            continue\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        t1 = time.time()\n        signal = audioBasicIO.stereo_to_mono(signal)\n        if signal.shape[0] < float(sampling_rate) / 5:\n            print('  (AUDIO FILE TOO SMALL - SKIPPING)')\n            continue\n        wav_file_list2.append(file_path)\n        if compute_beat:\n            (mid_features, short_features, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n            (beat, beat_conf) = beat_extraction(short_features, short_step)\n        else:\n            (mid_features, _, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_features = np.transpose(mid_features)\n        mid_features = mid_features.mean(axis=0)\n        if not np.isnan(mid_features).any() and (not np.isinf(mid_features).any()):\n            if compute_beat:\n                mid_features = np.append(mid_features, beat)\n                mid_features = np.append(mid_features, beat_conf)\n                mid_feature_names += ['bpm', 'ratio']\n            if len(mid_term_features) == 0:\n                mid_term_features = mid_features\n            else:\n                mid_term_features = np.vstack((mid_term_features, mid_features))\n            t2 = time.time()\n            duration = float(len(signal)) / sampling_rate\n            process_times.append((t2 - t1) / duration)\n    if len(process_times) > 0:\n        print('Feature extraction complexity ratio: {0:.1f} x realtime'.format(1.0 / np.mean(np.array(process_times))))\n    return (mid_term_features, wav_file_list2, mid_feature_names)",
            "def directory_feature_extraction(folder_path, mid_window, mid_step, short_window, short_step, compute_beat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    This function extracts the mid-term features of the WAVE files of a \\n    particular folder.\\n\\n    The resulting feature vector is extracted by long-term averaging the\\n    mid-term features.\\n    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\\n\\n    ARGUMENTS:\\n        - folder_path:        the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    '\n    mid_term_features = np.array([])\n    process_times = []\n    types = ('*.wav', '*.aif', '*.aiff', '*.mp3', '*.au', '*.ogg')\n    wav_file_list = []\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    (wav_file_list2, mid_feature_names) = ([], [])\n    for (i, file_path) in enumerate(wav_file_list):\n        print('Analyzing file {0:d} of {1:d}: {2:s}'.format(i + 1, len(wav_file_list), file_path))\n        if os.stat(file_path).st_size == 0:\n            print('   (EMPTY FILE -- SKIPPING)')\n            continue\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        t1 = time.time()\n        signal = audioBasicIO.stereo_to_mono(signal)\n        if signal.shape[0] < float(sampling_rate) / 5:\n            print('  (AUDIO FILE TOO SMALL - SKIPPING)')\n            continue\n        wav_file_list2.append(file_path)\n        if compute_beat:\n            (mid_features, short_features, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n            (beat, beat_conf) = beat_extraction(short_features, short_step)\n        else:\n            (mid_features, _, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_features = np.transpose(mid_features)\n        mid_features = mid_features.mean(axis=0)\n        if not np.isnan(mid_features).any() and (not np.isinf(mid_features).any()):\n            if compute_beat:\n                mid_features = np.append(mid_features, beat)\n                mid_features = np.append(mid_features, beat_conf)\n                mid_feature_names += ['bpm', 'ratio']\n            if len(mid_term_features) == 0:\n                mid_term_features = mid_features\n            else:\n                mid_term_features = np.vstack((mid_term_features, mid_features))\n            t2 = time.time()\n            duration = float(len(signal)) / sampling_rate\n            process_times.append((t2 - t1) / duration)\n    if len(process_times) > 0:\n        print('Feature extraction complexity ratio: {0:.1f} x realtime'.format(1.0 / np.mean(np.array(process_times))))\n    return (mid_term_features, wav_file_list2, mid_feature_names)",
            "def directory_feature_extraction(folder_path, mid_window, mid_step, short_window, short_step, compute_beat=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    This function extracts the mid-term features of the WAVE files of a \\n    particular folder.\\n\\n    The resulting feature vector is extracted by long-term averaging the\\n    mid-term features.\\n    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\\n\\n    ARGUMENTS:\\n        - folder_path:        the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    '\n    mid_term_features = np.array([])\n    process_times = []\n    types = ('*.wav', '*.aif', '*.aiff', '*.mp3', '*.au', '*.ogg')\n    wav_file_list = []\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    (wav_file_list2, mid_feature_names) = ([], [])\n    for (i, file_path) in enumerate(wav_file_list):\n        print('Analyzing file {0:d} of {1:d}: {2:s}'.format(i + 1, len(wav_file_list), file_path))\n        if os.stat(file_path).st_size == 0:\n            print('   (EMPTY FILE -- SKIPPING)')\n            continue\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        t1 = time.time()\n        signal = audioBasicIO.stereo_to_mono(signal)\n        if signal.shape[0] < float(sampling_rate) / 5:\n            print('  (AUDIO FILE TOO SMALL - SKIPPING)')\n            continue\n        wav_file_list2.append(file_path)\n        if compute_beat:\n            (mid_features, short_features, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n            (beat, beat_conf) = beat_extraction(short_features, short_step)\n        else:\n            (mid_features, _, mid_feature_names) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_features = np.transpose(mid_features)\n        mid_features = mid_features.mean(axis=0)\n        if not np.isnan(mid_features).any() and (not np.isinf(mid_features).any()):\n            if compute_beat:\n                mid_features = np.append(mid_features, beat)\n                mid_features = np.append(mid_features, beat_conf)\n                mid_feature_names += ['bpm', 'ratio']\n            if len(mid_term_features) == 0:\n                mid_term_features = mid_features\n            else:\n                mid_term_features = np.vstack((mid_term_features, mid_features))\n            t2 = time.time()\n            duration = float(len(signal)) / sampling_rate\n            process_times.append((t2 - t1) / duration)\n    if len(process_times) > 0:\n        print('Feature extraction complexity ratio: {0:.1f} x realtime'.format(1.0 / np.mean(np.array(process_times))))\n    return (mid_term_features, wav_file_list2, mid_feature_names)"
        ]
    },
    {
        "func_name": "multiple_directory_feature_extraction",
        "original": "def multiple_directory_feature_extraction(path_list, mid_window, mid_step, short_window, short_step, compute_beat=False):\n    \"\"\"\n    Same as dirWavFeatureExtraction, but instead of a single dir it\n    takes a list of paths as input and returns a list of feature matrices.\n    EXAMPLE:\n    [features, classNames] =\n           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise',\n                                       'audioData/classSegmentsRec/speech',\n                                       'audioData/classSegmentsRec/brush-teeth',\n                                       'audioData/classSegmentsRec/shower'], 1, \n                                       1, 0.02, 0.02);\n\n    It can be used during the training process of a classification model ,\n    in order to get feature matrices from various audio classes (each stored in\n    a separate path)\n    \"\"\"\n    features = []\n    class_names = []\n    file_names = []\n    for (i, d) in enumerate(path_list):\n        (f, fn, feature_names) = directory_feature_extraction(d, mid_window, mid_step, short_window, short_step, compute_beat=compute_beat)\n        if f.shape[0] > 0:\n            features.append(f)\n            file_names.append(fn)\n            if d[-1] == os.sep:\n                class_names.append(d.split(os.sep)[-2])\n            else:\n                class_names.append(d.split(os.sep)[-1])\n    return (features, class_names, file_names)",
        "mutated": [
            "def multiple_directory_feature_extraction(path_list, mid_window, mid_step, short_window, short_step, compute_beat=False):\n    if False:\n        i = 10\n    \"\\n    Same as dirWavFeatureExtraction, but instead of a single dir it\\n    takes a list of paths as input and returns a list of feature matrices.\\n    EXAMPLE:\\n    [features, classNames] =\\n           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise',\\n                                       'audioData/classSegmentsRec/speech',\\n                                       'audioData/classSegmentsRec/brush-teeth',\\n                                       'audioData/classSegmentsRec/shower'], 1, \\n                                       1, 0.02, 0.02);\\n\\n    It can be used during the training process of a classification model ,\\n    in order to get feature matrices from various audio classes (each stored in\\n    a separate path)\\n    \"\n    features = []\n    class_names = []\n    file_names = []\n    for (i, d) in enumerate(path_list):\n        (f, fn, feature_names) = directory_feature_extraction(d, mid_window, mid_step, short_window, short_step, compute_beat=compute_beat)\n        if f.shape[0] > 0:\n            features.append(f)\n            file_names.append(fn)\n            if d[-1] == os.sep:\n                class_names.append(d.split(os.sep)[-2])\n            else:\n                class_names.append(d.split(os.sep)[-1])\n    return (features, class_names, file_names)",
            "def multiple_directory_feature_extraction(path_list, mid_window, mid_step, short_window, short_step, compute_beat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Same as dirWavFeatureExtraction, but instead of a single dir it\\n    takes a list of paths as input and returns a list of feature matrices.\\n    EXAMPLE:\\n    [features, classNames] =\\n           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise',\\n                                       'audioData/classSegmentsRec/speech',\\n                                       'audioData/classSegmentsRec/brush-teeth',\\n                                       'audioData/classSegmentsRec/shower'], 1, \\n                                       1, 0.02, 0.02);\\n\\n    It can be used during the training process of a classification model ,\\n    in order to get feature matrices from various audio classes (each stored in\\n    a separate path)\\n    \"\n    features = []\n    class_names = []\n    file_names = []\n    for (i, d) in enumerate(path_list):\n        (f, fn, feature_names) = directory_feature_extraction(d, mid_window, mid_step, short_window, short_step, compute_beat=compute_beat)\n        if f.shape[0] > 0:\n            features.append(f)\n            file_names.append(fn)\n            if d[-1] == os.sep:\n                class_names.append(d.split(os.sep)[-2])\n            else:\n                class_names.append(d.split(os.sep)[-1])\n    return (features, class_names, file_names)",
            "def multiple_directory_feature_extraction(path_list, mid_window, mid_step, short_window, short_step, compute_beat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Same as dirWavFeatureExtraction, but instead of a single dir it\\n    takes a list of paths as input and returns a list of feature matrices.\\n    EXAMPLE:\\n    [features, classNames] =\\n           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise',\\n                                       'audioData/classSegmentsRec/speech',\\n                                       'audioData/classSegmentsRec/brush-teeth',\\n                                       'audioData/classSegmentsRec/shower'], 1, \\n                                       1, 0.02, 0.02);\\n\\n    It can be used during the training process of a classification model ,\\n    in order to get feature matrices from various audio classes (each stored in\\n    a separate path)\\n    \"\n    features = []\n    class_names = []\n    file_names = []\n    for (i, d) in enumerate(path_list):\n        (f, fn, feature_names) = directory_feature_extraction(d, mid_window, mid_step, short_window, short_step, compute_beat=compute_beat)\n        if f.shape[0] > 0:\n            features.append(f)\n            file_names.append(fn)\n            if d[-1] == os.sep:\n                class_names.append(d.split(os.sep)[-2])\n            else:\n                class_names.append(d.split(os.sep)[-1])\n    return (features, class_names, file_names)",
            "def multiple_directory_feature_extraction(path_list, mid_window, mid_step, short_window, short_step, compute_beat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Same as dirWavFeatureExtraction, but instead of a single dir it\\n    takes a list of paths as input and returns a list of feature matrices.\\n    EXAMPLE:\\n    [features, classNames] =\\n           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise',\\n                                       'audioData/classSegmentsRec/speech',\\n                                       'audioData/classSegmentsRec/brush-teeth',\\n                                       'audioData/classSegmentsRec/shower'], 1, \\n                                       1, 0.02, 0.02);\\n\\n    It can be used during the training process of a classification model ,\\n    in order to get feature matrices from various audio classes (each stored in\\n    a separate path)\\n    \"\n    features = []\n    class_names = []\n    file_names = []\n    for (i, d) in enumerate(path_list):\n        (f, fn, feature_names) = directory_feature_extraction(d, mid_window, mid_step, short_window, short_step, compute_beat=compute_beat)\n        if f.shape[0] > 0:\n            features.append(f)\n            file_names.append(fn)\n            if d[-1] == os.sep:\n                class_names.append(d.split(os.sep)[-2])\n            else:\n                class_names.append(d.split(os.sep)[-1])\n    return (features, class_names, file_names)",
            "def multiple_directory_feature_extraction(path_list, mid_window, mid_step, short_window, short_step, compute_beat=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Same as dirWavFeatureExtraction, but instead of a single dir it\\n    takes a list of paths as input and returns a list of feature matrices.\\n    EXAMPLE:\\n    [features, classNames] =\\n           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise',\\n                                       'audioData/classSegmentsRec/speech',\\n                                       'audioData/classSegmentsRec/brush-teeth',\\n                                       'audioData/classSegmentsRec/shower'], 1, \\n                                       1, 0.02, 0.02);\\n\\n    It can be used during the training process of a classification model ,\\n    in order to get feature matrices from various audio classes (each stored in\\n    a separate path)\\n    \"\n    features = []\n    class_names = []\n    file_names = []\n    for (i, d) in enumerate(path_list):\n        (f, fn, feature_names) = directory_feature_extraction(d, mid_window, mid_step, short_window, short_step, compute_beat=compute_beat)\n        if f.shape[0] > 0:\n            features.append(f)\n            file_names.append(fn)\n            if d[-1] == os.sep:\n                class_names.append(d.split(os.sep)[-2])\n            else:\n                class_names.append(d.split(os.sep)[-1])\n    return (features, class_names, file_names)"
        ]
    },
    {
        "func_name": "directory_feature_extraction_no_avg",
        "original": "def directory_feature_extraction_no_avg(folder_path, mid_window, mid_step, short_window, short_step):\n    \"\"\"\n    This function extracts the mid-term features of the WAVE\n    files of a particular folder without averaging each file.\n\n    ARGUMENTS:\n        - folder_path:          the path of the WAVE directory\n        - mid_window, mid_step:    mid-term window and step (in seconds)\n        - short_window, short_step:    short-term window and step (in seconds)\n    RETURNS:\n        - X:                A feature matrix\n        - Y:                A matrix of file labels\n        - filenames:\n    \"\"\"\n    wav_file_list = []\n    signal_idx = np.array([])\n    mid_features = np.array([])\n    types = ('*.wav', '*.aif', '*.aiff', '*.ogg')\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    for (i, file_path) in enumerate(wav_file_list):\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        signal = audioBasicIO.stereo_to_mono(signal)\n        (mid_feature_vector, _, _) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_feature_vector = np.transpose(mid_feature_vector)\n        if len(mid_features) == 0:\n            mid_features = mid_feature_vector\n            signal_idx = np.zeros((mid_feature_vector.shape[0],))\n        else:\n            mid_features = np.vstack((mid_features, mid_feature_vector))\n            signal_idx = np.append(signal_idx, i * np.ones((mid_feature_vector.shape[0],)))\n    return (mid_features, signal_idx, wav_file_list)",
        "mutated": [
            "def directory_feature_extraction_no_avg(folder_path, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n    '\\n    This function extracts the mid-term features of the WAVE\\n    files of a particular folder without averaging each file.\\n\\n    ARGUMENTS:\\n        - folder_path:          the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    RETURNS:\\n        - X:                A feature matrix\\n        - Y:                A matrix of file labels\\n        - filenames:\\n    '\n    wav_file_list = []\n    signal_idx = np.array([])\n    mid_features = np.array([])\n    types = ('*.wav', '*.aif', '*.aiff', '*.ogg')\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    for (i, file_path) in enumerate(wav_file_list):\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        signal = audioBasicIO.stereo_to_mono(signal)\n        (mid_feature_vector, _, _) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_feature_vector = np.transpose(mid_feature_vector)\n        if len(mid_features) == 0:\n            mid_features = mid_feature_vector\n            signal_idx = np.zeros((mid_feature_vector.shape[0],))\n        else:\n            mid_features = np.vstack((mid_features, mid_feature_vector))\n            signal_idx = np.append(signal_idx, i * np.ones((mid_feature_vector.shape[0],)))\n    return (mid_features, signal_idx, wav_file_list)",
            "def directory_feature_extraction_no_avg(folder_path, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    This function extracts the mid-term features of the WAVE\\n    files of a particular folder without averaging each file.\\n\\n    ARGUMENTS:\\n        - folder_path:          the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    RETURNS:\\n        - X:                A feature matrix\\n        - Y:                A matrix of file labels\\n        - filenames:\\n    '\n    wav_file_list = []\n    signal_idx = np.array([])\n    mid_features = np.array([])\n    types = ('*.wav', '*.aif', '*.aiff', '*.ogg')\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    for (i, file_path) in enumerate(wav_file_list):\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        signal = audioBasicIO.stereo_to_mono(signal)\n        (mid_feature_vector, _, _) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_feature_vector = np.transpose(mid_feature_vector)\n        if len(mid_features) == 0:\n            mid_features = mid_feature_vector\n            signal_idx = np.zeros((mid_feature_vector.shape[0],))\n        else:\n            mid_features = np.vstack((mid_features, mid_feature_vector))\n            signal_idx = np.append(signal_idx, i * np.ones((mid_feature_vector.shape[0],)))\n    return (mid_features, signal_idx, wav_file_list)",
            "def directory_feature_extraction_no_avg(folder_path, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    This function extracts the mid-term features of the WAVE\\n    files of a particular folder without averaging each file.\\n\\n    ARGUMENTS:\\n        - folder_path:          the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    RETURNS:\\n        - X:                A feature matrix\\n        - Y:                A matrix of file labels\\n        - filenames:\\n    '\n    wav_file_list = []\n    signal_idx = np.array([])\n    mid_features = np.array([])\n    types = ('*.wav', '*.aif', '*.aiff', '*.ogg')\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    for (i, file_path) in enumerate(wav_file_list):\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        signal = audioBasicIO.stereo_to_mono(signal)\n        (mid_feature_vector, _, _) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_feature_vector = np.transpose(mid_feature_vector)\n        if len(mid_features) == 0:\n            mid_features = mid_feature_vector\n            signal_idx = np.zeros((mid_feature_vector.shape[0],))\n        else:\n            mid_features = np.vstack((mid_features, mid_feature_vector))\n            signal_idx = np.append(signal_idx, i * np.ones((mid_feature_vector.shape[0],)))\n    return (mid_features, signal_idx, wav_file_list)",
            "def directory_feature_extraction_no_avg(folder_path, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    This function extracts the mid-term features of the WAVE\\n    files of a particular folder without averaging each file.\\n\\n    ARGUMENTS:\\n        - folder_path:          the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    RETURNS:\\n        - X:                A feature matrix\\n        - Y:                A matrix of file labels\\n        - filenames:\\n    '\n    wav_file_list = []\n    signal_idx = np.array([])\n    mid_features = np.array([])\n    types = ('*.wav', '*.aif', '*.aiff', '*.ogg')\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    for (i, file_path) in enumerate(wav_file_list):\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        signal = audioBasicIO.stereo_to_mono(signal)\n        (mid_feature_vector, _, _) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_feature_vector = np.transpose(mid_feature_vector)\n        if len(mid_features) == 0:\n            mid_features = mid_feature_vector\n            signal_idx = np.zeros((mid_feature_vector.shape[0],))\n        else:\n            mid_features = np.vstack((mid_features, mid_feature_vector))\n            signal_idx = np.append(signal_idx, i * np.ones((mid_feature_vector.shape[0],)))\n    return (mid_features, signal_idx, wav_file_list)",
            "def directory_feature_extraction_no_avg(folder_path, mid_window, mid_step, short_window, short_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    This function extracts the mid-term features of the WAVE\\n    files of a particular folder without averaging each file.\\n\\n    ARGUMENTS:\\n        - folder_path:          the path of the WAVE directory\\n        - mid_window, mid_step:    mid-term window and step (in seconds)\\n        - short_window, short_step:    short-term window and step (in seconds)\\n    RETURNS:\\n        - X:                A feature matrix\\n        - Y:                A matrix of file labels\\n        - filenames:\\n    '\n    wav_file_list = []\n    signal_idx = np.array([])\n    mid_features = np.array([])\n    types = ('*.wav', '*.aif', '*.aiff', '*.ogg')\n    for files in types:\n        wav_file_list.extend(glob.glob(os.path.join(folder_path, files)))\n    wav_file_list = sorted(wav_file_list)\n    for (i, file_path) in enumerate(wav_file_list):\n        (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n        if sampling_rate == 0:\n            continue\n        signal = audioBasicIO.stereo_to_mono(signal)\n        (mid_feature_vector, _, _) = mid_feature_extraction(signal, sampling_rate, round(mid_window * sampling_rate), round(mid_step * sampling_rate), round(sampling_rate * short_window), round(sampling_rate * short_step))\n        mid_feature_vector = np.transpose(mid_feature_vector)\n        if len(mid_features) == 0:\n            mid_features = mid_feature_vector\n            signal_idx = np.zeros((mid_feature_vector.shape[0],))\n        else:\n            mid_features = np.vstack((mid_features, mid_feature_vector))\n            signal_idx = np.append(signal_idx, i * np.ones((mid_feature_vector.shape[0],)))\n    return (mid_features, signal_idx, wav_file_list)"
        ]
    },
    {
        "func_name": "mid_feature_extraction_to_file",
        "original": "def mid_feature_extraction_to_file(file_path, mid_window, mid_step, short_window, short_step, output_file, store_short_features=False, store_csv=False, plot=False):\n    \"\"\"\n    This function is used as a wrapper to:\n    a) read the content of a WAV file\n    b) perform mid-term feature extraction on that signal\n    c) write the mid-term feature sequences to a np file\n    d) optionally write contents to csv file as well\n    e) optionally write short-term features in csv and np file\n    \"\"\"\n    (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n    signal = audioBasicIO.stereo_to_mono(signal)\n    (mid_features, short_features, _) = mid_feature_extraction(signal, sampling_rate, round(sampling_rate * mid_window), round(sampling_rate * mid_step), round(sampling_rate * short_window), round(sampling_rate * short_step))\n    if store_short_features:\n        np.save(output_file + '_st', short_features)\n        if plot:\n            print('Short-term np file: ' + output_file + '_st.npy saved')\n        if store_csv:\n            np.savetxt(output_file + '_st.csv', short_features.T, delimiter=',')\n            if plot:\n                print('Short-term CSV file: ' + output_file + '_st.csv saved')\n    np.save(output_file + '_mt', mid_features)\n    if plot:\n        print('Mid-term np file: ' + output_file + '_mt.npy saved')\n    if store_csv:\n        np.savetxt(output_file + '_mt.csv', mid_features.T, delimiter=',')\n        if plot:\n            print('Mid-term CSV file: ' + output_file + '_mt.csv saved')",
        "mutated": [
            "def mid_feature_extraction_to_file(file_path, mid_window, mid_step, short_window, short_step, output_file, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n    '\\n    This function is used as a wrapper to:\\n    a) read the content of a WAV file\\n    b) perform mid-term feature extraction on that signal\\n    c) write the mid-term feature sequences to a np file\\n    d) optionally write contents to csv file as well\\n    e) optionally write short-term features in csv and np file\\n    '\n    (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n    signal = audioBasicIO.stereo_to_mono(signal)\n    (mid_features, short_features, _) = mid_feature_extraction(signal, sampling_rate, round(sampling_rate * mid_window), round(sampling_rate * mid_step), round(sampling_rate * short_window), round(sampling_rate * short_step))\n    if store_short_features:\n        np.save(output_file + '_st', short_features)\n        if plot:\n            print('Short-term np file: ' + output_file + '_st.npy saved')\n        if store_csv:\n            np.savetxt(output_file + '_st.csv', short_features.T, delimiter=',')\n            if plot:\n                print('Short-term CSV file: ' + output_file + '_st.csv saved')\n    np.save(output_file + '_mt', mid_features)\n    if plot:\n        print('Mid-term np file: ' + output_file + '_mt.npy saved')\n    if store_csv:\n        np.savetxt(output_file + '_mt.csv', mid_features.T, delimiter=',')\n        if plot:\n            print('Mid-term CSV file: ' + output_file + '_mt.csv saved')",
            "def mid_feature_extraction_to_file(file_path, mid_window, mid_step, short_window, short_step, output_file, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    This function is used as a wrapper to:\\n    a) read the content of a WAV file\\n    b) perform mid-term feature extraction on that signal\\n    c) write the mid-term feature sequences to a np file\\n    d) optionally write contents to csv file as well\\n    e) optionally write short-term features in csv and np file\\n    '\n    (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n    signal = audioBasicIO.stereo_to_mono(signal)\n    (mid_features, short_features, _) = mid_feature_extraction(signal, sampling_rate, round(sampling_rate * mid_window), round(sampling_rate * mid_step), round(sampling_rate * short_window), round(sampling_rate * short_step))\n    if store_short_features:\n        np.save(output_file + '_st', short_features)\n        if plot:\n            print('Short-term np file: ' + output_file + '_st.npy saved')\n        if store_csv:\n            np.savetxt(output_file + '_st.csv', short_features.T, delimiter=',')\n            if plot:\n                print('Short-term CSV file: ' + output_file + '_st.csv saved')\n    np.save(output_file + '_mt', mid_features)\n    if plot:\n        print('Mid-term np file: ' + output_file + '_mt.npy saved')\n    if store_csv:\n        np.savetxt(output_file + '_mt.csv', mid_features.T, delimiter=',')\n        if plot:\n            print('Mid-term CSV file: ' + output_file + '_mt.csv saved')",
            "def mid_feature_extraction_to_file(file_path, mid_window, mid_step, short_window, short_step, output_file, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    This function is used as a wrapper to:\\n    a) read the content of a WAV file\\n    b) perform mid-term feature extraction on that signal\\n    c) write the mid-term feature sequences to a np file\\n    d) optionally write contents to csv file as well\\n    e) optionally write short-term features in csv and np file\\n    '\n    (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n    signal = audioBasicIO.stereo_to_mono(signal)\n    (mid_features, short_features, _) = mid_feature_extraction(signal, sampling_rate, round(sampling_rate * mid_window), round(sampling_rate * mid_step), round(sampling_rate * short_window), round(sampling_rate * short_step))\n    if store_short_features:\n        np.save(output_file + '_st', short_features)\n        if plot:\n            print('Short-term np file: ' + output_file + '_st.npy saved')\n        if store_csv:\n            np.savetxt(output_file + '_st.csv', short_features.T, delimiter=',')\n            if plot:\n                print('Short-term CSV file: ' + output_file + '_st.csv saved')\n    np.save(output_file + '_mt', mid_features)\n    if plot:\n        print('Mid-term np file: ' + output_file + '_mt.npy saved')\n    if store_csv:\n        np.savetxt(output_file + '_mt.csv', mid_features.T, delimiter=',')\n        if plot:\n            print('Mid-term CSV file: ' + output_file + '_mt.csv saved')",
            "def mid_feature_extraction_to_file(file_path, mid_window, mid_step, short_window, short_step, output_file, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    This function is used as a wrapper to:\\n    a) read the content of a WAV file\\n    b) perform mid-term feature extraction on that signal\\n    c) write the mid-term feature sequences to a np file\\n    d) optionally write contents to csv file as well\\n    e) optionally write short-term features in csv and np file\\n    '\n    (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n    signal = audioBasicIO.stereo_to_mono(signal)\n    (mid_features, short_features, _) = mid_feature_extraction(signal, sampling_rate, round(sampling_rate * mid_window), round(sampling_rate * mid_step), round(sampling_rate * short_window), round(sampling_rate * short_step))\n    if store_short_features:\n        np.save(output_file + '_st', short_features)\n        if plot:\n            print('Short-term np file: ' + output_file + '_st.npy saved')\n        if store_csv:\n            np.savetxt(output_file + '_st.csv', short_features.T, delimiter=',')\n            if plot:\n                print('Short-term CSV file: ' + output_file + '_st.csv saved')\n    np.save(output_file + '_mt', mid_features)\n    if plot:\n        print('Mid-term np file: ' + output_file + '_mt.npy saved')\n    if store_csv:\n        np.savetxt(output_file + '_mt.csv', mid_features.T, delimiter=',')\n        if plot:\n            print('Mid-term CSV file: ' + output_file + '_mt.csv saved')",
            "def mid_feature_extraction_to_file(file_path, mid_window, mid_step, short_window, short_step, output_file, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    This function is used as a wrapper to:\\n    a) read the content of a WAV file\\n    b) perform mid-term feature extraction on that signal\\n    c) write the mid-term feature sequences to a np file\\n    d) optionally write contents to csv file as well\\n    e) optionally write short-term features in csv and np file\\n    '\n    (sampling_rate, signal) = audioBasicIO.read_audio_file(file_path)\n    signal = audioBasicIO.stereo_to_mono(signal)\n    (mid_features, short_features, _) = mid_feature_extraction(signal, sampling_rate, round(sampling_rate * mid_window), round(sampling_rate * mid_step), round(sampling_rate * short_window), round(sampling_rate * short_step))\n    if store_short_features:\n        np.save(output_file + '_st', short_features)\n        if plot:\n            print('Short-term np file: ' + output_file + '_st.npy saved')\n        if store_csv:\n            np.savetxt(output_file + '_st.csv', short_features.T, delimiter=',')\n            if plot:\n                print('Short-term CSV file: ' + output_file + '_st.csv saved')\n    np.save(output_file + '_mt', mid_features)\n    if plot:\n        print('Mid-term np file: ' + output_file + '_mt.npy saved')\n    if store_csv:\n        np.savetxt(output_file + '_mt.csv', mid_features.T, delimiter=',')\n        if plot:\n            print('Mid-term CSV file: ' + output_file + '_mt.csv saved')"
        ]
    },
    {
        "func_name": "mid_feature_extraction_file_dir",
        "original": "def mid_feature_extraction_file_dir(folder_path, mid_window, mid_step, short_window, short_step, store_short_features=False, store_csv=False, plot=False):\n    types = (folder_path + os.sep + '*.wav',)\n    files_list = []\n    for t in types:\n        files_list.extend(glob.glob(t))\n    for f in files_list:\n        output_path = f\n        mid_feature_extraction_to_file(f, mid_window, mid_step, short_window, short_step, output_path, store_short_features, store_csv, plot)",
        "mutated": [
            "def mid_feature_extraction_file_dir(folder_path, mid_window, mid_step, short_window, short_step, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n    types = (folder_path + os.sep + '*.wav',)\n    files_list = []\n    for t in types:\n        files_list.extend(glob.glob(t))\n    for f in files_list:\n        output_path = f\n        mid_feature_extraction_to_file(f, mid_window, mid_step, short_window, short_step, output_path, store_short_features, store_csv, plot)",
            "def mid_feature_extraction_file_dir(folder_path, mid_window, mid_step, short_window, short_step, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    types = (folder_path + os.sep + '*.wav',)\n    files_list = []\n    for t in types:\n        files_list.extend(glob.glob(t))\n    for f in files_list:\n        output_path = f\n        mid_feature_extraction_to_file(f, mid_window, mid_step, short_window, short_step, output_path, store_short_features, store_csv, plot)",
            "def mid_feature_extraction_file_dir(folder_path, mid_window, mid_step, short_window, short_step, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    types = (folder_path + os.sep + '*.wav',)\n    files_list = []\n    for t in types:\n        files_list.extend(glob.glob(t))\n    for f in files_list:\n        output_path = f\n        mid_feature_extraction_to_file(f, mid_window, mid_step, short_window, short_step, output_path, store_short_features, store_csv, plot)",
            "def mid_feature_extraction_file_dir(folder_path, mid_window, mid_step, short_window, short_step, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    types = (folder_path + os.sep + '*.wav',)\n    files_list = []\n    for t in types:\n        files_list.extend(glob.glob(t))\n    for f in files_list:\n        output_path = f\n        mid_feature_extraction_to_file(f, mid_window, mid_step, short_window, short_step, output_path, store_short_features, store_csv, plot)",
            "def mid_feature_extraction_file_dir(folder_path, mid_window, mid_step, short_window, short_step, store_short_features=False, store_csv=False, plot=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    types = (folder_path + os.sep + '*.wav',)\n    files_list = []\n    for t in types:\n        files_list.extend(glob.glob(t))\n    for f in files_list:\n        output_path = f\n        mid_feature_extraction_to_file(f, mid_window, mid_step, short_window, short_step, output_path, store_short_features, store_csv, plot)"
        ]
    }
]