[
    {
        "func_name": "create_application",
        "original": "@Experimental\ndef create_application(name: str, release_label: str, application_type: Literal['Spark', 'Hive']='Spark', initial_capacity: Optional[Dict[str, str]]=None, maximum_capacity: Optional[Dict[str, str]]=None, tags: Optional[Dict[str, str]]=None, autostart: bool=True, autostop: bool=True, idle_timeout: int=15, network_configuration: Optional[Dict[str, str]]=None, architecture: Literal['ARM64', 'X86_64']='X86_64', image_uri: Optional[str]=None, worker_type_specifications: Optional[Dict[str, str]]=None, boto3_session: Optional[boto3.Session]=None) -> str:\n    \"\"\"\n    Create an EMR Serverless application.\n\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\n\n    Parameters\n    ----------\n    name : str\n        Name of EMR Serverless appliation\n    release_label : str\n        Release label e.g. `emr-6.10.0`\n    application_type : str, optional\n        Application type: \"Spark\" or \"Hive\". Defaults to \"Spark\".\n    initial_capacity : Dict[str, str], optional\n        The capacity to initialize when the application is created.\n    maximum_capacity : Dict[str, str], optional\n        The maximum capacity to allocate when the application is created.\n        This is cumulative across all workers at any given point in time,\n        not just when an application is created. No new resources will\n        be created once any one of the defined limits is hit.\n    tags : Dict[str, str], optional\n        Key/Value collection to put tags on the application.\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\n    autostart : bool, optional\n        Enables the application to automatically start on job submission. Defaults to true.\n    autostop : bool, optional\n        Enables the application to automatically stop after a certain amount of time being idle. Defaults to true.\n    idle_timeout : int, optional\n        The amount of idle time in minutes after which your application will automatically stop. Defaults to 15 minutes.\n    network_configuration : Dict[str, str], optional\n        The network configuration for customer VPC connectivity.\n    architecture : str, optional\n        The CPU architecture of an application: \"ARM64\" or \"X86_64\". Defaults to \"X86_64\".\n    image_uri : str, optional\n        The URI of an image in the Amazon ECR registry.\n    worker_type_specifications : Dict[str, str], optional\n        The key-value pairs that specify worker type.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    str\n        Application Id.\n    \"\"\"\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    application_args: Dict[str, Any] = {'name': name, 'releaseLabel': release_label, 'type': application_type, 'autoStartConfiguration': {'enabled': autostart}, 'autoStopConfiguration': {'enabled': autostop, 'idleTimeoutMinutes': idle_timeout}, 'architecture': architecture}\n    if initial_capacity:\n        application_args['initialCapacity'] = initial_capacity\n    if maximum_capacity:\n        application_args['maximumCapacity'] = maximum_capacity\n    if tags:\n        application_args['tags'] = tags\n    if network_configuration:\n        application_args['networkConfiguration'] = network_configuration\n    if worker_type_specifications:\n        application_args['workerTypeSpecifications'] = worker_type_specifications\n    if image_uri:\n        application_args['imageConfiguration'] = {'imageUri': image_uri}\n    response: Dict[str, str] = emr_serverless.create_application(**application_args)\n    _logger.debug('response: \\n%s', pprint.pformat(response))\n    return response['applicationId']",
        "mutated": [
            "@Experimental\ndef create_application(name: str, release_label: str, application_type: Literal['Spark', 'Hive']='Spark', initial_capacity: Optional[Dict[str, str]]=None, maximum_capacity: Optional[Dict[str, str]]=None, tags: Optional[Dict[str, str]]=None, autostart: bool=True, autostop: bool=True, idle_timeout: int=15, network_configuration: Optional[Dict[str, str]]=None, architecture: Literal['ARM64', 'X86_64']='X86_64', image_uri: Optional[str]=None, worker_type_specifications: Optional[Dict[str, str]]=None, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n    '\\n    Create an EMR Serverless application.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Name of EMR Serverless appliation\\n    release_label : str\\n        Release label e.g. `emr-6.10.0`\\n    application_type : str, optional\\n        Application type: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    initial_capacity : Dict[str, str], optional\\n        The capacity to initialize when the application is created.\\n    maximum_capacity : Dict[str, str], optional\\n        The maximum capacity to allocate when the application is created.\\n        This is cumulative across all workers at any given point in time,\\n        not just when an application is created. No new resources will\\n        be created once any one of the defined limits is hit.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    autostart : bool, optional\\n        Enables the application to automatically start on job submission. Defaults to true.\\n    autostop : bool, optional\\n        Enables the application to automatically stop after a certain amount of time being idle. Defaults to true.\\n    idle_timeout : int, optional\\n        The amount of idle time in minutes after which your application will automatically stop. Defaults to 15 minutes.\\n    network_configuration : Dict[str, str], optional\\n        The network configuration for customer VPC connectivity.\\n    architecture : str, optional\\n        The CPU architecture of an application: \"ARM64\" or \"X86_64\". Defaults to \"X86_64\".\\n    image_uri : str, optional\\n        The URI of an image in the Amazon ECR registry.\\n    worker_type_specifications : Dict[str, str], optional\\n        The key-value pairs that specify worker type.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Application Id.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    application_args: Dict[str, Any] = {'name': name, 'releaseLabel': release_label, 'type': application_type, 'autoStartConfiguration': {'enabled': autostart}, 'autoStopConfiguration': {'enabled': autostop, 'idleTimeoutMinutes': idle_timeout}, 'architecture': architecture}\n    if initial_capacity:\n        application_args['initialCapacity'] = initial_capacity\n    if maximum_capacity:\n        application_args['maximumCapacity'] = maximum_capacity\n    if tags:\n        application_args['tags'] = tags\n    if network_configuration:\n        application_args['networkConfiguration'] = network_configuration\n    if worker_type_specifications:\n        application_args['workerTypeSpecifications'] = worker_type_specifications\n    if image_uri:\n        application_args['imageConfiguration'] = {'imageUri': image_uri}\n    response: Dict[str, str] = emr_serverless.create_application(**application_args)\n    _logger.debug('response: \\n%s', pprint.pformat(response))\n    return response['applicationId']",
            "@Experimental\ndef create_application(name: str, release_label: str, application_type: Literal['Spark', 'Hive']='Spark', initial_capacity: Optional[Dict[str, str]]=None, maximum_capacity: Optional[Dict[str, str]]=None, tags: Optional[Dict[str, str]]=None, autostart: bool=True, autostop: bool=True, idle_timeout: int=15, network_configuration: Optional[Dict[str, str]]=None, architecture: Literal['ARM64', 'X86_64']='X86_64', image_uri: Optional[str]=None, worker_type_specifications: Optional[Dict[str, str]]=None, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Create an EMR Serverless application.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Name of EMR Serverless appliation\\n    release_label : str\\n        Release label e.g. `emr-6.10.0`\\n    application_type : str, optional\\n        Application type: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    initial_capacity : Dict[str, str], optional\\n        The capacity to initialize when the application is created.\\n    maximum_capacity : Dict[str, str], optional\\n        The maximum capacity to allocate when the application is created.\\n        This is cumulative across all workers at any given point in time,\\n        not just when an application is created. No new resources will\\n        be created once any one of the defined limits is hit.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    autostart : bool, optional\\n        Enables the application to automatically start on job submission. Defaults to true.\\n    autostop : bool, optional\\n        Enables the application to automatically stop after a certain amount of time being idle. Defaults to true.\\n    idle_timeout : int, optional\\n        The amount of idle time in minutes after which your application will automatically stop. Defaults to 15 minutes.\\n    network_configuration : Dict[str, str], optional\\n        The network configuration for customer VPC connectivity.\\n    architecture : str, optional\\n        The CPU architecture of an application: \"ARM64\" or \"X86_64\". Defaults to \"X86_64\".\\n    image_uri : str, optional\\n        The URI of an image in the Amazon ECR registry.\\n    worker_type_specifications : Dict[str, str], optional\\n        The key-value pairs that specify worker type.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Application Id.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    application_args: Dict[str, Any] = {'name': name, 'releaseLabel': release_label, 'type': application_type, 'autoStartConfiguration': {'enabled': autostart}, 'autoStopConfiguration': {'enabled': autostop, 'idleTimeoutMinutes': idle_timeout}, 'architecture': architecture}\n    if initial_capacity:\n        application_args['initialCapacity'] = initial_capacity\n    if maximum_capacity:\n        application_args['maximumCapacity'] = maximum_capacity\n    if tags:\n        application_args['tags'] = tags\n    if network_configuration:\n        application_args['networkConfiguration'] = network_configuration\n    if worker_type_specifications:\n        application_args['workerTypeSpecifications'] = worker_type_specifications\n    if image_uri:\n        application_args['imageConfiguration'] = {'imageUri': image_uri}\n    response: Dict[str, str] = emr_serverless.create_application(**application_args)\n    _logger.debug('response: \\n%s', pprint.pformat(response))\n    return response['applicationId']",
            "@Experimental\ndef create_application(name: str, release_label: str, application_type: Literal['Spark', 'Hive']='Spark', initial_capacity: Optional[Dict[str, str]]=None, maximum_capacity: Optional[Dict[str, str]]=None, tags: Optional[Dict[str, str]]=None, autostart: bool=True, autostop: bool=True, idle_timeout: int=15, network_configuration: Optional[Dict[str, str]]=None, architecture: Literal['ARM64', 'X86_64']='X86_64', image_uri: Optional[str]=None, worker_type_specifications: Optional[Dict[str, str]]=None, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Create an EMR Serverless application.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Name of EMR Serverless appliation\\n    release_label : str\\n        Release label e.g. `emr-6.10.0`\\n    application_type : str, optional\\n        Application type: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    initial_capacity : Dict[str, str], optional\\n        The capacity to initialize when the application is created.\\n    maximum_capacity : Dict[str, str], optional\\n        The maximum capacity to allocate when the application is created.\\n        This is cumulative across all workers at any given point in time,\\n        not just when an application is created. No new resources will\\n        be created once any one of the defined limits is hit.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    autostart : bool, optional\\n        Enables the application to automatically start on job submission. Defaults to true.\\n    autostop : bool, optional\\n        Enables the application to automatically stop after a certain amount of time being idle. Defaults to true.\\n    idle_timeout : int, optional\\n        The amount of idle time in minutes after which your application will automatically stop. Defaults to 15 minutes.\\n    network_configuration : Dict[str, str], optional\\n        The network configuration for customer VPC connectivity.\\n    architecture : str, optional\\n        The CPU architecture of an application: \"ARM64\" or \"X86_64\". Defaults to \"X86_64\".\\n    image_uri : str, optional\\n        The URI of an image in the Amazon ECR registry.\\n    worker_type_specifications : Dict[str, str], optional\\n        The key-value pairs that specify worker type.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Application Id.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    application_args: Dict[str, Any] = {'name': name, 'releaseLabel': release_label, 'type': application_type, 'autoStartConfiguration': {'enabled': autostart}, 'autoStopConfiguration': {'enabled': autostop, 'idleTimeoutMinutes': idle_timeout}, 'architecture': architecture}\n    if initial_capacity:\n        application_args['initialCapacity'] = initial_capacity\n    if maximum_capacity:\n        application_args['maximumCapacity'] = maximum_capacity\n    if tags:\n        application_args['tags'] = tags\n    if network_configuration:\n        application_args['networkConfiguration'] = network_configuration\n    if worker_type_specifications:\n        application_args['workerTypeSpecifications'] = worker_type_specifications\n    if image_uri:\n        application_args['imageConfiguration'] = {'imageUri': image_uri}\n    response: Dict[str, str] = emr_serverless.create_application(**application_args)\n    _logger.debug('response: \\n%s', pprint.pformat(response))\n    return response['applicationId']",
            "@Experimental\ndef create_application(name: str, release_label: str, application_type: Literal['Spark', 'Hive']='Spark', initial_capacity: Optional[Dict[str, str]]=None, maximum_capacity: Optional[Dict[str, str]]=None, tags: Optional[Dict[str, str]]=None, autostart: bool=True, autostop: bool=True, idle_timeout: int=15, network_configuration: Optional[Dict[str, str]]=None, architecture: Literal['ARM64', 'X86_64']='X86_64', image_uri: Optional[str]=None, worker_type_specifications: Optional[Dict[str, str]]=None, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Create an EMR Serverless application.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Name of EMR Serverless appliation\\n    release_label : str\\n        Release label e.g. `emr-6.10.0`\\n    application_type : str, optional\\n        Application type: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    initial_capacity : Dict[str, str], optional\\n        The capacity to initialize when the application is created.\\n    maximum_capacity : Dict[str, str], optional\\n        The maximum capacity to allocate when the application is created.\\n        This is cumulative across all workers at any given point in time,\\n        not just when an application is created. No new resources will\\n        be created once any one of the defined limits is hit.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    autostart : bool, optional\\n        Enables the application to automatically start on job submission. Defaults to true.\\n    autostop : bool, optional\\n        Enables the application to automatically stop after a certain amount of time being idle. Defaults to true.\\n    idle_timeout : int, optional\\n        The amount of idle time in minutes after which your application will automatically stop. Defaults to 15 minutes.\\n    network_configuration : Dict[str, str], optional\\n        The network configuration for customer VPC connectivity.\\n    architecture : str, optional\\n        The CPU architecture of an application: \"ARM64\" or \"X86_64\". Defaults to \"X86_64\".\\n    image_uri : str, optional\\n        The URI of an image in the Amazon ECR registry.\\n    worker_type_specifications : Dict[str, str], optional\\n        The key-value pairs that specify worker type.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Application Id.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    application_args: Dict[str, Any] = {'name': name, 'releaseLabel': release_label, 'type': application_type, 'autoStartConfiguration': {'enabled': autostart}, 'autoStopConfiguration': {'enabled': autostop, 'idleTimeoutMinutes': idle_timeout}, 'architecture': architecture}\n    if initial_capacity:\n        application_args['initialCapacity'] = initial_capacity\n    if maximum_capacity:\n        application_args['maximumCapacity'] = maximum_capacity\n    if tags:\n        application_args['tags'] = tags\n    if network_configuration:\n        application_args['networkConfiguration'] = network_configuration\n    if worker_type_specifications:\n        application_args['workerTypeSpecifications'] = worker_type_specifications\n    if image_uri:\n        application_args['imageConfiguration'] = {'imageUri': image_uri}\n    response: Dict[str, str] = emr_serverless.create_application(**application_args)\n    _logger.debug('response: \\n%s', pprint.pformat(response))\n    return response['applicationId']",
            "@Experimental\ndef create_application(name: str, release_label: str, application_type: Literal['Spark', 'Hive']='Spark', initial_capacity: Optional[Dict[str, str]]=None, maximum_capacity: Optional[Dict[str, str]]=None, tags: Optional[Dict[str, str]]=None, autostart: bool=True, autostop: bool=True, idle_timeout: int=15, network_configuration: Optional[Dict[str, str]]=None, architecture: Literal['ARM64', 'X86_64']='X86_64', image_uri: Optional[str]=None, worker_type_specifications: Optional[Dict[str, str]]=None, boto3_session: Optional[boto3.Session]=None) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Create an EMR Serverless application.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Name of EMR Serverless appliation\\n    release_label : str\\n        Release label e.g. `emr-6.10.0`\\n    application_type : str, optional\\n        Application type: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    initial_capacity : Dict[str, str], optional\\n        The capacity to initialize when the application is created.\\n    maximum_capacity : Dict[str, str], optional\\n        The maximum capacity to allocate when the application is created.\\n        This is cumulative across all workers at any given point in time,\\n        not just when an application is created. No new resources will\\n        be created once any one of the defined limits is hit.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    autostart : bool, optional\\n        Enables the application to automatically start on job submission. Defaults to true.\\n    autostop : bool, optional\\n        Enables the application to automatically stop after a certain amount of time being idle. Defaults to true.\\n    idle_timeout : int, optional\\n        The amount of idle time in minutes after which your application will automatically stop. Defaults to 15 minutes.\\n    network_configuration : Dict[str, str], optional\\n        The network configuration for customer VPC connectivity.\\n    architecture : str, optional\\n        The CPU architecture of an application: \"ARM64\" or \"X86_64\". Defaults to \"X86_64\".\\n    image_uri : str, optional\\n        The URI of an image in the Amazon ECR registry.\\n    worker_type_specifications : Dict[str, str], optional\\n        The key-value pairs that specify worker type.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    str\\n        Application Id.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    application_args: Dict[str, Any] = {'name': name, 'releaseLabel': release_label, 'type': application_type, 'autoStartConfiguration': {'enabled': autostart}, 'autoStopConfiguration': {'enabled': autostop, 'idleTimeoutMinutes': idle_timeout}, 'architecture': architecture}\n    if initial_capacity:\n        application_args['initialCapacity'] = initial_capacity\n    if maximum_capacity:\n        application_args['maximumCapacity'] = maximum_capacity\n    if tags:\n        application_args['tags'] = tags\n    if network_configuration:\n        application_args['networkConfiguration'] = network_configuration\n    if worker_type_specifications:\n        application_args['workerTypeSpecifications'] = worker_type_specifications\n    if image_uri:\n        application_args['imageConfiguration'] = {'imageUri': image_uri}\n    response: Dict[str, str] = emr_serverless.create_application(**application_args)\n    _logger.debug('response: \\n%s', pprint.pformat(response))\n    return response['applicationId']"
        ]
    },
    {
        "func_name": "run_job",
        "original": "@Experimental\n@apply_configs\ndef run_job(application_id: str, execution_role_arn: str, job_driver_args: Union[Dict[str, Any], SparkSubmitJobArgs, HiveRunJobArgs], job_type: Literal['Spark', 'Hive']='Spark', wait: bool=True, configuration_overrides: Optional[Dict[str, Any]]=None, tags: Optional[Dict[str, str]]=None, execution_timeout: Optional[int]=None, name: Optional[str]=None, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Union[str, Dict[str, Any]]:\n    \"\"\"\n    Run an EMR serverless job.\n\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\n\n    Parameters\n    ----------\n    application_id : str\n        The id of the application on which to run the job.\n    execution_role_arn : str\n        The execution role ARN for the job run.\n    job_driver_args : Union[Dict[str, str], SparkSubmitJobArgs, HiveRunJobArgs]\n        The job driver arguments for the job run.\n    job_type : str, optional\n        Type of the job: \"Spark\" or \"Hive\". Defaults to \"Spark\".\n    wait : bool, optional\n        Whether to wait for the job completion or not. Defaults to true.\n    configuration_overrides : Dict[str, str], optional\n        The configuration overrides for the job run.\n    tags : Dict[str, str], optional\n        Key/Value collection to put tags on the application.\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\n    execution_timeout : int, optional\n        The maximum duration for the job run to run. If the job run runs beyond this duration,\n        it will be automatically cancelled.\n    name : str, optional\n        Name of the job.\n    emr_serverless_job_wait_polling_delay : int, optional\n        Time to wait between polling attempts.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    Union[str, Dict[str, Any]]\n        Job Id if wait=False, or job run details.\n    \"\"\"\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    job_args: Dict[str, Any] = {'applicationId': application_id, 'executionRoleArn': execution_role_arn}\n    if job_type == 'Spark':\n        job_args['jobDriver'] = {'sparkSubmit': job_driver_args}\n    elif job_type == 'Hive':\n        job_args['jobDriver'] = {'hive': job_driver_args}\n    else:\n        raise exceptions.InvalidArgumentValue(f'Unsupported job type `{job_type}`')\n    if configuration_overrides:\n        job_args['configurationOverrides'] = configuration_overrides\n    if tags:\n        job_args['tags'] = tags\n    if execution_timeout:\n        job_args['executionTimeoutMinutes'] = execution_timeout\n    if name:\n        job_args['name'] = name\n    response = emr_serverless.start_job_run(**job_args)\n    _logger.debug('Job run response: %s', response)\n    job_run_id: str = response['jobRunId']\n    if wait:\n        return wait_job(application_id=application_id, job_run_id=job_run_id, emr_serverless_job_wait_polling_delay=emr_serverless_job_wait_polling_delay)\n    return job_run_id",
        "mutated": [
            "@Experimental\n@apply_configs\ndef run_job(application_id: str, execution_role_arn: str, job_driver_args: Union[Dict[str, Any], SparkSubmitJobArgs, HiveRunJobArgs], job_type: Literal['Spark', 'Hive']='Spark', wait: bool=True, configuration_overrides: Optional[Dict[str, Any]]=None, tags: Optional[Dict[str, str]]=None, execution_timeout: Optional[int]=None, name: Optional[str]=None, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Union[str, Dict[str, Any]]:\n    if False:\n        i = 10\n    '\\n    Run an EMR serverless job.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which to run the job.\\n    execution_role_arn : str\\n        The execution role ARN for the job run.\\n    job_driver_args : Union[Dict[str, str], SparkSubmitJobArgs, HiveRunJobArgs]\\n        The job driver arguments for the job run.\\n    job_type : str, optional\\n        Type of the job: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    wait : bool, optional\\n        Whether to wait for the job completion or not. Defaults to true.\\n    configuration_overrides : Dict[str, str], optional\\n        The configuration overrides for the job run.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    execution_timeout : int, optional\\n        The maximum duration for the job run to run. If the job run runs beyond this duration,\\n        it will be automatically cancelled.\\n    name : str, optional\\n        Name of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Union[str, Dict[str, Any]]\\n        Job Id if wait=False, or job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    job_args: Dict[str, Any] = {'applicationId': application_id, 'executionRoleArn': execution_role_arn}\n    if job_type == 'Spark':\n        job_args['jobDriver'] = {'sparkSubmit': job_driver_args}\n    elif job_type == 'Hive':\n        job_args['jobDriver'] = {'hive': job_driver_args}\n    else:\n        raise exceptions.InvalidArgumentValue(f'Unsupported job type `{job_type}`')\n    if configuration_overrides:\n        job_args['configurationOverrides'] = configuration_overrides\n    if tags:\n        job_args['tags'] = tags\n    if execution_timeout:\n        job_args['executionTimeoutMinutes'] = execution_timeout\n    if name:\n        job_args['name'] = name\n    response = emr_serverless.start_job_run(**job_args)\n    _logger.debug('Job run response: %s', response)\n    job_run_id: str = response['jobRunId']\n    if wait:\n        return wait_job(application_id=application_id, job_run_id=job_run_id, emr_serverless_job_wait_polling_delay=emr_serverless_job_wait_polling_delay)\n    return job_run_id",
            "@Experimental\n@apply_configs\ndef run_job(application_id: str, execution_role_arn: str, job_driver_args: Union[Dict[str, Any], SparkSubmitJobArgs, HiveRunJobArgs], job_type: Literal['Spark', 'Hive']='Spark', wait: bool=True, configuration_overrides: Optional[Dict[str, Any]]=None, tags: Optional[Dict[str, str]]=None, execution_timeout: Optional[int]=None, name: Optional[str]=None, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Union[str, Dict[str, Any]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Run an EMR serverless job.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which to run the job.\\n    execution_role_arn : str\\n        The execution role ARN for the job run.\\n    job_driver_args : Union[Dict[str, str], SparkSubmitJobArgs, HiveRunJobArgs]\\n        The job driver arguments for the job run.\\n    job_type : str, optional\\n        Type of the job: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    wait : bool, optional\\n        Whether to wait for the job completion or not. Defaults to true.\\n    configuration_overrides : Dict[str, str], optional\\n        The configuration overrides for the job run.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    execution_timeout : int, optional\\n        The maximum duration for the job run to run. If the job run runs beyond this duration,\\n        it will be automatically cancelled.\\n    name : str, optional\\n        Name of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Union[str, Dict[str, Any]]\\n        Job Id if wait=False, or job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    job_args: Dict[str, Any] = {'applicationId': application_id, 'executionRoleArn': execution_role_arn}\n    if job_type == 'Spark':\n        job_args['jobDriver'] = {'sparkSubmit': job_driver_args}\n    elif job_type == 'Hive':\n        job_args['jobDriver'] = {'hive': job_driver_args}\n    else:\n        raise exceptions.InvalidArgumentValue(f'Unsupported job type `{job_type}`')\n    if configuration_overrides:\n        job_args['configurationOverrides'] = configuration_overrides\n    if tags:\n        job_args['tags'] = tags\n    if execution_timeout:\n        job_args['executionTimeoutMinutes'] = execution_timeout\n    if name:\n        job_args['name'] = name\n    response = emr_serverless.start_job_run(**job_args)\n    _logger.debug('Job run response: %s', response)\n    job_run_id: str = response['jobRunId']\n    if wait:\n        return wait_job(application_id=application_id, job_run_id=job_run_id, emr_serverless_job_wait_polling_delay=emr_serverless_job_wait_polling_delay)\n    return job_run_id",
            "@Experimental\n@apply_configs\ndef run_job(application_id: str, execution_role_arn: str, job_driver_args: Union[Dict[str, Any], SparkSubmitJobArgs, HiveRunJobArgs], job_type: Literal['Spark', 'Hive']='Spark', wait: bool=True, configuration_overrides: Optional[Dict[str, Any]]=None, tags: Optional[Dict[str, str]]=None, execution_timeout: Optional[int]=None, name: Optional[str]=None, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Union[str, Dict[str, Any]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Run an EMR serverless job.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which to run the job.\\n    execution_role_arn : str\\n        The execution role ARN for the job run.\\n    job_driver_args : Union[Dict[str, str], SparkSubmitJobArgs, HiveRunJobArgs]\\n        The job driver arguments for the job run.\\n    job_type : str, optional\\n        Type of the job: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    wait : bool, optional\\n        Whether to wait for the job completion or not. Defaults to true.\\n    configuration_overrides : Dict[str, str], optional\\n        The configuration overrides for the job run.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    execution_timeout : int, optional\\n        The maximum duration for the job run to run. If the job run runs beyond this duration,\\n        it will be automatically cancelled.\\n    name : str, optional\\n        Name of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Union[str, Dict[str, Any]]\\n        Job Id if wait=False, or job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    job_args: Dict[str, Any] = {'applicationId': application_id, 'executionRoleArn': execution_role_arn}\n    if job_type == 'Spark':\n        job_args['jobDriver'] = {'sparkSubmit': job_driver_args}\n    elif job_type == 'Hive':\n        job_args['jobDriver'] = {'hive': job_driver_args}\n    else:\n        raise exceptions.InvalidArgumentValue(f'Unsupported job type `{job_type}`')\n    if configuration_overrides:\n        job_args['configurationOverrides'] = configuration_overrides\n    if tags:\n        job_args['tags'] = tags\n    if execution_timeout:\n        job_args['executionTimeoutMinutes'] = execution_timeout\n    if name:\n        job_args['name'] = name\n    response = emr_serverless.start_job_run(**job_args)\n    _logger.debug('Job run response: %s', response)\n    job_run_id: str = response['jobRunId']\n    if wait:\n        return wait_job(application_id=application_id, job_run_id=job_run_id, emr_serverless_job_wait_polling_delay=emr_serverless_job_wait_polling_delay)\n    return job_run_id",
            "@Experimental\n@apply_configs\ndef run_job(application_id: str, execution_role_arn: str, job_driver_args: Union[Dict[str, Any], SparkSubmitJobArgs, HiveRunJobArgs], job_type: Literal['Spark', 'Hive']='Spark', wait: bool=True, configuration_overrides: Optional[Dict[str, Any]]=None, tags: Optional[Dict[str, str]]=None, execution_timeout: Optional[int]=None, name: Optional[str]=None, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Union[str, Dict[str, Any]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Run an EMR serverless job.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which to run the job.\\n    execution_role_arn : str\\n        The execution role ARN for the job run.\\n    job_driver_args : Union[Dict[str, str], SparkSubmitJobArgs, HiveRunJobArgs]\\n        The job driver arguments for the job run.\\n    job_type : str, optional\\n        Type of the job: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    wait : bool, optional\\n        Whether to wait for the job completion or not. Defaults to true.\\n    configuration_overrides : Dict[str, str], optional\\n        The configuration overrides for the job run.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    execution_timeout : int, optional\\n        The maximum duration for the job run to run. If the job run runs beyond this duration,\\n        it will be automatically cancelled.\\n    name : str, optional\\n        Name of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Union[str, Dict[str, Any]]\\n        Job Id if wait=False, or job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    job_args: Dict[str, Any] = {'applicationId': application_id, 'executionRoleArn': execution_role_arn}\n    if job_type == 'Spark':\n        job_args['jobDriver'] = {'sparkSubmit': job_driver_args}\n    elif job_type == 'Hive':\n        job_args['jobDriver'] = {'hive': job_driver_args}\n    else:\n        raise exceptions.InvalidArgumentValue(f'Unsupported job type `{job_type}`')\n    if configuration_overrides:\n        job_args['configurationOverrides'] = configuration_overrides\n    if tags:\n        job_args['tags'] = tags\n    if execution_timeout:\n        job_args['executionTimeoutMinutes'] = execution_timeout\n    if name:\n        job_args['name'] = name\n    response = emr_serverless.start_job_run(**job_args)\n    _logger.debug('Job run response: %s', response)\n    job_run_id: str = response['jobRunId']\n    if wait:\n        return wait_job(application_id=application_id, job_run_id=job_run_id, emr_serverless_job_wait_polling_delay=emr_serverless_job_wait_polling_delay)\n    return job_run_id",
            "@Experimental\n@apply_configs\ndef run_job(application_id: str, execution_role_arn: str, job_driver_args: Union[Dict[str, Any], SparkSubmitJobArgs, HiveRunJobArgs], job_type: Literal['Spark', 'Hive']='Spark', wait: bool=True, configuration_overrides: Optional[Dict[str, Any]]=None, tags: Optional[Dict[str, str]]=None, execution_timeout: Optional[int]=None, name: Optional[str]=None, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Union[str, Dict[str, Any]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Run an EMR serverless job.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which to run the job.\\n    execution_role_arn : str\\n        The execution role ARN for the job run.\\n    job_driver_args : Union[Dict[str, str], SparkSubmitJobArgs, HiveRunJobArgs]\\n        The job driver arguments for the job run.\\n    job_type : str, optional\\n        Type of the job: \"Spark\" or \"Hive\". Defaults to \"Spark\".\\n    wait : bool, optional\\n        Whether to wait for the job completion or not. Defaults to true.\\n    configuration_overrides : Dict[str, str], optional\\n        The configuration overrides for the job run.\\n    tags : Dict[str, str], optional\\n        Key/Value collection to put tags on the application.\\n        e.g. {\"foo\": \"boo\", \"bar\": \"xoo\"})\\n    execution_timeout : int, optional\\n        The maximum duration for the job run to run. If the job run runs beyond this duration,\\n        it will be automatically cancelled.\\n    name : str, optional\\n        Name of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Union[str, Dict[str, Any]]\\n        Job Id if wait=False, or job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    job_args: Dict[str, Any] = {'applicationId': application_id, 'executionRoleArn': execution_role_arn}\n    if job_type == 'Spark':\n        job_args['jobDriver'] = {'sparkSubmit': job_driver_args}\n    elif job_type == 'Hive':\n        job_args['jobDriver'] = {'hive': job_driver_args}\n    else:\n        raise exceptions.InvalidArgumentValue(f'Unsupported job type `{job_type}`')\n    if configuration_overrides:\n        job_args['configurationOverrides'] = configuration_overrides\n    if tags:\n        job_args['tags'] = tags\n    if execution_timeout:\n        job_args['executionTimeoutMinutes'] = execution_timeout\n    if name:\n        job_args['name'] = name\n    response = emr_serverless.start_job_run(**job_args)\n    _logger.debug('Job run response: %s', response)\n    job_run_id: str = response['jobRunId']\n    if wait:\n        return wait_job(application_id=application_id, job_run_id=job_run_id, emr_serverless_job_wait_polling_delay=emr_serverless_job_wait_polling_delay)\n    return job_run_id"
        ]
    },
    {
        "func_name": "wait_job",
        "original": "@Experimental\n@apply_configs\ndef wait_job(application_id: str, job_run_id: str, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    \"\"\"\n    Wait for the EMR Serverless job to finish.\n\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\n\n    Parameters\n    ----------\n    application_id : str\n        The id of the application on which the job is running.\n    job_run_id : str\n        The id of the job.\n    emr_serverless_job_wait_polling_delay : int, optional\n        Time to wait between polling attempts.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    Dict[str, Any]\n        Job run details.\n    \"\"\"\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n    state = response['jobRun']['state']\n    while state not in _EMR_SERVERLESS_JOB_FINAL_STATES:\n        time.sleep(emr_serverless_job_wait_polling_delay)\n        response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n        state = response['jobRun']['state']\n    _logger.debug('Job state: %s', state)\n    if state != 'SUCCESS':\n        _logger.debug('Job run response: %s', response)\n        raise exceptions.EMRServerlessJobError(response.get('jobRun', {}).get('stateDetails'))\n    return response",
        "mutated": [
            "@Experimental\n@apply_configs\ndef wait_job(application_id: str, job_run_id: str, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n    '\\n    Wait for the EMR Serverless job to finish.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which the job is running.\\n    job_run_id : str\\n        The id of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n    state = response['jobRun']['state']\n    while state not in _EMR_SERVERLESS_JOB_FINAL_STATES:\n        time.sleep(emr_serverless_job_wait_polling_delay)\n        response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n        state = response['jobRun']['state']\n    _logger.debug('Job state: %s', state)\n    if state != 'SUCCESS':\n        _logger.debug('Job run response: %s', response)\n        raise exceptions.EMRServerlessJobError(response.get('jobRun', {}).get('stateDetails'))\n    return response",
            "@Experimental\n@apply_configs\ndef wait_job(application_id: str, job_run_id: str, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Wait for the EMR Serverless job to finish.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which the job is running.\\n    job_run_id : str\\n        The id of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n    state = response['jobRun']['state']\n    while state not in _EMR_SERVERLESS_JOB_FINAL_STATES:\n        time.sleep(emr_serverless_job_wait_polling_delay)\n        response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n        state = response['jobRun']['state']\n    _logger.debug('Job state: %s', state)\n    if state != 'SUCCESS':\n        _logger.debug('Job run response: %s', response)\n        raise exceptions.EMRServerlessJobError(response.get('jobRun', {}).get('stateDetails'))\n    return response",
            "@Experimental\n@apply_configs\ndef wait_job(application_id: str, job_run_id: str, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Wait for the EMR Serverless job to finish.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which the job is running.\\n    job_run_id : str\\n        The id of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n    state = response['jobRun']['state']\n    while state not in _EMR_SERVERLESS_JOB_FINAL_STATES:\n        time.sleep(emr_serverless_job_wait_polling_delay)\n        response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n        state = response['jobRun']['state']\n    _logger.debug('Job state: %s', state)\n    if state != 'SUCCESS':\n        _logger.debug('Job run response: %s', response)\n        raise exceptions.EMRServerlessJobError(response.get('jobRun', {}).get('stateDetails'))\n    return response",
            "@Experimental\n@apply_configs\ndef wait_job(application_id: str, job_run_id: str, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Wait for the EMR Serverless job to finish.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which the job is running.\\n    job_run_id : str\\n        The id of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n    state = response['jobRun']['state']\n    while state not in _EMR_SERVERLESS_JOB_FINAL_STATES:\n        time.sleep(emr_serverless_job_wait_polling_delay)\n        response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n        state = response['jobRun']['state']\n    _logger.debug('Job state: %s', state)\n    if state != 'SUCCESS':\n        _logger.debug('Job run response: %s', response)\n        raise exceptions.EMRServerlessJobError(response.get('jobRun', {}).get('stateDetails'))\n    return response",
            "@Experimental\n@apply_configs\ndef wait_job(application_id: str, job_run_id: str, emr_serverless_job_wait_polling_delay: float=_EMR_SERVERLESS_JOB_WAIT_POLLING_DELAY, boto3_session: Optional[boto3.Session]=None) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Wait for the EMR Serverless job to finish.\\n\\n    https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html\\n\\n    Parameters\\n    ----------\\n    application_id : str\\n        The id of the application on which the job is running.\\n    job_run_id : str\\n        The id of the job.\\n    emr_serverless_job_wait_polling_delay : int, optional\\n        Time to wait between polling attempts.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, Any]\\n        Job run details.\\n    '\n    emr_serverless = _utils.client(service_name='emr-serverless', session=boto3_session)\n    response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n    state = response['jobRun']['state']\n    while state not in _EMR_SERVERLESS_JOB_FINAL_STATES:\n        time.sleep(emr_serverless_job_wait_polling_delay)\n        response = emr_serverless.get_job_run(applicationId=application_id, jobRunId=job_run_id)\n        state = response['jobRun']['state']\n    _logger.debug('Job state: %s', state)\n    if state != 'SUCCESS':\n        _logger.debug('Job run response: %s', response)\n        raise exceptions.EMRServerlessJobError(response.get('jobRun', {}).get('stateDetails'))\n    return response"
        ]
    }
]