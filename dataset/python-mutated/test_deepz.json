[
    {
        "func_name": "fix_get_mnist_data",
        "original": "@pytest.fixture()\ndef fix_get_mnist_data():\n    \"\"\"\n    Get the first 100 samples of the mnist test set with channels first format\n    :return: First 100 sample/label pairs of the MNIST test dataset.\n    \"\"\"\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
        "mutated": [
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)"
        ]
    },
    {
        "func_name": "fix_get_cifar10_data",
        "original": "@pytest.fixture()\ndef fix_get_cifar10_data():\n    \"\"\"\n    Get the first 10 samples of the cifar10 test set\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\n    \"\"\"\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
        "mutated": [
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n    '\\n    Get the first 10 samples of the cifar10 test set\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Get the first 10 samples of the cifar10 test set\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Get the first 10 samples of the cifar10 test set\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Get the first 10 samples of the cifar10 test set\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Get the first 10 samples of the cifar10 test set\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test, y_test)"
        ]
    },
    {
        "func_name": "test_mnist_certification",
        "original": "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_mnist_certification(art_warning, fix_get_mnist_data):\n    \"\"\"\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound of 0.05.\n        1) Upper and lower bounds are calculated correctly.\n        2) The correct number of datapoints are certified.\n        3) The standard accuracy is correct.\n    \"\"\"\n    bound = 0.05\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_ub_results_0.05.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_lb_results_0.05.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(784) * bound\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps = eps.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=prediction)\n            assert is_certified == all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 94\n        assert correct == 99\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_mnist_certification(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound of 0.05.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.05\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_ub_results_0.05.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_lb_results_0.05.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(784) * bound\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps = eps.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=prediction)\n            assert is_certified == all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 94\n        assert correct == 99\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_mnist_certification(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound of 0.05.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.05\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_ub_results_0.05.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_lb_results_0.05.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(784) * bound\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps = eps.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=prediction)\n            assert is_certified == all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 94\n        assert correct == 99\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_mnist_certification(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound of 0.05.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.05\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_ub_results_0.05.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_lb_results_0.05.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(784) * bound\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps = eps.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=prediction)\n            assert is_certified == all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 94\n        assert correct == 99\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_mnist_certification(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound of 0.05.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.05\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_ub_results_0.05.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_lb_results_0.05.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(784) * bound\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps = eps.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=prediction)\n            assert is_certified == all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 94\n        assert correct == 99\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_mnist_certification(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound of 0.05.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.05\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_ub_results_0.05.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/mnist_lb_results_0.05.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(784) * bound\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps = eps.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=prediction)\n            assert is_certified == all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 94\n        assert correct == 99\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    },
    {
        "func_name": "test_cifar_certification",
        "original": "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_cifar_certification(art_warning, fix_get_cifar10_data):\n    \"\"\"\n    Check the following properties for the first 100 samples of the CIFAR10 test set given an l_inft bound of 0.004.\n        1) Upper and lower bounds are calculated correctly.\n        2) The correct number of datapoints are certified.\n        3) The standard accuracy is correct.\n    \"\"\"\n    bound = 0.004\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_ub_results_0.004.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_lb_results_0.004.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            x = np.moveaxis(x, [2], [0])\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps_bound) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps_bound)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps_bound = eps_bound.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps_bound)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 7\n        assert correct == 8\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_cifar_certification(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n    '\\n    Check the following properties for the first 100 samples of the CIFAR10 test set given an l_inft bound of 0.004.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.004\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_ub_results_0.004.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_lb_results_0.004.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            x = np.moveaxis(x, [2], [0])\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps_bound) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps_bound)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps_bound = eps_bound.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps_bound)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 7\n        assert correct == 8\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_cifar_certification(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check the following properties for the first 100 samples of the CIFAR10 test set given an l_inft bound of 0.004.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.004\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_ub_results_0.004.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_lb_results_0.004.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            x = np.moveaxis(x, [2], [0])\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps_bound) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps_bound)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps_bound = eps_bound.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps_bound)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 7\n        assert correct == 8\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_cifar_certification(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check the following properties for the first 100 samples of the CIFAR10 test set given an l_inft bound of 0.004.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.004\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_ub_results_0.004.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_lb_results_0.004.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            x = np.moveaxis(x, [2], [0])\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps_bound) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps_bound)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps_bound = eps_bound.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps_bound)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 7\n        assert correct == 8\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_cifar_certification(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check the following properties for the first 100 samples of the CIFAR10 test set given an l_inft bound of 0.004.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.004\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_ub_results_0.004.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_lb_results_0.004.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            x = np.moveaxis(x, [2], [0])\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps_bound) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps_bound)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps_bound = eps_bound.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps_bound)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 7\n        assert correct == 8\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2')\ndef test_cifar_certification(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check the following properties for the first 100 samples of the CIFAR10 test set given an l_inft bound of 0.004.\\n        1) Upper and lower bounds are calculated correctly.\\n        2) The correct number of datapoints are certified.\\n        3) The standard accuracy is correct.\\n    '\n    bound = 0.004\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    zonotope_model = PytorchDeepZ(model=ptc.model, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    correct_upper_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_ub_results_0.004.json'))))\n    correct_lower_bounds = np.asarray(json.load(open(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'certification/output_results/mini_nets/cifar10_lb_results_0.004.json'))))\n    num_cert = 0\n    correct = 0\n    try:\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            x = np.moveaxis(x, [2], [0])\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n            pred_sample = torch.from_numpy(pred_sample.astype('float32')).to(device)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = zonotope_model.model.forward(pred_sample)\n            prediction = np.argmax(prediction.cpu().detach().numpy())\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            zonotope_model.model.set_forward_mode('abstract')\n            (bias, eps_bound) = zonotope_model.model.forward(eps=eps_bound, cent=data_sample_processed)\n            (upper_bounds, lower_bounds) = zonotope_model.zonotope_get_bounds(bias, eps_bound)\n            if prediction == y:\n                for (bnds, correct_bds) in zip([upper_bounds, lower_bounds], [correct_upper_bounds[correct], correct_lower_bounds[correct]]):\n                    bnds = torch.stack(bnds)\n                    bnds = bnds.detach().cpu().numpy()\n                    assert np.allclose(bnds, correct_bds, rtol=1e-05, atol=1e-05)\n                correct += 1\n            bias = bias.detach().cpu().numpy()\n            eps_bound = eps_bound.detach().cpu().numpy()\n            certified = True\n            sub_certs = []\n            min_bound_on_class = lower_bounds[y]\n            for k in range(10):\n                if k != prediction:\n                    cert_via_sub = zonotope_model.certify_via_subtraction(predicted_class=prediction, class_to_consider=k, cent=bias, eps=eps_bound)\n                    sub_certs.append(cert_via_sub)\n                    if min_bound_on_class <= upper_bounds[k]:\n                        certified = False\n            if certified:\n                assert all(sub_certs)\n            if all(sub_certs) and int(prediction) == y:\n                num_cert += 1\n        assert num_cert == 7\n        assert correct == 8\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    }
]