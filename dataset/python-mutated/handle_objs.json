[
    {
        "func_name": "filter_outside_objs",
        "original": "def filter_outside_objs(gt_bboxes_list, gt_labels_list, gt_bboxes_3d_list, gt_labels_3d_list, centers2d_list, img_metas):\n    \"\"\"Function to filter the objects label outside the image.\n\n    Args:\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\n            each has shape (num_gt, 4).\n        gt_labels_list (list[Tensor]): Ground truth labels of each box,\n            each has shape (num_gt,).\n        gt_bboxes_3d_list (list[Tensor]): 3D Ground truth bboxes of each\n            image, each has shape (num_gt, bbox_code_size).\n        gt_labels_3d_list (list[Tensor]): 3D Ground truth labels of each\n            box, each has shape (num_gt,).\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\n            each has shape (num_gt, 2).\n        img_metas (list[dict]): Meta information of each image, e.g.,\n            image size, scaling factor, etc.\n    \"\"\"\n    bs = len(centers2d_list)\n    for i in range(bs):\n        centers2d = centers2d_list[i].clone()\n        img_shape = img_metas[i]['img_shape']\n        keep_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        centers2d_list[i] = centers2d[keep_inds]\n        gt_labels_list[i] = gt_labels_list[i][keep_inds]\n        gt_bboxes_list[i] = gt_bboxes_list[i][keep_inds]\n        gt_bboxes_3d_list[i].tensor = gt_bboxes_3d_list[i].tensor[keep_inds]\n        gt_labels_3d_list[i] = gt_labels_3d_list[i][keep_inds]",
        "mutated": [
            "def filter_outside_objs(gt_bboxes_list, gt_labels_list, gt_bboxes_3d_list, gt_labels_3d_list, centers2d_list, img_metas):\n    if False:\n        i = 10\n    'Function to filter the objects label outside the image.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            each has shape (num_gt, 4).\\n        gt_labels_list (list[Tensor]): Ground truth labels of each box,\\n            each has shape (num_gt,).\\n        gt_bboxes_3d_list (list[Tensor]): 3D Ground truth bboxes of each\\n            image, each has shape (num_gt, bbox_code_size).\\n        gt_labels_3d_list (list[Tensor]): 3D Ground truth labels of each\\n            box, each has shape (num_gt,).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            each has shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n    '\n    bs = len(centers2d_list)\n    for i in range(bs):\n        centers2d = centers2d_list[i].clone()\n        img_shape = img_metas[i]['img_shape']\n        keep_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        centers2d_list[i] = centers2d[keep_inds]\n        gt_labels_list[i] = gt_labels_list[i][keep_inds]\n        gt_bboxes_list[i] = gt_bboxes_list[i][keep_inds]\n        gt_bboxes_3d_list[i].tensor = gt_bboxes_3d_list[i].tensor[keep_inds]\n        gt_labels_3d_list[i] = gt_labels_3d_list[i][keep_inds]",
            "def filter_outside_objs(gt_bboxes_list, gt_labels_list, gt_bboxes_3d_list, gt_labels_3d_list, centers2d_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Function to filter the objects label outside the image.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            each has shape (num_gt, 4).\\n        gt_labels_list (list[Tensor]): Ground truth labels of each box,\\n            each has shape (num_gt,).\\n        gt_bboxes_3d_list (list[Tensor]): 3D Ground truth bboxes of each\\n            image, each has shape (num_gt, bbox_code_size).\\n        gt_labels_3d_list (list[Tensor]): 3D Ground truth labels of each\\n            box, each has shape (num_gt,).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            each has shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n    '\n    bs = len(centers2d_list)\n    for i in range(bs):\n        centers2d = centers2d_list[i].clone()\n        img_shape = img_metas[i]['img_shape']\n        keep_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        centers2d_list[i] = centers2d[keep_inds]\n        gt_labels_list[i] = gt_labels_list[i][keep_inds]\n        gt_bboxes_list[i] = gt_bboxes_list[i][keep_inds]\n        gt_bboxes_3d_list[i].tensor = gt_bboxes_3d_list[i].tensor[keep_inds]\n        gt_labels_3d_list[i] = gt_labels_3d_list[i][keep_inds]",
            "def filter_outside_objs(gt_bboxes_list, gt_labels_list, gt_bboxes_3d_list, gt_labels_3d_list, centers2d_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Function to filter the objects label outside the image.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            each has shape (num_gt, 4).\\n        gt_labels_list (list[Tensor]): Ground truth labels of each box,\\n            each has shape (num_gt,).\\n        gt_bboxes_3d_list (list[Tensor]): 3D Ground truth bboxes of each\\n            image, each has shape (num_gt, bbox_code_size).\\n        gt_labels_3d_list (list[Tensor]): 3D Ground truth labels of each\\n            box, each has shape (num_gt,).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            each has shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n    '\n    bs = len(centers2d_list)\n    for i in range(bs):\n        centers2d = centers2d_list[i].clone()\n        img_shape = img_metas[i]['img_shape']\n        keep_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        centers2d_list[i] = centers2d[keep_inds]\n        gt_labels_list[i] = gt_labels_list[i][keep_inds]\n        gt_bboxes_list[i] = gt_bboxes_list[i][keep_inds]\n        gt_bboxes_3d_list[i].tensor = gt_bboxes_3d_list[i].tensor[keep_inds]\n        gt_labels_3d_list[i] = gt_labels_3d_list[i][keep_inds]",
            "def filter_outside_objs(gt_bboxes_list, gt_labels_list, gt_bboxes_3d_list, gt_labels_3d_list, centers2d_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Function to filter the objects label outside the image.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            each has shape (num_gt, 4).\\n        gt_labels_list (list[Tensor]): Ground truth labels of each box,\\n            each has shape (num_gt,).\\n        gt_bboxes_3d_list (list[Tensor]): 3D Ground truth bboxes of each\\n            image, each has shape (num_gt, bbox_code_size).\\n        gt_labels_3d_list (list[Tensor]): 3D Ground truth labels of each\\n            box, each has shape (num_gt,).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            each has shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n    '\n    bs = len(centers2d_list)\n    for i in range(bs):\n        centers2d = centers2d_list[i].clone()\n        img_shape = img_metas[i]['img_shape']\n        keep_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        centers2d_list[i] = centers2d[keep_inds]\n        gt_labels_list[i] = gt_labels_list[i][keep_inds]\n        gt_bboxes_list[i] = gt_bboxes_list[i][keep_inds]\n        gt_bboxes_3d_list[i].tensor = gt_bboxes_3d_list[i].tensor[keep_inds]\n        gt_labels_3d_list[i] = gt_labels_3d_list[i][keep_inds]",
            "def filter_outside_objs(gt_bboxes_list, gt_labels_list, gt_bboxes_3d_list, gt_labels_3d_list, centers2d_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Function to filter the objects label outside the image.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            each has shape (num_gt, 4).\\n        gt_labels_list (list[Tensor]): Ground truth labels of each box,\\n            each has shape (num_gt,).\\n        gt_bboxes_3d_list (list[Tensor]): 3D Ground truth bboxes of each\\n            image, each has shape (num_gt, bbox_code_size).\\n        gt_labels_3d_list (list[Tensor]): 3D Ground truth labels of each\\n            box, each has shape (num_gt,).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            each has shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n    '\n    bs = len(centers2d_list)\n    for i in range(bs):\n        centers2d = centers2d_list[i].clone()\n        img_shape = img_metas[i]['img_shape']\n        keep_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        centers2d_list[i] = centers2d[keep_inds]\n        gt_labels_list[i] = gt_labels_list[i][keep_inds]\n        gt_bboxes_list[i] = gt_bboxes_list[i][keep_inds]\n        gt_bboxes_3d_list[i].tensor = gt_bboxes_3d_list[i].tensor[keep_inds]\n        gt_labels_3d_list[i] = gt_labels_3d_list[i][keep_inds]"
        ]
    },
    {
        "func_name": "get_centers2d_target",
        "original": "def get_centers2d_target(centers2d, centers, img_shape):\n    \"\"\"Function to get target centers2d.\n\n    Args:\n        centers2d (Tensor): Projected 3D centers onto 2D images.\n        centers (Tensor): Centers of 2d gt bboxes.\n        img_shape (tuple): Resized image shape.\n\n    Returns:\n        torch.Tensor: Projected 3D centers (centers2D) target.\n    \"\"\"\n    N = centers2d.shape[0]\n    (h, w) = img_shape[:2]\n    valid_intersects = centers2d.new_zeros((N, 2))\n    a = (centers[:, 1] - centers2d[:, 1]) / (centers[:, 0] - centers2d[:, 0])\n    b = centers[:, 1] - a * centers[:, 0]\n    left_y = b\n    right_y = (w - 1) * a + b\n    top_x = -b / a\n    bottom_x = (h - 1 - b) / a\n    left_coors = torch.stack((left_y.new_zeros(N), left_y), dim=1)\n    right_coors = torch.stack((right_y.new_full((N,), w - 1), right_y), dim=1)\n    top_coors = torch.stack((top_x, top_x.new_zeros(N)), dim=1)\n    bottom_coors = torch.stack((bottom_x, bottom_x.new_full((N,), h - 1)), dim=1)\n    intersects = torch.stack([left_coors, right_coors, top_coors, bottom_coors], dim=1)\n    intersects_x = intersects[:, :, 0]\n    intersects_y = intersects[:, :, 1]\n    inds = (intersects_x >= 0) & (intersects_x <= w - 1) & (intersects_y >= 0) & (intersects_y <= h - 1)\n    valid_intersects = intersects[inds].reshape(N, 2, 2)\n    dist = torch.norm(valid_intersects - centers2d.unsqueeze(1), dim=2)\n    min_idx = torch.argmin(dist, dim=1)\n    min_idx = min_idx.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 2)\n    centers2d_target = valid_intersects.gather(dim=1, index=min_idx).squeeze(1)\n    return centers2d_target",
        "mutated": [
            "def get_centers2d_target(centers2d, centers, img_shape):\n    if False:\n        i = 10\n    'Function to get target centers2d.\\n\\n    Args:\\n        centers2d (Tensor): Projected 3D centers onto 2D images.\\n        centers (Tensor): Centers of 2d gt bboxes.\\n        img_shape (tuple): Resized image shape.\\n\\n    Returns:\\n        torch.Tensor: Projected 3D centers (centers2D) target.\\n    '\n    N = centers2d.shape[0]\n    (h, w) = img_shape[:2]\n    valid_intersects = centers2d.new_zeros((N, 2))\n    a = (centers[:, 1] - centers2d[:, 1]) / (centers[:, 0] - centers2d[:, 0])\n    b = centers[:, 1] - a * centers[:, 0]\n    left_y = b\n    right_y = (w - 1) * a + b\n    top_x = -b / a\n    bottom_x = (h - 1 - b) / a\n    left_coors = torch.stack((left_y.new_zeros(N), left_y), dim=1)\n    right_coors = torch.stack((right_y.new_full((N,), w - 1), right_y), dim=1)\n    top_coors = torch.stack((top_x, top_x.new_zeros(N)), dim=1)\n    bottom_coors = torch.stack((bottom_x, bottom_x.new_full((N,), h - 1)), dim=1)\n    intersects = torch.stack([left_coors, right_coors, top_coors, bottom_coors], dim=1)\n    intersects_x = intersects[:, :, 0]\n    intersects_y = intersects[:, :, 1]\n    inds = (intersects_x >= 0) & (intersects_x <= w - 1) & (intersects_y >= 0) & (intersects_y <= h - 1)\n    valid_intersects = intersects[inds].reshape(N, 2, 2)\n    dist = torch.norm(valid_intersects - centers2d.unsqueeze(1), dim=2)\n    min_idx = torch.argmin(dist, dim=1)\n    min_idx = min_idx.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 2)\n    centers2d_target = valid_intersects.gather(dim=1, index=min_idx).squeeze(1)\n    return centers2d_target",
            "def get_centers2d_target(centers2d, centers, img_shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Function to get target centers2d.\\n\\n    Args:\\n        centers2d (Tensor): Projected 3D centers onto 2D images.\\n        centers (Tensor): Centers of 2d gt bboxes.\\n        img_shape (tuple): Resized image shape.\\n\\n    Returns:\\n        torch.Tensor: Projected 3D centers (centers2D) target.\\n    '\n    N = centers2d.shape[0]\n    (h, w) = img_shape[:2]\n    valid_intersects = centers2d.new_zeros((N, 2))\n    a = (centers[:, 1] - centers2d[:, 1]) / (centers[:, 0] - centers2d[:, 0])\n    b = centers[:, 1] - a * centers[:, 0]\n    left_y = b\n    right_y = (w - 1) * a + b\n    top_x = -b / a\n    bottom_x = (h - 1 - b) / a\n    left_coors = torch.stack((left_y.new_zeros(N), left_y), dim=1)\n    right_coors = torch.stack((right_y.new_full((N,), w - 1), right_y), dim=1)\n    top_coors = torch.stack((top_x, top_x.new_zeros(N)), dim=1)\n    bottom_coors = torch.stack((bottom_x, bottom_x.new_full((N,), h - 1)), dim=1)\n    intersects = torch.stack([left_coors, right_coors, top_coors, bottom_coors], dim=1)\n    intersects_x = intersects[:, :, 0]\n    intersects_y = intersects[:, :, 1]\n    inds = (intersects_x >= 0) & (intersects_x <= w - 1) & (intersects_y >= 0) & (intersects_y <= h - 1)\n    valid_intersects = intersects[inds].reshape(N, 2, 2)\n    dist = torch.norm(valid_intersects - centers2d.unsqueeze(1), dim=2)\n    min_idx = torch.argmin(dist, dim=1)\n    min_idx = min_idx.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 2)\n    centers2d_target = valid_intersects.gather(dim=1, index=min_idx).squeeze(1)\n    return centers2d_target",
            "def get_centers2d_target(centers2d, centers, img_shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Function to get target centers2d.\\n\\n    Args:\\n        centers2d (Tensor): Projected 3D centers onto 2D images.\\n        centers (Tensor): Centers of 2d gt bboxes.\\n        img_shape (tuple): Resized image shape.\\n\\n    Returns:\\n        torch.Tensor: Projected 3D centers (centers2D) target.\\n    '\n    N = centers2d.shape[0]\n    (h, w) = img_shape[:2]\n    valid_intersects = centers2d.new_zeros((N, 2))\n    a = (centers[:, 1] - centers2d[:, 1]) / (centers[:, 0] - centers2d[:, 0])\n    b = centers[:, 1] - a * centers[:, 0]\n    left_y = b\n    right_y = (w - 1) * a + b\n    top_x = -b / a\n    bottom_x = (h - 1 - b) / a\n    left_coors = torch.stack((left_y.new_zeros(N), left_y), dim=1)\n    right_coors = torch.stack((right_y.new_full((N,), w - 1), right_y), dim=1)\n    top_coors = torch.stack((top_x, top_x.new_zeros(N)), dim=1)\n    bottom_coors = torch.stack((bottom_x, bottom_x.new_full((N,), h - 1)), dim=1)\n    intersects = torch.stack([left_coors, right_coors, top_coors, bottom_coors], dim=1)\n    intersects_x = intersects[:, :, 0]\n    intersects_y = intersects[:, :, 1]\n    inds = (intersects_x >= 0) & (intersects_x <= w - 1) & (intersects_y >= 0) & (intersects_y <= h - 1)\n    valid_intersects = intersects[inds].reshape(N, 2, 2)\n    dist = torch.norm(valid_intersects - centers2d.unsqueeze(1), dim=2)\n    min_idx = torch.argmin(dist, dim=1)\n    min_idx = min_idx.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 2)\n    centers2d_target = valid_intersects.gather(dim=1, index=min_idx).squeeze(1)\n    return centers2d_target",
            "def get_centers2d_target(centers2d, centers, img_shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Function to get target centers2d.\\n\\n    Args:\\n        centers2d (Tensor): Projected 3D centers onto 2D images.\\n        centers (Tensor): Centers of 2d gt bboxes.\\n        img_shape (tuple): Resized image shape.\\n\\n    Returns:\\n        torch.Tensor: Projected 3D centers (centers2D) target.\\n    '\n    N = centers2d.shape[0]\n    (h, w) = img_shape[:2]\n    valid_intersects = centers2d.new_zeros((N, 2))\n    a = (centers[:, 1] - centers2d[:, 1]) / (centers[:, 0] - centers2d[:, 0])\n    b = centers[:, 1] - a * centers[:, 0]\n    left_y = b\n    right_y = (w - 1) * a + b\n    top_x = -b / a\n    bottom_x = (h - 1 - b) / a\n    left_coors = torch.stack((left_y.new_zeros(N), left_y), dim=1)\n    right_coors = torch.stack((right_y.new_full((N,), w - 1), right_y), dim=1)\n    top_coors = torch.stack((top_x, top_x.new_zeros(N)), dim=1)\n    bottom_coors = torch.stack((bottom_x, bottom_x.new_full((N,), h - 1)), dim=1)\n    intersects = torch.stack([left_coors, right_coors, top_coors, bottom_coors], dim=1)\n    intersects_x = intersects[:, :, 0]\n    intersects_y = intersects[:, :, 1]\n    inds = (intersects_x >= 0) & (intersects_x <= w - 1) & (intersects_y >= 0) & (intersects_y <= h - 1)\n    valid_intersects = intersects[inds].reshape(N, 2, 2)\n    dist = torch.norm(valid_intersects - centers2d.unsqueeze(1), dim=2)\n    min_idx = torch.argmin(dist, dim=1)\n    min_idx = min_idx.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 2)\n    centers2d_target = valid_intersects.gather(dim=1, index=min_idx).squeeze(1)\n    return centers2d_target",
            "def get_centers2d_target(centers2d, centers, img_shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Function to get target centers2d.\\n\\n    Args:\\n        centers2d (Tensor): Projected 3D centers onto 2D images.\\n        centers (Tensor): Centers of 2d gt bboxes.\\n        img_shape (tuple): Resized image shape.\\n\\n    Returns:\\n        torch.Tensor: Projected 3D centers (centers2D) target.\\n    '\n    N = centers2d.shape[0]\n    (h, w) = img_shape[:2]\n    valid_intersects = centers2d.new_zeros((N, 2))\n    a = (centers[:, 1] - centers2d[:, 1]) / (centers[:, 0] - centers2d[:, 0])\n    b = centers[:, 1] - a * centers[:, 0]\n    left_y = b\n    right_y = (w - 1) * a + b\n    top_x = -b / a\n    bottom_x = (h - 1 - b) / a\n    left_coors = torch.stack((left_y.new_zeros(N), left_y), dim=1)\n    right_coors = torch.stack((right_y.new_full((N,), w - 1), right_y), dim=1)\n    top_coors = torch.stack((top_x, top_x.new_zeros(N)), dim=1)\n    bottom_coors = torch.stack((bottom_x, bottom_x.new_full((N,), h - 1)), dim=1)\n    intersects = torch.stack([left_coors, right_coors, top_coors, bottom_coors], dim=1)\n    intersects_x = intersects[:, :, 0]\n    intersects_y = intersects[:, :, 1]\n    inds = (intersects_x >= 0) & (intersects_x <= w - 1) & (intersects_y >= 0) & (intersects_y <= h - 1)\n    valid_intersects = intersects[inds].reshape(N, 2, 2)\n    dist = torch.norm(valid_intersects - centers2d.unsqueeze(1), dim=2)\n    min_idx = torch.argmin(dist, dim=1)\n    min_idx = min_idx.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 2)\n    centers2d_target = valid_intersects.gather(dim=1, index=min_idx).squeeze(1)\n    return centers2d_target"
        ]
    },
    {
        "func_name": "handle_proj_objs",
        "original": "def handle_proj_objs(centers2d_list, gt_bboxes_list, img_metas):\n    \"\"\"Function to handle projected object centers2d, generate target\n    centers2d.\n\n    Args:\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\n            shape (num_gt, 4).\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\n            shape (num_gt, 2).\n        img_metas (list[dict]): Meta information of each image, e.g.,\n            image size, scaling factor, etc.\n\n    Returns:\n        tuple[list[Tensor]]: It contains three elements. The first is the\n        target centers2d after handling the truncated objects. The second\n        is the offsets between target centers2d and round int dtype\n        centers2d,and the last is the truncation mask for each object in\n        batch data.\n    \"\"\"\n    bs = len(centers2d_list)\n    centers2d_target_list = []\n    trunc_mask_list = []\n    offsets2d_list = []\n    for i in range(bs):\n        centers2d = centers2d_list[i]\n        gt_bbox = gt_bboxes_list[i]\n        img_shape = img_metas[i]['img_shape']\n        centers2d_target = centers2d.clone()\n        inside_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        outside_inds = ~inside_inds\n        if outside_inds.any():\n            centers = (gt_bbox[:, :2] + gt_bbox[:, 2:]) / 2\n            outside_centers2d = centers2d[outside_inds]\n            match_centers = centers[outside_inds]\n            target_outside_centers2d = get_centers2d_target(outside_centers2d, match_centers, img_shape)\n            centers2d_target[outside_inds] = target_outside_centers2d\n        offsets2d = centers2d - centers2d_target.round().int()\n        trunc_mask = outside_inds\n        centers2d_target_list.append(centers2d_target)\n        trunc_mask_list.append(trunc_mask)\n        offsets2d_list.append(offsets2d)\n    return (centers2d_target_list, offsets2d_list, trunc_mask_list)",
        "mutated": [
            "def handle_proj_objs(centers2d_list, gt_bboxes_list, img_metas):\n    if False:\n        i = 10\n    'Function to handle projected object centers2d, generate target\\n    centers2d.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            shape (num_gt, 4).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n\\n    Returns:\\n        tuple[list[Tensor]]: It contains three elements. The first is the\\n        target centers2d after handling the truncated objects. The second\\n        is the offsets between target centers2d and round int dtype\\n        centers2d,and the last is the truncation mask for each object in\\n        batch data.\\n    '\n    bs = len(centers2d_list)\n    centers2d_target_list = []\n    trunc_mask_list = []\n    offsets2d_list = []\n    for i in range(bs):\n        centers2d = centers2d_list[i]\n        gt_bbox = gt_bboxes_list[i]\n        img_shape = img_metas[i]['img_shape']\n        centers2d_target = centers2d.clone()\n        inside_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        outside_inds = ~inside_inds\n        if outside_inds.any():\n            centers = (gt_bbox[:, :2] + gt_bbox[:, 2:]) / 2\n            outside_centers2d = centers2d[outside_inds]\n            match_centers = centers[outside_inds]\n            target_outside_centers2d = get_centers2d_target(outside_centers2d, match_centers, img_shape)\n            centers2d_target[outside_inds] = target_outside_centers2d\n        offsets2d = centers2d - centers2d_target.round().int()\n        trunc_mask = outside_inds\n        centers2d_target_list.append(centers2d_target)\n        trunc_mask_list.append(trunc_mask)\n        offsets2d_list.append(offsets2d)\n    return (centers2d_target_list, offsets2d_list, trunc_mask_list)",
            "def handle_proj_objs(centers2d_list, gt_bboxes_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Function to handle projected object centers2d, generate target\\n    centers2d.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            shape (num_gt, 4).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n\\n    Returns:\\n        tuple[list[Tensor]]: It contains three elements. The first is the\\n        target centers2d after handling the truncated objects. The second\\n        is the offsets between target centers2d and round int dtype\\n        centers2d,and the last is the truncation mask for each object in\\n        batch data.\\n    '\n    bs = len(centers2d_list)\n    centers2d_target_list = []\n    trunc_mask_list = []\n    offsets2d_list = []\n    for i in range(bs):\n        centers2d = centers2d_list[i]\n        gt_bbox = gt_bboxes_list[i]\n        img_shape = img_metas[i]['img_shape']\n        centers2d_target = centers2d.clone()\n        inside_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        outside_inds = ~inside_inds\n        if outside_inds.any():\n            centers = (gt_bbox[:, :2] + gt_bbox[:, 2:]) / 2\n            outside_centers2d = centers2d[outside_inds]\n            match_centers = centers[outside_inds]\n            target_outside_centers2d = get_centers2d_target(outside_centers2d, match_centers, img_shape)\n            centers2d_target[outside_inds] = target_outside_centers2d\n        offsets2d = centers2d - centers2d_target.round().int()\n        trunc_mask = outside_inds\n        centers2d_target_list.append(centers2d_target)\n        trunc_mask_list.append(trunc_mask)\n        offsets2d_list.append(offsets2d)\n    return (centers2d_target_list, offsets2d_list, trunc_mask_list)",
            "def handle_proj_objs(centers2d_list, gt_bboxes_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Function to handle projected object centers2d, generate target\\n    centers2d.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            shape (num_gt, 4).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n\\n    Returns:\\n        tuple[list[Tensor]]: It contains three elements. The first is the\\n        target centers2d after handling the truncated objects. The second\\n        is the offsets between target centers2d and round int dtype\\n        centers2d,and the last is the truncation mask for each object in\\n        batch data.\\n    '\n    bs = len(centers2d_list)\n    centers2d_target_list = []\n    trunc_mask_list = []\n    offsets2d_list = []\n    for i in range(bs):\n        centers2d = centers2d_list[i]\n        gt_bbox = gt_bboxes_list[i]\n        img_shape = img_metas[i]['img_shape']\n        centers2d_target = centers2d.clone()\n        inside_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        outside_inds = ~inside_inds\n        if outside_inds.any():\n            centers = (gt_bbox[:, :2] + gt_bbox[:, 2:]) / 2\n            outside_centers2d = centers2d[outside_inds]\n            match_centers = centers[outside_inds]\n            target_outside_centers2d = get_centers2d_target(outside_centers2d, match_centers, img_shape)\n            centers2d_target[outside_inds] = target_outside_centers2d\n        offsets2d = centers2d - centers2d_target.round().int()\n        trunc_mask = outside_inds\n        centers2d_target_list.append(centers2d_target)\n        trunc_mask_list.append(trunc_mask)\n        offsets2d_list.append(offsets2d)\n    return (centers2d_target_list, offsets2d_list, trunc_mask_list)",
            "def handle_proj_objs(centers2d_list, gt_bboxes_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Function to handle projected object centers2d, generate target\\n    centers2d.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            shape (num_gt, 4).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n\\n    Returns:\\n        tuple[list[Tensor]]: It contains three elements. The first is the\\n        target centers2d after handling the truncated objects. The second\\n        is the offsets between target centers2d and round int dtype\\n        centers2d,and the last is the truncation mask for each object in\\n        batch data.\\n    '\n    bs = len(centers2d_list)\n    centers2d_target_list = []\n    trunc_mask_list = []\n    offsets2d_list = []\n    for i in range(bs):\n        centers2d = centers2d_list[i]\n        gt_bbox = gt_bboxes_list[i]\n        img_shape = img_metas[i]['img_shape']\n        centers2d_target = centers2d.clone()\n        inside_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        outside_inds = ~inside_inds\n        if outside_inds.any():\n            centers = (gt_bbox[:, :2] + gt_bbox[:, 2:]) / 2\n            outside_centers2d = centers2d[outside_inds]\n            match_centers = centers[outside_inds]\n            target_outside_centers2d = get_centers2d_target(outside_centers2d, match_centers, img_shape)\n            centers2d_target[outside_inds] = target_outside_centers2d\n        offsets2d = centers2d - centers2d_target.round().int()\n        trunc_mask = outside_inds\n        centers2d_target_list.append(centers2d_target)\n        trunc_mask_list.append(trunc_mask)\n        offsets2d_list.append(offsets2d)\n    return (centers2d_target_list, offsets2d_list, trunc_mask_list)",
            "def handle_proj_objs(centers2d_list, gt_bboxes_list, img_metas):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Function to handle projected object centers2d, generate target\\n    centers2d.\\n\\n    Args:\\n        gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,\\n            shape (num_gt, 4).\\n        centers2d_list (list[Tensor]): Projected 3D centers onto 2D image,\\n            shape (num_gt, 2).\\n        img_metas (list[dict]): Meta information of each image, e.g.,\\n            image size, scaling factor, etc.\\n\\n    Returns:\\n        tuple[list[Tensor]]: It contains three elements. The first is the\\n        target centers2d after handling the truncated objects. The second\\n        is the offsets between target centers2d and round int dtype\\n        centers2d,and the last is the truncation mask for each object in\\n        batch data.\\n    '\n    bs = len(centers2d_list)\n    centers2d_target_list = []\n    trunc_mask_list = []\n    offsets2d_list = []\n    for i in range(bs):\n        centers2d = centers2d_list[i]\n        gt_bbox = gt_bboxes_list[i]\n        img_shape = img_metas[i]['img_shape']\n        centers2d_target = centers2d.clone()\n        inside_inds = (centers2d[:, 0] > 0) & (centers2d[:, 0] < img_shape[1]) & (centers2d[:, 1] > 0) & (centers2d[:, 1] < img_shape[0])\n        outside_inds = ~inside_inds\n        if outside_inds.any():\n            centers = (gt_bbox[:, :2] + gt_bbox[:, 2:]) / 2\n            outside_centers2d = centers2d[outside_inds]\n            match_centers = centers[outside_inds]\n            target_outside_centers2d = get_centers2d_target(outside_centers2d, match_centers, img_shape)\n            centers2d_target[outside_inds] = target_outside_centers2d\n        offsets2d = centers2d - centers2d_target.round().int()\n        trunc_mask = outside_inds\n        centers2d_target_list.append(centers2d_target)\n        trunc_mask_list.append(trunc_mask)\n        offsets2d_list.append(offsets2d)\n    return (centers2d_target_list, offsets2d_list, trunc_mask_list)"
        ]
    }
]