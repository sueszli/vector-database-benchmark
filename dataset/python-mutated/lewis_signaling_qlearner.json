[
    {
        "func_name": "run_experiment",
        "original": "def run_experiment(num_players, env, payoffs, centralized):\n    \"\"\"Run the experiments.\"\"\"\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    num_actions = env.action_spec()['num_actions']\n    num_runs = FLAGS.num_runs\n    training_episodes = FLAGS.num_episodes\n    log_interval = FLAGS.log_interval\n    rewards = np.zeros((num_runs, training_episodes // log_interval))\n    opts = np.zeros((num_runs, training_episodes // log_interval))\n    converge_point = np.zeros((num_states, num_states))\n    percent_opt = 0\n    for i in range(num_runs):\n        eps_schedule = rl_tools.LinearSchedule(FLAGS.eps_init, FLAGS.eps_final, FLAGS.eps_decay_steps * 2)\n        agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions, step_size=FLAGS.step_size, epsilon_schedule=eps_schedule, centralized=centralized) for idx in range(num_players)]\n        for cur_episode in range(training_episodes):\n            time_step = env.reset()\n            cur_state = time_step.observations['info_state'][0][3:].index(1)\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = agents[player_id].step(time_step)\n                time_step = env.step([agent_output.action])\n            for agent in agents:\n                agent.step(time_step)\n            reward = time_step.rewards[0]\n            max_reward = payoffs[cur_state].max()\n            cur_idx = (i, cur_episode // log_interval)\n            rewards[cur_idx] += reward / log_interval\n            opts[cur_idx] += np.isclose(reward, max_reward) / log_interval\n        base_info_state0 = [1.0, 0.0, 0.0] + [0.0] * num_states\n        base_info_state1 = [0.0, 1.0, 0.0] + [0.0] * num_states\n        if centralized:\n            base_info_state0 = [base_info_state0, base_info_state0.copy()]\n            base_info_state1 = [base_info_state1, base_info_state1.copy()]\n        for s in range(num_states):\n            info_state0 = copy.deepcopy(base_info_state0)\n            if centralized:\n                info_state0[0][3 + s] = 1.0\n            else:\n                info_state0[3 + s] = 1.0\n            (m, _) = agents[0]._epsilon_greedy(str(info_state0), np.arange(num_messages), 0)\n            info_state1 = copy.deepcopy(base_info_state1)\n            if centralized:\n                info_state1[0][3 + s] = 1.0\n                info_state1[1][3 + m] = 1.0\n            else:\n                info_state1[3 + m] = 1.0\n            (a, _) = agents[1]._epsilon_greedy(str(info_state1), np.arange(num_states), 0)\n            converge_point[s, a] += 1\n            best_act = payoffs[s].argmax()\n            percent_opt += int(a == best_act) / num_runs / num_states\n    return (rewards, opts, converge_point, percent_opt)",
        "mutated": [
            "def run_experiment(num_players, env, payoffs, centralized):\n    if False:\n        i = 10\n    'Run the experiments.'\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    num_actions = env.action_spec()['num_actions']\n    num_runs = FLAGS.num_runs\n    training_episodes = FLAGS.num_episodes\n    log_interval = FLAGS.log_interval\n    rewards = np.zeros((num_runs, training_episodes // log_interval))\n    opts = np.zeros((num_runs, training_episodes // log_interval))\n    converge_point = np.zeros((num_states, num_states))\n    percent_opt = 0\n    for i in range(num_runs):\n        eps_schedule = rl_tools.LinearSchedule(FLAGS.eps_init, FLAGS.eps_final, FLAGS.eps_decay_steps * 2)\n        agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions, step_size=FLAGS.step_size, epsilon_schedule=eps_schedule, centralized=centralized) for idx in range(num_players)]\n        for cur_episode in range(training_episodes):\n            time_step = env.reset()\n            cur_state = time_step.observations['info_state'][0][3:].index(1)\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = agents[player_id].step(time_step)\n                time_step = env.step([agent_output.action])\n            for agent in agents:\n                agent.step(time_step)\n            reward = time_step.rewards[0]\n            max_reward = payoffs[cur_state].max()\n            cur_idx = (i, cur_episode // log_interval)\n            rewards[cur_idx] += reward / log_interval\n            opts[cur_idx] += np.isclose(reward, max_reward) / log_interval\n        base_info_state0 = [1.0, 0.0, 0.0] + [0.0] * num_states\n        base_info_state1 = [0.0, 1.0, 0.0] + [0.0] * num_states\n        if centralized:\n            base_info_state0 = [base_info_state0, base_info_state0.copy()]\n            base_info_state1 = [base_info_state1, base_info_state1.copy()]\n        for s in range(num_states):\n            info_state0 = copy.deepcopy(base_info_state0)\n            if centralized:\n                info_state0[0][3 + s] = 1.0\n            else:\n                info_state0[3 + s] = 1.0\n            (m, _) = agents[0]._epsilon_greedy(str(info_state0), np.arange(num_messages), 0)\n            info_state1 = copy.deepcopy(base_info_state1)\n            if centralized:\n                info_state1[0][3 + s] = 1.0\n                info_state1[1][3 + m] = 1.0\n            else:\n                info_state1[3 + m] = 1.0\n            (a, _) = agents[1]._epsilon_greedy(str(info_state1), np.arange(num_states), 0)\n            converge_point[s, a] += 1\n            best_act = payoffs[s].argmax()\n            percent_opt += int(a == best_act) / num_runs / num_states\n    return (rewards, opts, converge_point, percent_opt)",
            "def run_experiment(num_players, env, payoffs, centralized):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Run the experiments.'\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    num_actions = env.action_spec()['num_actions']\n    num_runs = FLAGS.num_runs\n    training_episodes = FLAGS.num_episodes\n    log_interval = FLAGS.log_interval\n    rewards = np.zeros((num_runs, training_episodes // log_interval))\n    opts = np.zeros((num_runs, training_episodes // log_interval))\n    converge_point = np.zeros((num_states, num_states))\n    percent_opt = 0\n    for i in range(num_runs):\n        eps_schedule = rl_tools.LinearSchedule(FLAGS.eps_init, FLAGS.eps_final, FLAGS.eps_decay_steps * 2)\n        agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions, step_size=FLAGS.step_size, epsilon_schedule=eps_schedule, centralized=centralized) for idx in range(num_players)]\n        for cur_episode in range(training_episodes):\n            time_step = env.reset()\n            cur_state = time_step.observations['info_state'][0][3:].index(1)\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = agents[player_id].step(time_step)\n                time_step = env.step([agent_output.action])\n            for agent in agents:\n                agent.step(time_step)\n            reward = time_step.rewards[0]\n            max_reward = payoffs[cur_state].max()\n            cur_idx = (i, cur_episode // log_interval)\n            rewards[cur_idx] += reward / log_interval\n            opts[cur_idx] += np.isclose(reward, max_reward) / log_interval\n        base_info_state0 = [1.0, 0.0, 0.0] + [0.0] * num_states\n        base_info_state1 = [0.0, 1.0, 0.0] + [0.0] * num_states\n        if centralized:\n            base_info_state0 = [base_info_state0, base_info_state0.copy()]\n            base_info_state1 = [base_info_state1, base_info_state1.copy()]\n        for s in range(num_states):\n            info_state0 = copy.deepcopy(base_info_state0)\n            if centralized:\n                info_state0[0][3 + s] = 1.0\n            else:\n                info_state0[3 + s] = 1.0\n            (m, _) = agents[0]._epsilon_greedy(str(info_state0), np.arange(num_messages), 0)\n            info_state1 = copy.deepcopy(base_info_state1)\n            if centralized:\n                info_state1[0][3 + s] = 1.0\n                info_state1[1][3 + m] = 1.0\n            else:\n                info_state1[3 + m] = 1.0\n            (a, _) = agents[1]._epsilon_greedy(str(info_state1), np.arange(num_states), 0)\n            converge_point[s, a] += 1\n            best_act = payoffs[s].argmax()\n            percent_opt += int(a == best_act) / num_runs / num_states\n    return (rewards, opts, converge_point, percent_opt)",
            "def run_experiment(num_players, env, payoffs, centralized):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Run the experiments.'\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    num_actions = env.action_spec()['num_actions']\n    num_runs = FLAGS.num_runs\n    training_episodes = FLAGS.num_episodes\n    log_interval = FLAGS.log_interval\n    rewards = np.zeros((num_runs, training_episodes // log_interval))\n    opts = np.zeros((num_runs, training_episodes // log_interval))\n    converge_point = np.zeros((num_states, num_states))\n    percent_opt = 0\n    for i in range(num_runs):\n        eps_schedule = rl_tools.LinearSchedule(FLAGS.eps_init, FLAGS.eps_final, FLAGS.eps_decay_steps * 2)\n        agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions, step_size=FLAGS.step_size, epsilon_schedule=eps_schedule, centralized=centralized) for idx in range(num_players)]\n        for cur_episode in range(training_episodes):\n            time_step = env.reset()\n            cur_state = time_step.observations['info_state'][0][3:].index(1)\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = agents[player_id].step(time_step)\n                time_step = env.step([agent_output.action])\n            for agent in agents:\n                agent.step(time_step)\n            reward = time_step.rewards[0]\n            max_reward = payoffs[cur_state].max()\n            cur_idx = (i, cur_episode // log_interval)\n            rewards[cur_idx] += reward / log_interval\n            opts[cur_idx] += np.isclose(reward, max_reward) / log_interval\n        base_info_state0 = [1.0, 0.0, 0.0] + [0.0] * num_states\n        base_info_state1 = [0.0, 1.0, 0.0] + [0.0] * num_states\n        if centralized:\n            base_info_state0 = [base_info_state0, base_info_state0.copy()]\n            base_info_state1 = [base_info_state1, base_info_state1.copy()]\n        for s in range(num_states):\n            info_state0 = copy.deepcopy(base_info_state0)\n            if centralized:\n                info_state0[0][3 + s] = 1.0\n            else:\n                info_state0[3 + s] = 1.0\n            (m, _) = agents[0]._epsilon_greedy(str(info_state0), np.arange(num_messages), 0)\n            info_state1 = copy.deepcopy(base_info_state1)\n            if centralized:\n                info_state1[0][3 + s] = 1.0\n                info_state1[1][3 + m] = 1.0\n            else:\n                info_state1[3 + m] = 1.0\n            (a, _) = agents[1]._epsilon_greedy(str(info_state1), np.arange(num_states), 0)\n            converge_point[s, a] += 1\n            best_act = payoffs[s].argmax()\n            percent_opt += int(a == best_act) / num_runs / num_states\n    return (rewards, opts, converge_point, percent_opt)",
            "def run_experiment(num_players, env, payoffs, centralized):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Run the experiments.'\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    num_actions = env.action_spec()['num_actions']\n    num_runs = FLAGS.num_runs\n    training_episodes = FLAGS.num_episodes\n    log_interval = FLAGS.log_interval\n    rewards = np.zeros((num_runs, training_episodes // log_interval))\n    opts = np.zeros((num_runs, training_episodes // log_interval))\n    converge_point = np.zeros((num_states, num_states))\n    percent_opt = 0\n    for i in range(num_runs):\n        eps_schedule = rl_tools.LinearSchedule(FLAGS.eps_init, FLAGS.eps_final, FLAGS.eps_decay_steps * 2)\n        agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions, step_size=FLAGS.step_size, epsilon_schedule=eps_schedule, centralized=centralized) for idx in range(num_players)]\n        for cur_episode in range(training_episodes):\n            time_step = env.reset()\n            cur_state = time_step.observations['info_state'][0][3:].index(1)\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = agents[player_id].step(time_step)\n                time_step = env.step([agent_output.action])\n            for agent in agents:\n                agent.step(time_step)\n            reward = time_step.rewards[0]\n            max_reward = payoffs[cur_state].max()\n            cur_idx = (i, cur_episode // log_interval)\n            rewards[cur_idx] += reward / log_interval\n            opts[cur_idx] += np.isclose(reward, max_reward) / log_interval\n        base_info_state0 = [1.0, 0.0, 0.0] + [0.0] * num_states\n        base_info_state1 = [0.0, 1.0, 0.0] + [0.0] * num_states\n        if centralized:\n            base_info_state0 = [base_info_state0, base_info_state0.copy()]\n            base_info_state1 = [base_info_state1, base_info_state1.copy()]\n        for s in range(num_states):\n            info_state0 = copy.deepcopy(base_info_state0)\n            if centralized:\n                info_state0[0][3 + s] = 1.0\n            else:\n                info_state0[3 + s] = 1.0\n            (m, _) = agents[0]._epsilon_greedy(str(info_state0), np.arange(num_messages), 0)\n            info_state1 = copy.deepcopy(base_info_state1)\n            if centralized:\n                info_state1[0][3 + s] = 1.0\n                info_state1[1][3 + m] = 1.0\n            else:\n                info_state1[3 + m] = 1.0\n            (a, _) = agents[1]._epsilon_greedy(str(info_state1), np.arange(num_states), 0)\n            converge_point[s, a] += 1\n            best_act = payoffs[s].argmax()\n            percent_opt += int(a == best_act) / num_runs / num_states\n    return (rewards, opts, converge_point, percent_opt)",
            "def run_experiment(num_players, env, payoffs, centralized):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Run the experiments.'\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    num_actions = env.action_spec()['num_actions']\n    num_runs = FLAGS.num_runs\n    training_episodes = FLAGS.num_episodes\n    log_interval = FLAGS.log_interval\n    rewards = np.zeros((num_runs, training_episodes // log_interval))\n    opts = np.zeros((num_runs, training_episodes // log_interval))\n    converge_point = np.zeros((num_states, num_states))\n    percent_opt = 0\n    for i in range(num_runs):\n        eps_schedule = rl_tools.LinearSchedule(FLAGS.eps_init, FLAGS.eps_final, FLAGS.eps_decay_steps * 2)\n        agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions, step_size=FLAGS.step_size, epsilon_schedule=eps_schedule, centralized=centralized) for idx in range(num_players)]\n        for cur_episode in range(training_episodes):\n            time_step = env.reset()\n            cur_state = time_step.observations['info_state'][0][3:].index(1)\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = agents[player_id].step(time_step)\n                time_step = env.step([agent_output.action])\n            for agent in agents:\n                agent.step(time_step)\n            reward = time_step.rewards[0]\n            max_reward = payoffs[cur_state].max()\n            cur_idx = (i, cur_episode // log_interval)\n            rewards[cur_idx] += reward / log_interval\n            opts[cur_idx] += np.isclose(reward, max_reward) / log_interval\n        base_info_state0 = [1.0, 0.0, 0.0] + [0.0] * num_states\n        base_info_state1 = [0.0, 1.0, 0.0] + [0.0] * num_states\n        if centralized:\n            base_info_state0 = [base_info_state0, base_info_state0.copy()]\n            base_info_state1 = [base_info_state1, base_info_state1.copy()]\n        for s in range(num_states):\n            info_state0 = copy.deepcopy(base_info_state0)\n            if centralized:\n                info_state0[0][3 + s] = 1.0\n            else:\n                info_state0[3 + s] = 1.0\n            (m, _) = agents[0]._epsilon_greedy(str(info_state0), np.arange(num_messages), 0)\n            info_state1 = copy.deepcopy(base_info_state1)\n            if centralized:\n                info_state1[0][3 + s] = 1.0\n                info_state1[1][3 + m] = 1.0\n            else:\n                info_state1[3 + m] = 1.0\n            (a, _) = agents[1]._epsilon_greedy(str(info_state1), np.arange(num_states), 0)\n            converge_point[s, a] += 1\n            best_act = payoffs[s].argmax()\n            percent_opt += int(a == best_act) / num_runs / num_states\n    return (rewards, opts, converge_point, percent_opt)"
        ]
    },
    {
        "func_name": "init_fig",
        "original": "def init_fig():\n    (fig, ax) = plt.subplots(1, 1)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return (fig, ax)",
        "mutated": [
            "def init_fig():\n    if False:\n        i = 10\n    (fig, ax) = plt.subplots(1, 1)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return (fig, ax)",
            "def init_fig():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (fig, ax) = plt.subplots(1, 1)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return (fig, ax)",
            "def init_fig():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (fig, ax) = plt.subplots(1, 1)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return (fig, ax)",
            "def init_fig():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (fig, ax) = plt.subplots(1, 1)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return (fig, ax)",
            "def init_fig():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (fig, ax) = plt.subplots(1, 1)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return (fig, ax)"
        ]
    },
    {
        "func_name": "plot_scalars",
        "original": "def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n    \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n    if not all([len(s.shape) == 2 for s in scalars]):\n        raise ValueError('Only 2D arrays supported for plotting')\n    if scalar_labels is None:\n        scalar_labels = [None] * len(scalars)\n    if len(scalars) != len(scalar_labels):\n        raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n    (_, plot_axis) = init_fig()\n    for (i, scalar) in enumerate(scalars):\n        xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n        mean = scalar.mean(axis=repetition_axis)\n        sem = stats.sem(scalar, axis=repetition_axis)\n        plot_axis.plot(xs, mean, label=scalar_labels[i])\n        plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n    if title is not None:\n        plot_axis.set_title(title)\n    if ax_labels is not None:\n        plot_axis.set_xlabel(ax_labels[0])\n        plot_axis.set_ylabel(ax_labels[1])",
        "mutated": [
            "def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n    if False:\n        i = 10\n    'Plots scalar on ax by filling 1 standard error.\\n\\n      Args:\\n          scalars: List of scalars to plot (mean taken over repetition\\n            axis)\\n          repetition_axis: Axis to take the mean over\\n          scalar_labels: Labels for the scalars (for legend)\\n          title: Figure title\\n          ax_labels: Labels for x and y axis (list of 2 strings)\\n      '\n    if not all([len(s.shape) == 2 for s in scalars]):\n        raise ValueError('Only 2D arrays supported for plotting')\n    if scalar_labels is None:\n        scalar_labels = [None] * len(scalars)\n    if len(scalars) != len(scalar_labels):\n        raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n    (_, plot_axis) = init_fig()\n    for (i, scalar) in enumerate(scalars):\n        xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n        mean = scalar.mean(axis=repetition_axis)\n        sem = stats.sem(scalar, axis=repetition_axis)\n        plot_axis.plot(xs, mean, label=scalar_labels[i])\n        plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n    if title is not None:\n        plot_axis.set_title(title)\n    if ax_labels is not None:\n        plot_axis.set_xlabel(ax_labels[0])\n        plot_axis.set_ylabel(ax_labels[1])",
            "def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Plots scalar on ax by filling 1 standard error.\\n\\n      Args:\\n          scalars: List of scalars to plot (mean taken over repetition\\n            axis)\\n          repetition_axis: Axis to take the mean over\\n          scalar_labels: Labels for the scalars (for legend)\\n          title: Figure title\\n          ax_labels: Labels for x and y axis (list of 2 strings)\\n      '\n    if not all([len(s.shape) == 2 for s in scalars]):\n        raise ValueError('Only 2D arrays supported for plotting')\n    if scalar_labels is None:\n        scalar_labels = [None] * len(scalars)\n    if len(scalars) != len(scalar_labels):\n        raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n    (_, plot_axis) = init_fig()\n    for (i, scalar) in enumerate(scalars):\n        xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n        mean = scalar.mean(axis=repetition_axis)\n        sem = stats.sem(scalar, axis=repetition_axis)\n        plot_axis.plot(xs, mean, label=scalar_labels[i])\n        plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n    if title is not None:\n        plot_axis.set_title(title)\n    if ax_labels is not None:\n        plot_axis.set_xlabel(ax_labels[0])\n        plot_axis.set_ylabel(ax_labels[1])",
            "def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Plots scalar on ax by filling 1 standard error.\\n\\n      Args:\\n          scalars: List of scalars to plot (mean taken over repetition\\n            axis)\\n          repetition_axis: Axis to take the mean over\\n          scalar_labels: Labels for the scalars (for legend)\\n          title: Figure title\\n          ax_labels: Labels for x and y axis (list of 2 strings)\\n      '\n    if not all([len(s.shape) == 2 for s in scalars]):\n        raise ValueError('Only 2D arrays supported for plotting')\n    if scalar_labels is None:\n        scalar_labels = [None] * len(scalars)\n    if len(scalars) != len(scalar_labels):\n        raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n    (_, plot_axis) = init_fig()\n    for (i, scalar) in enumerate(scalars):\n        xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n        mean = scalar.mean(axis=repetition_axis)\n        sem = stats.sem(scalar, axis=repetition_axis)\n        plot_axis.plot(xs, mean, label=scalar_labels[i])\n        plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n    if title is not None:\n        plot_axis.set_title(title)\n    if ax_labels is not None:\n        plot_axis.set_xlabel(ax_labels[0])\n        plot_axis.set_ylabel(ax_labels[1])",
            "def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Plots scalar on ax by filling 1 standard error.\\n\\n      Args:\\n          scalars: List of scalars to plot (mean taken over repetition\\n            axis)\\n          repetition_axis: Axis to take the mean over\\n          scalar_labels: Labels for the scalars (for legend)\\n          title: Figure title\\n          ax_labels: Labels for x and y axis (list of 2 strings)\\n      '\n    if not all([len(s.shape) == 2 for s in scalars]):\n        raise ValueError('Only 2D arrays supported for plotting')\n    if scalar_labels is None:\n        scalar_labels = [None] * len(scalars)\n    if len(scalars) != len(scalar_labels):\n        raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n    (_, plot_axis) = init_fig()\n    for (i, scalar) in enumerate(scalars):\n        xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n        mean = scalar.mean(axis=repetition_axis)\n        sem = stats.sem(scalar, axis=repetition_axis)\n        plot_axis.plot(xs, mean, label=scalar_labels[i])\n        plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n    if title is not None:\n        plot_axis.set_title(title)\n    if ax_labels is not None:\n        plot_axis.set_xlabel(ax_labels[0])\n        plot_axis.set_ylabel(ax_labels[1])",
            "def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Plots scalar on ax by filling 1 standard error.\\n\\n      Args:\\n          scalars: List of scalars to plot (mean taken over repetition\\n            axis)\\n          repetition_axis: Axis to take the mean over\\n          scalar_labels: Labels for the scalars (for legend)\\n          title: Figure title\\n          ax_labels: Labels for x and y axis (list of 2 strings)\\n      '\n    if not all([len(s.shape) == 2 for s in scalars]):\n        raise ValueError('Only 2D arrays supported for plotting')\n    if scalar_labels is None:\n        scalar_labels = [None] * len(scalars)\n    if len(scalars) != len(scalar_labels):\n        raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n    (_, plot_axis) = init_fig()\n    for (i, scalar) in enumerate(scalars):\n        xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n        mean = scalar.mean(axis=repetition_axis)\n        sem = stats.sem(scalar, axis=repetition_axis)\n        plot_axis.plot(xs, mean, label=scalar_labels[i])\n        plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n    if title is not None:\n        plot_axis.set_title(title)\n    if ax_labels is not None:\n        plot_axis.set_xlabel(ax_labels[0])\n        plot_axis.set_ylabel(ax_labels[1])"
        ]
    },
    {
        "func_name": "plot_confusion_matrix",
        "original": "def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n    \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n    (fig, ax) = plt.subplots()\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"Receiver's action\", fontsize=14)\n    ax.set_ylabel(\"Sender's state\", fontsize=14)\n    fmt = 'd'\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n    fig.tight_layout()\n    if title is not None:\n        ax.set_title(title)\n    return (fig, ax)",
        "mutated": [
            "def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n    if False:\n        i = 10\n    \"Plots the confusion matrix.\\n\\n      Args:\\n          cm (np.ndarray): Confusion matrix to plot\\n          cmap: Color map to be used in matplotlib's imshow\\n          title: Figure title\\n\\n      Returns:\\n          Figure and axis on which the confusion matrix is plotted\\n      \"\n    (fig, ax) = plt.subplots()\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"Receiver's action\", fontsize=14)\n    ax.set_ylabel(\"Sender's state\", fontsize=14)\n    fmt = 'd'\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n    fig.tight_layout()\n    if title is not None:\n        ax.set_title(title)\n    return (fig, ax)",
            "def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Plots the confusion matrix.\\n\\n      Args:\\n          cm (np.ndarray): Confusion matrix to plot\\n          cmap: Color map to be used in matplotlib's imshow\\n          title: Figure title\\n\\n      Returns:\\n          Figure and axis on which the confusion matrix is plotted\\n      \"\n    (fig, ax) = plt.subplots()\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"Receiver's action\", fontsize=14)\n    ax.set_ylabel(\"Sender's state\", fontsize=14)\n    fmt = 'd'\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n    fig.tight_layout()\n    if title is not None:\n        ax.set_title(title)\n    return (fig, ax)",
            "def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Plots the confusion matrix.\\n\\n      Args:\\n          cm (np.ndarray): Confusion matrix to plot\\n          cmap: Color map to be used in matplotlib's imshow\\n          title: Figure title\\n\\n      Returns:\\n          Figure and axis on which the confusion matrix is plotted\\n      \"\n    (fig, ax) = plt.subplots()\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"Receiver's action\", fontsize=14)\n    ax.set_ylabel(\"Sender's state\", fontsize=14)\n    fmt = 'd'\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n    fig.tight_layout()\n    if title is not None:\n        ax.set_title(title)\n    return (fig, ax)",
            "def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Plots the confusion matrix.\\n\\n      Args:\\n          cm (np.ndarray): Confusion matrix to plot\\n          cmap: Color map to be used in matplotlib's imshow\\n          title: Figure title\\n\\n      Returns:\\n          Figure and axis on which the confusion matrix is plotted\\n      \"\n    (fig, ax) = plt.subplots()\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"Receiver's action\", fontsize=14)\n    ax.set_ylabel(\"Sender's state\", fontsize=14)\n    fmt = 'd'\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n    fig.tight_layout()\n    if title is not None:\n        ax.set_title(title)\n    return (fig, ax)",
            "def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Plots the confusion matrix.\\n\\n      Args:\\n          cm (np.ndarray): Confusion matrix to plot\\n          cmap: Color map to be used in matplotlib's imshow\\n          title: Figure title\\n\\n      Returns:\\n          Figure and axis on which the confusion matrix is plotted\\n      \"\n    (fig, ax) = plt.subplots()\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"Receiver's action\", fontsize=14)\n    ax.set_ylabel(\"Sender's state\", fontsize=14)\n    fmt = 'd'\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n    fig.tight_layout()\n    if title is not None:\n        ax.set_title(title)\n    return (fig, ax)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(_):\n    game = 'lewis_signaling'\n    num_players = 2\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    if FLAGS.payoffs == 'random':\n        payoffs = np.random.random((num_states, num_states))\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    elif FLAGS.payoffs == 'climbing':\n        payoffs = np.array([[11, -30, 0], [-30, 7, 6], [0, 0, 5]]) / 30\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    else:\n        payoffs_str = FLAGS.payoffs\n        try:\n            payoffs_list = [float(x) for x in payoffs_str.split(',')]\n            payoffs = np.array(payoffs_list).reshape((num_states, num_states))\n        except ValueError:\n            raise ValueError('There should be {} (states * actions) elements in payoff. Found {} elements'.format(num_states * num_states, len(payoffs_list))) from None\n    env_configs = {'num_states': num_states, 'num_messages': num_messages, 'payoffs': payoffs_str}\n    env = rl_environment.Environment(game, **env_configs)\n    if FLAGS.compare:\n        rewards_list = []\n        opts_list = []\n        converge_point_list = []\n        percent_opt_list = []\n        for centralized in [True, False]:\n            (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, centralized)\n            rewards_list += [rewards]\n            opts_list += [opts]\n            converge_point_list += [converge_point]\n            percent_opt_list += [percent_opt]\n    else:\n        (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, FLAGS.centralized)\n        rewards_list = [rewards]\n        opts_list = [opts]\n        converge_point_list = [converge_point]\n        percent_opt_list = [percent_opt]\n    if FLAGS.plot:\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        from scipy import stats\n        params = {'font.size': 12, 'axes.labelsize': 12, 'xtick.labelsize': 11, 'ytick.labelsize': 11}\n        mpl.rcParams.update(params)\n\n        def init_fig():\n            (fig, ax) = plt.subplots(1, 1)\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            return (fig, ax)\n\n        def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n            \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n            if not all([len(s.shape) == 2 for s in scalars]):\n                raise ValueError('Only 2D arrays supported for plotting')\n            if scalar_labels is None:\n                scalar_labels = [None] * len(scalars)\n            if len(scalars) != len(scalar_labels):\n                raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n            (_, plot_axis) = init_fig()\n            for (i, scalar) in enumerate(scalars):\n                xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n                mean = scalar.mean(axis=repetition_axis)\n                sem = stats.sem(scalar, axis=repetition_axis)\n                plot_axis.plot(xs, mean, label=scalar_labels[i])\n                plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n            if title is not None:\n                plot_axis.set_title(title)\n            if ax_labels is not None:\n                plot_axis.set_xlabel(ax_labels[0])\n                plot_axis.set_ylabel(ax_labels[1])\n\n        def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n            \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n            (fig, ax) = plt.subplots()\n            ax.imshow(cm, interpolation='nearest', cmap=cmap)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_xlabel(\"Receiver's action\", fontsize=14)\n            ax.set_ylabel(\"Sender's state\", fontsize=14)\n            fmt = 'd'\n            thresh = cm.max() / 2.0\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n            fig.tight_layout()\n            if title is not None:\n                ax.set_title(title)\n            return (fig, ax)\n        if FLAGS.compare:\n            labels = ['Centralized', 'Decentralized']\n        else:\n            labels = ['Centralized'] if FLAGS.centralized else ['Decentralized']\n        plot_scalars(rewards_list, scalar_labels=labels, title='Reward graph (Tabular Q-Learning)', ax_labels=['Episodes', 'Reward per episode'])\n        plt.legend()\n        plot_scalars(opts_list, scalar_labels=labels, title='Percentage of optimal actions (Tabular Q-Learning)', ax_labels=['Episodes', '% optimal actions'])\n        plt.legend()\n        for (i, cp) in enumerate(converge_point_list):\n            plot_confusion_matrix(cp.astype(int), title='Final policy (Tabular {})'.format(labels[i]))\n        plt.show()\n    return percent_opt_list",
        "mutated": [
            "def main(_):\n    if False:\n        i = 10\n    game = 'lewis_signaling'\n    num_players = 2\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    if FLAGS.payoffs == 'random':\n        payoffs = np.random.random((num_states, num_states))\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    elif FLAGS.payoffs == 'climbing':\n        payoffs = np.array([[11, -30, 0], [-30, 7, 6], [0, 0, 5]]) / 30\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    else:\n        payoffs_str = FLAGS.payoffs\n        try:\n            payoffs_list = [float(x) for x in payoffs_str.split(',')]\n            payoffs = np.array(payoffs_list).reshape((num_states, num_states))\n        except ValueError:\n            raise ValueError('There should be {} (states * actions) elements in payoff. Found {} elements'.format(num_states * num_states, len(payoffs_list))) from None\n    env_configs = {'num_states': num_states, 'num_messages': num_messages, 'payoffs': payoffs_str}\n    env = rl_environment.Environment(game, **env_configs)\n    if FLAGS.compare:\n        rewards_list = []\n        opts_list = []\n        converge_point_list = []\n        percent_opt_list = []\n        for centralized in [True, False]:\n            (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, centralized)\n            rewards_list += [rewards]\n            opts_list += [opts]\n            converge_point_list += [converge_point]\n            percent_opt_list += [percent_opt]\n    else:\n        (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, FLAGS.centralized)\n        rewards_list = [rewards]\n        opts_list = [opts]\n        converge_point_list = [converge_point]\n        percent_opt_list = [percent_opt]\n    if FLAGS.plot:\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        from scipy import stats\n        params = {'font.size': 12, 'axes.labelsize': 12, 'xtick.labelsize': 11, 'ytick.labelsize': 11}\n        mpl.rcParams.update(params)\n\n        def init_fig():\n            (fig, ax) = plt.subplots(1, 1)\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            return (fig, ax)\n\n        def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n            \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n            if not all([len(s.shape) == 2 for s in scalars]):\n                raise ValueError('Only 2D arrays supported for plotting')\n            if scalar_labels is None:\n                scalar_labels = [None] * len(scalars)\n            if len(scalars) != len(scalar_labels):\n                raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n            (_, plot_axis) = init_fig()\n            for (i, scalar) in enumerate(scalars):\n                xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n                mean = scalar.mean(axis=repetition_axis)\n                sem = stats.sem(scalar, axis=repetition_axis)\n                plot_axis.plot(xs, mean, label=scalar_labels[i])\n                plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n            if title is not None:\n                plot_axis.set_title(title)\n            if ax_labels is not None:\n                plot_axis.set_xlabel(ax_labels[0])\n                plot_axis.set_ylabel(ax_labels[1])\n\n        def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n            \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n            (fig, ax) = plt.subplots()\n            ax.imshow(cm, interpolation='nearest', cmap=cmap)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_xlabel(\"Receiver's action\", fontsize=14)\n            ax.set_ylabel(\"Sender's state\", fontsize=14)\n            fmt = 'd'\n            thresh = cm.max() / 2.0\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n            fig.tight_layout()\n            if title is not None:\n                ax.set_title(title)\n            return (fig, ax)\n        if FLAGS.compare:\n            labels = ['Centralized', 'Decentralized']\n        else:\n            labels = ['Centralized'] if FLAGS.centralized else ['Decentralized']\n        plot_scalars(rewards_list, scalar_labels=labels, title='Reward graph (Tabular Q-Learning)', ax_labels=['Episodes', 'Reward per episode'])\n        plt.legend()\n        plot_scalars(opts_list, scalar_labels=labels, title='Percentage of optimal actions (Tabular Q-Learning)', ax_labels=['Episodes', '% optimal actions'])\n        plt.legend()\n        for (i, cp) in enumerate(converge_point_list):\n            plot_confusion_matrix(cp.astype(int), title='Final policy (Tabular {})'.format(labels[i]))\n        plt.show()\n    return percent_opt_list",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    game = 'lewis_signaling'\n    num_players = 2\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    if FLAGS.payoffs == 'random':\n        payoffs = np.random.random((num_states, num_states))\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    elif FLAGS.payoffs == 'climbing':\n        payoffs = np.array([[11, -30, 0], [-30, 7, 6], [0, 0, 5]]) / 30\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    else:\n        payoffs_str = FLAGS.payoffs\n        try:\n            payoffs_list = [float(x) for x in payoffs_str.split(',')]\n            payoffs = np.array(payoffs_list).reshape((num_states, num_states))\n        except ValueError:\n            raise ValueError('There should be {} (states * actions) elements in payoff. Found {} elements'.format(num_states * num_states, len(payoffs_list))) from None\n    env_configs = {'num_states': num_states, 'num_messages': num_messages, 'payoffs': payoffs_str}\n    env = rl_environment.Environment(game, **env_configs)\n    if FLAGS.compare:\n        rewards_list = []\n        opts_list = []\n        converge_point_list = []\n        percent_opt_list = []\n        for centralized in [True, False]:\n            (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, centralized)\n            rewards_list += [rewards]\n            opts_list += [opts]\n            converge_point_list += [converge_point]\n            percent_opt_list += [percent_opt]\n    else:\n        (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, FLAGS.centralized)\n        rewards_list = [rewards]\n        opts_list = [opts]\n        converge_point_list = [converge_point]\n        percent_opt_list = [percent_opt]\n    if FLAGS.plot:\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        from scipy import stats\n        params = {'font.size': 12, 'axes.labelsize': 12, 'xtick.labelsize': 11, 'ytick.labelsize': 11}\n        mpl.rcParams.update(params)\n\n        def init_fig():\n            (fig, ax) = plt.subplots(1, 1)\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            return (fig, ax)\n\n        def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n            \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n            if not all([len(s.shape) == 2 for s in scalars]):\n                raise ValueError('Only 2D arrays supported for plotting')\n            if scalar_labels is None:\n                scalar_labels = [None] * len(scalars)\n            if len(scalars) != len(scalar_labels):\n                raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n            (_, plot_axis) = init_fig()\n            for (i, scalar) in enumerate(scalars):\n                xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n                mean = scalar.mean(axis=repetition_axis)\n                sem = stats.sem(scalar, axis=repetition_axis)\n                plot_axis.plot(xs, mean, label=scalar_labels[i])\n                plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n            if title is not None:\n                plot_axis.set_title(title)\n            if ax_labels is not None:\n                plot_axis.set_xlabel(ax_labels[0])\n                plot_axis.set_ylabel(ax_labels[1])\n\n        def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n            \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n            (fig, ax) = plt.subplots()\n            ax.imshow(cm, interpolation='nearest', cmap=cmap)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_xlabel(\"Receiver's action\", fontsize=14)\n            ax.set_ylabel(\"Sender's state\", fontsize=14)\n            fmt = 'd'\n            thresh = cm.max() / 2.0\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n            fig.tight_layout()\n            if title is not None:\n                ax.set_title(title)\n            return (fig, ax)\n        if FLAGS.compare:\n            labels = ['Centralized', 'Decentralized']\n        else:\n            labels = ['Centralized'] if FLAGS.centralized else ['Decentralized']\n        plot_scalars(rewards_list, scalar_labels=labels, title='Reward graph (Tabular Q-Learning)', ax_labels=['Episodes', 'Reward per episode'])\n        plt.legend()\n        plot_scalars(opts_list, scalar_labels=labels, title='Percentage of optimal actions (Tabular Q-Learning)', ax_labels=['Episodes', '% optimal actions'])\n        plt.legend()\n        for (i, cp) in enumerate(converge_point_list):\n            plot_confusion_matrix(cp.astype(int), title='Final policy (Tabular {})'.format(labels[i]))\n        plt.show()\n    return percent_opt_list",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    game = 'lewis_signaling'\n    num_players = 2\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    if FLAGS.payoffs == 'random':\n        payoffs = np.random.random((num_states, num_states))\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    elif FLAGS.payoffs == 'climbing':\n        payoffs = np.array([[11, -30, 0], [-30, 7, 6], [0, 0, 5]]) / 30\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    else:\n        payoffs_str = FLAGS.payoffs\n        try:\n            payoffs_list = [float(x) for x in payoffs_str.split(',')]\n            payoffs = np.array(payoffs_list).reshape((num_states, num_states))\n        except ValueError:\n            raise ValueError('There should be {} (states * actions) elements in payoff. Found {} elements'.format(num_states * num_states, len(payoffs_list))) from None\n    env_configs = {'num_states': num_states, 'num_messages': num_messages, 'payoffs': payoffs_str}\n    env = rl_environment.Environment(game, **env_configs)\n    if FLAGS.compare:\n        rewards_list = []\n        opts_list = []\n        converge_point_list = []\n        percent_opt_list = []\n        for centralized in [True, False]:\n            (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, centralized)\n            rewards_list += [rewards]\n            opts_list += [opts]\n            converge_point_list += [converge_point]\n            percent_opt_list += [percent_opt]\n    else:\n        (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, FLAGS.centralized)\n        rewards_list = [rewards]\n        opts_list = [opts]\n        converge_point_list = [converge_point]\n        percent_opt_list = [percent_opt]\n    if FLAGS.plot:\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        from scipy import stats\n        params = {'font.size': 12, 'axes.labelsize': 12, 'xtick.labelsize': 11, 'ytick.labelsize': 11}\n        mpl.rcParams.update(params)\n\n        def init_fig():\n            (fig, ax) = plt.subplots(1, 1)\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            return (fig, ax)\n\n        def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n            \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n            if not all([len(s.shape) == 2 for s in scalars]):\n                raise ValueError('Only 2D arrays supported for plotting')\n            if scalar_labels is None:\n                scalar_labels = [None] * len(scalars)\n            if len(scalars) != len(scalar_labels):\n                raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n            (_, plot_axis) = init_fig()\n            for (i, scalar) in enumerate(scalars):\n                xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n                mean = scalar.mean(axis=repetition_axis)\n                sem = stats.sem(scalar, axis=repetition_axis)\n                plot_axis.plot(xs, mean, label=scalar_labels[i])\n                plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n            if title is not None:\n                plot_axis.set_title(title)\n            if ax_labels is not None:\n                plot_axis.set_xlabel(ax_labels[0])\n                plot_axis.set_ylabel(ax_labels[1])\n\n        def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n            \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n            (fig, ax) = plt.subplots()\n            ax.imshow(cm, interpolation='nearest', cmap=cmap)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_xlabel(\"Receiver's action\", fontsize=14)\n            ax.set_ylabel(\"Sender's state\", fontsize=14)\n            fmt = 'd'\n            thresh = cm.max() / 2.0\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n            fig.tight_layout()\n            if title is not None:\n                ax.set_title(title)\n            return (fig, ax)\n        if FLAGS.compare:\n            labels = ['Centralized', 'Decentralized']\n        else:\n            labels = ['Centralized'] if FLAGS.centralized else ['Decentralized']\n        plot_scalars(rewards_list, scalar_labels=labels, title='Reward graph (Tabular Q-Learning)', ax_labels=['Episodes', 'Reward per episode'])\n        plt.legend()\n        plot_scalars(opts_list, scalar_labels=labels, title='Percentage of optimal actions (Tabular Q-Learning)', ax_labels=['Episodes', '% optimal actions'])\n        plt.legend()\n        for (i, cp) in enumerate(converge_point_list):\n            plot_confusion_matrix(cp.astype(int), title='Final policy (Tabular {})'.format(labels[i]))\n        plt.show()\n    return percent_opt_list",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    game = 'lewis_signaling'\n    num_players = 2\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    if FLAGS.payoffs == 'random':\n        payoffs = np.random.random((num_states, num_states))\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    elif FLAGS.payoffs == 'climbing':\n        payoffs = np.array([[11, -30, 0], [-30, 7, 6], [0, 0, 5]]) / 30\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    else:\n        payoffs_str = FLAGS.payoffs\n        try:\n            payoffs_list = [float(x) for x in payoffs_str.split(',')]\n            payoffs = np.array(payoffs_list).reshape((num_states, num_states))\n        except ValueError:\n            raise ValueError('There should be {} (states * actions) elements in payoff. Found {} elements'.format(num_states * num_states, len(payoffs_list))) from None\n    env_configs = {'num_states': num_states, 'num_messages': num_messages, 'payoffs': payoffs_str}\n    env = rl_environment.Environment(game, **env_configs)\n    if FLAGS.compare:\n        rewards_list = []\n        opts_list = []\n        converge_point_list = []\n        percent_opt_list = []\n        for centralized in [True, False]:\n            (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, centralized)\n            rewards_list += [rewards]\n            opts_list += [opts]\n            converge_point_list += [converge_point]\n            percent_opt_list += [percent_opt]\n    else:\n        (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, FLAGS.centralized)\n        rewards_list = [rewards]\n        opts_list = [opts]\n        converge_point_list = [converge_point]\n        percent_opt_list = [percent_opt]\n    if FLAGS.plot:\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        from scipy import stats\n        params = {'font.size': 12, 'axes.labelsize': 12, 'xtick.labelsize': 11, 'ytick.labelsize': 11}\n        mpl.rcParams.update(params)\n\n        def init_fig():\n            (fig, ax) = plt.subplots(1, 1)\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            return (fig, ax)\n\n        def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n            \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n            if not all([len(s.shape) == 2 for s in scalars]):\n                raise ValueError('Only 2D arrays supported for plotting')\n            if scalar_labels is None:\n                scalar_labels = [None] * len(scalars)\n            if len(scalars) != len(scalar_labels):\n                raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n            (_, plot_axis) = init_fig()\n            for (i, scalar) in enumerate(scalars):\n                xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n                mean = scalar.mean(axis=repetition_axis)\n                sem = stats.sem(scalar, axis=repetition_axis)\n                plot_axis.plot(xs, mean, label=scalar_labels[i])\n                plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n            if title is not None:\n                plot_axis.set_title(title)\n            if ax_labels is not None:\n                plot_axis.set_xlabel(ax_labels[0])\n                plot_axis.set_ylabel(ax_labels[1])\n\n        def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n            \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n            (fig, ax) = plt.subplots()\n            ax.imshow(cm, interpolation='nearest', cmap=cmap)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_xlabel(\"Receiver's action\", fontsize=14)\n            ax.set_ylabel(\"Sender's state\", fontsize=14)\n            fmt = 'd'\n            thresh = cm.max() / 2.0\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n            fig.tight_layout()\n            if title is not None:\n                ax.set_title(title)\n            return (fig, ax)\n        if FLAGS.compare:\n            labels = ['Centralized', 'Decentralized']\n        else:\n            labels = ['Centralized'] if FLAGS.centralized else ['Decentralized']\n        plot_scalars(rewards_list, scalar_labels=labels, title='Reward graph (Tabular Q-Learning)', ax_labels=['Episodes', 'Reward per episode'])\n        plt.legend()\n        plot_scalars(opts_list, scalar_labels=labels, title='Percentage of optimal actions (Tabular Q-Learning)', ax_labels=['Episodes', '% optimal actions'])\n        plt.legend()\n        for (i, cp) in enumerate(converge_point_list):\n            plot_confusion_matrix(cp.astype(int), title='Final policy (Tabular {})'.format(labels[i]))\n        plt.show()\n    return percent_opt_list",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    game = 'lewis_signaling'\n    num_players = 2\n    num_states = FLAGS.num_states\n    num_messages = FLAGS.num_messages\n    if FLAGS.payoffs == 'random':\n        payoffs = np.random.random((num_states, num_states))\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    elif FLAGS.payoffs == 'climbing':\n        payoffs = np.array([[11, -30, 0], [-30, 7, 6], [0, 0, 5]]) / 30\n        payoffs_str = ','.join([str(x) for x in payoffs.flatten()])\n    else:\n        payoffs_str = FLAGS.payoffs\n        try:\n            payoffs_list = [float(x) for x in payoffs_str.split(',')]\n            payoffs = np.array(payoffs_list).reshape((num_states, num_states))\n        except ValueError:\n            raise ValueError('There should be {} (states * actions) elements in payoff. Found {} elements'.format(num_states * num_states, len(payoffs_list))) from None\n    env_configs = {'num_states': num_states, 'num_messages': num_messages, 'payoffs': payoffs_str}\n    env = rl_environment.Environment(game, **env_configs)\n    if FLAGS.compare:\n        rewards_list = []\n        opts_list = []\n        converge_point_list = []\n        percent_opt_list = []\n        for centralized in [True, False]:\n            (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, centralized)\n            rewards_list += [rewards]\n            opts_list += [opts]\n            converge_point_list += [converge_point]\n            percent_opt_list += [percent_opt]\n    else:\n        (rewards, opts, converge_point, percent_opt) = run_experiment(num_players, env, payoffs, FLAGS.centralized)\n        rewards_list = [rewards]\n        opts_list = [opts]\n        converge_point_list = [converge_point]\n        percent_opt_list = [percent_opt]\n    if FLAGS.plot:\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        from scipy import stats\n        params = {'font.size': 12, 'axes.labelsize': 12, 'xtick.labelsize': 11, 'ytick.labelsize': 11}\n        mpl.rcParams.update(params)\n\n        def init_fig():\n            (fig, ax) = plt.subplots(1, 1)\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            return (fig, ax)\n\n        def plot_scalars(scalars, repetition_axis=0, scalar_labels=None, title=None, ax_labels=None):\n            \"\"\"Plots scalar on ax by filling 1 standard error.\n\n      Args:\n          scalars: List of scalars to plot (mean taken over repetition\n            axis)\n          repetition_axis: Axis to take the mean over\n          scalar_labels: Labels for the scalars (for legend)\n          title: Figure title\n          ax_labels: Labels for x and y axis (list of 2 strings)\n      \"\"\"\n            if not all([len(s.shape) == 2 for s in scalars]):\n                raise ValueError('Only 2D arrays supported for plotting')\n            if scalar_labels is None:\n                scalar_labels = [None] * len(scalars)\n            if len(scalars) != len(scalar_labels):\n                raise ValueError('Wrong number of scalar labels, expected {} but received {}'.format(len(scalars), len(scalar_labels)))\n            (_, plot_axis) = init_fig()\n            for (i, scalar) in enumerate(scalars):\n                xs = np.arange(scalar.shape[1 - repetition_axis]) * FLAGS.log_interval\n                mean = scalar.mean(axis=repetition_axis)\n                sem = stats.sem(scalar, axis=repetition_axis)\n                plot_axis.plot(xs, mean, label=scalar_labels[i])\n                plot_axis.fill_between(xs, mean - sem, mean + sem, alpha=0.5)\n            if title is not None:\n                plot_axis.set_title(title)\n            if ax_labels is not None:\n                plot_axis.set_xlabel(ax_labels[0])\n                plot_axis.set_ylabel(ax_labels[1])\n\n        def plot_confusion_matrix(cm, cmap=plt.cm.Blues, title=None):\n            \"\"\"Plots the confusion matrix.\n\n      Args:\n          cm (np.ndarray): Confusion matrix to plot\n          cmap: Color map to be used in matplotlib's imshow\n          title: Figure title\n\n      Returns:\n          Figure and axis on which the confusion matrix is plotted\n      \"\"\"\n            (fig, ax) = plt.subplots()\n            ax.imshow(cm, interpolation='nearest', cmap=cmap)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_xlabel(\"Receiver's action\", fontsize=14)\n            ax.set_ylabel(\"Sender's state\", fontsize=14)\n            fmt = 'd'\n            thresh = cm.max() / 2.0\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    ax.text(j, i, format(cm[i, j], fmt), ha='center', va='center', color='white' if cm[i, j] > thresh else 'black')\n            fig.tight_layout()\n            if title is not None:\n                ax.set_title(title)\n            return (fig, ax)\n        if FLAGS.compare:\n            labels = ['Centralized', 'Decentralized']\n        else:\n            labels = ['Centralized'] if FLAGS.centralized else ['Decentralized']\n        plot_scalars(rewards_list, scalar_labels=labels, title='Reward graph (Tabular Q-Learning)', ax_labels=['Episodes', 'Reward per episode'])\n        plt.legend()\n        plot_scalars(opts_list, scalar_labels=labels, title='Percentage of optimal actions (Tabular Q-Learning)', ax_labels=['Episodes', '% optimal actions'])\n        plt.legend()\n        for (i, cp) in enumerate(converge_point_list):\n            plot_confusion_matrix(cp.astype(int), title='Final policy (Tabular {})'.format(labels[i]))\n        plt.show()\n    return percent_opt_list"
        ]
    }
]