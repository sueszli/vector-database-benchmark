[
    {
        "func_name": "sigmoid_focal_loss",
        "original": "def sigmoid_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, gamma: float=2.0, alpha: float=0.25, reduction: str='mean'):\n    \"\"\"\n    Compute binary focal loss between target and output logits.\n\n    Args:\n        outputs: tensor of arbitrary shape\n        targets: tensor of the same shape as input\n        gamma: gamma for focal loss\n        alpha: alpha for focal loss\n        reduction (string, optional):\n            specifies the reduction to apply to the output:\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\n            ``\"none\"``: no reduction will be applied,\n            ``\"mean\"``: the sum of the output will be divided by the number of\n            elements in the output,\n            ``\"sum\"``: the output will be summed.\n\n    Returns:\n        computed loss\n\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\n    \"\"\"\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    loss = -(1 - pt).pow(gamma) * logpt\n    if alpha is not None:\n        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
        "mutated": [
            "def sigmoid_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, gamma: float=2.0, alpha: float=0.25, reduction: str='mean'):\n    if False:\n        i = 10\n    '\\n    Compute binary focal loss between target and output logits.\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        gamma: gamma for focal loss\\n        alpha: alpha for focal loss\\n        reduction (string, optional):\\n            specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n\\n    Returns:\\n        computed loss\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    loss = -(1 - pt).pow(gamma) * logpt\n    if alpha is not None:\n        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def sigmoid_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, gamma: float=2.0, alpha: float=0.25, reduction: str='mean'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Compute binary focal loss between target and output logits.\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        gamma: gamma for focal loss\\n        alpha: alpha for focal loss\\n        reduction (string, optional):\\n            specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n\\n    Returns:\\n        computed loss\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    loss = -(1 - pt).pow(gamma) * logpt\n    if alpha is not None:\n        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def sigmoid_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, gamma: float=2.0, alpha: float=0.25, reduction: str='mean'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Compute binary focal loss between target and output logits.\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        gamma: gamma for focal loss\\n        alpha: alpha for focal loss\\n        reduction (string, optional):\\n            specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n\\n    Returns:\\n        computed loss\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    loss = -(1 - pt).pow(gamma) * logpt\n    if alpha is not None:\n        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def sigmoid_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, gamma: float=2.0, alpha: float=0.25, reduction: str='mean'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Compute binary focal loss between target and output logits.\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        gamma: gamma for focal loss\\n        alpha: alpha for focal loss\\n        reduction (string, optional):\\n            specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n\\n    Returns:\\n        computed loss\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    loss = -(1 - pt).pow(gamma) * logpt\n    if alpha is not None:\n        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def sigmoid_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, gamma: float=2.0, alpha: float=0.25, reduction: str='mean'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Compute binary focal loss between target and output logits.\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        gamma: gamma for focal loss\\n        alpha: alpha for focal loss\\n        reduction (string, optional):\\n            specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n\\n    Returns:\\n        computed loss\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    loss = -(1 - pt).pow(gamma) * logpt\n    if alpha is not None:\n        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss"
        ]
    },
    {
        "func_name": "reduced_focal_loss",
        "original": "def reduced_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, threshold: float=0.5, gamma: float=2.0, reduction='mean') -> torch.Tensor:\n    \"\"\"Compute reduced focal loss between target and output logits.\n\n    It has been proposed in `Reduced Focal Loss\\\\: 1st Place Solution to xView\n    object detection in Satellite Imagery`_ paper.\n\n    .. note::\n        ``size_average`` and ``reduce`` params are in the process of being\n        deprecated, and in the meantime, specifying either of those two args\n        will override ``reduction``.\n\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\n\n    .. _Reduced Focal Loss\\\\: 1st Place Solution to xView object detection\n        in Satellite Imagery: https://arxiv.org/abs/1903.01347\n\n    Args:\n        outputs: tensor of arbitrary shape\n        targets: tensor of the same shape as input\n        threshold: threshold for focal reduction\n        gamma: gamma for focal reduction\n        reduction: specifies the reduction to apply to the output:\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\n            ``\"none\"``: no reduction will be applied,\n            ``\"mean\"``: the sum of the output will be divided by the number of\n            elements in the output,\n            ``\"sum\"``: the output will be summed.\n            ``\"batchwise_mean\"`` computes mean loss per sample in batch.\n            Default: \"mean\"\n\n    Returns:  # noqa: DAR201\n        torch.Tensor: computed loss\n    \"\"\"\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)\n    focal_reduction[pt < threshold] = 1\n    loss = -focal_reduction * logpt\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
        "mutated": [
            "def reduced_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, threshold: float=0.5, gamma: float=2.0, reduction='mean') -> torch.Tensor:\n    if False:\n        i = 10\n    'Compute reduced focal loss between target and output logits.\\n\\n    It has been proposed in `Reduced Focal Loss\\\\: 1st Place Solution to xView\\n    object detection in Satellite Imagery`_ paper.\\n\\n    .. note::\\n        ``size_average`` and ``reduce`` params are in the process of being\\n        deprecated, and in the meantime, specifying either of those two args\\n        will override ``reduction``.\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n\\n    .. _Reduced Focal Loss\\\\: 1st Place Solution to xView object detection\\n        in Satellite Imagery: https://arxiv.org/abs/1903.01347\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        threshold: threshold for focal reduction\\n        gamma: gamma for focal reduction\\n        reduction: specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n            ``\"batchwise_mean\"`` computes mean loss per sample in batch.\\n            Default: \"mean\"\\n\\n    Returns:  # noqa: DAR201\\n        torch.Tensor: computed loss\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)\n    focal_reduction[pt < threshold] = 1\n    loss = -focal_reduction * logpt\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def reduced_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, threshold: float=0.5, gamma: float=2.0, reduction='mean') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute reduced focal loss between target and output logits.\\n\\n    It has been proposed in `Reduced Focal Loss\\\\: 1st Place Solution to xView\\n    object detection in Satellite Imagery`_ paper.\\n\\n    .. note::\\n        ``size_average`` and ``reduce`` params are in the process of being\\n        deprecated, and in the meantime, specifying either of those two args\\n        will override ``reduction``.\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n\\n    .. _Reduced Focal Loss\\\\: 1st Place Solution to xView object detection\\n        in Satellite Imagery: https://arxiv.org/abs/1903.01347\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        threshold: threshold for focal reduction\\n        gamma: gamma for focal reduction\\n        reduction: specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n            ``\"batchwise_mean\"`` computes mean loss per sample in batch.\\n            Default: \"mean\"\\n\\n    Returns:  # noqa: DAR201\\n        torch.Tensor: computed loss\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)\n    focal_reduction[pt < threshold] = 1\n    loss = -focal_reduction * logpt\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def reduced_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, threshold: float=0.5, gamma: float=2.0, reduction='mean') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute reduced focal loss between target and output logits.\\n\\n    It has been proposed in `Reduced Focal Loss\\\\: 1st Place Solution to xView\\n    object detection in Satellite Imagery`_ paper.\\n\\n    .. note::\\n        ``size_average`` and ``reduce`` params are in the process of being\\n        deprecated, and in the meantime, specifying either of those two args\\n        will override ``reduction``.\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n\\n    .. _Reduced Focal Loss\\\\: 1st Place Solution to xView object detection\\n        in Satellite Imagery: https://arxiv.org/abs/1903.01347\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        threshold: threshold for focal reduction\\n        gamma: gamma for focal reduction\\n        reduction: specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n            ``\"batchwise_mean\"`` computes mean loss per sample in batch.\\n            Default: \"mean\"\\n\\n    Returns:  # noqa: DAR201\\n        torch.Tensor: computed loss\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)\n    focal_reduction[pt < threshold] = 1\n    loss = -focal_reduction * logpt\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def reduced_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, threshold: float=0.5, gamma: float=2.0, reduction='mean') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute reduced focal loss between target and output logits.\\n\\n    It has been proposed in `Reduced Focal Loss\\\\: 1st Place Solution to xView\\n    object detection in Satellite Imagery`_ paper.\\n\\n    .. note::\\n        ``size_average`` and ``reduce`` params are in the process of being\\n        deprecated, and in the meantime, specifying either of those two args\\n        will override ``reduction``.\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n\\n    .. _Reduced Focal Loss\\\\: 1st Place Solution to xView object detection\\n        in Satellite Imagery: https://arxiv.org/abs/1903.01347\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        threshold: threshold for focal reduction\\n        gamma: gamma for focal reduction\\n        reduction: specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n            ``\"batchwise_mean\"`` computes mean loss per sample in batch.\\n            Default: \"mean\"\\n\\n    Returns:  # noqa: DAR201\\n        torch.Tensor: computed loss\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)\n    focal_reduction[pt < threshold] = 1\n    loss = -focal_reduction * logpt\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss",
            "def reduced_focal_loss(outputs: torch.Tensor, targets: torch.Tensor, threshold: float=0.5, gamma: float=2.0, reduction='mean') -> torch.Tensor:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute reduced focal loss between target and output logits.\\n\\n    It has been proposed in `Reduced Focal Loss\\\\: 1st Place Solution to xView\\n    object detection in Satellite Imagery`_ paper.\\n\\n    .. note::\\n        ``size_average`` and ``reduce`` params are in the process of being\\n        deprecated, and in the meantime, specifying either of those two args\\n        will override ``reduction``.\\n\\n    Source: https://github.com/BloodAxe/pytorch-toolbelt\\n\\n    .. _Reduced Focal Loss\\\\: 1st Place Solution to xView object detection\\n        in Satellite Imagery: https://arxiv.org/abs/1903.01347\\n\\n    Args:\\n        outputs: tensor of arbitrary shape\\n        targets: tensor of the same shape as input\\n        threshold: threshold for focal reduction\\n        gamma: gamma for focal reduction\\n        reduction: specifies the reduction to apply to the output:\\n            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"`` | ``\"batchwise_mean\"``.\\n            ``\"none\"``: no reduction will be applied,\\n            ``\"mean\"``: the sum of the output will be divided by the number of\\n            elements in the output,\\n            ``\"sum\"``: the output will be summed.\\n            ``\"batchwise_mean\"`` computes mean loss per sample in batch.\\n            Default: \"mean\"\\n\\n    Returns:  # noqa: DAR201\\n        torch.Tensor: computed loss\\n    '\n    targets = targets.type(outputs.type())\n    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n    pt = torch.exp(logpt)\n    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)\n    focal_reduction[pt < threshold] = 1\n    loss = -focal_reduction * logpt\n    if reduction == 'mean':\n        loss = loss.mean()\n    if reduction == 'sum':\n        loss = loss.sum()\n    if reduction == 'batchwise_mean':\n        loss = loss.sum(0)\n    return loss"
        ]
    }
]