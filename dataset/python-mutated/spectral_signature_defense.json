[
    {
        "func_name": "__init__",
        "original": "def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', x_train: np.ndarray, y_train: np.ndarray, expected_pp_poison: float=0.33, batch_size: int=128, eps_multiplier: float=1.5) -> None:\n    \"\"\"\n        Create an :class:`.SpectralSignatureDefense` object with the provided classifier.\n\n        :param classifier: Model evaluated for poison.\n        :param x_train: Dataset used to train the classifier.\n        :param y_train: Labels used to train the classifier.\n        :param expected_pp_poison: The expected percentage of poison in the dataset\n        :param batch_size: The batch size for predictions\n        :param eps_multiplier: The multiplier to add to the previous expectation. Numbers higher than one represent\n                               a potentially higher false positive rate, but may detect more poison samples\n        \"\"\"\n    super().__init__(classifier, x_train, y_train)\n    self.classifier: 'CLASSIFIER_NEURALNETWORK_TYPE' = classifier\n    self.batch_size = batch_size\n    self.eps_multiplier = eps_multiplier\n    self.expected_pp_poison = expected_pp_poison\n    self.y_train = y_train\n    self.evaluator = GroundTruthEvaluator()\n    self._check_params()",
        "mutated": [
            "def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', x_train: np.ndarray, y_train: np.ndarray, expected_pp_poison: float=0.33, batch_size: int=128, eps_multiplier: float=1.5) -> None:\n    if False:\n        i = 10\n    '\\n        Create an :class:`.SpectralSignatureDefense` object with the provided classifier.\\n\\n        :param classifier: Model evaluated for poison.\\n        :param x_train: Dataset used to train the classifier.\\n        :param y_train: Labels used to train the classifier.\\n        :param expected_pp_poison: The expected percentage of poison in the dataset\\n        :param batch_size: The batch size for predictions\\n        :param eps_multiplier: The multiplier to add to the previous expectation. Numbers higher than one represent\\n                               a potentially higher false positive rate, but may detect more poison samples\\n        '\n    super().__init__(classifier, x_train, y_train)\n    self.classifier: 'CLASSIFIER_NEURALNETWORK_TYPE' = classifier\n    self.batch_size = batch_size\n    self.eps_multiplier = eps_multiplier\n    self.expected_pp_poison = expected_pp_poison\n    self.y_train = y_train\n    self.evaluator = GroundTruthEvaluator()\n    self._check_params()",
            "def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', x_train: np.ndarray, y_train: np.ndarray, expected_pp_poison: float=0.33, batch_size: int=128, eps_multiplier: float=1.5) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Create an :class:`.SpectralSignatureDefense` object with the provided classifier.\\n\\n        :param classifier: Model evaluated for poison.\\n        :param x_train: Dataset used to train the classifier.\\n        :param y_train: Labels used to train the classifier.\\n        :param expected_pp_poison: The expected percentage of poison in the dataset\\n        :param batch_size: The batch size for predictions\\n        :param eps_multiplier: The multiplier to add to the previous expectation. Numbers higher than one represent\\n                               a potentially higher false positive rate, but may detect more poison samples\\n        '\n    super().__init__(classifier, x_train, y_train)\n    self.classifier: 'CLASSIFIER_NEURALNETWORK_TYPE' = classifier\n    self.batch_size = batch_size\n    self.eps_multiplier = eps_multiplier\n    self.expected_pp_poison = expected_pp_poison\n    self.y_train = y_train\n    self.evaluator = GroundTruthEvaluator()\n    self._check_params()",
            "def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', x_train: np.ndarray, y_train: np.ndarray, expected_pp_poison: float=0.33, batch_size: int=128, eps_multiplier: float=1.5) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Create an :class:`.SpectralSignatureDefense` object with the provided classifier.\\n\\n        :param classifier: Model evaluated for poison.\\n        :param x_train: Dataset used to train the classifier.\\n        :param y_train: Labels used to train the classifier.\\n        :param expected_pp_poison: The expected percentage of poison in the dataset\\n        :param batch_size: The batch size for predictions\\n        :param eps_multiplier: The multiplier to add to the previous expectation. Numbers higher than one represent\\n                               a potentially higher false positive rate, but may detect more poison samples\\n        '\n    super().__init__(classifier, x_train, y_train)\n    self.classifier: 'CLASSIFIER_NEURALNETWORK_TYPE' = classifier\n    self.batch_size = batch_size\n    self.eps_multiplier = eps_multiplier\n    self.expected_pp_poison = expected_pp_poison\n    self.y_train = y_train\n    self.evaluator = GroundTruthEvaluator()\n    self._check_params()",
            "def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', x_train: np.ndarray, y_train: np.ndarray, expected_pp_poison: float=0.33, batch_size: int=128, eps_multiplier: float=1.5) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Create an :class:`.SpectralSignatureDefense` object with the provided classifier.\\n\\n        :param classifier: Model evaluated for poison.\\n        :param x_train: Dataset used to train the classifier.\\n        :param y_train: Labels used to train the classifier.\\n        :param expected_pp_poison: The expected percentage of poison in the dataset\\n        :param batch_size: The batch size for predictions\\n        :param eps_multiplier: The multiplier to add to the previous expectation. Numbers higher than one represent\\n                               a potentially higher false positive rate, but may detect more poison samples\\n        '\n    super().__init__(classifier, x_train, y_train)\n    self.classifier: 'CLASSIFIER_NEURALNETWORK_TYPE' = classifier\n    self.batch_size = batch_size\n    self.eps_multiplier = eps_multiplier\n    self.expected_pp_poison = expected_pp_poison\n    self.y_train = y_train\n    self.evaluator = GroundTruthEvaluator()\n    self._check_params()",
            "def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', x_train: np.ndarray, y_train: np.ndarray, expected_pp_poison: float=0.33, batch_size: int=128, eps_multiplier: float=1.5) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Create an :class:`.SpectralSignatureDefense` object with the provided classifier.\\n\\n        :param classifier: Model evaluated for poison.\\n        :param x_train: Dataset used to train the classifier.\\n        :param y_train: Labels used to train the classifier.\\n        :param expected_pp_poison: The expected percentage of poison in the dataset\\n        :param batch_size: The batch size for predictions\\n        :param eps_multiplier: The multiplier to add to the previous expectation. Numbers higher than one represent\\n                               a potentially higher false positive rate, but may detect more poison samples\\n        '\n    super().__init__(classifier, x_train, y_train)\n    self.classifier: 'CLASSIFIER_NEURALNETWORK_TYPE' = classifier\n    self.batch_size = batch_size\n    self.eps_multiplier = eps_multiplier\n    self.expected_pp_poison = expected_pp_poison\n    self.y_train = y_train\n    self.evaluator = GroundTruthEvaluator()\n    self._check_params()"
        ]
    },
    {
        "func_name": "evaluate_defence",
        "original": "def evaluate_defence(self, is_clean: np.ndarray, **kwargs) -> str:\n    \"\"\"\n        If ground truth is known, this function returns a confusion matrix in the form of a JSON object.\n\n        :param is_clean: Ground truth, where is_clean[i]=1 means that x_train[i] is clean and is_clean[i]=0 means\n                         x_train[i] is poisonous.\n        :param kwargs: A dictionary of defence-specific parameters.\n        :return: JSON object with confusion matrix.\n        \"\"\"\n    if is_clean is None or is_clean.size == 0:\n        raise ValueError('is_clean was not provided while invoking evaluate_defence.')\n    is_clean_by_class = segment_by_class(is_clean, self.y_train, self.classifier.nb_classes)\n    (_, predicted_clean) = self.detect_poison()\n    predicted_clean_by_class = segment_by_class(predicted_clean, self.y_train, self.classifier.nb_classes)\n    (_, conf_matrix_json) = self.evaluator.analyze_correctness(predicted_clean_by_class, is_clean_by_class)\n    return conf_matrix_json",
        "mutated": [
            "def evaluate_defence(self, is_clean: np.ndarray, **kwargs) -> str:\n    if False:\n        i = 10\n    '\\n        If ground truth is known, this function returns a confusion matrix in the form of a JSON object.\\n\\n        :param is_clean: Ground truth, where is_clean[i]=1 means that x_train[i] is clean and is_clean[i]=0 means\\n                         x_train[i] is poisonous.\\n        :param kwargs: A dictionary of defence-specific parameters.\\n        :return: JSON object with confusion matrix.\\n        '\n    if is_clean is None or is_clean.size == 0:\n        raise ValueError('is_clean was not provided while invoking evaluate_defence.')\n    is_clean_by_class = segment_by_class(is_clean, self.y_train, self.classifier.nb_classes)\n    (_, predicted_clean) = self.detect_poison()\n    predicted_clean_by_class = segment_by_class(predicted_clean, self.y_train, self.classifier.nb_classes)\n    (_, conf_matrix_json) = self.evaluator.analyze_correctness(predicted_clean_by_class, is_clean_by_class)\n    return conf_matrix_json",
            "def evaluate_defence(self, is_clean: np.ndarray, **kwargs) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        If ground truth is known, this function returns a confusion matrix in the form of a JSON object.\\n\\n        :param is_clean: Ground truth, where is_clean[i]=1 means that x_train[i] is clean and is_clean[i]=0 means\\n                         x_train[i] is poisonous.\\n        :param kwargs: A dictionary of defence-specific parameters.\\n        :return: JSON object with confusion matrix.\\n        '\n    if is_clean is None or is_clean.size == 0:\n        raise ValueError('is_clean was not provided while invoking evaluate_defence.')\n    is_clean_by_class = segment_by_class(is_clean, self.y_train, self.classifier.nb_classes)\n    (_, predicted_clean) = self.detect_poison()\n    predicted_clean_by_class = segment_by_class(predicted_clean, self.y_train, self.classifier.nb_classes)\n    (_, conf_matrix_json) = self.evaluator.analyze_correctness(predicted_clean_by_class, is_clean_by_class)\n    return conf_matrix_json",
            "def evaluate_defence(self, is_clean: np.ndarray, **kwargs) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        If ground truth is known, this function returns a confusion matrix in the form of a JSON object.\\n\\n        :param is_clean: Ground truth, where is_clean[i]=1 means that x_train[i] is clean and is_clean[i]=0 means\\n                         x_train[i] is poisonous.\\n        :param kwargs: A dictionary of defence-specific parameters.\\n        :return: JSON object with confusion matrix.\\n        '\n    if is_clean is None or is_clean.size == 0:\n        raise ValueError('is_clean was not provided while invoking evaluate_defence.')\n    is_clean_by_class = segment_by_class(is_clean, self.y_train, self.classifier.nb_classes)\n    (_, predicted_clean) = self.detect_poison()\n    predicted_clean_by_class = segment_by_class(predicted_clean, self.y_train, self.classifier.nb_classes)\n    (_, conf_matrix_json) = self.evaluator.analyze_correctness(predicted_clean_by_class, is_clean_by_class)\n    return conf_matrix_json",
            "def evaluate_defence(self, is_clean: np.ndarray, **kwargs) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        If ground truth is known, this function returns a confusion matrix in the form of a JSON object.\\n\\n        :param is_clean: Ground truth, where is_clean[i]=1 means that x_train[i] is clean and is_clean[i]=0 means\\n                         x_train[i] is poisonous.\\n        :param kwargs: A dictionary of defence-specific parameters.\\n        :return: JSON object with confusion matrix.\\n        '\n    if is_clean is None or is_clean.size == 0:\n        raise ValueError('is_clean was not provided while invoking evaluate_defence.')\n    is_clean_by_class = segment_by_class(is_clean, self.y_train, self.classifier.nb_classes)\n    (_, predicted_clean) = self.detect_poison()\n    predicted_clean_by_class = segment_by_class(predicted_clean, self.y_train, self.classifier.nb_classes)\n    (_, conf_matrix_json) = self.evaluator.analyze_correctness(predicted_clean_by_class, is_clean_by_class)\n    return conf_matrix_json",
            "def evaluate_defence(self, is_clean: np.ndarray, **kwargs) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        If ground truth is known, this function returns a confusion matrix in the form of a JSON object.\\n\\n        :param is_clean: Ground truth, where is_clean[i]=1 means that x_train[i] is clean and is_clean[i]=0 means\\n                         x_train[i] is poisonous.\\n        :param kwargs: A dictionary of defence-specific parameters.\\n        :return: JSON object with confusion matrix.\\n        '\n    if is_clean is None or is_clean.size == 0:\n        raise ValueError('is_clean was not provided while invoking evaluate_defence.')\n    is_clean_by_class = segment_by_class(is_clean, self.y_train, self.classifier.nb_classes)\n    (_, predicted_clean) = self.detect_poison()\n    predicted_clean_by_class = segment_by_class(predicted_clean, self.y_train, self.classifier.nb_classes)\n    (_, conf_matrix_json) = self.evaluator.analyze_correctness(predicted_clean_by_class, is_clean_by_class)\n    return conf_matrix_json"
        ]
    },
    {
        "func_name": "detect_poison",
        "original": "def detect_poison(self, **kwargs) -> Tuple[dict, List[int]]:\n    \"\"\"\n        Returns poison detected and a report.\n\n        :return: (report, is_clean_lst):\n                where a report is a dictionary containing the index as keys the outlier score of suspected poisons as\n                values where is_clean is a list, where is_clean_lst[i]=1 means that x_train[i] there is clean and\n                is_clean_lst[i]=0, means that x_train[i] was classified as poison.\n        \"\"\"\n    self.set_params(**kwargs)\n    if self.classifier.layer_names is not None:\n        nb_layers = len(self.classifier.layer_names)\n    else:\n        raise ValueError('No layer names identified.')\n    features_x_poisoned = self.classifier.get_activations(self.x_train, layer=nb_layers - 1, batch_size=self.batch_size)\n    if not isinstance(features_x_poisoned, np.ndarray):\n        raise ValueError('Wrong type detected.')\n    if features_x_poisoned is not None:\n        features_split = segment_by_class(features_x_poisoned, self.y_train, self.classifier.nb_classes)\n    else:\n        raise ValueError('Activation are `None`.')\n    score_by_class = []\n    keep_by_class = []\n    for (idx, feature) in enumerate(features_split):\n        if len(feature):\n            score = SpectralSignatureDefense.spectral_signature_scores(np.vstack(feature))\n            score_cutoff = np.quantile(score, max(1 - self.eps_multiplier * self.expected_pp_poison, 0.0))\n            score_by_class.append(score)\n            keep_by_class.append(score < score_cutoff)\n        else:\n            score_by_class.append([0])\n            keep_by_class.append([True])\n    base_indices_by_class = segment_by_class(np.arange(self.y_train.shape[0]), self.y_train, self.classifier.nb_classes)\n    is_clean_lst = [0] * self.y_train.shape[0]\n    report = {}\n    for (keep_booleans, all_scores, indices) in zip(keep_by_class, score_by_class, base_indices_by_class):\n        for (keep_boolean, all_score, idx) in zip(keep_booleans, all_scores, indices):\n            if keep_boolean:\n                is_clean_lst[idx] = 1\n            else:\n                report[idx] = all_score[0]\n    return (report, is_clean_lst)",
        "mutated": [
            "def detect_poison(self, **kwargs) -> Tuple[dict, List[int]]:\n    if False:\n        i = 10\n    '\\n        Returns poison detected and a report.\\n\\n        :return: (report, is_clean_lst):\\n                where a report is a dictionary containing the index as keys the outlier score of suspected poisons as\\n                values where is_clean is a list, where is_clean_lst[i]=1 means that x_train[i] there is clean and\\n                is_clean_lst[i]=0, means that x_train[i] was classified as poison.\\n        '\n    self.set_params(**kwargs)\n    if self.classifier.layer_names is not None:\n        nb_layers = len(self.classifier.layer_names)\n    else:\n        raise ValueError('No layer names identified.')\n    features_x_poisoned = self.classifier.get_activations(self.x_train, layer=nb_layers - 1, batch_size=self.batch_size)\n    if not isinstance(features_x_poisoned, np.ndarray):\n        raise ValueError('Wrong type detected.')\n    if features_x_poisoned is not None:\n        features_split = segment_by_class(features_x_poisoned, self.y_train, self.classifier.nb_classes)\n    else:\n        raise ValueError('Activation are `None`.')\n    score_by_class = []\n    keep_by_class = []\n    for (idx, feature) in enumerate(features_split):\n        if len(feature):\n            score = SpectralSignatureDefense.spectral_signature_scores(np.vstack(feature))\n            score_cutoff = np.quantile(score, max(1 - self.eps_multiplier * self.expected_pp_poison, 0.0))\n            score_by_class.append(score)\n            keep_by_class.append(score < score_cutoff)\n        else:\n            score_by_class.append([0])\n            keep_by_class.append([True])\n    base_indices_by_class = segment_by_class(np.arange(self.y_train.shape[0]), self.y_train, self.classifier.nb_classes)\n    is_clean_lst = [0] * self.y_train.shape[0]\n    report = {}\n    for (keep_booleans, all_scores, indices) in zip(keep_by_class, score_by_class, base_indices_by_class):\n        for (keep_boolean, all_score, idx) in zip(keep_booleans, all_scores, indices):\n            if keep_boolean:\n                is_clean_lst[idx] = 1\n            else:\n                report[idx] = all_score[0]\n    return (report, is_clean_lst)",
            "def detect_poison(self, **kwargs) -> Tuple[dict, List[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns poison detected and a report.\\n\\n        :return: (report, is_clean_lst):\\n                where a report is a dictionary containing the index as keys the outlier score of suspected poisons as\\n                values where is_clean is a list, where is_clean_lst[i]=1 means that x_train[i] there is clean and\\n                is_clean_lst[i]=0, means that x_train[i] was classified as poison.\\n        '\n    self.set_params(**kwargs)\n    if self.classifier.layer_names is not None:\n        nb_layers = len(self.classifier.layer_names)\n    else:\n        raise ValueError('No layer names identified.')\n    features_x_poisoned = self.classifier.get_activations(self.x_train, layer=nb_layers - 1, batch_size=self.batch_size)\n    if not isinstance(features_x_poisoned, np.ndarray):\n        raise ValueError('Wrong type detected.')\n    if features_x_poisoned is not None:\n        features_split = segment_by_class(features_x_poisoned, self.y_train, self.classifier.nb_classes)\n    else:\n        raise ValueError('Activation are `None`.')\n    score_by_class = []\n    keep_by_class = []\n    for (idx, feature) in enumerate(features_split):\n        if len(feature):\n            score = SpectralSignatureDefense.spectral_signature_scores(np.vstack(feature))\n            score_cutoff = np.quantile(score, max(1 - self.eps_multiplier * self.expected_pp_poison, 0.0))\n            score_by_class.append(score)\n            keep_by_class.append(score < score_cutoff)\n        else:\n            score_by_class.append([0])\n            keep_by_class.append([True])\n    base_indices_by_class = segment_by_class(np.arange(self.y_train.shape[0]), self.y_train, self.classifier.nb_classes)\n    is_clean_lst = [0] * self.y_train.shape[0]\n    report = {}\n    for (keep_booleans, all_scores, indices) in zip(keep_by_class, score_by_class, base_indices_by_class):\n        for (keep_boolean, all_score, idx) in zip(keep_booleans, all_scores, indices):\n            if keep_boolean:\n                is_clean_lst[idx] = 1\n            else:\n                report[idx] = all_score[0]\n    return (report, is_clean_lst)",
            "def detect_poison(self, **kwargs) -> Tuple[dict, List[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns poison detected and a report.\\n\\n        :return: (report, is_clean_lst):\\n                where a report is a dictionary containing the index as keys the outlier score of suspected poisons as\\n                values where is_clean is a list, where is_clean_lst[i]=1 means that x_train[i] there is clean and\\n                is_clean_lst[i]=0, means that x_train[i] was classified as poison.\\n        '\n    self.set_params(**kwargs)\n    if self.classifier.layer_names is not None:\n        nb_layers = len(self.classifier.layer_names)\n    else:\n        raise ValueError('No layer names identified.')\n    features_x_poisoned = self.classifier.get_activations(self.x_train, layer=nb_layers - 1, batch_size=self.batch_size)\n    if not isinstance(features_x_poisoned, np.ndarray):\n        raise ValueError('Wrong type detected.')\n    if features_x_poisoned is not None:\n        features_split = segment_by_class(features_x_poisoned, self.y_train, self.classifier.nb_classes)\n    else:\n        raise ValueError('Activation are `None`.')\n    score_by_class = []\n    keep_by_class = []\n    for (idx, feature) in enumerate(features_split):\n        if len(feature):\n            score = SpectralSignatureDefense.spectral_signature_scores(np.vstack(feature))\n            score_cutoff = np.quantile(score, max(1 - self.eps_multiplier * self.expected_pp_poison, 0.0))\n            score_by_class.append(score)\n            keep_by_class.append(score < score_cutoff)\n        else:\n            score_by_class.append([0])\n            keep_by_class.append([True])\n    base_indices_by_class = segment_by_class(np.arange(self.y_train.shape[0]), self.y_train, self.classifier.nb_classes)\n    is_clean_lst = [0] * self.y_train.shape[0]\n    report = {}\n    for (keep_booleans, all_scores, indices) in zip(keep_by_class, score_by_class, base_indices_by_class):\n        for (keep_boolean, all_score, idx) in zip(keep_booleans, all_scores, indices):\n            if keep_boolean:\n                is_clean_lst[idx] = 1\n            else:\n                report[idx] = all_score[0]\n    return (report, is_clean_lst)",
            "def detect_poison(self, **kwargs) -> Tuple[dict, List[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns poison detected and a report.\\n\\n        :return: (report, is_clean_lst):\\n                where a report is a dictionary containing the index as keys the outlier score of suspected poisons as\\n                values where is_clean is a list, where is_clean_lst[i]=1 means that x_train[i] there is clean and\\n                is_clean_lst[i]=0, means that x_train[i] was classified as poison.\\n        '\n    self.set_params(**kwargs)\n    if self.classifier.layer_names is not None:\n        nb_layers = len(self.classifier.layer_names)\n    else:\n        raise ValueError('No layer names identified.')\n    features_x_poisoned = self.classifier.get_activations(self.x_train, layer=nb_layers - 1, batch_size=self.batch_size)\n    if not isinstance(features_x_poisoned, np.ndarray):\n        raise ValueError('Wrong type detected.')\n    if features_x_poisoned is not None:\n        features_split = segment_by_class(features_x_poisoned, self.y_train, self.classifier.nb_classes)\n    else:\n        raise ValueError('Activation are `None`.')\n    score_by_class = []\n    keep_by_class = []\n    for (idx, feature) in enumerate(features_split):\n        if len(feature):\n            score = SpectralSignatureDefense.spectral_signature_scores(np.vstack(feature))\n            score_cutoff = np.quantile(score, max(1 - self.eps_multiplier * self.expected_pp_poison, 0.0))\n            score_by_class.append(score)\n            keep_by_class.append(score < score_cutoff)\n        else:\n            score_by_class.append([0])\n            keep_by_class.append([True])\n    base_indices_by_class = segment_by_class(np.arange(self.y_train.shape[0]), self.y_train, self.classifier.nb_classes)\n    is_clean_lst = [0] * self.y_train.shape[0]\n    report = {}\n    for (keep_booleans, all_scores, indices) in zip(keep_by_class, score_by_class, base_indices_by_class):\n        for (keep_boolean, all_score, idx) in zip(keep_booleans, all_scores, indices):\n            if keep_boolean:\n                is_clean_lst[idx] = 1\n            else:\n                report[idx] = all_score[0]\n    return (report, is_clean_lst)",
            "def detect_poison(self, **kwargs) -> Tuple[dict, List[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns poison detected and a report.\\n\\n        :return: (report, is_clean_lst):\\n                where a report is a dictionary containing the index as keys the outlier score of suspected poisons as\\n                values where is_clean is a list, where is_clean_lst[i]=1 means that x_train[i] there is clean and\\n                is_clean_lst[i]=0, means that x_train[i] was classified as poison.\\n        '\n    self.set_params(**kwargs)\n    if self.classifier.layer_names is not None:\n        nb_layers = len(self.classifier.layer_names)\n    else:\n        raise ValueError('No layer names identified.')\n    features_x_poisoned = self.classifier.get_activations(self.x_train, layer=nb_layers - 1, batch_size=self.batch_size)\n    if not isinstance(features_x_poisoned, np.ndarray):\n        raise ValueError('Wrong type detected.')\n    if features_x_poisoned is not None:\n        features_split = segment_by_class(features_x_poisoned, self.y_train, self.classifier.nb_classes)\n    else:\n        raise ValueError('Activation are `None`.')\n    score_by_class = []\n    keep_by_class = []\n    for (idx, feature) in enumerate(features_split):\n        if len(feature):\n            score = SpectralSignatureDefense.spectral_signature_scores(np.vstack(feature))\n            score_cutoff = np.quantile(score, max(1 - self.eps_multiplier * self.expected_pp_poison, 0.0))\n            score_by_class.append(score)\n            keep_by_class.append(score < score_cutoff)\n        else:\n            score_by_class.append([0])\n            keep_by_class.append([True])\n    base_indices_by_class = segment_by_class(np.arange(self.y_train.shape[0]), self.y_train, self.classifier.nb_classes)\n    is_clean_lst = [0] * self.y_train.shape[0]\n    report = {}\n    for (keep_booleans, all_scores, indices) in zip(keep_by_class, score_by_class, base_indices_by_class):\n        for (keep_boolean, all_score, idx) in zip(keep_booleans, all_scores, indices):\n            if keep_boolean:\n                is_clean_lst[idx] = 1\n            else:\n                report[idx] = all_score[0]\n    return (report, is_clean_lst)"
        ]
    },
    {
        "func_name": "_check_params",
        "original": "def _check_params(self) -> None:\n    if self.batch_size < 0:\n        raise ValueError('Batch size must be positive integer. Unsupported batch size: ' + str(self.batch_size))\n    if self.eps_multiplier < 0:\n        raise ValueError('eps_multiplier must be positive. Unsupported value: ' + str(self.eps_multiplier))\n    if self.expected_pp_poison < 0 or self.expected_pp_poison > 1:\n        raise ValueError('expected_pp_poison must be between 0 and 1. Unsupported value: ' + str(self.expected_pp_poison))",
        "mutated": [
            "def _check_params(self) -> None:\n    if False:\n        i = 10\n    if self.batch_size < 0:\n        raise ValueError('Batch size must be positive integer. Unsupported batch size: ' + str(self.batch_size))\n    if self.eps_multiplier < 0:\n        raise ValueError('eps_multiplier must be positive. Unsupported value: ' + str(self.eps_multiplier))\n    if self.expected_pp_poison < 0 or self.expected_pp_poison > 1:\n        raise ValueError('expected_pp_poison must be between 0 and 1. Unsupported value: ' + str(self.expected_pp_poison))",
            "def _check_params(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if self.batch_size < 0:\n        raise ValueError('Batch size must be positive integer. Unsupported batch size: ' + str(self.batch_size))\n    if self.eps_multiplier < 0:\n        raise ValueError('eps_multiplier must be positive. Unsupported value: ' + str(self.eps_multiplier))\n    if self.expected_pp_poison < 0 or self.expected_pp_poison > 1:\n        raise ValueError('expected_pp_poison must be between 0 and 1. Unsupported value: ' + str(self.expected_pp_poison))",
            "def _check_params(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if self.batch_size < 0:\n        raise ValueError('Batch size must be positive integer. Unsupported batch size: ' + str(self.batch_size))\n    if self.eps_multiplier < 0:\n        raise ValueError('eps_multiplier must be positive. Unsupported value: ' + str(self.eps_multiplier))\n    if self.expected_pp_poison < 0 or self.expected_pp_poison > 1:\n        raise ValueError('expected_pp_poison must be between 0 and 1. Unsupported value: ' + str(self.expected_pp_poison))",
            "def _check_params(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if self.batch_size < 0:\n        raise ValueError('Batch size must be positive integer. Unsupported batch size: ' + str(self.batch_size))\n    if self.eps_multiplier < 0:\n        raise ValueError('eps_multiplier must be positive. Unsupported value: ' + str(self.eps_multiplier))\n    if self.expected_pp_poison < 0 or self.expected_pp_poison > 1:\n        raise ValueError('expected_pp_poison must be between 0 and 1. Unsupported value: ' + str(self.expected_pp_poison))",
            "def _check_params(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if self.batch_size < 0:\n        raise ValueError('Batch size must be positive integer. Unsupported batch size: ' + str(self.batch_size))\n    if self.eps_multiplier < 0:\n        raise ValueError('eps_multiplier must be positive. Unsupported value: ' + str(self.eps_multiplier))\n    if self.expected_pp_poison < 0 or self.expected_pp_poison > 1:\n        raise ValueError('expected_pp_poison must be between 0 and 1. Unsupported value: ' + str(self.expected_pp_poison))"
        ]
    },
    {
        "func_name": "spectral_signature_scores",
        "original": "@staticmethod\ndef spectral_signature_scores(matrix_r: np.ndarray) -> np.ndarray:\n    \"\"\"\n        :param matrix_r: Matrix of feature representations.\n        :return: Outlier scores for each observation based on spectral signature.\n        \"\"\"\n    matrix_m = matrix_r - np.mean(matrix_r, axis=0)\n    (_, _, matrix_v) = np.linalg.svd(matrix_m, full_matrices=False)\n    eigs = matrix_v[:1]\n    corrs = np.matmul(eigs, np.transpose(matrix_r))\n    score = np.expand_dims(np.linalg.norm(corrs, axis=0), axis=1)\n    return score",
        "mutated": [
            "@staticmethod\ndef spectral_signature_scores(matrix_r: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n    '\\n        :param matrix_r: Matrix of feature representations.\\n        :return: Outlier scores for each observation based on spectral signature.\\n        '\n    matrix_m = matrix_r - np.mean(matrix_r, axis=0)\n    (_, _, matrix_v) = np.linalg.svd(matrix_m, full_matrices=False)\n    eigs = matrix_v[:1]\n    corrs = np.matmul(eigs, np.transpose(matrix_r))\n    score = np.expand_dims(np.linalg.norm(corrs, axis=0), axis=1)\n    return score",
            "@staticmethod\ndef spectral_signature_scores(matrix_r: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        :param matrix_r: Matrix of feature representations.\\n        :return: Outlier scores for each observation based on spectral signature.\\n        '\n    matrix_m = matrix_r - np.mean(matrix_r, axis=0)\n    (_, _, matrix_v) = np.linalg.svd(matrix_m, full_matrices=False)\n    eigs = matrix_v[:1]\n    corrs = np.matmul(eigs, np.transpose(matrix_r))\n    score = np.expand_dims(np.linalg.norm(corrs, axis=0), axis=1)\n    return score",
            "@staticmethod\ndef spectral_signature_scores(matrix_r: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        :param matrix_r: Matrix of feature representations.\\n        :return: Outlier scores for each observation based on spectral signature.\\n        '\n    matrix_m = matrix_r - np.mean(matrix_r, axis=0)\n    (_, _, matrix_v) = np.linalg.svd(matrix_m, full_matrices=False)\n    eigs = matrix_v[:1]\n    corrs = np.matmul(eigs, np.transpose(matrix_r))\n    score = np.expand_dims(np.linalg.norm(corrs, axis=0), axis=1)\n    return score",
            "@staticmethod\ndef spectral_signature_scores(matrix_r: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        :param matrix_r: Matrix of feature representations.\\n        :return: Outlier scores for each observation based on spectral signature.\\n        '\n    matrix_m = matrix_r - np.mean(matrix_r, axis=0)\n    (_, _, matrix_v) = np.linalg.svd(matrix_m, full_matrices=False)\n    eigs = matrix_v[:1]\n    corrs = np.matmul(eigs, np.transpose(matrix_r))\n    score = np.expand_dims(np.linalg.norm(corrs, axis=0), axis=1)\n    return score",
            "@staticmethod\ndef spectral_signature_scores(matrix_r: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        :param matrix_r: Matrix of feature representations.\\n        :return: Outlier scores for each observation based on spectral signature.\\n        '\n    matrix_m = matrix_r - np.mean(matrix_r, axis=0)\n    (_, _, matrix_v) = np.linalg.svd(matrix_m, full_matrices=False)\n    eigs = matrix_v[:1]\n    corrs = np.matmul(eigs, np.transpose(matrix_r))\n    score = np.expand_dims(np.linalg.norm(corrs, axis=0), axis=1)\n    return score"
        ]
    }
]