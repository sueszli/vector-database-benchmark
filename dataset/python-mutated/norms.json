[
    {
        "func_name": "layer_norm",
        "original": "def layer_norm(self: Union[ivy.Array, ivy.NativeArray, ivy.Container], normalized_idxs: List[Union[int, ivy.Container]], /, *, scale: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, offset: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, eps: Union[float, ivy.Container]=1e-05, new_std: Union[float, ivy.Container]=1.0, out: Optional[Union[ivy.Array, ivy.Container]]=None) -> ivy.Container:\n    \"\"\"\n        ivy.Container instance method variant of ivy.layer_norm. This method simply\n        wraps the function, and so the docstring for ivy.layer_norm also applies to this\n        method with minimal changes.\n\n        Parameters\n        ----------\n        self\n            Input container\n        normalized_idxs\n            Indices to apply the normalization to.\n        scale\n            Learnable gamma variables for elementwise post-multiplication,\n            default is ``None``.\n        offset\n            Learnable beta variables for elementwise post-addition, default is ``None``.\n        eps\n            small constant to add to the denominator. Default is ``1e-05``.\n        new_std\n            The standard deviation of the new normalized values. Default is 1.\n        out\n            optional output container, for writing the result to. It must have a shape\n            that the inputs broadcast to.\n\n        Returns\n        -------\n        ret\n            The layer after applying layer normalization.\n\n        Examples\n        --------\n        With one :class:`ivy.Container` input:\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\n        >>> normalized_idxs = [0]\n        >>> norm = x.layer_norm(normalized_idxs, eps=1.25, scale=0.3)\n        >>> print(norm)\n        {\n            a: ivy.array([-0.34198591, 0.04274819, 0.29923761]),\n            b: ivy.array([[-0.24053511, -0.24053511, -0.24053511],\n                          [0.24053511, 0.24053511, 0.24053511]])\n        }\n        With multiple :class:`ivy.Container` inputs:\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\n        >>> normalized_idxs = ivy.Container({'a': [0], 'b': [1]})\n        >>> new_std = ivy.Container({'a': 1.25, 'b': 1.5})\n        >>> bias = ivy.Container({'a': [0.2, 0.5, 0.7], 'b': 0.3})\n        >>> norm = x.layer_norm(normalized_idxs, new_std=new_std, offset=1)\n        >>> print(norm)\n        {\n            a: ivy.array([-1.62221265, 0.20277636, 1.41943574]),\n            b: ivy.array([[-1.83710337, 0., 1.83710337],\n                          [-1.83710337, 0., 1.83710337]])\n        }\n        \"\"\"\n    return ivy.layer_norm(self, normalized_idxs, scale=scale, offset=offset, eps=eps, new_std=new_std, out=out)",
        "mutated": [
            "def layer_norm(self: Union[ivy.Array, ivy.NativeArray, ivy.Container], normalized_idxs: List[Union[int, ivy.Container]], /, *, scale: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, offset: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, eps: Union[float, ivy.Container]=1e-05, new_std: Union[float, ivy.Container]=1.0, out: Optional[Union[ivy.Array, ivy.Container]]=None) -> ivy.Container:\n    if False:\n        i = 10\n    \"\\n        ivy.Container instance method variant of ivy.layer_norm. This method simply\\n        wraps the function, and so the docstring for ivy.layer_norm also applies to this\\n        method with minimal changes.\\n\\n        Parameters\\n        ----------\\n        self\\n            Input container\\n        normalized_idxs\\n            Indices to apply the normalization to.\\n        scale\\n            Learnable gamma variables for elementwise post-multiplication,\\n            default is ``None``.\\n        offset\\n            Learnable beta variables for elementwise post-addition, default is ``None``.\\n        eps\\n            small constant to add to the denominator. Default is ``1e-05``.\\n        new_std\\n            The standard deviation of the new normalized values. Default is 1.\\n        out\\n            optional output container, for writing the result to. It must have a shape\\n            that the inputs broadcast to.\\n\\n        Returns\\n        -------\\n        ret\\n            The layer after applying layer normalization.\\n\\n        Examples\\n        --------\\n        With one :class:`ivy.Container` input:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = [0]\\n        >>> norm = x.layer_norm(normalized_idxs, eps=1.25, scale=0.3)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-0.34198591, 0.04274819, 0.29923761]),\\n            b: ivy.array([[-0.24053511, -0.24053511, -0.24053511],\\n                          [0.24053511, 0.24053511, 0.24053511]])\\n        }\\n        With multiple :class:`ivy.Container` inputs:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = ivy.Container({'a': [0], 'b': [1]})\\n        >>> new_std = ivy.Container({'a': 1.25, 'b': 1.5})\\n        >>> bias = ivy.Container({'a': [0.2, 0.5, 0.7], 'b': 0.3})\\n        >>> norm = x.layer_norm(normalized_idxs, new_std=new_std, offset=1)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-1.62221265, 0.20277636, 1.41943574]),\\n            b: ivy.array([[-1.83710337, 0., 1.83710337],\\n                          [-1.83710337, 0., 1.83710337]])\\n        }\\n        \"\n    return ivy.layer_norm(self, normalized_idxs, scale=scale, offset=offset, eps=eps, new_std=new_std, out=out)",
            "def layer_norm(self: Union[ivy.Array, ivy.NativeArray, ivy.Container], normalized_idxs: List[Union[int, ivy.Container]], /, *, scale: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, offset: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, eps: Union[float, ivy.Container]=1e-05, new_std: Union[float, ivy.Container]=1.0, out: Optional[Union[ivy.Array, ivy.Container]]=None) -> ivy.Container:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        ivy.Container instance method variant of ivy.layer_norm. This method simply\\n        wraps the function, and so the docstring for ivy.layer_norm also applies to this\\n        method with minimal changes.\\n\\n        Parameters\\n        ----------\\n        self\\n            Input container\\n        normalized_idxs\\n            Indices to apply the normalization to.\\n        scale\\n            Learnable gamma variables for elementwise post-multiplication,\\n            default is ``None``.\\n        offset\\n            Learnable beta variables for elementwise post-addition, default is ``None``.\\n        eps\\n            small constant to add to the denominator. Default is ``1e-05``.\\n        new_std\\n            The standard deviation of the new normalized values. Default is 1.\\n        out\\n            optional output container, for writing the result to. It must have a shape\\n            that the inputs broadcast to.\\n\\n        Returns\\n        -------\\n        ret\\n            The layer after applying layer normalization.\\n\\n        Examples\\n        --------\\n        With one :class:`ivy.Container` input:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = [0]\\n        >>> norm = x.layer_norm(normalized_idxs, eps=1.25, scale=0.3)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-0.34198591, 0.04274819, 0.29923761]),\\n            b: ivy.array([[-0.24053511, -0.24053511, -0.24053511],\\n                          [0.24053511, 0.24053511, 0.24053511]])\\n        }\\n        With multiple :class:`ivy.Container` inputs:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = ivy.Container({'a': [0], 'b': [1]})\\n        >>> new_std = ivy.Container({'a': 1.25, 'b': 1.5})\\n        >>> bias = ivy.Container({'a': [0.2, 0.5, 0.7], 'b': 0.3})\\n        >>> norm = x.layer_norm(normalized_idxs, new_std=new_std, offset=1)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-1.62221265, 0.20277636, 1.41943574]),\\n            b: ivy.array([[-1.83710337, 0., 1.83710337],\\n                          [-1.83710337, 0., 1.83710337]])\\n        }\\n        \"\n    return ivy.layer_norm(self, normalized_idxs, scale=scale, offset=offset, eps=eps, new_std=new_std, out=out)",
            "def layer_norm(self: Union[ivy.Array, ivy.NativeArray, ivy.Container], normalized_idxs: List[Union[int, ivy.Container]], /, *, scale: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, offset: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, eps: Union[float, ivy.Container]=1e-05, new_std: Union[float, ivy.Container]=1.0, out: Optional[Union[ivy.Array, ivy.Container]]=None) -> ivy.Container:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        ivy.Container instance method variant of ivy.layer_norm. This method simply\\n        wraps the function, and so the docstring for ivy.layer_norm also applies to this\\n        method with minimal changes.\\n\\n        Parameters\\n        ----------\\n        self\\n            Input container\\n        normalized_idxs\\n            Indices to apply the normalization to.\\n        scale\\n            Learnable gamma variables for elementwise post-multiplication,\\n            default is ``None``.\\n        offset\\n            Learnable beta variables for elementwise post-addition, default is ``None``.\\n        eps\\n            small constant to add to the denominator. Default is ``1e-05``.\\n        new_std\\n            The standard deviation of the new normalized values. Default is 1.\\n        out\\n            optional output container, for writing the result to. It must have a shape\\n            that the inputs broadcast to.\\n\\n        Returns\\n        -------\\n        ret\\n            The layer after applying layer normalization.\\n\\n        Examples\\n        --------\\n        With one :class:`ivy.Container` input:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = [0]\\n        >>> norm = x.layer_norm(normalized_idxs, eps=1.25, scale=0.3)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-0.34198591, 0.04274819, 0.29923761]),\\n            b: ivy.array([[-0.24053511, -0.24053511, -0.24053511],\\n                          [0.24053511, 0.24053511, 0.24053511]])\\n        }\\n        With multiple :class:`ivy.Container` inputs:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = ivy.Container({'a': [0], 'b': [1]})\\n        >>> new_std = ivy.Container({'a': 1.25, 'b': 1.5})\\n        >>> bias = ivy.Container({'a': [0.2, 0.5, 0.7], 'b': 0.3})\\n        >>> norm = x.layer_norm(normalized_idxs, new_std=new_std, offset=1)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-1.62221265, 0.20277636, 1.41943574]),\\n            b: ivy.array([[-1.83710337, 0., 1.83710337],\\n                          [-1.83710337, 0., 1.83710337]])\\n        }\\n        \"\n    return ivy.layer_norm(self, normalized_idxs, scale=scale, offset=offset, eps=eps, new_std=new_std, out=out)",
            "def layer_norm(self: Union[ivy.Array, ivy.NativeArray, ivy.Container], normalized_idxs: List[Union[int, ivy.Container]], /, *, scale: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, offset: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, eps: Union[float, ivy.Container]=1e-05, new_std: Union[float, ivy.Container]=1.0, out: Optional[Union[ivy.Array, ivy.Container]]=None) -> ivy.Container:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        ivy.Container instance method variant of ivy.layer_norm. This method simply\\n        wraps the function, and so the docstring for ivy.layer_norm also applies to this\\n        method with minimal changes.\\n\\n        Parameters\\n        ----------\\n        self\\n            Input container\\n        normalized_idxs\\n            Indices to apply the normalization to.\\n        scale\\n            Learnable gamma variables for elementwise post-multiplication,\\n            default is ``None``.\\n        offset\\n            Learnable beta variables for elementwise post-addition, default is ``None``.\\n        eps\\n            small constant to add to the denominator. Default is ``1e-05``.\\n        new_std\\n            The standard deviation of the new normalized values. Default is 1.\\n        out\\n            optional output container, for writing the result to. It must have a shape\\n            that the inputs broadcast to.\\n\\n        Returns\\n        -------\\n        ret\\n            The layer after applying layer normalization.\\n\\n        Examples\\n        --------\\n        With one :class:`ivy.Container` input:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = [0]\\n        >>> norm = x.layer_norm(normalized_idxs, eps=1.25, scale=0.3)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-0.34198591, 0.04274819, 0.29923761]),\\n            b: ivy.array([[-0.24053511, -0.24053511, -0.24053511],\\n                          [0.24053511, 0.24053511, 0.24053511]])\\n        }\\n        With multiple :class:`ivy.Container` inputs:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = ivy.Container({'a': [0], 'b': [1]})\\n        >>> new_std = ivy.Container({'a': 1.25, 'b': 1.5})\\n        >>> bias = ivy.Container({'a': [0.2, 0.5, 0.7], 'b': 0.3})\\n        >>> norm = x.layer_norm(normalized_idxs, new_std=new_std, offset=1)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-1.62221265, 0.20277636, 1.41943574]),\\n            b: ivy.array([[-1.83710337, 0., 1.83710337],\\n                          [-1.83710337, 0., 1.83710337]])\\n        }\\n        \"\n    return ivy.layer_norm(self, normalized_idxs, scale=scale, offset=offset, eps=eps, new_std=new_std, out=out)",
            "def layer_norm(self: Union[ivy.Array, ivy.NativeArray, ivy.Container], normalized_idxs: List[Union[int, ivy.Container]], /, *, scale: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, offset: Optional[Union[ivy.Array, ivy.NativeArray, ivy.Container]]=None, eps: Union[float, ivy.Container]=1e-05, new_std: Union[float, ivy.Container]=1.0, out: Optional[Union[ivy.Array, ivy.Container]]=None) -> ivy.Container:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        ivy.Container instance method variant of ivy.layer_norm. This method simply\\n        wraps the function, and so the docstring for ivy.layer_norm also applies to this\\n        method with minimal changes.\\n\\n        Parameters\\n        ----------\\n        self\\n            Input container\\n        normalized_idxs\\n            Indices to apply the normalization to.\\n        scale\\n            Learnable gamma variables for elementwise post-multiplication,\\n            default is ``None``.\\n        offset\\n            Learnable beta variables for elementwise post-addition, default is ``None``.\\n        eps\\n            small constant to add to the denominator. Default is ``1e-05``.\\n        new_std\\n            The standard deviation of the new normalized values. Default is 1.\\n        out\\n            optional output container, for writing the result to. It must have a shape\\n            that the inputs broadcast to.\\n\\n        Returns\\n        -------\\n        ret\\n            The layer after applying layer normalization.\\n\\n        Examples\\n        --------\\n        With one :class:`ivy.Container` input:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = [0]\\n        >>> norm = x.layer_norm(normalized_idxs, eps=1.25, scale=0.3)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-0.34198591, 0.04274819, 0.29923761]),\\n            b: ivy.array([[-0.24053511, -0.24053511, -0.24053511],\\n                          [0.24053511, 0.24053511, 0.24053511]])\\n        }\\n        With multiple :class:`ivy.Container` inputs:\\n        >>> x = ivy.Container({'a': ivy.array([7., 10., 12.]),\\n        ...                    'b': ivy.array([[1., 2., 3.], [4., 5., 6.]])})\\n        >>> normalized_idxs = ivy.Container({'a': [0], 'b': [1]})\\n        >>> new_std = ivy.Container({'a': 1.25, 'b': 1.5})\\n        >>> bias = ivy.Container({'a': [0.2, 0.5, 0.7], 'b': 0.3})\\n        >>> norm = x.layer_norm(normalized_idxs, new_std=new_std, offset=1)\\n        >>> print(norm)\\n        {\\n            a: ivy.array([-1.62221265, 0.20277636, 1.41943574]),\\n            b: ivy.array([[-1.83710337, 0., 1.83710337],\\n                          [-1.83710337, 0., 1.83710337]])\\n        }\\n        \"\n    return ivy.layer_norm(self, normalized_idxs, scale=scale, offset=offset, eps=eps, new_std=new_std, out=out)"
        ]
    }
]