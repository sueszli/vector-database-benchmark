[
    {
        "func_name": "_update_if_necessary",
        "original": "def _update_if_necessary(dic: Dict[str, str], key: str, value: Optional[str], mode: str) -> str:\n    if value is not None:\n        if key not in dic or dic[key] != value:\n            dic[key] = value\n            if mode in ('append', 'overwrite_partitions'):\n                return 'update'\n    return mode",
        "mutated": [
            "def _update_if_necessary(dic: Dict[str, str], key: str, value: Optional[str], mode: str) -> str:\n    if False:\n        i = 10\n    if value is not None:\n        if key not in dic or dic[key] != value:\n            dic[key] = value\n            if mode in ('append', 'overwrite_partitions'):\n                return 'update'\n    return mode",
            "def _update_if_necessary(dic: Dict[str, str], key: str, value: Optional[str], mode: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if value is not None:\n        if key not in dic or dic[key] != value:\n            dic[key] = value\n            if mode in ('append', 'overwrite_partitions'):\n                return 'update'\n    return mode",
            "def _update_if_necessary(dic: Dict[str, str], key: str, value: Optional[str], mode: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if value is not None:\n        if key not in dic or dic[key] != value:\n            dic[key] = value\n            if mode in ('append', 'overwrite_partitions'):\n                return 'update'\n    return mode",
            "def _update_if_necessary(dic: Dict[str, str], key: str, value: Optional[str], mode: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if value is not None:\n        if key not in dic or dic[key] != value:\n            dic[key] = value\n            if mode in ('append', 'overwrite_partitions'):\n                return 'update'\n    return mode",
            "def _update_if_necessary(dic: Dict[str, str], key: str, value: Optional[str], mode: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if value is not None:\n        if key not in dic or dic[key] != value:\n            dic[key] = value\n            if mode in ('append', 'overwrite_partitions'):\n                return 'update'\n    return mode"
        ]
    },
    {
        "func_name": "_create_table",
        "original": "def _create_table(database: str, table: str, description: Optional[str], parameters: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, boto3_session: Optional[boto3.Session], table_input: Dict[str, Any], table_type: Optional[str], table_exist: bool, partitions_types: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_id: Optional[str]) -> None:\n    mode = _update_if_necessary(dic=table_input, key='Description', value=description, mode=mode)\n    if 'Parameters' not in table_input:\n        table_input['Parameters'] = {}\n    parameters = parameters if parameters else {}\n    for (k, v) in parameters.items():\n        mode = _update_if_necessary(dic=table_input['Parameters'], key=k, value=v, mode=mode)\n    projection_params = athena_partition_projection_settings if athena_partition_projection_settings else {}\n    if athena_partition_projection_settings:\n        table_input['Parameters']['projection.enabled'] = 'true'\n        partitions_types = partitions_types if partitions_types else {}\n        projection_types = projection_params.get('projection_types', {})\n        projection_ranges = projection_params.get('projection_ranges', {})\n        projection_values = projection_params.get('projection_values', {})\n        projection_intervals = projection_params.get('projection_intervals', {})\n        projection_digits = projection_params.get('projection_digits', {})\n        projection_formats = projection_params.get('projection_formats', {})\n        projection_types = {sanitize_column_name(k): v for (k, v) in projection_types.items()}\n        projection_ranges = {sanitize_column_name(k): v for (k, v) in projection_ranges.items()}\n        projection_values = {sanitize_column_name(k): v for (k, v) in projection_values.items()}\n        projection_intervals = {sanitize_column_name(k): v for (k, v) in projection_intervals.items()}\n        projection_digits = {sanitize_column_name(k): v for (k, v) in projection_digits.items()}\n        projection_formats = {sanitize_column_name(k): v for (k, v) in projection_formats.items()}\n        projection_storage_location_template = projection_params.get('projection_storage_location_template')\n        for (k, v) in projection_types.items():\n            dtype: Optional[str] = partitions_types.get(k)\n            if dtype is None and projection_storage_location_template is None:\n                raise exceptions.InvalidArgumentCombination(f'Column {k} appears as projected column but not as partitioned column.')\n            if dtype == 'date':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd'\n            elif dtype == 'timestamp':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd HH:mm:ss'\n                table_input['Parameters'][f'projection.{k}.interval.unit'] = 'SECONDS'\n                table_input['Parameters'][f'projection.{k}.interval'] = '1'\n        for (k, v) in projection_types.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.type', value=v, mode=mode)\n        for (k, v) in projection_ranges.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.range', value=v, mode=mode)\n        for (k, v) in projection_values.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.values', value=v, mode=mode)\n        for (k, v) in projection_intervals.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.interval', value=str(v), mode=mode)\n        for (k, v) in projection_digits.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.digits', value=str(v), mode=mode)\n        for (k, v) in projection_formats.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.format', value=str(v), mode=mode)\n        mode = _update_if_necessary(table_input['Parameters'], key='storage.location.template', value=projection_storage_location_template, mode=mode)\n    else:\n        table_input['Parameters']['projection.enabled'] = 'false'\n    columns_comments = columns_comments if columns_comments else {}\n    columns_comments = {sanitize_column_name(k): v for (k, v) in columns_comments.items()}\n    if columns_comments:\n        for col in table_input['StorageDescriptor']['Columns']:\n            name: str = col['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=col, key='Comment', value=columns_comments[name], mode=mode)\n        for par in table_input['PartitionKeys']:\n            name = par['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=par, key='Comment', value=columns_comments[name], mode=mode)\n    _logger.debug('table_input: %s', table_input)\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    if mode not in ('overwrite', 'append', 'overwrite_partitions', 'update'):\n        raise exceptions.InvalidArgument(f\"{mode} is not a valid mode. It must be 'overwrite', 'append' or 'overwrite_partitions'.\")\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    if table_exist:\n        _logger.debug('Updating table (%s)...', mode)\n        args['SkipArchive'] = skip_archive\n        if mode == 'overwrite':\n            if table_type != 'GOVERNED':\n                delete_all_partitions(table=table, database=database, catalog_id=catalog_id, boto3_session=boto3_session)\n            client_glue.update_table(**args)\n        elif mode == 'update':\n            client_glue.update_table(**args)\n    else:\n        try:\n            _logger.debug('Creating table (%s)...', mode)\n            client_glue.create_table(**args)\n        except client_glue.exceptions.AlreadyExistsException:\n            if mode == 'overwrite':\n                _utils.try_it(f=_overwrite_table, ex=client_glue.exceptions.AlreadyExistsException, client_glue=client_glue, catalog_id=catalog_id, database=database, table=table, table_input=table_input, transaction_id=transaction_id, boto3_session=boto3_session)\n    _logger.debug('Leaving table as is (%s)...', mode)",
        "mutated": [
            "def _create_table(database: str, table: str, description: Optional[str], parameters: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, boto3_session: Optional[boto3.Session], table_input: Dict[str, Any], table_type: Optional[str], table_exist: bool, partitions_types: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n    mode = _update_if_necessary(dic=table_input, key='Description', value=description, mode=mode)\n    if 'Parameters' not in table_input:\n        table_input['Parameters'] = {}\n    parameters = parameters if parameters else {}\n    for (k, v) in parameters.items():\n        mode = _update_if_necessary(dic=table_input['Parameters'], key=k, value=v, mode=mode)\n    projection_params = athena_partition_projection_settings if athena_partition_projection_settings else {}\n    if athena_partition_projection_settings:\n        table_input['Parameters']['projection.enabled'] = 'true'\n        partitions_types = partitions_types if partitions_types else {}\n        projection_types = projection_params.get('projection_types', {})\n        projection_ranges = projection_params.get('projection_ranges', {})\n        projection_values = projection_params.get('projection_values', {})\n        projection_intervals = projection_params.get('projection_intervals', {})\n        projection_digits = projection_params.get('projection_digits', {})\n        projection_formats = projection_params.get('projection_formats', {})\n        projection_types = {sanitize_column_name(k): v for (k, v) in projection_types.items()}\n        projection_ranges = {sanitize_column_name(k): v for (k, v) in projection_ranges.items()}\n        projection_values = {sanitize_column_name(k): v for (k, v) in projection_values.items()}\n        projection_intervals = {sanitize_column_name(k): v for (k, v) in projection_intervals.items()}\n        projection_digits = {sanitize_column_name(k): v for (k, v) in projection_digits.items()}\n        projection_formats = {sanitize_column_name(k): v for (k, v) in projection_formats.items()}\n        projection_storage_location_template = projection_params.get('projection_storage_location_template')\n        for (k, v) in projection_types.items():\n            dtype: Optional[str] = partitions_types.get(k)\n            if dtype is None and projection_storage_location_template is None:\n                raise exceptions.InvalidArgumentCombination(f'Column {k} appears as projected column but not as partitioned column.')\n            if dtype == 'date':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd'\n            elif dtype == 'timestamp':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd HH:mm:ss'\n                table_input['Parameters'][f'projection.{k}.interval.unit'] = 'SECONDS'\n                table_input['Parameters'][f'projection.{k}.interval'] = '1'\n        for (k, v) in projection_types.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.type', value=v, mode=mode)\n        for (k, v) in projection_ranges.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.range', value=v, mode=mode)\n        for (k, v) in projection_values.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.values', value=v, mode=mode)\n        for (k, v) in projection_intervals.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.interval', value=str(v), mode=mode)\n        for (k, v) in projection_digits.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.digits', value=str(v), mode=mode)\n        for (k, v) in projection_formats.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.format', value=str(v), mode=mode)\n        mode = _update_if_necessary(table_input['Parameters'], key='storage.location.template', value=projection_storage_location_template, mode=mode)\n    else:\n        table_input['Parameters']['projection.enabled'] = 'false'\n    columns_comments = columns_comments if columns_comments else {}\n    columns_comments = {sanitize_column_name(k): v for (k, v) in columns_comments.items()}\n    if columns_comments:\n        for col in table_input['StorageDescriptor']['Columns']:\n            name: str = col['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=col, key='Comment', value=columns_comments[name], mode=mode)\n        for par in table_input['PartitionKeys']:\n            name = par['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=par, key='Comment', value=columns_comments[name], mode=mode)\n    _logger.debug('table_input: %s', table_input)\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    if mode not in ('overwrite', 'append', 'overwrite_partitions', 'update'):\n        raise exceptions.InvalidArgument(f\"{mode} is not a valid mode. It must be 'overwrite', 'append' or 'overwrite_partitions'.\")\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    if table_exist:\n        _logger.debug('Updating table (%s)...', mode)\n        args['SkipArchive'] = skip_archive\n        if mode == 'overwrite':\n            if table_type != 'GOVERNED':\n                delete_all_partitions(table=table, database=database, catalog_id=catalog_id, boto3_session=boto3_session)\n            client_glue.update_table(**args)\n        elif mode == 'update':\n            client_glue.update_table(**args)\n    else:\n        try:\n            _logger.debug('Creating table (%s)...', mode)\n            client_glue.create_table(**args)\n        except client_glue.exceptions.AlreadyExistsException:\n            if mode == 'overwrite':\n                _utils.try_it(f=_overwrite_table, ex=client_glue.exceptions.AlreadyExistsException, client_glue=client_glue, catalog_id=catalog_id, database=database, table=table, table_input=table_input, transaction_id=transaction_id, boto3_session=boto3_session)\n    _logger.debug('Leaving table as is (%s)...', mode)",
            "def _create_table(database: str, table: str, description: Optional[str], parameters: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, boto3_session: Optional[boto3.Session], table_input: Dict[str, Any], table_type: Optional[str], table_exist: bool, partitions_types: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    mode = _update_if_necessary(dic=table_input, key='Description', value=description, mode=mode)\n    if 'Parameters' not in table_input:\n        table_input['Parameters'] = {}\n    parameters = parameters if parameters else {}\n    for (k, v) in parameters.items():\n        mode = _update_if_necessary(dic=table_input['Parameters'], key=k, value=v, mode=mode)\n    projection_params = athena_partition_projection_settings if athena_partition_projection_settings else {}\n    if athena_partition_projection_settings:\n        table_input['Parameters']['projection.enabled'] = 'true'\n        partitions_types = partitions_types if partitions_types else {}\n        projection_types = projection_params.get('projection_types', {})\n        projection_ranges = projection_params.get('projection_ranges', {})\n        projection_values = projection_params.get('projection_values', {})\n        projection_intervals = projection_params.get('projection_intervals', {})\n        projection_digits = projection_params.get('projection_digits', {})\n        projection_formats = projection_params.get('projection_formats', {})\n        projection_types = {sanitize_column_name(k): v for (k, v) in projection_types.items()}\n        projection_ranges = {sanitize_column_name(k): v for (k, v) in projection_ranges.items()}\n        projection_values = {sanitize_column_name(k): v for (k, v) in projection_values.items()}\n        projection_intervals = {sanitize_column_name(k): v for (k, v) in projection_intervals.items()}\n        projection_digits = {sanitize_column_name(k): v for (k, v) in projection_digits.items()}\n        projection_formats = {sanitize_column_name(k): v for (k, v) in projection_formats.items()}\n        projection_storage_location_template = projection_params.get('projection_storage_location_template')\n        for (k, v) in projection_types.items():\n            dtype: Optional[str] = partitions_types.get(k)\n            if dtype is None and projection_storage_location_template is None:\n                raise exceptions.InvalidArgumentCombination(f'Column {k} appears as projected column but not as partitioned column.')\n            if dtype == 'date':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd'\n            elif dtype == 'timestamp':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd HH:mm:ss'\n                table_input['Parameters'][f'projection.{k}.interval.unit'] = 'SECONDS'\n                table_input['Parameters'][f'projection.{k}.interval'] = '1'\n        for (k, v) in projection_types.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.type', value=v, mode=mode)\n        for (k, v) in projection_ranges.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.range', value=v, mode=mode)\n        for (k, v) in projection_values.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.values', value=v, mode=mode)\n        for (k, v) in projection_intervals.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.interval', value=str(v), mode=mode)\n        for (k, v) in projection_digits.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.digits', value=str(v), mode=mode)\n        for (k, v) in projection_formats.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.format', value=str(v), mode=mode)\n        mode = _update_if_necessary(table_input['Parameters'], key='storage.location.template', value=projection_storage_location_template, mode=mode)\n    else:\n        table_input['Parameters']['projection.enabled'] = 'false'\n    columns_comments = columns_comments if columns_comments else {}\n    columns_comments = {sanitize_column_name(k): v for (k, v) in columns_comments.items()}\n    if columns_comments:\n        for col in table_input['StorageDescriptor']['Columns']:\n            name: str = col['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=col, key='Comment', value=columns_comments[name], mode=mode)\n        for par in table_input['PartitionKeys']:\n            name = par['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=par, key='Comment', value=columns_comments[name], mode=mode)\n    _logger.debug('table_input: %s', table_input)\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    if mode not in ('overwrite', 'append', 'overwrite_partitions', 'update'):\n        raise exceptions.InvalidArgument(f\"{mode} is not a valid mode. It must be 'overwrite', 'append' or 'overwrite_partitions'.\")\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    if table_exist:\n        _logger.debug('Updating table (%s)...', mode)\n        args['SkipArchive'] = skip_archive\n        if mode == 'overwrite':\n            if table_type != 'GOVERNED':\n                delete_all_partitions(table=table, database=database, catalog_id=catalog_id, boto3_session=boto3_session)\n            client_glue.update_table(**args)\n        elif mode == 'update':\n            client_glue.update_table(**args)\n    else:\n        try:\n            _logger.debug('Creating table (%s)...', mode)\n            client_glue.create_table(**args)\n        except client_glue.exceptions.AlreadyExistsException:\n            if mode == 'overwrite':\n                _utils.try_it(f=_overwrite_table, ex=client_glue.exceptions.AlreadyExistsException, client_glue=client_glue, catalog_id=catalog_id, database=database, table=table, table_input=table_input, transaction_id=transaction_id, boto3_session=boto3_session)\n    _logger.debug('Leaving table as is (%s)...', mode)",
            "def _create_table(database: str, table: str, description: Optional[str], parameters: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, boto3_session: Optional[boto3.Session], table_input: Dict[str, Any], table_type: Optional[str], table_exist: bool, partitions_types: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    mode = _update_if_necessary(dic=table_input, key='Description', value=description, mode=mode)\n    if 'Parameters' not in table_input:\n        table_input['Parameters'] = {}\n    parameters = parameters if parameters else {}\n    for (k, v) in parameters.items():\n        mode = _update_if_necessary(dic=table_input['Parameters'], key=k, value=v, mode=mode)\n    projection_params = athena_partition_projection_settings if athena_partition_projection_settings else {}\n    if athena_partition_projection_settings:\n        table_input['Parameters']['projection.enabled'] = 'true'\n        partitions_types = partitions_types if partitions_types else {}\n        projection_types = projection_params.get('projection_types', {})\n        projection_ranges = projection_params.get('projection_ranges', {})\n        projection_values = projection_params.get('projection_values', {})\n        projection_intervals = projection_params.get('projection_intervals', {})\n        projection_digits = projection_params.get('projection_digits', {})\n        projection_formats = projection_params.get('projection_formats', {})\n        projection_types = {sanitize_column_name(k): v for (k, v) in projection_types.items()}\n        projection_ranges = {sanitize_column_name(k): v for (k, v) in projection_ranges.items()}\n        projection_values = {sanitize_column_name(k): v for (k, v) in projection_values.items()}\n        projection_intervals = {sanitize_column_name(k): v for (k, v) in projection_intervals.items()}\n        projection_digits = {sanitize_column_name(k): v for (k, v) in projection_digits.items()}\n        projection_formats = {sanitize_column_name(k): v for (k, v) in projection_formats.items()}\n        projection_storage_location_template = projection_params.get('projection_storage_location_template')\n        for (k, v) in projection_types.items():\n            dtype: Optional[str] = partitions_types.get(k)\n            if dtype is None and projection_storage_location_template is None:\n                raise exceptions.InvalidArgumentCombination(f'Column {k} appears as projected column but not as partitioned column.')\n            if dtype == 'date':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd'\n            elif dtype == 'timestamp':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd HH:mm:ss'\n                table_input['Parameters'][f'projection.{k}.interval.unit'] = 'SECONDS'\n                table_input['Parameters'][f'projection.{k}.interval'] = '1'\n        for (k, v) in projection_types.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.type', value=v, mode=mode)\n        for (k, v) in projection_ranges.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.range', value=v, mode=mode)\n        for (k, v) in projection_values.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.values', value=v, mode=mode)\n        for (k, v) in projection_intervals.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.interval', value=str(v), mode=mode)\n        for (k, v) in projection_digits.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.digits', value=str(v), mode=mode)\n        for (k, v) in projection_formats.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.format', value=str(v), mode=mode)\n        mode = _update_if_necessary(table_input['Parameters'], key='storage.location.template', value=projection_storage_location_template, mode=mode)\n    else:\n        table_input['Parameters']['projection.enabled'] = 'false'\n    columns_comments = columns_comments if columns_comments else {}\n    columns_comments = {sanitize_column_name(k): v for (k, v) in columns_comments.items()}\n    if columns_comments:\n        for col in table_input['StorageDescriptor']['Columns']:\n            name: str = col['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=col, key='Comment', value=columns_comments[name], mode=mode)\n        for par in table_input['PartitionKeys']:\n            name = par['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=par, key='Comment', value=columns_comments[name], mode=mode)\n    _logger.debug('table_input: %s', table_input)\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    if mode not in ('overwrite', 'append', 'overwrite_partitions', 'update'):\n        raise exceptions.InvalidArgument(f\"{mode} is not a valid mode. It must be 'overwrite', 'append' or 'overwrite_partitions'.\")\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    if table_exist:\n        _logger.debug('Updating table (%s)...', mode)\n        args['SkipArchive'] = skip_archive\n        if mode == 'overwrite':\n            if table_type != 'GOVERNED':\n                delete_all_partitions(table=table, database=database, catalog_id=catalog_id, boto3_session=boto3_session)\n            client_glue.update_table(**args)\n        elif mode == 'update':\n            client_glue.update_table(**args)\n    else:\n        try:\n            _logger.debug('Creating table (%s)...', mode)\n            client_glue.create_table(**args)\n        except client_glue.exceptions.AlreadyExistsException:\n            if mode == 'overwrite':\n                _utils.try_it(f=_overwrite_table, ex=client_glue.exceptions.AlreadyExistsException, client_glue=client_glue, catalog_id=catalog_id, database=database, table=table, table_input=table_input, transaction_id=transaction_id, boto3_session=boto3_session)\n    _logger.debug('Leaving table as is (%s)...', mode)",
            "def _create_table(database: str, table: str, description: Optional[str], parameters: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, boto3_session: Optional[boto3.Session], table_input: Dict[str, Any], table_type: Optional[str], table_exist: bool, partitions_types: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    mode = _update_if_necessary(dic=table_input, key='Description', value=description, mode=mode)\n    if 'Parameters' not in table_input:\n        table_input['Parameters'] = {}\n    parameters = parameters if parameters else {}\n    for (k, v) in parameters.items():\n        mode = _update_if_necessary(dic=table_input['Parameters'], key=k, value=v, mode=mode)\n    projection_params = athena_partition_projection_settings if athena_partition_projection_settings else {}\n    if athena_partition_projection_settings:\n        table_input['Parameters']['projection.enabled'] = 'true'\n        partitions_types = partitions_types if partitions_types else {}\n        projection_types = projection_params.get('projection_types', {})\n        projection_ranges = projection_params.get('projection_ranges', {})\n        projection_values = projection_params.get('projection_values', {})\n        projection_intervals = projection_params.get('projection_intervals', {})\n        projection_digits = projection_params.get('projection_digits', {})\n        projection_formats = projection_params.get('projection_formats', {})\n        projection_types = {sanitize_column_name(k): v for (k, v) in projection_types.items()}\n        projection_ranges = {sanitize_column_name(k): v for (k, v) in projection_ranges.items()}\n        projection_values = {sanitize_column_name(k): v for (k, v) in projection_values.items()}\n        projection_intervals = {sanitize_column_name(k): v for (k, v) in projection_intervals.items()}\n        projection_digits = {sanitize_column_name(k): v for (k, v) in projection_digits.items()}\n        projection_formats = {sanitize_column_name(k): v for (k, v) in projection_formats.items()}\n        projection_storage_location_template = projection_params.get('projection_storage_location_template')\n        for (k, v) in projection_types.items():\n            dtype: Optional[str] = partitions_types.get(k)\n            if dtype is None and projection_storage_location_template is None:\n                raise exceptions.InvalidArgumentCombination(f'Column {k} appears as projected column but not as partitioned column.')\n            if dtype == 'date':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd'\n            elif dtype == 'timestamp':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd HH:mm:ss'\n                table_input['Parameters'][f'projection.{k}.interval.unit'] = 'SECONDS'\n                table_input['Parameters'][f'projection.{k}.interval'] = '1'\n        for (k, v) in projection_types.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.type', value=v, mode=mode)\n        for (k, v) in projection_ranges.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.range', value=v, mode=mode)\n        for (k, v) in projection_values.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.values', value=v, mode=mode)\n        for (k, v) in projection_intervals.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.interval', value=str(v), mode=mode)\n        for (k, v) in projection_digits.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.digits', value=str(v), mode=mode)\n        for (k, v) in projection_formats.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.format', value=str(v), mode=mode)\n        mode = _update_if_necessary(table_input['Parameters'], key='storage.location.template', value=projection_storage_location_template, mode=mode)\n    else:\n        table_input['Parameters']['projection.enabled'] = 'false'\n    columns_comments = columns_comments if columns_comments else {}\n    columns_comments = {sanitize_column_name(k): v for (k, v) in columns_comments.items()}\n    if columns_comments:\n        for col in table_input['StorageDescriptor']['Columns']:\n            name: str = col['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=col, key='Comment', value=columns_comments[name], mode=mode)\n        for par in table_input['PartitionKeys']:\n            name = par['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=par, key='Comment', value=columns_comments[name], mode=mode)\n    _logger.debug('table_input: %s', table_input)\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    if mode not in ('overwrite', 'append', 'overwrite_partitions', 'update'):\n        raise exceptions.InvalidArgument(f\"{mode} is not a valid mode. It must be 'overwrite', 'append' or 'overwrite_partitions'.\")\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    if table_exist:\n        _logger.debug('Updating table (%s)...', mode)\n        args['SkipArchive'] = skip_archive\n        if mode == 'overwrite':\n            if table_type != 'GOVERNED':\n                delete_all_partitions(table=table, database=database, catalog_id=catalog_id, boto3_session=boto3_session)\n            client_glue.update_table(**args)\n        elif mode == 'update':\n            client_glue.update_table(**args)\n    else:\n        try:\n            _logger.debug('Creating table (%s)...', mode)\n            client_glue.create_table(**args)\n        except client_glue.exceptions.AlreadyExistsException:\n            if mode == 'overwrite':\n                _utils.try_it(f=_overwrite_table, ex=client_glue.exceptions.AlreadyExistsException, client_glue=client_glue, catalog_id=catalog_id, database=database, table=table, table_input=table_input, transaction_id=transaction_id, boto3_session=boto3_session)\n    _logger.debug('Leaving table as is (%s)...', mode)",
            "def _create_table(database: str, table: str, description: Optional[str], parameters: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, boto3_session: Optional[boto3.Session], table_input: Dict[str, Any], table_type: Optional[str], table_exist: bool, partitions_types: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    mode = _update_if_necessary(dic=table_input, key='Description', value=description, mode=mode)\n    if 'Parameters' not in table_input:\n        table_input['Parameters'] = {}\n    parameters = parameters if parameters else {}\n    for (k, v) in parameters.items():\n        mode = _update_if_necessary(dic=table_input['Parameters'], key=k, value=v, mode=mode)\n    projection_params = athena_partition_projection_settings if athena_partition_projection_settings else {}\n    if athena_partition_projection_settings:\n        table_input['Parameters']['projection.enabled'] = 'true'\n        partitions_types = partitions_types if partitions_types else {}\n        projection_types = projection_params.get('projection_types', {})\n        projection_ranges = projection_params.get('projection_ranges', {})\n        projection_values = projection_params.get('projection_values', {})\n        projection_intervals = projection_params.get('projection_intervals', {})\n        projection_digits = projection_params.get('projection_digits', {})\n        projection_formats = projection_params.get('projection_formats', {})\n        projection_types = {sanitize_column_name(k): v for (k, v) in projection_types.items()}\n        projection_ranges = {sanitize_column_name(k): v for (k, v) in projection_ranges.items()}\n        projection_values = {sanitize_column_name(k): v for (k, v) in projection_values.items()}\n        projection_intervals = {sanitize_column_name(k): v for (k, v) in projection_intervals.items()}\n        projection_digits = {sanitize_column_name(k): v for (k, v) in projection_digits.items()}\n        projection_formats = {sanitize_column_name(k): v for (k, v) in projection_formats.items()}\n        projection_storage_location_template = projection_params.get('projection_storage_location_template')\n        for (k, v) in projection_types.items():\n            dtype: Optional[str] = partitions_types.get(k)\n            if dtype is None and projection_storage_location_template is None:\n                raise exceptions.InvalidArgumentCombination(f'Column {k} appears as projected column but not as partitioned column.')\n            if dtype == 'date':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd'\n            elif dtype == 'timestamp':\n                table_input['Parameters'][f'projection.{k}.format'] = 'yyyy-MM-dd HH:mm:ss'\n                table_input['Parameters'][f'projection.{k}.interval.unit'] = 'SECONDS'\n                table_input['Parameters'][f'projection.{k}.interval'] = '1'\n        for (k, v) in projection_types.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.type', value=v, mode=mode)\n        for (k, v) in projection_ranges.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.range', value=v, mode=mode)\n        for (k, v) in projection_values.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.values', value=v, mode=mode)\n        for (k, v) in projection_intervals.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.interval', value=str(v), mode=mode)\n        for (k, v) in projection_digits.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.digits', value=str(v), mode=mode)\n        for (k, v) in projection_formats.items():\n            mode = _update_if_necessary(dic=table_input['Parameters'], key=f'projection.{k}.format', value=str(v), mode=mode)\n        mode = _update_if_necessary(table_input['Parameters'], key='storage.location.template', value=projection_storage_location_template, mode=mode)\n    else:\n        table_input['Parameters']['projection.enabled'] = 'false'\n    columns_comments = columns_comments if columns_comments else {}\n    columns_comments = {sanitize_column_name(k): v for (k, v) in columns_comments.items()}\n    if columns_comments:\n        for col in table_input['StorageDescriptor']['Columns']:\n            name: str = col['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=col, key='Comment', value=columns_comments[name], mode=mode)\n        for par in table_input['PartitionKeys']:\n            name = par['Name']\n            if name in columns_comments:\n                mode = _update_if_necessary(dic=par, key='Comment', value=columns_comments[name], mode=mode)\n    _logger.debug('table_input: %s', table_input)\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    if mode not in ('overwrite', 'append', 'overwrite_partitions', 'update'):\n        raise exceptions.InvalidArgument(f\"{mode} is not a valid mode. It must be 'overwrite', 'append' or 'overwrite_partitions'.\")\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    if table_exist:\n        _logger.debug('Updating table (%s)...', mode)\n        args['SkipArchive'] = skip_archive\n        if mode == 'overwrite':\n            if table_type != 'GOVERNED':\n                delete_all_partitions(table=table, database=database, catalog_id=catalog_id, boto3_session=boto3_session)\n            client_glue.update_table(**args)\n        elif mode == 'update':\n            client_glue.update_table(**args)\n    else:\n        try:\n            _logger.debug('Creating table (%s)...', mode)\n            client_glue.create_table(**args)\n        except client_glue.exceptions.AlreadyExistsException:\n            if mode == 'overwrite':\n                _utils.try_it(f=_overwrite_table, ex=client_glue.exceptions.AlreadyExistsException, client_glue=client_glue, catalog_id=catalog_id, database=database, table=table, table_input=table_input, transaction_id=transaction_id, boto3_session=boto3_session)\n    _logger.debug('Leaving table as is (%s)...', mode)"
        ]
    },
    {
        "func_name": "_overwrite_table",
        "original": "def _overwrite_table(client_glue: 'GlueClient', catalog_id: Optional[str], database: str, table: str, table_input: Dict[str, Any], transaction_id: Optional[str], boto3_session: boto3.Session) -> None:\n    delete_table_if_exists(database=database, table=table, transaction_id=transaction_id, boto3_session=boto3_session, catalog_id=catalog_id)\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    client_glue.create_table(**args)",
        "mutated": [
            "def _overwrite_table(client_glue: 'GlueClient', catalog_id: Optional[str], database: str, table: str, table_input: Dict[str, Any], transaction_id: Optional[str], boto3_session: boto3.Session) -> None:\n    if False:\n        i = 10\n    delete_table_if_exists(database=database, table=table, transaction_id=transaction_id, boto3_session=boto3_session, catalog_id=catalog_id)\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    client_glue.create_table(**args)",
            "def _overwrite_table(client_glue: 'GlueClient', catalog_id: Optional[str], database: str, table: str, table_input: Dict[str, Any], transaction_id: Optional[str], boto3_session: boto3.Session) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    delete_table_if_exists(database=database, table=table, transaction_id=transaction_id, boto3_session=boto3_session, catalog_id=catalog_id)\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    client_glue.create_table(**args)",
            "def _overwrite_table(client_glue: 'GlueClient', catalog_id: Optional[str], database: str, table: str, table_input: Dict[str, Any], transaction_id: Optional[str], boto3_session: boto3.Session) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    delete_table_if_exists(database=database, table=table, transaction_id=transaction_id, boto3_session=boto3_session, catalog_id=catalog_id)\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    client_glue.create_table(**args)",
            "def _overwrite_table(client_glue: 'GlueClient', catalog_id: Optional[str], database: str, table: str, table_input: Dict[str, Any], transaction_id: Optional[str], boto3_session: boto3.Session) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    delete_table_if_exists(database=database, table=table, transaction_id=transaction_id, boto3_session=boto3_session, catalog_id=catalog_id)\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    client_glue.create_table(**args)",
            "def _overwrite_table(client_glue: 'GlueClient', catalog_id: Optional[str], database: str, table: str, table_input: Dict[str, Any], transaction_id: Optional[str], boto3_session: boto3.Session) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    delete_table_if_exists(database=database, table=table, transaction_id=transaction_id, boto3_session=boto3_session, catalog_id=catalog_id)\n    args: Dict[str, Any] = _catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input))\n    client_glue.create_table(**args)"
        ]
    },
    {
        "func_name": "_upsert_table_parameters",
        "original": "def _upsert_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    pars: Dict[str, str] = table_input['Parameters']\n    update: bool = False\n    for (k, v) in parameters.items():\n        if k not in pars or v != pars[k]:\n            pars[k] = v\n            update = True\n    if update is True:\n        _overwrite_table_parameters(parameters=pars, database=database, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session, table_input=table_input, catalog_versioning=catalog_versioning)\n    return pars",
        "mutated": [
            "def _upsert_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n    pars: Dict[str, str] = table_input['Parameters']\n    update: bool = False\n    for (k, v) in parameters.items():\n        if k not in pars or v != pars[k]:\n            pars[k] = v\n            update = True\n    if update is True:\n        _overwrite_table_parameters(parameters=pars, database=database, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session, table_input=table_input, catalog_versioning=catalog_versioning)\n    return pars",
            "def _upsert_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pars: Dict[str, str] = table_input['Parameters']\n    update: bool = False\n    for (k, v) in parameters.items():\n        if k not in pars or v != pars[k]:\n            pars[k] = v\n            update = True\n    if update is True:\n        _overwrite_table_parameters(parameters=pars, database=database, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session, table_input=table_input, catalog_versioning=catalog_versioning)\n    return pars",
            "def _upsert_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pars: Dict[str, str] = table_input['Parameters']\n    update: bool = False\n    for (k, v) in parameters.items():\n        if k not in pars or v != pars[k]:\n            pars[k] = v\n            update = True\n    if update is True:\n        _overwrite_table_parameters(parameters=pars, database=database, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session, table_input=table_input, catalog_versioning=catalog_versioning)\n    return pars",
            "def _upsert_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pars: Dict[str, str] = table_input['Parameters']\n    update: bool = False\n    for (k, v) in parameters.items():\n        if k not in pars or v != pars[k]:\n            pars[k] = v\n            update = True\n    if update is True:\n        _overwrite_table_parameters(parameters=pars, database=database, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session, table_input=table_input, catalog_versioning=catalog_versioning)\n    return pars",
            "def _upsert_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pars: Dict[str, str] = table_input['Parameters']\n    update: bool = False\n    for (k, v) in parameters.items():\n        if k not in pars or v != pars[k]:\n            pars[k] = v\n            update = True\n    if update is True:\n        _overwrite_table_parameters(parameters=pars, database=database, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session, table_input=table_input, catalog_versioning=catalog_versioning)\n    return pars"
        ]
    },
    {
        "func_name": "_overwrite_table_parameters",
        "original": "def _overwrite_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    table_input['Parameters'] = parameters\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    client_glue.update_table(**_catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input, SkipArchive=skip_archive)))\n    return parameters",
        "mutated": [
            "def _overwrite_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n    table_input['Parameters'] = parameters\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    client_glue.update_table(**_catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input, SkipArchive=skip_archive)))\n    return parameters",
            "def _overwrite_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    table_input['Parameters'] = parameters\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    client_glue.update_table(**_catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input, SkipArchive=skip_archive)))\n    return parameters",
            "def _overwrite_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    table_input['Parameters'] = parameters\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    client_glue.update_table(**_catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input, SkipArchive=skip_archive)))\n    return parameters",
            "def _overwrite_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    table_input['Parameters'] = parameters\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    client_glue.update_table(**_catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input, SkipArchive=skip_archive)))\n    return parameters",
            "def _overwrite_table_parameters(parameters: Dict[str, str], database: str, transaction_id: Optional[str], catalog_versioning: bool, catalog_id: Optional[str], table_input: Dict[str, Any], boto3_session: Optional[boto3.Session]) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    table_input['Parameters'] = parameters\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    skip_archive: bool = not catalog_versioning\n    client_glue.update_table(**_catalog_id(catalog_id=catalog_id, **_transaction_id(transaction_id=transaction_id, DatabaseName=database, TableInput=table_input, SkipArchive=skip_archive)))\n    return parameters"
        ]
    },
    {
        "func_name": "_update_table_input",
        "original": "def _update_table_input(table_input: Dict[str, Any], columns_types: Dict[str, str], allow_reorder: bool=True) -> bool:\n    column_updated = False\n    catalog_cols: Dict[str, str] = {x['Name']: x['Type'] for x in table_input['StorageDescriptor']['Columns']}\n    if not allow_reorder:\n        for (catalog_key, frame_key) in zip(catalog_cols, columns_types):\n            if catalog_key != frame_key:\n                raise exceptions.InvalidArgumentValue(f'Column {frame_key} is out of order.')\n    for (c, t) in columns_types.items():\n        if c not in catalog_cols:\n            _logger.debug('New column %s with type %s.', c, t)\n            table_input['StorageDescriptor']['Columns'].append({'Name': c, 'Type': t})\n            column_updated = True\n        elif t != catalog_cols[c]:\n            raise exceptions.InvalidArgumentValue(f'Data type change detected on column {c} (Old type: {catalog_cols[c]} / New type {t}).')\n    return column_updated",
        "mutated": [
            "def _update_table_input(table_input: Dict[str, Any], columns_types: Dict[str, str], allow_reorder: bool=True) -> bool:\n    if False:\n        i = 10\n    column_updated = False\n    catalog_cols: Dict[str, str] = {x['Name']: x['Type'] for x in table_input['StorageDescriptor']['Columns']}\n    if not allow_reorder:\n        for (catalog_key, frame_key) in zip(catalog_cols, columns_types):\n            if catalog_key != frame_key:\n                raise exceptions.InvalidArgumentValue(f'Column {frame_key} is out of order.')\n    for (c, t) in columns_types.items():\n        if c not in catalog_cols:\n            _logger.debug('New column %s with type %s.', c, t)\n            table_input['StorageDescriptor']['Columns'].append({'Name': c, 'Type': t})\n            column_updated = True\n        elif t != catalog_cols[c]:\n            raise exceptions.InvalidArgumentValue(f'Data type change detected on column {c} (Old type: {catalog_cols[c]} / New type {t}).')\n    return column_updated",
            "def _update_table_input(table_input: Dict[str, Any], columns_types: Dict[str, str], allow_reorder: bool=True) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    column_updated = False\n    catalog_cols: Dict[str, str] = {x['Name']: x['Type'] for x in table_input['StorageDescriptor']['Columns']}\n    if not allow_reorder:\n        for (catalog_key, frame_key) in zip(catalog_cols, columns_types):\n            if catalog_key != frame_key:\n                raise exceptions.InvalidArgumentValue(f'Column {frame_key} is out of order.')\n    for (c, t) in columns_types.items():\n        if c not in catalog_cols:\n            _logger.debug('New column %s with type %s.', c, t)\n            table_input['StorageDescriptor']['Columns'].append({'Name': c, 'Type': t})\n            column_updated = True\n        elif t != catalog_cols[c]:\n            raise exceptions.InvalidArgumentValue(f'Data type change detected on column {c} (Old type: {catalog_cols[c]} / New type {t}).')\n    return column_updated",
            "def _update_table_input(table_input: Dict[str, Any], columns_types: Dict[str, str], allow_reorder: bool=True) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    column_updated = False\n    catalog_cols: Dict[str, str] = {x['Name']: x['Type'] for x in table_input['StorageDescriptor']['Columns']}\n    if not allow_reorder:\n        for (catalog_key, frame_key) in zip(catalog_cols, columns_types):\n            if catalog_key != frame_key:\n                raise exceptions.InvalidArgumentValue(f'Column {frame_key} is out of order.')\n    for (c, t) in columns_types.items():\n        if c not in catalog_cols:\n            _logger.debug('New column %s with type %s.', c, t)\n            table_input['StorageDescriptor']['Columns'].append({'Name': c, 'Type': t})\n            column_updated = True\n        elif t != catalog_cols[c]:\n            raise exceptions.InvalidArgumentValue(f'Data type change detected on column {c} (Old type: {catalog_cols[c]} / New type {t}).')\n    return column_updated",
            "def _update_table_input(table_input: Dict[str, Any], columns_types: Dict[str, str], allow_reorder: bool=True) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    column_updated = False\n    catalog_cols: Dict[str, str] = {x['Name']: x['Type'] for x in table_input['StorageDescriptor']['Columns']}\n    if not allow_reorder:\n        for (catalog_key, frame_key) in zip(catalog_cols, columns_types):\n            if catalog_key != frame_key:\n                raise exceptions.InvalidArgumentValue(f'Column {frame_key} is out of order.')\n    for (c, t) in columns_types.items():\n        if c not in catalog_cols:\n            _logger.debug('New column %s with type %s.', c, t)\n            table_input['StorageDescriptor']['Columns'].append({'Name': c, 'Type': t})\n            column_updated = True\n        elif t != catalog_cols[c]:\n            raise exceptions.InvalidArgumentValue(f'Data type change detected on column {c} (Old type: {catalog_cols[c]} / New type {t}).')\n    return column_updated",
            "def _update_table_input(table_input: Dict[str, Any], columns_types: Dict[str, str], allow_reorder: bool=True) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    column_updated = False\n    catalog_cols: Dict[str, str] = {x['Name']: x['Type'] for x in table_input['StorageDescriptor']['Columns']}\n    if not allow_reorder:\n        for (catalog_key, frame_key) in zip(catalog_cols, columns_types):\n            if catalog_key != frame_key:\n                raise exceptions.InvalidArgumentValue(f'Column {frame_key} is out of order.')\n    for (c, t) in columns_types.items():\n        if c not in catalog_cols:\n            _logger.debug('New column %s with type %s.', c, t)\n            table_input['StorageDescriptor']['Columns'].append({'Name': c, 'Type': t})\n            column_updated = True\n        elif t != catalog_cols[c]:\n            raise exceptions.InvalidArgumentValue(f'Data type change detected on column {c} (Old type: {catalog_cols[c]} / New type {t}).')\n    return column_updated"
        ]
    },
    {
        "func_name": "_create_parquet_table",
        "original": "def _create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _parquet_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
        "mutated": [
            "def _create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _parquet_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _parquet_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _parquet_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _parquet_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _parquet_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)"
        ]
    },
    {
        "func_name": "_create_orc_table",
        "original": "def _create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _orc_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
        "mutated": [
            "def _create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _orc_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _orc_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _orc_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _orc_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], catalog_id: Optional[str], compression: Optional[str], description: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, transaction_id: Optional[str], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], boto3_session: Optional[boto3.Session], catalog_table_input: Optional[Dict[str, Any]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _orc_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)"
        ]
    },
    {
        "func_name": "_create_csv_table",
        "original": "def _create_csv_table(database: str, table: str, path: Optional[str], columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, transaction_id: Optional[str], catalog_versioning: bool, schema_evolution: bool, sep: str, skip_header_line_count: Optional[int], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types, allow_reorder=False)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _csv_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
        "mutated": [
            "def _create_csv_table(database: str, table: str, path: Optional[str], columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, transaction_id: Optional[str], catalog_versioning: bool, schema_evolution: bool, sep: str, skip_header_line_count: Optional[int], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types, allow_reorder=False)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _csv_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_csv_table(database: str, table: str, path: Optional[str], columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, transaction_id: Optional[str], catalog_versioning: bool, schema_evolution: bool, sep: str, skip_header_line_count: Optional[int], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types, allow_reorder=False)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _csv_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_csv_table(database: str, table: str, path: Optional[str], columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, transaction_id: Optional[str], catalog_versioning: bool, schema_evolution: bool, sep: str, skip_header_line_count: Optional[int], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types, allow_reorder=False)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _csv_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_csv_table(database: str, table: str, path: Optional[str], columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, transaction_id: Optional[str], catalog_versioning: bool, schema_evolution: bool, sep: str, skip_header_line_count: Optional[int], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types, allow_reorder=False)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _csv_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_csv_table(database: str, table: str, path: Optional[str], columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, transaction_id: Optional[str], catalog_versioning: bool, schema_evolution: bool, sep: str, skip_header_line_count: Optional[int], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    table_input: Dict[str, Any]\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types, allow_reorder=False)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _csv_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)"
        ]
    },
    {
        "func_name": "_create_json_table",
        "original": "def _create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, schema_evolution: bool, transaction_id: Optional[str], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _json_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
        "mutated": [
            "def _create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, schema_evolution: bool, transaction_id: Optional[str], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _json_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, schema_evolution: bool, transaction_id: Optional[str], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _json_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, schema_evolution: bool, transaction_id: Optional[str], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _json_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, schema_evolution: bool, transaction_id: Optional[str], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _json_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)",
            "def _create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str], partitions_types: Optional[Dict[str, str]], bucketing_info: Optional[typing.BucketingInfoTuple], description: Optional[str], compression: Optional[str], parameters: Optional[Dict[str, str]], columns_comments: Optional[Dict[str, str]], mode: str, catalog_versioning: bool, schema_evolution: bool, transaction_id: Optional[str], serde_library: Optional[str], serde_parameters: Optional[Dict[str, str]], boto3_session: Optional[boto3.Session], athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings], catalog_table_input: Optional[Dict[str, Any]], catalog_id: Optional[str]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    table = sanitize_table_name(table=table)\n    columns_types = {sanitize_column_name(k): v for (k, v) in columns_types.items()}\n    partitions_types = {} if partitions_types is None else partitions_types\n    _logger.debug('catalog_table_input: %s', catalog_table_input)\n    table_input: Dict[str, Any]\n    if schema_evolution is False:\n        _utils.check_schema_changes(columns_types=columns_types, table_input=catalog_table_input, mode=mode)\n    if catalog_table_input is not None and mode in ('append', 'overwrite_partitions'):\n        table_input = catalog_table_input\n        is_table_updated = _update_table_input(table_input, columns_types)\n        if is_table_updated:\n            mode = 'update'\n    else:\n        table_input = _json_table_definition(table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, compression=compression, serde_library=serde_library, serde_parameters=serde_parameters)\n    table_exist: bool = catalog_table_input is not None\n    _logger.debug('table_exist: %s', table_exist)\n    _create_table(database=database, table=table, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, boto3_session=boto3_session, table_input=table_input, table_type=table_type, table_exist=table_exist, partitions_types=partitions_types, athena_partition_projection_settings=athena_partition_projection_settings, catalog_id=catalog_id)"
        ]
    },
    {
        "func_name": "upsert_table_parameters",
        "original": "@apply_configs\ndef upsert_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    \"\"\"Insert or Update the received parameters.\n\n    Parameters\n    ----------\n    parameters : Dict[str, str]\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\n    database : str\n        Database name.\n    table : str\n        Table name.\n    transaction_id: str, optional\n        The ID of the transaction (i.e. used with GOVERNED tables).\n    catalog_versioning : bool\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    Dict[str, str]\n       All parameters after the upsert.\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> pars = wr.catalog.upsert_table_parameters(\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\n    ...     database=\"...\",\n    ...     table=\"...\")\n\n    \"\"\"\n    table_input: Optional[Dict[str, str]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    if table_input is None:\n        raise exceptions.InvalidArgumentValue(f'Table {database}.{table} does not exist.')\n    return _upsert_table_parameters(parameters=parameters, database=database, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id, table_input=table_input, catalog_versioning=catalog_versioning)",
        "mutated": [
            "@apply_configs\ndef upsert_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n    'Insert or Update the received parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the upsert.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.upsert_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, str]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    if table_input is None:\n        raise exceptions.InvalidArgumentValue(f'Table {database}.{table} does not exist.')\n    return _upsert_table_parameters(parameters=parameters, database=database, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id, table_input=table_input, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef upsert_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Insert or Update the received parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the upsert.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.upsert_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, str]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    if table_input is None:\n        raise exceptions.InvalidArgumentValue(f'Table {database}.{table} does not exist.')\n    return _upsert_table_parameters(parameters=parameters, database=database, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id, table_input=table_input, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef upsert_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Insert or Update the received parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the upsert.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.upsert_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, str]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    if table_input is None:\n        raise exceptions.InvalidArgumentValue(f'Table {database}.{table} does not exist.')\n    return _upsert_table_parameters(parameters=parameters, database=database, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id, table_input=table_input, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef upsert_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Insert or Update the received parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the upsert.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.upsert_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, str]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    if table_input is None:\n        raise exceptions.InvalidArgumentValue(f'Table {database}.{table} does not exist.')\n    return _upsert_table_parameters(parameters=parameters, database=database, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id, table_input=table_input, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef upsert_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Insert or Update the received parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the upsert.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.upsert_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, str]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    if table_input is None:\n        raise exceptions.InvalidArgumentValue(f'Table {database}.{table} does not exist.')\n    return _upsert_table_parameters(parameters=parameters, database=database, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id, table_input=table_input, catalog_versioning=catalog_versioning)"
        ]
    },
    {
        "func_name": "overwrite_table_parameters",
        "original": "@apply_configs\ndef overwrite_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    \"\"\"Overwrite all existing parameters.\n\n    Parameters\n    ----------\n    parameters : Dict[str, str]\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\n    database : str\n        Database name.\n    table : str\n        Table name.\n    transaction_id: str, optional\n        The ID of the transaction (i.e. used with GOVERNED tables).\n    catalog_versioning : bool\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    Dict[str, str]\n       All parameters after the overwrite (The same received).\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> pars = wr.catalog.overwrite_table_parameters(\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\n    ...     database=\"...\",\n    ...     table=\"...\")\n\n    \"\"\"\n    table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session)\n    if table_input is None:\n        raise exceptions.InvalidTable(f'Table {table} does not exist on database {database}.')\n    return _overwrite_table_parameters(parameters=parameters, database=database, catalog_id=catalog_id, transaction_id=transaction_id, table_input=table_input, boto3_session=boto3_session, catalog_versioning=catalog_versioning)",
        "mutated": [
            "@apply_configs\ndef overwrite_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n    'Overwrite all existing parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the overwrite (The same received).\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.overwrite_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session)\n    if table_input is None:\n        raise exceptions.InvalidTable(f'Table {table} does not exist on database {database}.')\n    return _overwrite_table_parameters(parameters=parameters, database=database, catalog_id=catalog_id, transaction_id=transaction_id, table_input=table_input, boto3_session=boto3_session, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef overwrite_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Overwrite all existing parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the overwrite (The same received).\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.overwrite_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session)\n    if table_input is None:\n        raise exceptions.InvalidTable(f'Table {table} does not exist on database {database}.')\n    return _overwrite_table_parameters(parameters=parameters, database=database, catalog_id=catalog_id, transaction_id=transaction_id, table_input=table_input, boto3_session=boto3_session, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef overwrite_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Overwrite all existing parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the overwrite (The same received).\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.overwrite_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session)\n    if table_input is None:\n        raise exceptions.InvalidTable(f'Table {table} does not exist on database {database}.')\n    return _overwrite_table_parameters(parameters=parameters, database=database, catalog_id=catalog_id, transaction_id=transaction_id, table_input=table_input, boto3_session=boto3_session, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef overwrite_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Overwrite all existing parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the overwrite (The same received).\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.overwrite_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session)\n    if table_input is None:\n        raise exceptions.InvalidTable(f'Table {table} does not exist on database {database}.')\n    return _overwrite_table_parameters(parameters=parameters, database=database, catalog_id=catalog_id, transaction_id=transaction_id, table_input=table_input, boto3_session=boto3_session, catalog_versioning=catalog_versioning)",
            "@apply_configs\ndef overwrite_table_parameters(parameters: Dict[str, str], database: str, table: str, transaction_id: Optional[str]=None, catalog_versioning: bool=False, catalog_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None) -> Dict[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Overwrite all existing parameters.\\n\\n    Parameters\\n    ----------\\n    parameters : Dict[str, str]\\n        e.g. {\"source\": \"mysql\", \"destination\":  \"datalake\"}\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    Dict[str, str]\\n       All parameters after the overwrite (The same received).\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> pars = wr.catalog.overwrite_table_parameters(\\n    ...     parameters={\"source\": \"mysql\", \"destination\":  \"datalake\"},\\n    ...     database=\"...\",\\n    ...     table=\"...\")\\n\\n    '\n    table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, transaction_id=transaction_id, catalog_id=catalog_id, boto3_session=boto3_session)\n    if table_input is None:\n        raise exceptions.InvalidTable(f'Table {table} does not exist on database {database}.')\n    return _overwrite_table_parameters(parameters=parameters, database=database, catalog_id=catalog_id, transaction_id=transaction_id, table_input=table_input, boto3_session=boto3_session, catalog_versioning=catalog_versioning)"
        ]
    },
    {
        "func_name": "create_database",
        "original": "@apply_configs\ndef create_database(name: str, description: Optional[str]=None, catalog_id: Optional[str]=None, exist_ok: bool=False, database_input_args: Optional[Dict[str, Any]]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    \"\"\"Create a database in AWS Glue Catalog.\n\n    Parameters\n    ----------\n    name : str\n        Database name.\n    description : str, optional\n        A description for the Database.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n    exist_ok : bool\n        If set to True will not raise an Exception if a Database with the same already exists.\n        In this case the description will be updated if it is different from the current one.\n    database_input_args : dict[str, Any], optional\n        Additional metadata to pass to database creation. Supported arguments listed here:\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    None\n        None.\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> wr.catalog.create_database(\n    ...     name='awswrangler_test'\n    ... )\n    \"\"\"\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    args: Dict[str, Any] = {'Name': name, **database_input_args} if database_input_args else {'Name': name}\n    if description is not None:\n        args['Description'] = description\n    try:\n        r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n        if not exist_ok:\n            raise exceptions.AlreadyExists(f'Database {name} already exists and <exist_ok> is set to False.')\n        for (k, v) in args.items():\n            if v != r['Database'].get(k, ''):\n                client_glue.update_database(**_catalog_id(catalog_id=catalog_id, Name=name, DatabaseInput=args))\n                break\n    except client_glue.exceptions.EntityNotFoundException:\n        client_glue.create_database(**_catalog_id(catalog_id=catalog_id, DatabaseInput=args))",
        "mutated": [
            "@apply_configs\ndef create_database(name: str, description: Optional[str]=None, catalog_id: Optional[str]=None, exist_ok: bool=False, database_input_args: Optional[Dict[str, Any]]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n    \"Create a database in AWS Glue Catalog.\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Database name.\\n    description : str, optional\\n        A description for the Database.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    exist_ok : bool\\n        If set to True will not raise an Exception if a Database with the same already exists.\\n        In this case the description will be updated if it is different from the current one.\\n    database_input_args : dict[str, Any], optional\\n        Additional metadata to pass to database creation. Supported arguments listed here:\\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_database(\\n    ...     name='awswrangler_test'\\n    ... )\\n    \"\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    args: Dict[str, Any] = {'Name': name, **database_input_args} if database_input_args else {'Name': name}\n    if description is not None:\n        args['Description'] = description\n    try:\n        r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n        if not exist_ok:\n            raise exceptions.AlreadyExists(f'Database {name} already exists and <exist_ok> is set to False.')\n        for (k, v) in args.items():\n            if v != r['Database'].get(k, ''):\n                client_glue.update_database(**_catalog_id(catalog_id=catalog_id, Name=name, DatabaseInput=args))\n                break\n    except client_glue.exceptions.EntityNotFoundException:\n        client_glue.create_database(**_catalog_id(catalog_id=catalog_id, DatabaseInput=args))",
            "@apply_configs\ndef create_database(name: str, description: Optional[str]=None, catalog_id: Optional[str]=None, exist_ok: bool=False, database_input_args: Optional[Dict[str, Any]]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Create a database in AWS Glue Catalog.\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Database name.\\n    description : str, optional\\n        A description for the Database.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    exist_ok : bool\\n        If set to True will not raise an Exception if a Database with the same already exists.\\n        In this case the description will be updated if it is different from the current one.\\n    database_input_args : dict[str, Any], optional\\n        Additional metadata to pass to database creation. Supported arguments listed here:\\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_database(\\n    ...     name='awswrangler_test'\\n    ... )\\n    \"\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    args: Dict[str, Any] = {'Name': name, **database_input_args} if database_input_args else {'Name': name}\n    if description is not None:\n        args['Description'] = description\n    try:\n        r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n        if not exist_ok:\n            raise exceptions.AlreadyExists(f'Database {name} already exists and <exist_ok> is set to False.')\n        for (k, v) in args.items():\n            if v != r['Database'].get(k, ''):\n                client_glue.update_database(**_catalog_id(catalog_id=catalog_id, Name=name, DatabaseInput=args))\n                break\n    except client_glue.exceptions.EntityNotFoundException:\n        client_glue.create_database(**_catalog_id(catalog_id=catalog_id, DatabaseInput=args))",
            "@apply_configs\ndef create_database(name: str, description: Optional[str]=None, catalog_id: Optional[str]=None, exist_ok: bool=False, database_input_args: Optional[Dict[str, Any]]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Create a database in AWS Glue Catalog.\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Database name.\\n    description : str, optional\\n        A description for the Database.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    exist_ok : bool\\n        If set to True will not raise an Exception if a Database with the same already exists.\\n        In this case the description will be updated if it is different from the current one.\\n    database_input_args : dict[str, Any], optional\\n        Additional metadata to pass to database creation. Supported arguments listed here:\\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_database(\\n    ...     name='awswrangler_test'\\n    ... )\\n    \"\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    args: Dict[str, Any] = {'Name': name, **database_input_args} if database_input_args else {'Name': name}\n    if description is not None:\n        args['Description'] = description\n    try:\n        r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n        if not exist_ok:\n            raise exceptions.AlreadyExists(f'Database {name} already exists and <exist_ok> is set to False.')\n        for (k, v) in args.items():\n            if v != r['Database'].get(k, ''):\n                client_glue.update_database(**_catalog_id(catalog_id=catalog_id, Name=name, DatabaseInput=args))\n                break\n    except client_glue.exceptions.EntityNotFoundException:\n        client_glue.create_database(**_catalog_id(catalog_id=catalog_id, DatabaseInput=args))",
            "@apply_configs\ndef create_database(name: str, description: Optional[str]=None, catalog_id: Optional[str]=None, exist_ok: bool=False, database_input_args: Optional[Dict[str, Any]]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Create a database in AWS Glue Catalog.\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Database name.\\n    description : str, optional\\n        A description for the Database.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    exist_ok : bool\\n        If set to True will not raise an Exception if a Database with the same already exists.\\n        In this case the description will be updated if it is different from the current one.\\n    database_input_args : dict[str, Any], optional\\n        Additional metadata to pass to database creation. Supported arguments listed here:\\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_database(\\n    ...     name='awswrangler_test'\\n    ... )\\n    \"\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    args: Dict[str, Any] = {'Name': name, **database_input_args} if database_input_args else {'Name': name}\n    if description is not None:\n        args['Description'] = description\n    try:\n        r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n        if not exist_ok:\n            raise exceptions.AlreadyExists(f'Database {name} already exists and <exist_ok> is set to False.')\n        for (k, v) in args.items():\n            if v != r['Database'].get(k, ''):\n                client_glue.update_database(**_catalog_id(catalog_id=catalog_id, Name=name, DatabaseInput=args))\n                break\n    except client_glue.exceptions.EntityNotFoundException:\n        client_glue.create_database(**_catalog_id(catalog_id=catalog_id, DatabaseInput=args))",
            "@apply_configs\ndef create_database(name: str, description: Optional[str]=None, catalog_id: Optional[str]=None, exist_ok: bool=False, database_input_args: Optional[Dict[str, Any]]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Create a database in AWS Glue Catalog.\\n\\n    Parameters\\n    ----------\\n    name : str\\n        Database name.\\n    description : str, optional\\n        A description for the Database.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    exist_ok : bool\\n        If set to True will not raise an Exception if a Database with the same already exists.\\n        In this case the description will be updated if it is different from the current one.\\n    database_input_args : dict[str, Any], optional\\n        Additional metadata to pass to database creation. Supported arguments listed here:\\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_database(\\n    ...     name='awswrangler_test'\\n    ... )\\n    \"\n    client_glue = _utils.client(service_name='glue', session=boto3_session)\n    args: Dict[str, Any] = {'Name': name, **database_input_args} if database_input_args else {'Name': name}\n    if description is not None:\n        args['Description'] = description\n    try:\n        r = client_glue.get_database(**_catalog_id(catalog_id=catalog_id, Name=name))\n        if not exist_ok:\n            raise exceptions.AlreadyExists(f'Database {name} already exists and <exist_ok> is set to False.')\n        for (k, v) in args.items():\n            if v != r['Database'].get(k, ''):\n                client_glue.update_database(**_catalog_id(catalog_id=catalog_id, Name=name, DatabaseInput=args))\n                break\n    except client_glue.exceptions.EntityNotFoundException:\n        client_glue.create_database(**_catalog_id(catalog_id=catalog_id, DatabaseInput=args))"
        ]
    },
    {
        "func_name": "create_parquet_table",
        "original": "@apply_configs\ndef create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    \"\"\"Create a Parquet Table (Metadata Only) in the AWS Glue Catalog.\n\n    'https://docs.aws.amazon.com/athena/latest/ug/data-types.html'\n\n    Parameters\n    ----------\n    database : str\n        Database name.\n    table : str\n        Table name.\n    path : str\n        Amazon S3 path (e.g. s3://bucket/prefix/).\n    columns_types: Dict[str, str]\n        Dictionary with keys as column names and values as data types (e.g. {'col0': 'bigint', 'col1': 'double'}).\n    table_type: str, optional\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\n    partitions_types: Dict[str, str], optional\n        Dictionary with keys as partition names and values as data types (e.g. {'col2': 'date'}).\n    bucketing_info: Tuple[List[str], int], optional\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\n        second element.\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n    compression: str, optional\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\n    description: str, optional\n        Table description\n    parameters: Dict[str, str], optional\n        Key/value pairs to tag the table.\n    columns_comments: Dict[str, str], optional\n        Columns names and the related comments (e.g. {'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}).\n    mode: str\n        'overwrite' to recreate any possible existing table or 'append' to keep any possible existing table.\n    catalog_versioning : bool\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\n    transaction_id: str, optional\n        The ID of the transaction (i.e. used with GOVERNED tables).\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\n\n        Following projection parameters are supported:\n\n        .. list-table:: Projection Parameters\n           :header-rows: 1\n\n           * - Name\n             - Type\n             - Description\n           * - projection_types\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections types.\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'enum', 'col2_name': 'integer'})\n           * - projection_ranges\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections ranges.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '0,10', 'col2_name': '-1,8675309'})\n           * - projection_values\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections values.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'A,B,Unknown', 'col2_name': 'foo,boo,bar'})\n           * - projection_intervals\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections intervals.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '5'})\n           * - projection_digits\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections digits.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '2'})\n           * - projection_formats\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections formats.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_date': 'yyyy-MM-dd', 'col2_timestamp': 'yyyy-MM-dd HH:mm:ss'})\n           * - projection_storage_location_template\n             - Optional[str]\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\n               a typical `.../column=value/...` pattern.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    None\n        None.\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> wr.catalog.create_parquet_table(\n    ...     database='default',\n    ...     table='my_table',\n    ...     path='s3://bucket/prefix/',\n    ...     columns_types={'col0': 'bigint', 'col1': 'double'},\n    ...     partitions_types={'col2': 'date'},\n    ...     compression='snappy',\n    ...     description='My own table!',\n    ...     parameters={'source': 'postgresql'},\n    ...     columns_comments={'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}\n    ... )\n\n    \"\"\"\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_parquet_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
        "mutated": [
            "@apply_configs\ndef create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n    'Create a Parquet Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_parquet_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create a Parquet Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_parquet_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create a Parquet Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_parquet_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create a Parquet Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_parquet_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_parquet_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create a Parquet Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_parquet_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)"
        ]
    },
    {
        "func_name": "create_orc_table",
        "original": "@apply_configs\ndef create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    \"\"\"Create a ORC Table (Metadata Only) in the AWS Glue Catalog.\n\n    'https://docs.aws.amazon.com/athena/latest/ug/data-types.html'\n\n    Parameters\n    ----------\n    database : str\n        Database name.\n    table : str\n        Table name.\n    path : str\n        Amazon S3 path (e.g. s3://bucket/prefix/).\n    columns_types: Dict[str, str]\n        Dictionary with keys as column names and values as data types (e.g. {'col0': 'bigint', 'col1': 'double'}).\n    table_type: str, optional\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\n    partitions_types: Dict[str, str], optional\n        Dictionary with keys as partition names and values as data types (e.g. {'col2': 'date'}).\n    bucketing_info: Tuple[List[str], int], optional\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\n        second element.\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n    compression: str, optional\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\n    description: str, optional\n        Table description\n    parameters: Dict[str, str], optional\n        Key/value pairs to tag the table.\n    columns_comments: Dict[str, str], optional\n        Columns names and the related comments (e.g. {'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}).\n    mode: str\n        'overwrite' to recreate any possible existing table or 'append' to keep any possible existing table.\n    catalog_versioning : bool\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\n    transaction_id: str, optional\n        The ID of the transaction (i.e. used with GOVERNED tables).\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\n\n        Following projection parameters are supported:\n\n        .. list-table:: Projection Parameters\n           :header-rows: 1\n\n           * - Name\n             - Type\n             - Description\n           * - projection_types\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections types.\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'enum', 'col2_name': 'integer'})\n           * - projection_ranges\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections ranges.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '0,10', 'col2_name': '-1,8675309'})\n           * - projection_values\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections values.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'A,B,Unknown', 'col2_name': 'foo,boo,bar'})\n           * - projection_intervals\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections intervals.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '5'})\n           * - projection_digits\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections digits.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '2'})\n           * - projection_formats\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections formats.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_date': 'yyyy-MM-dd', 'col2_timestamp': 'yyyy-MM-dd HH:mm:ss'})\n           * - projection_storage_location_template\n             - Optional[str]\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\n               a typical `.../column=value/...` pattern.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n\n    Returns\n    -------\n    None\n        None.\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> wr.catalog.create_parquet_table(\n    ...     database='default',\n    ...     table='my_table',\n    ...     path='s3://bucket/prefix/',\n    ...     columns_types={'col0': 'bigint', 'col1': 'double'},\n    ...     partitions_types={'col2': 'date'},\n    ...     compression='snappy',\n    ...     description='My own table!',\n    ...     parameters={'source': 'postgresql'},\n    ...     columns_comments={'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}\n    ... )\n\n    \"\"\"\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_orc_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
        "mutated": [
            "@apply_configs\ndef create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n    'Create a ORC Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_orc_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create a ORC Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_orc_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create a ORC Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_orc_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create a ORC Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_orc_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)",
            "@apply_configs\ndef create_orc_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, catalog_id: Optional[str]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, transaction_id: Optional[str]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, boto3_session: Optional[boto3.Session]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create a ORC Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n    compression: str, optional\\n        Compression style (``None``, ``snappy``, ``gzip``, etc).\\n    description: str, optional\\n        Table description\\n    parameters: Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode: str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_parquet_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'snappy\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_orc_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input)"
        ]
    },
    {
        "func_name": "create_csv_table",
        "original": "@apply_configs\ndef create_csv_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, sep: str=',', skip_header_line_count: Optional[int]=None, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    \"\"\"Create a CSV Table (Metadata Only) in the AWS Glue Catalog.\n\n    'https://docs.aws.amazon.com/athena/latest/ug/data-types.html'\n\n    Note\n    ----\n    Athena requires the columns in the underlying CSV files in S3 to be in the same order\n    as the columns in the Glue data catalog.\n\n    Parameters\n    ----------\n    database : str\n        Database name.\n    table : str\n        Table name.\n    path : str\n        Amazon S3 path (e.g. s3://bucket/prefix/).\n    columns_types: Dict[str, str]\n        Dictionary with keys as column names and values as data types (e.g. {'col0': 'bigint', 'col1': 'double'}).\n    table_type: str, optional\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\n    partitions_types: Dict[str, str], optional\n        Dictionary with keys as partition names and values as data types (e.g. {'col2': 'date'}).\n    bucketing_info: Tuple[List[str], int], optional\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\n        second element.\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\n    compression : str, optional\n        Compression style (``None``, ``gzip``, etc).\n    description : str, optional\n        Table description\n    parameters : Dict[str, str], optional\n        Key/value pairs to tag the table.\n    columns_comments: Dict[str, str], optional\n        Columns names and the related comments (e.g. {'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}).\n    mode : str\n        'overwrite' to recreate any possible existing table or 'append' to keep any possible existing table.\n    catalog_versioning : bool\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\n    schema_evolution : bool\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\n        Related tutorial:\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\n    sep : str\n        String of length 1. Field delimiter for the output file.\n    skip_header_line_count : Optional[int]\n        Number of Lines to skip regarding to the header.\n    serde_library : Optional[str]\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\n        as a string.\n        If no library is provided the default is `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`.\n    serde_parameters : Optional[str]\n        Dictionary of initialization parameters for the SerDe.\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\n    transaction_id: str, optional\n        The ID of the transaction (i.e. used with GOVERNED tables).\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\n\n        Following projection parameters are supported:\n\n        .. list-table:: Projection Parameters\n           :header-rows: 1\n\n           * - Name\n             - Type\n             - Description\n           * - projection_types\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections types.\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'enum', 'col2_name': 'integer'})\n           * - projection_ranges\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections ranges.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '0,10', 'col2_name': '-1,8675309'})\n           * - projection_values\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections values.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'A,B,Unknown', 'col2_name': 'foo,boo,bar'})\n           * - projection_intervals\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections intervals.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '5'})\n           * - projection_digits\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections digits.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '2'})\n           * - projection_formats\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections formats.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_date': 'yyyy-MM-dd', 'col2_timestamp': 'yyyy-MM-dd HH:mm:ss'})\n           * - projection_storage_location_template\n             - Optional[str]\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\n               a typical `.../column=value/...` pattern.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n\n    Returns\n    -------\n    None\n        None.\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> wr.catalog.create_csv_table(\n    ...     database='default',\n    ...     table='my_table',\n    ...     path='s3://bucket/prefix/',\n    ...     columns_types={'col0': 'bigint', 'col1': 'double'},\n    ...     partitions_types={'col2': 'date'},\n    ...     compression='gzip',\n    ...     description='My own table!',\n    ...     parameters={'source': 'postgresql'},\n    ...     columns_comments={'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}\n    ... )\n\n    \"\"\"\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_csv_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)",
        "mutated": [
            "@apply_configs\ndef create_csv_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, sep: str=',', skip_header_line_count: Optional[int]=None, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n    'Create a CSV Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Note\\n    ----\\n    Athena requires the columns in the underlying CSV files in S3 to be in the same order\\n    as the columns in the Glue data catalog.\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    sep : str\\n        String of length 1. Field delimiter for the output file.\\n    skip_header_line_count : Optional[int]\\n        Number of Lines to skip regarding to the header.\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_csv_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'gzip\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_csv_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_csv_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, sep: str=',', skip_header_line_count: Optional[int]=None, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create a CSV Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Note\\n    ----\\n    Athena requires the columns in the underlying CSV files in S3 to be in the same order\\n    as the columns in the Glue data catalog.\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    sep : str\\n        String of length 1. Field delimiter for the output file.\\n    skip_header_line_count : Optional[int]\\n        Number of Lines to skip regarding to the header.\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_csv_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'gzip\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_csv_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_csv_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, sep: str=',', skip_header_line_count: Optional[int]=None, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create a CSV Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Note\\n    ----\\n    Athena requires the columns in the underlying CSV files in S3 to be in the same order\\n    as the columns in the Glue data catalog.\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    sep : str\\n        String of length 1. Field delimiter for the output file.\\n    skip_header_line_count : Optional[int]\\n        Number of Lines to skip regarding to the header.\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_csv_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'gzip\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_csv_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_csv_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, sep: str=',', skip_header_line_count: Optional[int]=None, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create a CSV Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Note\\n    ----\\n    Athena requires the columns in the underlying CSV files in S3 to be in the same order\\n    as the columns in the Glue data catalog.\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    sep : str\\n        String of length 1. Field delimiter for the output file.\\n    skip_header_line_count : Optional[int]\\n        Number of Lines to skip regarding to the header.\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_csv_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'gzip\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_csv_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_csv_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, sep: str=',', skip_header_line_count: Optional[int]=None, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create a CSV Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Note\\n    ----\\n    Athena requires the columns in the underlying CSV files in S3 to be in the same order\\n    as the columns in the Glue data catalog.\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    sep : str\\n        String of length 1. Field delimiter for the output file.\\n    skip_header_line_count : Optional[int]\\n        Number of Lines to skip regarding to the header.\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_csv_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     compression=\\'gzip\\',\\n    ...     description=\\'My own table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, transaction_id=transaction_id, catalog_id=catalog_id)\n    _create_csv_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, sep=sep, skip_header_line_count=skip_header_line_count, serde_library=serde_library, serde_parameters=serde_parameters)"
        ]
    },
    {
        "func_name": "create_json_table",
        "original": "@apply_configs\ndef create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    \"\"\"Create a JSON Table (Metadata Only) in the AWS Glue Catalog.\n\n    'https://docs.aws.amazon.com/athena/latest/ug/data-types.html'\n\n    Parameters\n    ----------\n    database : str\n        Database name.\n    table : str\n        Table name.\n    path : str\n        Amazon S3 path (e.g. s3://bucket/prefix/).\n    columns_types: Dict[str, str]\n        Dictionary with keys as column names and values as data types (e.g. {'col0': 'bigint', 'col1': 'double'}).\n    table_type: str, optional\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\n    partitions_types: Dict[str, str], optional\n        Dictionary with keys as partition names and values as data types (e.g. {'col2': 'date'}).\n    bucketing_info: Tuple[List[str], int], optional\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\n        second element.\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\n    compression : str, optional\n        Compression style (``None``, ``gzip``, etc).\n    description : str, optional\n        Table description\n    parameters : Dict[str, str], optional\n        Key/value pairs to tag the table.\n    columns_comments: Dict[str, str], optional\n        Columns names and the related comments (e.g. {'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}).\n    mode : str\n        'overwrite' to recreate any possible existing table or 'append' to keep any possible existing table.\n    catalog_versioning : bool\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\n    schema_evolution : bool\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\n        Related tutorial:\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\n    serde_library : Optional[str]\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\n        as a string.\n        If no library is provided the default is `org.openx.data.jsonserde.JsonSerDe`.\n    serde_parameters : Optional[str]\n        Dictionary of initialization parameters for the SerDe.\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\n    transaction_id: str, optional\n        The ID of the transaction (i.e. used with GOVERNED tables).\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\n\n        Following projection parameters are supported:\n\n        .. list-table:: Projection Parameters\n           :header-rows: 1\n\n           * - Name\n             - Type\n             - Description\n           * - projection_types\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections types.\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'enum', 'col2_name': 'integer'})\n           * - projection_ranges\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections ranges.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '0,10', 'col2_name': '-1,8675309'})\n           * - projection_values\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections values.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': 'A,B,Unknown', 'col2_name': 'foo,boo,bar'})\n           * - projection_intervals\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections intervals.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '5'})\n           * - projection_digits\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections digits.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_name': '1', 'col2_name': '2'})\n           * - projection_formats\n             - Optional[Dict[str, str]]\n             - Dictionary of partitions names and Athena projections formats.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\n               (e.g. {'col_date': 'yyyy-MM-dd', 'col2_timestamp': 'yyyy-MM-dd HH:mm:ss'})\n           * - projection_storage_location_template\n             - Optional[str]\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\n               a typical `.../column=value/...` pattern.\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\n    boto3_session : boto3.Session(), optional\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\n    catalog_id : str, optional\n        The ID of the Data Catalog from which to retrieve Databases.\n        If none is provided, the AWS account ID is used by default.\n\n    Returns\n    -------\n    None\n        None.\n\n    Examples\n    --------\n    >>> import awswrangler as wr\n    >>> wr.catalog.create_json_table(\n    ...     database='default',\n    ...     table='my_table',\n    ...     path='s3://bucket/prefix/',\n    ...     columns_types={'col0': 'bigint', 'col1': 'double'},\n    ...     partitions_types={'col2': 'date'},\n    ...     description='My very own JSON table!',\n    ...     parameters={'source': 'postgresql'},\n    ...     columns_comments={'col0': 'Column 0.', 'col1': 'Column 1.', 'col2': 'Partition.'}\n    ... )\n\n    \"\"\"\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, catalog_id=catalog_id)\n    _create_json_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, serde_library=serde_library, serde_parameters=serde_parameters)",
        "mutated": [
            "@apply_configs\ndef create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n    'Create a JSON Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.openx.data.jsonserde.JsonSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_json_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     description=\\'My very own JSON table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, catalog_id=catalog_id)\n    _create_json_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create a JSON Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.openx.data.jsonserde.JsonSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_json_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     description=\\'My very own JSON table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, catalog_id=catalog_id)\n    _create_json_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create a JSON Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.openx.data.jsonserde.JsonSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_json_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     description=\\'My very own JSON table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, catalog_id=catalog_id)\n    _create_json_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create a JSON Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.openx.data.jsonserde.JsonSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_json_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     description=\\'My very own JSON table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, catalog_id=catalog_id)\n    _create_json_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, serde_library=serde_library, serde_parameters=serde_parameters)",
            "@apply_configs\ndef create_json_table(database: str, table: str, path: str, columns_types: Dict[str, str], table_type: Optional[str]=None, partitions_types: Optional[Dict[str, str]]=None, bucketing_info: Optional[typing.BucketingInfoTuple]=None, compression: Optional[str]=None, description: Optional[str]=None, parameters: Optional[Dict[str, str]]=None, columns_comments: Optional[Dict[str, str]]=None, mode: Literal['overwrite', 'append']='overwrite', catalog_versioning: bool=False, schema_evolution: bool=False, serde_library: Optional[str]=None, serde_parameters: Optional[Dict[str, str]]=None, transaction_id: Optional[str]=None, boto3_session: Optional[boto3.Session]=None, athena_partition_projection_settings: Optional[typing.AthenaPartitionProjectionSettings]=None, catalog_id: Optional[str]=None) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create a JSON Table (Metadata Only) in the AWS Glue Catalog.\\n\\n    \\'https://docs.aws.amazon.com/athena/latest/ug/data-types.html\\'\\n\\n    Parameters\\n    ----------\\n    database : str\\n        Database name.\\n    table : str\\n        Table name.\\n    path : str\\n        Amazon S3 path (e.g. s3://bucket/prefix/).\\n    columns_types: Dict[str, str]\\n        Dictionary with keys as column names and values as data types (e.g. {\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'}).\\n    table_type: str, optional\\n        The type of the Glue Table (EXTERNAL_TABLE, GOVERNED...). Set to EXTERNAL_TABLE if None\\n    partitions_types: Dict[str, str], optional\\n        Dictionary with keys as partition names and values as data types (e.g. {\\'col2\\': \\'date\\'}).\\n    bucketing_info: Tuple[List[str], int], optional\\n        Tuple consisting of the column names used for bucketing as the first element and the number of buckets as the\\n        second element.\\n        Only `str`, `int` and `bool` are supported as column data types for bucketing.\\n    compression : str, optional\\n        Compression style (``None``, ``gzip``, etc).\\n    description : str, optional\\n        Table description\\n    parameters : Dict[str, str], optional\\n        Key/value pairs to tag the table.\\n    columns_comments: Dict[str, str], optional\\n        Columns names and the related comments (e.g. {\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}).\\n    mode : str\\n        \\'overwrite\\' to recreate any possible existing table or \\'append\\' to keep any possible existing table.\\n    catalog_versioning : bool\\n        If True and `mode=\"overwrite\"`, creates an archived version of the table catalog before updating it.\\n    schema_evolution : bool\\n        If True allows schema evolution (new or missing columns), otherwise a exception will be raised.\\n        (Only considered if dataset=True and mode in (\"append\", \"overwrite_partitions\"))\\n        Related tutorial:\\n        https://aws-sdk-pandas.readthedocs.io/en/2.11.0/tutorials/014%20-%20Schema%20Evolution.html\\n    serde_library : Optional[str]\\n        Specifies the SerDe Serialization library which will be used. You need to provide the Class library name\\n        as a string.\\n        If no library is provided the default is `org.openx.data.jsonserde.JsonSerDe`.\\n    serde_parameters : Optional[str]\\n        Dictionary of initialization parameters for the SerDe.\\n        The default is `{\"field.delim\": sep, \"escape.delim\": \"\\\\\\\\\"}`.\\n    transaction_id: str, optional\\n        The ID of the transaction (i.e. used with GOVERNED tables).\\n    athena_partition_projection_settings: typing.AthenaPartitionProjectionSettings, optional\\n        Parameters of the Athena Partition Projection (https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html).\\n        AthenaPartitionProjectionSettings is a `TypedDict`, meaning the passed parameter can be instantiated either as an\\n        instance of AthenaPartitionProjectionSettings or as a regular Python dict.\\n\\n        Following projection parameters are supported:\\n\\n        .. list-table:: Projection Parameters\\n           :header-rows: 1\\n\\n           * - Name\\n             - Type\\n             - Description\\n           * - projection_types\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections types.\\n               Valid types: \"enum\", \"integer\", \"date\", \"injected\"\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'enum\\', \\'col2_name\\': \\'integer\\'})\\n           * - projection_ranges\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections ranges.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'0,10\\', \\'col2_name\\': \\'-1,8675309\\'})\\n           * - projection_values\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections values.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'A,B,Unknown\\', \\'col2_name\\': \\'foo,boo,bar\\'})\\n           * - projection_intervals\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections intervals.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'5\\'})\\n           * - projection_digits\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections digits.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_name\\': \\'1\\', \\'col2_name\\': \\'2\\'})\\n           * - projection_formats\\n             - Optional[Dict[str, str]]\\n             - Dictionary of partitions names and Athena projections formats.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-supported-types.html\\n               (e.g. {\\'col_date\\': \\'yyyy-MM-dd\\', \\'col2_timestamp\\': \\'yyyy-MM-dd HH:mm:ss\\'})\\n           * - projection_storage_location_template\\n             - Optional[str]\\n             - Value which is allows Athena to properly map partition values if the S3 file locations do not follow\\n               a typical `.../column=value/...` pattern.\\n               https://docs.aws.amazon.com/athena/latest/ug/partition-projection-setting-up.html\\n               (e.g. s3://bucket/table_root/a=${a}/${b}/some_static_subdirectory/${c}/)\\n    boto3_session : boto3.Session(), optional\\n        Boto3 Session. The default boto3 session will be used if boto3_session receive None.\\n    catalog_id : str, optional\\n        The ID of the Data Catalog from which to retrieve Databases.\\n        If none is provided, the AWS account ID is used by default.\\n\\n    Returns\\n    -------\\n    None\\n        None.\\n\\n    Examples\\n    --------\\n    >>> import awswrangler as wr\\n    >>> wr.catalog.create_json_table(\\n    ...     database=\\'default\\',\\n    ...     table=\\'my_table\\',\\n    ...     path=\\'s3://bucket/prefix/\\',\\n    ...     columns_types={\\'col0\\': \\'bigint\\', \\'col1\\': \\'double\\'},\\n    ...     partitions_types={\\'col2\\': \\'date\\'},\\n    ...     description=\\'My very own JSON table!\\',\\n    ...     parameters={\\'source\\': \\'postgresql\\'},\\n    ...     columns_comments={\\'col0\\': \\'Column 0.\\', \\'col1\\': \\'Column 1.\\', \\'col2\\': \\'Partition.\\'}\\n    ... )\\n\\n    '\n    catalog_table_input: Optional[Dict[str, Any]] = _get_table_input(database=database, table=table, boto3_session=boto3_session, catalog_id=catalog_id)\n    _create_json_table(database=database, table=table, path=path, columns_types=columns_types, table_type=table_type, partitions_types=partitions_types, bucketing_info=bucketing_info, catalog_id=catalog_id, compression=compression, description=description, parameters=parameters, columns_comments=columns_comments, mode=mode, catalog_versioning=catalog_versioning, transaction_id=transaction_id, schema_evolution=schema_evolution, athena_partition_projection_settings=athena_partition_projection_settings, boto3_session=boto3_session, catalog_table_input=catalog_table_input, serde_library=serde_library, serde_parameters=serde_parameters)"
        ]
    }
]