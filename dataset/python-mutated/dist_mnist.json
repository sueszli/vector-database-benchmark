[
    {
        "func_name": "generate_default_params",
        "original": "def generate_default_params():\n    \"\"\"\n    Generate default hyper parameters\n    \"\"\"\n    return {'learning_rate': 0.01, 'batch_size': 100, 'hidden_units': 100}",
        "mutated": [
            "def generate_default_params():\n    if False:\n        i = 10\n    '\\n    Generate default hyper parameters\\n    '\n    return {'learning_rate': 0.01, 'batch_size': 100, 'hidden_units': 100}",
            "def generate_default_params():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Generate default hyper parameters\\n    '\n    return {'learning_rate': 0.01, 'batch_size': 100, 'hidden_units': 100}",
            "def generate_default_params():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Generate default hyper parameters\\n    '\n    return {'learning_rate': 0.01, 'batch_size': 100, 'hidden_units': 100}",
            "def generate_default_params():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Generate default hyper parameters\\n    '\n    return {'learning_rate': 0.01, 'batch_size': 100, 'hidden_units': 100}",
            "def generate_default_params():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Generate default hyper parameters\\n    '\n    return {'learning_rate': 0.01, 'batch_size': 100, 'hidden_units': 100}"
        ]
    },
    {
        "func_name": "download_mnist_retry",
        "original": "def download_mnist_retry(data_dir, max_num_retries=20):\n    \"\"\"Try to download mnist dataset and avoid errors\"\"\"\n    for _ in range(max_num_retries):\n        try:\n            return input_data.read_data_sets(data_dir, one_hot=True)\n        except tf.errors.AlreadyExistsError:\n            time.sleep(1)\n    raise Exception('Failed to download MNIST.')",
        "mutated": [
            "def download_mnist_retry(data_dir, max_num_retries=20):\n    if False:\n        i = 10\n    'Try to download mnist dataset and avoid errors'\n    for _ in range(max_num_retries):\n        try:\n            return input_data.read_data_sets(data_dir, one_hot=True)\n        except tf.errors.AlreadyExistsError:\n            time.sleep(1)\n    raise Exception('Failed to download MNIST.')",
            "def download_mnist_retry(data_dir, max_num_retries=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Try to download mnist dataset and avoid errors'\n    for _ in range(max_num_retries):\n        try:\n            return input_data.read_data_sets(data_dir, one_hot=True)\n        except tf.errors.AlreadyExistsError:\n            time.sleep(1)\n    raise Exception('Failed to download MNIST.')",
            "def download_mnist_retry(data_dir, max_num_retries=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Try to download mnist dataset and avoid errors'\n    for _ in range(max_num_retries):\n        try:\n            return input_data.read_data_sets(data_dir, one_hot=True)\n        except tf.errors.AlreadyExistsError:\n            time.sleep(1)\n    raise Exception('Failed to download MNIST.')",
            "def download_mnist_retry(data_dir, max_num_retries=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Try to download mnist dataset and avoid errors'\n    for _ in range(max_num_retries):\n        try:\n            return input_data.read_data_sets(data_dir, one_hot=True)\n        except tf.errors.AlreadyExistsError:\n            time.sleep(1)\n    raise Exception('Failed to download MNIST.')",
            "def download_mnist_retry(data_dir, max_num_retries=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Try to download mnist dataset and avoid errors'\n    for _ in range(max_num_retries):\n        try:\n            return input_data.read_data_sets(data_dir, one_hot=True)\n        except tf.errors.AlreadyExistsError:\n            time.sleep(1)\n    raise Exception('Failed to download MNIST.')"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(unused_argv):\n    RECEIVED_PARAMS = nni.get_next_parameter()\n    PARAMS = generate_default_params()\n    PARAMS.update(RECEIVED_PARAMS)\n    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')\n    task_config = tf_config.get('task', {})\n    task_type = task_config.get('type')\n    task_index = task_config.get('index')\n    FLAGS.job_name = task_type\n    FLAGS.task_index = task_index\n    mnist = download_mnist_retry(FLAGS.data_dir)\n    if FLAGS.download_only:\n        sys.exit(0)\n    if FLAGS.job_name is None or FLAGS.job_name == '':\n        raise ValueError('Must specify an explicit `job_name`')\n    if FLAGS.task_index is None or FLAGS.task_index == '':\n        raise ValueError('Must specify an explicit `task_index`')\n    print('job name = %s' % FLAGS.job_name)\n    print('task index = %d' % FLAGS.task_index)\n    cluster_config = tf_config.get('cluster', {})\n    ps_hosts = cluster_config.get('ps')\n    worker_hosts = cluster_config.get('worker')\n    ps_hosts_str = ','.join(ps_hosts)\n    worker_hosts_str = ','.join(worker_hosts)\n    FLAGS.ps_hosts = ps_hosts_str\n    FLAGS.worker_hosts = worker_hosts_str\n    ps_spec = FLAGS.ps_hosts.split(',')\n    worker_spec = FLAGS.worker_hosts.split(',')\n    num_workers = len(worker_spec)\n    cluster = tf.train.ClusterSpec({'ps': ps_spec, 'worker': worker_spec})\n    if not FLAGS.existing_servers:\n        server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n        if FLAGS.job_name == 'ps':\n            server.join()\n    is_chief = FLAGS.task_index == 0\n    if FLAGS.num_gpus > 0:\n        gpu = FLAGS.task_index % FLAGS.num_gpus\n        worker_device = '/job:worker/task:%d/gpu:%d' % (FLAGS.task_index, gpu)\n    elif FLAGS.num_gpus == 0:\n        cpu = 0\n        worker_device = '/job:worker/task:%d/cpu:%d' % (FLAGS.task_index, cpu)\n    with tf.device(tf.train.replica_device_setter(worker_device=worker_device, ps_device='/job:ps/cpu:0', cluster=cluster)):\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        hid_w = tf.Variable(tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, PARAMS['hidden_units']], stddev=1.0 / IMAGE_PIXELS), name='hid_w')\n        hid_b = tf.Variable(tf.zeros([PARAMS['hidden_units']]), name='hid_b')\n        sm_w = tf.Variable(tf.truncated_normal([PARAMS['hidden_units'], 10], stddev=1.0 / math.sqrt(PARAMS['hidden_units'])), name='sm_w')\n        sm_b = tf.Variable(tf.zeros([10]), name='sm_b')\n        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n        y_ = tf.placeholder(tf.float32, [None, 10])\n        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n        hid = tf.nn.relu(hid_lin)\n        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n        opt = tf.train.AdamOptimizer(PARAMS['learning_rate'])\n        if FLAGS.sync_replicas:\n            if FLAGS.replicas_to_aggregate is None:\n                replicas_to_aggregate = num_workers\n            else:\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\n            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=replicas_to_aggregate, total_num_replicas=num_workers, name='mnist_sync_replicas')\n        train_step = opt.minimize(cross_entropy, global_step=global_step)\n        if FLAGS.sync_replicas:\n            local_init_op = opt.local_step_init_op\n            if is_chief:\n                local_init_op = opt.chief_init_op\n            ready_for_local_init_op = opt.ready_for_local_init_op\n            chief_queue_runner = opt.get_chief_queue_runner()\n            sync_init_op = opt.get_init_tokens_op()\n        init_op = tf.global_variables_initializer()\n        train_dir = tempfile.mkdtemp()\n        if FLAGS.sync_replicas:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, recovery_wait_secs=1, global_step=global_step)\n        else:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, recovery_wait_secs=1, global_step=global_step)\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, device_filters=['/job:ps', '/job:worker/task:%d' % FLAGS.task_index])\n        if is_chief:\n            print('Worker %d: Initializing session...' % FLAGS.task_index)\n        else:\n            print('Worker %d: Waiting for session to be initialized...' % FLAGS.task_index)\n        if FLAGS.existing_servers:\n            server_grpc_url = 'grpc://' + worker_spec[FLAGS.task_index]\n            print('Using existing server at: %s' % server_grpc_url)\n            sess = sv.prepare_or_wait_for_session(server_grpc_url, config=sess_config)\n        else:\n            sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n        print('Worker %d: Session initialization complete.' % FLAGS.task_index)\n        if FLAGS.sync_replicas and is_chief:\n            sess.run(sync_init_op)\n            sv.start_queue_runners(sess, [chief_queue_runner])\n        time_begin = time.time()\n        print('Training begins @ %f' % time_begin)\n        local_step = 0\n        while True:\n            (batch_xs, batch_ys) = mnist.train.next_batch(PARAMS['batch_size'])\n            train_feed = {x: batch_xs, y_: batch_ys}\n            (_, step) = sess.run([train_step, global_step], feed_dict=train_feed)\n            local_step += 1\n            now = time.time()\n            print('%f: Worker %d: training step %d done (global step: %d)' % (now, FLAGS.task_index, local_step, step))\n            if step > 0 and step % 5000 == 0 and is_chief:\n                val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n                interim_val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n                print('After %d training step(s), validation cross entropy = %g' % (step, interim_val_xent))\n                nni.report_intermediate_result(interim_val_xent)\n            if step >= FLAGS.train_steps:\n                break\n        time_end = time.time()\n        print('Training ends @ %f' % time_end)\n        training_time = time_end - time_begin\n        print('Training elapsed time: %f s' % training_time)\n        val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n        val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n        print('After %d training step(s), validation cross entropy = %g' % (FLAGS.train_steps, val_xent))\n        if is_chief:\n            nni.report_final_result(val_xent)",
        "mutated": [
            "def main(unused_argv):\n    if False:\n        i = 10\n    RECEIVED_PARAMS = nni.get_next_parameter()\n    PARAMS = generate_default_params()\n    PARAMS.update(RECEIVED_PARAMS)\n    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')\n    task_config = tf_config.get('task', {})\n    task_type = task_config.get('type')\n    task_index = task_config.get('index')\n    FLAGS.job_name = task_type\n    FLAGS.task_index = task_index\n    mnist = download_mnist_retry(FLAGS.data_dir)\n    if FLAGS.download_only:\n        sys.exit(0)\n    if FLAGS.job_name is None or FLAGS.job_name == '':\n        raise ValueError('Must specify an explicit `job_name`')\n    if FLAGS.task_index is None or FLAGS.task_index == '':\n        raise ValueError('Must specify an explicit `task_index`')\n    print('job name = %s' % FLAGS.job_name)\n    print('task index = %d' % FLAGS.task_index)\n    cluster_config = tf_config.get('cluster', {})\n    ps_hosts = cluster_config.get('ps')\n    worker_hosts = cluster_config.get('worker')\n    ps_hosts_str = ','.join(ps_hosts)\n    worker_hosts_str = ','.join(worker_hosts)\n    FLAGS.ps_hosts = ps_hosts_str\n    FLAGS.worker_hosts = worker_hosts_str\n    ps_spec = FLAGS.ps_hosts.split(',')\n    worker_spec = FLAGS.worker_hosts.split(',')\n    num_workers = len(worker_spec)\n    cluster = tf.train.ClusterSpec({'ps': ps_spec, 'worker': worker_spec})\n    if not FLAGS.existing_servers:\n        server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n        if FLAGS.job_name == 'ps':\n            server.join()\n    is_chief = FLAGS.task_index == 0\n    if FLAGS.num_gpus > 0:\n        gpu = FLAGS.task_index % FLAGS.num_gpus\n        worker_device = '/job:worker/task:%d/gpu:%d' % (FLAGS.task_index, gpu)\n    elif FLAGS.num_gpus == 0:\n        cpu = 0\n        worker_device = '/job:worker/task:%d/cpu:%d' % (FLAGS.task_index, cpu)\n    with tf.device(tf.train.replica_device_setter(worker_device=worker_device, ps_device='/job:ps/cpu:0', cluster=cluster)):\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        hid_w = tf.Variable(tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, PARAMS['hidden_units']], stddev=1.0 / IMAGE_PIXELS), name='hid_w')\n        hid_b = tf.Variable(tf.zeros([PARAMS['hidden_units']]), name='hid_b')\n        sm_w = tf.Variable(tf.truncated_normal([PARAMS['hidden_units'], 10], stddev=1.0 / math.sqrt(PARAMS['hidden_units'])), name='sm_w')\n        sm_b = tf.Variable(tf.zeros([10]), name='sm_b')\n        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n        y_ = tf.placeholder(tf.float32, [None, 10])\n        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n        hid = tf.nn.relu(hid_lin)\n        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n        opt = tf.train.AdamOptimizer(PARAMS['learning_rate'])\n        if FLAGS.sync_replicas:\n            if FLAGS.replicas_to_aggregate is None:\n                replicas_to_aggregate = num_workers\n            else:\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\n            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=replicas_to_aggregate, total_num_replicas=num_workers, name='mnist_sync_replicas')\n        train_step = opt.minimize(cross_entropy, global_step=global_step)\n        if FLAGS.sync_replicas:\n            local_init_op = opt.local_step_init_op\n            if is_chief:\n                local_init_op = opt.chief_init_op\n            ready_for_local_init_op = opt.ready_for_local_init_op\n            chief_queue_runner = opt.get_chief_queue_runner()\n            sync_init_op = opt.get_init_tokens_op()\n        init_op = tf.global_variables_initializer()\n        train_dir = tempfile.mkdtemp()\n        if FLAGS.sync_replicas:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, recovery_wait_secs=1, global_step=global_step)\n        else:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, recovery_wait_secs=1, global_step=global_step)\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, device_filters=['/job:ps', '/job:worker/task:%d' % FLAGS.task_index])\n        if is_chief:\n            print('Worker %d: Initializing session...' % FLAGS.task_index)\n        else:\n            print('Worker %d: Waiting for session to be initialized...' % FLAGS.task_index)\n        if FLAGS.existing_servers:\n            server_grpc_url = 'grpc://' + worker_spec[FLAGS.task_index]\n            print('Using existing server at: %s' % server_grpc_url)\n            sess = sv.prepare_or_wait_for_session(server_grpc_url, config=sess_config)\n        else:\n            sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n        print('Worker %d: Session initialization complete.' % FLAGS.task_index)\n        if FLAGS.sync_replicas and is_chief:\n            sess.run(sync_init_op)\n            sv.start_queue_runners(sess, [chief_queue_runner])\n        time_begin = time.time()\n        print('Training begins @ %f' % time_begin)\n        local_step = 0\n        while True:\n            (batch_xs, batch_ys) = mnist.train.next_batch(PARAMS['batch_size'])\n            train_feed = {x: batch_xs, y_: batch_ys}\n            (_, step) = sess.run([train_step, global_step], feed_dict=train_feed)\n            local_step += 1\n            now = time.time()\n            print('%f: Worker %d: training step %d done (global step: %d)' % (now, FLAGS.task_index, local_step, step))\n            if step > 0 and step % 5000 == 0 and is_chief:\n                val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n                interim_val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n                print('After %d training step(s), validation cross entropy = %g' % (step, interim_val_xent))\n                nni.report_intermediate_result(interim_val_xent)\n            if step >= FLAGS.train_steps:\n                break\n        time_end = time.time()\n        print('Training ends @ %f' % time_end)\n        training_time = time_end - time_begin\n        print('Training elapsed time: %f s' % training_time)\n        val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n        val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n        print('After %d training step(s), validation cross entropy = %g' % (FLAGS.train_steps, val_xent))\n        if is_chief:\n            nni.report_final_result(val_xent)",
            "def main(unused_argv):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    RECEIVED_PARAMS = nni.get_next_parameter()\n    PARAMS = generate_default_params()\n    PARAMS.update(RECEIVED_PARAMS)\n    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')\n    task_config = tf_config.get('task', {})\n    task_type = task_config.get('type')\n    task_index = task_config.get('index')\n    FLAGS.job_name = task_type\n    FLAGS.task_index = task_index\n    mnist = download_mnist_retry(FLAGS.data_dir)\n    if FLAGS.download_only:\n        sys.exit(0)\n    if FLAGS.job_name is None or FLAGS.job_name == '':\n        raise ValueError('Must specify an explicit `job_name`')\n    if FLAGS.task_index is None or FLAGS.task_index == '':\n        raise ValueError('Must specify an explicit `task_index`')\n    print('job name = %s' % FLAGS.job_name)\n    print('task index = %d' % FLAGS.task_index)\n    cluster_config = tf_config.get('cluster', {})\n    ps_hosts = cluster_config.get('ps')\n    worker_hosts = cluster_config.get('worker')\n    ps_hosts_str = ','.join(ps_hosts)\n    worker_hosts_str = ','.join(worker_hosts)\n    FLAGS.ps_hosts = ps_hosts_str\n    FLAGS.worker_hosts = worker_hosts_str\n    ps_spec = FLAGS.ps_hosts.split(',')\n    worker_spec = FLAGS.worker_hosts.split(',')\n    num_workers = len(worker_spec)\n    cluster = tf.train.ClusterSpec({'ps': ps_spec, 'worker': worker_spec})\n    if not FLAGS.existing_servers:\n        server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n        if FLAGS.job_name == 'ps':\n            server.join()\n    is_chief = FLAGS.task_index == 0\n    if FLAGS.num_gpus > 0:\n        gpu = FLAGS.task_index % FLAGS.num_gpus\n        worker_device = '/job:worker/task:%d/gpu:%d' % (FLAGS.task_index, gpu)\n    elif FLAGS.num_gpus == 0:\n        cpu = 0\n        worker_device = '/job:worker/task:%d/cpu:%d' % (FLAGS.task_index, cpu)\n    with tf.device(tf.train.replica_device_setter(worker_device=worker_device, ps_device='/job:ps/cpu:0', cluster=cluster)):\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        hid_w = tf.Variable(tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, PARAMS['hidden_units']], stddev=1.0 / IMAGE_PIXELS), name='hid_w')\n        hid_b = tf.Variable(tf.zeros([PARAMS['hidden_units']]), name='hid_b')\n        sm_w = tf.Variable(tf.truncated_normal([PARAMS['hidden_units'], 10], stddev=1.0 / math.sqrt(PARAMS['hidden_units'])), name='sm_w')\n        sm_b = tf.Variable(tf.zeros([10]), name='sm_b')\n        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n        y_ = tf.placeholder(tf.float32, [None, 10])\n        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n        hid = tf.nn.relu(hid_lin)\n        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n        opt = tf.train.AdamOptimizer(PARAMS['learning_rate'])\n        if FLAGS.sync_replicas:\n            if FLAGS.replicas_to_aggregate is None:\n                replicas_to_aggregate = num_workers\n            else:\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\n            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=replicas_to_aggregate, total_num_replicas=num_workers, name='mnist_sync_replicas')\n        train_step = opt.minimize(cross_entropy, global_step=global_step)\n        if FLAGS.sync_replicas:\n            local_init_op = opt.local_step_init_op\n            if is_chief:\n                local_init_op = opt.chief_init_op\n            ready_for_local_init_op = opt.ready_for_local_init_op\n            chief_queue_runner = opt.get_chief_queue_runner()\n            sync_init_op = opt.get_init_tokens_op()\n        init_op = tf.global_variables_initializer()\n        train_dir = tempfile.mkdtemp()\n        if FLAGS.sync_replicas:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, recovery_wait_secs=1, global_step=global_step)\n        else:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, recovery_wait_secs=1, global_step=global_step)\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, device_filters=['/job:ps', '/job:worker/task:%d' % FLAGS.task_index])\n        if is_chief:\n            print('Worker %d: Initializing session...' % FLAGS.task_index)\n        else:\n            print('Worker %d: Waiting for session to be initialized...' % FLAGS.task_index)\n        if FLAGS.existing_servers:\n            server_grpc_url = 'grpc://' + worker_spec[FLAGS.task_index]\n            print('Using existing server at: %s' % server_grpc_url)\n            sess = sv.prepare_or_wait_for_session(server_grpc_url, config=sess_config)\n        else:\n            sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n        print('Worker %d: Session initialization complete.' % FLAGS.task_index)\n        if FLAGS.sync_replicas and is_chief:\n            sess.run(sync_init_op)\n            sv.start_queue_runners(sess, [chief_queue_runner])\n        time_begin = time.time()\n        print('Training begins @ %f' % time_begin)\n        local_step = 0\n        while True:\n            (batch_xs, batch_ys) = mnist.train.next_batch(PARAMS['batch_size'])\n            train_feed = {x: batch_xs, y_: batch_ys}\n            (_, step) = sess.run([train_step, global_step], feed_dict=train_feed)\n            local_step += 1\n            now = time.time()\n            print('%f: Worker %d: training step %d done (global step: %d)' % (now, FLAGS.task_index, local_step, step))\n            if step > 0 and step % 5000 == 0 and is_chief:\n                val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n                interim_val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n                print('After %d training step(s), validation cross entropy = %g' % (step, interim_val_xent))\n                nni.report_intermediate_result(interim_val_xent)\n            if step >= FLAGS.train_steps:\n                break\n        time_end = time.time()\n        print('Training ends @ %f' % time_end)\n        training_time = time_end - time_begin\n        print('Training elapsed time: %f s' % training_time)\n        val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n        val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n        print('After %d training step(s), validation cross entropy = %g' % (FLAGS.train_steps, val_xent))\n        if is_chief:\n            nni.report_final_result(val_xent)",
            "def main(unused_argv):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    RECEIVED_PARAMS = nni.get_next_parameter()\n    PARAMS = generate_default_params()\n    PARAMS.update(RECEIVED_PARAMS)\n    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')\n    task_config = tf_config.get('task', {})\n    task_type = task_config.get('type')\n    task_index = task_config.get('index')\n    FLAGS.job_name = task_type\n    FLAGS.task_index = task_index\n    mnist = download_mnist_retry(FLAGS.data_dir)\n    if FLAGS.download_only:\n        sys.exit(0)\n    if FLAGS.job_name is None or FLAGS.job_name == '':\n        raise ValueError('Must specify an explicit `job_name`')\n    if FLAGS.task_index is None or FLAGS.task_index == '':\n        raise ValueError('Must specify an explicit `task_index`')\n    print('job name = %s' % FLAGS.job_name)\n    print('task index = %d' % FLAGS.task_index)\n    cluster_config = tf_config.get('cluster', {})\n    ps_hosts = cluster_config.get('ps')\n    worker_hosts = cluster_config.get('worker')\n    ps_hosts_str = ','.join(ps_hosts)\n    worker_hosts_str = ','.join(worker_hosts)\n    FLAGS.ps_hosts = ps_hosts_str\n    FLAGS.worker_hosts = worker_hosts_str\n    ps_spec = FLAGS.ps_hosts.split(',')\n    worker_spec = FLAGS.worker_hosts.split(',')\n    num_workers = len(worker_spec)\n    cluster = tf.train.ClusterSpec({'ps': ps_spec, 'worker': worker_spec})\n    if not FLAGS.existing_servers:\n        server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n        if FLAGS.job_name == 'ps':\n            server.join()\n    is_chief = FLAGS.task_index == 0\n    if FLAGS.num_gpus > 0:\n        gpu = FLAGS.task_index % FLAGS.num_gpus\n        worker_device = '/job:worker/task:%d/gpu:%d' % (FLAGS.task_index, gpu)\n    elif FLAGS.num_gpus == 0:\n        cpu = 0\n        worker_device = '/job:worker/task:%d/cpu:%d' % (FLAGS.task_index, cpu)\n    with tf.device(tf.train.replica_device_setter(worker_device=worker_device, ps_device='/job:ps/cpu:0', cluster=cluster)):\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        hid_w = tf.Variable(tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, PARAMS['hidden_units']], stddev=1.0 / IMAGE_PIXELS), name='hid_w')\n        hid_b = tf.Variable(tf.zeros([PARAMS['hidden_units']]), name='hid_b')\n        sm_w = tf.Variable(tf.truncated_normal([PARAMS['hidden_units'], 10], stddev=1.0 / math.sqrt(PARAMS['hidden_units'])), name='sm_w')\n        sm_b = tf.Variable(tf.zeros([10]), name='sm_b')\n        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n        y_ = tf.placeholder(tf.float32, [None, 10])\n        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n        hid = tf.nn.relu(hid_lin)\n        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n        opt = tf.train.AdamOptimizer(PARAMS['learning_rate'])\n        if FLAGS.sync_replicas:\n            if FLAGS.replicas_to_aggregate is None:\n                replicas_to_aggregate = num_workers\n            else:\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\n            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=replicas_to_aggregate, total_num_replicas=num_workers, name='mnist_sync_replicas')\n        train_step = opt.minimize(cross_entropy, global_step=global_step)\n        if FLAGS.sync_replicas:\n            local_init_op = opt.local_step_init_op\n            if is_chief:\n                local_init_op = opt.chief_init_op\n            ready_for_local_init_op = opt.ready_for_local_init_op\n            chief_queue_runner = opt.get_chief_queue_runner()\n            sync_init_op = opt.get_init_tokens_op()\n        init_op = tf.global_variables_initializer()\n        train_dir = tempfile.mkdtemp()\n        if FLAGS.sync_replicas:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, recovery_wait_secs=1, global_step=global_step)\n        else:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, recovery_wait_secs=1, global_step=global_step)\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, device_filters=['/job:ps', '/job:worker/task:%d' % FLAGS.task_index])\n        if is_chief:\n            print('Worker %d: Initializing session...' % FLAGS.task_index)\n        else:\n            print('Worker %d: Waiting for session to be initialized...' % FLAGS.task_index)\n        if FLAGS.existing_servers:\n            server_grpc_url = 'grpc://' + worker_spec[FLAGS.task_index]\n            print('Using existing server at: %s' % server_grpc_url)\n            sess = sv.prepare_or_wait_for_session(server_grpc_url, config=sess_config)\n        else:\n            sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n        print('Worker %d: Session initialization complete.' % FLAGS.task_index)\n        if FLAGS.sync_replicas and is_chief:\n            sess.run(sync_init_op)\n            sv.start_queue_runners(sess, [chief_queue_runner])\n        time_begin = time.time()\n        print('Training begins @ %f' % time_begin)\n        local_step = 0\n        while True:\n            (batch_xs, batch_ys) = mnist.train.next_batch(PARAMS['batch_size'])\n            train_feed = {x: batch_xs, y_: batch_ys}\n            (_, step) = sess.run([train_step, global_step], feed_dict=train_feed)\n            local_step += 1\n            now = time.time()\n            print('%f: Worker %d: training step %d done (global step: %d)' % (now, FLAGS.task_index, local_step, step))\n            if step > 0 and step % 5000 == 0 and is_chief:\n                val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n                interim_val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n                print('After %d training step(s), validation cross entropy = %g' % (step, interim_val_xent))\n                nni.report_intermediate_result(interim_val_xent)\n            if step >= FLAGS.train_steps:\n                break\n        time_end = time.time()\n        print('Training ends @ %f' % time_end)\n        training_time = time_end - time_begin\n        print('Training elapsed time: %f s' % training_time)\n        val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n        val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n        print('After %d training step(s), validation cross entropy = %g' % (FLAGS.train_steps, val_xent))\n        if is_chief:\n            nni.report_final_result(val_xent)",
            "def main(unused_argv):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    RECEIVED_PARAMS = nni.get_next_parameter()\n    PARAMS = generate_default_params()\n    PARAMS.update(RECEIVED_PARAMS)\n    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')\n    task_config = tf_config.get('task', {})\n    task_type = task_config.get('type')\n    task_index = task_config.get('index')\n    FLAGS.job_name = task_type\n    FLAGS.task_index = task_index\n    mnist = download_mnist_retry(FLAGS.data_dir)\n    if FLAGS.download_only:\n        sys.exit(0)\n    if FLAGS.job_name is None or FLAGS.job_name == '':\n        raise ValueError('Must specify an explicit `job_name`')\n    if FLAGS.task_index is None or FLAGS.task_index == '':\n        raise ValueError('Must specify an explicit `task_index`')\n    print('job name = %s' % FLAGS.job_name)\n    print('task index = %d' % FLAGS.task_index)\n    cluster_config = tf_config.get('cluster', {})\n    ps_hosts = cluster_config.get('ps')\n    worker_hosts = cluster_config.get('worker')\n    ps_hosts_str = ','.join(ps_hosts)\n    worker_hosts_str = ','.join(worker_hosts)\n    FLAGS.ps_hosts = ps_hosts_str\n    FLAGS.worker_hosts = worker_hosts_str\n    ps_spec = FLAGS.ps_hosts.split(',')\n    worker_spec = FLAGS.worker_hosts.split(',')\n    num_workers = len(worker_spec)\n    cluster = tf.train.ClusterSpec({'ps': ps_spec, 'worker': worker_spec})\n    if not FLAGS.existing_servers:\n        server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n        if FLAGS.job_name == 'ps':\n            server.join()\n    is_chief = FLAGS.task_index == 0\n    if FLAGS.num_gpus > 0:\n        gpu = FLAGS.task_index % FLAGS.num_gpus\n        worker_device = '/job:worker/task:%d/gpu:%d' % (FLAGS.task_index, gpu)\n    elif FLAGS.num_gpus == 0:\n        cpu = 0\n        worker_device = '/job:worker/task:%d/cpu:%d' % (FLAGS.task_index, cpu)\n    with tf.device(tf.train.replica_device_setter(worker_device=worker_device, ps_device='/job:ps/cpu:0', cluster=cluster)):\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        hid_w = tf.Variable(tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, PARAMS['hidden_units']], stddev=1.0 / IMAGE_PIXELS), name='hid_w')\n        hid_b = tf.Variable(tf.zeros([PARAMS['hidden_units']]), name='hid_b')\n        sm_w = tf.Variable(tf.truncated_normal([PARAMS['hidden_units'], 10], stddev=1.0 / math.sqrt(PARAMS['hidden_units'])), name='sm_w')\n        sm_b = tf.Variable(tf.zeros([10]), name='sm_b')\n        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n        y_ = tf.placeholder(tf.float32, [None, 10])\n        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n        hid = tf.nn.relu(hid_lin)\n        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n        opt = tf.train.AdamOptimizer(PARAMS['learning_rate'])\n        if FLAGS.sync_replicas:\n            if FLAGS.replicas_to_aggregate is None:\n                replicas_to_aggregate = num_workers\n            else:\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\n            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=replicas_to_aggregate, total_num_replicas=num_workers, name='mnist_sync_replicas')\n        train_step = opt.minimize(cross_entropy, global_step=global_step)\n        if FLAGS.sync_replicas:\n            local_init_op = opt.local_step_init_op\n            if is_chief:\n                local_init_op = opt.chief_init_op\n            ready_for_local_init_op = opt.ready_for_local_init_op\n            chief_queue_runner = opt.get_chief_queue_runner()\n            sync_init_op = opt.get_init_tokens_op()\n        init_op = tf.global_variables_initializer()\n        train_dir = tempfile.mkdtemp()\n        if FLAGS.sync_replicas:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, recovery_wait_secs=1, global_step=global_step)\n        else:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, recovery_wait_secs=1, global_step=global_step)\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, device_filters=['/job:ps', '/job:worker/task:%d' % FLAGS.task_index])\n        if is_chief:\n            print('Worker %d: Initializing session...' % FLAGS.task_index)\n        else:\n            print('Worker %d: Waiting for session to be initialized...' % FLAGS.task_index)\n        if FLAGS.existing_servers:\n            server_grpc_url = 'grpc://' + worker_spec[FLAGS.task_index]\n            print('Using existing server at: %s' % server_grpc_url)\n            sess = sv.prepare_or_wait_for_session(server_grpc_url, config=sess_config)\n        else:\n            sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n        print('Worker %d: Session initialization complete.' % FLAGS.task_index)\n        if FLAGS.sync_replicas and is_chief:\n            sess.run(sync_init_op)\n            sv.start_queue_runners(sess, [chief_queue_runner])\n        time_begin = time.time()\n        print('Training begins @ %f' % time_begin)\n        local_step = 0\n        while True:\n            (batch_xs, batch_ys) = mnist.train.next_batch(PARAMS['batch_size'])\n            train_feed = {x: batch_xs, y_: batch_ys}\n            (_, step) = sess.run([train_step, global_step], feed_dict=train_feed)\n            local_step += 1\n            now = time.time()\n            print('%f: Worker %d: training step %d done (global step: %d)' % (now, FLAGS.task_index, local_step, step))\n            if step > 0 and step % 5000 == 0 and is_chief:\n                val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n                interim_val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n                print('After %d training step(s), validation cross entropy = %g' % (step, interim_val_xent))\n                nni.report_intermediate_result(interim_val_xent)\n            if step >= FLAGS.train_steps:\n                break\n        time_end = time.time()\n        print('Training ends @ %f' % time_end)\n        training_time = time_end - time_begin\n        print('Training elapsed time: %f s' % training_time)\n        val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n        val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n        print('After %d training step(s), validation cross entropy = %g' % (FLAGS.train_steps, val_xent))\n        if is_chief:\n            nni.report_final_result(val_xent)",
            "def main(unused_argv):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    RECEIVED_PARAMS = nni.get_next_parameter()\n    PARAMS = generate_default_params()\n    PARAMS.update(RECEIVED_PARAMS)\n    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')\n    task_config = tf_config.get('task', {})\n    task_type = task_config.get('type')\n    task_index = task_config.get('index')\n    FLAGS.job_name = task_type\n    FLAGS.task_index = task_index\n    mnist = download_mnist_retry(FLAGS.data_dir)\n    if FLAGS.download_only:\n        sys.exit(0)\n    if FLAGS.job_name is None or FLAGS.job_name == '':\n        raise ValueError('Must specify an explicit `job_name`')\n    if FLAGS.task_index is None or FLAGS.task_index == '':\n        raise ValueError('Must specify an explicit `task_index`')\n    print('job name = %s' % FLAGS.job_name)\n    print('task index = %d' % FLAGS.task_index)\n    cluster_config = tf_config.get('cluster', {})\n    ps_hosts = cluster_config.get('ps')\n    worker_hosts = cluster_config.get('worker')\n    ps_hosts_str = ','.join(ps_hosts)\n    worker_hosts_str = ','.join(worker_hosts)\n    FLAGS.ps_hosts = ps_hosts_str\n    FLAGS.worker_hosts = worker_hosts_str\n    ps_spec = FLAGS.ps_hosts.split(',')\n    worker_spec = FLAGS.worker_hosts.split(',')\n    num_workers = len(worker_spec)\n    cluster = tf.train.ClusterSpec({'ps': ps_spec, 'worker': worker_spec})\n    if not FLAGS.existing_servers:\n        server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n        if FLAGS.job_name == 'ps':\n            server.join()\n    is_chief = FLAGS.task_index == 0\n    if FLAGS.num_gpus > 0:\n        gpu = FLAGS.task_index % FLAGS.num_gpus\n        worker_device = '/job:worker/task:%d/gpu:%d' % (FLAGS.task_index, gpu)\n    elif FLAGS.num_gpus == 0:\n        cpu = 0\n        worker_device = '/job:worker/task:%d/cpu:%d' % (FLAGS.task_index, cpu)\n    with tf.device(tf.train.replica_device_setter(worker_device=worker_device, ps_device='/job:ps/cpu:0', cluster=cluster)):\n        global_step = tf.Variable(0, name='global_step', trainable=False)\n        hid_w = tf.Variable(tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, PARAMS['hidden_units']], stddev=1.0 / IMAGE_PIXELS), name='hid_w')\n        hid_b = tf.Variable(tf.zeros([PARAMS['hidden_units']]), name='hid_b')\n        sm_w = tf.Variable(tf.truncated_normal([PARAMS['hidden_units'], 10], stddev=1.0 / math.sqrt(PARAMS['hidden_units'])), name='sm_w')\n        sm_b = tf.Variable(tf.zeros([10]), name='sm_b')\n        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n        y_ = tf.placeholder(tf.float32, [None, 10])\n        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n        hid = tf.nn.relu(hid_lin)\n        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n        opt = tf.train.AdamOptimizer(PARAMS['learning_rate'])\n        if FLAGS.sync_replicas:\n            if FLAGS.replicas_to_aggregate is None:\n                replicas_to_aggregate = num_workers\n            else:\n                replicas_to_aggregate = FLAGS.replicas_to_aggregate\n            opt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=replicas_to_aggregate, total_num_replicas=num_workers, name='mnist_sync_replicas')\n        train_step = opt.minimize(cross_entropy, global_step=global_step)\n        if FLAGS.sync_replicas:\n            local_init_op = opt.local_step_init_op\n            if is_chief:\n                local_init_op = opt.chief_init_op\n            ready_for_local_init_op = opt.ready_for_local_init_op\n            chief_queue_runner = opt.get_chief_queue_runner()\n            sync_init_op = opt.get_init_tokens_op()\n        init_op = tf.global_variables_initializer()\n        train_dir = tempfile.mkdtemp()\n        if FLAGS.sync_replicas:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, recovery_wait_secs=1, global_step=global_step)\n        else:\n            sv = tf.train.Supervisor(is_chief=is_chief, logdir=train_dir, init_op=init_op, recovery_wait_secs=1, global_step=global_step)\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, device_filters=['/job:ps', '/job:worker/task:%d' % FLAGS.task_index])\n        if is_chief:\n            print('Worker %d: Initializing session...' % FLAGS.task_index)\n        else:\n            print('Worker %d: Waiting for session to be initialized...' % FLAGS.task_index)\n        if FLAGS.existing_servers:\n            server_grpc_url = 'grpc://' + worker_spec[FLAGS.task_index]\n            print('Using existing server at: %s' % server_grpc_url)\n            sess = sv.prepare_or_wait_for_session(server_grpc_url, config=sess_config)\n        else:\n            sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n        print('Worker %d: Session initialization complete.' % FLAGS.task_index)\n        if FLAGS.sync_replicas and is_chief:\n            sess.run(sync_init_op)\n            sv.start_queue_runners(sess, [chief_queue_runner])\n        time_begin = time.time()\n        print('Training begins @ %f' % time_begin)\n        local_step = 0\n        while True:\n            (batch_xs, batch_ys) = mnist.train.next_batch(PARAMS['batch_size'])\n            train_feed = {x: batch_xs, y_: batch_ys}\n            (_, step) = sess.run([train_step, global_step], feed_dict=train_feed)\n            local_step += 1\n            now = time.time()\n            print('%f: Worker %d: training step %d done (global step: %d)' % (now, FLAGS.task_index, local_step, step))\n            if step > 0 and step % 5000 == 0 and is_chief:\n                val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n                interim_val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n                print('After %d training step(s), validation cross entropy = %g' % (step, interim_val_xent))\n                nni.report_intermediate_result(interim_val_xent)\n            if step >= FLAGS.train_steps:\n                break\n        time_end = time.time()\n        print('Training ends @ %f' % time_end)\n        training_time = time_end - time_begin\n        print('Training elapsed time: %f s' % training_time)\n        val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n        val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n        print('After %d training step(s), validation cross entropy = %g' % (FLAGS.train_steps, val_xent))\n        if is_chief:\n            nni.report_final_result(val_xent)"
        ]
    }
]