[
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, bw, var_type, fform, estimator, nboot=100):\n    self.endog = endog\n    self.exog = exog\n    self.var_type = var_type\n    self.fform = fform\n    self.estimator = estimator\n    self.nboot = nboot\n    self.bw = KDEMultivariate(exog, bw=bw, var_type=var_type).bw\n    self.sig = self._compute_sig()",
        "mutated": [
            "def __init__(self, endog, exog, bw, var_type, fform, estimator, nboot=100):\n    if False:\n        i = 10\n    self.endog = endog\n    self.exog = exog\n    self.var_type = var_type\n    self.fform = fform\n    self.estimator = estimator\n    self.nboot = nboot\n    self.bw = KDEMultivariate(exog, bw=bw, var_type=var_type).bw\n    self.sig = self._compute_sig()",
            "def __init__(self, endog, exog, bw, var_type, fform, estimator, nboot=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.endog = endog\n    self.exog = exog\n    self.var_type = var_type\n    self.fform = fform\n    self.estimator = estimator\n    self.nboot = nboot\n    self.bw = KDEMultivariate(exog, bw=bw, var_type=var_type).bw\n    self.sig = self._compute_sig()",
            "def __init__(self, endog, exog, bw, var_type, fform, estimator, nboot=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.endog = endog\n    self.exog = exog\n    self.var_type = var_type\n    self.fform = fform\n    self.estimator = estimator\n    self.nboot = nboot\n    self.bw = KDEMultivariate(exog, bw=bw, var_type=var_type).bw\n    self.sig = self._compute_sig()",
            "def __init__(self, endog, exog, bw, var_type, fform, estimator, nboot=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.endog = endog\n    self.exog = exog\n    self.var_type = var_type\n    self.fform = fform\n    self.estimator = estimator\n    self.nboot = nboot\n    self.bw = KDEMultivariate(exog, bw=bw, var_type=var_type).bw\n    self.sig = self._compute_sig()",
            "def __init__(self, endog, exog, bw, var_type, fform, estimator, nboot=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.endog = endog\n    self.exog = exog\n    self.var_type = var_type\n    self.fform = fform\n    self.estimator = estimator\n    self.nboot = nboot\n    self.bw = KDEMultivariate(exog, bw=bw, var_type=var_type).bw\n    self.sig = self._compute_sig()"
        ]
    },
    {
        "func_name": "_compute_sig",
        "original": "def _compute_sig(self):\n    Y = self.endog\n    X = self.exog\n    b = self.estimator(Y, X)\n    m = self.fform(X, b)\n    n = np.shape(X)[0]\n    resid = Y - m\n    resid = resid - np.mean(resid)\n    self.test_stat = self._compute_test_stat(resid)\n    sqrt5 = np.sqrt(5.0)\n    fct1 = (1 - sqrt5) / 2.0\n    fct2 = (1 + sqrt5) / 2.0\n    u1 = fct1 * resid\n    u2 = fct2 * resid\n    r = fct2 / sqrt5\n    I_dist = np.empty((self.nboot, 1))\n    for j in range(self.nboot):\n        u_boot = u2.copy()\n        prob = np.random.uniform(0, 1, size=(n,))\n        ind = prob < r\n        u_boot[ind] = u1[ind]\n        Y_boot = m + u_boot\n        b_hat = self.estimator(Y_boot, X)\n        m_hat = self.fform(X, b_hat)\n        u_boot_hat = Y_boot - m_hat\n        I_dist[j] = self._compute_test_stat(u_boot_hat)\n    self.boots_results = I_dist\n    sig = 'Not Significant'\n    if self.test_stat > mquantiles(I_dist, 0.9):\n        sig = '*'\n    if self.test_stat > mquantiles(I_dist, 0.95):\n        sig = '**'\n    if self.test_stat > mquantiles(I_dist, 0.99):\n        sig = '***'\n    return sig",
        "mutated": [
            "def _compute_sig(self):\n    if False:\n        i = 10\n    Y = self.endog\n    X = self.exog\n    b = self.estimator(Y, X)\n    m = self.fform(X, b)\n    n = np.shape(X)[0]\n    resid = Y - m\n    resid = resid - np.mean(resid)\n    self.test_stat = self._compute_test_stat(resid)\n    sqrt5 = np.sqrt(5.0)\n    fct1 = (1 - sqrt5) / 2.0\n    fct2 = (1 + sqrt5) / 2.0\n    u1 = fct1 * resid\n    u2 = fct2 * resid\n    r = fct2 / sqrt5\n    I_dist = np.empty((self.nboot, 1))\n    for j in range(self.nboot):\n        u_boot = u2.copy()\n        prob = np.random.uniform(0, 1, size=(n,))\n        ind = prob < r\n        u_boot[ind] = u1[ind]\n        Y_boot = m + u_boot\n        b_hat = self.estimator(Y_boot, X)\n        m_hat = self.fform(X, b_hat)\n        u_boot_hat = Y_boot - m_hat\n        I_dist[j] = self._compute_test_stat(u_boot_hat)\n    self.boots_results = I_dist\n    sig = 'Not Significant'\n    if self.test_stat > mquantiles(I_dist, 0.9):\n        sig = '*'\n    if self.test_stat > mquantiles(I_dist, 0.95):\n        sig = '**'\n    if self.test_stat > mquantiles(I_dist, 0.99):\n        sig = '***'\n    return sig",
            "def _compute_sig(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    Y = self.endog\n    X = self.exog\n    b = self.estimator(Y, X)\n    m = self.fform(X, b)\n    n = np.shape(X)[0]\n    resid = Y - m\n    resid = resid - np.mean(resid)\n    self.test_stat = self._compute_test_stat(resid)\n    sqrt5 = np.sqrt(5.0)\n    fct1 = (1 - sqrt5) / 2.0\n    fct2 = (1 + sqrt5) / 2.0\n    u1 = fct1 * resid\n    u2 = fct2 * resid\n    r = fct2 / sqrt5\n    I_dist = np.empty((self.nboot, 1))\n    for j in range(self.nboot):\n        u_boot = u2.copy()\n        prob = np.random.uniform(0, 1, size=(n,))\n        ind = prob < r\n        u_boot[ind] = u1[ind]\n        Y_boot = m + u_boot\n        b_hat = self.estimator(Y_boot, X)\n        m_hat = self.fform(X, b_hat)\n        u_boot_hat = Y_boot - m_hat\n        I_dist[j] = self._compute_test_stat(u_boot_hat)\n    self.boots_results = I_dist\n    sig = 'Not Significant'\n    if self.test_stat > mquantiles(I_dist, 0.9):\n        sig = '*'\n    if self.test_stat > mquantiles(I_dist, 0.95):\n        sig = '**'\n    if self.test_stat > mquantiles(I_dist, 0.99):\n        sig = '***'\n    return sig",
            "def _compute_sig(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    Y = self.endog\n    X = self.exog\n    b = self.estimator(Y, X)\n    m = self.fform(X, b)\n    n = np.shape(X)[0]\n    resid = Y - m\n    resid = resid - np.mean(resid)\n    self.test_stat = self._compute_test_stat(resid)\n    sqrt5 = np.sqrt(5.0)\n    fct1 = (1 - sqrt5) / 2.0\n    fct2 = (1 + sqrt5) / 2.0\n    u1 = fct1 * resid\n    u2 = fct2 * resid\n    r = fct2 / sqrt5\n    I_dist = np.empty((self.nboot, 1))\n    for j in range(self.nboot):\n        u_boot = u2.copy()\n        prob = np.random.uniform(0, 1, size=(n,))\n        ind = prob < r\n        u_boot[ind] = u1[ind]\n        Y_boot = m + u_boot\n        b_hat = self.estimator(Y_boot, X)\n        m_hat = self.fform(X, b_hat)\n        u_boot_hat = Y_boot - m_hat\n        I_dist[j] = self._compute_test_stat(u_boot_hat)\n    self.boots_results = I_dist\n    sig = 'Not Significant'\n    if self.test_stat > mquantiles(I_dist, 0.9):\n        sig = '*'\n    if self.test_stat > mquantiles(I_dist, 0.95):\n        sig = '**'\n    if self.test_stat > mquantiles(I_dist, 0.99):\n        sig = '***'\n    return sig",
            "def _compute_sig(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    Y = self.endog\n    X = self.exog\n    b = self.estimator(Y, X)\n    m = self.fform(X, b)\n    n = np.shape(X)[0]\n    resid = Y - m\n    resid = resid - np.mean(resid)\n    self.test_stat = self._compute_test_stat(resid)\n    sqrt5 = np.sqrt(5.0)\n    fct1 = (1 - sqrt5) / 2.0\n    fct2 = (1 + sqrt5) / 2.0\n    u1 = fct1 * resid\n    u2 = fct2 * resid\n    r = fct2 / sqrt5\n    I_dist = np.empty((self.nboot, 1))\n    for j in range(self.nboot):\n        u_boot = u2.copy()\n        prob = np.random.uniform(0, 1, size=(n,))\n        ind = prob < r\n        u_boot[ind] = u1[ind]\n        Y_boot = m + u_boot\n        b_hat = self.estimator(Y_boot, X)\n        m_hat = self.fform(X, b_hat)\n        u_boot_hat = Y_boot - m_hat\n        I_dist[j] = self._compute_test_stat(u_boot_hat)\n    self.boots_results = I_dist\n    sig = 'Not Significant'\n    if self.test_stat > mquantiles(I_dist, 0.9):\n        sig = '*'\n    if self.test_stat > mquantiles(I_dist, 0.95):\n        sig = '**'\n    if self.test_stat > mquantiles(I_dist, 0.99):\n        sig = '***'\n    return sig",
            "def _compute_sig(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    Y = self.endog\n    X = self.exog\n    b = self.estimator(Y, X)\n    m = self.fform(X, b)\n    n = np.shape(X)[0]\n    resid = Y - m\n    resid = resid - np.mean(resid)\n    self.test_stat = self._compute_test_stat(resid)\n    sqrt5 = np.sqrt(5.0)\n    fct1 = (1 - sqrt5) / 2.0\n    fct2 = (1 + sqrt5) / 2.0\n    u1 = fct1 * resid\n    u2 = fct2 * resid\n    r = fct2 / sqrt5\n    I_dist = np.empty((self.nboot, 1))\n    for j in range(self.nboot):\n        u_boot = u2.copy()\n        prob = np.random.uniform(0, 1, size=(n,))\n        ind = prob < r\n        u_boot[ind] = u1[ind]\n        Y_boot = m + u_boot\n        b_hat = self.estimator(Y_boot, X)\n        m_hat = self.fform(X, b_hat)\n        u_boot_hat = Y_boot - m_hat\n        I_dist[j] = self._compute_test_stat(u_boot_hat)\n    self.boots_results = I_dist\n    sig = 'Not Significant'\n    if self.test_stat > mquantiles(I_dist, 0.9):\n        sig = '*'\n    if self.test_stat > mquantiles(I_dist, 0.95):\n        sig = '**'\n    if self.test_stat > mquantiles(I_dist, 0.99):\n        sig = '***'\n    return sig"
        ]
    },
    {
        "func_name": "_compute_test_stat",
        "original": "def _compute_test_stat(self, u):\n    n = np.shape(u)[0]\n    XLOO = LeaveOneOut(self.exog)\n    uLOO = LeaveOneOut(u[:, None]).__iter__()\n    ival = 0\n    S2 = 0\n    for (i, X_not_i) in enumerate(XLOO):\n        u_j = next(uLOO)\n        u_j = np.squeeze(u_j)\n        K = gpke(self.bw, data=-X_not_i, data_predict=-self.exog[i, :], var_type=self.var_type, tosum=False)\n        f_i = u[i] * u_j * K\n        assert u_j.shape == K.shape\n        ival += f_i.sum()\n        S2 += (f_i ** 2).sum()\n        assert np.size(ival) == 1\n        assert np.size(S2) == 1\n    ival *= 1.0 / (n * (n - 1))\n    ix_cont = _get_type_pos(self.var_type)[0]\n    hp = self.bw[ix_cont].prod()\n    S2 *= 2 * hp / (n * (n - 1))\n    T = n * ival * np.sqrt(hp / S2)\n    return T",
        "mutated": [
            "def _compute_test_stat(self, u):\n    if False:\n        i = 10\n    n = np.shape(u)[0]\n    XLOO = LeaveOneOut(self.exog)\n    uLOO = LeaveOneOut(u[:, None]).__iter__()\n    ival = 0\n    S2 = 0\n    for (i, X_not_i) in enumerate(XLOO):\n        u_j = next(uLOO)\n        u_j = np.squeeze(u_j)\n        K = gpke(self.bw, data=-X_not_i, data_predict=-self.exog[i, :], var_type=self.var_type, tosum=False)\n        f_i = u[i] * u_j * K\n        assert u_j.shape == K.shape\n        ival += f_i.sum()\n        S2 += (f_i ** 2).sum()\n        assert np.size(ival) == 1\n        assert np.size(S2) == 1\n    ival *= 1.0 / (n * (n - 1))\n    ix_cont = _get_type_pos(self.var_type)[0]\n    hp = self.bw[ix_cont].prod()\n    S2 *= 2 * hp / (n * (n - 1))\n    T = n * ival * np.sqrt(hp / S2)\n    return T",
            "def _compute_test_stat(self, u):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    n = np.shape(u)[0]\n    XLOO = LeaveOneOut(self.exog)\n    uLOO = LeaveOneOut(u[:, None]).__iter__()\n    ival = 0\n    S2 = 0\n    for (i, X_not_i) in enumerate(XLOO):\n        u_j = next(uLOO)\n        u_j = np.squeeze(u_j)\n        K = gpke(self.bw, data=-X_not_i, data_predict=-self.exog[i, :], var_type=self.var_type, tosum=False)\n        f_i = u[i] * u_j * K\n        assert u_j.shape == K.shape\n        ival += f_i.sum()\n        S2 += (f_i ** 2).sum()\n        assert np.size(ival) == 1\n        assert np.size(S2) == 1\n    ival *= 1.0 / (n * (n - 1))\n    ix_cont = _get_type_pos(self.var_type)[0]\n    hp = self.bw[ix_cont].prod()\n    S2 *= 2 * hp / (n * (n - 1))\n    T = n * ival * np.sqrt(hp / S2)\n    return T",
            "def _compute_test_stat(self, u):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    n = np.shape(u)[0]\n    XLOO = LeaveOneOut(self.exog)\n    uLOO = LeaveOneOut(u[:, None]).__iter__()\n    ival = 0\n    S2 = 0\n    for (i, X_not_i) in enumerate(XLOO):\n        u_j = next(uLOO)\n        u_j = np.squeeze(u_j)\n        K = gpke(self.bw, data=-X_not_i, data_predict=-self.exog[i, :], var_type=self.var_type, tosum=False)\n        f_i = u[i] * u_j * K\n        assert u_j.shape == K.shape\n        ival += f_i.sum()\n        S2 += (f_i ** 2).sum()\n        assert np.size(ival) == 1\n        assert np.size(S2) == 1\n    ival *= 1.0 / (n * (n - 1))\n    ix_cont = _get_type_pos(self.var_type)[0]\n    hp = self.bw[ix_cont].prod()\n    S2 *= 2 * hp / (n * (n - 1))\n    T = n * ival * np.sqrt(hp / S2)\n    return T",
            "def _compute_test_stat(self, u):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    n = np.shape(u)[0]\n    XLOO = LeaveOneOut(self.exog)\n    uLOO = LeaveOneOut(u[:, None]).__iter__()\n    ival = 0\n    S2 = 0\n    for (i, X_not_i) in enumerate(XLOO):\n        u_j = next(uLOO)\n        u_j = np.squeeze(u_j)\n        K = gpke(self.bw, data=-X_not_i, data_predict=-self.exog[i, :], var_type=self.var_type, tosum=False)\n        f_i = u[i] * u_j * K\n        assert u_j.shape == K.shape\n        ival += f_i.sum()\n        S2 += (f_i ** 2).sum()\n        assert np.size(ival) == 1\n        assert np.size(S2) == 1\n    ival *= 1.0 / (n * (n - 1))\n    ix_cont = _get_type_pos(self.var_type)[0]\n    hp = self.bw[ix_cont].prod()\n    S2 *= 2 * hp / (n * (n - 1))\n    T = n * ival * np.sqrt(hp / S2)\n    return T",
            "def _compute_test_stat(self, u):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    n = np.shape(u)[0]\n    XLOO = LeaveOneOut(self.exog)\n    uLOO = LeaveOneOut(u[:, None]).__iter__()\n    ival = 0\n    S2 = 0\n    for (i, X_not_i) in enumerate(XLOO):\n        u_j = next(uLOO)\n        u_j = np.squeeze(u_j)\n        K = gpke(self.bw, data=-X_not_i, data_predict=-self.exog[i, :], var_type=self.var_type, tosum=False)\n        f_i = u[i] * u_j * K\n        assert u_j.shape == K.shape\n        ival += f_i.sum()\n        S2 += (f_i ** 2).sum()\n        assert np.size(ival) == 1\n        assert np.size(S2) == 1\n    ival *= 1.0 / (n * (n - 1))\n    ix_cont = _get_type_pos(self.var_type)[0]\n    hp = self.bw[ix_cont].prod()\n    S2 *= 2 * hp / (n * (n - 1))\n    T = n * ival * np.sqrt(hp / S2)\n    return T"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, var_type):\n    self.var_type = var_type\n    self.K = len(var_type)\n    self.var_type = self.var_type[0]\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, self.K)\n    self.nobs = np.shape(self.exog)[0]\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
        "mutated": [
            "def __init__(self, endog, exog, var_type):\n    if False:\n        i = 10\n    self.var_type = var_type\n    self.K = len(var_type)\n    self.var_type = self.var_type[0]\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, self.K)\n    self.nobs = np.shape(self.exog)[0]\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, var_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.var_type = var_type\n    self.K = len(var_type)\n    self.var_type = self.var_type[0]\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, self.K)\n    self.nobs = np.shape(self.exog)[0]\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, var_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.var_type = var_type\n    self.K = len(var_type)\n    self.var_type = self.var_type[0]\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, self.K)\n    self.nobs = np.shape(self.exog)[0]\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, var_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.var_type = var_type\n    self.K = len(var_type)\n    self.var_type = self.var_type[0]\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, self.K)\n    self.nobs = np.shape(self.exog)[0]\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, var_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.var_type = var_type\n    self.K = len(var_type)\n    self.var_type = self.var_type[0]\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, self.K)\n    self.nobs = np.shape(self.exog)[0]\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()"
        ]
    },
    {
        "func_name": "_est_b_bw",
        "original": "def _est_b_bw(self):\n    params0 = np.random.uniform(size=(self.K + 1,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.K]\n    bw = b_bw[self.K:]\n    bw = self._set_bw_bounds(bw)\n    return (b, bw)",
        "mutated": [
            "def _est_b_bw(self):\n    if False:\n        i = 10\n    params0 = np.random.uniform(size=(self.K + 1,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.K]\n    bw = b_bw[self.K:]\n    bw = self._set_bw_bounds(bw)\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    params0 = np.random.uniform(size=(self.K + 1,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.K]\n    bw = b_bw[self.K:]\n    bw = self._set_bw_bounds(bw)\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    params0 = np.random.uniform(size=(self.K + 1,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.K]\n    bw = b_bw[self.K:]\n    bw = self._set_bw_bounds(bw)\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    params0 = np.random.uniform(size=(self.K + 1,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.K]\n    bw = b_bw[self.K:]\n    bw = self._set_bw_bounds(bw)\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    params0 = np.random.uniform(size=(self.K + 1,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.K]\n    bw = b_bw[self.K:]\n    bw = self._set_bw_bounds(bw)\n    return (b, bw)"
        ]
    },
    {
        "func_name": "cv_loo",
        "original": "def cv_loo(self, params):\n    params = np.asarray(params)\n    b = params[0:self.K]\n    bw = params[self.K:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    L = 0\n    for (i, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        G = self.func(bw, endog=Y, exog=-np.dot(X_not_i, b)[:, None], data_predict=-np.dot(self.exog[i:i + 1, :], b))[0]\n        L += (self.endog[i] - G) ** 2\n    return L / self.nobs",
        "mutated": [
            "def cv_loo(self, params):\n    if False:\n        i = 10\n    params = np.asarray(params)\n    b = params[0:self.K]\n    bw = params[self.K:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    L = 0\n    for (i, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        G = self.func(bw, endog=Y, exog=-np.dot(X_not_i, b)[:, None], data_predict=-np.dot(self.exog[i:i + 1, :], b))[0]\n        L += (self.endog[i] - G) ** 2\n    return L / self.nobs",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    params = np.asarray(params)\n    b = params[0:self.K]\n    bw = params[self.K:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    L = 0\n    for (i, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        G = self.func(bw, endog=Y, exog=-np.dot(X_not_i, b)[:, None], data_predict=-np.dot(self.exog[i:i + 1, :], b))[0]\n        L += (self.endog[i] - G) ** 2\n    return L / self.nobs",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    params = np.asarray(params)\n    b = params[0:self.K]\n    bw = params[self.K:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    L = 0\n    for (i, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        G = self.func(bw, endog=Y, exog=-np.dot(X_not_i, b)[:, None], data_predict=-np.dot(self.exog[i:i + 1, :], b))[0]\n        L += (self.endog[i] - G) ** 2\n    return L / self.nobs",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    params = np.asarray(params)\n    b = params[0:self.K]\n    bw = params[self.K:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    L = 0\n    for (i, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        G = self.func(bw, endog=Y, exog=-np.dot(X_not_i, b)[:, None], data_predict=-np.dot(self.exog[i:i + 1, :], b))[0]\n        L += (self.endog[i] - G) ** 2\n    return L / self.nobs",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    params = np.asarray(params)\n    b = params[0:self.K]\n    bw = params[self.K:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    L = 0\n    for (i, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        G = self.func(bw, endog=Y, exog=-np.dot(X_not_i, b)[:, None], data_predict=-np.dot(self.exog[i:i + 1, :], b))[0]\n        L += (self.endog[i] - G) ** 2\n    return L / self.nobs"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, data_predict=None):\n    if data_predict is None:\n        data_predict = self.exog\n    else:\n        data_predict = _adjust_shape(data_predict, self.K)\n    N_data_predict = np.shape(data_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, self.endog, np.dot(self.exog, self.b)[:, None], data_predict=np.dot(data_predict[i:i + 1, :], self.b))\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
        "mutated": [
            "def fit(self, data_predict=None):\n    if False:\n        i = 10\n    if data_predict is None:\n        data_predict = self.exog\n    else:\n        data_predict = _adjust_shape(data_predict, self.K)\n    N_data_predict = np.shape(data_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, self.endog, np.dot(self.exog, self.b)[:, None], data_predict=np.dot(data_predict[i:i + 1, :], self.b))\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, data_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if data_predict is None:\n        data_predict = self.exog\n    else:\n        data_predict = _adjust_shape(data_predict, self.K)\n    N_data_predict = np.shape(data_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, self.endog, np.dot(self.exog, self.b)[:, None], data_predict=np.dot(data_predict[i:i + 1, :], self.b))\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, data_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if data_predict is None:\n        data_predict = self.exog\n    else:\n        data_predict = _adjust_shape(data_predict, self.K)\n    N_data_predict = np.shape(data_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, self.endog, np.dot(self.exog, self.b)[:, None], data_predict=np.dot(data_predict[i:i + 1, :], self.b))\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, data_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if data_predict is None:\n        data_predict = self.exog\n    else:\n        data_predict = _adjust_shape(data_predict, self.K)\n    N_data_predict = np.shape(data_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, self.endog, np.dot(self.exog, self.b)[:, None], data_predict=np.dot(data_predict[i:i + 1, :], self.b))\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, data_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if data_predict is None:\n        data_predict = self.exog\n    else:\n        data_predict = _adjust_shape(data_predict, self.K)\n    N_data_predict = np.shape(data_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, self.endog, np.dot(self.exog, self.b)[:, None], data_predict=np.dot(data_predict[i:i + 1, :], self.b))\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)"
        ]
    },
    {
        "func_name": "__repr__",
        "original": "def __repr__(self):\n    \"\"\"Provide something sane to print.\"\"\"\n    repr = 'Single Index Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   nobs = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
        "mutated": [
            "def __repr__(self):\n    if False:\n        i = 10\n    'Provide something sane to print.'\n    repr = 'Single Index Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   nobs = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Provide something sane to print.'\n    repr = 'Single Index Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   nobs = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Provide something sane to print.'\n    repr = 'Single Index Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   nobs = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Provide something sane to print.'\n    repr = 'Single Index Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   nobs = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Provide something sane to print.'\n    repr = 'Single Index Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   nobs = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, exog_nonparametric, var_type, k_linear):\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, k_linear)\n    self.K = len(var_type)\n    self.exog_nonparametric = _adjust_shape(exog_nonparametric, self.K)\n    self.k_linear = k_linear\n    self.nobs = np.shape(self.exog)[0]\n    self.var_type = var_type\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
        "mutated": [
            "def __init__(self, endog, exog, exog_nonparametric, var_type, k_linear):\n    if False:\n        i = 10\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, k_linear)\n    self.K = len(var_type)\n    self.exog_nonparametric = _adjust_shape(exog_nonparametric, self.K)\n    self.k_linear = k_linear\n    self.nobs = np.shape(self.exog)[0]\n    self.var_type = var_type\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, exog_nonparametric, var_type, k_linear):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, k_linear)\n    self.K = len(var_type)\n    self.exog_nonparametric = _adjust_shape(exog_nonparametric, self.K)\n    self.k_linear = k_linear\n    self.nobs = np.shape(self.exog)[0]\n    self.var_type = var_type\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, exog_nonparametric, var_type, k_linear):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, k_linear)\n    self.K = len(var_type)\n    self.exog_nonparametric = _adjust_shape(exog_nonparametric, self.K)\n    self.k_linear = k_linear\n    self.nobs = np.shape(self.exog)[0]\n    self.var_type = var_type\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, exog_nonparametric, var_type, k_linear):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, k_linear)\n    self.K = len(var_type)\n    self.exog_nonparametric = _adjust_shape(exog_nonparametric, self.K)\n    self.k_linear = k_linear\n    self.nobs = np.shape(self.exog)[0]\n    self.var_type = var_type\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()",
            "def __init__(self, endog, exog, exog_nonparametric, var_type, k_linear):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.endog = _adjust_shape(endog, 1)\n    self.exog = _adjust_shape(exog, k_linear)\n    self.K = len(var_type)\n    self.exog_nonparametric = _adjust_shape(exog_nonparametric, self.K)\n    self.k_linear = k_linear\n    self.nobs = np.shape(self.exog)[0]\n    self.var_type = var_type\n    self.data_type = self.var_type\n    self.ckertype = 'gaussian'\n    self.okertype = 'wangryzin'\n    self.ukertype = 'aitchisonaitken'\n    self.func = self._est_loc_linear\n    (self.b, self.bw) = self._est_b_bw()"
        ]
    },
    {
        "func_name": "_est_b_bw",
        "original": "def _est_b_bw(self):\n    \"\"\"\n        Computes the (beta) coefficients and the bandwidths.\n\n        Minimizes ``cv_loo`` with respect to ``b`` and ``bw``.\n        \"\"\"\n    params0 = np.random.uniform(size=(self.k_linear + self.K,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.k_linear]\n    bw = b_bw[self.k_linear:]\n    return (b, bw)",
        "mutated": [
            "def _est_b_bw(self):\n    if False:\n        i = 10\n    '\\n        Computes the (beta) coefficients and the bandwidths.\\n\\n        Minimizes ``cv_loo`` with respect to ``b`` and ``bw``.\\n        '\n    params0 = np.random.uniform(size=(self.k_linear + self.K,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.k_linear]\n    bw = b_bw[self.k_linear:]\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Computes the (beta) coefficients and the bandwidths.\\n\\n        Minimizes ``cv_loo`` with respect to ``b`` and ``bw``.\\n        '\n    params0 = np.random.uniform(size=(self.k_linear + self.K,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.k_linear]\n    bw = b_bw[self.k_linear:]\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Computes the (beta) coefficients and the bandwidths.\\n\\n        Minimizes ``cv_loo`` with respect to ``b`` and ``bw``.\\n        '\n    params0 = np.random.uniform(size=(self.k_linear + self.K,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.k_linear]\n    bw = b_bw[self.k_linear:]\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Computes the (beta) coefficients and the bandwidths.\\n\\n        Minimizes ``cv_loo`` with respect to ``b`` and ``bw``.\\n        '\n    params0 = np.random.uniform(size=(self.k_linear + self.K,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.k_linear]\n    bw = b_bw[self.k_linear:]\n    return (b, bw)",
            "def _est_b_bw(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Computes the (beta) coefficients and the bandwidths.\\n\\n        Minimizes ``cv_loo`` with respect to ``b`` and ``bw``.\\n        '\n    params0 = np.random.uniform(size=(self.k_linear + self.K,))\n    b_bw = optimize.fmin(self.cv_loo, params0, disp=0)\n    b = b_bw[0:self.k_linear]\n    bw = b_bw[self.k_linear:]\n    return (b, bw)"
        ]
    },
    {
        "func_name": "cv_loo",
        "original": "def cv_loo(self, params):\n    \"\"\"\n        Similar to the cross validation leave-one-out estimator.\n\n        Modified to reflect the linear components.\n\n        Parameters\n        ----------\n        params : array_like\n            Vector consisting of the coefficients (b) and the bandwidths (bw).\n            The first ``k_linear`` elements are the coefficients.\n\n        Returns\n        -------\n        L : float\n            The value of the objective function\n\n        References\n        ----------\n        See p.254 in [1]\n        \"\"\"\n    params = np.asarray(params)\n    b = params[0:self.k_linear]\n    bw = params[self.k_linear:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    LOO_Z = LeaveOneOut(self.exog_nonparametric).__iter__()\n    Xb = np.dot(self.exog, b)[:, None]\n    L = 0\n    for (ii, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        Z = next(LOO_Z)\n        Xb_j = np.dot(X_not_i, b)[:, None]\n        Yx = Y - Xb_j\n        G = self.func(bw, endog=Yx, exog=-Z, data_predict=-self.exog_nonparametric[ii, :])[0]\n        lt = Xb[ii, :]\n        L += (self.endog[ii] - lt - G) ** 2\n    return L",
        "mutated": [
            "def cv_loo(self, params):\n    if False:\n        i = 10\n    '\\n        Similar to the cross validation leave-one-out estimator.\\n\\n        Modified to reflect the linear components.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Vector consisting of the coefficients (b) and the bandwidths (bw).\\n            The first ``k_linear`` elements are the coefficients.\\n\\n        Returns\\n        -------\\n        L : float\\n            The value of the objective function\\n\\n        References\\n        ----------\\n        See p.254 in [1]\\n        '\n    params = np.asarray(params)\n    b = params[0:self.k_linear]\n    bw = params[self.k_linear:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    LOO_Z = LeaveOneOut(self.exog_nonparametric).__iter__()\n    Xb = np.dot(self.exog, b)[:, None]\n    L = 0\n    for (ii, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        Z = next(LOO_Z)\n        Xb_j = np.dot(X_not_i, b)[:, None]\n        Yx = Y - Xb_j\n        G = self.func(bw, endog=Yx, exog=-Z, data_predict=-self.exog_nonparametric[ii, :])[0]\n        lt = Xb[ii, :]\n        L += (self.endog[ii] - lt - G) ** 2\n    return L",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Similar to the cross validation leave-one-out estimator.\\n\\n        Modified to reflect the linear components.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Vector consisting of the coefficients (b) and the bandwidths (bw).\\n            The first ``k_linear`` elements are the coefficients.\\n\\n        Returns\\n        -------\\n        L : float\\n            The value of the objective function\\n\\n        References\\n        ----------\\n        See p.254 in [1]\\n        '\n    params = np.asarray(params)\n    b = params[0:self.k_linear]\n    bw = params[self.k_linear:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    LOO_Z = LeaveOneOut(self.exog_nonparametric).__iter__()\n    Xb = np.dot(self.exog, b)[:, None]\n    L = 0\n    for (ii, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        Z = next(LOO_Z)\n        Xb_j = np.dot(X_not_i, b)[:, None]\n        Yx = Y - Xb_j\n        G = self.func(bw, endog=Yx, exog=-Z, data_predict=-self.exog_nonparametric[ii, :])[0]\n        lt = Xb[ii, :]\n        L += (self.endog[ii] - lt - G) ** 2\n    return L",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Similar to the cross validation leave-one-out estimator.\\n\\n        Modified to reflect the linear components.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Vector consisting of the coefficients (b) and the bandwidths (bw).\\n            The first ``k_linear`` elements are the coefficients.\\n\\n        Returns\\n        -------\\n        L : float\\n            The value of the objective function\\n\\n        References\\n        ----------\\n        See p.254 in [1]\\n        '\n    params = np.asarray(params)\n    b = params[0:self.k_linear]\n    bw = params[self.k_linear:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    LOO_Z = LeaveOneOut(self.exog_nonparametric).__iter__()\n    Xb = np.dot(self.exog, b)[:, None]\n    L = 0\n    for (ii, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        Z = next(LOO_Z)\n        Xb_j = np.dot(X_not_i, b)[:, None]\n        Yx = Y - Xb_j\n        G = self.func(bw, endog=Yx, exog=-Z, data_predict=-self.exog_nonparametric[ii, :])[0]\n        lt = Xb[ii, :]\n        L += (self.endog[ii] - lt - G) ** 2\n    return L",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Similar to the cross validation leave-one-out estimator.\\n\\n        Modified to reflect the linear components.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Vector consisting of the coefficients (b) and the bandwidths (bw).\\n            The first ``k_linear`` elements are the coefficients.\\n\\n        Returns\\n        -------\\n        L : float\\n            The value of the objective function\\n\\n        References\\n        ----------\\n        See p.254 in [1]\\n        '\n    params = np.asarray(params)\n    b = params[0:self.k_linear]\n    bw = params[self.k_linear:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    LOO_Z = LeaveOneOut(self.exog_nonparametric).__iter__()\n    Xb = np.dot(self.exog, b)[:, None]\n    L = 0\n    for (ii, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        Z = next(LOO_Z)\n        Xb_j = np.dot(X_not_i, b)[:, None]\n        Yx = Y - Xb_j\n        G = self.func(bw, endog=Yx, exog=-Z, data_predict=-self.exog_nonparametric[ii, :])[0]\n        lt = Xb[ii, :]\n        L += (self.endog[ii] - lt - G) ** 2\n    return L",
            "def cv_loo(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Similar to the cross validation leave-one-out estimator.\\n\\n        Modified to reflect the linear components.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Vector consisting of the coefficients (b) and the bandwidths (bw).\\n            The first ``k_linear`` elements are the coefficients.\\n\\n        Returns\\n        -------\\n        L : float\\n            The value of the objective function\\n\\n        References\\n        ----------\\n        See p.254 in [1]\\n        '\n    params = np.asarray(params)\n    b = params[0:self.k_linear]\n    bw = params[self.k_linear:]\n    LOO_X = LeaveOneOut(self.exog)\n    LOO_Y = LeaveOneOut(self.endog).__iter__()\n    LOO_Z = LeaveOneOut(self.exog_nonparametric).__iter__()\n    Xb = np.dot(self.exog, b)[:, None]\n    L = 0\n    for (ii, X_not_i) in enumerate(LOO_X):\n        Y = next(LOO_Y)\n        Z = next(LOO_Z)\n        Xb_j = np.dot(X_not_i, b)[:, None]\n        Yx = Y - Xb_j\n        G = self.func(bw, endog=Yx, exog=-Z, data_predict=-self.exog_nonparametric[ii, :])[0]\n        lt = Xb[ii, :]\n        L += (self.endog[ii] - lt - G) ** 2\n    return L"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, exog_predict=None, exog_nonparametric_predict=None):\n    \"\"\"Computes fitted values and marginal effects\"\"\"\n    if exog_predict is None:\n        exog_predict = self.exog\n    else:\n        exog_predict = _adjust_shape(exog_predict, self.k_linear)\n    if exog_nonparametric_predict is None:\n        exog_nonparametric_predict = self.exog_nonparametric\n    else:\n        exog_nonparametric_predict = _adjust_shape(exog_nonparametric_predict, self.K)\n    N_data_predict = np.shape(exog_nonparametric_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    Y = self.endog - np.dot(exog_predict, self.b)[:, None]\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, Y, self.exog_nonparametric, data_predict=exog_nonparametric_predict[i, :])\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
        "mutated": [
            "def fit(self, exog_predict=None, exog_nonparametric_predict=None):\n    if False:\n        i = 10\n    'Computes fitted values and marginal effects'\n    if exog_predict is None:\n        exog_predict = self.exog\n    else:\n        exog_predict = _adjust_shape(exog_predict, self.k_linear)\n    if exog_nonparametric_predict is None:\n        exog_nonparametric_predict = self.exog_nonparametric\n    else:\n        exog_nonparametric_predict = _adjust_shape(exog_nonparametric_predict, self.K)\n    N_data_predict = np.shape(exog_nonparametric_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    Y = self.endog - np.dot(exog_predict, self.b)[:, None]\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, Y, self.exog_nonparametric, data_predict=exog_nonparametric_predict[i, :])\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, exog_predict=None, exog_nonparametric_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Computes fitted values and marginal effects'\n    if exog_predict is None:\n        exog_predict = self.exog\n    else:\n        exog_predict = _adjust_shape(exog_predict, self.k_linear)\n    if exog_nonparametric_predict is None:\n        exog_nonparametric_predict = self.exog_nonparametric\n    else:\n        exog_nonparametric_predict = _adjust_shape(exog_nonparametric_predict, self.K)\n    N_data_predict = np.shape(exog_nonparametric_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    Y = self.endog - np.dot(exog_predict, self.b)[:, None]\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, Y, self.exog_nonparametric, data_predict=exog_nonparametric_predict[i, :])\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, exog_predict=None, exog_nonparametric_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Computes fitted values and marginal effects'\n    if exog_predict is None:\n        exog_predict = self.exog\n    else:\n        exog_predict = _adjust_shape(exog_predict, self.k_linear)\n    if exog_nonparametric_predict is None:\n        exog_nonparametric_predict = self.exog_nonparametric\n    else:\n        exog_nonparametric_predict = _adjust_shape(exog_nonparametric_predict, self.K)\n    N_data_predict = np.shape(exog_nonparametric_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    Y = self.endog - np.dot(exog_predict, self.b)[:, None]\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, Y, self.exog_nonparametric, data_predict=exog_nonparametric_predict[i, :])\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, exog_predict=None, exog_nonparametric_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Computes fitted values and marginal effects'\n    if exog_predict is None:\n        exog_predict = self.exog\n    else:\n        exog_predict = _adjust_shape(exog_predict, self.k_linear)\n    if exog_nonparametric_predict is None:\n        exog_nonparametric_predict = self.exog_nonparametric\n    else:\n        exog_nonparametric_predict = _adjust_shape(exog_nonparametric_predict, self.K)\n    N_data_predict = np.shape(exog_nonparametric_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    Y = self.endog - np.dot(exog_predict, self.b)[:, None]\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, Y, self.exog_nonparametric, data_predict=exog_nonparametric_predict[i, :])\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)",
            "def fit(self, exog_predict=None, exog_nonparametric_predict=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Computes fitted values and marginal effects'\n    if exog_predict is None:\n        exog_predict = self.exog\n    else:\n        exog_predict = _adjust_shape(exog_predict, self.k_linear)\n    if exog_nonparametric_predict is None:\n        exog_nonparametric_predict = self.exog_nonparametric\n    else:\n        exog_nonparametric_predict = _adjust_shape(exog_nonparametric_predict, self.K)\n    N_data_predict = np.shape(exog_nonparametric_predict)[0]\n    mean = np.empty((N_data_predict,))\n    mfx = np.empty((N_data_predict, self.K))\n    Y = self.endog - np.dot(exog_predict, self.b)[:, None]\n    for i in range(N_data_predict):\n        mean_mfx = self.func(self.bw, Y, self.exog_nonparametric, data_predict=exog_nonparametric_predict[i, :])\n        mean[i] = mean_mfx[0]\n        mfx_c = np.squeeze(mean_mfx[1])\n        mfx[i, :] = mfx_c\n    return (mean, mfx)"
        ]
    },
    {
        "func_name": "__repr__",
        "original": "def __repr__(self):\n    \"\"\"Provide something sane to print.\"\"\"\n    repr = 'Semiparamatric Partially Linear Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   N = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
        "mutated": [
            "def __repr__(self):\n    if False:\n        i = 10\n    'Provide something sane to print.'\n    repr = 'Semiparamatric Partially Linear Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   N = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Provide something sane to print.'\n    repr = 'Semiparamatric Partially Linear Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   N = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Provide something sane to print.'\n    repr = 'Semiparamatric Partially Linear Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   N = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Provide something sane to print.'\n    repr = 'Semiparamatric Partially Linear Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   N = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Provide something sane to print.'\n    repr = 'Semiparamatric Partially Linear Model \\n'\n    repr += 'Number of variables: K = ' + str(self.K) + '\\n'\n    repr += 'Number of samples:   N = ' + str(self.nobs) + '\\n'\n    repr += 'Variable types:      ' + self.var_type + '\\n'\n    repr += 'BW selection method: cv_ls' + '\\n'\n    repr += 'Estimator type: local constant' + '\\n'\n    return repr"
        ]
    }
]