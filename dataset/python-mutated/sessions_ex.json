[
    {
        "func_name": "__get_sql_operator",
        "original": "def __get_sql_operator(op: schemas.SearchEventOperator):\n    return {schemas.SearchEventOperator._is: '=', schemas.SearchEventOperator._is_any: 'IN', schemas.SearchEventOperator._on: '=', schemas.SearchEventOperator._on_any: 'IN', schemas.SearchEventOperator._is_not: '!=', schemas.SearchEventOperator._not_on: '!=', schemas.SearchEventOperator._contains: 'ILIKE', schemas.SearchEventOperator._not_contains: 'NOT ILIKE', schemas.SearchEventOperator._starts_with: 'ILIKE', schemas.SearchEventOperator._ends_with: 'ILIKE'}.get(op, '=')",
        "mutated": [
            "def __get_sql_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n    return {schemas.SearchEventOperator._is: '=', schemas.SearchEventOperator._is_any: 'IN', schemas.SearchEventOperator._on: '=', schemas.SearchEventOperator._on_any: 'IN', schemas.SearchEventOperator._is_not: '!=', schemas.SearchEventOperator._not_on: '!=', schemas.SearchEventOperator._contains: 'ILIKE', schemas.SearchEventOperator._not_contains: 'NOT ILIKE', schemas.SearchEventOperator._starts_with: 'ILIKE', schemas.SearchEventOperator._ends_with: 'ILIKE'}.get(op, '=')",
            "def __get_sql_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return {schemas.SearchEventOperator._is: '=', schemas.SearchEventOperator._is_any: 'IN', schemas.SearchEventOperator._on: '=', schemas.SearchEventOperator._on_any: 'IN', schemas.SearchEventOperator._is_not: '!=', schemas.SearchEventOperator._not_on: '!=', schemas.SearchEventOperator._contains: 'ILIKE', schemas.SearchEventOperator._not_contains: 'NOT ILIKE', schemas.SearchEventOperator._starts_with: 'ILIKE', schemas.SearchEventOperator._ends_with: 'ILIKE'}.get(op, '=')",
            "def __get_sql_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return {schemas.SearchEventOperator._is: '=', schemas.SearchEventOperator._is_any: 'IN', schemas.SearchEventOperator._on: '=', schemas.SearchEventOperator._on_any: 'IN', schemas.SearchEventOperator._is_not: '!=', schemas.SearchEventOperator._not_on: '!=', schemas.SearchEventOperator._contains: 'ILIKE', schemas.SearchEventOperator._not_contains: 'NOT ILIKE', schemas.SearchEventOperator._starts_with: 'ILIKE', schemas.SearchEventOperator._ends_with: 'ILIKE'}.get(op, '=')",
            "def __get_sql_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return {schemas.SearchEventOperator._is: '=', schemas.SearchEventOperator._is_any: 'IN', schemas.SearchEventOperator._on: '=', schemas.SearchEventOperator._on_any: 'IN', schemas.SearchEventOperator._is_not: '!=', schemas.SearchEventOperator._not_on: '!=', schemas.SearchEventOperator._contains: 'ILIKE', schemas.SearchEventOperator._not_contains: 'NOT ILIKE', schemas.SearchEventOperator._starts_with: 'ILIKE', schemas.SearchEventOperator._ends_with: 'ILIKE'}.get(op, '=')",
            "def __get_sql_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return {schemas.SearchEventOperator._is: '=', schemas.SearchEventOperator._is_any: 'IN', schemas.SearchEventOperator._on: '=', schemas.SearchEventOperator._on_any: 'IN', schemas.SearchEventOperator._is_not: '!=', schemas.SearchEventOperator._not_on: '!=', schemas.SearchEventOperator._contains: 'ILIKE', schemas.SearchEventOperator._not_contains: 'NOT ILIKE', schemas.SearchEventOperator._starts_with: 'ILIKE', schemas.SearchEventOperator._ends_with: 'ILIKE'}.get(op, '=')"
        ]
    },
    {
        "func_name": "__is_negation_operator",
        "original": "def __is_negation_operator(op: schemas.SearchEventOperator):\n    return op in [schemas.SearchEventOperator._is_not, schemas.SearchEventOperator._not_on, schemas.SearchEventOperator._not_contains]",
        "mutated": [
            "def __is_negation_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n    return op in [schemas.SearchEventOperator._is_not, schemas.SearchEventOperator._not_on, schemas.SearchEventOperator._not_contains]",
            "def __is_negation_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return op in [schemas.SearchEventOperator._is_not, schemas.SearchEventOperator._not_on, schemas.SearchEventOperator._not_contains]",
            "def __is_negation_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return op in [schemas.SearchEventOperator._is_not, schemas.SearchEventOperator._not_on, schemas.SearchEventOperator._not_contains]",
            "def __is_negation_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return op in [schemas.SearchEventOperator._is_not, schemas.SearchEventOperator._not_on, schemas.SearchEventOperator._not_contains]",
            "def __is_negation_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return op in [schemas.SearchEventOperator._is_not, schemas.SearchEventOperator._not_on, schemas.SearchEventOperator._not_contains]"
        ]
    },
    {
        "func_name": "__reverse_sql_operator",
        "original": "def __reverse_sql_operator(op):\n    return '=' if op == '!=' else '!=' if op == '=' else 'ILIKE' if op == 'NOT ILIKE' else 'NOT ILIKE'",
        "mutated": [
            "def __reverse_sql_operator(op):\n    if False:\n        i = 10\n    return '=' if op == '!=' else '!=' if op == '=' else 'ILIKE' if op == 'NOT ILIKE' else 'NOT ILIKE'",
            "def __reverse_sql_operator(op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return '=' if op == '!=' else '!=' if op == '=' else 'ILIKE' if op == 'NOT ILIKE' else 'NOT ILIKE'",
            "def __reverse_sql_operator(op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return '=' if op == '!=' else '!=' if op == '=' else 'ILIKE' if op == 'NOT ILIKE' else 'NOT ILIKE'",
            "def __reverse_sql_operator(op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return '=' if op == '!=' else '!=' if op == '=' else 'ILIKE' if op == 'NOT ILIKE' else 'NOT ILIKE'",
            "def __reverse_sql_operator(op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return '=' if op == '!=' else '!=' if op == '=' else 'ILIKE' if op == 'NOT ILIKE' else 'NOT ILIKE'"
        ]
    },
    {
        "func_name": "_multiple_conditions",
        "original": "def _multiple_conditions(condition, values, value_key='value', is_not=False):\n    query = []\n    for i in range(len(values)):\n        k = f'{value_key}_{i}'\n        query.append(condition.replace(value_key, k))\n    return '(' + (' AND ' if is_not else ' OR ').join(query) + ')'",
        "mutated": [
            "def _multiple_conditions(condition, values, value_key='value', is_not=False):\n    if False:\n        i = 10\n    query = []\n    for i in range(len(values)):\n        k = f'{value_key}_{i}'\n        query.append(condition.replace(value_key, k))\n    return '(' + (' AND ' if is_not else ' OR ').join(query) + ')'",
            "def _multiple_conditions(condition, values, value_key='value', is_not=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    query = []\n    for i in range(len(values)):\n        k = f'{value_key}_{i}'\n        query.append(condition.replace(value_key, k))\n    return '(' + (' AND ' if is_not else ' OR ').join(query) + ')'",
            "def _multiple_conditions(condition, values, value_key='value', is_not=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    query = []\n    for i in range(len(values)):\n        k = f'{value_key}_{i}'\n        query.append(condition.replace(value_key, k))\n    return '(' + (' AND ' if is_not else ' OR ').join(query) + ')'",
            "def _multiple_conditions(condition, values, value_key='value', is_not=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    query = []\n    for i in range(len(values)):\n        k = f'{value_key}_{i}'\n        query.append(condition.replace(value_key, k))\n    return '(' + (' AND ' if is_not else ' OR ').join(query) + ')'",
            "def _multiple_conditions(condition, values, value_key='value', is_not=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    query = []\n    for i in range(len(values)):\n        k = f'{value_key}_{i}'\n        query.append(condition.replace(value_key, k))\n    return '(' + (' AND ' if is_not else ' OR ').join(query) + ')'"
        ]
    },
    {
        "func_name": "_multiple_values",
        "original": "def _multiple_values(values, value_key='value'):\n    query_values = {}\n    if values is not None and isinstance(values, list):\n        for i in range(len(values)):\n            k = f'{value_key}_{i}'\n            query_values[k] = values[i]\n    return query_values",
        "mutated": [
            "def _multiple_values(values, value_key='value'):\n    if False:\n        i = 10\n    query_values = {}\n    if values is not None and isinstance(values, list):\n        for i in range(len(values)):\n            k = f'{value_key}_{i}'\n            query_values[k] = values[i]\n    return query_values",
            "def _multiple_values(values, value_key='value'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    query_values = {}\n    if values is not None and isinstance(values, list):\n        for i in range(len(values)):\n            k = f'{value_key}_{i}'\n            query_values[k] = values[i]\n    return query_values",
            "def _multiple_values(values, value_key='value'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    query_values = {}\n    if values is not None and isinstance(values, list):\n        for i in range(len(values)):\n            k = f'{value_key}_{i}'\n            query_values[k] = values[i]\n    return query_values",
            "def _multiple_values(values, value_key='value'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    query_values = {}\n    if values is not None and isinstance(values, list):\n        for i in range(len(values)):\n            k = f'{value_key}_{i}'\n            query_values[k] = values[i]\n    return query_values",
            "def _multiple_values(values, value_key='value'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    query_values = {}\n    if values is not None and isinstance(values, list):\n        for i in range(len(values)):\n            k = f'{value_key}_{i}'\n            query_values[k] = values[i]\n    return query_values"
        ]
    },
    {
        "func_name": "_isAny_opreator",
        "original": "def _isAny_opreator(op: schemas.SearchEventOperator):\n    return op in [schemas.SearchEventOperator._on_any, schemas.SearchEventOperator._is_any]",
        "mutated": [
            "def _isAny_opreator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n    return op in [schemas.SearchEventOperator._on_any, schemas.SearchEventOperator._is_any]",
            "def _isAny_opreator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return op in [schemas.SearchEventOperator._on_any, schemas.SearchEventOperator._is_any]",
            "def _isAny_opreator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return op in [schemas.SearchEventOperator._on_any, schemas.SearchEventOperator._is_any]",
            "def _isAny_opreator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return op in [schemas.SearchEventOperator._on_any, schemas.SearchEventOperator._is_any]",
            "def _isAny_opreator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return op in [schemas.SearchEventOperator._on_any, schemas.SearchEventOperator._is_any]"
        ]
    },
    {
        "func_name": "_isUndefined_operator",
        "original": "def _isUndefined_operator(op: schemas.SearchEventOperator):\n    return op in [schemas.SearchEventOperator._is_undefined]",
        "mutated": [
            "def _isUndefined_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n    return op in [schemas.SearchEventOperator._is_undefined]",
            "def _isUndefined_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return op in [schemas.SearchEventOperator._is_undefined]",
            "def _isUndefined_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return op in [schemas.SearchEventOperator._is_undefined]",
            "def _isUndefined_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return op in [schemas.SearchEventOperator._is_undefined]",
            "def _isUndefined_operator(op: schemas.SearchEventOperator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return op in [schemas.SearchEventOperator._is_undefined]"
        ]
    },
    {
        "func_name": "search_sessions",
        "original": "def search_sessions(data: schemas.SessionsSearchPayloadSchema, project_id, user_id, errors_only=False, error_status=schemas.ErrorStatus.all, count_only=False, issue=None, ids_only=False, platform='web'):\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=error_status, errors_only=errors_only, favorite_only=data.bookmarked, issue=issue, project_id=project_id, user_id=user_id, platform=platform)\n    if data.sort == 'startTs':\n        data.sort = 'datetime'\n    if data.limit is not None and data.page is not None:\n        full_args['sessions_limit'] = data.limit\n        full_args['sessions_limit_s'] = (data.page - 1) * data.limit\n        full_args['sessions_limit_e'] = data.page * data.limit\n    else:\n        full_args['sessions_limit'] = 200\n        full_args['sessions_limit_s'] = 0\n        full_args['sessions_limit_e'] = 200\n    meta_keys = []\n    with ch_client.ClickHouseClient() as cur:\n        if errors_only:\n            main_query = cur.format(f'SELECT DISTINCT er.error_id,\\n                                        COALESCE((SELECT TRUE\\n                                                 FROM {exp_ch_helper.get_user_viewed_errors_table()} AS ve\\n                                                 WHERE er.error_id = ve.error_id\\n                                                   AND ve.user_id = %(userId)s LIMIT 1), FALSE) AS viewed\\n                                        {query_part};', full_args)\n        elif count_only:\n            main_query = cur.mogrify(f'SELECT COUNT(DISTINCT s.session_id) AS count_sessions, \\n                                                COUNT(DISTINCT s.user_uuid) AS count_users\\n                                        {query_part};', full_args)\n        elif data.group_by_user:\n            g_sort = 'count(full_sessions)'\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            if data.sort is not None and data.sort != 'sessionsCount':\n                sort = helper.key_to_snake_case(data.sort)\n                g_sort = f\"{('MIN' if data.order == schemas.SortOrderType.desc else 'MAX')}({sort})\"\n            else:\n                sort = 'start_ts'\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",map(%s) AS 'metadata'\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.mogrify(f\"SELECT COUNT(*) AS count,\\n                                                COALESCE(JSONB_AGG(users_sessions) \\n                                                    FILTER (WHERE rn>%(sessions_limit_s)s AND rn<=%(sessions_limit_e)s), '[]'::JSONB) AS sessions\\n                                        FROM (SELECT user_id,\\n                                                 count(full_sessions)                                   AS user_sessions_count,\\n                                                 jsonb_agg(full_sessions) FILTER (WHERE rn <= 1)        AS last_session,\\n                                                 MIN(full_sessions.start_ts)                            AS first_session_ts,\\n                                                 ROW_NUMBER() OVER (ORDER BY {g_sort} {data.order}) AS rn\\n                                            FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY {sort} {data.order}) AS rn \\n                                                FROM (SELECT DISTINCT ON(s.session_id) {SESSION_PROJECTION_COLS} {meta_map}\\n                                                    {query_part}\\n                                                    ) AS filtred_sessions\\n                                                ) AS full_sessions\\n                                                GROUP BY user_id\\n                                            ) AS users_sessions;\", full_args)\n        elif ids_only:\n            main_query = cur.format(f'SELECT DISTINCT ON(s.session_id) s.session_id\\n                                             {query_part}\\n                                             ORDER BY s.session_id desc\\n                                             LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s;', full_args)\n        else:\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            sort = 'session_id'\n            if data.sort is not None and data.sort != 'session_id':\n                sort = helper.key_to_snake_case(data.sort)\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",'metadata',toString(map(%s))\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.format(f'SELECT any(total) AS count, groupArray(%(sessions_limit)s)(details) AS sessions\\n                                        FROM (SELECT total, details\\n                                              FROM (SELECT COUNT() OVER () AS total,\\n                                                    s.{sort} AS sort_key,\\n                                                    map({SESSION_PROJECTION_COLS_CH_MAP}{meta_map}) AS details\\n                                                {query_part}\\n                                              LEFT JOIN (SELECT session_id\\n                                                FROM experimental.user_viewed_sessions\\n                                                WHERE user_id = %(userId)s AND project_id=%(project_id)s\\n                                                  AND _timestamp >= toDateTime(%(startDate)s / 1000)) AS viewed_sessions\\n                                               ON (viewed_sessions.session_id = s.session_id)\\n                                             ) AS raw\\n                                        ORDER BY sort_key {data.order}\\n                                        LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s) AS sorted_sessions;', full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        try:\n            sessions = cur.execute(main_query)\n        except Exception as err:\n            logging.warning('--------- SESSIONS-CH SEARCH QUERY EXCEPTION -----------')\n            logging.warning(main_query)\n            logging.warning('--------- PAYLOAD -----------')\n            logging.warning(data.model_dump_json())\n            logging.warning('--------------------')\n            raise err\n        if errors_only or ids_only:\n            return helper.list_to_camel_case(sessions)\n        if len(sessions) > 0:\n            sessions = sessions[0]\n        total = sessions['count']\n        sessions = sessions['sessions']\n    if data.group_by_user:\n        for (i, s) in enumerate(sessions):\n            sessions[i] = {**s.pop('last_session')[0], **s}\n            sessions[i].pop('rn')\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n    else:\n        for i in range(len(sessions)):\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n            sessions[i] = schemas.SessionModel.parse_obj(helper.dict_to_camel_case(sessions[i]))\n    return {'total': total, 'sessions': sessions}",
        "mutated": [
            "def search_sessions(data: schemas.SessionsSearchPayloadSchema, project_id, user_id, errors_only=False, error_status=schemas.ErrorStatus.all, count_only=False, issue=None, ids_only=False, platform='web'):\n    if False:\n        i = 10\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=error_status, errors_only=errors_only, favorite_only=data.bookmarked, issue=issue, project_id=project_id, user_id=user_id, platform=platform)\n    if data.sort == 'startTs':\n        data.sort = 'datetime'\n    if data.limit is not None and data.page is not None:\n        full_args['sessions_limit'] = data.limit\n        full_args['sessions_limit_s'] = (data.page - 1) * data.limit\n        full_args['sessions_limit_e'] = data.page * data.limit\n    else:\n        full_args['sessions_limit'] = 200\n        full_args['sessions_limit_s'] = 0\n        full_args['sessions_limit_e'] = 200\n    meta_keys = []\n    with ch_client.ClickHouseClient() as cur:\n        if errors_only:\n            main_query = cur.format(f'SELECT DISTINCT er.error_id,\\n                                        COALESCE((SELECT TRUE\\n                                                 FROM {exp_ch_helper.get_user_viewed_errors_table()} AS ve\\n                                                 WHERE er.error_id = ve.error_id\\n                                                   AND ve.user_id = %(userId)s LIMIT 1), FALSE) AS viewed\\n                                        {query_part};', full_args)\n        elif count_only:\n            main_query = cur.mogrify(f'SELECT COUNT(DISTINCT s.session_id) AS count_sessions, \\n                                                COUNT(DISTINCT s.user_uuid) AS count_users\\n                                        {query_part};', full_args)\n        elif data.group_by_user:\n            g_sort = 'count(full_sessions)'\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            if data.sort is not None and data.sort != 'sessionsCount':\n                sort = helper.key_to_snake_case(data.sort)\n                g_sort = f\"{('MIN' if data.order == schemas.SortOrderType.desc else 'MAX')}({sort})\"\n            else:\n                sort = 'start_ts'\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",map(%s) AS 'metadata'\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.mogrify(f\"SELECT COUNT(*) AS count,\\n                                                COALESCE(JSONB_AGG(users_sessions) \\n                                                    FILTER (WHERE rn>%(sessions_limit_s)s AND rn<=%(sessions_limit_e)s), '[]'::JSONB) AS sessions\\n                                        FROM (SELECT user_id,\\n                                                 count(full_sessions)                                   AS user_sessions_count,\\n                                                 jsonb_agg(full_sessions) FILTER (WHERE rn <= 1)        AS last_session,\\n                                                 MIN(full_sessions.start_ts)                            AS first_session_ts,\\n                                                 ROW_NUMBER() OVER (ORDER BY {g_sort} {data.order}) AS rn\\n                                            FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY {sort} {data.order}) AS rn \\n                                                FROM (SELECT DISTINCT ON(s.session_id) {SESSION_PROJECTION_COLS} {meta_map}\\n                                                    {query_part}\\n                                                    ) AS filtred_sessions\\n                                                ) AS full_sessions\\n                                                GROUP BY user_id\\n                                            ) AS users_sessions;\", full_args)\n        elif ids_only:\n            main_query = cur.format(f'SELECT DISTINCT ON(s.session_id) s.session_id\\n                                             {query_part}\\n                                             ORDER BY s.session_id desc\\n                                             LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s;', full_args)\n        else:\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            sort = 'session_id'\n            if data.sort is not None and data.sort != 'session_id':\n                sort = helper.key_to_snake_case(data.sort)\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",'metadata',toString(map(%s))\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.format(f'SELECT any(total) AS count, groupArray(%(sessions_limit)s)(details) AS sessions\\n                                        FROM (SELECT total, details\\n                                              FROM (SELECT COUNT() OVER () AS total,\\n                                                    s.{sort} AS sort_key,\\n                                                    map({SESSION_PROJECTION_COLS_CH_MAP}{meta_map}) AS details\\n                                                {query_part}\\n                                              LEFT JOIN (SELECT session_id\\n                                                FROM experimental.user_viewed_sessions\\n                                                WHERE user_id = %(userId)s AND project_id=%(project_id)s\\n                                                  AND _timestamp >= toDateTime(%(startDate)s / 1000)) AS viewed_sessions\\n                                               ON (viewed_sessions.session_id = s.session_id)\\n                                             ) AS raw\\n                                        ORDER BY sort_key {data.order}\\n                                        LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s) AS sorted_sessions;', full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        try:\n            sessions = cur.execute(main_query)\n        except Exception as err:\n            logging.warning('--------- SESSIONS-CH SEARCH QUERY EXCEPTION -----------')\n            logging.warning(main_query)\n            logging.warning('--------- PAYLOAD -----------')\n            logging.warning(data.model_dump_json())\n            logging.warning('--------------------')\n            raise err\n        if errors_only or ids_only:\n            return helper.list_to_camel_case(sessions)\n        if len(sessions) > 0:\n            sessions = sessions[0]\n        total = sessions['count']\n        sessions = sessions['sessions']\n    if data.group_by_user:\n        for (i, s) in enumerate(sessions):\n            sessions[i] = {**s.pop('last_session')[0], **s}\n            sessions[i].pop('rn')\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n    else:\n        for i in range(len(sessions)):\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n            sessions[i] = schemas.SessionModel.parse_obj(helper.dict_to_camel_case(sessions[i]))\n    return {'total': total, 'sessions': sessions}",
            "def search_sessions(data: schemas.SessionsSearchPayloadSchema, project_id, user_id, errors_only=False, error_status=schemas.ErrorStatus.all, count_only=False, issue=None, ids_only=False, platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=error_status, errors_only=errors_only, favorite_only=data.bookmarked, issue=issue, project_id=project_id, user_id=user_id, platform=platform)\n    if data.sort == 'startTs':\n        data.sort = 'datetime'\n    if data.limit is not None and data.page is not None:\n        full_args['sessions_limit'] = data.limit\n        full_args['sessions_limit_s'] = (data.page - 1) * data.limit\n        full_args['sessions_limit_e'] = data.page * data.limit\n    else:\n        full_args['sessions_limit'] = 200\n        full_args['sessions_limit_s'] = 0\n        full_args['sessions_limit_e'] = 200\n    meta_keys = []\n    with ch_client.ClickHouseClient() as cur:\n        if errors_only:\n            main_query = cur.format(f'SELECT DISTINCT er.error_id,\\n                                        COALESCE((SELECT TRUE\\n                                                 FROM {exp_ch_helper.get_user_viewed_errors_table()} AS ve\\n                                                 WHERE er.error_id = ve.error_id\\n                                                   AND ve.user_id = %(userId)s LIMIT 1), FALSE) AS viewed\\n                                        {query_part};', full_args)\n        elif count_only:\n            main_query = cur.mogrify(f'SELECT COUNT(DISTINCT s.session_id) AS count_sessions, \\n                                                COUNT(DISTINCT s.user_uuid) AS count_users\\n                                        {query_part};', full_args)\n        elif data.group_by_user:\n            g_sort = 'count(full_sessions)'\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            if data.sort is not None and data.sort != 'sessionsCount':\n                sort = helper.key_to_snake_case(data.sort)\n                g_sort = f\"{('MIN' if data.order == schemas.SortOrderType.desc else 'MAX')}({sort})\"\n            else:\n                sort = 'start_ts'\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",map(%s) AS 'metadata'\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.mogrify(f\"SELECT COUNT(*) AS count,\\n                                                COALESCE(JSONB_AGG(users_sessions) \\n                                                    FILTER (WHERE rn>%(sessions_limit_s)s AND rn<=%(sessions_limit_e)s), '[]'::JSONB) AS sessions\\n                                        FROM (SELECT user_id,\\n                                                 count(full_sessions)                                   AS user_sessions_count,\\n                                                 jsonb_agg(full_sessions) FILTER (WHERE rn <= 1)        AS last_session,\\n                                                 MIN(full_sessions.start_ts)                            AS first_session_ts,\\n                                                 ROW_NUMBER() OVER (ORDER BY {g_sort} {data.order}) AS rn\\n                                            FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY {sort} {data.order}) AS rn \\n                                                FROM (SELECT DISTINCT ON(s.session_id) {SESSION_PROJECTION_COLS} {meta_map}\\n                                                    {query_part}\\n                                                    ) AS filtred_sessions\\n                                                ) AS full_sessions\\n                                                GROUP BY user_id\\n                                            ) AS users_sessions;\", full_args)\n        elif ids_only:\n            main_query = cur.format(f'SELECT DISTINCT ON(s.session_id) s.session_id\\n                                             {query_part}\\n                                             ORDER BY s.session_id desc\\n                                             LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s;', full_args)\n        else:\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            sort = 'session_id'\n            if data.sort is not None and data.sort != 'session_id':\n                sort = helper.key_to_snake_case(data.sort)\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",'metadata',toString(map(%s))\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.format(f'SELECT any(total) AS count, groupArray(%(sessions_limit)s)(details) AS sessions\\n                                        FROM (SELECT total, details\\n                                              FROM (SELECT COUNT() OVER () AS total,\\n                                                    s.{sort} AS sort_key,\\n                                                    map({SESSION_PROJECTION_COLS_CH_MAP}{meta_map}) AS details\\n                                                {query_part}\\n                                              LEFT JOIN (SELECT session_id\\n                                                FROM experimental.user_viewed_sessions\\n                                                WHERE user_id = %(userId)s AND project_id=%(project_id)s\\n                                                  AND _timestamp >= toDateTime(%(startDate)s / 1000)) AS viewed_sessions\\n                                               ON (viewed_sessions.session_id = s.session_id)\\n                                             ) AS raw\\n                                        ORDER BY sort_key {data.order}\\n                                        LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s) AS sorted_sessions;', full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        try:\n            sessions = cur.execute(main_query)\n        except Exception as err:\n            logging.warning('--------- SESSIONS-CH SEARCH QUERY EXCEPTION -----------')\n            logging.warning(main_query)\n            logging.warning('--------- PAYLOAD -----------')\n            logging.warning(data.model_dump_json())\n            logging.warning('--------------------')\n            raise err\n        if errors_only or ids_only:\n            return helper.list_to_camel_case(sessions)\n        if len(sessions) > 0:\n            sessions = sessions[0]\n        total = sessions['count']\n        sessions = sessions['sessions']\n    if data.group_by_user:\n        for (i, s) in enumerate(sessions):\n            sessions[i] = {**s.pop('last_session')[0], **s}\n            sessions[i].pop('rn')\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n    else:\n        for i in range(len(sessions)):\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n            sessions[i] = schemas.SessionModel.parse_obj(helper.dict_to_camel_case(sessions[i]))\n    return {'total': total, 'sessions': sessions}",
            "def search_sessions(data: schemas.SessionsSearchPayloadSchema, project_id, user_id, errors_only=False, error_status=schemas.ErrorStatus.all, count_only=False, issue=None, ids_only=False, platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=error_status, errors_only=errors_only, favorite_only=data.bookmarked, issue=issue, project_id=project_id, user_id=user_id, platform=platform)\n    if data.sort == 'startTs':\n        data.sort = 'datetime'\n    if data.limit is not None and data.page is not None:\n        full_args['sessions_limit'] = data.limit\n        full_args['sessions_limit_s'] = (data.page - 1) * data.limit\n        full_args['sessions_limit_e'] = data.page * data.limit\n    else:\n        full_args['sessions_limit'] = 200\n        full_args['sessions_limit_s'] = 0\n        full_args['sessions_limit_e'] = 200\n    meta_keys = []\n    with ch_client.ClickHouseClient() as cur:\n        if errors_only:\n            main_query = cur.format(f'SELECT DISTINCT er.error_id,\\n                                        COALESCE((SELECT TRUE\\n                                                 FROM {exp_ch_helper.get_user_viewed_errors_table()} AS ve\\n                                                 WHERE er.error_id = ve.error_id\\n                                                   AND ve.user_id = %(userId)s LIMIT 1), FALSE) AS viewed\\n                                        {query_part};', full_args)\n        elif count_only:\n            main_query = cur.mogrify(f'SELECT COUNT(DISTINCT s.session_id) AS count_sessions, \\n                                                COUNT(DISTINCT s.user_uuid) AS count_users\\n                                        {query_part};', full_args)\n        elif data.group_by_user:\n            g_sort = 'count(full_sessions)'\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            if data.sort is not None and data.sort != 'sessionsCount':\n                sort = helper.key_to_snake_case(data.sort)\n                g_sort = f\"{('MIN' if data.order == schemas.SortOrderType.desc else 'MAX')}({sort})\"\n            else:\n                sort = 'start_ts'\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",map(%s) AS 'metadata'\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.mogrify(f\"SELECT COUNT(*) AS count,\\n                                                COALESCE(JSONB_AGG(users_sessions) \\n                                                    FILTER (WHERE rn>%(sessions_limit_s)s AND rn<=%(sessions_limit_e)s), '[]'::JSONB) AS sessions\\n                                        FROM (SELECT user_id,\\n                                                 count(full_sessions)                                   AS user_sessions_count,\\n                                                 jsonb_agg(full_sessions) FILTER (WHERE rn <= 1)        AS last_session,\\n                                                 MIN(full_sessions.start_ts)                            AS first_session_ts,\\n                                                 ROW_NUMBER() OVER (ORDER BY {g_sort} {data.order}) AS rn\\n                                            FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY {sort} {data.order}) AS rn \\n                                                FROM (SELECT DISTINCT ON(s.session_id) {SESSION_PROJECTION_COLS} {meta_map}\\n                                                    {query_part}\\n                                                    ) AS filtred_sessions\\n                                                ) AS full_sessions\\n                                                GROUP BY user_id\\n                                            ) AS users_sessions;\", full_args)\n        elif ids_only:\n            main_query = cur.format(f'SELECT DISTINCT ON(s.session_id) s.session_id\\n                                             {query_part}\\n                                             ORDER BY s.session_id desc\\n                                             LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s;', full_args)\n        else:\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            sort = 'session_id'\n            if data.sort is not None and data.sort != 'session_id':\n                sort = helper.key_to_snake_case(data.sort)\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",'metadata',toString(map(%s))\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.format(f'SELECT any(total) AS count, groupArray(%(sessions_limit)s)(details) AS sessions\\n                                        FROM (SELECT total, details\\n                                              FROM (SELECT COUNT() OVER () AS total,\\n                                                    s.{sort} AS sort_key,\\n                                                    map({SESSION_PROJECTION_COLS_CH_MAP}{meta_map}) AS details\\n                                                {query_part}\\n                                              LEFT JOIN (SELECT session_id\\n                                                FROM experimental.user_viewed_sessions\\n                                                WHERE user_id = %(userId)s AND project_id=%(project_id)s\\n                                                  AND _timestamp >= toDateTime(%(startDate)s / 1000)) AS viewed_sessions\\n                                               ON (viewed_sessions.session_id = s.session_id)\\n                                             ) AS raw\\n                                        ORDER BY sort_key {data.order}\\n                                        LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s) AS sorted_sessions;', full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        try:\n            sessions = cur.execute(main_query)\n        except Exception as err:\n            logging.warning('--------- SESSIONS-CH SEARCH QUERY EXCEPTION -----------')\n            logging.warning(main_query)\n            logging.warning('--------- PAYLOAD -----------')\n            logging.warning(data.model_dump_json())\n            logging.warning('--------------------')\n            raise err\n        if errors_only or ids_only:\n            return helper.list_to_camel_case(sessions)\n        if len(sessions) > 0:\n            sessions = sessions[0]\n        total = sessions['count']\n        sessions = sessions['sessions']\n    if data.group_by_user:\n        for (i, s) in enumerate(sessions):\n            sessions[i] = {**s.pop('last_session')[0], **s}\n            sessions[i].pop('rn')\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n    else:\n        for i in range(len(sessions)):\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n            sessions[i] = schemas.SessionModel.parse_obj(helper.dict_to_camel_case(sessions[i]))\n    return {'total': total, 'sessions': sessions}",
            "def search_sessions(data: schemas.SessionsSearchPayloadSchema, project_id, user_id, errors_only=False, error_status=schemas.ErrorStatus.all, count_only=False, issue=None, ids_only=False, platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=error_status, errors_only=errors_only, favorite_only=data.bookmarked, issue=issue, project_id=project_id, user_id=user_id, platform=platform)\n    if data.sort == 'startTs':\n        data.sort = 'datetime'\n    if data.limit is not None and data.page is not None:\n        full_args['sessions_limit'] = data.limit\n        full_args['sessions_limit_s'] = (data.page - 1) * data.limit\n        full_args['sessions_limit_e'] = data.page * data.limit\n    else:\n        full_args['sessions_limit'] = 200\n        full_args['sessions_limit_s'] = 0\n        full_args['sessions_limit_e'] = 200\n    meta_keys = []\n    with ch_client.ClickHouseClient() as cur:\n        if errors_only:\n            main_query = cur.format(f'SELECT DISTINCT er.error_id,\\n                                        COALESCE((SELECT TRUE\\n                                                 FROM {exp_ch_helper.get_user_viewed_errors_table()} AS ve\\n                                                 WHERE er.error_id = ve.error_id\\n                                                   AND ve.user_id = %(userId)s LIMIT 1), FALSE) AS viewed\\n                                        {query_part};', full_args)\n        elif count_only:\n            main_query = cur.mogrify(f'SELECT COUNT(DISTINCT s.session_id) AS count_sessions, \\n                                                COUNT(DISTINCT s.user_uuid) AS count_users\\n                                        {query_part};', full_args)\n        elif data.group_by_user:\n            g_sort = 'count(full_sessions)'\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            if data.sort is not None and data.sort != 'sessionsCount':\n                sort = helper.key_to_snake_case(data.sort)\n                g_sort = f\"{('MIN' if data.order == schemas.SortOrderType.desc else 'MAX')}({sort})\"\n            else:\n                sort = 'start_ts'\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",map(%s) AS 'metadata'\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.mogrify(f\"SELECT COUNT(*) AS count,\\n                                                COALESCE(JSONB_AGG(users_sessions) \\n                                                    FILTER (WHERE rn>%(sessions_limit_s)s AND rn<=%(sessions_limit_e)s), '[]'::JSONB) AS sessions\\n                                        FROM (SELECT user_id,\\n                                                 count(full_sessions)                                   AS user_sessions_count,\\n                                                 jsonb_agg(full_sessions) FILTER (WHERE rn <= 1)        AS last_session,\\n                                                 MIN(full_sessions.start_ts)                            AS first_session_ts,\\n                                                 ROW_NUMBER() OVER (ORDER BY {g_sort} {data.order}) AS rn\\n                                            FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY {sort} {data.order}) AS rn \\n                                                FROM (SELECT DISTINCT ON(s.session_id) {SESSION_PROJECTION_COLS} {meta_map}\\n                                                    {query_part}\\n                                                    ) AS filtred_sessions\\n                                                ) AS full_sessions\\n                                                GROUP BY user_id\\n                                            ) AS users_sessions;\", full_args)\n        elif ids_only:\n            main_query = cur.format(f'SELECT DISTINCT ON(s.session_id) s.session_id\\n                                             {query_part}\\n                                             ORDER BY s.session_id desc\\n                                             LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s;', full_args)\n        else:\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            sort = 'session_id'\n            if data.sort is not None and data.sort != 'session_id':\n                sort = helper.key_to_snake_case(data.sort)\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",'metadata',toString(map(%s))\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.format(f'SELECT any(total) AS count, groupArray(%(sessions_limit)s)(details) AS sessions\\n                                        FROM (SELECT total, details\\n                                              FROM (SELECT COUNT() OVER () AS total,\\n                                                    s.{sort} AS sort_key,\\n                                                    map({SESSION_PROJECTION_COLS_CH_MAP}{meta_map}) AS details\\n                                                {query_part}\\n                                              LEFT JOIN (SELECT session_id\\n                                                FROM experimental.user_viewed_sessions\\n                                                WHERE user_id = %(userId)s AND project_id=%(project_id)s\\n                                                  AND _timestamp >= toDateTime(%(startDate)s / 1000)) AS viewed_sessions\\n                                               ON (viewed_sessions.session_id = s.session_id)\\n                                             ) AS raw\\n                                        ORDER BY sort_key {data.order}\\n                                        LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s) AS sorted_sessions;', full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        try:\n            sessions = cur.execute(main_query)\n        except Exception as err:\n            logging.warning('--------- SESSIONS-CH SEARCH QUERY EXCEPTION -----------')\n            logging.warning(main_query)\n            logging.warning('--------- PAYLOAD -----------')\n            logging.warning(data.model_dump_json())\n            logging.warning('--------------------')\n            raise err\n        if errors_only or ids_only:\n            return helper.list_to_camel_case(sessions)\n        if len(sessions) > 0:\n            sessions = sessions[0]\n        total = sessions['count']\n        sessions = sessions['sessions']\n    if data.group_by_user:\n        for (i, s) in enumerate(sessions):\n            sessions[i] = {**s.pop('last_session')[0], **s}\n            sessions[i].pop('rn')\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n    else:\n        for i in range(len(sessions)):\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n            sessions[i] = schemas.SessionModel.parse_obj(helper.dict_to_camel_case(sessions[i]))\n    return {'total': total, 'sessions': sessions}",
            "def search_sessions(data: schemas.SessionsSearchPayloadSchema, project_id, user_id, errors_only=False, error_status=schemas.ErrorStatus.all, count_only=False, issue=None, ids_only=False, platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=error_status, errors_only=errors_only, favorite_only=data.bookmarked, issue=issue, project_id=project_id, user_id=user_id, platform=platform)\n    if data.sort == 'startTs':\n        data.sort = 'datetime'\n    if data.limit is not None and data.page is not None:\n        full_args['sessions_limit'] = data.limit\n        full_args['sessions_limit_s'] = (data.page - 1) * data.limit\n        full_args['sessions_limit_e'] = data.page * data.limit\n    else:\n        full_args['sessions_limit'] = 200\n        full_args['sessions_limit_s'] = 0\n        full_args['sessions_limit_e'] = 200\n    meta_keys = []\n    with ch_client.ClickHouseClient() as cur:\n        if errors_only:\n            main_query = cur.format(f'SELECT DISTINCT er.error_id,\\n                                        COALESCE((SELECT TRUE\\n                                                 FROM {exp_ch_helper.get_user_viewed_errors_table()} AS ve\\n                                                 WHERE er.error_id = ve.error_id\\n                                                   AND ve.user_id = %(userId)s LIMIT 1), FALSE) AS viewed\\n                                        {query_part};', full_args)\n        elif count_only:\n            main_query = cur.mogrify(f'SELECT COUNT(DISTINCT s.session_id) AS count_sessions, \\n                                                COUNT(DISTINCT s.user_uuid) AS count_users\\n                                        {query_part};', full_args)\n        elif data.group_by_user:\n            g_sort = 'count(full_sessions)'\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            if data.sort is not None and data.sort != 'sessionsCount':\n                sort = helper.key_to_snake_case(data.sort)\n                g_sort = f\"{('MIN' if data.order == schemas.SortOrderType.desc else 'MAX')}({sort})\"\n            else:\n                sort = 'start_ts'\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",map(%s) AS 'metadata'\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.mogrify(f\"SELECT COUNT(*) AS count,\\n                                                COALESCE(JSONB_AGG(users_sessions) \\n                                                    FILTER (WHERE rn>%(sessions_limit_s)s AND rn<=%(sessions_limit_e)s), '[]'::JSONB) AS sessions\\n                                        FROM (SELECT user_id,\\n                                                 count(full_sessions)                                   AS user_sessions_count,\\n                                                 jsonb_agg(full_sessions) FILTER (WHERE rn <= 1)        AS last_session,\\n                                                 MIN(full_sessions.start_ts)                            AS first_session_ts,\\n                                                 ROW_NUMBER() OVER (ORDER BY {g_sort} {data.order}) AS rn\\n                                            FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY {sort} {data.order}) AS rn \\n                                                FROM (SELECT DISTINCT ON(s.session_id) {SESSION_PROJECTION_COLS} {meta_map}\\n                                                    {query_part}\\n                                                    ) AS filtred_sessions\\n                                                ) AS full_sessions\\n                                                GROUP BY user_id\\n                                            ) AS users_sessions;\", full_args)\n        elif ids_only:\n            main_query = cur.format(f'SELECT DISTINCT ON(s.session_id) s.session_id\\n                                             {query_part}\\n                                             ORDER BY s.session_id desc\\n                                             LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s;', full_args)\n        else:\n            if data.order is None:\n                data.order = schemas.SortOrderType.desc.value\n            else:\n                data.order = data.order\n            sort = 'session_id'\n            if data.sort is not None and data.sort != 'session_id':\n                sort = helper.key_to_snake_case(data.sort)\n            meta_keys = metadata.get(project_id=project_id)\n            meta_map = \",'metadata',toString(map(%s))\" % ','.join([f\"'{m['key']}',coalesce(metadata_{m['index']},'None')\" for m in meta_keys])\n            main_query = cur.format(f'SELECT any(total) AS count, groupArray(%(sessions_limit)s)(details) AS sessions\\n                                        FROM (SELECT total, details\\n                                              FROM (SELECT COUNT() OVER () AS total,\\n                                                    s.{sort} AS sort_key,\\n                                                    map({SESSION_PROJECTION_COLS_CH_MAP}{meta_map}) AS details\\n                                                {query_part}\\n                                              LEFT JOIN (SELECT session_id\\n                                                FROM experimental.user_viewed_sessions\\n                                                WHERE user_id = %(userId)s AND project_id=%(project_id)s\\n                                                  AND _timestamp >= toDateTime(%(startDate)s / 1000)) AS viewed_sessions\\n                                               ON (viewed_sessions.session_id = s.session_id)\\n                                             ) AS raw\\n                                        ORDER BY sort_key {data.order}\\n                                        LIMIT %(sessions_limit)s OFFSET %(sessions_limit_s)s) AS sorted_sessions;', full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        try:\n            sessions = cur.execute(main_query)\n        except Exception as err:\n            logging.warning('--------- SESSIONS-CH SEARCH QUERY EXCEPTION -----------')\n            logging.warning(main_query)\n            logging.warning('--------- PAYLOAD -----------')\n            logging.warning(data.model_dump_json())\n            logging.warning('--------------------')\n            raise err\n        if errors_only or ids_only:\n            return helper.list_to_camel_case(sessions)\n        if len(sessions) > 0:\n            sessions = sessions[0]\n        total = sessions['count']\n        sessions = sessions['sessions']\n    if data.group_by_user:\n        for (i, s) in enumerate(sessions):\n            sessions[i] = {**s.pop('last_session')[0], **s}\n            sessions[i].pop('rn')\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n    else:\n        for i in range(len(sessions)):\n            sessions[i]['metadata'] = ast.literal_eval(sessions[i]['metadata'])\n            sessions[i] = schemas.SessionModel.parse_obj(helper.dict_to_camel_case(sessions[i]))\n    return {'total': total, 'sessions': sessions}"
        ]
    },
    {
        "func_name": "search2_series",
        "original": "def search2_series(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, view_type: schemas.MetricTimeseriesViewType, metric_type: schemas.MetricType, metric_of: schemas.MetricOfTable, metric_value: List):\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        if metric_type == schemas.MetricType.timeseries:\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                query = f'SELECT toUnixTimestamp(\\n                                    toStartOfInterval(processed_sessions.datetime, INTERVAL %(step_size)s second)\\n                                    ) * 1000 AS timestamp,\\n                                COUNT(processed_sessions.session_id) AS count\\n                            FROM (SELECT DISTINCT ON(s.session_id) s.session_id AS session_id,\\n                                        s.datetime AS datetime\\n                                    {query_part}) AS processed_sessions\\n                            GROUP BY timestamp\\n                            ORDER BY timestamp;'\n                main_query = cur.format(query, full_args)\n            else:\n                main_query = cur.format(f'SELECT count(DISTINCT s.session_id) AS count\\n                                            {query_part};', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                sessions = metrics.__complete_missing_steps(start_time=data.startTimestamp, end_time=data.endTimestamp, density=density, neutral={'count': 0}, rows=sessions)\n            else:\n                sessions = sessions[0]['count'] if len(sessions) > 0 else 0\n        elif metric_type == schemas.MetricType.table:\n            full_args['limit_s'] = 0\n            full_args['limit_e'] = 200\n            if isinstance(metric_of, schemas.MetricOfTable):\n                main_col = 'user_id'\n                extra_col = 's.user_id'\n                extra_where = ''\n                pre_query = ''\n                if metric_of == schemas.MetricOfTable.user_country:\n                    main_col = 'user_country'\n                    extra_col = 's.user_country'\n                elif metric_of == schemas.MetricOfTable.user_device:\n                    main_col = 'user_device'\n                    extra_col = 's.user_device'\n                elif metric_of == schemas.MetricOfTable.user_browser:\n                    main_col = 'user_browser'\n                    extra_col = 's.user_browser'\n                elif metric_of == schemas.MetricOfTable.issues:\n                    main_col = 'issue'\n                    extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                    if len(metric_value) > 0:\n                        extra_where = []\n                        for i in range(len(metric_value)):\n                            arg_name = f'selected_issue_{i}'\n                            extra_where.append(f'{main_col} = %({arg_name})s')\n                            full_args[arg_name] = metric_value[i]\n                        extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n                elif metric_of == schemas.MetricOfTable.visited_url:\n                    main_col = 'url_path'\n                    extra_col = 's.url_path'\n                main_query = cur.format(f'{pre_query}\\n                                            SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                                 {main_col} AS name,\\n                                                 count(DISTINCT session_id) AS session_count\\n                                            FROM (SELECT s.session_id AS session_id, \\n                                                        {extra_col}\\n                                            {query_part}\\n                                            ORDER BY s.session_id desc) AS filtred_sessions\\n                                            {extra_where}\\n                                            GROUP BY {main_col}\\n                                            ORDER BY session_count DESC\\n                                            LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
        "mutated": [
            "def search2_series(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, view_type: schemas.MetricTimeseriesViewType, metric_type: schemas.MetricType, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        if metric_type == schemas.MetricType.timeseries:\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                query = f'SELECT toUnixTimestamp(\\n                                    toStartOfInterval(processed_sessions.datetime, INTERVAL %(step_size)s second)\\n                                    ) * 1000 AS timestamp,\\n                                COUNT(processed_sessions.session_id) AS count\\n                            FROM (SELECT DISTINCT ON(s.session_id) s.session_id AS session_id,\\n                                        s.datetime AS datetime\\n                                    {query_part}) AS processed_sessions\\n                            GROUP BY timestamp\\n                            ORDER BY timestamp;'\n                main_query = cur.format(query, full_args)\n            else:\n                main_query = cur.format(f'SELECT count(DISTINCT s.session_id) AS count\\n                                            {query_part};', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                sessions = metrics.__complete_missing_steps(start_time=data.startTimestamp, end_time=data.endTimestamp, density=density, neutral={'count': 0}, rows=sessions)\n            else:\n                sessions = sessions[0]['count'] if len(sessions) > 0 else 0\n        elif metric_type == schemas.MetricType.table:\n            full_args['limit_s'] = 0\n            full_args['limit_e'] = 200\n            if isinstance(metric_of, schemas.MetricOfTable):\n                main_col = 'user_id'\n                extra_col = 's.user_id'\n                extra_where = ''\n                pre_query = ''\n                if metric_of == schemas.MetricOfTable.user_country:\n                    main_col = 'user_country'\n                    extra_col = 's.user_country'\n                elif metric_of == schemas.MetricOfTable.user_device:\n                    main_col = 'user_device'\n                    extra_col = 's.user_device'\n                elif metric_of == schemas.MetricOfTable.user_browser:\n                    main_col = 'user_browser'\n                    extra_col = 's.user_browser'\n                elif metric_of == schemas.MetricOfTable.issues:\n                    main_col = 'issue'\n                    extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                    if len(metric_value) > 0:\n                        extra_where = []\n                        for i in range(len(metric_value)):\n                            arg_name = f'selected_issue_{i}'\n                            extra_where.append(f'{main_col} = %({arg_name})s')\n                            full_args[arg_name] = metric_value[i]\n                        extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n                elif metric_of == schemas.MetricOfTable.visited_url:\n                    main_col = 'url_path'\n                    extra_col = 's.url_path'\n                main_query = cur.format(f'{pre_query}\\n                                            SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                                 {main_col} AS name,\\n                                                 count(DISTINCT session_id) AS session_count\\n                                            FROM (SELECT s.session_id AS session_id, \\n                                                        {extra_col}\\n                                            {query_part}\\n                                            ORDER BY s.session_id desc) AS filtred_sessions\\n                                            {extra_where}\\n                                            GROUP BY {main_col}\\n                                            ORDER BY session_count DESC\\n                                            LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_series(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, view_type: schemas.MetricTimeseriesViewType, metric_type: schemas.MetricType, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        if metric_type == schemas.MetricType.timeseries:\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                query = f'SELECT toUnixTimestamp(\\n                                    toStartOfInterval(processed_sessions.datetime, INTERVAL %(step_size)s second)\\n                                    ) * 1000 AS timestamp,\\n                                COUNT(processed_sessions.session_id) AS count\\n                            FROM (SELECT DISTINCT ON(s.session_id) s.session_id AS session_id,\\n                                        s.datetime AS datetime\\n                                    {query_part}) AS processed_sessions\\n                            GROUP BY timestamp\\n                            ORDER BY timestamp;'\n                main_query = cur.format(query, full_args)\n            else:\n                main_query = cur.format(f'SELECT count(DISTINCT s.session_id) AS count\\n                                            {query_part};', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                sessions = metrics.__complete_missing_steps(start_time=data.startTimestamp, end_time=data.endTimestamp, density=density, neutral={'count': 0}, rows=sessions)\n            else:\n                sessions = sessions[0]['count'] if len(sessions) > 0 else 0\n        elif metric_type == schemas.MetricType.table:\n            full_args['limit_s'] = 0\n            full_args['limit_e'] = 200\n            if isinstance(metric_of, schemas.MetricOfTable):\n                main_col = 'user_id'\n                extra_col = 's.user_id'\n                extra_where = ''\n                pre_query = ''\n                if metric_of == schemas.MetricOfTable.user_country:\n                    main_col = 'user_country'\n                    extra_col = 's.user_country'\n                elif metric_of == schemas.MetricOfTable.user_device:\n                    main_col = 'user_device'\n                    extra_col = 's.user_device'\n                elif metric_of == schemas.MetricOfTable.user_browser:\n                    main_col = 'user_browser'\n                    extra_col = 's.user_browser'\n                elif metric_of == schemas.MetricOfTable.issues:\n                    main_col = 'issue'\n                    extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                    if len(metric_value) > 0:\n                        extra_where = []\n                        for i in range(len(metric_value)):\n                            arg_name = f'selected_issue_{i}'\n                            extra_where.append(f'{main_col} = %({arg_name})s')\n                            full_args[arg_name] = metric_value[i]\n                        extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n                elif metric_of == schemas.MetricOfTable.visited_url:\n                    main_col = 'url_path'\n                    extra_col = 's.url_path'\n                main_query = cur.format(f'{pre_query}\\n                                            SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                                 {main_col} AS name,\\n                                                 count(DISTINCT session_id) AS session_count\\n                                            FROM (SELECT s.session_id AS session_id, \\n                                                        {extra_col}\\n                                            {query_part}\\n                                            ORDER BY s.session_id desc) AS filtred_sessions\\n                                            {extra_where}\\n                                            GROUP BY {main_col}\\n                                            ORDER BY session_count DESC\\n                                            LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_series(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, view_type: schemas.MetricTimeseriesViewType, metric_type: schemas.MetricType, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        if metric_type == schemas.MetricType.timeseries:\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                query = f'SELECT toUnixTimestamp(\\n                                    toStartOfInterval(processed_sessions.datetime, INTERVAL %(step_size)s second)\\n                                    ) * 1000 AS timestamp,\\n                                COUNT(processed_sessions.session_id) AS count\\n                            FROM (SELECT DISTINCT ON(s.session_id) s.session_id AS session_id,\\n                                        s.datetime AS datetime\\n                                    {query_part}) AS processed_sessions\\n                            GROUP BY timestamp\\n                            ORDER BY timestamp;'\n                main_query = cur.format(query, full_args)\n            else:\n                main_query = cur.format(f'SELECT count(DISTINCT s.session_id) AS count\\n                                            {query_part};', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                sessions = metrics.__complete_missing_steps(start_time=data.startTimestamp, end_time=data.endTimestamp, density=density, neutral={'count': 0}, rows=sessions)\n            else:\n                sessions = sessions[0]['count'] if len(sessions) > 0 else 0\n        elif metric_type == schemas.MetricType.table:\n            full_args['limit_s'] = 0\n            full_args['limit_e'] = 200\n            if isinstance(metric_of, schemas.MetricOfTable):\n                main_col = 'user_id'\n                extra_col = 's.user_id'\n                extra_where = ''\n                pre_query = ''\n                if metric_of == schemas.MetricOfTable.user_country:\n                    main_col = 'user_country'\n                    extra_col = 's.user_country'\n                elif metric_of == schemas.MetricOfTable.user_device:\n                    main_col = 'user_device'\n                    extra_col = 's.user_device'\n                elif metric_of == schemas.MetricOfTable.user_browser:\n                    main_col = 'user_browser'\n                    extra_col = 's.user_browser'\n                elif metric_of == schemas.MetricOfTable.issues:\n                    main_col = 'issue'\n                    extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                    if len(metric_value) > 0:\n                        extra_where = []\n                        for i in range(len(metric_value)):\n                            arg_name = f'selected_issue_{i}'\n                            extra_where.append(f'{main_col} = %({arg_name})s')\n                            full_args[arg_name] = metric_value[i]\n                        extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n                elif metric_of == schemas.MetricOfTable.visited_url:\n                    main_col = 'url_path'\n                    extra_col = 's.url_path'\n                main_query = cur.format(f'{pre_query}\\n                                            SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                                 {main_col} AS name,\\n                                                 count(DISTINCT session_id) AS session_count\\n                                            FROM (SELECT s.session_id AS session_id, \\n                                                        {extra_col}\\n                                            {query_part}\\n                                            ORDER BY s.session_id desc) AS filtred_sessions\\n                                            {extra_where}\\n                                            GROUP BY {main_col}\\n                                            ORDER BY session_count DESC\\n                                            LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_series(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, view_type: schemas.MetricTimeseriesViewType, metric_type: schemas.MetricType, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        if metric_type == schemas.MetricType.timeseries:\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                query = f'SELECT toUnixTimestamp(\\n                                    toStartOfInterval(processed_sessions.datetime, INTERVAL %(step_size)s second)\\n                                    ) * 1000 AS timestamp,\\n                                COUNT(processed_sessions.session_id) AS count\\n                            FROM (SELECT DISTINCT ON(s.session_id) s.session_id AS session_id,\\n                                        s.datetime AS datetime\\n                                    {query_part}) AS processed_sessions\\n                            GROUP BY timestamp\\n                            ORDER BY timestamp;'\n                main_query = cur.format(query, full_args)\n            else:\n                main_query = cur.format(f'SELECT count(DISTINCT s.session_id) AS count\\n                                            {query_part};', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                sessions = metrics.__complete_missing_steps(start_time=data.startTimestamp, end_time=data.endTimestamp, density=density, neutral={'count': 0}, rows=sessions)\n            else:\n                sessions = sessions[0]['count'] if len(sessions) > 0 else 0\n        elif metric_type == schemas.MetricType.table:\n            full_args['limit_s'] = 0\n            full_args['limit_e'] = 200\n            if isinstance(metric_of, schemas.MetricOfTable):\n                main_col = 'user_id'\n                extra_col = 's.user_id'\n                extra_where = ''\n                pre_query = ''\n                if metric_of == schemas.MetricOfTable.user_country:\n                    main_col = 'user_country'\n                    extra_col = 's.user_country'\n                elif metric_of == schemas.MetricOfTable.user_device:\n                    main_col = 'user_device'\n                    extra_col = 's.user_device'\n                elif metric_of == schemas.MetricOfTable.user_browser:\n                    main_col = 'user_browser'\n                    extra_col = 's.user_browser'\n                elif metric_of == schemas.MetricOfTable.issues:\n                    main_col = 'issue'\n                    extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                    if len(metric_value) > 0:\n                        extra_where = []\n                        for i in range(len(metric_value)):\n                            arg_name = f'selected_issue_{i}'\n                            extra_where.append(f'{main_col} = %({arg_name})s')\n                            full_args[arg_name] = metric_value[i]\n                        extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n                elif metric_of == schemas.MetricOfTable.visited_url:\n                    main_col = 'url_path'\n                    extra_col = 's.url_path'\n                main_query = cur.format(f'{pre_query}\\n                                            SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                                 {main_col} AS name,\\n                                                 count(DISTINCT session_id) AS session_count\\n                                            FROM (SELECT s.session_id AS session_id, \\n                                                        {extra_col}\\n                                            {query_part}\\n                                            ORDER BY s.session_id desc) AS filtred_sessions\\n                                            {extra_where}\\n                                            GROUP BY {main_col}\\n                                            ORDER BY session_count DESC\\n                                            LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_series(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, view_type: schemas.MetricTimeseriesViewType, metric_type: schemas.MetricType, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        if metric_type == schemas.MetricType.timeseries:\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                query = f'SELECT toUnixTimestamp(\\n                                    toStartOfInterval(processed_sessions.datetime, INTERVAL %(step_size)s second)\\n                                    ) * 1000 AS timestamp,\\n                                COUNT(processed_sessions.session_id) AS count\\n                            FROM (SELECT DISTINCT ON(s.session_id) s.session_id AS session_id,\\n                                        s.datetime AS datetime\\n                                    {query_part}) AS processed_sessions\\n                            GROUP BY timestamp\\n                            ORDER BY timestamp;'\n                main_query = cur.format(query, full_args)\n            else:\n                main_query = cur.format(f'SELECT count(DISTINCT s.session_id) AS count\\n                                            {query_part};', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            if view_type == schemas.MetricTimeseriesViewType.line_chart:\n                sessions = metrics.__complete_missing_steps(start_time=data.startTimestamp, end_time=data.endTimestamp, density=density, neutral={'count': 0}, rows=sessions)\n            else:\n                sessions = sessions[0]['count'] if len(sessions) > 0 else 0\n        elif metric_type == schemas.MetricType.table:\n            full_args['limit_s'] = 0\n            full_args['limit_e'] = 200\n            if isinstance(metric_of, schemas.MetricOfTable):\n                main_col = 'user_id'\n                extra_col = 's.user_id'\n                extra_where = ''\n                pre_query = ''\n                if metric_of == schemas.MetricOfTable.user_country:\n                    main_col = 'user_country'\n                    extra_col = 's.user_country'\n                elif metric_of == schemas.MetricOfTable.user_device:\n                    main_col = 'user_device'\n                    extra_col = 's.user_device'\n                elif metric_of == schemas.MetricOfTable.user_browser:\n                    main_col = 'user_browser'\n                    extra_col = 's.user_browser'\n                elif metric_of == schemas.MetricOfTable.issues:\n                    main_col = 'issue'\n                    extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                    if len(metric_value) > 0:\n                        extra_where = []\n                        for i in range(len(metric_value)):\n                            arg_name = f'selected_issue_{i}'\n                            extra_where.append(f'{main_col} = %({arg_name})s')\n                            full_args[arg_name] = metric_value[i]\n                        extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n                elif metric_of == schemas.MetricOfTable.visited_url:\n                    main_col = 'url_path'\n                    extra_col = 's.url_path'\n                main_query = cur.format(f'{pre_query}\\n                                            SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                                 {main_col} AS name,\\n                                                 count(DISTINCT session_id) AS session_count\\n                                            FROM (SELECT s.session_id AS session_id, \\n                                                        {extra_col}\\n                                            {query_part}\\n                                            ORDER BY s.session_id desc) AS filtred_sessions\\n                                            {extra_where}\\n                                            GROUP BY {main_col}\\n                                            ORDER BY session_count DESC\\n                                            LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions"
        ]
    },
    {
        "func_name": "search2_table",
        "original": "def search2_table(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, metric_of: schemas.MetricOfTable, metric_value: List):\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        full_args['limit_s'] = 0\n        full_args['limit_e'] = 200\n        if isinstance(metric_of, schemas.MetricOfTable):\n            main_col = 'user_id'\n            extra_col = 's.user_id'\n            extra_where = ''\n            pre_query = ''\n            if metric_of == schemas.MetricOfTable.user_country:\n                main_col = 'user_country'\n                extra_col = 's.user_country'\n            elif metric_of == schemas.MetricOfTable.user_device:\n                main_col = 'user_device'\n                extra_col = 's.user_device'\n            elif metric_of == schemas.MetricOfTable.user_browser:\n                main_col = 'user_browser'\n                extra_col = 's.user_browser'\n            elif metric_of == schemas.MetricOfTable.issues:\n                main_col = 'issue'\n                extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                if len(metric_value) > 0:\n                    extra_where = []\n                    for i in range(len(metric_value)):\n                        arg_name = f'selected_issue_{i}'\n                        extra_where.append(f'{main_col} = %({arg_name})s')\n                        full_args[arg_name] = metric_value[i]\n                    extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n            elif metric_of == schemas.MetricOfTable.visited_url:\n                main_col = 'url_path'\n                extra_col = 's.url_path'\n            main_query = cur.format(f'{pre_query}\\n                                        SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                             {main_col} AS name,\\n                                             count(DISTINCT session_id) AS session_count\\n                                        FROM (SELECT s.session_id AS session_id, \\n                                                    {extra_col}\\n                                        {query_part}\\n                                        ORDER BY s.session_id desc) AS filtred_sessions\\n                                        {extra_where}\\n                                        GROUP BY {main_col}\\n                                        ORDER BY session_count DESC\\n                                        LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
        "mutated": [
            "def search2_table(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        full_args['limit_s'] = 0\n        full_args['limit_e'] = 200\n        if isinstance(metric_of, schemas.MetricOfTable):\n            main_col = 'user_id'\n            extra_col = 's.user_id'\n            extra_where = ''\n            pre_query = ''\n            if metric_of == schemas.MetricOfTable.user_country:\n                main_col = 'user_country'\n                extra_col = 's.user_country'\n            elif metric_of == schemas.MetricOfTable.user_device:\n                main_col = 'user_device'\n                extra_col = 's.user_device'\n            elif metric_of == schemas.MetricOfTable.user_browser:\n                main_col = 'user_browser'\n                extra_col = 's.user_browser'\n            elif metric_of == schemas.MetricOfTable.issues:\n                main_col = 'issue'\n                extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                if len(metric_value) > 0:\n                    extra_where = []\n                    for i in range(len(metric_value)):\n                        arg_name = f'selected_issue_{i}'\n                        extra_where.append(f'{main_col} = %({arg_name})s')\n                        full_args[arg_name] = metric_value[i]\n                    extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n            elif metric_of == schemas.MetricOfTable.visited_url:\n                main_col = 'url_path'\n                extra_col = 's.url_path'\n            main_query = cur.format(f'{pre_query}\\n                                        SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                             {main_col} AS name,\\n                                             count(DISTINCT session_id) AS session_count\\n                                        FROM (SELECT s.session_id AS session_id, \\n                                                    {extra_col}\\n                                        {query_part}\\n                                        ORDER BY s.session_id desc) AS filtred_sessions\\n                                        {extra_where}\\n                                        GROUP BY {main_col}\\n                                        ORDER BY session_count DESC\\n                                        LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_table(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        full_args['limit_s'] = 0\n        full_args['limit_e'] = 200\n        if isinstance(metric_of, schemas.MetricOfTable):\n            main_col = 'user_id'\n            extra_col = 's.user_id'\n            extra_where = ''\n            pre_query = ''\n            if metric_of == schemas.MetricOfTable.user_country:\n                main_col = 'user_country'\n                extra_col = 's.user_country'\n            elif metric_of == schemas.MetricOfTable.user_device:\n                main_col = 'user_device'\n                extra_col = 's.user_device'\n            elif metric_of == schemas.MetricOfTable.user_browser:\n                main_col = 'user_browser'\n                extra_col = 's.user_browser'\n            elif metric_of == schemas.MetricOfTable.issues:\n                main_col = 'issue'\n                extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                if len(metric_value) > 0:\n                    extra_where = []\n                    for i in range(len(metric_value)):\n                        arg_name = f'selected_issue_{i}'\n                        extra_where.append(f'{main_col} = %({arg_name})s')\n                        full_args[arg_name] = metric_value[i]\n                    extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n            elif metric_of == schemas.MetricOfTable.visited_url:\n                main_col = 'url_path'\n                extra_col = 's.url_path'\n            main_query = cur.format(f'{pre_query}\\n                                        SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                             {main_col} AS name,\\n                                             count(DISTINCT session_id) AS session_count\\n                                        FROM (SELECT s.session_id AS session_id, \\n                                                    {extra_col}\\n                                        {query_part}\\n                                        ORDER BY s.session_id desc) AS filtred_sessions\\n                                        {extra_where}\\n                                        GROUP BY {main_col}\\n                                        ORDER BY session_count DESC\\n                                        LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_table(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        full_args['limit_s'] = 0\n        full_args['limit_e'] = 200\n        if isinstance(metric_of, schemas.MetricOfTable):\n            main_col = 'user_id'\n            extra_col = 's.user_id'\n            extra_where = ''\n            pre_query = ''\n            if metric_of == schemas.MetricOfTable.user_country:\n                main_col = 'user_country'\n                extra_col = 's.user_country'\n            elif metric_of == schemas.MetricOfTable.user_device:\n                main_col = 'user_device'\n                extra_col = 's.user_device'\n            elif metric_of == schemas.MetricOfTable.user_browser:\n                main_col = 'user_browser'\n                extra_col = 's.user_browser'\n            elif metric_of == schemas.MetricOfTable.issues:\n                main_col = 'issue'\n                extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                if len(metric_value) > 0:\n                    extra_where = []\n                    for i in range(len(metric_value)):\n                        arg_name = f'selected_issue_{i}'\n                        extra_where.append(f'{main_col} = %({arg_name})s')\n                        full_args[arg_name] = metric_value[i]\n                    extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n            elif metric_of == schemas.MetricOfTable.visited_url:\n                main_col = 'url_path'\n                extra_col = 's.url_path'\n            main_query = cur.format(f'{pre_query}\\n                                        SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                             {main_col} AS name,\\n                                             count(DISTINCT session_id) AS session_count\\n                                        FROM (SELECT s.session_id AS session_id, \\n                                                    {extra_col}\\n                                        {query_part}\\n                                        ORDER BY s.session_id desc) AS filtred_sessions\\n                                        {extra_where}\\n                                        GROUP BY {main_col}\\n                                        ORDER BY session_count DESC\\n                                        LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_table(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        full_args['limit_s'] = 0\n        full_args['limit_e'] = 200\n        if isinstance(metric_of, schemas.MetricOfTable):\n            main_col = 'user_id'\n            extra_col = 's.user_id'\n            extra_where = ''\n            pre_query = ''\n            if metric_of == schemas.MetricOfTable.user_country:\n                main_col = 'user_country'\n                extra_col = 's.user_country'\n            elif metric_of == schemas.MetricOfTable.user_device:\n                main_col = 'user_device'\n                extra_col = 's.user_device'\n            elif metric_of == schemas.MetricOfTable.user_browser:\n                main_col = 'user_browser'\n                extra_col = 's.user_browser'\n            elif metric_of == schemas.MetricOfTable.issues:\n                main_col = 'issue'\n                extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                if len(metric_value) > 0:\n                    extra_where = []\n                    for i in range(len(metric_value)):\n                        arg_name = f'selected_issue_{i}'\n                        extra_where.append(f'{main_col} = %({arg_name})s')\n                        full_args[arg_name] = metric_value[i]\n                    extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n            elif metric_of == schemas.MetricOfTable.visited_url:\n                main_col = 'url_path'\n                extra_col = 's.url_path'\n            main_query = cur.format(f'{pre_query}\\n                                        SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                             {main_col} AS name,\\n                                             count(DISTINCT session_id) AS session_count\\n                                        FROM (SELECT s.session_id AS session_id, \\n                                                    {extra_col}\\n                                        {query_part}\\n                                        ORDER BY s.session_id desc) AS filtred_sessions\\n                                        {extra_where}\\n                                        GROUP BY {main_col}\\n                                        ORDER BY session_count DESC\\n                                        LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions",
            "def search2_table(data: schemas.SessionsSearchPayloadSchema, project_id: int, density: int, metric_of: schemas.MetricOfTable, metric_value: List):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    step_size = int(metrics_helper.__get_step_size(endTimestamp=data.endTimestamp, startTimestamp=data.startTimestamp, density=density))\n    extra_event = None\n    if metric_of == schemas.MetricOfTable.visited_url:\n        extra_event = f\"SELECT DISTINCT ev.session_id, ev.url_path\\n                            FROM {exp_ch_helper.get_main_events_table(data.startTimestamp)} AS ev\\n                            WHERE ev.datetime >= toDateTime(%(startDate)s / 1000)\\n                              AND ev.datetime <= toDateTime(%(endDate)s / 1000)\\n                              AND ev.project_id = %(project_id)s\\n                              AND ev.event_type = 'LOCATION'\"\n    elif metric_of == schemas.MetricOfTable.issues and len(metric_value) > 0:\n        data.filters.append(schemas.SessionSearchFilterSchema(value=metric_value, type=schemas.FilterType.issue, operator=schemas.SearchEventOperator._is))\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None, extra_event=extra_event)\n    full_args['step_size'] = step_size\n    sessions = []\n    with ch_client.ClickHouseClient() as cur:\n        full_args['limit_s'] = 0\n        full_args['limit_e'] = 200\n        if isinstance(metric_of, schemas.MetricOfTable):\n            main_col = 'user_id'\n            extra_col = 's.user_id'\n            extra_where = ''\n            pre_query = ''\n            if metric_of == schemas.MetricOfTable.user_country:\n                main_col = 'user_country'\n                extra_col = 's.user_country'\n            elif metric_of == schemas.MetricOfTable.user_device:\n                main_col = 'user_device'\n                extra_col = 's.user_device'\n            elif metric_of == schemas.MetricOfTable.user_browser:\n                main_col = 'user_browser'\n                extra_col = 's.user_browser'\n            elif metric_of == schemas.MetricOfTable.issues:\n                main_col = 'issue'\n                extra_col = f'arrayJoin(s.issue_types) AS {main_col}'\n                if len(metric_value) > 0:\n                    extra_where = []\n                    for i in range(len(metric_value)):\n                        arg_name = f'selected_issue_{i}'\n                        extra_where.append(f'{main_col} = %({arg_name})s')\n                        full_args[arg_name] = metric_value[i]\n                    extra_where = f\"WHERE ({' OR '.join(extra_where)})\"\n            elif metric_of == schemas.MetricOfTable.visited_url:\n                main_col = 'url_path'\n                extra_col = 's.url_path'\n            main_query = cur.format(f'{pre_query}\\n                                        SELECT COUNT(DISTINCT {main_col}) OVER () AS main_count, \\n                                             {main_col} AS name,\\n                                             count(DISTINCT session_id) AS session_count\\n                                        FROM (SELECT s.session_id AS session_id, \\n                                                    {extra_col}\\n                                        {query_part}\\n                                        ORDER BY s.session_id desc) AS filtred_sessions\\n                                        {extra_where}\\n                                        GROUP BY {main_col}\\n                                        ORDER BY session_count DESC\\n                                        LIMIT %(limit_e)s OFFSET %(limit_s)s;', full_args)\n            logging.debug('--------------------')\n            logging.debug(main_query)\n            logging.debug('--------------------')\n            sessions = cur.execute(main_query)\n            count = 0\n            if len(sessions) > 0:\n                count = sessions[0]['main_count']\n                for s in sessions:\n                    s.pop('main_count')\n            sessions = {'count': count, 'values': helper.list_to_camel_case(sessions)}\n        return sessions"
        ]
    },
    {
        "func_name": "search_table_of_individual_issues",
        "original": "def search_table_of_individual_issues(data: schemas.SessionsSearchPayloadSchema, project_id: int):\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None)\n    with ch_client.ClickHouseClient() as cur:\n        full_args['issues_limit'] = data.limit\n        full_args['issues_limit_s'] = (data.page - 1) * data.limit\n        full_args['issues_limit_e'] = data.page * data.limit\n        print(full_args)\n        main_query = cur.format(f\"SELECT issues.type                             AS name,\\n                                                 issues.context_string                   AS value,\\n                                                 COUNT(DISTINCT raw_sessions.session_id) AS session_count,\\n                                                 sum(session_count) OVER ()              AS total_sessions,\\n                                                 COUNT(1) OVER ()                        AS count\\n                                          FROM (SELECT session_id\\n                                                {query_part}) AS raw_sessions\\n                                                   INNER JOIN experimental.events ON (raw_sessions.session_id = events.session_id)\\n                                                   INNER JOIN experimental.issues ON (events.issue_id = issues.issue_id)\\n                                          WHERE event_type = 'ISSUE'\\n                                            AND events.datetime >= toDateTime(%(startDate)s / 1000)\\n                                            AND events.datetime <= toDateTime(%(endDate)s / 1000)\\n                                            AND events.project_id = %(projectId)s\\n                                            AND issues.project_id = %(projectId)s\\n                                          GROUP BY issues.type, issues.context_string\\n                                          ORDER BY session_count DESC\\n                                          LIMIT %(issues_limit)s OFFSET %(issues_limit_s)s\", full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        issues = cur.execute(main_query)\n        issues = helper.list_to_camel_case(issues)\n        if len(issues) > 0:\n            total_sessions = issues[0]['totalSessions']\n            issues_count = issues[0]['count']\n            for s in issues:\n                s.pop('totalSessions')\n                s.pop('count')\n        else:\n            total_sessions = 0\n            issues_count = 0\n        return {'count': issues_count, 'totalSessions': total_sessions, 'values': issues}",
        "mutated": [
            "def search_table_of_individual_issues(data: schemas.SessionsSearchPayloadSchema, project_id: int):\n    if False:\n        i = 10\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None)\n    with ch_client.ClickHouseClient() as cur:\n        full_args['issues_limit'] = data.limit\n        full_args['issues_limit_s'] = (data.page - 1) * data.limit\n        full_args['issues_limit_e'] = data.page * data.limit\n        print(full_args)\n        main_query = cur.format(f\"SELECT issues.type                             AS name,\\n                                                 issues.context_string                   AS value,\\n                                                 COUNT(DISTINCT raw_sessions.session_id) AS session_count,\\n                                                 sum(session_count) OVER ()              AS total_sessions,\\n                                                 COUNT(1) OVER ()                        AS count\\n                                          FROM (SELECT session_id\\n                                                {query_part}) AS raw_sessions\\n                                                   INNER JOIN experimental.events ON (raw_sessions.session_id = events.session_id)\\n                                                   INNER JOIN experimental.issues ON (events.issue_id = issues.issue_id)\\n                                          WHERE event_type = 'ISSUE'\\n                                            AND events.datetime >= toDateTime(%(startDate)s / 1000)\\n                                            AND events.datetime <= toDateTime(%(endDate)s / 1000)\\n                                            AND events.project_id = %(projectId)s\\n                                            AND issues.project_id = %(projectId)s\\n                                          GROUP BY issues.type, issues.context_string\\n                                          ORDER BY session_count DESC\\n                                          LIMIT %(issues_limit)s OFFSET %(issues_limit_s)s\", full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        issues = cur.execute(main_query)\n        issues = helper.list_to_camel_case(issues)\n        if len(issues) > 0:\n            total_sessions = issues[0]['totalSessions']\n            issues_count = issues[0]['count']\n            for s in issues:\n                s.pop('totalSessions')\n                s.pop('count')\n        else:\n            total_sessions = 0\n            issues_count = 0\n        return {'count': issues_count, 'totalSessions': total_sessions, 'values': issues}",
            "def search_table_of_individual_issues(data: schemas.SessionsSearchPayloadSchema, project_id: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None)\n    with ch_client.ClickHouseClient() as cur:\n        full_args['issues_limit'] = data.limit\n        full_args['issues_limit_s'] = (data.page - 1) * data.limit\n        full_args['issues_limit_e'] = data.page * data.limit\n        print(full_args)\n        main_query = cur.format(f\"SELECT issues.type                             AS name,\\n                                                 issues.context_string                   AS value,\\n                                                 COUNT(DISTINCT raw_sessions.session_id) AS session_count,\\n                                                 sum(session_count) OVER ()              AS total_sessions,\\n                                                 COUNT(1) OVER ()                        AS count\\n                                          FROM (SELECT session_id\\n                                                {query_part}) AS raw_sessions\\n                                                   INNER JOIN experimental.events ON (raw_sessions.session_id = events.session_id)\\n                                                   INNER JOIN experimental.issues ON (events.issue_id = issues.issue_id)\\n                                          WHERE event_type = 'ISSUE'\\n                                            AND events.datetime >= toDateTime(%(startDate)s / 1000)\\n                                            AND events.datetime <= toDateTime(%(endDate)s / 1000)\\n                                            AND events.project_id = %(projectId)s\\n                                            AND issues.project_id = %(projectId)s\\n                                          GROUP BY issues.type, issues.context_string\\n                                          ORDER BY session_count DESC\\n                                          LIMIT %(issues_limit)s OFFSET %(issues_limit_s)s\", full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        issues = cur.execute(main_query)\n        issues = helper.list_to_camel_case(issues)\n        if len(issues) > 0:\n            total_sessions = issues[0]['totalSessions']\n            issues_count = issues[0]['count']\n            for s in issues:\n                s.pop('totalSessions')\n                s.pop('count')\n        else:\n            total_sessions = 0\n            issues_count = 0\n        return {'count': issues_count, 'totalSessions': total_sessions, 'values': issues}",
            "def search_table_of_individual_issues(data: schemas.SessionsSearchPayloadSchema, project_id: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None)\n    with ch_client.ClickHouseClient() as cur:\n        full_args['issues_limit'] = data.limit\n        full_args['issues_limit_s'] = (data.page - 1) * data.limit\n        full_args['issues_limit_e'] = data.page * data.limit\n        print(full_args)\n        main_query = cur.format(f\"SELECT issues.type                             AS name,\\n                                                 issues.context_string                   AS value,\\n                                                 COUNT(DISTINCT raw_sessions.session_id) AS session_count,\\n                                                 sum(session_count) OVER ()              AS total_sessions,\\n                                                 COUNT(1) OVER ()                        AS count\\n                                          FROM (SELECT session_id\\n                                                {query_part}) AS raw_sessions\\n                                                   INNER JOIN experimental.events ON (raw_sessions.session_id = events.session_id)\\n                                                   INNER JOIN experimental.issues ON (events.issue_id = issues.issue_id)\\n                                          WHERE event_type = 'ISSUE'\\n                                            AND events.datetime >= toDateTime(%(startDate)s / 1000)\\n                                            AND events.datetime <= toDateTime(%(endDate)s / 1000)\\n                                            AND events.project_id = %(projectId)s\\n                                            AND issues.project_id = %(projectId)s\\n                                          GROUP BY issues.type, issues.context_string\\n                                          ORDER BY session_count DESC\\n                                          LIMIT %(issues_limit)s OFFSET %(issues_limit_s)s\", full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        issues = cur.execute(main_query)\n        issues = helper.list_to_camel_case(issues)\n        if len(issues) > 0:\n            total_sessions = issues[0]['totalSessions']\n            issues_count = issues[0]['count']\n            for s in issues:\n                s.pop('totalSessions')\n                s.pop('count')\n        else:\n            total_sessions = 0\n            issues_count = 0\n        return {'count': issues_count, 'totalSessions': total_sessions, 'values': issues}",
            "def search_table_of_individual_issues(data: schemas.SessionsSearchPayloadSchema, project_id: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None)\n    with ch_client.ClickHouseClient() as cur:\n        full_args['issues_limit'] = data.limit\n        full_args['issues_limit_s'] = (data.page - 1) * data.limit\n        full_args['issues_limit_e'] = data.page * data.limit\n        print(full_args)\n        main_query = cur.format(f\"SELECT issues.type                             AS name,\\n                                                 issues.context_string                   AS value,\\n                                                 COUNT(DISTINCT raw_sessions.session_id) AS session_count,\\n                                                 sum(session_count) OVER ()              AS total_sessions,\\n                                                 COUNT(1) OVER ()                        AS count\\n                                          FROM (SELECT session_id\\n                                                {query_part}) AS raw_sessions\\n                                                   INNER JOIN experimental.events ON (raw_sessions.session_id = events.session_id)\\n                                                   INNER JOIN experimental.issues ON (events.issue_id = issues.issue_id)\\n                                          WHERE event_type = 'ISSUE'\\n                                            AND events.datetime >= toDateTime(%(startDate)s / 1000)\\n                                            AND events.datetime <= toDateTime(%(endDate)s / 1000)\\n                                            AND events.project_id = %(projectId)s\\n                                            AND issues.project_id = %(projectId)s\\n                                          GROUP BY issues.type, issues.context_string\\n                                          ORDER BY session_count DESC\\n                                          LIMIT %(issues_limit)s OFFSET %(issues_limit_s)s\", full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        issues = cur.execute(main_query)\n        issues = helper.list_to_camel_case(issues)\n        if len(issues) > 0:\n            total_sessions = issues[0]['totalSessions']\n            issues_count = issues[0]['count']\n            for s in issues:\n                s.pop('totalSessions')\n                s.pop('count')\n        else:\n            total_sessions = 0\n            issues_count = 0\n        return {'count': issues_count, 'totalSessions': total_sessions, 'values': issues}",
            "def search_table_of_individual_issues(data: schemas.SessionsSearchPayloadSchema, project_id: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (full_args, query_part) = search_query_parts_ch(data=data, error_status=None, errors_only=False, favorite_only=False, issue=None, project_id=project_id, user_id=None)\n    with ch_client.ClickHouseClient() as cur:\n        full_args['issues_limit'] = data.limit\n        full_args['issues_limit_s'] = (data.page - 1) * data.limit\n        full_args['issues_limit_e'] = data.page * data.limit\n        print(full_args)\n        main_query = cur.format(f\"SELECT issues.type                             AS name,\\n                                                 issues.context_string                   AS value,\\n                                                 COUNT(DISTINCT raw_sessions.session_id) AS session_count,\\n                                                 sum(session_count) OVER ()              AS total_sessions,\\n                                                 COUNT(1) OVER ()                        AS count\\n                                          FROM (SELECT session_id\\n                                                {query_part}) AS raw_sessions\\n                                                   INNER JOIN experimental.events ON (raw_sessions.session_id = events.session_id)\\n                                                   INNER JOIN experimental.issues ON (events.issue_id = issues.issue_id)\\n                                          WHERE event_type = 'ISSUE'\\n                                            AND events.datetime >= toDateTime(%(startDate)s / 1000)\\n                                            AND events.datetime <= toDateTime(%(endDate)s / 1000)\\n                                            AND events.project_id = %(projectId)s\\n                                            AND issues.project_id = %(projectId)s\\n                                          GROUP BY issues.type, issues.context_string\\n                                          ORDER BY session_count DESC\\n                                          LIMIT %(issues_limit)s OFFSET %(issues_limit_s)s\", full_args)\n        logging.debug('--------------------')\n        logging.debug(main_query)\n        logging.debug('--------------------')\n        issues = cur.execute(main_query)\n        issues = helper.list_to_camel_case(issues)\n        if len(issues) > 0:\n            total_sessions = issues[0]['totalSessions']\n            issues_count = issues[0]['count']\n            for s in issues:\n                s.pop('totalSessions')\n                s.pop('count')\n        else:\n            total_sessions = 0\n            issues_count = 0\n        return {'count': issues_count, 'totalSessions': total_sessions, 'values': issues}"
        ]
    },
    {
        "func_name": "__is_valid_event",
        "original": "def __is_valid_event(is_any: bool, event: schemas.SessionSearchEventSchema2):\n    return not (not is_any and len(event.value) == 0 and (event.type not in [schemas.EventType.request_details, schemas.EventType.graphql]) or (event.type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb, schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage] and (event.source is None or len(event.source) == 0)) or (event.type in [schemas.EventType.request_details, schemas.EventType.graphql] and (event.filters is None or len(event.filters) == 0)))",
        "mutated": [
            "def __is_valid_event(is_any: bool, event: schemas.SessionSearchEventSchema2):\n    if False:\n        i = 10\n    return not (not is_any and len(event.value) == 0 and (event.type not in [schemas.EventType.request_details, schemas.EventType.graphql]) or (event.type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb, schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage] and (event.source is None or len(event.source) == 0)) or (event.type in [schemas.EventType.request_details, schemas.EventType.graphql] and (event.filters is None or len(event.filters) == 0)))",
            "def __is_valid_event(is_any: bool, event: schemas.SessionSearchEventSchema2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return not (not is_any and len(event.value) == 0 and (event.type not in [schemas.EventType.request_details, schemas.EventType.graphql]) or (event.type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb, schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage] and (event.source is None or len(event.source) == 0)) or (event.type in [schemas.EventType.request_details, schemas.EventType.graphql] and (event.filters is None or len(event.filters) == 0)))",
            "def __is_valid_event(is_any: bool, event: schemas.SessionSearchEventSchema2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return not (not is_any and len(event.value) == 0 and (event.type not in [schemas.EventType.request_details, schemas.EventType.graphql]) or (event.type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb, schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage] and (event.source is None or len(event.source) == 0)) or (event.type in [schemas.EventType.request_details, schemas.EventType.graphql] and (event.filters is None or len(event.filters) == 0)))",
            "def __is_valid_event(is_any: bool, event: schemas.SessionSearchEventSchema2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return not (not is_any and len(event.value) == 0 and (event.type not in [schemas.EventType.request_details, schemas.EventType.graphql]) or (event.type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb, schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage] and (event.source is None or len(event.source) == 0)) or (event.type in [schemas.EventType.request_details, schemas.EventType.graphql] and (event.filters is None or len(event.filters) == 0)))",
            "def __is_valid_event(is_any: bool, event: schemas.SessionSearchEventSchema2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return not (not is_any and len(event.value) == 0 and (event.type not in [schemas.EventType.request_details, schemas.EventType.graphql]) or (event.type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb, schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage] and (event.source is None or len(event.source) == 0)) or (event.type in [schemas.EventType.request_details, schemas.EventType.graphql] and (event.filters is None or len(event.filters) == 0)))"
        ]
    },
    {
        "func_name": "__get_event_type",
        "original": "def __get_event_type(event_type: Union[schemas.EventType, schemas.PerformanceEventType], platform='web'):\n    defs = {schemas.EventType.click: 'CLICK', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'LOCATION', schemas.PerformanceEventType.location_dom_complete: 'LOCATION', schemas.PerformanceEventType.location_largest_contentful_paint_time: 'LOCATION', schemas.PerformanceEventType.location_ttfb: 'LOCATION', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.state_action: 'STATEACTION', schemas.EventType.error: 'ERROR', schemas.PerformanceEventType.location_avg_cpu_load: 'PERFORMANCE', schemas.PerformanceEventType.location_avg_memory_usage: 'PERFORMANCE'}\n    defs_ios = {schemas.EventType.click: 'TAP', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'VIEW', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.error: 'CRASH'}\n    if platform == 'ios' and event_type in defs_ios:\n        return defs_ios.get(event_type)\n    if event_type not in defs:\n        raise Exception(f'unsupported EventType:{event_type}')\n    return defs.get(event_type)",
        "mutated": [
            "def __get_event_type(event_type: Union[schemas.EventType, schemas.PerformanceEventType], platform='web'):\n    if False:\n        i = 10\n    defs = {schemas.EventType.click: 'CLICK', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'LOCATION', schemas.PerformanceEventType.location_dom_complete: 'LOCATION', schemas.PerformanceEventType.location_largest_contentful_paint_time: 'LOCATION', schemas.PerformanceEventType.location_ttfb: 'LOCATION', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.state_action: 'STATEACTION', schemas.EventType.error: 'ERROR', schemas.PerformanceEventType.location_avg_cpu_load: 'PERFORMANCE', schemas.PerformanceEventType.location_avg_memory_usage: 'PERFORMANCE'}\n    defs_ios = {schemas.EventType.click: 'TAP', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'VIEW', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.error: 'CRASH'}\n    if platform == 'ios' and event_type in defs_ios:\n        return defs_ios.get(event_type)\n    if event_type not in defs:\n        raise Exception(f'unsupported EventType:{event_type}')\n    return defs.get(event_type)",
            "def __get_event_type(event_type: Union[schemas.EventType, schemas.PerformanceEventType], platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    defs = {schemas.EventType.click: 'CLICK', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'LOCATION', schemas.PerformanceEventType.location_dom_complete: 'LOCATION', schemas.PerformanceEventType.location_largest_contentful_paint_time: 'LOCATION', schemas.PerformanceEventType.location_ttfb: 'LOCATION', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.state_action: 'STATEACTION', schemas.EventType.error: 'ERROR', schemas.PerformanceEventType.location_avg_cpu_load: 'PERFORMANCE', schemas.PerformanceEventType.location_avg_memory_usage: 'PERFORMANCE'}\n    defs_ios = {schemas.EventType.click: 'TAP', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'VIEW', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.error: 'CRASH'}\n    if platform == 'ios' and event_type in defs_ios:\n        return defs_ios.get(event_type)\n    if event_type not in defs:\n        raise Exception(f'unsupported EventType:{event_type}')\n    return defs.get(event_type)",
            "def __get_event_type(event_type: Union[schemas.EventType, schemas.PerformanceEventType], platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    defs = {schemas.EventType.click: 'CLICK', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'LOCATION', schemas.PerformanceEventType.location_dom_complete: 'LOCATION', schemas.PerformanceEventType.location_largest_contentful_paint_time: 'LOCATION', schemas.PerformanceEventType.location_ttfb: 'LOCATION', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.state_action: 'STATEACTION', schemas.EventType.error: 'ERROR', schemas.PerformanceEventType.location_avg_cpu_load: 'PERFORMANCE', schemas.PerformanceEventType.location_avg_memory_usage: 'PERFORMANCE'}\n    defs_ios = {schemas.EventType.click: 'TAP', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'VIEW', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.error: 'CRASH'}\n    if platform == 'ios' and event_type in defs_ios:\n        return defs_ios.get(event_type)\n    if event_type not in defs:\n        raise Exception(f'unsupported EventType:{event_type}')\n    return defs.get(event_type)",
            "def __get_event_type(event_type: Union[schemas.EventType, schemas.PerformanceEventType], platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    defs = {schemas.EventType.click: 'CLICK', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'LOCATION', schemas.PerformanceEventType.location_dom_complete: 'LOCATION', schemas.PerformanceEventType.location_largest_contentful_paint_time: 'LOCATION', schemas.PerformanceEventType.location_ttfb: 'LOCATION', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.state_action: 'STATEACTION', schemas.EventType.error: 'ERROR', schemas.PerformanceEventType.location_avg_cpu_load: 'PERFORMANCE', schemas.PerformanceEventType.location_avg_memory_usage: 'PERFORMANCE'}\n    defs_ios = {schemas.EventType.click: 'TAP', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'VIEW', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.error: 'CRASH'}\n    if platform == 'ios' and event_type in defs_ios:\n        return defs_ios.get(event_type)\n    if event_type not in defs:\n        raise Exception(f'unsupported EventType:{event_type}')\n    return defs.get(event_type)",
            "def __get_event_type(event_type: Union[schemas.EventType, schemas.PerformanceEventType], platform='web'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    defs = {schemas.EventType.click: 'CLICK', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'LOCATION', schemas.PerformanceEventType.location_dom_complete: 'LOCATION', schemas.PerformanceEventType.location_largest_contentful_paint_time: 'LOCATION', schemas.PerformanceEventType.location_ttfb: 'LOCATION', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.state_action: 'STATEACTION', schemas.EventType.error: 'ERROR', schemas.PerformanceEventType.location_avg_cpu_load: 'PERFORMANCE', schemas.PerformanceEventType.location_avg_memory_usage: 'PERFORMANCE'}\n    defs_ios = {schemas.EventType.click: 'TAP', schemas.EventType.input: 'INPUT', schemas.EventType.location: 'VIEW', schemas.EventType.custom: 'CUSTOM', schemas.EventType.request: 'REQUEST', schemas.EventType.request_details: 'REQUEST', schemas.PerformanceEventType.fetch_failed: 'REQUEST', schemas.EventType.error: 'CRASH'}\n    if platform == 'ios' and event_type in defs_ios:\n        return defs_ios.get(event_type)\n    if event_type not in defs:\n        raise Exception(f'unsupported EventType:{event_type}')\n    return defs.get(event_type)"
        ]
    },
    {
        "func_name": "search_query_parts_ch",
        "original": "def search_query_parts_ch(data: schemas.SessionsSearchPayloadSchema, error_status, errors_only, favorite_only, issue, project_id, user_id, platform='web', extra_event=None):\n    ss_constraints = []\n    full_args = {'project_id': project_id, 'startDate': data.startTimestamp, 'endDate': data.endTimestamp, 'projectId': project_id, 'userId': user_id}\n    MAIN_EVENTS_TABLE = exp_ch_helper.get_main_events_table(timestamp=data.startTimestamp, platform=platform)\n    MAIN_SESSIONS_TABLE = exp_ch_helper.get_main_sessions_table(data.startTimestamp)\n    full_args['MAIN_EVENTS_TABLE'] = MAIN_EVENTS_TABLE\n    full_args['MAIN_SESSIONS_TABLE'] = MAIN_SESSIONS_TABLE\n    extra_constraints = ['s.project_id = %(project_id)s', 'isNotNull(s.duration)']\n    if favorite_only:\n        extra_constraints.append(f's.session_id IN (SELECT session_id\\n                                        FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                        WHERE user_id = %(userId)s)')\n    extra_from = ''\n    events_query_part = ''\n    issues = []\n    __events_where_basic = ['project_id = %(projectId)s', 'datetime >= toDateTime(%(startDate)s/1000)', 'datetime <= toDateTime(%(endDate)s/1000)']\n    events_conditions_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n    if len(data.filters) > 0:\n        meta_keys = None\n        include_in_events = False\n        for (i, f) in enumerate(data.filters):\n            if not isinstance(f.value, list):\n                f.value = [f.value]\n            filter_type = f.type\n            f.value = helper.values_for_operator(value=f.value, op=f.operator)\n            f_k = f'f_value{i}'\n            full_args = {**full_args, f_k: f.value, **_multiple_values(f.value, value_key=f_k)}\n            op = __get_sql_operator(f.operator) if filter_type not in [schemas.FilterType.events_count] else f.operator\n            is_any = _isAny_opreator(f.operator)\n            is_undefined = _isUndefined_operator(f.operator)\n            if not is_any and (not is_undefined) and (len(f.value) == 0):\n                continue\n            is_not = False\n            if __is_negation_operator(f.operator):\n                is_not = True\n            if filter_type == schemas.FilterType.user_browser:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_browser)')\n                    ss_constraints.append('isNotNull(ms.user_browser)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_os, schemas.FilterType.user_os_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_os)')\n                    ss_constraints.append('isNotNull(ms.user_os)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_device, schemas.FilterType.user_device_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_device)')\n                    ss_constraints.append('isNotNull(ms.user_device)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_country, schemas.FilterType.user_country_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_country)')\n                    ss_constraints.append('isNotNull(ms.user_country)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_city:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_city)')\n                    ss_constraints.append('isNotNull(ms.user_city)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_state:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_state)')\n                    ss_constraints.append('isNotNull(ms.user_state)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_source]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_source)')\n                    ss_constraints.append('isNotNull(ms.utm_source)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_source)')\n                    ss_constraints.append('isNull(ms.utm_source)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_medium]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_medium)')\n                    ss_constraints.append('isNotNull(ms.utm_medium)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_medium)')\n                    ss_constraints.append('isNull(ms.utm_medium')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_campaign]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_campaign)')\n                    ss_constraints.append('isNotNull(ms.utm_campaign)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_campaign)')\n                    ss_constraints.append('isNull(ms.utm_campaign)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.duration:\n                if len(f.value) > 0 and f.value[0] is not None:\n                    extra_constraints.append('s.duration >= %(minDuration)s')\n                    ss_constraints.append('ms.duration >= %(minDuration)s')\n                    full_args['minDuration'] = f.value[0]\n                if len(f.value) > 1 and f.value[1] is not None and (int(f.value[1]) > 0):\n                    extra_constraints.append('s.duration <= %(maxDuration)s')\n                    ss_constraints.append('ms.duration <= %(maxDuration)s')\n                    full_args['maxDuration'] = f.value[1]\n            elif filter_type == schemas.FilterType.referrer:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.base_referrer)')\n                    ss_constraints.append('isNotNull(ms.base_referrer)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == events.EventType.METADATA.ui_type:\n                if meta_keys is None:\n                    meta_keys = metadata.get(project_id=project_id)\n                    meta_keys = {m['key']: m['index'] for m in meta_keys}\n                if f.source in meta_keys.keys():\n                    if is_any:\n                        extra_constraints.append(f'isNotNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNotNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    elif is_undefined:\n                        extra_constraints.append(f'isNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    else:\n                        extra_constraints.append(_multiple_conditions(f's.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                        ss_constraints.append(_multiple_conditions(f'ms.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_id, schemas.FilterType.user_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_id)')\n                    ss_constraints.append('isNotNull(ms.user_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_id)')\n                    ss_constraints.append('isNull(ms.user_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_anonymous_id, schemas.FilterType.user_anonymous_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNotNull(ms.user_anonymous_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNull(ms.user_anonymous_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.rev_id, schemas.FilterType.rev_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.rev_id)')\n                    ss_constraints.append('isNotNull(ms.rev_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.rev_id)')\n                    ss_constraints.append('isNull(ms.rev_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.platform:\n                extra_constraints.append(_multiple_conditions(f's.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.issue:\n                if is_any:\n                    extra_constraints.append('notEmpty(s.issue_types)')\n                    ss_constraints.append('notEmpty(ms.issue_types)')\n                else:\n                    if f.source:\n                        issues.append(f)\n                    extra_constraints.append(f'hasAny(s.issue_types,%({f_k})s)')\n                    ss_constraints.append(f'hasAny(ms.issue_types,%({f_k})s)')\n                    if is_not:\n                        extra_constraints[-1] = f'not({extra_constraints[-1]})'\n                        ss_constraints[-1] = f'not({ss_constraints[-1]})'\n            elif filter_type == schemas.FilterType.events_count:\n                extra_constraints.append(_multiple_conditions(f's.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            else:\n                continue\n            include_in_events = True\n        if include_in_events:\n            events_conditions_where.append(f\"main.session_id IN (SELECT s.session_id \\n                                                FROM {MAIN_SESSIONS_TABLE} AS s\\n                                                WHERE {' AND '.join(extra_constraints)})\")\n    events_extra_join = ''\n    if len(data.events) > 0:\n        valid_events_count = 0\n        for event in data.events:\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if __is_valid_event(is_any=is_any, event=event):\n                valid_events_count += 1\n        events_query_from = []\n        events_conditions = []\n        events_conditions_not = []\n        event_index = 0\n        or_events = data.events_order == schemas.SearchEventOrder._or\n        for (i, event) in enumerate(data.events):\n            event_type = event.type\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if not __is_valid_event(is_any=is_any, event=event):\n                continue\n            op = __get_sql_operator(event.operator)\n            is_not = False\n            if __is_negation_operator(event.operator):\n                is_not = True\n                op = __reverse_sql_operator(op)\n            event_from = '%s'\n            event_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n            e_k = f'e_value{i}'\n            s_k = e_k + '_source'\n            if True or event.type != schemas.PerformanceEventType.time_between_events:\n                event.value = helper.values_for_operator(value=event.value, op=event.operator)\n                full_args = {**full_args, **_multiple_values(event.value, value_key=e_k), **_multiple_values(event.source, value_key=s_k)}\n            if event_type == events.EventType.CLICK.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.CLICK.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if event.operator == schemas.ClickEventExtraOperator._on_selector:\n                            event_where.append(_multiple_conditions(f'main.selector = %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                        elif is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.CLICK_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.INPUT.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.INPUT.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                    if event.source is not None and len(event.source) > 0:\n                        event_where.append(_multiple_conditions(f'main.value ILIKE %(custom{i})s', event.source, value_key=f'custom{i}'))\n                        full_args = {**full_args, **_multiple_values(event.source, value_key=f'custom{i}')}\n                else:\n                    _column = events.EventType.INPUT_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.LOCATION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = 'url_path'\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.VIEW_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.CUSTOM.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.CUSTOM.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.REQUEST.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.STATEACTION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.STATEACTION.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.ERROR.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main'\n                events_extra_join = f'SELECT * FROM {MAIN_EVENTS_TABLE} AS main1 WHERE main1.project_id=%(project_id)s'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                event.source = tuple(event.source)\n                events_conditions[-1]['condition'] = []\n                if not is_any and event.value not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'(main1.message {op} %({e_k})s OR main1.name {op} %({e_k})s)', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                if len(event.source) > 0 and event.source[0] not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'main1.source = %({s_k})s', event.source, value_key=s_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.PerformanceEventType.fetch_failed:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                event_where.append(f'main.{colname} = 0')\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.request_details:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                apply = False\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_fetch{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.FetchFilterType._url:\n                        event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._status_code:\n                        event_where.append(_multiple_conditions(f'main.status {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._duration:\n                        event_where.append(_multiple_conditions(f'main.duration {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    else:\n                        logging.warning(f'undefined FETCH filter: {f.type}')\n                if not apply:\n                    continue\n                else:\n                    events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.graphql:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='GRAPHQL'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_graphql{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.GraphqlFilterType._name:\n                        event_where.append(_multiple_conditions(f'main.{events.EventType.GRAPHQL.column} {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    else:\n                        logging.warning(f'undefined GRAPHQL filter: {f.type}')\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            else:\n                continue\n            if event_index == 0 or or_events:\n                event_where += ss_constraints\n            if is_not:\n                if event_index == 0 or or_events:\n                    events_query_from.append(f\"                                    (SELECT\\n                                        session_id, \\n                                        0 AS timestamp\\n                                      FROM sessions\\n                                      WHERE EXISTS(SELECT session_id \\n                                                    FROM {event_from} \\n                                                    WHERE {' AND '.join(event_where)} \\n                                                        AND sessions.session_id=ms.session_id) IS FALSE\\n                                        AND project_id = %(projectId)s \\n                                        AND start_ts >= %(startDate)s\\n                                        AND start_ts <= %(endDate)s\\n                                        AND duration IS NOT NULL\\n                                    ) {('' if or_events else f'AS event_{event_index}' + ('ON(TRUE)' if event_index > 0 else ''))}                                    \")\n                else:\n                    events_query_from.append(f\"            (SELECT\\n                event_0.session_id, \\n                event_{event_index - 1}.timestamp AS timestamp\\n              WHERE EXISTS(SELECT session_id FROM {event_from} WHERE {' AND '.join(event_where)}) IS FALSE\\n            ) AS event_{event_index} {('ON(TRUE)' if event_index > 0 else '')}            \")\n            elif data.events_order == schemas.SearchEventOrder._then:\n                pass\n            else:\n                events_query_from.append(f\"            (SELECT main.session_id, {('MIN' if event_index < valid_events_count - 1 else 'MAX')}(main.datetime) AS datetime\\n              FROM {event_from}\\n              WHERE {' AND '.join(event_where)}\\n              GROUP BY session_id\\n            ) {('' if or_events else f'AS event_{event_index} ' + ('ON(TRUE)' if event_index > 0 else ''))}            \")\n            event_index += 1\n            if event_index == 7 and data.events_order == schemas.SearchEventOrder._then:\n                break\n        if event_index < 2:\n            data.events_order = schemas.SearchEventOrder._or\n        if len(events_extra_join) > 0:\n            if event_index < 2:\n                events_extra_join = f'INNER JOIN ({events_extra_join}) AS main1 USING(error_id)'\n            else:\n                events_extra_join = f'LEFT JOIN ({events_extra_join}) AS main1 USING(error_id)'\n        if favorite_only and user_id is not None:\n            events_conditions_where.append(f'main.session_id IN (SELECT session_id\\n                                                FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                                WHERE user_id = %(userId)s)')\n        if data.events_order in [schemas.SearchEventOrder._then, schemas.SearchEventOrder._and]:\n            sequence_pattern = [f\"(?{i + 1}){c.get('time', '')}\" for (i, c) in enumerate(events_conditions)]\n            sub_join = ''\n            type_conditions = []\n            value_conditions = []\n            _value_conditions = []\n            sequence_conditions = []\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                if c.get('condition') and c['condition'] not in value_conditions and (c['condition'] % full_args not in _value_conditions):\n                    value_conditions.append(c['condition'])\n                    _value_conditions.append(c['condition'] % full_args)\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            del _value_conditions\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            del type_conditions\n            if len(value_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in value_conditions])})\")\n            del value_conditions\n            if len(events_conditions_not) > 0:\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND {c['condition']}\"\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                value_conditions_not = [f'sub.{c}' for c in __events_where_basic] + value_conditions_not\n                sub_join = f\"LEFT ANTI JOIN ( SELECT DISTINCT sub.session_id\\n                                    FROM {MAIN_EVENTS_TABLE} AS sub\\n                                    WHERE {' AND '.join([c for c in value_conditions_not])}) AS sub USING(session_id)\"\n                del _value_conditions_not\n                del value_conditions_not\n            if data.events_order == schemas.SearchEventOrder._then:\n                having = f\"HAVING sequenceMatch('{''.join(sequence_pattern)}')(main.datetime,{','.join(sequence_conditions)})\"\n            else:\n                having = f\"HAVING {' AND '.join([f'countIf({c})>0' for c in list(set(sequence_conditions))])}\"\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                        {sub_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\\n                                    {having}\"\n        else:\n            type_conditions = []\n            sequence_conditions = []\n            has_values = False\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    has_values = True\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            if len(events_conditions_not) > 0:\n                has_values = True\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND not({c['condition']})\".replace('sub.', 'main.')\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                del _value_conditions_not\n                sequence_conditions += value_conditions_not\n            if has_values:\n                events_conditions = [c for c in list(set(sequence_conditions))]\n                events_conditions_where.append(f\"({' OR '.join(events_conditions)})\")\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\"\n    else:\n        data.events = []\n    if data.startTimestamp is not None:\n        extra_constraints.append('s.datetime >= toDateTime(%(startDate)s/1000)')\n    if data.endTimestamp is not None:\n        extra_constraints.append('s.datetime <= toDateTime(%(endDate)s/1000)')\n    extra_join = ''\n    if issue is not None:\n        extra_join = '\\n                INNER JOIN LATERAL(SELECT TRUE FROM events_common.issues INNER JOIN public.issues AS p_issues USING (issue_id)\\n                WHERE issues.session_id=f.session_id \\n                    AND p_issues.type=%(issue_type)s \\n                    AND p_issues.context_string=%(issue_contextString)s\\n                    AND timestamp >= f.first_event_ts\\n                    AND timestamp <= f.last_event_ts) AS issues ON(TRUE)\\n                '\n        full_args['issue_contextString'] = issue['contextString']\n        full_args['issue_type'] = issue['type']\n    elif len(issues) > 0:\n        issues_conditions = []\n        for (i, f) in enumerate(issues):\n            f_k_v = f'f_issue_v{i}'\n            f_k_s = f_k_v + '_source'\n            full_args = {**full_args, **_multiple_values(f.value, value_key=f_k_v), f_k_s: f.source}\n            issues_conditions.append(_multiple_conditions(f'issues.type=%({f_k_v})s', f.value, value_key=f_k_v))\n            issues_conditions[-1] = f'({issues_conditions[-1]} AND issues.context_string=%({f_k_s})s)'\n        extra_join = f\"INNER JOIN (SELECT DISTINCT events.session_id\\n                                 FROM experimental.issues\\n                                          INNER JOIN experimental.events USING (issue_id)\\n                                 WHERE issues.project_id = %(projectId)s\\n                                   AND events.project_id = %(projectId)s\\n                                   AND events.datetime >= toDateTime(%(startDate)s/1000)\\n                                   AND events.datetime <= toDateTime(%(endDate)s/1000)\\n                                   AND {' OR '.join(issues_conditions)}\\n                            ) AS issues USING (session_id)\"\n    if extra_event:\n        extra_event = f'INNER JOIN ({extra_event}) AS extra_event USING(session_id)'\n    else:\n        extra_event = ''\n    if errors_only:\n        query_part = f\"{(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\"\n    else:\n        if len(events_query_part) > 0:\n            extra_join += f\"INNER JOIN (SELECT * \\n                                    FROM {MAIN_SESSIONS_TABLE} AS s {extra_event}\\n                                    WHERE {' AND '.join(extra_constraints)}) AS s ON(s.session_id=f.session_id)\"\n        else:\n            extra_join = f\"(SELECT * \\n                                FROM {MAIN_SESSIONS_TABLE} AS s {extra_join} {extra_event}\\n                                WHERE {' AND '.join(extra_constraints)}\\n                                ORDER BY _timestamp DESC\\n                                LIMIT 1 BY session_id) AS s\"\n        query_part = f\"                            FROM {(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\\n                            {extra_join}\\n                            {extra_from}\\n                            \"\n    return (full_args, query_part)",
        "mutated": [
            "def search_query_parts_ch(data: schemas.SessionsSearchPayloadSchema, error_status, errors_only, favorite_only, issue, project_id, user_id, platform='web', extra_event=None):\n    if False:\n        i = 10\n    ss_constraints = []\n    full_args = {'project_id': project_id, 'startDate': data.startTimestamp, 'endDate': data.endTimestamp, 'projectId': project_id, 'userId': user_id}\n    MAIN_EVENTS_TABLE = exp_ch_helper.get_main_events_table(timestamp=data.startTimestamp, platform=platform)\n    MAIN_SESSIONS_TABLE = exp_ch_helper.get_main_sessions_table(data.startTimestamp)\n    full_args['MAIN_EVENTS_TABLE'] = MAIN_EVENTS_TABLE\n    full_args['MAIN_SESSIONS_TABLE'] = MAIN_SESSIONS_TABLE\n    extra_constraints = ['s.project_id = %(project_id)s', 'isNotNull(s.duration)']\n    if favorite_only:\n        extra_constraints.append(f's.session_id IN (SELECT session_id\\n                                        FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                        WHERE user_id = %(userId)s)')\n    extra_from = ''\n    events_query_part = ''\n    issues = []\n    __events_where_basic = ['project_id = %(projectId)s', 'datetime >= toDateTime(%(startDate)s/1000)', 'datetime <= toDateTime(%(endDate)s/1000)']\n    events_conditions_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n    if len(data.filters) > 0:\n        meta_keys = None\n        include_in_events = False\n        for (i, f) in enumerate(data.filters):\n            if not isinstance(f.value, list):\n                f.value = [f.value]\n            filter_type = f.type\n            f.value = helper.values_for_operator(value=f.value, op=f.operator)\n            f_k = f'f_value{i}'\n            full_args = {**full_args, f_k: f.value, **_multiple_values(f.value, value_key=f_k)}\n            op = __get_sql_operator(f.operator) if filter_type not in [schemas.FilterType.events_count] else f.operator\n            is_any = _isAny_opreator(f.operator)\n            is_undefined = _isUndefined_operator(f.operator)\n            if not is_any and (not is_undefined) and (len(f.value) == 0):\n                continue\n            is_not = False\n            if __is_negation_operator(f.operator):\n                is_not = True\n            if filter_type == schemas.FilterType.user_browser:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_browser)')\n                    ss_constraints.append('isNotNull(ms.user_browser)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_os, schemas.FilterType.user_os_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_os)')\n                    ss_constraints.append('isNotNull(ms.user_os)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_device, schemas.FilterType.user_device_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_device)')\n                    ss_constraints.append('isNotNull(ms.user_device)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_country, schemas.FilterType.user_country_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_country)')\n                    ss_constraints.append('isNotNull(ms.user_country)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_city:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_city)')\n                    ss_constraints.append('isNotNull(ms.user_city)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_state:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_state)')\n                    ss_constraints.append('isNotNull(ms.user_state)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_source]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_source)')\n                    ss_constraints.append('isNotNull(ms.utm_source)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_source)')\n                    ss_constraints.append('isNull(ms.utm_source)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_medium]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_medium)')\n                    ss_constraints.append('isNotNull(ms.utm_medium)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_medium)')\n                    ss_constraints.append('isNull(ms.utm_medium')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_campaign]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_campaign)')\n                    ss_constraints.append('isNotNull(ms.utm_campaign)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_campaign)')\n                    ss_constraints.append('isNull(ms.utm_campaign)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.duration:\n                if len(f.value) > 0 and f.value[0] is not None:\n                    extra_constraints.append('s.duration >= %(minDuration)s')\n                    ss_constraints.append('ms.duration >= %(minDuration)s')\n                    full_args['minDuration'] = f.value[0]\n                if len(f.value) > 1 and f.value[1] is not None and (int(f.value[1]) > 0):\n                    extra_constraints.append('s.duration <= %(maxDuration)s')\n                    ss_constraints.append('ms.duration <= %(maxDuration)s')\n                    full_args['maxDuration'] = f.value[1]\n            elif filter_type == schemas.FilterType.referrer:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.base_referrer)')\n                    ss_constraints.append('isNotNull(ms.base_referrer)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == events.EventType.METADATA.ui_type:\n                if meta_keys is None:\n                    meta_keys = metadata.get(project_id=project_id)\n                    meta_keys = {m['key']: m['index'] for m in meta_keys}\n                if f.source in meta_keys.keys():\n                    if is_any:\n                        extra_constraints.append(f'isNotNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNotNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    elif is_undefined:\n                        extra_constraints.append(f'isNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    else:\n                        extra_constraints.append(_multiple_conditions(f's.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                        ss_constraints.append(_multiple_conditions(f'ms.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_id, schemas.FilterType.user_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_id)')\n                    ss_constraints.append('isNotNull(ms.user_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_id)')\n                    ss_constraints.append('isNull(ms.user_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_anonymous_id, schemas.FilterType.user_anonymous_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNotNull(ms.user_anonymous_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNull(ms.user_anonymous_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.rev_id, schemas.FilterType.rev_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.rev_id)')\n                    ss_constraints.append('isNotNull(ms.rev_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.rev_id)')\n                    ss_constraints.append('isNull(ms.rev_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.platform:\n                extra_constraints.append(_multiple_conditions(f's.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.issue:\n                if is_any:\n                    extra_constraints.append('notEmpty(s.issue_types)')\n                    ss_constraints.append('notEmpty(ms.issue_types)')\n                else:\n                    if f.source:\n                        issues.append(f)\n                    extra_constraints.append(f'hasAny(s.issue_types,%({f_k})s)')\n                    ss_constraints.append(f'hasAny(ms.issue_types,%({f_k})s)')\n                    if is_not:\n                        extra_constraints[-1] = f'not({extra_constraints[-1]})'\n                        ss_constraints[-1] = f'not({ss_constraints[-1]})'\n            elif filter_type == schemas.FilterType.events_count:\n                extra_constraints.append(_multiple_conditions(f's.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            else:\n                continue\n            include_in_events = True\n        if include_in_events:\n            events_conditions_where.append(f\"main.session_id IN (SELECT s.session_id \\n                                                FROM {MAIN_SESSIONS_TABLE} AS s\\n                                                WHERE {' AND '.join(extra_constraints)})\")\n    events_extra_join = ''\n    if len(data.events) > 0:\n        valid_events_count = 0\n        for event in data.events:\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if __is_valid_event(is_any=is_any, event=event):\n                valid_events_count += 1\n        events_query_from = []\n        events_conditions = []\n        events_conditions_not = []\n        event_index = 0\n        or_events = data.events_order == schemas.SearchEventOrder._or\n        for (i, event) in enumerate(data.events):\n            event_type = event.type\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if not __is_valid_event(is_any=is_any, event=event):\n                continue\n            op = __get_sql_operator(event.operator)\n            is_not = False\n            if __is_negation_operator(event.operator):\n                is_not = True\n                op = __reverse_sql_operator(op)\n            event_from = '%s'\n            event_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n            e_k = f'e_value{i}'\n            s_k = e_k + '_source'\n            if True or event.type != schemas.PerformanceEventType.time_between_events:\n                event.value = helper.values_for_operator(value=event.value, op=event.operator)\n                full_args = {**full_args, **_multiple_values(event.value, value_key=e_k), **_multiple_values(event.source, value_key=s_k)}\n            if event_type == events.EventType.CLICK.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.CLICK.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if event.operator == schemas.ClickEventExtraOperator._on_selector:\n                            event_where.append(_multiple_conditions(f'main.selector = %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                        elif is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.CLICK_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.INPUT.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.INPUT.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                    if event.source is not None and len(event.source) > 0:\n                        event_where.append(_multiple_conditions(f'main.value ILIKE %(custom{i})s', event.source, value_key=f'custom{i}'))\n                        full_args = {**full_args, **_multiple_values(event.source, value_key=f'custom{i}')}\n                else:\n                    _column = events.EventType.INPUT_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.LOCATION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = 'url_path'\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.VIEW_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.CUSTOM.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.CUSTOM.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.REQUEST.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.STATEACTION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.STATEACTION.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.ERROR.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main'\n                events_extra_join = f'SELECT * FROM {MAIN_EVENTS_TABLE} AS main1 WHERE main1.project_id=%(project_id)s'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                event.source = tuple(event.source)\n                events_conditions[-1]['condition'] = []\n                if not is_any and event.value not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'(main1.message {op} %({e_k})s OR main1.name {op} %({e_k})s)', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                if len(event.source) > 0 and event.source[0] not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'main1.source = %({s_k})s', event.source, value_key=s_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.PerformanceEventType.fetch_failed:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                event_where.append(f'main.{colname} = 0')\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.request_details:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                apply = False\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_fetch{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.FetchFilterType._url:\n                        event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._status_code:\n                        event_where.append(_multiple_conditions(f'main.status {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._duration:\n                        event_where.append(_multiple_conditions(f'main.duration {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    else:\n                        logging.warning(f'undefined FETCH filter: {f.type}')\n                if not apply:\n                    continue\n                else:\n                    events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.graphql:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='GRAPHQL'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_graphql{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.GraphqlFilterType._name:\n                        event_where.append(_multiple_conditions(f'main.{events.EventType.GRAPHQL.column} {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    else:\n                        logging.warning(f'undefined GRAPHQL filter: {f.type}')\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            else:\n                continue\n            if event_index == 0 or or_events:\n                event_where += ss_constraints\n            if is_not:\n                if event_index == 0 or or_events:\n                    events_query_from.append(f\"                                    (SELECT\\n                                        session_id, \\n                                        0 AS timestamp\\n                                      FROM sessions\\n                                      WHERE EXISTS(SELECT session_id \\n                                                    FROM {event_from} \\n                                                    WHERE {' AND '.join(event_where)} \\n                                                        AND sessions.session_id=ms.session_id) IS FALSE\\n                                        AND project_id = %(projectId)s \\n                                        AND start_ts >= %(startDate)s\\n                                        AND start_ts <= %(endDate)s\\n                                        AND duration IS NOT NULL\\n                                    ) {('' if or_events else f'AS event_{event_index}' + ('ON(TRUE)' if event_index > 0 else ''))}                                    \")\n                else:\n                    events_query_from.append(f\"            (SELECT\\n                event_0.session_id, \\n                event_{event_index - 1}.timestamp AS timestamp\\n              WHERE EXISTS(SELECT session_id FROM {event_from} WHERE {' AND '.join(event_where)}) IS FALSE\\n            ) AS event_{event_index} {('ON(TRUE)' if event_index > 0 else '')}            \")\n            elif data.events_order == schemas.SearchEventOrder._then:\n                pass\n            else:\n                events_query_from.append(f\"            (SELECT main.session_id, {('MIN' if event_index < valid_events_count - 1 else 'MAX')}(main.datetime) AS datetime\\n              FROM {event_from}\\n              WHERE {' AND '.join(event_where)}\\n              GROUP BY session_id\\n            ) {('' if or_events else f'AS event_{event_index} ' + ('ON(TRUE)' if event_index > 0 else ''))}            \")\n            event_index += 1\n            if event_index == 7 and data.events_order == schemas.SearchEventOrder._then:\n                break\n        if event_index < 2:\n            data.events_order = schemas.SearchEventOrder._or\n        if len(events_extra_join) > 0:\n            if event_index < 2:\n                events_extra_join = f'INNER JOIN ({events_extra_join}) AS main1 USING(error_id)'\n            else:\n                events_extra_join = f'LEFT JOIN ({events_extra_join}) AS main1 USING(error_id)'\n        if favorite_only and user_id is not None:\n            events_conditions_where.append(f'main.session_id IN (SELECT session_id\\n                                                FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                                WHERE user_id = %(userId)s)')\n        if data.events_order in [schemas.SearchEventOrder._then, schemas.SearchEventOrder._and]:\n            sequence_pattern = [f\"(?{i + 1}){c.get('time', '')}\" for (i, c) in enumerate(events_conditions)]\n            sub_join = ''\n            type_conditions = []\n            value_conditions = []\n            _value_conditions = []\n            sequence_conditions = []\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                if c.get('condition') and c['condition'] not in value_conditions and (c['condition'] % full_args not in _value_conditions):\n                    value_conditions.append(c['condition'])\n                    _value_conditions.append(c['condition'] % full_args)\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            del _value_conditions\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            del type_conditions\n            if len(value_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in value_conditions])})\")\n            del value_conditions\n            if len(events_conditions_not) > 0:\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND {c['condition']}\"\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                value_conditions_not = [f'sub.{c}' for c in __events_where_basic] + value_conditions_not\n                sub_join = f\"LEFT ANTI JOIN ( SELECT DISTINCT sub.session_id\\n                                    FROM {MAIN_EVENTS_TABLE} AS sub\\n                                    WHERE {' AND '.join([c for c in value_conditions_not])}) AS sub USING(session_id)\"\n                del _value_conditions_not\n                del value_conditions_not\n            if data.events_order == schemas.SearchEventOrder._then:\n                having = f\"HAVING sequenceMatch('{''.join(sequence_pattern)}')(main.datetime,{','.join(sequence_conditions)})\"\n            else:\n                having = f\"HAVING {' AND '.join([f'countIf({c})>0' for c in list(set(sequence_conditions))])}\"\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                        {sub_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\\n                                    {having}\"\n        else:\n            type_conditions = []\n            sequence_conditions = []\n            has_values = False\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    has_values = True\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            if len(events_conditions_not) > 0:\n                has_values = True\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND not({c['condition']})\".replace('sub.', 'main.')\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                del _value_conditions_not\n                sequence_conditions += value_conditions_not\n            if has_values:\n                events_conditions = [c for c in list(set(sequence_conditions))]\n                events_conditions_where.append(f\"({' OR '.join(events_conditions)})\")\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\"\n    else:\n        data.events = []\n    if data.startTimestamp is not None:\n        extra_constraints.append('s.datetime >= toDateTime(%(startDate)s/1000)')\n    if data.endTimestamp is not None:\n        extra_constraints.append('s.datetime <= toDateTime(%(endDate)s/1000)')\n    extra_join = ''\n    if issue is not None:\n        extra_join = '\\n                INNER JOIN LATERAL(SELECT TRUE FROM events_common.issues INNER JOIN public.issues AS p_issues USING (issue_id)\\n                WHERE issues.session_id=f.session_id \\n                    AND p_issues.type=%(issue_type)s \\n                    AND p_issues.context_string=%(issue_contextString)s\\n                    AND timestamp >= f.first_event_ts\\n                    AND timestamp <= f.last_event_ts) AS issues ON(TRUE)\\n                '\n        full_args['issue_contextString'] = issue['contextString']\n        full_args['issue_type'] = issue['type']\n    elif len(issues) > 0:\n        issues_conditions = []\n        for (i, f) in enumerate(issues):\n            f_k_v = f'f_issue_v{i}'\n            f_k_s = f_k_v + '_source'\n            full_args = {**full_args, **_multiple_values(f.value, value_key=f_k_v), f_k_s: f.source}\n            issues_conditions.append(_multiple_conditions(f'issues.type=%({f_k_v})s', f.value, value_key=f_k_v))\n            issues_conditions[-1] = f'({issues_conditions[-1]} AND issues.context_string=%({f_k_s})s)'\n        extra_join = f\"INNER JOIN (SELECT DISTINCT events.session_id\\n                                 FROM experimental.issues\\n                                          INNER JOIN experimental.events USING (issue_id)\\n                                 WHERE issues.project_id = %(projectId)s\\n                                   AND events.project_id = %(projectId)s\\n                                   AND events.datetime >= toDateTime(%(startDate)s/1000)\\n                                   AND events.datetime <= toDateTime(%(endDate)s/1000)\\n                                   AND {' OR '.join(issues_conditions)}\\n                            ) AS issues USING (session_id)\"\n    if extra_event:\n        extra_event = f'INNER JOIN ({extra_event}) AS extra_event USING(session_id)'\n    else:\n        extra_event = ''\n    if errors_only:\n        query_part = f\"{(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\"\n    else:\n        if len(events_query_part) > 0:\n            extra_join += f\"INNER JOIN (SELECT * \\n                                    FROM {MAIN_SESSIONS_TABLE} AS s {extra_event}\\n                                    WHERE {' AND '.join(extra_constraints)}) AS s ON(s.session_id=f.session_id)\"\n        else:\n            extra_join = f\"(SELECT * \\n                                FROM {MAIN_SESSIONS_TABLE} AS s {extra_join} {extra_event}\\n                                WHERE {' AND '.join(extra_constraints)}\\n                                ORDER BY _timestamp DESC\\n                                LIMIT 1 BY session_id) AS s\"\n        query_part = f\"                            FROM {(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\\n                            {extra_join}\\n                            {extra_from}\\n                            \"\n    return (full_args, query_part)",
            "def search_query_parts_ch(data: schemas.SessionsSearchPayloadSchema, error_status, errors_only, favorite_only, issue, project_id, user_id, platform='web', extra_event=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ss_constraints = []\n    full_args = {'project_id': project_id, 'startDate': data.startTimestamp, 'endDate': data.endTimestamp, 'projectId': project_id, 'userId': user_id}\n    MAIN_EVENTS_TABLE = exp_ch_helper.get_main_events_table(timestamp=data.startTimestamp, platform=platform)\n    MAIN_SESSIONS_TABLE = exp_ch_helper.get_main_sessions_table(data.startTimestamp)\n    full_args['MAIN_EVENTS_TABLE'] = MAIN_EVENTS_TABLE\n    full_args['MAIN_SESSIONS_TABLE'] = MAIN_SESSIONS_TABLE\n    extra_constraints = ['s.project_id = %(project_id)s', 'isNotNull(s.duration)']\n    if favorite_only:\n        extra_constraints.append(f's.session_id IN (SELECT session_id\\n                                        FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                        WHERE user_id = %(userId)s)')\n    extra_from = ''\n    events_query_part = ''\n    issues = []\n    __events_where_basic = ['project_id = %(projectId)s', 'datetime >= toDateTime(%(startDate)s/1000)', 'datetime <= toDateTime(%(endDate)s/1000)']\n    events_conditions_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n    if len(data.filters) > 0:\n        meta_keys = None\n        include_in_events = False\n        for (i, f) in enumerate(data.filters):\n            if not isinstance(f.value, list):\n                f.value = [f.value]\n            filter_type = f.type\n            f.value = helper.values_for_operator(value=f.value, op=f.operator)\n            f_k = f'f_value{i}'\n            full_args = {**full_args, f_k: f.value, **_multiple_values(f.value, value_key=f_k)}\n            op = __get_sql_operator(f.operator) if filter_type not in [schemas.FilterType.events_count] else f.operator\n            is_any = _isAny_opreator(f.operator)\n            is_undefined = _isUndefined_operator(f.operator)\n            if not is_any and (not is_undefined) and (len(f.value) == 0):\n                continue\n            is_not = False\n            if __is_negation_operator(f.operator):\n                is_not = True\n            if filter_type == schemas.FilterType.user_browser:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_browser)')\n                    ss_constraints.append('isNotNull(ms.user_browser)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_os, schemas.FilterType.user_os_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_os)')\n                    ss_constraints.append('isNotNull(ms.user_os)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_device, schemas.FilterType.user_device_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_device)')\n                    ss_constraints.append('isNotNull(ms.user_device)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_country, schemas.FilterType.user_country_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_country)')\n                    ss_constraints.append('isNotNull(ms.user_country)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_city:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_city)')\n                    ss_constraints.append('isNotNull(ms.user_city)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_state:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_state)')\n                    ss_constraints.append('isNotNull(ms.user_state)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_source]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_source)')\n                    ss_constraints.append('isNotNull(ms.utm_source)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_source)')\n                    ss_constraints.append('isNull(ms.utm_source)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_medium]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_medium)')\n                    ss_constraints.append('isNotNull(ms.utm_medium)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_medium)')\n                    ss_constraints.append('isNull(ms.utm_medium')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_campaign]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_campaign)')\n                    ss_constraints.append('isNotNull(ms.utm_campaign)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_campaign)')\n                    ss_constraints.append('isNull(ms.utm_campaign)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.duration:\n                if len(f.value) > 0 and f.value[0] is not None:\n                    extra_constraints.append('s.duration >= %(minDuration)s')\n                    ss_constraints.append('ms.duration >= %(minDuration)s')\n                    full_args['minDuration'] = f.value[0]\n                if len(f.value) > 1 and f.value[1] is not None and (int(f.value[1]) > 0):\n                    extra_constraints.append('s.duration <= %(maxDuration)s')\n                    ss_constraints.append('ms.duration <= %(maxDuration)s')\n                    full_args['maxDuration'] = f.value[1]\n            elif filter_type == schemas.FilterType.referrer:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.base_referrer)')\n                    ss_constraints.append('isNotNull(ms.base_referrer)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == events.EventType.METADATA.ui_type:\n                if meta_keys is None:\n                    meta_keys = metadata.get(project_id=project_id)\n                    meta_keys = {m['key']: m['index'] for m in meta_keys}\n                if f.source in meta_keys.keys():\n                    if is_any:\n                        extra_constraints.append(f'isNotNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNotNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    elif is_undefined:\n                        extra_constraints.append(f'isNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    else:\n                        extra_constraints.append(_multiple_conditions(f's.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                        ss_constraints.append(_multiple_conditions(f'ms.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_id, schemas.FilterType.user_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_id)')\n                    ss_constraints.append('isNotNull(ms.user_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_id)')\n                    ss_constraints.append('isNull(ms.user_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_anonymous_id, schemas.FilterType.user_anonymous_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNotNull(ms.user_anonymous_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNull(ms.user_anonymous_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.rev_id, schemas.FilterType.rev_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.rev_id)')\n                    ss_constraints.append('isNotNull(ms.rev_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.rev_id)')\n                    ss_constraints.append('isNull(ms.rev_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.platform:\n                extra_constraints.append(_multiple_conditions(f's.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.issue:\n                if is_any:\n                    extra_constraints.append('notEmpty(s.issue_types)')\n                    ss_constraints.append('notEmpty(ms.issue_types)')\n                else:\n                    if f.source:\n                        issues.append(f)\n                    extra_constraints.append(f'hasAny(s.issue_types,%({f_k})s)')\n                    ss_constraints.append(f'hasAny(ms.issue_types,%({f_k})s)')\n                    if is_not:\n                        extra_constraints[-1] = f'not({extra_constraints[-1]})'\n                        ss_constraints[-1] = f'not({ss_constraints[-1]})'\n            elif filter_type == schemas.FilterType.events_count:\n                extra_constraints.append(_multiple_conditions(f's.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            else:\n                continue\n            include_in_events = True\n        if include_in_events:\n            events_conditions_where.append(f\"main.session_id IN (SELECT s.session_id \\n                                                FROM {MAIN_SESSIONS_TABLE} AS s\\n                                                WHERE {' AND '.join(extra_constraints)})\")\n    events_extra_join = ''\n    if len(data.events) > 0:\n        valid_events_count = 0\n        for event in data.events:\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if __is_valid_event(is_any=is_any, event=event):\n                valid_events_count += 1\n        events_query_from = []\n        events_conditions = []\n        events_conditions_not = []\n        event_index = 0\n        or_events = data.events_order == schemas.SearchEventOrder._or\n        for (i, event) in enumerate(data.events):\n            event_type = event.type\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if not __is_valid_event(is_any=is_any, event=event):\n                continue\n            op = __get_sql_operator(event.operator)\n            is_not = False\n            if __is_negation_operator(event.operator):\n                is_not = True\n                op = __reverse_sql_operator(op)\n            event_from = '%s'\n            event_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n            e_k = f'e_value{i}'\n            s_k = e_k + '_source'\n            if True or event.type != schemas.PerformanceEventType.time_between_events:\n                event.value = helper.values_for_operator(value=event.value, op=event.operator)\n                full_args = {**full_args, **_multiple_values(event.value, value_key=e_k), **_multiple_values(event.source, value_key=s_k)}\n            if event_type == events.EventType.CLICK.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.CLICK.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if event.operator == schemas.ClickEventExtraOperator._on_selector:\n                            event_where.append(_multiple_conditions(f'main.selector = %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                        elif is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.CLICK_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.INPUT.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.INPUT.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                    if event.source is not None and len(event.source) > 0:\n                        event_where.append(_multiple_conditions(f'main.value ILIKE %(custom{i})s', event.source, value_key=f'custom{i}'))\n                        full_args = {**full_args, **_multiple_values(event.source, value_key=f'custom{i}')}\n                else:\n                    _column = events.EventType.INPUT_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.LOCATION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = 'url_path'\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.VIEW_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.CUSTOM.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.CUSTOM.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.REQUEST.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.STATEACTION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.STATEACTION.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.ERROR.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main'\n                events_extra_join = f'SELECT * FROM {MAIN_EVENTS_TABLE} AS main1 WHERE main1.project_id=%(project_id)s'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                event.source = tuple(event.source)\n                events_conditions[-1]['condition'] = []\n                if not is_any and event.value not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'(main1.message {op} %({e_k})s OR main1.name {op} %({e_k})s)', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                if len(event.source) > 0 and event.source[0] not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'main1.source = %({s_k})s', event.source, value_key=s_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.PerformanceEventType.fetch_failed:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                event_where.append(f'main.{colname} = 0')\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.request_details:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                apply = False\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_fetch{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.FetchFilterType._url:\n                        event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._status_code:\n                        event_where.append(_multiple_conditions(f'main.status {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._duration:\n                        event_where.append(_multiple_conditions(f'main.duration {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    else:\n                        logging.warning(f'undefined FETCH filter: {f.type}')\n                if not apply:\n                    continue\n                else:\n                    events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.graphql:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='GRAPHQL'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_graphql{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.GraphqlFilterType._name:\n                        event_where.append(_multiple_conditions(f'main.{events.EventType.GRAPHQL.column} {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    else:\n                        logging.warning(f'undefined GRAPHQL filter: {f.type}')\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            else:\n                continue\n            if event_index == 0 or or_events:\n                event_where += ss_constraints\n            if is_not:\n                if event_index == 0 or or_events:\n                    events_query_from.append(f\"                                    (SELECT\\n                                        session_id, \\n                                        0 AS timestamp\\n                                      FROM sessions\\n                                      WHERE EXISTS(SELECT session_id \\n                                                    FROM {event_from} \\n                                                    WHERE {' AND '.join(event_where)} \\n                                                        AND sessions.session_id=ms.session_id) IS FALSE\\n                                        AND project_id = %(projectId)s \\n                                        AND start_ts >= %(startDate)s\\n                                        AND start_ts <= %(endDate)s\\n                                        AND duration IS NOT NULL\\n                                    ) {('' if or_events else f'AS event_{event_index}' + ('ON(TRUE)' if event_index > 0 else ''))}                                    \")\n                else:\n                    events_query_from.append(f\"            (SELECT\\n                event_0.session_id, \\n                event_{event_index - 1}.timestamp AS timestamp\\n              WHERE EXISTS(SELECT session_id FROM {event_from} WHERE {' AND '.join(event_where)}) IS FALSE\\n            ) AS event_{event_index} {('ON(TRUE)' if event_index > 0 else '')}            \")\n            elif data.events_order == schemas.SearchEventOrder._then:\n                pass\n            else:\n                events_query_from.append(f\"            (SELECT main.session_id, {('MIN' if event_index < valid_events_count - 1 else 'MAX')}(main.datetime) AS datetime\\n              FROM {event_from}\\n              WHERE {' AND '.join(event_where)}\\n              GROUP BY session_id\\n            ) {('' if or_events else f'AS event_{event_index} ' + ('ON(TRUE)' if event_index > 0 else ''))}            \")\n            event_index += 1\n            if event_index == 7 and data.events_order == schemas.SearchEventOrder._then:\n                break\n        if event_index < 2:\n            data.events_order = schemas.SearchEventOrder._or\n        if len(events_extra_join) > 0:\n            if event_index < 2:\n                events_extra_join = f'INNER JOIN ({events_extra_join}) AS main1 USING(error_id)'\n            else:\n                events_extra_join = f'LEFT JOIN ({events_extra_join}) AS main1 USING(error_id)'\n        if favorite_only and user_id is not None:\n            events_conditions_where.append(f'main.session_id IN (SELECT session_id\\n                                                FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                                WHERE user_id = %(userId)s)')\n        if data.events_order in [schemas.SearchEventOrder._then, schemas.SearchEventOrder._and]:\n            sequence_pattern = [f\"(?{i + 1}){c.get('time', '')}\" for (i, c) in enumerate(events_conditions)]\n            sub_join = ''\n            type_conditions = []\n            value_conditions = []\n            _value_conditions = []\n            sequence_conditions = []\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                if c.get('condition') and c['condition'] not in value_conditions and (c['condition'] % full_args not in _value_conditions):\n                    value_conditions.append(c['condition'])\n                    _value_conditions.append(c['condition'] % full_args)\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            del _value_conditions\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            del type_conditions\n            if len(value_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in value_conditions])})\")\n            del value_conditions\n            if len(events_conditions_not) > 0:\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND {c['condition']}\"\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                value_conditions_not = [f'sub.{c}' for c in __events_where_basic] + value_conditions_not\n                sub_join = f\"LEFT ANTI JOIN ( SELECT DISTINCT sub.session_id\\n                                    FROM {MAIN_EVENTS_TABLE} AS sub\\n                                    WHERE {' AND '.join([c for c in value_conditions_not])}) AS sub USING(session_id)\"\n                del _value_conditions_not\n                del value_conditions_not\n            if data.events_order == schemas.SearchEventOrder._then:\n                having = f\"HAVING sequenceMatch('{''.join(sequence_pattern)}')(main.datetime,{','.join(sequence_conditions)})\"\n            else:\n                having = f\"HAVING {' AND '.join([f'countIf({c})>0' for c in list(set(sequence_conditions))])}\"\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                        {sub_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\\n                                    {having}\"\n        else:\n            type_conditions = []\n            sequence_conditions = []\n            has_values = False\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    has_values = True\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            if len(events_conditions_not) > 0:\n                has_values = True\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND not({c['condition']})\".replace('sub.', 'main.')\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                del _value_conditions_not\n                sequence_conditions += value_conditions_not\n            if has_values:\n                events_conditions = [c for c in list(set(sequence_conditions))]\n                events_conditions_where.append(f\"({' OR '.join(events_conditions)})\")\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\"\n    else:\n        data.events = []\n    if data.startTimestamp is not None:\n        extra_constraints.append('s.datetime >= toDateTime(%(startDate)s/1000)')\n    if data.endTimestamp is not None:\n        extra_constraints.append('s.datetime <= toDateTime(%(endDate)s/1000)')\n    extra_join = ''\n    if issue is not None:\n        extra_join = '\\n                INNER JOIN LATERAL(SELECT TRUE FROM events_common.issues INNER JOIN public.issues AS p_issues USING (issue_id)\\n                WHERE issues.session_id=f.session_id \\n                    AND p_issues.type=%(issue_type)s \\n                    AND p_issues.context_string=%(issue_contextString)s\\n                    AND timestamp >= f.first_event_ts\\n                    AND timestamp <= f.last_event_ts) AS issues ON(TRUE)\\n                '\n        full_args['issue_contextString'] = issue['contextString']\n        full_args['issue_type'] = issue['type']\n    elif len(issues) > 0:\n        issues_conditions = []\n        for (i, f) in enumerate(issues):\n            f_k_v = f'f_issue_v{i}'\n            f_k_s = f_k_v + '_source'\n            full_args = {**full_args, **_multiple_values(f.value, value_key=f_k_v), f_k_s: f.source}\n            issues_conditions.append(_multiple_conditions(f'issues.type=%({f_k_v})s', f.value, value_key=f_k_v))\n            issues_conditions[-1] = f'({issues_conditions[-1]} AND issues.context_string=%({f_k_s})s)'\n        extra_join = f\"INNER JOIN (SELECT DISTINCT events.session_id\\n                                 FROM experimental.issues\\n                                          INNER JOIN experimental.events USING (issue_id)\\n                                 WHERE issues.project_id = %(projectId)s\\n                                   AND events.project_id = %(projectId)s\\n                                   AND events.datetime >= toDateTime(%(startDate)s/1000)\\n                                   AND events.datetime <= toDateTime(%(endDate)s/1000)\\n                                   AND {' OR '.join(issues_conditions)}\\n                            ) AS issues USING (session_id)\"\n    if extra_event:\n        extra_event = f'INNER JOIN ({extra_event}) AS extra_event USING(session_id)'\n    else:\n        extra_event = ''\n    if errors_only:\n        query_part = f\"{(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\"\n    else:\n        if len(events_query_part) > 0:\n            extra_join += f\"INNER JOIN (SELECT * \\n                                    FROM {MAIN_SESSIONS_TABLE} AS s {extra_event}\\n                                    WHERE {' AND '.join(extra_constraints)}) AS s ON(s.session_id=f.session_id)\"\n        else:\n            extra_join = f\"(SELECT * \\n                                FROM {MAIN_SESSIONS_TABLE} AS s {extra_join} {extra_event}\\n                                WHERE {' AND '.join(extra_constraints)}\\n                                ORDER BY _timestamp DESC\\n                                LIMIT 1 BY session_id) AS s\"\n        query_part = f\"                            FROM {(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\\n                            {extra_join}\\n                            {extra_from}\\n                            \"\n    return (full_args, query_part)",
            "def search_query_parts_ch(data: schemas.SessionsSearchPayloadSchema, error_status, errors_only, favorite_only, issue, project_id, user_id, platform='web', extra_event=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ss_constraints = []\n    full_args = {'project_id': project_id, 'startDate': data.startTimestamp, 'endDate': data.endTimestamp, 'projectId': project_id, 'userId': user_id}\n    MAIN_EVENTS_TABLE = exp_ch_helper.get_main_events_table(timestamp=data.startTimestamp, platform=platform)\n    MAIN_SESSIONS_TABLE = exp_ch_helper.get_main_sessions_table(data.startTimestamp)\n    full_args['MAIN_EVENTS_TABLE'] = MAIN_EVENTS_TABLE\n    full_args['MAIN_SESSIONS_TABLE'] = MAIN_SESSIONS_TABLE\n    extra_constraints = ['s.project_id = %(project_id)s', 'isNotNull(s.duration)']\n    if favorite_only:\n        extra_constraints.append(f's.session_id IN (SELECT session_id\\n                                        FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                        WHERE user_id = %(userId)s)')\n    extra_from = ''\n    events_query_part = ''\n    issues = []\n    __events_where_basic = ['project_id = %(projectId)s', 'datetime >= toDateTime(%(startDate)s/1000)', 'datetime <= toDateTime(%(endDate)s/1000)']\n    events_conditions_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n    if len(data.filters) > 0:\n        meta_keys = None\n        include_in_events = False\n        for (i, f) in enumerate(data.filters):\n            if not isinstance(f.value, list):\n                f.value = [f.value]\n            filter_type = f.type\n            f.value = helper.values_for_operator(value=f.value, op=f.operator)\n            f_k = f'f_value{i}'\n            full_args = {**full_args, f_k: f.value, **_multiple_values(f.value, value_key=f_k)}\n            op = __get_sql_operator(f.operator) if filter_type not in [schemas.FilterType.events_count] else f.operator\n            is_any = _isAny_opreator(f.operator)\n            is_undefined = _isUndefined_operator(f.operator)\n            if not is_any and (not is_undefined) and (len(f.value) == 0):\n                continue\n            is_not = False\n            if __is_negation_operator(f.operator):\n                is_not = True\n            if filter_type == schemas.FilterType.user_browser:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_browser)')\n                    ss_constraints.append('isNotNull(ms.user_browser)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_os, schemas.FilterType.user_os_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_os)')\n                    ss_constraints.append('isNotNull(ms.user_os)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_device, schemas.FilterType.user_device_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_device)')\n                    ss_constraints.append('isNotNull(ms.user_device)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_country, schemas.FilterType.user_country_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_country)')\n                    ss_constraints.append('isNotNull(ms.user_country)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_city:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_city)')\n                    ss_constraints.append('isNotNull(ms.user_city)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_state:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_state)')\n                    ss_constraints.append('isNotNull(ms.user_state)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_source]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_source)')\n                    ss_constraints.append('isNotNull(ms.utm_source)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_source)')\n                    ss_constraints.append('isNull(ms.utm_source)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_medium]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_medium)')\n                    ss_constraints.append('isNotNull(ms.utm_medium)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_medium)')\n                    ss_constraints.append('isNull(ms.utm_medium')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_campaign]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_campaign)')\n                    ss_constraints.append('isNotNull(ms.utm_campaign)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_campaign)')\n                    ss_constraints.append('isNull(ms.utm_campaign)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.duration:\n                if len(f.value) > 0 and f.value[0] is not None:\n                    extra_constraints.append('s.duration >= %(minDuration)s')\n                    ss_constraints.append('ms.duration >= %(minDuration)s')\n                    full_args['minDuration'] = f.value[0]\n                if len(f.value) > 1 and f.value[1] is not None and (int(f.value[1]) > 0):\n                    extra_constraints.append('s.duration <= %(maxDuration)s')\n                    ss_constraints.append('ms.duration <= %(maxDuration)s')\n                    full_args['maxDuration'] = f.value[1]\n            elif filter_type == schemas.FilterType.referrer:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.base_referrer)')\n                    ss_constraints.append('isNotNull(ms.base_referrer)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == events.EventType.METADATA.ui_type:\n                if meta_keys is None:\n                    meta_keys = metadata.get(project_id=project_id)\n                    meta_keys = {m['key']: m['index'] for m in meta_keys}\n                if f.source in meta_keys.keys():\n                    if is_any:\n                        extra_constraints.append(f'isNotNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNotNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    elif is_undefined:\n                        extra_constraints.append(f'isNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    else:\n                        extra_constraints.append(_multiple_conditions(f's.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                        ss_constraints.append(_multiple_conditions(f'ms.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_id, schemas.FilterType.user_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_id)')\n                    ss_constraints.append('isNotNull(ms.user_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_id)')\n                    ss_constraints.append('isNull(ms.user_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_anonymous_id, schemas.FilterType.user_anonymous_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNotNull(ms.user_anonymous_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNull(ms.user_anonymous_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.rev_id, schemas.FilterType.rev_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.rev_id)')\n                    ss_constraints.append('isNotNull(ms.rev_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.rev_id)')\n                    ss_constraints.append('isNull(ms.rev_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.platform:\n                extra_constraints.append(_multiple_conditions(f's.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.issue:\n                if is_any:\n                    extra_constraints.append('notEmpty(s.issue_types)')\n                    ss_constraints.append('notEmpty(ms.issue_types)')\n                else:\n                    if f.source:\n                        issues.append(f)\n                    extra_constraints.append(f'hasAny(s.issue_types,%({f_k})s)')\n                    ss_constraints.append(f'hasAny(ms.issue_types,%({f_k})s)')\n                    if is_not:\n                        extra_constraints[-1] = f'not({extra_constraints[-1]})'\n                        ss_constraints[-1] = f'not({ss_constraints[-1]})'\n            elif filter_type == schemas.FilterType.events_count:\n                extra_constraints.append(_multiple_conditions(f's.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            else:\n                continue\n            include_in_events = True\n        if include_in_events:\n            events_conditions_where.append(f\"main.session_id IN (SELECT s.session_id \\n                                                FROM {MAIN_SESSIONS_TABLE} AS s\\n                                                WHERE {' AND '.join(extra_constraints)})\")\n    events_extra_join = ''\n    if len(data.events) > 0:\n        valid_events_count = 0\n        for event in data.events:\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if __is_valid_event(is_any=is_any, event=event):\n                valid_events_count += 1\n        events_query_from = []\n        events_conditions = []\n        events_conditions_not = []\n        event_index = 0\n        or_events = data.events_order == schemas.SearchEventOrder._or\n        for (i, event) in enumerate(data.events):\n            event_type = event.type\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if not __is_valid_event(is_any=is_any, event=event):\n                continue\n            op = __get_sql_operator(event.operator)\n            is_not = False\n            if __is_negation_operator(event.operator):\n                is_not = True\n                op = __reverse_sql_operator(op)\n            event_from = '%s'\n            event_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n            e_k = f'e_value{i}'\n            s_k = e_k + '_source'\n            if True or event.type != schemas.PerformanceEventType.time_between_events:\n                event.value = helper.values_for_operator(value=event.value, op=event.operator)\n                full_args = {**full_args, **_multiple_values(event.value, value_key=e_k), **_multiple_values(event.source, value_key=s_k)}\n            if event_type == events.EventType.CLICK.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.CLICK.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if event.operator == schemas.ClickEventExtraOperator._on_selector:\n                            event_where.append(_multiple_conditions(f'main.selector = %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                        elif is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.CLICK_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.INPUT.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.INPUT.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                    if event.source is not None and len(event.source) > 0:\n                        event_where.append(_multiple_conditions(f'main.value ILIKE %(custom{i})s', event.source, value_key=f'custom{i}'))\n                        full_args = {**full_args, **_multiple_values(event.source, value_key=f'custom{i}')}\n                else:\n                    _column = events.EventType.INPUT_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.LOCATION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = 'url_path'\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.VIEW_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.CUSTOM.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.CUSTOM.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.REQUEST.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.STATEACTION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.STATEACTION.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.ERROR.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main'\n                events_extra_join = f'SELECT * FROM {MAIN_EVENTS_TABLE} AS main1 WHERE main1.project_id=%(project_id)s'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                event.source = tuple(event.source)\n                events_conditions[-1]['condition'] = []\n                if not is_any and event.value not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'(main1.message {op} %({e_k})s OR main1.name {op} %({e_k})s)', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                if len(event.source) > 0 and event.source[0] not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'main1.source = %({s_k})s', event.source, value_key=s_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.PerformanceEventType.fetch_failed:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                event_where.append(f'main.{colname} = 0')\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.request_details:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                apply = False\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_fetch{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.FetchFilterType._url:\n                        event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._status_code:\n                        event_where.append(_multiple_conditions(f'main.status {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._duration:\n                        event_where.append(_multiple_conditions(f'main.duration {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    else:\n                        logging.warning(f'undefined FETCH filter: {f.type}')\n                if not apply:\n                    continue\n                else:\n                    events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.graphql:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='GRAPHQL'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_graphql{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.GraphqlFilterType._name:\n                        event_where.append(_multiple_conditions(f'main.{events.EventType.GRAPHQL.column} {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    else:\n                        logging.warning(f'undefined GRAPHQL filter: {f.type}')\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            else:\n                continue\n            if event_index == 0 or or_events:\n                event_where += ss_constraints\n            if is_not:\n                if event_index == 0 or or_events:\n                    events_query_from.append(f\"                                    (SELECT\\n                                        session_id, \\n                                        0 AS timestamp\\n                                      FROM sessions\\n                                      WHERE EXISTS(SELECT session_id \\n                                                    FROM {event_from} \\n                                                    WHERE {' AND '.join(event_where)} \\n                                                        AND sessions.session_id=ms.session_id) IS FALSE\\n                                        AND project_id = %(projectId)s \\n                                        AND start_ts >= %(startDate)s\\n                                        AND start_ts <= %(endDate)s\\n                                        AND duration IS NOT NULL\\n                                    ) {('' if or_events else f'AS event_{event_index}' + ('ON(TRUE)' if event_index > 0 else ''))}                                    \")\n                else:\n                    events_query_from.append(f\"            (SELECT\\n                event_0.session_id, \\n                event_{event_index - 1}.timestamp AS timestamp\\n              WHERE EXISTS(SELECT session_id FROM {event_from} WHERE {' AND '.join(event_where)}) IS FALSE\\n            ) AS event_{event_index} {('ON(TRUE)' if event_index > 0 else '')}            \")\n            elif data.events_order == schemas.SearchEventOrder._then:\n                pass\n            else:\n                events_query_from.append(f\"            (SELECT main.session_id, {('MIN' if event_index < valid_events_count - 1 else 'MAX')}(main.datetime) AS datetime\\n              FROM {event_from}\\n              WHERE {' AND '.join(event_where)}\\n              GROUP BY session_id\\n            ) {('' if or_events else f'AS event_{event_index} ' + ('ON(TRUE)' if event_index > 0 else ''))}            \")\n            event_index += 1\n            if event_index == 7 and data.events_order == schemas.SearchEventOrder._then:\n                break\n        if event_index < 2:\n            data.events_order = schemas.SearchEventOrder._or\n        if len(events_extra_join) > 0:\n            if event_index < 2:\n                events_extra_join = f'INNER JOIN ({events_extra_join}) AS main1 USING(error_id)'\n            else:\n                events_extra_join = f'LEFT JOIN ({events_extra_join}) AS main1 USING(error_id)'\n        if favorite_only and user_id is not None:\n            events_conditions_where.append(f'main.session_id IN (SELECT session_id\\n                                                FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                                WHERE user_id = %(userId)s)')\n        if data.events_order in [schemas.SearchEventOrder._then, schemas.SearchEventOrder._and]:\n            sequence_pattern = [f\"(?{i + 1}){c.get('time', '')}\" for (i, c) in enumerate(events_conditions)]\n            sub_join = ''\n            type_conditions = []\n            value_conditions = []\n            _value_conditions = []\n            sequence_conditions = []\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                if c.get('condition') and c['condition'] not in value_conditions and (c['condition'] % full_args not in _value_conditions):\n                    value_conditions.append(c['condition'])\n                    _value_conditions.append(c['condition'] % full_args)\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            del _value_conditions\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            del type_conditions\n            if len(value_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in value_conditions])})\")\n            del value_conditions\n            if len(events_conditions_not) > 0:\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND {c['condition']}\"\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                value_conditions_not = [f'sub.{c}' for c in __events_where_basic] + value_conditions_not\n                sub_join = f\"LEFT ANTI JOIN ( SELECT DISTINCT sub.session_id\\n                                    FROM {MAIN_EVENTS_TABLE} AS sub\\n                                    WHERE {' AND '.join([c for c in value_conditions_not])}) AS sub USING(session_id)\"\n                del _value_conditions_not\n                del value_conditions_not\n            if data.events_order == schemas.SearchEventOrder._then:\n                having = f\"HAVING sequenceMatch('{''.join(sequence_pattern)}')(main.datetime,{','.join(sequence_conditions)})\"\n            else:\n                having = f\"HAVING {' AND '.join([f'countIf({c})>0' for c in list(set(sequence_conditions))])}\"\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                        {sub_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\\n                                    {having}\"\n        else:\n            type_conditions = []\n            sequence_conditions = []\n            has_values = False\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    has_values = True\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            if len(events_conditions_not) > 0:\n                has_values = True\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND not({c['condition']})\".replace('sub.', 'main.')\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                del _value_conditions_not\n                sequence_conditions += value_conditions_not\n            if has_values:\n                events_conditions = [c for c in list(set(sequence_conditions))]\n                events_conditions_where.append(f\"({' OR '.join(events_conditions)})\")\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\"\n    else:\n        data.events = []\n    if data.startTimestamp is not None:\n        extra_constraints.append('s.datetime >= toDateTime(%(startDate)s/1000)')\n    if data.endTimestamp is not None:\n        extra_constraints.append('s.datetime <= toDateTime(%(endDate)s/1000)')\n    extra_join = ''\n    if issue is not None:\n        extra_join = '\\n                INNER JOIN LATERAL(SELECT TRUE FROM events_common.issues INNER JOIN public.issues AS p_issues USING (issue_id)\\n                WHERE issues.session_id=f.session_id \\n                    AND p_issues.type=%(issue_type)s \\n                    AND p_issues.context_string=%(issue_contextString)s\\n                    AND timestamp >= f.first_event_ts\\n                    AND timestamp <= f.last_event_ts) AS issues ON(TRUE)\\n                '\n        full_args['issue_contextString'] = issue['contextString']\n        full_args['issue_type'] = issue['type']\n    elif len(issues) > 0:\n        issues_conditions = []\n        for (i, f) in enumerate(issues):\n            f_k_v = f'f_issue_v{i}'\n            f_k_s = f_k_v + '_source'\n            full_args = {**full_args, **_multiple_values(f.value, value_key=f_k_v), f_k_s: f.source}\n            issues_conditions.append(_multiple_conditions(f'issues.type=%({f_k_v})s', f.value, value_key=f_k_v))\n            issues_conditions[-1] = f'({issues_conditions[-1]} AND issues.context_string=%({f_k_s})s)'\n        extra_join = f\"INNER JOIN (SELECT DISTINCT events.session_id\\n                                 FROM experimental.issues\\n                                          INNER JOIN experimental.events USING (issue_id)\\n                                 WHERE issues.project_id = %(projectId)s\\n                                   AND events.project_id = %(projectId)s\\n                                   AND events.datetime >= toDateTime(%(startDate)s/1000)\\n                                   AND events.datetime <= toDateTime(%(endDate)s/1000)\\n                                   AND {' OR '.join(issues_conditions)}\\n                            ) AS issues USING (session_id)\"\n    if extra_event:\n        extra_event = f'INNER JOIN ({extra_event}) AS extra_event USING(session_id)'\n    else:\n        extra_event = ''\n    if errors_only:\n        query_part = f\"{(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\"\n    else:\n        if len(events_query_part) > 0:\n            extra_join += f\"INNER JOIN (SELECT * \\n                                    FROM {MAIN_SESSIONS_TABLE} AS s {extra_event}\\n                                    WHERE {' AND '.join(extra_constraints)}) AS s ON(s.session_id=f.session_id)\"\n        else:\n            extra_join = f\"(SELECT * \\n                                FROM {MAIN_SESSIONS_TABLE} AS s {extra_join} {extra_event}\\n                                WHERE {' AND '.join(extra_constraints)}\\n                                ORDER BY _timestamp DESC\\n                                LIMIT 1 BY session_id) AS s\"\n        query_part = f\"                            FROM {(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\\n                            {extra_join}\\n                            {extra_from}\\n                            \"\n    return (full_args, query_part)",
            "def search_query_parts_ch(data: schemas.SessionsSearchPayloadSchema, error_status, errors_only, favorite_only, issue, project_id, user_id, platform='web', extra_event=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ss_constraints = []\n    full_args = {'project_id': project_id, 'startDate': data.startTimestamp, 'endDate': data.endTimestamp, 'projectId': project_id, 'userId': user_id}\n    MAIN_EVENTS_TABLE = exp_ch_helper.get_main_events_table(timestamp=data.startTimestamp, platform=platform)\n    MAIN_SESSIONS_TABLE = exp_ch_helper.get_main_sessions_table(data.startTimestamp)\n    full_args['MAIN_EVENTS_TABLE'] = MAIN_EVENTS_TABLE\n    full_args['MAIN_SESSIONS_TABLE'] = MAIN_SESSIONS_TABLE\n    extra_constraints = ['s.project_id = %(project_id)s', 'isNotNull(s.duration)']\n    if favorite_only:\n        extra_constraints.append(f's.session_id IN (SELECT session_id\\n                                        FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                        WHERE user_id = %(userId)s)')\n    extra_from = ''\n    events_query_part = ''\n    issues = []\n    __events_where_basic = ['project_id = %(projectId)s', 'datetime >= toDateTime(%(startDate)s/1000)', 'datetime <= toDateTime(%(endDate)s/1000)']\n    events_conditions_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n    if len(data.filters) > 0:\n        meta_keys = None\n        include_in_events = False\n        for (i, f) in enumerate(data.filters):\n            if not isinstance(f.value, list):\n                f.value = [f.value]\n            filter_type = f.type\n            f.value = helper.values_for_operator(value=f.value, op=f.operator)\n            f_k = f'f_value{i}'\n            full_args = {**full_args, f_k: f.value, **_multiple_values(f.value, value_key=f_k)}\n            op = __get_sql_operator(f.operator) if filter_type not in [schemas.FilterType.events_count] else f.operator\n            is_any = _isAny_opreator(f.operator)\n            is_undefined = _isUndefined_operator(f.operator)\n            if not is_any and (not is_undefined) and (len(f.value) == 0):\n                continue\n            is_not = False\n            if __is_negation_operator(f.operator):\n                is_not = True\n            if filter_type == schemas.FilterType.user_browser:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_browser)')\n                    ss_constraints.append('isNotNull(ms.user_browser)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_os, schemas.FilterType.user_os_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_os)')\n                    ss_constraints.append('isNotNull(ms.user_os)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_device, schemas.FilterType.user_device_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_device)')\n                    ss_constraints.append('isNotNull(ms.user_device)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_country, schemas.FilterType.user_country_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_country)')\n                    ss_constraints.append('isNotNull(ms.user_country)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_city:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_city)')\n                    ss_constraints.append('isNotNull(ms.user_city)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_state:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_state)')\n                    ss_constraints.append('isNotNull(ms.user_state)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_source]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_source)')\n                    ss_constraints.append('isNotNull(ms.utm_source)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_source)')\n                    ss_constraints.append('isNull(ms.utm_source)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_medium]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_medium)')\n                    ss_constraints.append('isNotNull(ms.utm_medium)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_medium)')\n                    ss_constraints.append('isNull(ms.utm_medium')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_campaign]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_campaign)')\n                    ss_constraints.append('isNotNull(ms.utm_campaign)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_campaign)')\n                    ss_constraints.append('isNull(ms.utm_campaign)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.duration:\n                if len(f.value) > 0 and f.value[0] is not None:\n                    extra_constraints.append('s.duration >= %(minDuration)s')\n                    ss_constraints.append('ms.duration >= %(minDuration)s')\n                    full_args['minDuration'] = f.value[0]\n                if len(f.value) > 1 and f.value[1] is not None and (int(f.value[1]) > 0):\n                    extra_constraints.append('s.duration <= %(maxDuration)s')\n                    ss_constraints.append('ms.duration <= %(maxDuration)s')\n                    full_args['maxDuration'] = f.value[1]\n            elif filter_type == schemas.FilterType.referrer:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.base_referrer)')\n                    ss_constraints.append('isNotNull(ms.base_referrer)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == events.EventType.METADATA.ui_type:\n                if meta_keys is None:\n                    meta_keys = metadata.get(project_id=project_id)\n                    meta_keys = {m['key']: m['index'] for m in meta_keys}\n                if f.source in meta_keys.keys():\n                    if is_any:\n                        extra_constraints.append(f'isNotNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNotNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    elif is_undefined:\n                        extra_constraints.append(f'isNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    else:\n                        extra_constraints.append(_multiple_conditions(f's.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                        ss_constraints.append(_multiple_conditions(f'ms.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_id, schemas.FilterType.user_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_id)')\n                    ss_constraints.append('isNotNull(ms.user_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_id)')\n                    ss_constraints.append('isNull(ms.user_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_anonymous_id, schemas.FilterType.user_anonymous_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNotNull(ms.user_anonymous_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNull(ms.user_anonymous_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.rev_id, schemas.FilterType.rev_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.rev_id)')\n                    ss_constraints.append('isNotNull(ms.rev_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.rev_id)')\n                    ss_constraints.append('isNull(ms.rev_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.platform:\n                extra_constraints.append(_multiple_conditions(f's.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.issue:\n                if is_any:\n                    extra_constraints.append('notEmpty(s.issue_types)')\n                    ss_constraints.append('notEmpty(ms.issue_types)')\n                else:\n                    if f.source:\n                        issues.append(f)\n                    extra_constraints.append(f'hasAny(s.issue_types,%({f_k})s)')\n                    ss_constraints.append(f'hasAny(ms.issue_types,%({f_k})s)')\n                    if is_not:\n                        extra_constraints[-1] = f'not({extra_constraints[-1]})'\n                        ss_constraints[-1] = f'not({ss_constraints[-1]})'\n            elif filter_type == schemas.FilterType.events_count:\n                extra_constraints.append(_multiple_conditions(f's.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            else:\n                continue\n            include_in_events = True\n        if include_in_events:\n            events_conditions_where.append(f\"main.session_id IN (SELECT s.session_id \\n                                                FROM {MAIN_SESSIONS_TABLE} AS s\\n                                                WHERE {' AND '.join(extra_constraints)})\")\n    events_extra_join = ''\n    if len(data.events) > 0:\n        valid_events_count = 0\n        for event in data.events:\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if __is_valid_event(is_any=is_any, event=event):\n                valid_events_count += 1\n        events_query_from = []\n        events_conditions = []\n        events_conditions_not = []\n        event_index = 0\n        or_events = data.events_order == schemas.SearchEventOrder._or\n        for (i, event) in enumerate(data.events):\n            event_type = event.type\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if not __is_valid_event(is_any=is_any, event=event):\n                continue\n            op = __get_sql_operator(event.operator)\n            is_not = False\n            if __is_negation_operator(event.operator):\n                is_not = True\n                op = __reverse_sql_operator(op)\n            event_from = '%s'\n            event_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n            e_k = f'e_value{i}'\n            s_k = e_k + '_source'\n            if True or event.type != schemas.PerformanceEventType.time_between_events:\n                event.value = helper.values_for_operator(value=event.value, op=event.operator)\n                full_args = {**full_args, **_multiple_values(event.value, value_key=e_k), **_multiple_values(event.source, value_key=s_k)}\n            if event_type == events.EventType.CLICK.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.CLICK.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if event.operator == schemas.ClickEventExtraOperator._on_selector:\n                            event_where.append(_multiple_conditions(f'main.selector = %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                        elif is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.CLICK_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.INPUT.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.INPUT.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                    if event.source is not None and len(event.source) > 0:\n                        event_where.append(_multiple_conditions(f'main.value ILIKE %(custom{i})s', event.source, value_key=f'custom{i}'))\n                        full_args = {**full_args, **_multiple_values(event.source, value_key=f'custom{i}')}\n                else:\n                    _column = events.EventType.INPUT_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.LOCATION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = 'url_path'\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.VIEW_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.CUSTOM.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.CUSTOM.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.REQUEST.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.STATEACTION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.STATEACTION.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.ERROR.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main'\n                events_extra_join = f'SELECT * FROM {MAIN_EVENTS_TABLE} AS main1 WHERE main1.project_id=%(project_id)s'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                event.source = tuple(event.source)\n                events_conditions[-1]['condition'] = []\n                if not is_any and event.value not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'(main1.message {op} %({e_k})s OR main1.name {op} %({e_k})s)', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                if len(event.source) > 0 and event.source[0] not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'main1.source = %({s_k})s', event.source, value_key=s_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.PerformanceEventType.fetch_failed:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                event_where.append(f'main.{colname} = 0')\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.request_details:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                apply = False\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_fetch{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.FetchFilterType._url:\n                        event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._status_code:\n                        event_where.append(_multiple_conditions(f'main.status {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._duration:\n                        event_where.append(_multiple_conditions(f'main.duration {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    else:\n                        logging.warning(f'undefined FETCH filter: {f.type}')\n                if not apply:\n                    continue\n                else:\n                    events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.graphql:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='GRAPHQL'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_graphql{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.GraphqlFilterType._name:\n                        event_where.append(_multiple_conditions(f'main.{events.EventType.GRAPHQL.column} {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    else:\n                        logging.warning(f'undefined GRAPHQL filter: {f.type}')\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            else:\n                continue\n            if event_index == 0 or or_events:\n                event_where += ss_constraints\n            if is_not:\n                if event_index == 0 or or_events:\n                    events_query_from.append(f\"                                    (SELECT\\n                                        session_id, \\n                                        0 AS timestamp\\n                                      FROM sessions\\n                                      WHERE EXISTS(SELECT session_id \\n                                                    FROM {event_from} \\n                                                    WHERE {' AND '.join(event_where)} \\n                                                        AND sessions.session_id=ms.session_id) IS FALSE\\n                                        AND project_id = %(projectId)s \\n                                        AND start_ts >= %(startDate)s\\n                                        AND start_ts <= %(endDate)s\\n                                        AND duration IS NOT NULL\\n                                    ) {('' if or_events else f'AS event_{event_index}' + ('ON(TRUE)' if event_index > 0 else ''))}                                    \")\n                else:\n                    events_query_from.append(f\"            (SELECT\\n                event_0.session_id, \\n                event_{event_index - 1}.timestamp AS timestamp\\n              WHERE EXISTS(SELECT session_id FROM {event_from} WHERE {' AND '.join(event_where)}) IS FALSE\\n            ) AS event_{event_index} {('ON(TRUE)' if event_index > 0 else '')}            \")\n            elif data.events_order == schemas.SearchEventOrder._then:\n                pass\n            else:\n                events_query_from.append(f\"            (SELECT main.session_id, {('MIN' if event_index < valid_events_count - 1 else 'MAX')}(main.datetime) AS datetime\\n              FROM {event_from}\\n              WHERE {' AND '.join(event_where)}\\n              GROUP BY session_id\\n            ) {('' if or_events else f'AS event_{event_index} ' + ('ON(TRUE)' if event_index > 0 else ''))}            \")\n            event_index += 1\n            if event_index == 7 and data.events_order == schemas.SearchEventOrder._then:\n                break\n        if event_index < 2:\n            data.events_order = schemas.SearchEventOrder._or\n        if len(events_extra_join) > 0:\n            if event_index < 2:\n                events_extra_join = f'INNER JOIN ({events_extra_join}) AS main1 USING(error_id)'\n            else:\n                events_extra_join = f'LEFT JOIN ({events_extra_join}) AS main1 USING(error_id)'\n        if favorite_only and user_id is not None:\n            events_conditions_where.append(f'main.session_id IN (SELECT session_id\\n                                                FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                                WHERE user_id = %(userId)s)')\n        if data.events_order in [schemas.SearchEventOrder._then, schemas.SearchEventOrder._and]:\n            sequence_pattern = [f\"(?{i + 1}){c.get('time', '')}\" for (i, c) in enumerate(events_conditions)]\n            sub_join = ''\n            type_conditions = []\n            value_conditions = []\n            _value_conditions = []\n            sequence_conditions = []\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                if c.get('condition') and c['condition'] not in value_conditions and (c['condition'] % full_args not in _value_conditions):\n                    value_conditions.append(c['condition'])\n                    _value_conditions.append(c['condition'] % full_args)\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            del _value_conditions\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            del type_conditions\n            if len(value_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in value_conditions])})\")\n            del value_conditions\n            if len(events_conditions_not) > 0:\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND {c['condition']}\"\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                value_conditions_not = [f'sub.{c}' for c in __events_where_basic] + value_conditions_not\n                sub_join = f\"LEFT ANTI JOIN ( SELECT DISTINCT sub.session_id\\n                                    FROM {MAIN_EVENTS_TABLE} AS sub\\n                                    WHERE {' AND '.join([c for c in value_conditions_not])}) AS sub USING(session_id)\"\n                del _value_conditions_not\n                del value_conditions_not\n            if data.events_order == schemas.SearchEventOrder._then:\n                having = f\"HAVING sequenceMatch('{''.join(sequence_pattern)}')(main.datetime,{','.join(sequence_conditions)})\"\n            else:\n                having = f\"HAVING {' AND '.join([f'countIf({c})>0' for c in list(set(sequence_conditions))])}\"\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                        {sub_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\\n                                    {having}\"\n        else:\n            type_conditions = []\n            sequence_conditions = []\n            has_values = False\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    has_values = True\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            if len(events_conditions_not) > 0:\n                has_values = True\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND not({c['condition']})\".replace('sub.', 'main.')\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                del _value_conditions_not\n                sequence_conditions += value_conditions_not\n            if has_values:\n                events_conditions = [c for c in list(set(sequence_conditions))]\n                events_conditions_where.append(f\"({' OR '.join(events_conditions)})\")\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\"\n    else:\n        data.events = []\n    if data.startTimestamp is not None:\n        extra_constraints.append('s.datetime >= toDateTime(%(startDate)s/1000)')\n    if data.endTimestamp is not None:\n        extra_constraints.append('s.datetime <= toDateTime(%(endDate)s/1000)')\n    extra_join = ''\n    if issue is not None:\n        extra_join = '\\n                INNER JOIN LATERAL(SELECT TRUE FROM events_common.issues INNER JOIN public.issues AS p_issues USING (issue_id)\\n                WHERE issues.session_id=f.session_id \\n                    AND p_issues.type=%(issue_type)s \\n                    AND p_issues.context_string=%(issue_contextString)s\\n                    AND timestamp >= f.first_event_ts\\n                    AND timestamp <= f.last_event_ts) AS issues ON(TRUE)\\n                '\n        full_args['issue_contextString'] = issue['contextString']\n        full_args['issue_type'] = issue['type']\n    elif len(issues) > 0:\n        issues_conditions = []\n        for (i, f) in enumerate(issues):\n            f_k_v = f'f_issue_v{i}'\n            f_k_s = f_k_v + '_source'\n            full_args = {**full_args, **_multiple_values(f.value, value_key=f_k_v), f_k_s: f.source}\n            issues_conditions.append(_multiple_conditions(f'issues.type=%({f_k_v})s', f.value, value_key=f_k_v))\n            issues_conditions[-1] = f'({issues_conditions[-1]} AND issues.context_string=%({f_k_s})s)'\n        extra_join = f\"INNER JOIN (SELECT DISTINCT events.session_id\\n                                 FROM experimental.issues\\n                                          INNER JOIN experimental.events USING (issue_id)\\n                                 WHERE issues.project_id = %(projectId)s\\n                                   AND events.project_id = %(projectId)s\\n                                   AND events.datetime >= toDateTime(%(startDate)s/1000)\\n                                   AND events.datetime <= toDateTime(%(endDate)s/1000)\\n                                   AND {' OR '.join(issues_conditions)}\\n                            ) AS issues USING (session_id)\"\n    if extra_event:\n        extra_event = f'INNER JOIN ({extra_event}) AS extra_event USING(session_id)'\n    else:\n        extra_event = ''\n    if errors_only:\n        query_part = f\"{(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\"\n    else:\n        if len(events_query_part) > 0:\n            extra_join += f\"INNER JOIN (SELECT * \\n                                    FROM {MAIN_SESSIONS_TABLE} AS s {extra_event}\\n                                    WHERE {' AND '.join(extra_constraints)}) AS s ON(s.session_id=f.session_id)\"\n        else:\n            extra_join = f\"(SELECT * \\n                                FROM {MAIN_SESSIONS_TABLE} AS s {extra_join} {extra_event}\\n                                WHERE {' AND '.join(extra_constraints)}\\n                                ORDER BY _timestamp DESC\\n                                LIMIT 1 BY session_id) AS s\"\n        query_part = f\"                            FROM {(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\\n                            {extra_join}\\n                            {extra_from}\\n                            \"\n    return (full_args, query_part)",
            "def search_query_parts_ch(data: schemas.SessionsSearchPayloadSchema, error_status, errors_only, favorite_only, issue, project_id, user_id, platform='web', extra_event=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ss_constraints = []\n    full_args = {'project_id': project_id, 'startDate': data.startTimestamp, 'endDate': data.endTimestamp, 'projectId': project_id, 'userId': user_id}\n    MAIN_EVENTS_TABLE = exp_ch_helper.get_main_events_table(timestamp=data.startTimestamp, platform=platform)\n    MAIN_SESSIONS_TABLE = exp_ch_helper.get_main_sessions_table(data.startTimestamp)\n    full_args['MAIN_EVENTS_TABLE'] = MAIN_EVENTS_TABLE\n    full_args['MAIN_SESSIONS_TABLE'] = MAIN_SESSIONS_TABLE\n    extra_constraints = ['s.project_id = %(project_id)s', 'isNotNull(s.duration)']\n    if favorite_only:\n        extra_constraints.append(f's.session_id IN (SELECT session_id\\n                                        FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                        WHERE user_id = %(userId)s)')\n    extra_from = ''\n    events_query_part = ''\n    issues = []\n    __events_where_basic = ['project_id = %(projectId)s', 'datetime >= toDateTime(%(startDate)s/1000)', 'datetime <= toDateTime(%(endDate)s/1000)']\n    events_conditions_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n    if len(data.filters) > 0:\n        meta_keys = None\n        include_in_events = False\n        for (i, f) in enumerate(data.filters):\n            if not isinstance(f.value, list):\n                f.value = [f.value]\n            filter_type = f.type\n            f.value = helper.values_for_operator(value=f.value, op=f.operator)\n            f_k = f'f_value{i}'\n            full_args = {**full_args, f_k: f.value, **_multiple_values(f.value, value_key=f_k)}\n            op = __get_sql_operator(f.operator) if filter_type not in [schemas.FilterType.events_count] else f.operator\n            is_any = _isAny_opreator(f.operator)\n            is_undefined = _isUndefined_operator(f.operator)\n            if not is_any and (not is_undefined) and (len(f.value) == 0):\n                continue\n            is_not = False\n            if __is_negation_operator(f.operator):\n                is_not = True\n            if filter_type == schemas.FilterType.user_browser:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_browser)')\n                    ss_constraints.append('isNotNull(ms.user_browser)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_browser {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_os, schemas.FilterType.user_os_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_os)')\n                    ss_constraints.append('isNotNull(ms.user_os)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_os {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_device, schemas.FilterType.user_device_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_device)')\n                    ss_constraints.append('isNotNull(ms.user_device)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_device {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_country, schemas.FilterType.user_country_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_country)')\n                    ss_constraints.append('isNotNull(ms.user_country)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_country {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_city:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_city)')\n                    ss_constraints.append('isNotNull(ms.user_city)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_city {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in schemas.FilterType.user_state:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_state)')\n                    ss_constraints.append('isNotNull(ms.user_state)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_state {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_source]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_source)')\n                    ss_constraints.append('isNotNull(ms.utm_source)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_source)')\n                    ss_constraints.append('isNull(ms.utm_source)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_source {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_medium]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_medium)')\n                    ss_constraints.append('isNotNull(ms.utm_medium)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_medium)')\n                    ss_constraints.append('isNull(ms.utm_medium')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_medium {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.utm_campaign]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.utm_campaign)')\n                    ss_constraints.append('isNotNull(ms.utm_campaign)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.utm_campaign)')\n                    ss_constraints.append('isNull(ms.utm_campaign)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.utm_campaign {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.duration:\n                if len(f.value) > 0 and f.value[0] is not None:\n                    extra_constraints.append('s.duration >= %(minDuration)s')\n                    ss_constraints.append('ms.duration >= %(minDuration)s')\n                    full_args['minDuration'] = f.value[0]\n                if len(f.value) > 1 and f.value[1] is not None and (int(f.value[1]) > 0):\n                    extra_constraints.append('s.duration <= %(maxDuration)s')\n                    ss_constraints.append('ms.duration <= %(maxDuration)s')\n                    full_args['maxDuration'] = f.value[1]\n            elif filter_type == schemas.FilterType.referrer:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.base_referrer)')\n                    ss_constraints.append('isNotNull(ms.base_referrer)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.base_referrer {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == events.EventType.METADATA.ui_type:\n                if meta_keys is None:\n                    meta_keys = metadata.get(project_id=project_id)\n                    meta_keys = {m['key']: m['index'] for m in meta_keys}\n                if f.source in meta_keys.keys():\n                    if is_any:\n                        extra_constraints.append(f'isNotNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNotNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    elif is_undefined:\n                        extra_constraints.append(f'isNull(s.{metadata.index_to_colname(meta_keys[f.source])})')\n                        ss_constraints.append(f'isNull(ms.{metadata.index_to_colname(meta_keys[f.source])})')\n                    else:\n                        extra_constraints.append(_multiple_conditions(f's.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                        ss_constraints.append(_multiple_conditions(f'ms.{metadata.index_to_colname(meta_keys[f.source])} {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_id, schemas.FilterType.user_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_id)')\n                    ss_constraints.append('isNotNull(ms.user_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_id)')\n                    ss_constraints.append('isNull(ms.user_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.user_anonymous_id, schemas.FilterType.user_anonymous_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNotNull(ms.user_anonymous_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.user_anonymous_id)')\n                    ss_constraints.append('isNull(ms.user_anonymous_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.user_anonymous_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type in [schemas.FilterType.rev_id, schemas.FilterType.rev_id_ios]:\n                if is_any:\n                    extra_constraints.append('isNotNull(s.rev_id)')\n                    ss_constraints.append('isNotNull(ms.rev_id)')\n                elif is_undefined:\n                    extra_constraints.append('isNull(s.rev_id)')\n                    ss_constraints.append('isNull(ms.rev_id)')\n                else:\n                    extra_constraints.append(_multiple_conditions(f's.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n                    ss_constraints.append(_multiple_conditions(f'ms.rev_id {op} toString(%({f_k})s)', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.platform:\n                extra_constraints.append(_multiple_conditions(f's.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.user_device_type {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            elif filter_type == schemas.FilterType.issue:\n                if is_any:\n                    extra_constraints.append('notEmpty(s.issue_types)')\n                    ss_constraints.append('notEmpty(ms.issue_types)')\n                else:\n                    if f.source:\n                        issues.append(f)\n                    extra_constraints.append(f'hasAny(s.issue_types,%({f_k})s)')\n                    ss_constraints.append(f'hasAny(ms.issue_types,%({f_k})s)')\n                    if is_not:\n                        extra_constraints[-1] = f'not({extra_constraints[-1]})'\n                        ss_constraints[-1] = f'not({ss_constraints[-1]})'\n            elif filter_type == schemas.FilterType.events_count:\n                extra_constraints.append(_multiple_conditions(f's.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n                ss_constraints.append(_multiple_conditions(f'ms.events_count {op} %({f_k})s', f.value, is_not=is_not, value_key=f_k))\n            else:\n                continue\n            include_in_events = True\n        if include_in_events:\n            events_conditions_where.append(f\"main.session_id IN (SELECT s.session_id \\n                                                FROM {MAIN_SESSIONS_TABLE} AS s\\n                                                WHERE {' AND '.join(extra_constraints)})\")\n    events_extra_join = ''\n    if len(data.events) > 0:\n        valid_events_count = 0\n        for event in data.events:\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if __is_valid_event(is_any=is_any, event=event):\n                valid_events_count += 1\n        events_query_from = []\n        events_conditions = []\n        events_conditions_not = []\n        event_index = 0\n        or_events = data.events_order == schemas.SearchEventOrder._or\n        for (i, event) in enumerate(data.events):\n            event_type = event.type\n            is_any = _isAny_opreator(event.operator)\n            if not isinstance(event.value, list):\n                event.value = [event.value]\n            if not __is_valid_event(is_any=is_any, event=event):\n                continue\n            op = __get_sql_operator(event.operator)\n            is_not = False\n            if __is_negation_operator(event.operator):\n                is_not = True\n                op = __reverse_sql_operator(op)\n            event_from = '%s'\n            event_where = ['main.project_id = %(projectId)s', 'main.datetime >= toDateTime(%(startDate)s/1000)', 'main.datetime <= toDateTime(%(endDate)s/1000)']\n            e_k = f'e_value{i}'\n            s_k = e_k + '_source'\n            if True or event.type != schemas.PerformanceEventType.time_between_events:\n                event.value = helper.values_for_operator(value=event.value, op=event.operator)\n                full_args = {**full_args, **_multiple_values(event.value, value_key=e_k), **_multiple_values(event.source, value_key=s_k)}\n            if event_type == events.EventType.CLICK.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.CLICK.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if event.operator == schemas.ClickEventExtraOperator._on_selector:\n                            event_where.append(_multiple_conditions(f'main.selector = %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                        elif is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.CLICK_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.INPUT.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = events.EventType.INPUT.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                    if event.source is not None and len(event.source) > 0:\n                        event_where.append(_multiple_conditions(f'main.value ILIKE %(custom{i})s', event.source, value_key=f'custom{i}'))\n                        full_args = {**full_args, **_multiple_values(event.source, value_key=f'custom{i}')}\n                else:\n                    _column = events.EventType.INPUT_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.LOCATION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                if platform == 'web':\n                    _column = 'url_path'\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n                else:\n                    _column = events.EventType.VIEW_IOS.column\n                    event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                    events_conditions.append({'type': event_where[-1]})\n                    if not is_any:\n                        if is_not:\n                            event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                            events_conditions_not[-1]['condition'] = event_where[-1]\n                        else:\n                            event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                            events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.CUSTOM.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.CUSTOM.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.REQUEST.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.STATEACTION.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = events.EventType.STATEACTION.column\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'] = event_where[-1]\n            elif event_type == events.EventType.ERROR.ui_type:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main'\n                events_extra_join = f'SELECT * FROM {MAIN_EVENTS_TABLE} AS main1 WHERE main1.project_id=%(project_id)s'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                event.source = tuple(event.source)\n                events_conditions[-1]['condition'] = []\n                if not is_any and event.value not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'(main1.message {op} %({e_k})s OR main1.name {op} %({e_k})s)', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                if len(event.source) > 0 and event.source[0] not in [None, '*', '']:\n                    event_where.append(_multiple_conditions(f'main1.source = %({s_k})s', event.source, value_key=s_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                    events_extra_join += f' AND {event_where[-1]}'\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.PerformanceEventType.fetch_failed:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                _column = 'url_path'\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                if not is_any:\n                    if is_not:\n                        event_where.append(_multiple_conditions(f'sub.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions_not.append({'type': f\"sub.event_type='{__get_event_type(event_type, platform=platform)}'\"})\n                        events_conditions_not[-1]['condition'] = event_where[-1]\n                    else:\n                        event_where.append(_multiple_conditions(f'main.{_column} {op} %({e_k})s', event.value, value_key=e_k))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                event_where.append(f'main.{colname} = 0')\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_dom_complete, schemas.PerformanceEventType.location_largest_contentful_paint_time, schemas.PerformanceEventType.location_ttfb]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type in [schemas.PerformanceEventType.location_avg_cpu_load, schemas.PerformanceEventType.location_avg_memory_usage]:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                col = performance_event.get_col(event_type)\n                colname = col['column']\n                tname = 'main'\n                if not is_any:\n                    event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k})s', event.value, value_key=e_k))\n                    events_conditions[-1]['condition'].append(event_where[-1])\n                e_k += '_custom'\n                full_args = {**full_args, **_multiple_values(event.source, value_key=e_k)}\n                event_where.append(f'isNotNull({tname}.{colname}) AND {tname}.{colname}>0 AND ' + _multiple_conditions(f'{tname}.{colname} {event.sourceOperator.value} %({e_k})s', event.source, value_key=e_k))\n                events_conditions[-1]['condition'].append(event_where[-1])\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.request_details:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='{__get_event_type(event_type, platform=platform)}'\")\n                events_conditions.append({'type': event_where[-1]})\n                apply = False\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_fetch{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.FetchFilterType._url:\n                        event_where.append(_multiple_conditions(f'main.url_path {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._status_code:\n                        event_where.append(_multiple_conditions(f'main.status {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._duration:\n                        event_where.append(_multiple_conditions(f'main.duration {f.operator} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    elif f.type == schemas.FetchFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                        apply = True\n                    else:\n                        logging.warning(f'undefined FETCH filter: {f.type}')\n                if not apply:\n                    continue\n                else:\n                    events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            elif event_type == schemas.EventType.graphql:\n                event_from = event_from % f'{MAIN_EVENTS_TABLE} AS main '\n                event_where.append(f\"main.event_type='GRAPHQL'\")\n                events_conditions.append({'type': event_where[-1]})\n                events_conditions[-1]['condition'] = []\n                for (j, f) in enumerate(event.filters):\n                    is_any = _isAny_opreator(f.operator)\n                    if is_any or len(f.value) == 0:\n                        continue\n                    f.value = helper.values_for_operator(value=f.value, op=f.operator)\n                    op = __get_sql_operator(f.operator)\n                    e_k_f = e_k + f'_graphql{j}'\n                    full_args = {**full_args, **_multiple_values(f.value, value_key=e_k_f)}\n                    if f.type == schemas.GraphqlFilterType._name:\n                        event_where.append(_multiple_conditions(f'main.{events.EventType.GRAPHQL.column} {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._method:\n                        event_where.append(_multiple_conditions(f'main.method {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._request_body:\n                        event_where.append(_multiple_conditions(f'main.request_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    elif f.type == schemas.GraphqlFilterType._response_body:\n                        event_where.append(_multiple_conditions(f'main.response_body {op} %({e_k_f})s', f.value, value_key=e_k_f))\n                        events_conditions[-1]['condition'].append(event_where[-1])\n                    else:\n                        logging.warning(f'undefined GRAPHQL filter: {f.type}')\n                events_conditions[-1]['condition'] = ' AND '.join(events_conditions[-1]['condition'])\n            else:\n                continue\n            if event_index == 0 or or_events:\n                event_where += ss_constraints\n            if is_not:\n                if event_index == 0 or or_events:\n                    events_query_from.append(f\"                                    (SELECT\\n                                        session_id, \\n                                        0 AS timestamp\\n                                      FROM sessions\\n                                      WHERE EXISTS(SELECT session_id \\n                                                    FROM {event_from} \\n                                                    WHERE {' AND '.join(event_where)} \\n                                                        AND sessions.session_id=ms.session_id) IS FALSE\\n                                        AND project_id = %(projectId)s \\n                                        AND start_ts >= %(startDate)s\\n                                        AND start_ts <= %(endDate)s\\n                                        AND duration IS NOT NULL\\n                                    ) {('' if or_events else f'AS event_{event_index}' + ('ON(TRUE)' if event_index > 0 else ''))}                                    \")\n                else:\n                    events_query_from.append(f\"            (SELECT\\n                event_0.session_id, \\n                event_{event_index - 1}.timestamp AS timestamp\\n              WHERE EXISTS(SELECT session_id FROM {event_from} WHERE {' AND '.join(event_where)}) IS FALSE\\n            ) AS event_{event_index} {('ON(TRUE)' if event_index > 0 else '')}            \")\n            elif data.events_order == schemas.SearchEventOrder._then:\n                pass\n            else:\n                events_query_from.append(f\"            (SELECT main.session_id, {('MIN' if event_index < valid_events_count - 1 else 'MAX')}(main.datetime) AS datetime\\n              FROM {event_from}\\n              WHERE {' AND '.join(event_where)}\\n              GROUP BY session_id\\n            ) {('' if or_events else f'AS event_{event_index} ' + ('ON(TRUE)' if event_index > 0 else ''))}            \")\n            event_index += 1\n            if event_index == 7 and data.events_order == schemas.SearchEventOrder._then:\n                break\n        if event_index < 2:\n            data.events_order = schemas.SearchEventOrder._or\n        if len(events_extra_join) > 0:\n            if event_index < 2:\n                events_extra_join = f'INNER JOIN ({events_extra_join}) AS main1 USING(error_id)'\n            else:\n                events_extra_join = f'LEFT JOIN ({events_extra_join}) AS main1 USING(error_id)'\n        if favorite_only and user_id is not None:\n            events_conditions_where.append(f'main.session_id IN (SELECT session_id\\n                                                FROM {exp_ch_helper.get_user_favorite_sessions_table()} AS user_favorite_sessions\\n                                                WHERE user_id = %(userId)s)')\n        if data.events_order in [schemas.SearchEventOrder._then, schemas.SearchEventOrder._and]:\n            sequence_pattern = [f\"(?{i + 1}){c.get('time', '')}\" for (i, c) in enumerate(events_conditions)]\n            sub_join = ''\n            type_conditions = []\n            value_conditions = []\n            _value_conditions = []\n            sequence_conditions = []\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                if c.get('condition') and c['condition'] not in value_conditions and (c['condition'] % full_args not in _value_conditions):\n                    value_conditions.append(c['condition'])\n                    _value_conditions.append(c['condition'] % full_args)\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            del _value_conditions\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            del type_conditions\n            if len(value_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in value_conditions])})\")\n            del value_conditions\n            if len(events_conditions_not) > 0:\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND {c['condition']}\"\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                value_conditions_not = [f'sub.{c}' for c in __events_where_basic] + value_conditions_not\n                sub_join = f\"LEFT ANTI JOIN ( SELECT DISTINCT sub.session_id\\n                                    FROM {MAIN_EVENTS_TABLE} AS sub\\n                                    WHERE {' AND '.join([c for c in value_conditions_not])}) AS sub USING(session_id)\"\n                del _value_conditions_not\n                del value_conditions_not\n            if data.events_order == schemas.SearchEventOrder._then:\n                having = f\"HAVING sequenceMatch('{''.join(sequence_pattern)}')(main.datetime,{','.join(sequence_conditions)})\"\n            else:\n                having = f\"HAVING {' AND '.join([f'countIf({c})>0' for c in list(set(sequence_conditions))])}\"\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                        {sub_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\\n                                    {having}\"\n        else:\n            type_conditions = []\n            sequence_conditions = []\n            has_values = False\n            for c in events_conditions:\n                if c['type'] not in type_conditions:\n                    type_conditions.append(c['type'])\n                sequence_conditions.append(c['type'])\n                if c.get('condition'):\n                    has_values = True\n                    sequence_conditions[-1] += ' AND ' + c['condition']\n            if len(events_conditions) > 0:\n                events_conditions_where.append(f\"({' OR '.join([c for c in type_conditions])})\")\n            if len(events_conditions_not) > 0:\n                has_values = True\n                _value_conditions_not = []\n                value_conditions_not = []\n                for c in events_conditions_not:\n                    p = f\"{c['type']} AND not({c['condition']})\".replace('sub.', 'main.')\n                    _p = p % full_args\n                    if _p not in _value_conditions_not:\n                        _value_conditions_not.append(_p)\n                        value_conditions_not.append(p)\n                del _value_conditions_not\n                sequence_conditions += value_conditions_not\n            if has_values:\n                events_conditions = [c for c in list(set(sequence_conditions))]\n                events_conditions_where.append(f\"({' OR '.join(events_conditions)})\")\n            events_query_part = f\"SELECT main.session_id,\\n                                        MIN(main.datetime) AS first_event_ts,\\n                                        MAX(main.datetime) AS last_event_ts\\n                                    FROM {MAIN_EVENTS_TABLE} AS main {events_extra_join}\\n                                    WHERE {' AND '.join(events_conditions_where)}\\n                                    GROUP BY session_id\"\n    else:\n        data.events = []\n    if data.startTimestamp is not None:\n        extra_constraints.append('s.datetime >= toDateTime(%(startDate)s/1000)')\n    if data.endTimestamp is not None:\n        extra_constraints.append('s.datetime <= toDateTime(%(endDate)s/1000)')\n    extra_join = ''\n    if issue is not None:\n        extra_join = '\\n                INNER JOIN LATERAL(SELECT TRUE FROM events_common.issues INNER JOIN public.issues AS p_issues USING (issue_id)\\n                WHERE issues.session_id=f.session_id \\n                    AND p_issues.type=%(issue_type)s \\n                    AND p_issues.context_string=%(issue_contextString)s\\n                    AND timestamp >= f.first_event_ts\\n                    AND timestamp <= f.last_event_ts) AS issues ON(TRUE)\\n                '\n        full_args['issue_contextString'] = issue['contextString']\n        full_args['issue_type'] = issue['type']\n    elif len(issues) > 0:\n        issues_conditions = []\n        for (i, f) in enumerate(issues):\n            f_k_v = f'f_issue_v{i}'\n            f_k_s = f_k_v + '_source'\n            full_args = {**full_args, **_multiple_values(f.value, value_key=f_k_v), f_k_s: f.source}\n            issues_conditions.append(_multiple_conditions(f'issues.type=%({f_k_v})s', f.value, value_key=f_k_v))\n            issues_conditions[-1] = f'({issues_conditions[-1]} AND issues.context_string=%({f_k_s})s)'\n        extra_join = f\"INNER JOIN (SELECT DISTINCT events.session_id\\n                                 FROM experimental.issues\\n                                          INNER JOIN experimental.events USING (issue_id)\\n                                 WHERE issues.project_id = %(projectId)s\\n                                   AND events.project_id = %(projectId)s\\n                                   AND events.datetime >= toDateTime(%(startDate)s/1000)\\n                                   AND events.datetime <= toDateTime(%(endDate)s/1000)\\n                                   AND {' OR '.join(issues_conditions)}\\n                            ) AS issues USING (session_id)\"\n    if extra_event:\n        extra_event = f'INNER JOIN ({extra_event}) AS extra_event USING(session_id)'\n    else:\n        extra_event = ''\n    if errors_only:\n        query_part = f\"{(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\"\n    else:\n        if len(events_query_part) > 0:\n            extra_join += f\"INNER JOIN (SELECT * \\n                                    FROM {MAIN_SESSIONS_TABLE} AS s {extra_event}\\n                                    WHERE {' AND '.join(extra_constraints)}) AS s ON(s.session_id=f.session_id)\"\n        else:\n            extra_join = f\"(SELECT * \\n                                FROM {MAIN_SESSIONS_TABLE} AS s {extra_join} {extra_event}\\n                                WHERE {' AND '.join(extra_constraints)}\\n                                ORDER BY _timestamp DESC\\n                                LIMIT 1 BY session_id) AS s\"\n        query_part = f\"                            FROM {(f'({events_query_part}) AS f' if len(events_query_part) > 0 else '')}\\n                            {extra_join}\\n                            {extra_from}\\n                            \"\n    return (full_args, query_part)"
        ]
    },
    {
        "func_name": "search_by_metadata",
        "original": "def search_by_metadata(tenant_id, user_id, m_key, m_value, project_id=None):\n    if project_id is None:\n        all_projects = projects.get_projects(tenant_id=tenant_id)\n    else:\n        all_projects = [projects.get_project(tenant_id=tenant_id, project_id=int(project_id), include_last_session=False, include_gdpr=False)]\n    all_projects = {int(p['projectId']): p['name'] for p in all_projects}\n    project_ids = list(all_projects.keys())\n    available_keys = metadata.get_keys_by_projects(project_ids)\n    for i in available_keys:\n        available_keys[i]['user_id'] = schemas.FilterType.user_id\n        available_keys[i]['user_anonymous_id'] = schemas.FilterType.user_anonymous_id\n    results = {}\n    for i in project_ids:\n        if m_key not in available_keys[i].values():\n            available_keys.pop(i)\n            results[i] = {'total': 0, 'sessions': [], 'missingMetadata': True}\n    project_ids = list(available_keys.keys())\n    if len(project_ids) > 0:\n        with pg_client.PostgresClient() as cur:\n            sub_queries = []\n            for i in project_ids:\n                col_name = list(available_keys[i].keys())[list(available_keys[i].values()).index(m_key)]\n                sub_queries.append(cur.mogrify(f'(SELECT COALESCE(COUNT(s.*)) AS count FROM public.sessions AS s WHERE s.project_id = %(id)s AND s.{col_name} = %(value)s) AS \"{i}\"', {'id': i, 'value': m_value}).decode('UTF-8'))\n            query = f\"SELECT {', '.join(sub_queries)};\"\n            cur.execute(query=query)\n            rows = cur.fetchone()\n            sub_queries = []\n            for i in rows.keys():\n                results[i] = {'total': rows[i], 'sessions': [], 'missingMetadata': False, 'name': all_projects[int(i)]}\n                if rows[i] > 0:\n                    col_name = list(available_keys[int(i)].keys())[list(available_keys[int(i)].values()).index(m_key)]\n                    sub_queries.append(cur.mogrify(f'(\\n                                    SELECT *\\n                                    FROM (\\n                                            SELECT DISTINCT ON(favorite_sessions.session_id, s.session_id) {SESSION_PROJECTION_COLS}\\n                                            FROM public.sessions AS s LEFT JOIN (SELECT session_id\\n                                                                                    FROM public.user_favorite_sessions\\n                                                                                    WHERE user_favorite_sessions.user_id = %(userId)s\\n                                                                                ) AS favorite_sessions USING (session_id)\\n                                            WHERE s.project_id = %(id)s AND s.duration IS NOT NULL AND s.{col_name} = %(value)s\\n                                        ) AS full_sessions\\n                                    ORDER BY favorite DESC, issue_score DESC\\n                                    LIMIT 10\\n                                )', {'id': i, 'value': m_value, 'userId': user_id}).decode('UTF-8'))\n            if len(sub_queries) > 0:\n                cur.execute('\\nUNION\\n'.join(sub_queries))\n                rows = cur.fetchall()\n                for i in rows:\n                    results[str(i['project_id'])]['sessions'].append(helper.dict_to_camel_case(i))\n    return results",
        "mutated": [
            "def search_by_metadata(tenant_id, user_id, m_key, m_value, project_id=None):\n    if False:\n        i = 10\n    if project_id is None:\n        all_projects = projects.get_projects(tenant_id=tenant_id)\n    else:\n        all_projects = [projects.get_project(tenant_id=tenant_id, project_id=int(project_id), include_last_session=False, include_gdpr=False)]\n    all_projects = {int(p['projectId']): p['name'] for p in all_projects}\n    project_ids = list(all_projects.keys())\n    available_keys = metadata.get_keys_by_projects(project_ids)\n    for i in available_keys:\n        available_keys[i]['user_id'] = schemas.FilterType.user_id\n        available_keys[i]['user_anonymous_id'] = schemas.FilterType.user_anonymous_id\n    results = {}\n    for i in project_ids:\n        if m_key not in available_keys[i].values():\n            available_keys.pop(i)\n            results[i] = {'total': 0, 'sessions': [], 'missingMetadata': True}\n    project_ids = list(available_keys.keys())\n    if len(project_ids) > 0:\n        with pg_client.PostgresClient() as cur:\n            sub_queries = []\n            for i in project_ids:\n                col_name = list(available_keys[i].keys())[list(available_keys[i].values()).index(m_key)]\n                sub_queries.append(cur.mogrify(f'(SELECT COALESCE(COUNT(s.*)) AS count FROM public.sessions AS s WHERE s.project_id = %(id)s AND s.{col_name} = %(value)s) AS \"{i}\"', {'id': i, 'value': m_value}).decode('UTF-8'))\n            query = f\"SELECT {', '.join(sub_queries)};\"\n            cur.execute(query=query)\n            rows = cur.fetchone()\n            sub_queries = []\n            for i in rows.keys():\n                results[i] = {'total': rows[i], 'sessions': [], 'missingMetadata': False, 'name': all_projects[int(i)]}\n                if rows[i] > 0:\n                    col_name = list(available_keys[int(i)].keys())[list(available_keys[int(i)].values()).index(m_key)]\n                    sub_queries.append(cur.mogrify(f'(\\n                                    SELECT *\\n                                    FROM (\\n                                            SELECT DISTINCT ON(favorite_sessions.session_id, s.session_id) {SESSION_PROJECTION_COLS}\\n                                            FROM public.sessions AS s LEFT JOIN (SELECT session_id\\n                                                                                    FROM public.user_favorite_sessions\\n                                                                                    WHERE user_favorite_sessions.user_id = %(userId)s\\n                                                                                ) AS favorite_sessions USING (session_id)\\n                                            WHERE s.project_id = %(id)s AND s.duration IS NOT NULL AND s.{col_name} = %(value)s\\n                                        ) AS full_sessions\\n                                    ORDER BY favorite DESC, issue_score DESC\\n                                    LIMIT 10\\n                                )', {'id': i, 'value': m_value, 'userId': user_id}).decode('UTF-8'))\n            if len(sub_queries) > 0:\n                cur.execute('\\nUNION\\n'.join(sub_queries))\n                rows = cur.fetchall()\n                for i in rows:\n                    results[str(i['project_id'])]['sessions'].append(helper.dict_to_camel_case(i))\n    return results",
            "def search_by_metadata(tenant_id, user_id, m_key, m_value, project_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if project_id is None:\n        all_projects = projects.get_projects(tenant_id=tenant_id)\n    else:\n        all_projects = [projects.get_project(tenant_id=tenant_id, project_id=int(project_id), include_last_session=False, include_gdpr=False)]\n    all_projects = {int(p['projectId']): p['name'] for p in all_projects}\n    project_ids = list(all_projects.keys())\n    available_keys = metadata.get_keys_by_projects(project_ids)\n    for i in available_keys:\n        available_keys[i]['user_id'] = schemas.FilterType.user_id\n        available_keys[i]['user_anonymous_id'] = schemas.FilterType.user_anonymous_id\n    results = {}\n    for i in project_ids:\n        if m_key not in available_keys[i].values():\n            available_keys.pop(i)\n            results[i] = {'total': 0, 'sessions': [], 'missingMetadata': True}\n    project_ids = list(available_keys.keys())\n    if len(project_ids) > 0:\n        with pg_client.PostgresClient() as cur:\n            sub_queries = []\n            for i in project_ids:\n                col_name = list(available_keys[i].keys())[list(available_keys[i].values()).index(m_key)]\n                sub_queries.append(cur.mogrify(f'(SELECT COALESCE(COUNT(s.*)) AS count FROM public.sessions AS s WHERE s.project_id = %(id)s AND s.{col_name} = %(value)s) AS \"{i}\"', {'id': i, 'value': m_value}).decode('UTF-8'))\n            query = f\"SELECT {', '.join(sub_queries)};\"\n            cur.execute(query=query)\n            rows = cur.fetchone()\n            sub_queries = []\n            for i in rows.keys():\n                results[i] = {'total': rows[i], 'sessions': [], 'missingMetadata': False, 'name': all_projects[int(i)]}\n                if rows[i] > 0:\n                    col_name = list(available_keys[int(i)].keys())[list(available_keys[int(i)].values()).index(m_key)]\n                    sub_queries.append(cur.mogrify(f'(\\n                                    SELECT *\\n                                    FROM (\\n                                            SELECT DISTINCT ON(favorite_sessions.session_id, s.session_id) {SESSION_PROJECTION_COLS}\\n                                            FROM public.sessions AS s LEFT JOIN (SELECT session_id\\n                                                                                    FROM public.user_favorite_sessions\\n                                                                                    WHERE user_favorite_sessions.user_id = %(userId)s\\n                                                                                ) AS favorite_sessions USING (session_id)\\n                                            WHERE s.project_id = %(id)s AND s.duration IS NOT NULL AND s.{col_name} = %(value)s\\n                                        ) AS full_sessions\\n                                    ORDER BY favorite DESC, issue_score DESC\\n                                    LIMIT 10\\n                                )', {'id': i, 'value': m_value, 'userId': user_id}).decode('UTF-8'))\n            if len(sub_queries) > 0:\n                cur.execute('\\nUNION\\n'.join(sub_queries))\n                rows = cur.fetchall()\n                for i in rows:\n                    results[str(i['project_id'])]['sessions'].append(helper.dict_to_camel_case(i))\n    return results",
            "def search_by_metadata(tenant_id, user_id, m_key, m_value, project_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if project_id is None:\n        all_projects = projects.get_projects(tenant_id=tenant_id)\n    else:\n        all_projects = [projects.get_project(tenant_id=tenant_id, project_id=int(project_id), include_last_session=False, include_gdpr=False)]\n    all_projects = {int(p['projectId']): p['name'] for p in all_projects}\n    project_ids = list(all_projects.keys())\n    available_keys = metadata.get_keys_by_projects(project_ids)\n    for i in available_keys:\n        available_keys[i]['user_id'] = schemas.FilterType.user_id\n        available_keys[i]['user_anonymous_id'] = schemas.FilterType.user_anonymous_id\n    results = {}\n    for i in project_ids:\n        if m_key not in available_keys[i].values():\n            available_keys.pop(i)\n            results[i] = {'total': 0, 'sessions': [], 'missingMetadata': True}\n    project_ids = list(available_keys.keys())\n    if len(project_ids) > 0:\n        with pg_client.PostgresClient() as cur:\n            sub_queries = []\n            for i in project_ids:\n                col_name = list(available_keys[i].keys())[list(available_keys[i].values()).index(m_key)]\n                sub_queries.append(cur.mogrify(f'(SELECT COALESCE(COUNT(s.*)) AS count FROM public.sessions AS s WHERE s.project_id = %(id)s AND s.{col_name} = %(value)s) AS \"{i}\"', {'id': i, 'value': m_value}).decode('UTF-8'))\n            query = f\"SELECT {', '.join(sub_queries)};\"\n            cur.execute(query=query)\n            rows = cur.fetchone()\n            sub_queries = []\n            for i in rows.keys():\n                results[i] = {'total': rows[i], 'sessions': [], 'missingMetadata': False, 'name': all_projects[int(i)]}\n                if rows[i] > 0:\n                    col_name = list(available_keys[int(i)].keys())[list(available_keys[int(i)].values()).index(m_key)]\n                    sub_queries.append(cur.mogrify(f'(\\n                                    SELECT *\\n                                    FROM (\\n                                            SELECT DISTINCT ON(favorite_sessions.session_id, s.session_id) {SESSION_PROJECTION_COLS}\\n                                            FROM public.sessions AS s LEFT JOIN (SELECT session_id\\n                                                                                    FROM public.user_favorite_sessions\\n                                                                                    WHERE user_favorite_sessions.user_id = %(userId)s\\n                                                                                ) AS favorite_sessions USING (session_id)\\n                                            WHERE s.project_id = %(id)s AND s.duration IS NOT NULL AND s.{col_name} = %(value)s\\n                                        ) AS full_sessions\\n                                    ORDER BY favorite DESC, issue_score DESC\\n                                    LIMIT 10\\n                                )', {'id': i, 'value': m_value, 'userId': user_id}).decode('UTF-8'))\n            if len(sub_queries) > 0:\n                cur.execute('\\nUNION\\n'.join(sub_queries))\n                rows = cur.fetchall()\n                for i in rows:\n                    results[str(i['project_id'])]['sessions'].append(helper.dict_to_camel_case(i))\n    return results",
            "def search_by_metadata(tenant_id, user_id, m_key, m_value, project_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if project_id is None:\n        all_projects = projects.get_projects(tenant_id=tenant_id)\n    else:\n        all_projects = [projects.get_project(tenant_id=tenant_id, project_id=int(project_id), include_last_session=False, include_gdpr=False)]\n    all_projects = {int(p['projectId']): p['name'] for p in all_projects}\n    project_ids = list(all_projects.keys())\n    available_keys = metadata.get_keys_by_projects(project_ids)\n    for i in available_keys:\n        available_keys[i]['user_id'] = schemas.FilterType.user_id\n        available_keys[i]['user_anonymous_id'] = schemas.FilterType.user_anonymous_id\n    results = {}\n    for i in project_ids:\n        if m_key not in available_keys[i].values():\n            available_keys.pop(i)\n            results[i] = {'total': 0, 'sessions': [], 'missingMetadata': True}\n    project_ids = list(available_keys.keys())\n    if len(project_ids) > 0:\n        with pg_client.PostgresClient() as cur:\n            sub_queries = []\n            for i in project_ids:\n                col_name = list(available_keys[i].keys())[list(available_keys[i].values()).index(m_key)]\n                sub_queries.append(cur.mogrify(f'(SELECT COALESCE(COUNT(s.*)) AS count FROM public.sessions AS s WHERE s.project_id = %(id)s AND s.{col_name} = %(value)s) AS \"{i}\"', {'id': i, 'value': m_value}).decode('UTF-8'))\n            query = f\"SELECT {', '.join(sub_queries)};\"\n            cur.execute(query=query)\n            rows = cur.fetchone()\n            sub_queries = []\n            for i in rows.keys():\n                results[i] = {'total': rows[i], 'sessions': [], 'missingMetadata': False, 'name': all_projects[int(i)]}\n                if rows[i] > 0:\n                    col_name = list(available_keys[int(i)].keys())[list(available_keys[int(i)].values()).index(m_key)]\n                    sub_queries.append(cur.mogrify(f'(\\n                                    SELECT *\\n                                    FROM (\\n                                            SELECT DISTINCT ON(favorite_sessions.session_id, s.session_id) {SESSION_PROJECTION_COLS}\\n                                            FROM public.sessions AS s LEFT JOIN (SELECT session_id\\n                                                                                    FROM public.user_favorite_sessions\\n                                                                                    WHERE user_favorite_sessions.user_id = %(userId)s\\n                                                                                ) AS favorite_sessions USING (session_id)\\n                                            WHERE s.project_id = %(id)s AND s.duration IS NOT NULL AND s.{col_name} = %(value)s\\n                                        ) AS full_sessions\\n                                    ORDER BY favorite DESC, issue_score DESC\\n                                    LIMIT 10\\n                                )', {'id': i, 'value': m_value, 'userId': user_id}).decode('UTF-8'))\n            if len(sub_queries) > 0:\n                cur.execute('\\nUNION\\n'.join(sub_queries))\n                rows = cur.fetchall()\n                for i in rows:\n                    results[str(i['project_id'])]['sessions'].append(helper.dict_to_camel_case(i))\n    return results",
            "def search_by_metadata(tenant_id, user_id, m_key, m_value, project_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if project_id is None:\n        all_projects = projects.get_projects(tenant_id=tenant_id)\n    else:\n        all_projects = [projects.get_project(tenant_id=tenant_id, project_id=int(project_id), include_last_session=False, include_gdpr=False)]\n    all_projects = {int(p['projectId']): p['name'] for p in all_projects}\n    project_ids = list(all_projects.keys())\n    available_keys = metadata.get_keys_by_projects(project_ids)\n    for i in available_keys:\n        available_keys[i]['user_id'] = schemas.FilterType.user_id\n        available_keys[i]['user_anonymous_id'] = schemas.FilterType.user_anonymous_id\n    results = {}\n    for i in project_ids:\n        if m_key not in available_keys[i].values():\n            available_keys.pop(i)\n            results[i] = {'total': 0, 'sessions': [], 'missingMetadata': True}\n    project_ids = list(available_keys.keys())\n    if len(project_ids) > 0:\n        with pg_client.PostgresClient() as cur:\n            sub_queries = []\n            for i in project_ids:\n                col_name = list(available_keys[i].keys())[list(available_keys[i].values()).index(m_key)]\n                sub_queries.append(cur.mogrify(f'(SELECT COALESCE(COUNT(s.*)) AS count FROM public.sessions AS s WHERE s.project_id = %(id)s AND s.{col_name} = %(value)s) AS \"{i}\"', {'id': i, 'value': m_value}).decode('UTF-8'))\n            query = f\"SELECT {', '.join(sub_queries)};\"\n            cur.execute(query=query)\n            rows = cur.fetchone()\n            sub_queries = []\n            for i in rows.keys():\n                results[i] = {'total': rows[i], 'sessions': [], 'missingMetadata': False, 'name': all_projects[int(i)]}\n                if rows[i] > 0:\n                    col_name = list(available_keys[int(i)].keys())[list(available_keys[int(i)].values()).index(m_key)]\n                    sub_queries.append(cur.mogrify(f'(\\n                                    SELECT *\\n                                    FROM (\\n                                            SELECT DISTINCT ON(favorite_sessions.session_id, s.session_id) {SESSION_PROJECTION_COLS}\\n                                            FROM public.sessions AS s LEFT JOIN (SELECT session_id\\n                                                                                    FROM public.user_favorite_sessions\\n                                                                                    WHERE user_favorite_sessions.user_id = %(userId)s\\n                                                                                ) AS favorite_sessions USING (session_id)\\n                                            WHERE s.project_id = %(id)s AND s.duration IS NOT NULL AND s.{col_name} = %(value)s\\n                                        ) AS full_sessions\\n                                    ORDER BY favorite DESC, issue_score DESC\\n                                    LIMIT 10\\n                                )', {'id': i, 'value': m_value, 'userId': user_id}).decode('UTF-8'))\n            if len(sub_queries) > 0:\n                cur.execute('\\nUNION\\n'.join(sub_queries))\n                rows = cur.fetchall()\n                for i in rows:\n                    results[str(i['project_id'])]['sessions'].append(helper.dict_to_camel_case(i))\n    return results"
        ]
    },
    {
        "func_name": "get_user_sessions",
        "original": "def get_user_sessions(project_id, user_id, start_date, end_date):\n    with pg_client.PostgresClient() as cur:\n        constraints = ['s.project_id = %(projectId)s', 's.user_id = %(userId)s']\n        if start_date is not None:\n            constraints.append('s.start_ts >= %(startDate)s')\n        if end_date is not None:\n            constraints.append('s.start_ts <= %(endDate)s')\n        query_part = f\"            FROM public.sessions AS s\\n            WHERE {' AND '.join(constraints)}\"\n        cur.execute(cur.mogrify(f'                    SELECT s.project_id,\\n                           s.session_id::text AS session_id,\\n                           s.user_uuid,\\n                           s.user_id,\\n                           s.user_os,\\n                           s.user_browser,\\n                           s.user_device,\\n                           s.user_country,\\n                           s.start_ts,\\n                           s.duration,\\n                           s.events_count,\\n                           s.pages_count,\\n                           s.errors_count\\n                    {query_part}\\n                    ORDER BY s.session_id         \\n                    LIMIT 50;', {'projectId': project_id, 'userId': user_id, 'startDate': start_date, 'endDate': end_date}))\n        sessions = cur.fetchall()\n    return helper.list_to_camel_case(sessions)",
        "mutated": [
            "def get_user_sessions(project_id, user_id, start_date, end_date):\n    if False:\n        i = 10\n    with pg_client.PostgresClient() as cur:\n        constraints = ['s.project_id = %(projectId)s', 's.user_id = %(userId)s']\n        if start_date is not None:\n            constraints.append('s.start_ts >= %(startDate)s')\n        if end_date is not None:\n            constraints.append('s.start_ts <= %(endDate)s')\n        query_part = f\"            FROM public.sessions AS s\\n            WHERE {' AND '.join(constraints)}\"\n        cur.execute(cur.mogrify(f'                    SELECT s.project_id,\\n                           s.session_id::text AS session_id,\\n                           s.user_uuid,\\n                           s.user_id,\\n                           s.user_os,\\n                           s.user_browser,\\n                           s.user_device,\\n                           s.user_country,\\n                           s.start_ts,\\n                           s.duration,\\n                           s.events_count,\\n                           s.pages_count,\\n                           s.errors_count\\n                    {query_part}\\n                    ORDER BY s.session_id         \\n                    LIMIT 50;', {'projectId': project_id, 'userId': user_id, 'startDate': start_date, 'endDate': end_date}))\n        sessions = cur.fetchall()\n    return helper.list_to_camel_case(sessions)",
            "def get_user_sessions(project_id, user_id, start_date, end_date):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with pg_client.PostgresClient() as cur:\n        constraints = ['s.project_id = %(projectId)s', 's.user_id = %(userId)s']\n        if start_date is not None:\n            constraints.append('s.start_ts >= %(startDate)s')\n        if end_date is not None:\n            constraints.append('s.start_ts <= %(endDate)s')\n        query_part = f\"            FROM public.sessions AS s\\n            WHERE {' AND '.join(constraints)}\"\n        cur.execute(cur.mogrify(f'                    SELECT s.project_id,\\n                           s.session_id::text AS session_id,\\n                           s.user_uuid,\\n                           s.user_id,\\n                           s.user_os,\\n                           s.user_browser,\\n                           s.user_device,\\n                           s.user_country,\\n                           s.start_ts,\\n                           s.duration,\\n                           s.events_count,\\n                           s.pages_count,\\n                           s.errors_count\\n                    {query_part}\\n                    ORDER BY s.session_id         \\n                    LIMIT 50;', {'projectId': project_id, 'userId': user_id, 'startDate': start_date, 'endDate': end_date}))\n        sessions = cur.fetchall()\n    return helper.list_to_camel_case(sessions)",
            "def get_user_sessions(project_id, user_id, start_date, end_date):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with pg_client.PostgresClient() as cur:\n        constraints = ['s.project_id = %(projectId)s', 's.user_id = %(userId)s']\n        if start_date is not None:\n            constraints.append('s.start_ts >= %(startDate)s')\n        if end_date is not None:\n            constraints.append('s.start_ts <= %(endDate)s')\n        query_part = f\"            FROM public.sessions AS s\\n            WHERE {' AND '.join(constraints)}\"\n        cur.execute(cur.mogrify(f'                    SELECT s.project_id,\\n                           s.session_id::text AS session_id,\\n                           s.user_uuid,\\n                           s.user_id,\\n                           s.user_os,\\n                           s.user_browser,\\n                           s.user_device,\\n                           s.user_country,\\n                           s.start_ts,\\n                           s.duration,\\n                           s.events_count,\\n                           s.pages_count,\\n                           s.errors_count\\n                    {query_part}\\n                    ORDER BY s.session_id         \\n                    LIMIT 50;', {'projectId': project_id, 'userId': user_id, 'startDate': start_date, 'endDate': end_date}))\n        sessions = cur.fetchall()\n    return helper.list_to_camel_case(sessions)",
            "def get_user_sessions(project_id, user_id, start_date, end_date):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with pg_client.PostgresClient() as cur:\n        constraints = ['s.project_id = %(projectId)s', 's.user_id = %(userId)s']\n        if start_date is not None:\n            constraints.append('s.start_ts >= %(startDate)s')\n        if end_date is not None:\n            constraints.append('s.start_ts <= %(endDate)s')\n        query_part = f\"            FROM public.sessions AS s\\n            WHERE {' AND '.join(constraints)}\"\n        cur.execute(cur.mogrify(f'                    SELECT s.project_id,\\n                           s.session_id::text AS session_id,\\n                           s.user_uuid,\\n                           s.user_id,\\n                           s.user_os,\\n                           s.user_browser,\\n                           s.user_device,\\n                           s.user_country,\\n                           s.start_ts,\\n                           s.duration,\\n                           s.events_count,\\n                           s.pages_count,\\n                           s.errors_count\\n                    {query_part}\\n                    ORDER BY s.session_id         \\n                    LIMIT 50;', {'projectId': project_id, 'userId': user_id, 'startDate': start_date, 'endDate': end_date}))\n        sessions = cur.fetchall()\n    return helper.list_to_camel_case(sessions)",
            "def get_user_sessions(project_id, user_id, start_date, end_date):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with pg_client.PostgresClient() as cur:\n        constraints = ['s.project_id = %(projectId)s', 's.user_id = %(userId)s']\n        if start_date is not None:\n            constraints.append('s.start_ts >= %(startDate)s')\n        if end_date is not None:\n            constraints.append('s.start_ts <= %(endDate)s')\n        query_part = f\"            FROM public.sessions AS s\\n            WHERE {' AND '.join(constraints)}\"\n        cur.execute(cur.mogrify(f'                    SELECT s.project_id,\\n                           s.session_id::text AS session_id,\\n                           s.user_uuid,\\n                           s.user_id,\\n                           s.user_os,\\n                           s.user_browser,\\n                           s.user_device,\\n                           s.user_country,\\n                           s.start_ts,\\n                           s.duration,\\n                           s.events_count,\\n                           s.pages_count,\\n                           s.errors_count\\n                    {query_part}\\n                    ORDER BY s.session_id         \\n                    LIMIT 50;', {'projectId': project_id, 'userId': user_id, 'startDate': start_date, 'endDate': end_date}))\n        sessions = cur.fetchall()\n    return helper.list_to_camel_case(sessions)"
        ]
    },
    {
        "func_name": "get_session_user",
        "original": "def get_session_user(project_id, user_id):\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify('            SELECT\\n                user_id,\\n                count(*) as session_count,\\t\\n                max(start_ts) as last_seen,\\n                min(start_ts) as first_seen\\n            FROM\\n                \"public\".sessions\\n            WHERE\\n                project_id = %(project_id)s\\n                AND user_id = %(userId)s\\n                AND duration is not null\\n            GROUP BY user_id;\\n            ', {'project_id': project_id, 'userId': user_id})\n        cur.execute(query=query)\n        data = cur.fetchone()\n    return helper.dict_to_camel_case(data)",
        "mutated": [
            "def get_session_user(project_id, user_id):\n    if False:\n        i = 10\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify('            SELECT\\n                user_id,\\n                count(*) as session_count,\\t\\n                max(start_ts) as last_seen,\\n                min(start_ts) as first_seen\\n            FROM\\n                \"public\".sessions\\n            WHERE\\n                project_id = %(project_id)s\\n                AND user_id = %(userId)s\\n                AND duration is not null\\n            GROUP BY user_id;\\n            ', {'project_id': project_id, 'userId': user_id})\n        cur.execute(query=query)\n        data = cur.fetchone()\n    return helper.dict_to_camel_case(data)",
            "def get_session_user(project_id, user_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify('            SELECT\\n                user_id,\\n                count(*) as session_count,\\t\\n                max(start_ts) as last_seen,\\n                min(start_ts) as first_seen\\n            FROM\\n                \"public\".sessions\\n            WHERE\\n                project_id = %(project_id)s\\n                AND user_id = %(userId)s\\n                AND duration is not null\\n            GROUP BY user_id;\\n            ', {'project_id': project_id, 'userId': user_id})\n        cur.execute(query=query)\n        data = cur.fetchone()\n    return helper.dict_to_camel_case(data)",
            "def get_session_user(project_id, user_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify('            SELECT\\n                user_id,\\n                count(*) as session_count,\\t\\n                max(start_ts) as last_seen,\\n                min(start_ts) as first_seen\\n            FROM\\n                \"public\".sessions\\n            WHERE\\n                project_id = %(project_id)s\\n                AND user_id = %(userId)s\\n                AND duration is not null\\n            GROUP BY user_id;\\n            ', {'project_id': project_id, 'userId': user_id})\n        cur.execute(query=query)\n        data = cur.fetchone()\n    return helper.dict_to_camel_case(data)",
            "def get_session_user(project_id, user_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify('            SELECT\\n                user_id,\\n                count(*) as session_count,\\t\\n                max(start_ts) as last_seen,\\n                min(start_ts) as first_seen\\n            FROM\\n                \"public\".sessions\\n            WHERE\\n                project_id = %(project_id)s\\n                AND user_id = %(userId)s\\n                AND duration is not null\\n            GROUP BY user_id;\\n            ', {'project_id': project_id, 'userId': user_id})\n        cur.execute(query=query)\n        data = cur.fetchone()\n    return helper.dict_to_camel_case(data)",
            "def get_session_user(project_id, user_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify('            SELECT\\n                user_id,\\n                count(*) as session_count,\\t\\n                max(start_ts) as last_seen,\\n                min(start_ts) as first_seen\\n            FROM\\n                \"public\".sessions\\n            WHERE\\n                project_id = %(project_id)s\\n                AND user_id = %(userId)s\\n                AND duration is not null\\n            GROUP BY user_id;\\n            ', {'project_id': project_id, 'userId': user_id})\n        cur.execute(query=query)\n        data = cur.fetchone()\n    return helper.dict_to_camel_case(data)"
        ]
    },
    {
        "func_name": "session_exists",
        "original": "def session_exists(project_id, session_id):\n    with ch_client.ClickHouseClient() as cur:\n        query = cur.format(f'SELECT 1 \\n                               FROM {exp_ch_helper.get_main_sessions_table()} \\n                               WHERE session_id=%(session_id)s \\n                                    AND project_id=%(project_id)s\\n                               LIMIT 1', {'project_id': project_id, 'session_id': session_id})\n        row = cur.execute(query)\n    return row is not None",
        "mutated": [
            "def session_exists(project_id, session_id):\n    if False:\n        i = 10\n    with ch_client.ClickHouseClient() as cur:\n        query = cur.format(f'SELECT 1 \\n                               FROM {exp_ch_helper.get_main_sessions_table()} \\n                               WHERE session_id=%(session_id)s \\n                                    AND project_id=%(project_id)s\\n                               LIMIT 1', {'project_id': project_id, 'session_id': session_id})\n        row = cur.execute(query)\n    return row is not None",
            "def session_exists(project_id, session_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with ch_client.ClickHouseClient() as cur:\n        query = cur.format(f'SELECT 1 \\n                               FROM {exp_ch_helper.get_main_sessions_table()} \\n                               WHERE session_id=%(session_id)s \\n                                    AND project_id=%(project_id)s\\n                               LIMIT 1', {'project_id': project_id, 'session_id': session_id})\n        row = cur.execute(query)\n    return row is not None",
            "def session_exists(project_id, session_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with ch_client.ClickHouseClient() as cur:\n        query = cur.format(f'SELECT 1 \\n                               FROM {exp_ch_helper.get_main_sessions_table()} \\n                               WHERE session_id=%(session_id)s \\n                                    AND project_id=%(project_id)s\\n                               LIMIT 1', {'project_id': project_id, 'session_id': session_id})\n        row = cur.execute(query)\n    return row is not None",
            "def session_exists(project_id, session_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with ch_client.ClickHouseClient() as cur:\n        query = cur.format(f'SELECT 1 \\n                               FROM {exp_ch_helper.get_main_sessions_table()} \\n                               WHERE session_id=%(session_id)s \\n                                    AND project_id=%(project_id)s\\n                               LIMIT 1', {'project_id': project_id, 'session_id': session_id})\n        row = cur.execute(query)\n    return row is not None",
            "def session_exists(project_id, session_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with ch_client.ClickHouseClient() as cur:\n        query = cur.format(f'SELECT 1 \\n                               FROM {exp_ch_helper.get_main_sessions_table()} \\n                               WHERE session_id=%(session_id)s \\n                                    AND project_id=%(project_id)s\\n                               LIMIT 1', {'project_id': project_id, 'session_id': session_id})\n        row = cur.execute(query)\n    return row is not None"
        ]
    },
    {
        "func_name": "check_recording_status",
        "original": "def check_recording_status(project_id: int) -> dict:\n    query = f\"\\n        WITH project_sessions AS (SELECT COUNT(1)                                      AS full_count,\\n                                 COUNT(1) FILTER ( WHERE duration IS NOT NULL) AS nn_duration_count\\n                          FROM public.sessions\\n                          WHERE project_id = %(project_id)s\\n                            AND start_ts >= (extract(EPOCH FROM now() - INTERVAL '1 day')) * 1000\\n                            AND start_ts <= (extract(EPOCH FROM now() + INTERVAL '1 day')) * 1000)\\n        SELECT CASE\\n                   WHEN full_count = 0 THEN 0\\n                   WHEN nn_duration_count = 0 THEN 1\\n                   ELSE 2\\n                   END    AS recording_status,\\n               full_count AS sessions_count\\n        FROM project_sessions;\\n    \"\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify(query, {'project_id': project_id})\n        cur.execute(query)\n        row = cur.fetchone()\n    return {'recordingStatus': row['recording_status'], 'sessionsCount': row['sessions_count']}",
        "mutated": [
            "def check_recording_status(project_id: int) -> dict:\n    if False:\n        i = 10\n    query = f\"\\n        WITH project_sessions AS (SELECT COUNT(1)                                      AS full_count,\\n                                 COUNT(1) FILTER ( WHERE duration IS NOT NULL) AS nn_duration_count\\n                          FROM public.sessions\\n                          WHERE project_id = %(project_id)s\\n                            AND start_ts >= (extract(EPOCH FROM now() - INTERVAL '1 day')) * 1000\\n                            AND start_ts <= (extract(EPOCH FROM now() + INTERVAL '1 day')) * 1000)\\n        SELECT CASE\\n                   WHEN full_count = 0 THEN 0\\n                   WHEN nn_duration_count = 0 THEN 1\\n                   ELSE 2\\n                   END    AS recording_status,\\n               full_count AS sessions_count\\n        FROM project_sessions;\\n    \"\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify(query, {'project_id': project_id})\n        cur.execute(query)\n        row = cur.fetchone()\n    return {'recordingStatus': row['recording_status'], 'sessionsCount': row['sessions_count']}",
            "def check_recording_status(project_id: int) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    query = f\"\\n        WITH project_sessions AS (SELECT COUNT(1)                                      AS full_count,\\n                                 COUNT(1) FILTER ( WHERE duration IS NOT NULL) AS nn_duration_count\\n                          FROM public.sessions\\n                          WHERE project_id = %(project_id)s\\n                            AND start_ts >= (extract(EPOCH FROM now() - INTERVAL '1 day')) * 1000\\n                            AND start_ts <= (extract(EPOCH FROM now() + INTERVAL '1 day')) * 1000)\\n        SELECT CASE\\n                   WHEN full_count = 0 THEN 0\\n                   WHEN nn_duration_count = 0 THEN 1\\n                   ELSE 2\\n                   END    AS recording_status,\\n               full_count AS sessions_count\\n        FROM project_sessions;\\n    \"\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify(query, {'project_id': project_id})\n        cur.execute(query)\n        row = cur.fetchone()\n    return {'recordingStatus': row['recording_status'], 'sessionsCount': row['sessions_count']}",
            "def check_recording_status(project_id: int) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    query = f\"\\n        WITH project_sessions AS (SELECT COUNT(1)                                      AS full_count,\\n                                 COUNT(1) FILTER ( WHERE duration IS NOT NULL) AS nn_duration_count\\n                          FROM public.sessions\\n                          WHERE project_id = %(project_id)s\\n                            AND start_ts >= (extract(EPOCH FROM now() - INTERVAL '1 day')) * 1000\\n                            AND start_ts <= (extract(EPOCH FROM now() + INTERVAL '1 day')) * 1000)\\n        SELECT CASE\\n                   WHEN full_count = 0 THEN 0\\n                   WHEN nn_duration_count = 0 THEN 1\\n                   ELSE 2\\n                   END    AS recording_status,\\n               full_count AS sessions_count\\n        FROM project_sessions;\\n    \"\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify(query, {'project_id': project_id})\n        cur.execute(query)\n        row = cur.fetchone()\n    return {'recordingStatus': row['recording_status'], 'sessionsCount': row['sessions_count']}",
            "def check_recording_status(project_id: int) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    query = f\"\\n        WITH project_sessions AS (SELECT COUNT(1)                                      AS full_count,\\n                                 COUNT(1) FILTER ( WHERE duration IS NOT NULL) AS nn_duration_count\\n                          FROM public.sessions\\n                          WHERE project_id = %(project_id)s\\n                            AND start_ts >= (extract(EPOCH FROM now() - INTERVAL '1 day')) * 1000\\n                            AND start_ts <= (extract(EPOCH FROM now() + INTERVAL '1 day')) * 1000)\\n        SELECT CASE\\n                   WHEN full_count = 0 THEN 0\\n                   WHEN nn_duration_count = 0 THEN 1\\n                   ELSE 2\\n                   END    AS recording_status,\\n               full_count AS sessions_count\\n        FROM project_sessions;\\n    \"\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify(query, {'project_id': project_id})\n        cur.execute(query)\n        row = cur.fetchone()\n    return {'recordingStatus': row['recording_status'], 'sessionsCount': row['sessions_count']}",
            "def check_recording_status(project_id: int) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    query = f\"\\n        WITH project_sessions AS (SELECT COUNT(1)                                      AS full_count,\\n                                 COUNT(1) FILTER ( WHERE duration IS NOT NULL) AS nn_duration_count\\n                          FROM public.sessions\\n                          WHERE project_id = %(project_id)s\\n                            AND start_ts >= (extract(EPOCH FROM now() - INTERVAL '1 day')) * 1000\\n                            AND start_ts <= (extract(EPOCH FROM now() + INTERVAL '1 day')) * 1000)\\n        SELECT CASE\\n                   WHEN full_count = 0 THEN 0\\n                   WHEN nn_duration_count = 0 THEN 1\\n                   ELSE 2\\n                   END    AS recording_status,\\n               full_count AS sessions_count\\n        FROM project_sessions;\\n    \"\n    with pg_client.PostgresClient() as cur:\n        query = cur.mogrify(query, {'project_id': project_id})\n        cur.execute(query)\n        row = cur.fetchone()\n    return {'recordingStatus': row['recording_status'], 'sessionsCount': row['sessions_count']}"
        ]
    }
]