[
    {
        "func_name": "load_checkpoint",
        "original": "def load_checkpoint(checkpoint_path):\n    \"\"\"Checkpoint path should end in model.pt\"\"\"\n    sd = torch.load(checkpoint_path, map_location='cpu')\n    if 'model' in sd.keys():\n        sd = torch.load(checkpoint_path, map_location='cpu')['model']\n    keys_to_delete = ['decoder.version', 'decoder.output_projection.weight']\n    for key in keys_to_delete:\n        if key in sd:\n            sd.pop(key)\n    keys_to_rename = {'decoder.project_in_dim.weight': 'decoder.project_in.weight', 'decoder.project_out_dim.weight': 'decoder.project_out.weight', 'decoder.layer_norm.weight': 'decoder.final_layer_norm.weight', 'decoder.layer_norm.bias': 'decoder.final_layer_norm.bias'}\n    for (old_key, new_key) in keys_to_rename.items():\n        if old_key in sd:\n            sd[new_key] = sd.pop(old_key)\n    keys = list(sd.keys())\n    for key in keys:\n        if '.qkv_proj.' in key:\n            value = sd[key]\n            q_name = key.replace('.qkv_proj.', '.q_proj.')\n            k_name = key.replace('.qkv_proj.', '.k_proj.')\n            v_name = key.replace('.qkv_proj.', '.v_proj.')\n            depth = value.shape[0]\n            assert depth % 3 == 0\n            (k, v, q) = torch.split(value, depth // 3, dim=0)\n            sd[q_name] = q\n            sd[k_name] = k\n            sd[v_name] = v\n            del sd[key]\n    return sd",
        "mutated": [
            "def load_checkpoint(checkpoint_path):\n    if False:\n        i = 10\n    'Checkpoint path should end in model.pt'\n    sd = torch.load(checkpoint_path, map_location='cpu')\n    if 'model' in sd.keys():\n        sd = torch.load(checkpoint_path, map_location='cpu')['model']\n    keys_to_delete = ['decoder.version', 'decoder.output_projection.weight']\n    for key in keys_to_delete:\n        if key in sd:\n            sd.pop(key)\n    keys_to_rename = {'decoder.project_in_dim.weight': 'decoder.project_in.weight', 'decoder.project_out_dim.weight': 'decoder.project_out.weight', 'decoder.layer_norm.weight': 'decoder.final_layer_norm.weight', 'decoder.layer_norm.bias': 'decoder.final_layer_norm.bias'}\n    for (old_key, new_key) in keys_to_rename.items():\n        if old_key in sd:\n            sd[new_key] = sd.pop(old_key)\n    keys = list(sd.keys())\n    for key in keys:\n        if '.qkv_proj.' in key:\n            value = sd[key]\n            q_name = key.replace('.qkv_proj.', '.q_proj.')\n            k_name = key.replace('.qkv_proj.', '.k_proj.')\n            v_name = key.replace('.qkv_proj.', '.v_proj.')\n            depth = value.shape[0]\n            assert depth % 3 == 0\n            (k, v, q) = torch.split(value, depth // 3, dim=0)\n            sd[q_name] = q\n            sd[k_name] = k\n            sd[v_name] = v\n            del sd[key]\n    return sd",
            "def load_checkpoint(checkpoint_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Checkpoint path should end in model.pt'\n    sd = torch.load(checkpoint_path, map_location='cpu')\n    if 'model' in sd.keys():\n        sd = torch.load(checkpoint_path, map_location='cpu')['model']\n    keys_to_delete = ['decoder.version', 'decoder.output_projection.weight']\n    for key in keys_to_delete:\n        if key in sd:\n            sd.pop(key)\n    keys_to_rename = {'decoder.project_in_dim.weight': 'decoder.project_in.weight', 'decoder.project_out_dim.weight': 'decoder.project_out.weight', 'decoder.layer_norm.weight': 'decoder.final_layer_norm.weight', 'decoder.layer_norm.bias': 'decoder.final_layer_norm.bias'}\n    for (old_key, new_key) in keys_to_rename.items():\n        if old_key in sd:\n            sd[new_key] = sd.pop(old_key)\n    keys = list(sd.keys())\n    for key in keys:\n        if '.qkv_proj.' in key:\n            value = sd[key]\n            q_name = key.replace('.qkv_proj.', '.q_proj.')\n            k_name = key.replace('.qkv_proj.', '.k_proj.')\n            v_name = key.replace('.qkv_proj.', '.v_proj.')\n            depth = value.shape[0]\n            assert depth % 3 == 0\n            (k, v, q) = torch.split(value, depth // 3, dim=0)\n            sd[q_name] = q\n            sd[k_name] = k\n            sd[v_name] = v\n            del sd[key]\n    return sd",
            "def load_checkpoint(checkpoint_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Checkpoint path should end in model.pt'\n    sd = torch.load(checkpoint_path, map_location='cpu')\n    if 'model' in sd.keys():\n        sd = torch.load(checkpoint_path, map_location='cpu')['model']\n    keys_to_delete = ['decoder.version', 'decoder.output_projection.weight']\n    for key in keys_to_delete:\n        if key in sd:\n            sd.pop(key)\n    keys_to_rename = {'decoder.project_in_dim.weight': 'decoder.project_in.weight', 'decoder.project_out_dim.weight': 'decoder.project_out.weight', 'decoder.layer_norm.weight': 'decoder.final_layer_norm.weight', 'decoder.layer_norm.bias': 'decoder.final_layer_norm.bias'}\n    for (old_key, new_key) in keys_to_rename.items():\n        if old_key in sd:\n            sd[new_key] = sd.pop(old_key)\n    keys = list(sd.keys())\n    for key in keys:\n        if '.qkv_proj.' in key:\n            value = sd[key]\n            q_name = key.replace('.qkv_proj.', '.q_proj.')\n            k_name = key.replace('.qkv_proj.', '.k_proj.')\n            v_name = key.replace('.qkv_proj.', '.v_proj.')\n            depth = value.shape[0]\n            assert depth % 3 == 0\n            (k, v, q) = torch.split(value, depth // 3, dim=0)\n            sd[q_name] = q\n            sd[k_name] = k\n            sd[v_name] = v\n            del sd[key]\n    return sd",
            "def load_checkpoint(checkpoint_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Checkpoint path should end in model.pt'\n    sd = torch.load(checkpoint_path, map_location='cpu')\n    if 'model' in sd.keys():\n        sd = torch.load(checkpoint_path, map_location='cpu')['model']\n    keys_to_delete = ['decoder.version', 'decoder.output_projection.weight']\n    for key in keys_to_delete:\n        if key in sd:\n            sd.pop(key)\n    keys_to_rename = {'decoder.project_in_dim.weight': 'decoder.project_in.weight', 'decoder.project_out_dim.weight': 'decoder.project_out.weight', 'decoder.layer_norm.weight': 'decoder.final_layer_norm.weight', 'decoder.layer_norm.bias': 'decoder.final_layer_norm.bias'}\n    for (old_key, new_key) in keys_to_rename.items():\n        if old_key in sd:\n            sd[new_key] = sd.pop(old_key)\n    keys = list(sd.keys())\n    for key in keys:\n        if '.qkv_proj.' in key:\n            value = sd[key]\n            q_name = key.replace('.qkv_proj.', '.q_proj.')\n            k_name = key.replace('.qkv_proj.', '.k_proj.')\n            v_name = key.replace('.qkv_proj.', '.v_proj.')\n            depth = value.shape[0]\n            assert depth % 3 == 0\n            (k, v, q) = torch.split(value, depth // 3, dim=0)\n            sd[q_name] = q\n            sd[k_name] = k\n            sd[v_name] = v\n            del sd[key]\n    return sd",
            "def load_checkpoint(checkpoint_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Checkpoint path should end in model.pt'\n    sd = torch.load(checkpoint_path, map_location='cpu')\n    if 'model' in sd.keys():\n        sd = torch.load(checkpoint_path, map_location='cpu')['model']\n    keys_to_delete = ['decoder.version', 'decoder.output_projection.weight']\n    for key in keys_to_delete:\n        if key in sd:\n            sd.pop(key)\n    keys_to_rename = {'decoder.project_in_dim.weight': 'decoder.project_in.weight', 'decoder.project_out_dim.weight': 'decoder.project_out.weight', 'decoder.layer_norm.weight': 'decoder.final_layer_norm.weight', 'decoder.layer_norm.bias': 'decoder.final_layer_norm.bias'}\n    for (old_key, new_key) in keys_to_rename.items():\n        if old_key in sd:\n            sd[new_key] = sd.pop(old_key)\n    keys = list(sd.keys())\n    for key in keys:\n        if '.qkv_proj.' in key:\n            value = sd[key]\n            q_name = key.replace('.qkv_proj.', '.q_proj.')\n            k_name = key.replace('.qkv_proj.', '.k_proj.')\n            v_name = key.replace('.qkv_proj.', '.v_proj.')\n            depth = value.shape[0]\n            assert depth % 3 == 0\n            (k, v, q) = torch.split(value, depth // 3, dim=0)\n            sd[q_name] = q\n            sd[k_name] = k\n            sd[v_name] = v\n            del sd[key]\n    return sd"
        ]
    },
    {
        "func_name": "convert_opt_checkpoint",
        "original": "@torch.no_grad()\ndef convert_opt_checkpoint(checkpoint_path, pytorch_dump_folder_path, config=None):\n    \"\"\"\n    Copy/paste/tweak model's weights to our BERT structure.\n    \"\"\"\n    state_dict = load_checkpoint(checkpoint_path)\n    if config is not None:\n        config = OPTConfig.from_pretrained(config)\n    else:\n        config = OPTConfig()\n    model = OPTModel(config).half().eval()\n    model.load_state_dict(state_dict)\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)",
        "mutated": [
            "@torch.no_grad()\ndef convert_opt_checkpoint(checkpoint_path, pytorch_dump_folder_path, config=None):\n    if False:\n        i = 10\n    \"\\n    Copy/paste/tweak model's weights to our BERT structure.\\n    \"\n    state_dict = load_checkpoint(checkpoint_path)\n    if config is not None:\n        config = OPTConfig.from_pretrained(config)\n    else:\n        config = OPTConfig()\n    model = OPTModel(config).half().eval()\n    model.load_state_dict(state_dict)\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)",
            "@torch.no_grad()\ndef convert_opt_checkpoint(checkpoint_path, pytorch_dump_folder_path, config=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Copy/paste/tweak model's weights to our BERT structure.\\n    \"\n    state_dict = load_checkpoint(checkpoint_path)\n    if config is not None:\n        config = OPTConfig.from_pretrained(config)\n    else:\n        config = OPTConfig()\n    model = OPTModel(config).half().eval()\n    model.load_state_dict(state_dict)\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)",
            "@torch.no_grad()\ndef convert_opt_checkpoint(checkpoint_path, pytorch_dump_folder_path, config=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Copy/paste/tweak model's weights to our BERT structure.\\n    \"\n    state_dict = load_checkpoint(checkpoint_path)\n    if config is not None:\n        config = OPTConfig.from_pretrained(config)\n    else:\n        config = OPTConfig()\n    model = OPTModel(config).half().eval()\n    model.load_state_dict(state_dict)\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)",
            "@torch.no_grad()\ndef convert_opt_checkpoint(checkpoint_path, pytorch_dump_folder_path, config=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Copy/paste/tweak model's weights to our BERT structure.\\n    \"\n    state_dict = load_checkpoint(checkpoint_path)\n    if config is not None:\n        config = OPTConfig.from_pretrained(config)\n    else:\n        config = OPTConfig()\n    model = OPTModel(config).half().eval()\n    model.load_state_dict(state_dict)\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)",
            "@torch.no_grad()\ndef convert_opt_checkpoint(checkpoint_path, pytorch_dump_folder_path, config=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Copy/paste/tweak model's weights to our BERT structure.\\n    \"\n    state_dict = load_checkpoint(checkpoint_path)\n    if config is not None:\n        config = OPTConfig.from_pretrained(config)\n    else:\n        config = OPTConfig()\n    model = OPTModel(config).half().eval()\n    model.load_state_dict(state_dict)\n    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)\n    model.save_pretrained(pytorch_dump_folder_path)"
        ]
    }
]