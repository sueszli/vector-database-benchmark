[
    {
        "func_name": "as_json_table_type",
        "original": "def as_json_table_type(x: DtypeObj) -> str:\n    \"\"\"\n    Convert a NumPy / pandas type to its corresponding json_table.\n\n    Parameters\n    ----------\n    x : np.dtype or ExtensionDtype\n\n    Returns\n    -------\n    str\n        the Table Schema data types\n\n    Notes\n    -----\n    This table shows the relationship between NumPy / pandas dtypes,\n    and Table Schema dtypes.\n\n    ==============  =================\n    Pandas type     Table Schema type\n    ==============  =================\n    int64           integer\n    float64         number\n    bool            boolean\n    datetime64[ns]  datetime\n    timedelta64[ns] duration\n    object          str\n    categorical     any\n    =============== =================\n    \"\"\"\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype, PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'",
        "mutated": [
            "def as_json_table_type(x: DtypeObj) -> str:\n    if False:\n        i = 10\n    '\\n    Convert a NumPy / pandas type to its corresponding json_table.\\n\\n    Parameters\\n    ----------\\n    x : np.dtype or ExtensionDtype\\n\\n    Returns\\n    -------\\n    str\\n        the Table Schema data types\\n\\n    Notes\\n    -----\\n    This table shows the relationship between NumPy / pandas dtypes,\\n    and Table Schema dtypes.\\n\\n    ==============  =================\\n    Pandas type     Table Schema type\\n    ==============  =================\\n    int64           integer\\n    float64         number\\n    bool            boolean\\n    datetime64[ns]  datetime\\n    timedelta64[ns] duration\\n    object          str\\n    categorical     any\\n    =============== =================\\n    '\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype, PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'",
            "def as_json_table_type(x: DtypeObj) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Convert a NumPy / pandas type to its corresponding json_table.\\n\\n    Parameters\\n    ----------\\n    x : np.dtype or ExtensionDtype\\n\\n    Returns\\n    -------\\n    str\\n        the Table Schema data types\\n\\n    Notes\\n    -----\\n    This table shows the relationship between NumPy / pandas dtypes,\\n    and Table Schema dtypes.\\n\\n    ==============  =================\\n    Pandas type     Table Schema type\\n    ==============  =================\\n    int64           integer\\n    float64         number\\n    bool            boolean\\n    datetime64[ns]  datetime\\n    timedelta64[ns] duration\\n    object          str\\n    categorical     any\\n    =============== =================\\n    '\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype, PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'",
            "def as_json_table_type(x: DtypeObj) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Convert a NumPy / pandas type to its corresponding json_table.\\n\\n    Parameters\\n    ----------\\n    x : np.dtype or ExtensionDtype\\n\\n    Returns\\n    -------\\n    str\\n        the Table Schema data types\\n\\n    Notes\\n    -----\\n    This table shows the relationship between NumPy / pandas dtypes,\\n    and Table Schema dtypes.\\n\\n    ==============  =================\\n    Pandas type     Table Schema type\\n    ==============  =================\\n    int64           integer\\n    float64         number\\n    bool            boolean\\n    datetime64[ns]  datetime\\n    timedelta64[ns] duration\\n    object          str\\n    categorical     any\\n    =============== =================\\n    '\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype, PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'",
            "def as_json_table_type(x: DtypeObj) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Convert a NumPy / pandas type to its corresponding json_table.\\n\\n    Parameters\\n    ----------\\n    x : np.dtype or ExtensionDtype\\n\\n    Returns\\n    -------\\n    str\\n        the Table Schema data types\\n\\n    Notes\\n    -----\\n    This table shows the relationship between NumPy / pandas dtypes,\\n    and Table Schema dtypes.\\n\\n    ==============  =================\\n    Pandas type     Table Schema type\\n    ==============  =================\\n    int64           integer\\n    float64         number\\n    bool            boolean\\n    datetime64[ns]  datetime\\n    timedelta64[ns] duration\\n    object          str\\n    categorical     any\\n    =============== =================\\n    '\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype, PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'",
            "def as_json_table_type(x: DtypeObj) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Convert a NumPy / pandas type to its corresponding json_table.\\n\\n    Parameters\\n    ----------\\n    x : np.dtype or ExtensionDtype\\n\\n    Returns\\n    -------\\n    str\\n        the Table Schema data types\\n\\n    Notes\\n    -----\\n    This table shows the relationship between NumPy / pandas dtypes,\\n    and Table Schema dtypes.\\n\\n    ==============  =================\\n    Pandas type     Table Schema type\\n    ==============  =================\\n    int64           integer\\n    float64         number\\n    bool            boolean\\n    datetime64[ns]  datetime\\n    timedelta64[ns] duration\\n    object          str\\n    categorical     any\\n    =============== =================\\n    '\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype, PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'"
        ]
    },
    {
        "func_name": "set_default_names",
        "original": "def set_default_names(data):\n    \"\"\"Sets index names to 'index' for regular, or 'level_x' for Multi\"\"\"\n    if com.all_not_none(*data.index.names):\n        nms = data.index.names\n        if len(nms) == 1 and data.index.name == 'index':\n            warnings.warn(\"Index name of 'index' is not round-trippable.\", stacklevel=find_stack_level())\n        elif len(nms) > 1 and any((x.startswith('level_') for x in nms)):\n            warnings.warn(\"Index names beginning with 'level_' are not round-trippable.\", stacklevel=find_stack_level())\n        return data\n    data = data.copy()\n    if data.index.nlevels > 1:\n        data.index.names = com.fill_missing_names(data.index.names)\n    else:\n        data.index.name = data.index.name or 'index'\n    return data",
        "mutated": [
            "def set_default_names(data):\n    if False:\n        i = 10\n    \"Sets index names to 'index' for regular, or 'level_x' for Multi\"\n    if com.all_not_none(*data.index.names):\n        nms = data.index.names\n        if len(nms) == 1 and data.index.name == 'index':\n            warnings.warn(\"Index name of 'index' is not round-trippable.\", stacklevel=find_stack_level())\n        elif len(nms) > 1 and any((x.startswith('level_') for x in nms)):\n            warnings.warn(\"Index names beginning with 'level_' are not round-trippable.\", stacklevel=find_stack_level())\n        return data\n    data = data.copy()\n    if data.index.nlevels > 1:\n        data.index.names = com.fill_missing_names(data.index.names)\n    else:\n        data.index.name = data.index.name or 'index'\n    return data",
            "def set_default_names(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Sets index names to 'index' for regular, or 'level_x' for Multi\"\n    if com.all_not_none(*data.index.names):\n        nms = data.index.names\n        if len(nms) == 1 and data.index.name == 'index':\n            warnings.warn(\"Index name of 'index' is not round-trippable.\", stacklevel=find_stack_level())\n        elif len(nms) > 1 and any((x.startswith('level_') for x in nms)):\n            warnings.warn(\"Index names beginning with 'level_' are not round-trippable.\", stacklevel=find_stack_level())\n        return data\n    data = data.copy()\n    if data.index.nlevels > 1:\n        data.index.names = com.fill_missing_names(data.index.names)\n    else:\n        data.index.name = data.index.name or 'index'\n    return data",
            "def set_default_names(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Sets index names to 'index' for regular, or 'level_x' for Multi\"\n    if com.all_not_none(*data.index.names):\n        nms = data.index.names\n        if len(nms) == 1 and data.index.name == 'index':\n            warnings.warn(\"Index name of 'index' is not round-trippable.\", stacklevel=find_stack_level())\n        elif len(nms) > 1 and any((x.startswith('level_') for x in nms)):\n            warnings.warn(\"Index names beginning with 'level_' are not round-trippable.\", stacklevel=find_stack_level())\n        return data\n    data = data.copy()\n    if data.index.nlevels > 1:\n        data.index.names = com.fill_missing_names(data.index.names)\n    else:\n        data.index.name = data.index.name or 'index'\n    return data",
            "def set_default_names(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Sets index names to 'index' for regular, or 'level_x' for Multi\"\n    if com.all_not_none(*data.index.names):\n        nms = data.index.names\n        if len(nms) == 1 and data.index.name == 'index':\n            warnings.warn(\"Index name of 'index' is not round-trippable.\", stacklevel=find_stack_level())\n        elif len(nms) > 1 and any((x.startswith('level_') for x in nms)):\n            warnings.warn(\"Index names beginning with 'level_' are not round-trippable.\", stacklevel=find_stack_level())\n        return data\n    data = data.copy()\n    if data.index.nlevels > 1:\n        data.index.names = com.fill_missing_names(data.index.names)\n    else:\n        data.index.name = data.index.name or 'index'\n    return data",
            "def set_default_names(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Sets index names to 'index' for regular, or 'level_x' for Multi\"\n    if com.all_not_none(*data.index.names):\n        nms = data.index.names\n        if len(nms) == 1 and data.index.name == 'index':\n            warnings.warn(\"Index name of 'index' is not round-trippable.\", stacklevel=find_stack_level())\n        elif len(nms) > 1 and any((x.startswith('level_') for x in nms)):\n            warnings.warn(\"Index names beginning with 'level_' are not round-trippable.\", stacklevel=find_stack_level())\n        return data\n    data = data.copy()\n    if data.index.nlevels > 1:\n        data.index.names = com.fill_missing_names(data.index.names)\n    else:\n        data.index.name = data.index.name or 'index'\n    return data"
        ]
    },
    {
        "func_name": "convert_pandas_type_to_json_field",
        "original": "def convert_pandas_type_to_json_field(arr) -> dict[str, JSONSerializable]:\n    dtype = arr.dtype\n    name: JSONSerializable\n    if arr.name is None:\n        name = 'values'\n    else:\n        name = arr.name\n    field: dict[str, JSONSerializable] = {'name': name, 'type': as_json_table_type(dtype)}\n    if isinstance(dtype, CategoricalDtype):\n        cats = dtype.categories\n        ordered = dtype.ordered\n        field['constraints'] = {'enum': list(cats)}\n        field['ordered'] = ordered\n    elif isinstance(dtype, PeriodDtype):\n        field['freq'] = dtype.freq.freqstr\n    elif isinstance(dtype, DatetimeTZDtype):\n        if timezones.is_utc(dtype.tz):\n            field['tz'] = 'UTC'\n        else:\n            field['tz'] = dtype.tz.zone\n    elif isinstance(dtype, ExtensionDtype):\n        field['extDtype'] = dtype.name\n    return field",
        "mutated": [
            "def convert_pandas_type_to_json_field(arr) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n    dtype = arr.dtype\n    name: JSONSerializable\n    if arr.name is None:\n        name = 'values'\n    else:\n        name = arr.name\n    field: dict[str, JSONSerializable] = {'name': name, 'type': as_json_table_type(dtype)}\n    if isinstance(dtype, CategoricalDtype):\n        cats = dtype.categories\n        ordered = dtype.ordered\n        field['constraints'] = {'enum': list(cats)}\n        field['ordered'] = ordered\n    elif isinstance(dtype, PeriodDtype):\n        field['freq'] = dtype.freq.freqstr\n    elif isinstance(dtype, DatetimeTZDtype):\n        if timezones.is_utc(dtype.tz):\n            field['tz'] = 'UTC'\n        else:\n            field['tz'] = dtype.tz.zone\n    elif isinstance(dtype, ExtensionDtype):\n        field['extDtype'] = dtype.name\n    return field",
            "def convert_pandas_type_to_json_field(arr) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dtype = arr.dtype\n    name: JSONSerializable\n    if arr.name is None:\n        name = 'values'\n    else:\n        name = arr.name\n    field: dict[str, JSONSerializable] = {'name': name, 'type': as_json_table_type(dtype)}\n    if isinstance(dtype, CategoricalDtype):\n        cats = dtype.categories\n        ordered = dtype.ordered\n        field['constraints'] = {'enum': list(cats)}\n        field['ordered'] = ordered\n    elif isinstance(dtype, PeriodDtype):\n        field['freq'] = dtype.freq.freqstr\n    elif isinstance(dtype, DatetimeTZDtype):\n        if timezones.is_utc(dtype.tz):\n            field['tz'] = 'UTC'\n        else:\n            field['tz'] = dtype.tz.zone\n    elif isinstance(dtype, ExtensionDtype):\n        field['extDtype'] = dtype.name\n    return field",
            "def convert_pandas_type_to_json_field(arr) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dtype = arr.dtype\n    name: JSONSerializable\n    if arr.name is None:\n        name = 'values'\n    else:\n        name = arr.name\n    field: dict[str, JSONSerializable] = {'name': name, 'type': as_json_table_type(dtype)}\n    if isinstance(dtype, CategoricalDtype):\n        cats = dtype.categories\n        ordered = dtype.ordered\n        field['constraints'] = {'enum': list(cats)}\n        field['ordered'] = ordered\n    elif isinstance(dtype, PeriodDtype):\n        field['freq'] = dtype.freq.freqstr\n    elif isinstance(dtype, DatetimeTZDtype):\n        if timezones.is_utc(dtype.tz):\n            field['tz'] = 'UTC'\n        else:\n            field['tz'] = dtype.tz.zone\n    elif isinstance(dtype, ExtensionDtype):\n        field['extDtype'] = dtype.name\n    return field",
            "def convert_pandas_type_to_json_field(arr) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dtype = arr.dtype\n    name: JSONSerializable\n    if arr.name is None:\n        name = 'values'\n    else:\n        name = arr.name\n    field: dict[str, JSONSerializable] = {'name': name, 'type': as_json_table_type(dtype)}\n    if isinstance(dtype, CategoricalDtype):\n        cats = dtype.categories\n        ordered = dtype.ordered\n        field['constraints'] = {'enum': list(cats)}\n        field['ordered'] = ordered\n    elif isinstance(dtype, PeriodDtype):\n        field['freq'] = dtype.freq.freqstr\n    elif isinstance(dtype, DatetimeTZDtype):\n        if timezones.is_utc(dtype.tz):\n            field['tz'] = 'UTC'\n        else:\n            field['tz'] = dtype.tz.zone\n    elif isinstance(dtype, ExtensionDtype):\n        field['extDtype'] = dtype.name\n    return field",
            "def convert_pandas_type_to_json_field(arr) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dtype = arr.dtype\n    name: JSONSerializable\n    if arr.name is None:\n        name = 'values'\n    else:\n        name = arr.name\n    field: dict[str, JSONSerializable] = {'name': name, 'type': as_json_table_type(dtype)}\n    if isinstance(dtype, CategoricalDtype):\n        cats = dtype.categories\n        ordered = dtype.ordered\n        field['constraints'] = {'enum': list(cats)}\n        field['ordered'] = ordered\n    elif isinstance(dtype, PeriodDtype):\n        field['freq'] = dtype.freq.freqstr\n    elif isinstance(dtype, DatetimeTZDtype):\n        if timezones.is_utc(dtype.tz):\n            field['tz'] = 'UTC'\n        else:\n            field['tz'] = dtype.tz.zone\n    elif isinstance(dtype, ExtensionDtype):\n        field['extDtype'] = dtype.name\n    return field"
        ]
    },
    {
        "func_name": "convert_json_field_to_pandas_type",
        "original": "def convert_json_field_to_pandas_type(field) -> str | CategoricalDtype:\n    \"\"\"\n    Converts a JSON field descriptor into its corresponding NumPy / pandas type\n\n    Parameters\n    ----------\n    field\n        A JSON field descriptor\n\n    Returns\n    -------\n    dtype\n\n    Raises\n    ------\n    ValueError\n        If the type of the provided field is unknown or currently unsupported\n\n    Examples\n    --------\n    >>> convert_json_field_to_pandas_type({\"name\": \"an_int\", \"type\": \"integer\"})\n    'int64'\n\n    >>> convert_json_field_to_pandas_type(\n    ...     {\n    ...         \"name\": \"a_categorical\",\n    ...         \"type\": \"any\",\n    ...         \"constraints\": {\"enum\": [\"a\", \"b\", \"c\"]},\n    ...         \"ordered\": True,\n    ...     }\n    ... )\n    CategoricalDtype(categories=['a', 'b', 'c'], ordered=True, categories_dtype=object)\n\n    >>> convert_json_field_to_pandas_type({\"name\": \"a_datetime\", \"type\": \"datetime\"})\n    'datetime64[ns]'\n\n    >>> convert_json_field_to_pandas_type(\n    ...     {\"name\": \"a_datetime_with_tz\", \"type\": \"datetime\", \"tz\": \"US/Central\"}\n    ... )\n    'datetime64[ns, US/Central]'\n    \"\"\"\n    typ = field['type']\n    if typ == 'string':\n        return 'object'\n    elif typ == 'integer':\n        return field.get('extDtype', 'int64')\n    elif typ == 'number':\n        return field.get('extDtype', 'float64')\n    elif typ == 'boolean':\n        return field.get('extDtype', 'bool')\n    elif typ == 'duration':\n        return 'timedelta64'\n    elif typ == 'datetime':\n        if field.get('tz'):\n            return f\"datetime64[ns, {field['tz']}]\"\n        elif field.get('freq'):\n            offset = to_offset(field['freq'])\n            (freq_n, freq_name) = (offset.n, offset.name)\n            freq = freq_to_period_freqstr(freq_n, freq_name)\n            return f'period[{freq}]'\n        else:\n            return 'datetime64[ns]'\n    elif typ == 'any':\n        if 'constraints' in field and 'ordered' in field:\n            return CategoricalDtype(categories=field['constraints']['enum'], ordered=field['ordered'])\n        elif 'extDtype' in field:\n            return registry.find(field['extDtype'])\n        else:\n            return 'object'\n    raise ValueError(f'Unsupported or invalid field type: {typ}')",
        "mutated": [
            "def convert_json_field_to_pandas_type(field) -> str | CategoricalDtype:\n    if False:\n        i = 10\n    '\\n    Converts a JSON field descriptor into its corresponding NumPy / pandas type\\n\\n    Parameters\\n    ----------\\n    field\\n        A JSON field descriptor\\n\\n    Returns\\n    -------\\n    dtype\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the type of the provided field is unknown or currently unsupported\\n\\n    Examples\\n    --------\\n    >>> convert_json_field_to_pandas_type({\"name\": \"an_int\", \"type\": \"integer\"})\\n    \\'int64\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\\n    ...         \"name\": \"a_categorical\",\\n    ...         \"type\": \"any\",\\n    ...         \"constraints\": {\"enum\": [\"a\", \"b\", \"c\"]},\\n    ...         \"ordered\": True,\\n    ...     }\\n    ... )\\n    CategoricalDtype(categories=[\\'a\\', \\'b\\', \\'c\\'], ordered=True, categories_dtype=object)\\n\\n    >>> convert_json_field_to_pandas_type({\"name\": \"a_datetime\", \"type\": \"datetime\"})\\n    \\'datetime64[ns]\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\"name\": \"a_datetime_with_tz\", \"type\": \"datetime\", \"tz\": \"US/Central\"}\\n    ... )\\n    \\'datetime64[ns, US/Central]\\'\\n    '\n    typ = field['type']\n    if typ == 'string':\n        return 'object'\n    elif typ == 'integer':\n        return field.get('extDtype', 'int64')\n    elif typ == 'number':\n        return field.get('extDtype', 'float64')\n    elif typ == 'boolean':\n        return field.get('extDtype', 'bool')\n    elif typ == 'duration':\n        return 'timedelta64'\n    elif typ == 'datetime':\n        if field.get('tz'):\n            return f\"datetime64[ns, {field['tz']}]\"\n        elif field.get('freq'):\n            offset = to_offset(field['freq'])\n            (freq_n, freq_name) = (offset.n, offset.name)\n            freq = freq_to_period_freqstr(freq_n, freq_name)\n            return f'period[{freq}]'\n        else:\n            return 'datetime64[ns]'\n    elif typ == 'any':\n        if 'constraints' in field and 'ordered' in field:\n            return CategoricalDtype(categories=field['constraints']['enum'], ordered=field['ordered'])\n        elif 'extDtype' in field:\n            return registry.find(field['extDtype'])\n        else:\n            return 'object'\n    raise ValueError(f'Unsupported or invalid field type: {typ}')",
            "def convert_json_field_to_pandas_type(field) -> str | CategoricalDtype:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Converts a JSON field descriptor into its corresponding NumPy / pandas type\\n\\n    Parameters\\n    ----------\\n    field\\n        A JSON field descriptor\\n\\n    Returns\\n    -------\\n    dtype\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the type of the provided field is unknown or currently unsupported\\n\\n    Examples\\n    --------\\n    >>> convert_json_field_to_pandas_type({\"name\": \"an_int\", \"type\": \"integer\"})\\n    \\'int64\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\\n    ...         \"name\": \"a_categorical\",\\n    ...         \"type\": \"any\",\\n    ...         \"constraints\": {\"enum\": [\"a\", \"b\", \"c\"]},\\n    ...         \"ordered\": True,\\n    ...     }\\n    ... )\\n    CategoricalDtype(categories=[\\'a\\', \\'b\\', \\'c\\'], ordered=True, categories_dtype=object)\\n\\n    >>> convert_json_field_to_pandas_type({\"name\": \"a_datetime\", \"type\": \"datetime\"})\\n    \\'datetime64[ns]\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\"name\": \"a_datetime_with_tz\", \"type\": \"datetime\", \"tz\": \"US/Central\"}\\n    ... )\\n    \\'datetime64[ns, US/Central]\\'\\n    '\n    typ = field['type']\n    if typ == 'string':\n        return 'object'\n    elif typ == 'integer':\n        return field.get('extDtype', 'int64')\n    elif typ == 'number':\n        return field.get('extDtype', 'float64')\n    elif typ == 'boolean':\n        return field.get('extDtype', 'bool')\n    elif typ == 'duration':\n        return 'timedelta64'\n    elif typ == 'datetime':\n        if field.get('tz'):\n            return f\"datetime64[ns, {field['tz']}]\"\n        elif field.get('freq'):\n            offset = to_offset(field['freq'])\n            (freq_n, freq_name) = (offset.n, offset.name)\n            freq = freq_to_period_freqstr(freq_n, freq_name)\n            return f'period[{freq}]'\n        else:\n            return 'datetime64[ns]'\n    elif typ == 'any':\n        if 'constraints' in field and 'ordered' in field:\n            return CategoricalDtype(categories=field['constraints']['enum'], ordered=field['ordered'])\n        elif 'extDtype' in field:\n            return registry.find(field['extDtype'])\n        else:\n            return 'object'\n    raise ValueError(f'Unsupported or invalid field type: {typ}')",
            "def convert_json_field_to_pandas_type(field) -> str | CategoricalDtype:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Converts a JSON field descriptor into its corresponding NumPy / pandas type\\n\\n    Parameters\\n    ----------\\n    field\\n        A JSON field descriptor\\n\\n    Returns\\n    -------\\n    dtype\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the type of the provided field is unknown or currently unsupported\\n\\n    Examples\\n    --------\\n    >>> convert_json_field_to_pandas_type({\"name\": \"an_int\", \"type\": \"integer\"})\\n    \\'int64\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\\n    ...         \"name\": \"a_categorical\",\\n    ...         \"type\": \"any\",\\n    ...         \"constraints\": {\"enum\": [\"a\", \"b\", \"c\"]},\\n    ...         \"ordered\": True,\\n    ...     }\\n    ... )\\n    CategoricalDtype(categories=[\\'a\\', \\'b\\', \\'c\\'], ordered=True, categories_dtype=object)\\n\\n    >>> convert_json_field_to_pandas_type({\"name\": \"a_datetime\", \"type\": \"datetime\"})\\n    \\'datetime64[ns]\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\"name\": \"a_datetime_with_tz\", \"type\": \"datetime\", \"tz\": \"US/Central\"}\\n    ... )\\n    \\'datetime64[ns, US/Central]\\'\\n    '\n    typ = field['type']\n    if typ == 'string':\n        return 'object'\n    elif typ == 'integer':\n        return field.get('extDtype', 'int64')\n    elif typ == 'number':\n        return field.get('extDtype', 'float64')\n    elif typ == 'boolean':\n        return field.get('extDtype', 'bool')\n    elif typ == 'duration':\n        return 'timedelta64'\n    elif typ == 'datetime':\n        if field.get('tz'):\n            return f\"datetime64[ns, {field['tz']}]\"\n        elif field.get('freq'):\n            offset = to_offset(field['freq'])\n            (freq_n, freq_name) = (offset.n, offset.name)\n            freq = freq_to_period_freqstr(freq_n, freq_name)\n            return f'period[{freq}]'\n        else:\n            return 'datetime64[ns]'\n    elif typ == 'any':\n        if 'constraints' in field and 'ordered' in field:\n            return CategoricalDtype(categories=field['constraints']['enum'], ordered=field['ordered'])\n        elif 'extDtype' in field:\n            return registry.find(field['extDtype'])\n        else:\n            return 'object'\n    raise ValueError(f'Unsupported or invalid field type: {typ}')",
            "def convert_json_field_to_pandas_type(field) -> str | CategoricalDtype:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Converts a JSON field descriptor into its corresponding NumPy / pandas type\\n\\n    Parameters\\n    ----------\\n    field\\n        A JSON field descriptor\\n\\n    Returns\\n    -------\\n    dtype\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the type of the provided field is unknown or currently unsupported\\n\\n    Examples\\n    --------\\n    >>> convert_json_field_to_pandas_type({\"name\": \"an_int\", \"type\": \"integer\"})\\n    \\'int64\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\\n    ...         \"name\": \"a_categorical\",\\n    ...         \"type\": \"any\",\\n    ...         \"constraints\": {\"enum\": [\"a\", \"b\", \"c\"]},\\n    ...         \"ordered\": True,\\n    ...     }\\n    ... )\\n    CategoricalDtype(categories=[\\'a\\', \\'b\\', \\'c\\'], ordered=True, categories_dtype=object)\\n\\n    >>> convert_json_field_to_pandas_type({\"name\": \"a_datetime\", \"type\": \"datetime\"})\\n    \\'datetime64[ns]\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\"name\": \"a_datetime_with_tz\", \"type\": \"datetime\", \"tz\": \"US/Central\"}\\n    ... )\\n    \\'datetime64[ns, US/Central]\\'\\n    '\n    typ = field['type']\n    if typ == 'string':\n        return 'object'\n    elif typ == 'integer':\n        return field.get('extDtype', 'int64')\n    elif typ == 'number':\n        return field.get('extDtype', 'float64')\n    elif typ == 'boolean':\n        return field.get('extDtype', 'bool')\n    elif typ == 'duration':\n        return 'timedelta64'\n    elif typ == 'datetime':\n        if field.get('tz'):\n            return f\"datetime64[ns, {field['tz']}]\"\n        elif field.get('freq'):\n            offset = to_offset(field['freq'])\n            (freq_n, freq_name) = (offset.n, offset.name)\n            freq = freq_to_period_freqstr(freq_n, freq_name)\n            return f'period[{freq}]'\n        else:\n            return 'datetime64[ns]'\n    elif typ == 'any':\n        if 'constraints' in field and 'ordered' in field:\n            return CategoricalDtype(categories=field['constraints']['enum'], ordered=field['ordered'])\n        elif 'extDtype' in field:\n            return registry.find(field['extDtype'])\n        else:\n            return 'object'\n    raise ValueError(f'Unsupported or invalid field type: {typ}')",
            "def convert_json_field_to_pandas_type(field) -> str | CategoricalDtype:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Converts a JSON field descriptor into its corresponding NumPy / pandas type\\n\\n    Parameters\\n    ----------\\n    field\\n        A JSON field descriptor\\n\\n    Returns\\n    -------\\n    dtype\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the type of the provided field is unknown or currently unsupported\\n\\n    Examples\\n    --------\\n    >>> convert_json_field_to_pandas_type({\"name\": \"an_int\", \"type\": \"integer\"})\\n    \\'int64\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\\n    ...         \"name\": \"a_categorical\",\\n    ...         \"type\": \"any\",\\n    ...         \"constraints\": {\"enum\": [\"a\", \"b\", \"c\"]},\\n    ...         \"ordered\": True,\\n    ...     }\\n    ... )\\n    CategoricalDtype(categories=[\\'a\\', \\'b\\', \\'c\\'], ordered=True, categories_dtype=object)\\n\\n    >>> convert_json_field_to_pandas_type({\"name\": \"a_datetime\", \"type\": \"datetime\"})\\n    \\'datetime64[ns]\\'\\n\\n    >>> convert_json_field_to_pandas_type(\\n    ...     {\"name\": \"a_datetime_with_tz\", \"type\": \"datetime\", \"tz\": \"US/Central\"}\\n    ... )\\n    \\'datetime64[ns, US/Central]\\'\\n    '\n    typ = field['type']\n    if typ == 'string':\n        return 'object'\n    elif typ == 'integer':\n        return field.get('extDtype', 'int64')\n    elif typ == 'number':\n        return field.get('extDtype', 'float64')\n    elif typ == 'boolean':\n        return field.get('extDtype', 'bool')\n    elif typ == 'duration':\n        return 'timedelta64'\n    elif typ == 'datetime':\n        if field.get('tz'):\n            return f\"datetime64[ns, {field['tz']}]\"\n        elif field.get('freq'):\n            offset = to_offset(field['freq'])\n            (freq_n, freq_name) = (offset.n, offset.name)\n            freq = freq_to_period_freqstr(freq_n, freq_name)\n            return f'period[{freq}]'\n        else:\n            return 'datetime64[ns]'\n    elif typ == 'any':\n        if 'constraints' in field and 'ordered' in field:\n            return CategoricalDtype(categories=field['constraints']['enum'], ordered=field['ordered'])\n        elif 'extDtype' in field:\n            return registry.find(field['extDtype'])\n        else:\n            return 'object'\n    raise ValueError(f'Unsupported or invalid field type: {typ}')"
        ]
    },
    {
        "func_name": "build_table_schema",
        "original": "def build_table_schema(data: DataFrame | Series, index: bool=True, primary_key: bool | None=None, version: bool=True) -> dict[str, JSONSerializable]:\n    \"\"\"\n    Create a Table schema from ``data``.\n\n    Parameters\n    ----------\n    data : Series, DataFrame\n    index : bool, default True\n        Whether to include ``data.index`` in the schema.\n    primary_key : bool or None, default True\n        Column names to designate as the primary key.\n        The default `None` will set `'primaryKey'` to the index\n        level or levels if the index is unique.\n    version : bool, default True\n        Whether to include a field `pandas_version` with the version\n        of pandas that last revised the table schema. This version\n        can be different from the installed pandas version.\n\n    Returns\n    -------\n    dict\n\n    Notes\n    -----\n    See `Table Schema\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\n    conversion types.\n    Timedeltas as converted to ISO8601 duration format with\n    9 decimal places after the seconds field for nanosecond precision.\n\n    Categoricals are converted to the `any` dtype, and use the `enum` field\n    constraint to list the allowed values. The `ordered` attribute is included\n    in an `ordered` field.\n\n    Examples\n    --------\n    >>> from pandas.io.json._table_schema import build_table_schema\n    >>> df = pd.DataFrame(\n    ...     {'A': [1, 2, 3],\n    ...      'B': ['a', 'b', 'c'],\n    ...      'C': pd.date_range('2016-01-01', freq='d', periods=3),\n    ...     }, index=pd.Index(range(3), name='idx'))\n    >>> build_table_schema(df)\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\n    \"\"\"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for (level, name) in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for (column, s) in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and (primary_key is None):\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema",
        "mutated": [
            "def build_table_schema(data: DataFrame | Series, index: bool=True, primary_key: bool | None=None, version: bool=True) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n    \"\\n    Create a Table schema from ``data``.\\n\\n    Parameters\\n    ----------\\n    data : Series, DataFrame\\n    index : bool, default True\\n        Whether to include ``data.index`` in the schema.\\n    primary_key : bool or None, default True\\n        Column names to designate as the primary key.\\n        The default `None` will set `'primaryKey'` to the index\\n        level or levels if the index is unique.\\n    version : bool, default True\\n        Whether to include a field `pandas_version` with the version\\n        of pandas that last revised the table schema. This version\\n        can be different from the installed pandas version.\\n\\n    Returns\\n    -------\\n    dict\\n\\n    Notes\\n    -----\\n    See `Table Schema\\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\\n    conversion types.\\n    Timedeltas as converted to ISO8601 duration format with\\n    9 decimal places after the seconds field for nanosecond precision.\\n\\n    Categoricals are converted to the `any` dtype, and use the `enum` field\\n    constraint to list the allowed values. The `ordered` attribute is included\\n    in an `ordered` field.\\n\\n    Examples\\n    --------\\n    >>> from pandas.io.json._table_schema import build_table_schema\\n    >>> df = pd.DataFrame(\\n    ...     {'A': [1, 2, 3],\\n    ...      'B': ['a', 'b', 'c'],\\n    ...      'C': pd.date_range('2016-01-01', freq='d', periods=3),\\n    ...     }, index=pd.Index(range(3), name='idx'))\\n    >>> build_table_schema(df)\\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\\n    \"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for (level, name) in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for (column, s) in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and (primary_key is None):\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema",
            "def build_table_schema(data: DataFrame | Series, index: bool=True, primary_key: bool | None=None, version: bool=True) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Create a Table schema from ``data``.\\n\\n    Parameters\\n    ----------\\n    data : Series, DataFrame\\n    index : bool, default True\\n        Whether to include ``data.index`` in the schema.\\n    primary_key : bool or None, default True\\n        Column names to designate as the primary key.\\n        The default `None` will set `'primaryKey'` to the index\\n        level or levels if the index is unique.\\n    version : bool, default True\\n        Whether to include a field `pandas_version` with the version\\n        of pandas that last revised the table schema. This version\\n        can be different from the installed pandas version.\\n\\n    Returns\\n    -------\\n    dict\\n\\n    Notes\\n    -----\\n    See `Table Schema\\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\\n    conversion types.\\n    Timedeltas as converted to ISO8601 duration format with\\n    9 decimal places after the seconds field for nanosecond precision.\\n\\n    Categoricals are converted to the `any` dtype, and use the `enum` field\\n    constraint to list the allowed values. The `ordered` attribute is included\\n    in an `ordered` field.\\n\\n    Examples\\n    --------\\n    >>> from pandas.io.json._table_schema import build_table_schema\\n    >>> df = pd.DataFrame(\\n    ...     {'A': [1, 2, 3],\\n    ...      'B': ['a', 'b', 'c'],\\n    ...      'C': pd.date_range('2016-01-01', freq='d', periods=3),\\n    ...     }, index=pd.Index(range(3), name='idx'))\\n    >>> build_table_schema(df)\\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\\n    \"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for (level, name) in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for (column, s) in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and (primary_key is None):\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema",
            "def build_table_schema(data: DataFrame | Series, index: bool=True, primary_key: bool | None=None, version: bool=True) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Create a Table schema from ``data``.\\n\\n    Parameters\\n    ----------\\n    data : Series, DataFrame\\n    index : bool, default True\\n        Whether to include ``data.index`` in the schema.\\n    primary_key : bool or None, default True\\n        Column names to designate as the primary key.\\n        The default `None` will set `'primaryKey'` to the index\\n        level or levels if the index is unique.\\n    version : bool, default True\\n        Whether to include a field `pandas_version` with the version\\n        of pandas that last revised the table schema. This version\\n        can be different from the installed pandas version.\\n\\n    Returns\\n    -------\\n    dict\\n\\n    Notes\\n    -----\\n    See `Table Schema\\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\\n    conversion types.\\n    Timedeltas as converted to ISO8601 duration format with\\n    9 decimal places after the seconds field for nanosecond precision.\\n\\n    Categoricals are converted to the `any` dtype, and use the `enum` field\\n    constraint to list the allowed values. The `ordered` attribute is included\\n    in an `ordered` field.\\n\\n    Examples\\n    --------\\n    >>> from pandas.io.json._table_schema import build_table_schema\\n    >>> df = pd.DataFrame(\\n    ...     {'A': [1, 2, 3],\\n    ...      'B': ['a', 'b', 'c'],\\n    ...      'C': pd.date_range('2016-01-01', freq='d', periods=3),\\n    ...     }, index=pd.Index(range(3), name='idx'))\\n    >>> build_table_schema(df)\\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\\n    \"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for (level, name) in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for (column, s) in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and (primary_key is None):\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema",
            "def build_table_schema(data: DataFrame | Series, index: bool=True, primary_key: bool | None=None, version: bool=True) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Create a Table schema from ``data``.\\n\\n    Parameters\\n    ----------\\n    data : Series, DataFrame\\n    index : bool, default True\\n        Whether to include ``data.index`` in the schema.\\n    primary_key : bool or None, default True\\n        Column names to designate as the primary key.\\n        The default `None` will set `'primaryKey'` to the index\\n        level or levels if the index is unique.\\n    version : bool, default True\\n        Whether to include a field `pandas_version` with the version\\n        of pandas that last revised the table schema. This version\\n        can be different from the installed pandas version.\\n\\n    Returns\\n    -------\\n    dict\\n\\n    Notes\\n    -----\\n    See `Table Schema\\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\\n    conversion types.\\n    Timedeltas as converted to ISO8601 duration format with\\n    9 decimal places after the seconds field for nanosecond precision.\\n\\n    Categoricals are converted to the `any` dtype, and use the `enum` field\\n    constraint to list the allowed values. The `ordered` attribute is included\\n    in an `ordered` field.\\n\\n    Examples\\n    --------\\n    >>> from pandas.io.json._table_schema import build_table_schema\\n    >>> df = pd.DataFrame(\\n    ...     {'A': [1, 2, 3],\\n    ...      'B': ['a', 'b', 'c'],\\n    ...      'C': pd.date_range('2016-01-01', freq='d', periods=3),\\n    ...     }, index=pd.Index(range(3), name='idx'))\\n    >>> build_table_schema(df)\\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\\n    \"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for (level, name) in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for (column, s) in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and (primary_key is None):\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema",
            "def build_table_schema(data: DataFrame | Series, index: bool=True, primary_key: bool | None=None, version: bool=True) -> dict[str, JSONSerializable]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Create a Table schema from ``data``.\\n\\n    Parameters\\n    ----------\\n    data : Series, DataFrame\\n    index : bool, default True\\n        Whether to include ``data.index`` in the schema.\\n    primary_key : bool or None, default True\\n        Column names to designate as the primary key.\\n        The default `None` will set `'primaryKey'` to the index\\n        level or levels if the index is unique.\\n    version : bool, default True\\n        Whether to include a field `pandas_version` with the version\\n        of pandas that last revised the table schema. This version\\n        can be different from the installed pandas version.\\n\\n    Returns\\n    -------\\n    dict\\n\\n    Notes\\n    -----\\n    See `Table Schema\\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\\n    conversion types.\\n    Timedeltas as converted to ISO8601 duration format with\\n    9 decimal places after the seconds field for nanosecond precision.\\n\\n    Categoricals are converted to the `any` dtype, and use the `enum` field\\n    constraint to list the allowed values. The `ordered` attribute is included\\n    in an `ordered` field.\\n\\n    Examples\\n    --------\\n    >>> from pandas.io.json._table_schema import build_table_schema\\n    >>> df = pd.DataFrame(\\n    ...     {'A': [1, 2, 3],\\n    ...      'B': ['a', 'b', 'c'],\\n    ...      'C': pd.date_range('2016-01-01', freq='d', periods=3),\\n    ...     }, index=pd.Index(range(3), name='idx'))\\n    >>> build_table_schema(df)\\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\\n    \"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for (level, name) in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for (column, s) in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and (primary_key is None):\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema"
        ]
    },
    {
        "func_name": "parse_table_schema",
        "original": "def parse_table_schema(json, precise_float: bool) -> DataFrame:\n    \"\"\"\n    Builds a DataFrame from a given schema\n\n    Parameters\n    ----------\n    json :\n        A JSON table schema\n    precise_float : bool\n        Flag controlling precision when decoding string to double values, as\n        dictated by ``read_json``\n\n    Returns\n    -------\n    df : DataFrame\n\n    Raises\n    ------\n    NotImplementedError\n        If the JSON table schema contains either timezone or timedelta data\n\n    Notes\n    -----\n        Because :func:`DataFrame.to_json` uses the string 'index' to denote a\n        name-less :class:`Index`, this function sets the name of the returned\n        :class:`DataFrame` to ``None`` when said string is encountered with a\n        normal :class:`Index`. For a :class:`MultiIndex`, the same limitation\n        applies to any strings beginning with 'level_'. Therefore, an\n        :class:`Index` name of 'index'  and :class:`MultiIndex` names starting\n        with 'level_' are not supported.\n\n    See Also\n    --------\n    build_table_schema : Inverse function.\n    pandas.read_json\n    \"\"\"\n    table = ujson_loads(json, precise_float=precise_float)\n    col_order = [field['name'] for field in table['schema']['fields']]\n    df = DataFrame(table['data'], columns=col_order)[col_order]\n    dtypes = {field['name']: convert_json_field_to_pandas_type(field) for field in table['schema']['fields']}\n    if 'timedelta64' in dtypes.values():\n        raise NotImplementedError('table=\"orient\" can not yet read ISO-formatted Timedelta data')\n    df = df.astype(dtypes)\n    if 'primaryKey' in table['schema']:\n        df = df.set_index(table['schema']['primaryKey'])\n        if len(df.index.names) == 1:\n            if df.index.name == 'index':\n                df.index.name = None\n        else:\n            df.index.names = [None if x.startswith('level_') else x for x in df.index.names]\n    return df",
        "mutated": [
            "def parse_table_schema(json, precise_float: bool) -> DataFrame:\n    if False:\n        i = 10\n    \"\\n    Builds a DataFrame from a given schema\\n\\n    Parameters\\n    ----------\\n    json :\\n        A JSON table schema\\n    precise_float : bool\\n        Flag controlling precision when decoding string to double values, as\\n        dictated by ``read_json``\\n\\n    Returns\\n    -------\\n    df : DataFrame\\n\\n    Raises\\n    ------\\n    NotImplementedError\\n        If the JSON table schema contains either timezone or timedelta data\\n\\n    Notes\\n    -----\\n        Because :func:`DataFrame.to_json` uses the string 'index' to denote a\\n        name-less :class:`Index`, this function sets the name of the returned\\n        :class:`DataFrame` to ``None`` when said string is encountered with a\\n        normal :class:`Index`. For a :class:`MultiIndex`, the same limitation\\n        applies to any strings beginning with 'level_'. Therefore, an\\n        :class:`Index` name of 'index'  and :class:`MultiIndex` names starting\\n        with 'level_' are not supported.\\n\\n    See Also\\n    --------\\n    build_table_schema : Inverse function.\\n    pandas.read_json\\n    \"\n    table = ujson_loads(json, precise_float=precise_float)\n    col_order = [field['name'] for field in table['schema']['fields']]\n    df = DataFrame(table['data'], columns=col_order)[col_order]\n    dtypes = {field['name']: convert_json_field_to_pandas_type(field) for field in table['schema']['fields']}\n    if 'timedelta64' in dtypes.values():\n        raise NotImplementedError('table=\"orient\" can not yet read ISO-formatted Timedelta data')\n    df = df.astype(dtypes)\n    if 'primaryKey' in table['schema']:\n        df = df.set_index(table['schema']['primaryKey'])\n        if len(df.index.names) == 1:\n            if df.index.name == 'index':\n                df.index.name = None\n        else:\n            df.index.names = [None if x.startswith('level_') else x for x in df.index.names]\n    return df",
            "def parse_table_schema(json, precise_float: bool) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Builds a DataFrame from a given schema\\n\\n    Parameters\\n    ----------\\n    json :\\n        A JSON table schema\\n    precise_float : bool\\n        Flag controlling precision when decoding string to double values, as\\n        dictated by ``read_json``\\n\\n    Returns\\n    -------\\n    df : DataFrame\\n\\n    Raises\\n    ------\\n    NotImplementedError\\n        If the JSON table schema contains either timezone or timedelta data\\n\\n    Notes\\n    -----\\n        Because :func:`DataFrame.to_json` uses the string 'index' to denote a\\n        name-less :class:`Index`, this function sets the name of the returned\\n        :class:`DataFrame` to ``None`` when said string is encountered with a\\n        normal :class:`Index`. For a :class:`MultiIndex`, the same limitation\\n        applies to any strings beginning with 'level_'. Therefore, an\\n        :class:`Index` name of 'index'  and :class:`MultiIndex` names starting\\n        with 'level_' are not supported.\\n\\n    See Also\\n    --------\\n    build_table_schema : Inverse function.\\n    pandas.read_json\\n    \"\n    table = ujson_loads(json, precise_float=precise_float)\n    col_order = [field['name'] for field in table['schema']['fields']]\n    df = DataFrame(table['data'], columns=col_order)[col_order]\n    dtypes = {field['name']: convert_json_field_to_pandas_type(field) for field in table['schema']['fields']}\n    if 'timedelta64' in dtypes.values():\n        raise NotImplementedError('table=\"orient\" can not yet read ISO-formatted Timedelta data')\n    df = df.astype(dtypes)\n    if 'primaryKey' in table['schema']:\n        df = df.set_index(table['schema']['primaryKey'])\n        if len(df.index.names) == 1:\n            if df.index.name == 'index':\n                df.index.name = None\n        else:\n            df.index.names = [None if x.startswith('level_') else x for x in df.index.names]\n    return df",
            "def parse_table_schema(json, precise_float: bool) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Builds a DataFrame from a given schema\\n\\n    Parameters\\n    ----------\\n    json :\\n        A JSON table schema\\n    precise_float : bool\\n        Flag controlling precision when decoding string to double values, as\\n        dictated by ``read_json``\\n\\n    Returns\\n    -------\\n    df : DataFrame\\n\\n    Raises\\n    ------\\n    NotImplementedError\\n        If the JSON table schema contains either timezone or timedelta data\\n\\n    Notes\\n    -----\\n        Because :func:`DataFrame.to_json` uses the string 'index' to denote a\\n        name-less :class:`Index`, this function sets the name of the returned\\n        :class:`DataFrame` to ``None`` when said string is encountered with a\\n        normal :class:`Index`. For a :class:`MultiIndex`, the same limitation\\n        applies to any strings beginning with 'level_'. Therefore, an\\n        :class:`Index` name of 'index'  and :class:`MultiIndex` names starting\\n        with 'level_' are not supported.\\n\\n    See Also\\n    --------\\n    build_table_schema : Inverse function.\\n    pandas.read_json\\n    \"\n    table = ujson_loads(json, precise_float=precise_float)\n    col_order = [field['name'] for field in table['schema']['fields']]\n    df = DataFrame(table['data'], columns=col_order)[col_order]\n    dtypes = {field['name']: convert_json_field_to_pandas_type(field) for field in table['schema']['fields']}\n    if 'timedelta64' in dtypes.values():\n        raise NotImplementedError('table=\"orient\" can not yet read ISO-formatted Timedelta data')\n    df = df.astype(dtypes)\n    if 'primaryKey' in table['schema']:\n        df = df.set_index(table['schema']['primaryKey'])\n        if len(df.index.names) == 1:\n            if df.index.name == 'index':\n                df.index.name = None\n        else:\n            df.index.names = [None if x.startswith('level_') else x for x in df.index.names]\n    return df",
            "def parse_table_schema(json, precise_float: bool) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Builds a DataFrame from a given schema\\n\\n    Parameters\\n    ----------\\n    json :\\n        A JSON table schema\\n    precise_float : bool\\n        Flag controlling precision when decoding string to double values, as\\n        dictated by ``read_json``\\n\\n    Returns\\n    -------\\n    df : DataFrame\\n\\n    Raises\\n    ------\\n    NotImplementedError\\n        If the JSON table schema contains either timezone or timedelta data\\n\\n    Notes\\n    -----\\n        Because :func:`DataFrame.to_json` uses the string 'index' to denote a\\n        name-less :class:`Index`, this function sets the name of the returned\\n        :class:`DataFrame` to ``None`` when said string is encountered with a\\n        normal :class:`Index`. For a :class:`MultiIndex`, the same limitation\\n        applies to any strings beginning with 'level_'. Therefore, an\\n        :class:`Index` name of 'index'  and :class:`MultiIndex` names starting\\n        with 'level_' are not supported.\\n\\n    See Also\\n    --------\\n    build_table_schema : Inverse function.\\n    pandas.read_json\\n    \"\n    table = ujson_loads(json, precise_float=precise_float)\n    col_order = [field['name'] for field in table['schema']['fields']]\n    df = DataFrame(table['data'], columns=col_order)[col_order]\n    dtypes = {field['name']: convert_json_field_to_pandas_type(field) for field in table['schema']['fields']}\n    if 'timedelta64' in dtypes.values():\n        raise NotImplementedError('table=\"orient\" can not yet read ISO-formatted Timedelta data')\n    df = df.astype(dtypes)\n    if 'primaryKey' in table['schema']:\n        df = df.set_index(table['schema']['primaryKey'])\n        if len(df.index.names) == 1:\n            if df.index.name == 'index':\n                df.index.name = None\n        else:\n            df.index.names = [None if x.startswith('level_') else x for x in df.index.names]\n    return df",
            "def parse_table_schema(json, precise_float: bool) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Builds a DataFrame from a given schema\\n\\n    Parameters\\n    ----------\\n    json :\\n        A JSON table schema\\n    precise_float : bool\\n        Flag controlling precision when decoding string to double values, as\\n        dictated by ``read_json``\\n\\n    Returns\\n    -------\\n    df : DataFrame\\n\\n    Raises\\n    ------\\n    NotImplementedError\\n        If the JSON table schema contains either timezone or timedelta data\\n\\n    Notes\\n    -----\\n        Because :func:`DataFrame.to_json` uses the string 'index' to denote a\\n        name-less :class:`Index`, this function sets the name of the returned\\n        :class:`DataFrame` to ``None`` when said string is encountered with a\\n        normal :class:`Index`. For a :class:`MultiIndex`, the same limitation\\n        applies to any strings beginning with 'level_'. Therefore, an\\n        :class:`Index` name of 'index'  and :class:`MultiIndex` names starting\\n        with 'level_' are not supported.\\n\\n    See Also\\n    --------\\n    build_table_schema : Inverse function.\\n    pandas.read_json\\n    \"\n    table = ujson_loads(json, precise_float=precise_float)\n    col_order = [field['name'] for field in table['schema']['fields']]\n    df = DataFrame(table['data'], columns=col_order)[col_order]\n    dtypes = {field['name']: convert_json_field_to_pandas_type(field) for field in table['schema']['fields']}\n    if 'timedelta64' in dtypes.values():\n        raise NotImplementedError('table=\"orient\" can not yet read ISO-formatted Timedelta data')\n    df = df.astype(dtypes)\n    if 'primaryKey' in table['schema']:\n        df = df.set_index(table['schema']['primaryKey'])\n        if len(df.index.names) == 1:\n            if df.index.name == 'index':\n                df.index.name = None\n        else:\n            df.index.names = [None if x.startswith('level_') else x for x in df.index.names]\n    return df"
        ]
    }
]