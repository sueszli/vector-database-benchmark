[
    {
        "func_name": "create_lagged_data",
        "original": "def create_lagged_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, is_training: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    \"\"\"\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\n    `sklearn` model) when `is_training = True`; alternatively, creates the features array `X` to produce a series\n    of prediction from an already-trained regression model when `is_training = False`. In both cases, a list of time\n    indices corresponding to each generated observation is also returned.\n\n    Notes\n    -----\n    Instead of calling `create_lagged_data` directly, it is instead recommended that:\n        - `create_lagged_training_data` be called if one wishes to create the `X` and `y` arrays\n        to train a regression model.\n        - `create_lagged_prediction_data` be called if one wishes to create the `X` array required\n        to generate a prediction from an already-trained regression model.\n    This is because even though both of these functions are merely wrappers around `create_lagged_data`, their\n    call signatures are more easily interpreted than `create_lagged_data`. For example,\n    `create_lagged_prediction_data` does not accept `output_chunk_length` nor `multi_models` as inputs, since\n    these inputs are not used when constructing prediction data. Similarly, `create_lagged_prediction_data`\n    returns only `X` and `times` as outputs, as opposed to returning `y` as `None` along with `X` and `times`.\n\n    The `X` array is constructed from the lagged values of up to three separate timeseries:\n        1. The `target_series`, which contains the values we're trying to predict. A regression model that\n        uses previous values of the target its predicting is referred to as *auto-regressive*; please refer to\n        [1]_ for further details about auto-regressive timeseries models.\n        2. The past covariates series, which contains values that are *not* known into the future. Unlike\n        the target series, however, past covariates are *not* to be predicted by the regression model.\n        3. The future covariates (AKA 'exogenous' covariates) series, which contains values that are known\n        into the future, even beyond the data in `target_series` and `past_covariates`.\n    See [2]_ for a more detailed discussion about target, past, and future covariates. Conversely, `y` is\n    comprised only of the lagged values of `target_series`.\n\n    The shape of `X` is:\n        `X.shape = (n_observations, n_lagged_features, n_samples)`,\n    where `n_observations` equals either the number of time points shared between all specified series,\n    or `max_samples_per_ts`, whichever is smallest.\n    The shape of `y` is:\n        `y.shape = (n_observations, output_chunk_length, n_samples)`,\n    if `multi_models = True`, otherwise:\n        `y.shape = (n_observations, 1, n_samples)`.\n\n    Along the `n_lagged_features` axis, `X` has the following structure (for `*_lags=[-2,-1]` and\n    `*_series.n_components = 2`):\n        lagged_target | lagged_past_covariates | lagged_future_covariates\n    where each `lagged_*` has the following structure:\n        lag_-2_comp_1_* | lag_-2_comp_2_* | lag_-1_comp_1_* | lag_-1_comp_2_*\n\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\n    `target_series.n_components=2`):\n        lag_+0_comp_1_target | lag_+0_comp_2_target | ... | lag_+3_comp_1_target | lag_+3_comp_2_target\n\n    The `lags` and `lags_past_covariates` must contain only values less than or equal to -1. In other words, one\n    cannot use the value of either of these series at time `t` to predict the value of the target series at the\n    same time `t`; this is because the values of `target_series` and `past_covariates` at time `t` aren't available\n    at prediction time, by definition. Conversely, since the values of `future_covariates` are known into the future,\n    `lags_future_covariates` can contain negative, positive, and/or zero lag values (i.e. we *can* use the values of\n    `future_covariates` at time `t` or beyond to predict the value of `target_series` at time `t`).\n\n    The exact method used to construct `X` and `y` depends on whether all of the specified timeseries are\n    of the same frequency or not:\n        - If all specified timeseries are of the same frequency, `strided_moving_window` is used to extract\n        contiguous time blocks from each timeseries; the lagged variables are then extracted from each window.\n        - If all specified timeseries are *not* of the same frequency, then `find_shared_times` is first used\n        to find those times common to all three timeseries, after which the lagged features are extracted by\n        offsetting the time indices of these common times by the requested lags.\n    In cases where it can be validly applied, the 'moving window' method is expected to be faster than the\n    'intersecting time' method. However, in exceptional cases where only a small number of lags are being\n    extracted, but the difference between the lag values is large (e.g. `lags = [-1, -1000]`), the 'moving\n    window' method is expected to consume significantly more memory, since it extracts all of the series values\n    between the maximum and minimum lags as 'windows', before actually extracting the specific requested lag values.\n\n    In order for the lagged features of a series to be added to `X`, *both* that series and the corresponding lags\n    must be specified; if a series is specified without the corresponding lags, that series will be ignored and not\n    added to `X`. `X` and `y` arrays are constructed independently over the samples dimension (i.e. the second axis)\n    of each series.\n\n    If the provided series are stochastic (i.e. `series.n_components > 1`), then an `X` and `y` array will be\n    constructed for each sample; the arrays corresponding to each sample are concatenated togather along the `2`nd\n    axis of `X` and `y`. In other words, `create_lagged_data` is vectorised over the sample axis of the `target_series`,\n    `past_covariates`, and `future_covariates` inputs. Importantly, if stochastic series are provided, each series must\n    have the same number of samples, otherwise an error will be thrown.\n\n    Each series input (i.e. `target_series`, `past_covariates`, and `future_covariates`) can be specified either as\n    a single `TimeSeries`, or as a `Sequence` of `TimeSeries`; the specified series must all be of the same type,\n    however (i.e. either all `TimeSeries` or all `Sequence[TimeSeries]`). If `Sequence[TimeSeries]` are specified,\n    then a feature matrix `X` and labels array `y` will be constructed using the corresponding `TimeSeries` in\n    each `Sequence` (i.e. the first `TimeSeries` in each `Sequence` are used to create an `X` and `y`, then\n    the second `TimeSeries` in each `Sequence` are used to create an `X` and `y`, etc.). If `concatenate = True`,\n    these `X`'s and `y`'s will be concatenated along the `0`th axis; otherwise, a list of `X` and `y` array will\n    be returned. Note that `times` is always returned as a `Sequence[pd.Index]`, however, even when\n    `concatenate = True`.\n\n    Parameters\n    ----------\n    target_series\n        Optionally, the series for the regression model to predict. Must be specified if `is_training = True`.\n        Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\n    output_chunk_length\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. Must\n        best specified if `is_training = True`.\n    past_covariates\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model. Can be\n        specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\n    future_covariates\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\n        use as inputs. Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\n    lags\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\n        component in the target series.\n    lags_past_covariates\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\n        component in the past covariates series.\n    lags_future_covariates\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and\n        `lags_past_covariates`, `lags_future_covariates` values can be positive (i.e. use values *after* time `t`\n        to predict target at time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or\n        negative (i.e. use values *before* time `t` to predict target at time `t`). If the lags are provided as\n        a dictionary, the lags values are specific to each component in the future covariates series.\n    uses_static_covariates\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\n        have identical shapes across all target series.\n    last_static_covariates_shape\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\n        `uses_static_covariates` is ``False``.\n    max_samples_per_ts\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\n        especially in cases where many observations could be generated.\n    multi_models\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\n        This input is ignored if `is_training = False`.\n    check_inputs\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\n        should be set to `True`.\n    use_moving_windows\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\n        details.\n    is_training\n        Optionally, specifies whether the constructed lagged data are to be used for training a regression model\n        (i.e. `is_training = True`), or for generating predictions from an already-trained regression model (i.e.\n        `is_training = False`). If `is_training = True`, `target_series` and `output_chunk_length` must be specified,\n        the `multi_models` input is utilised, and a label array `y` is returned. Conversely, if `is_training = False`,\n        then `target_series` and `output_chunk_length` do not need to be specified, the `multi_models` input is ignored,\n        and the returned `y` value is `None`.\n    concatenate\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\n        `Sequence[pd.Index]`, even when `concatenate = True`.\n\n    Returns\n    -------\n    X\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\n    y\n        The constructed labels array. If `multi_models = True`, then `y` is a\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\n    times\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\n    last_static_covariates_shape\n        The last observed shape of the static covariates. This is ``None`` when `uses_static_covariates`\n        is ``False``.\n\n\n    Raises\n    ------\n    ValueError\n        If the specified time series do not share any times for which features (and labels if `is_training = True`) can\n        be constructed.\n    ValueError\n        If no lags are specified, or if any of the specified lag values are non-negative.\n    ValueError\n        If any of the series are too short to create features and/or labels for the requested lags and\n        `output_chunk_length` values.\n    ValueError\n        If `target_series` and/or `output_chunk_length` are *not* specified when `is_training = True`.\n    ValueError\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\n\n    References\n    ----------\n    .. [1] https://otexts.com/fpp2/AR.html#AR\n    .. [2] https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\n\n    See Also\n    --------\n        tabularization.create_lagged_component_names : return the lagged features names as a list of strings.\n\n    \"\"\"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` if `is_training = True`.')\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    seq_ts_lens = [len(seq_ts) for seq_ts in (target_series, past_covariates, future_covariates) if seq_ts is not None]\n    seq_ts_lens = set(seq_ts_lens)\n    raise_if(len(seq_ts_lens) > 1, 'Must specify the same number of `TimeSeries` for each series input.')\n    if max_samples_per_ts is None:\n        max_samples_per_ts = inf\n    (X, y, times) = ([], [], [])\n    for i in range(max(seq_ts_lens)):\n        target_i = target_series[i] if target_series else None\n        past_i = past_covariates[i] if past_covariates else None\n        future_i = future_covariates[i] if future_covariates else None\n        if use_moving_windows and _all_equal_freq(target_i, past_i, future_i):\n            (X_i, y_i, times_i) = _create_lagged_data_by_moving_window(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        else:\n            (X_i, y_i, times_i) = _create_lagged_data_by_intersecting_times(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        (X_i, last_static_covariates_shape) = add_static_covariates_to_lagged_data(features=X_i, target_series=target_i, uses_static_covariates=uses_static_covariates, last_shape=last_static_covariates_shape)\n        X.append(X_i)\n        y.append(y_i)\n        times.append(times_i)\n    if concatenate:\n        X = np.concatenate(X, axis=0)\n    if not is_training:\n        y = None\n    elif concatenate:\n        y = np.concatenate(y, axis=0)\n    return (X, y, times, last_static_covariates_shape)",
        "mutated": [
            "def create_lagged_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, is_training: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model) when `is_training = True`; alternatively, creates the features array `X` to produce a series\\n    of prediction from an already-trained regression model when `is_training = False`. In both cases, a list of time\\n    indices corresponding to each generated observation is also returned.\\n\\n    Notes\\n    -----\\n    Instead of calling `create_lagged_data` directly, it is instead recommended that:\\n        - `create_lagged_training_data` be called if one wishes to create the `X` and `y` arrays\\n        to train a regression model.\\n        - `create_lagged_prediction_data` be called if one wishes to create the `X` array required\\n        to generate a prediction from an already-trained regression model.\\n    This is because even though both of these functions are merely wrappers around `create_lagged_data`, their\\n    call signatures are more easily interpreted than `create_lagged_data`. For example,\\n    `create_lagged_prediction_data` does not accept `output_chunk_length` nor `multi_models` as inputs, since\\n    these inputs are not used when constructing prediction data. Similarly, `create_lagged_prediction_data`\\n    returns only `X` and `times` as outputs, as opposed to returning `y` as `None` along with `X` and `times`.\\n\\n    The `X` array is constructed from the lagged values of up to three separate timeseries:\\n        1. The `target_series`, which contains the values we're trying to predict. A regression model that\\n        uses previous values of the target its predicting is referred to as *auto-regressive*; please refer to\\n        [1]_ for further details about auto-regressive timeseries models.\\n        2. The past covariates series, which contains values that are *not* known into the future. Unlike\\n        the target series, however, past covariates are *not* to be predicted by the regression model.\\n        3. The future covariates (AKA 'exogenous' covariates) series, which contains values that are known\\n        into the future, even beyond the data in `target_series` and `past_covariates`.\\n    See [2]_ for a more detailed discussion about target, past, and future covariates. Conversely, `y` is\\n    comprised only of the lagged values of `target_series`.\\n\\n    The shape of `X` is:\\n        `X.shape = (n_observations, n_lagged_features, n_samples)`,\\n    where `n_observations` equals either the number of time points shared between all specified series,\\n    or `max_samples_per_ts`, whichever is smallest.\\n    The shape of `y` is:\\n        `y.shape = (n_observations, output_chunk_length, n_samples)`,\\n    if `multi_models = True`, otherwise:\\n        `y.shape = (n_observations, 1, n_samples)`.\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure (for `*_lags=[-2,-1]` and\\n    `*_series.n_components = 2`):\\n        lagged_target | lagged_past_covariates | lagged_future_covariates\\n    where each `lagged_*` has the following structure:\\n        lag_-2_comp_1_* | lag_-2_comp_2_* | lag_-1_comp_1_* | lag_-1_comp_2_*\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        lag_+0_comp_1_target | lag_+0_comp_2_target | ... | lag_+3_comp_1_target | lag_+3_comp_2_target\\n\\n    The `lags` and `lags_past_covariates` must contain only values less than or equal to -1. In other words, one\\n    cannot use the value of either of these series at time `t` to predict the value of the target series at the\\n    same time `t`; this is because the values of `target_series` and `past_covariates` at time `t` aren't available\\n    at prediction time, by definition. Conversely, since the values of `future_covariates` are known into the future,\\n    `lags_future_covariates` can contain negative, positive, and/or zero lag values (i.e. we *can* use the values of\\n    `future_covariates` at time `t` or beyond to predict the value of `target_series` at time `t`).\\n\\n    The exact method used to construct `X` and `y` depends on whether all of the specified timeseries are\\n    of the same frequency or not:\\n        - If all specified timeseries are of the same frequency, `strided_moving_window` is used to extract\\n        contiguous time blocks from each timeseries; the lagged variables are then extracted from each window.\\n        - If all specified timeseries are *not* of the same frequency, then `find_shared_times` is first used\\n        to find those times common to all three timeseries, after which the lagged features are extracted by\\n        offsetting the time indices of these common times by the requested lags.\\n    In cases where it can be validly applied, the 'moving window' method is expected to be faster than the\\n    'intersecting time' method. However, in exceptional cases where only a small number of lags are being\\n    extracted, but the difference between the lag values is large (e.g. `lags = [-1, -1000]`), the 'moving\\n    window' method is expected to consume significantly more memory, since it extracts all of the series values\\n    between the maximum and minimum lags as 'windows', before actually extracting the specific requested lag values.\\n\\n    In order for the lagged features of a series to be added to `X`, *both* that series and the corresponding lags\\n    must be specified; if a series is specified without the corresponding lags, that series will be ignored and not\\n    added to `X`. `X` and `y` arrays are constructed independently over the samples dimension (i.e. the second axis)\\n    of each series.\\n\\n    If the provided series are stochastic (i.e. `series.n_components > 1`), then an `X` and `y` array will be\\n    constructed for each sample; the arrays corresponding to each sample are concatenated togather along the `2`nd\\n    axis of `X` and `y`. In other words, `create_lagged_data` is vectorised over the sample axis of the `target_series`,\\n    `past_covariates`, and `future_covariates` inputs. Importantly, if stochastic series are provided, each series must\\n    have the same number of samples, otherwise an error will be thrown.\\n\\n    Each series input (i.e. `target_series`, `past_covariates`, and `future_covariates`) can be specified either as\\n    a single `TimeSeries`, or as a `Sequence` of `TimeSeries`; the specified series must all be of the same type,\\n    however (i.e. either all `TimeSeries` or all `Sequence[TimeSeries]`). If `Sequence[TimeSeries]` are specified,\\n    then a feature matrix `X` and labels array `y` will be constructed using the corresponding `TimeSeries` in\\n    each `Sequence` (i.e. the first `TimeSeries` in each `Sequence` are used to create an `X` and `y`, then\\n    the second `TimeSeries` in each `Sequence` are used to create an `X` and `y`, etc.). If `concatenate = True`,\\n    these `X`'s and `y`'s will be concatenated along the `0`th axis; otherwise, a list of `X` and `y` array will\\n    be returned. Note that `times` is always returned as a `Sequence[pd.Index]`, however, even when\\n    `concatenate = True`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict. Must be specified if `is_training = True`.\\n        Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. Must\\n        best specified if `is_training = True`.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model. Can be\\n        specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs. Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and\\n        `lags_past_covariates`, `lags_future_covariates` values can be positive (i.e. use values *after* time `t`\\n        to predict target at time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or\\n        negative (i.e. use values *before* time `t` to predict target at time `t`). If the lags are provided as\\n        a dictionary, the lags values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n        This input is ignored if `is_training = False`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    is_training\\n        Optionally, specifies whether the constructed lagged data are to be used for training a regression model\\n        (i.e. `is_training = True`), or for generating predictions from an already-trained regression model (i.e.\\n        `is_training = False`). If `is_training = True`, `target_series` and `output_chunk_length` must be specified,\\n        the `multi_models` input is utilised, and a label array `y` is returned. Conversely, if `is_training = False`,\\n        then `target_series` and `output_chunk_length` do not need to be specified, the `multi_models` input is ignored,\\n        and the returned `y` value is `None`.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n    last_static_covariates_shape\\n        The last observed shape of the static covariates. This is ``None`` when `uses_static_covariates`\\n        is ``False``.\\n\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features (and labels if `is_training = True`) can\\n        be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and/or labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If `target_series` and/or `output_chunk_length` are *not* specified when `is_training = True`.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n\\n    References\\n    ----------\\n    .. [1] https://otexts.com/fpp2/AR.html#AR\\n    .. [2] https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_component_names : return the lagged features names as a list of strings.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` if `is_training = True`.')\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    seq_ts_lens = [len(seq_ts) for seq_ts in (target_series, past_covariates, future_covariates) if seq_ts is not None]\n    seq_ts_lens = set(seq_ts_lens)\n    raise_if(len(seq_ts_lens) > 1, 'Must specify the same number of `TimeSeries` for each series input.')\n    if max_samples_per_ts is None:\n        max_samples_per_ts = inf\n    (X, y, times) = ([], [], [])\n    for i in range(max(seq_ts_lens)):\n        target_i = target_series[i] if target_series else None\n        past_i = past_covariates[i] if past_covariates else None\n        future_i = future_covariates[i] if future_covariates else None\n        if use_moving_windows and _all_equal_freq(target_i, past_i, future_i):\n            (X_i, y_i, times_i) = _create_lagged_data_by_moving_window(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        else:\n            (X_i, y_i, times_i) = _create_lagged_data_by_intersecting_times(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        (X_i, last_static_covariates_shape) = add_static_covariates_to_lagged_data(features=X_i, target_series=target_i, uses_static_covariates=uses_static_covariates, last_shape=last_static_covariates_shape)\n        X.append(X_i)\n        y.append(y_i)\n        times.append(times_i)\n    if concatenate:\n        X = np.concatenate(X, axis=0)\n    if not is_training:\n        y = None\n    elif concatenate:\n        y = np.concatenate(y, axis=0)\n    return (X, y, times, last_static_covariates_shape)",
            "def create_lagged_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, is_training: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model) when `is_training = True`; alternatively, creates the features array `X` to produce a series\\n    of prediction from an already-trained regression model when `is_training = False`. In both cases, a list of time\\n    indices corresponding to each generated observation is also returned.\\n\\n    Notes\\n    -----\\n    Instead of calling `create_lagged_data` directly, it is instead recommended that:\\n        - `create_lagged_training_data` be called if one wishes to create the `X` and `y` arrays\\n        to train a regression model.\\n        - `create_lagged_prediction_data` be called if one wishes to create the `X` array required\\n        to generate a prediction from an already-trained regression model.\\n    This is because even though both of these functions are merely wrappers around `create_lagged_data`, their\\n    call signatures are more easily interpreted than `create_lagged_data`. For example,\\n    `create_lagged_prediction_data` does not accept `output_chunk_length` nor `multi_models` as inputs, since\\n    these inputs are not used when constructing prediction data. Similarly, `create_lagged_prediction_data`\\n    returns only `X` and `times` as outputs, as opposed to returning `y` as `None` along with `X` and `times`.\\n\\n    The `X` array is constructed from the lagged values of up to three separate timeseries:\\n        1. The `target_series`, which contains the values we're trying to predict. A regression model that\\n        uses previous values of the target its predicting is referred to as *auto-regressive*; please refer to\\n        [1]_ for further details about auto-regressive timeseries models.\\n        2. The past covariates series, which contains values that are *not* known into the future. Unlike\\n        the target series, however, past covariates are *not* to be predicted by the regression model.\\n        3. The future covariates (AKA 'exogenous' covariates) series, which contains values that are known\\n        into the future, even beyond the data in `target_series` and `past_covariates`.\\n    See [2]_ for a more detailed discussion about target, past, and future covariates. Conversely, `y` is\\n    comprised only of the lagged values of `target_series`.\\n\\n    The shape of `X` is:\\n        `X.shape = (n_observations, n_lagged_features, n_samples)`,\\n    where `n_observations` equals either the number of time points shared between all specified series,\\n    or `max_samples_per_ts`, whichever is smallest.\\n    The shape of `y` is:\\n        `y.shape = (n_observations, output_chunk_length, n_samples)`,\\n    if `multi_models = True`, otherwise:\\n        `y.shape = (n_observations, 1, n_samples)`.\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure (for `*_lags=[-2,-1]` and\\n    `*_series.n_components = 2`):\\n        lagged_target | lagged_past_covariates | lagged_future_covariates\\n    where each `lagged_*` has the following structure:\\n        lag_-2_comp_1_* | lag_-2_comp_2_* | lag_-1_comp_1_* | lag_-1_comp_2_*\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        lag_+0_comp_1_target | lag_+0_comp_2_target | ... | lag_+3_comp_1_target | lag_+3_comp_2_target\\n\\n    The `lags` and `lags_past_covariates` must contain only values less than or equal to -1. In other words, one\\n    cannot use the value of either of these series at time `t` to predict the value of the target series at the\\n    same time `t`; this is because the values of `target_series` and `past_covariates` at time `t` aren't available\\n    at prediction time, by definition. Conversely, since the values of `future_covariates` are known into the future,\\n    `lags_future_covariates` can contain negative, positive, and/or zero lag values (i.e. we *can* use the values of\\n    `future_covariates` at time `t` or beyond to predict the value of `target_series` at time `t`).\\n\\n    The exact method used to construct `X` and `y` depends on whether all of the specified timeseries are\\n    of the same frequency or not:\\n        - If all specified timeseries are of the same frequency, `strided_moving_window` is used to extract\\n        contiguous time blocks from each timeseries; the lagged variables are then extracted from each window.\\n        - If all specified timeseries are *not* of the same frequency, then `find_shared_times` is first used\\n        to find those times common to all three timeseries, after which the lagged features are extracted by\\n        offsetting the time indices of these common times by the requested lags.\\n    In cases where it can be validly applied, the 'moving window' method is expected to be faster than the\\n    'intersecting time' method. However, in exceptional cases where only a small number of lags are being\\n    extracted, but the difference between the lag values is large (e.g. `lags = [-1, -1000]`), the 'moving\\n    window' method is expected to consume significantly more memory, since it extracts all of the series values\\n    between the maximum and minimum lags as 'windows', before actually extracting the specific requested lag values.\\n\\n    In order for the lagged features of a series to be added to `X`, *both* that series and the corresponding lags\\n    must be specified; if a series is specified without the corresponding lags, that series will be ignored and not\\n    added to `X`. `X` and `y` arrays are constructed independently over the samples dimension (i.e. the second axis)\\n    of each series.\\n\\n    If the provided series are stochastic (i.e. `series.n_components > 1`), then an `X` and `y` array will be\\n    constructed for each sample; the arrays corresponding to each sample are concatenated togather along the `2`nd\\n    axis of `X` and `y`. In other words, `create_lagged_data` is vectorised over the sample axis of the `target_series`,\\n    `past_covariates`, and `future_covariates` inputs. Importantly, if stochastic series are provided, each series must\\n    have the same number of samples, otherwise an error will be thrown.\\n\\n    Each series input (i.e. `target_series`, `past_covariates`, and `future_covariates`) can be specified either as\\n    a single `TimeSeries`, or as a `Sequence` of `TimeSeries`; the specified series must all be of the same type,\\n    however (i.e. either all `TimeSeries` or all `Sequence[TimeSeries]`). If `Sequence[TimeSeries]` are specified,\\n    then a feature matrix `X` and labels array `y` will be constructed using the corresponding `TimeSeries` in\\n    each `Sequence` (i.e. the first `TimeSeries` in each `Sequence` are used to create an `X` and `y`, then\\n    the second `TimeSeries` in each `Sequence` are used to create an `X` and `y`, etc.). If `concatenate = True`,\\n    these `X`'s and `y`'s will be concatenated along the `0`th axis; otherwise, a list of `X` and `y` array will\\n    be returned. Note that `times` is always returned as a `Sequence[pd.Index]`, however, even when\\n    `concatenate = True`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict. Must be specified if `is_training = True`.\\n        Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. Must\\n        best specified if `is_training = True`.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model. Can be\\n        specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs. Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and\\n        `lags_past_covariates`, `lags_future_covariates` values can be positive (i.e. use values *after* time `t`\\n        to predict target at time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or\\n        negative (i.e. use values *before* time `t` to predict target at time `t`). If the lags are provided as\\n        a dictionary, the lags values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n        This input is ignored if `is_training = False`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    is_training\\n        Optionally, specifies whether the constructed lagged data are to be used for training a regression model\\n        (i.e. `is_training = True`), or for generating predictions from an already-trained regression model (i.e.\\n        `is_training = False`). If `is_training = True`, `target_series` and `output_chunk_length` must be specified,\\n        the `multi_models` input is utilised, and a label array `y` is returned. Conversely, if `is_training = False`,\\n        then `target_series` and `output_chunk_length` do not need to be specified, the `multi_models` input is ignored,\\n        and the returned `y` value is `None`.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n    last_static_covariates_shape\\n        The last observed shape of the static covariates. This is ``None`` when `uses_static_covariates`\\n        is ``False``.\\n\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features (and labels if `is_training = True`) can\\n        be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and/or labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If `target_series` and/or `output_chunk_length` are *not* specified when `is_training = True`.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n\\n    References\\n    ----------\\n    .. [1] https://otexts.com/fpp2/AR.html#AR\\n    .. [2] https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_component_names : return the lagged features names as a list of strings.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` if `is_training = True`.')\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    seq_ts_lens = [len(seq_ts) for seq_ts in (target_series, past_covariates, future_covariates) if seq_ts is not None]\n    seq_ts_lens = set(seq_ts_lens)\n    raise_if(len(seq_ts_lens) > 1, 'Must specify the same number of `TimeSeries` for each series input.')\n    if max_samples_per_ts is None:\n        max_samples_per_ts = inf\n    (X, y, times) = ([], [], [])\n    for i in range(max(seq_ts_lens)):\n        target_i = target_series[i] if target_series else None\n        past_i = past_covariates[i] if past_covariates else None\n        future_i = future_covariates[i] if future_covariates else None\n        if use_moving_windows and _all_equal_freq(target_i, past_i, future_i):\n            (X_i, y_i, times_i) = _create_lagged_data_by_moving_window(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        else:\n            (X_i, y_i, times_i) = _create_lagged_data_by_intersecting_times(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        (X_i, last_static_covariates_shape) = add_static_covariates_to_lagged_data(features=X_i, target_series=target_i, uses_static_covariates=uses_static_covariates, last_shape=last_static_covariates_shape)\n        X.append(X_i)\n        y.append(y_i)\n        times.append(times_i)\n    if concatenate:\n        X = np.concatenate(X, axis=0)\n    if not is_training:\n        y = None\n    elif concatenate:\n        y = np.concatenate(y, axis=0)\n    return (X, y, times, last_static_covariates_shape)",
            "def create_lagged_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, is_training: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model) when `is_training = True`; alternatively, creates the features array `X` to produce a series\\n    of prediction from an already-trained regression model when `is_training = False`. In both cases, a list of time\\n    indices corresponding to each generated observation is also returned.\\n\\n    Notes\\n    -----\\n    Instead of calling `create_lagged_data` directly, it is instead recommended that:\\n        - `create_lagged_training_data` be called if one wishes to create the `X` and `y` arrays\\n        to train a regression model.\\n        - `create_lagged_prediction_data` be called if one wishes to create the `X` array required\\n        to generate a prediction from an already-trained regression model.\\n    This is because even though both of these functions are merely wrappers around `create_lagged_data`, their\\n    call signatures are more easily interpreted than `create_lagged_data`. For example,\\n    `create_lagged_prediction_data` does not accept `output_chunk_length` nor `multi_models` as inputs, since\\n    these inputs are not used when constructing prediction data. Similarly, `create_lagged_prediction_data`\\n    returns only `X` and `times` as outputs, as opposed to returning `y` as `None` along with `X` and `times`.\\n\\n    The `X` array is constructed from the lagged values of up to three separate timeseries:\\n        1. The `target_series`, which contains the values we're trying to predict. A regression model that\\n        uses previous values of the target its predicting is referred to as *auto-regressive*; please refer to\\n        [1]_ for further details about auto-regressive timeseries models.\\n        2. The past covariates series, which contains values that are *not* known into the future. Unlike\\n        the target series, however, past covariates are *not* to be predicted by the regression model.\\n        3. The future covariates (AKA 'exogenous' covariates) series, which contains values that are known\\n        into the future, even beyond the data in `target_series` and `past_covariates`.\\n    See [2]_ for a more detailed discussion about target, past, and future covariates. Conversely, `y` is\\n    comprised only of the lagged values of `target_series`.\\n\\n    The shape of `X` is:\\n        `X.shape = (n_observations, n_lagged_features, n_samples)`,\\n    where `n_observations` equals either the number of time points shared between all specified series,\\n    or `max_samples_per_ts`, whichever is smallest.\\n    The shape of `y` is:\\n        `y.shape = (n_observations, output_chunk_length, n_samples)`,\\n    if `multi_models = True`, otherwise:\\n        `y.shape = (n_observations, 1, n_samples)`.\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure (for `*_lags=[-2,-1]` and\\n    `*_series.n_components = 2`):\\n        lagged_target | lagged_past_covariates | lagged_future_covariates\\n    where each `lagged_*` has the following structure:\\n        lag_-2_comp_1_* | lag_-2_comp_2_* | lag_-1_comp_1_* | lag_-1_comp_2_*\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        lag_+0_comp_1_target | lag_+0_comp_2_target | ... | lag_+3_comp_1_target | lag_+3_comp_2_target\\n\\n    The `lags` and `lags_past_covariates` must contain only values less than or equal to -1. In other words, one\\n    cannot use the value of either of these series at time `t` to predict the value of the target series at the\\n    same time `t`; this is because the values of `target_series` and `past_covariates` at time `t` aren't available\\n    at prediction time, by definition. Conversely, since the values of `future_covariates` are known into the future,\\n    `lags_future_covariates` can contain negative, positive, and/or zero lag values (i.e. we *can* use the values of\\n    `future_covariates` at time `t` or beyond to predict the value of `target_series` at time `t`).\\n\\n    The exact method used to construct `X` and `y` depends on whether all of the specified timeseries are\\n    of the same frequency or not:\\n        - If all specified timeseries are of the same frequency, `strided_moving_window` is used to extract\\n        contiguous time blocks from each timeseries; the lagged variables are then extracted from each window.\\n        - If all specified timeseries are *not* of the same frequency, then `find_shared_times` is first used\\n        to find those times common to all three timeseries, after which the lagged features are extracted by\\n        offsetting the time indices of these common times by the requested lags.\\n    In cases where it can be validly applied, the 'moving window' method is expected to be faster than the\\n    'intersecting time' method. However, in exceptional cases where only a small number of lags are being\\n    extracted, but the difference between the lag values is large (e.g. `lags = [-1, -1000]`), the 'moving\\n    window' method is expected to consume significantly more memory, since it extracts all of the series values\\n    between the maximum and minimum lags as 'windows', before actually extracting the specific requested lag values.\\n\\n    In order for the lagged features of a series to be added to `X`, *both* that series and the corresponding lags\\n    must be specified; if a series is specified without the corresponding lags, that series will be ignored and not\\n    added to `X`. `X` and `y` arrays are constructed independently over the samples dimension (i.e. the second axis)\\n    of each series.\\n\\n    If the provided series are stochastic (i.e. `series.n_components > 1`), then an `X` and `y` array will be\\n    constructed for each sample; the arrays corresponding to each sample are concatenated togather along the `2`nd\\n    axis of `X` and `y`. In other words, `create_lagged_data` is vectorised over the sample axis of the `target_series`,\\n    `past_covariates`, and `future_covariates` inputs. Importantly, if stochastic series are provided, each series must\\n    have the same number of samples, otherwise an error will be thrown.\\n\\n    Each series input (i.e. `target_series`, `past_covariates`, and `future_covariates`) can be specified either as\\n    a single `TimeSeries`, or as a `Sequence` of `TimeSeries`; the specified series must all be of the same type,\\n    however (i.e. either all `TimeSeries` or all `Sequence[TimeSeries]`). If `Sequence[TimeSeries]` are specified,\\n    then a feature matrix `X` and labels array `y` will be constructed using the corresponding `TimeSeries` in\\n    each `Sequence` (i.e. the first `TimeSeries` in each `Sequence` are used to create an `X` and `y`, then\\n    the second `TimeSeries` in each `Sequence` are used to create an `X` and `y`, etc.). If `concatenate = True`,\\n    these `X`'s and `y`'s will be concatenated along the `0`th axis; otherwise, a list of `X` and `y` array will\\n    be returned. Note that `times` is always returned as a `Sequence[pd.Index]`, however, even when\\n    `concatenate = True`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict. Must be specified if `is_training = True`.\\n        Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. Must\\n        best specified if `is_training = True`.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model. Can be\\n        specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs. Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and\\n        `lags_past_covariates`, `lags_future_covariates` values can be positive (i.e. use values *after* time `t`\\n        to predict target at time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or\\n        negative (i.e. use values *before* time `t` to predict target at time `t`). If the lags are provided as\\n        a dictionary, the lags values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n        This input is ignored if `is_training = False`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    is_training\\n        Optionally, specifies whether the constructed lagged data are to be used for training a regression model\\n        (i.e. `is_training = True`), or for generating predictions from an already-trained regression model (i.e.\\n        `is_training = False`). If `is_training = True`, `target_series` and `output_chunk_length` must be specified,\\n        the `multi_models` input is utilised, and a label array `y` is returned. Conversely, if `is_training = False`,\\n        then `target_series` and `output_chunk_length` do not need to be specified, the `multi_models` input is ignored,\\n        and the returned `y` value is `None`.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n    last_static_covariates_shape\\n        The last observed shape of the static covariates. This is ``None`` when `uses_static_covariates`\\n        is ``False``.\\n\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features (and labels if `is_training = True`) can\\n        be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and/or labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If `target_series` and/or `output_chunk_length` are *not* specified when `is_training = True`.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n\\n    References\\n    ----------\\n    .. [1] https://otexts.com/fpp2/AR.html#AR\\n    .. [2] https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_component_names : return the lagged features names as a list of strings.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` if `is_training = True`.')\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    seq_ts_lens = [len(seq_ts) for seq_ts in (target_series, past_covariates, future_covariates) if seq_ts is not None]\n    seq_ts_lens = set(seq_ts_lens)\n    raise_if(len(seq_ts_lens) > 1, 'Must specify the same number of `TimeSeries` for each series input.')\n    if max_samples_per_ts is None:\n        max_samples_per_ts = inf\n    (X, y, times) = ([], [], [])\n    for i in range(max(seq_ts_lens)):\n        target_i = target_series[i] if target_series else None\n        past_i = past_covariates[i] if past_covariates else None\n        future_i = future_covariates[i] if future_covariates else None\n        if use_moving_windows and _all_equal_freq(target_i, past_i, future_i):\n            (X_i, y_i, times_i) = _create_lagged_data_by_moving_window(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        else:\n            (X_i, y_i, times_i) = _create_lagged_data_by_intersecting_times(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        (X_i, last_static_covariates_shape) = add_static_covariates_to_lagged_data(features=X_i, target_series=target_i, uses_static_covariates=uses_static_covariates, last_shape=last_static_covariates_shape)\n        X.append(X_i)\n        y.append(y_i)\n        times.append(times_i)\n    if concatenate:\n        X = np.concatenate(X, axis=0)\n    if not is_training:\n        y = None\n    elif concatenate:\n        y = np.concatenate(y, axis=0)\n    return (X, y, times, last_static_covariates_shape)",
            "def create_lagged_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, is_training: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model) when `is_training = True`; alternatively, creates the features array `X` to produce a series\\n    of prediction from an already-trained regression model when `is_training = False`. In both cases, a list of time\\n    indices corresponding to each generated observation is also returned.\\n\\n    Notes\\n    -----\\n    Instead of calling `create_lagged_data` directly, it is instead recommended that:\\n        - `create_lagged_training_data` be called if one wishes to create the `X` and `y` arrays\\n        to train a regression model.\\n        - `create_lagged_prediction_data` be called if one wishes to create the `X` array required\\n        to generate a prediction from an already-trained regression model.\\n    This is because even though both of these functions are merely wrappers around `create_lagged_data`, their\\n    call signatures are more easily interpreted than `create_lagged_data`. For example,\\n    `create_lagged_prediction_data` does not accept `output_chunk_length` nor `multi_models` as inputs, since\\n    these inputs are not used when constructing prediction data. Similarly, `create_lagged_prediction_data`\\n    returns only `X` and `times` as outputs, as opposed to returning `y` as `None` along with `X` and `times`.\\n\\n    The `X` array is constructed from the lagged values of up to three separate timeseries:\\n        1. The `target_series`, which contains the values we're trying to predict. A regression model that\\n        uses previous values of the target its predicting is referred to as *auto-regressive*; please refer to\\n        [1]_ for further details about auto-regressive timeseries models.\\n        2. The past covariates series, which contains values that are *not* known into the future. Unlike\\n        the target series, however, past covariates are *not* to be predicted by the regression model.\\n        3. The future covariates (AKA 'exogenous' covariates) series, which contains values that are known\\n        into the future, even beyond the data in `target_series` and `past_covariates`.\\n    See [2]_ for a more detailed discussion about target, past, and future covariates. Conversely, `y` is\\n    comprised only of the lagged values of `target_series`.\\n\\n    The shape of `X` is:\\n        `X.shape = (n_observations, n_lagged_features, n_samples)`,\\n    where `n_observations` equals either the number of time points shared between all specified series,\\n    or `max_samples_per_ts`, whichever is smallest.\\n    The shape of `y` is:\\n        `y.shape = (n_observations, output_chunk_length, n_samples)`,\\n    if `multi_models = True`, otherwise:\\n        `y.shape = (n_observations, 1, n_samples)`.\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure (for `*_lags=[-2,-1]` and\\n    `*_series.n_components = 2`):\\n        lagged_target | lagged_past_covariates | lagged_future_covariates\\n    where each `lagged_*` has the following structure:\\n        lag_-2_comp_1_* | lag_-2_comp_2_* | lag_-1_comp_1_* | lag_-1_comp_2_*\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        lag_+0_comp_1_target | lag_+0_comp_2_target | ... | lag_+3_comp_1_target | lag_+3_comp_2_target\\n\\n    The `lags` and `lags_past_covariates` must contain only values less than or equal to -1. In other words, one\\n    cannot use the value of either of these series at time `t` to predict the value of the target series at the\\n    same time `t`; this is because the values of `target_series` and `past_covariates` at time `t` aren't available\\n    at prediction time, by definition. Conversely, since the values of `future_covariates` are known into the future,\\n    `lags_future_covariates` can contain negative, positive, and/or zero lag values (i.e. we *can* use the values of\\n    `future_covariates` at time `t` or beyond to predict the value of `target_series` at time `t`).\\n\\n    The exact method used to construct `X` and `y` depends on whether all of the specified timeseries are\\n    of the same frequency or not:\\n        - If all specified timeseries are of the same frequency, `strided_moving_window` is used to extract\\n        contiguous time blocks from each timeseries; the lagged variables are then extracted from each window.\\n        - If all specified timeseries are *not* of the same frequency, then `find_shared_times` is first used\\n        to find those times common to all three timeseries, after which the lagged features are extracted by\\n        offsetting the time indices of these common times by the requested lags.\\n    In cases where it can be validly applied, the 'moving window' method is expected to be faster than the\\n    'intersecting time' method. However, in exceptional cases where only a small number of lags are being\\n    extracted, but the difference between the lag values is large (e.g. `lags = [-1, -1000]`), the 'moving\\n    window' method is expected to consume significantly more memory, since it extracts all of the series values\\n    between the maximum and minimum lags as 'windows', before actually extracting the specific requested lag values.\\n\\n    In order for the lagged features of a series to be added to `X`, *both* that series and the corresponding lags\\n    must be specified; if a series is specified without the corresponding lags, that series will be ignored and not\\n    added to `X`. `X` and `y` arrays are constructed independently over the samples dimension (i.e. the second axis)\\n    of each series.\\n\\n    If the provided series are stochastic (i.e. `series.n_components > 1`), then an `X` and `y` array will be\\n    constructed for each sample; the arrays corresponding to each sample are concatenated togather along the `2`nd\\n    axis of `X` and `y`. In other words, `create_lagged_data` is vectorised over the sample axis of the `target_series`,\\n    `past_covariates`, and `future_covariates` inputs. Importantly, if stochastic series are provided, each series must\\n    have the same number of samples, otherwise an error will be thrown.\\n\\n    Each series input (i.e. `target_series`, `past_covariates`, and `future_covariates`) can be specified either as\\n    a single `TimeSeries`, or as a `Sequence` of `TimeSeries`; the specified series must all be of the same type,\\n    however (i.e. either all `TimeSeries` or all `Sequence[TimeSeries]`). If `Sequence[TimeSeries]` are specified,\\n    then a feature matrix `X` and labels array `y` will be constructed using the corresponding `TimeSeries` in\\n    each `Sequence` (i.e. the first `TimeSeries` in each `Sequence` are used to create an `X` and `y`, then\\n    the second `TimeSeries` in each `Sequence` are used to create an `X` and `y`, etc.). If `concatenate = True`,\\n    these `X`'s and `y`'s will be concatenated along the `0`th axis; otherwise, a list of `X` and `y` array will\\n    be returned. Note that `times` is always returned as a `Sequence[pd.Index]`, however, even when\\n    `concatenate = True`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict. Must be specified if `is_training = True`.\\n        Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. Must\\n        best specified if `is_training = True`.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model. Can be\\n        specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs. Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and\\n        `lags_past_covariates`, `lags_future_covariates` values can be positive (i.e. use values *after* time `t`\\n        to predict target at time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or\\n        negative (i.e. use values *before* time `t` to predict target at time `t`). If the lags are provided as\\n        a dictionary, the lags values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n        This input is ignored if `is_training = False`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    is_training\\n        Optionally, specifies whether the constructed lagged data are to be used for training a regression model\\n        (i.e. `is_training = True`), or for generating predictions from an already-trained regression model (i.e.\\n        `is_training = False`). If `is_training = True`, `target_series` and `output_chunk_length` must be specified,\\n        the `multi_models` input is utilised, and a label array `y` is returned. Conversely, if `is_training = False`,\\n        then `target_series` and `output_chunk_length` do not need to be specified, the `multi_models` input is ignored,\\n        and the returned `y` value is `None`.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n    last_static_covariates_shape\\n        The last observed shape of the static covariates. This is ``None`` when `uses_static_covariates`\\n        is ``False``.\\n\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features (and labels if `is_training = True`) can\\n        be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and/or labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If `target_series` and/or `output_chunk_length` are *not* specified when `is_training = True`.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n\\n    References\\n    ----------\\n    .. [1] https://otexts.com/fpp2/AR.html#AR\\n    .. [2] https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_component_names : return the lagged features names as a list of strings.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` if `is_training = True`.')\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    seq_ts_lens = [len(seq_ts) for seq_ts in (target_series, past_covariates, future_covariates) if seq_ts is not None]\n    seq_ts_lens = set(seq_ts_lens)\n    raise_if(len(seq_ts_lens) > 1, 'Must specify the same number of `TimeSeries` for each series input.')\n    if max_samples_per_ts is None:\n        max_samples_per_ts = inf\n    (X, y, times) = ([], [], [])\n    for i in range(max(seq_ts_lens)):\n        target_i = target_series[i] if target_series else None\n        past_i = past_covariates[i] if past_covariates else None\n        future_i = future_covariates[i] if future_covariates else None\n        if use_moving_windows and _all_equal_freq(target_i, past_i, future_i):\n            (X_i, y_i, times_i) = _create_lagged_data_by_moving_window(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        else:\n            (X_i, y_i, times_i) = _create_lagged_data_by_intersecting_times(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        (X_i, last_static_covariates_shape) = add_static_covariates_to_lagged_data(features=X_i, target_series=target_i, uses_static_covariates=uses_static_covariates, last_shape=last_static_covariates_shape)\n        X.append(X_i)\n        y.append(y_i)\n        times.append(times_i)\n    if concatenate:\n        X = np.concatenate(X, axis=0)\n    if not is_training:\n        y = None\n    elif concatenate:\n        y = np.concatenate(y, axis=0)\n    return (X, y, times, last_static_covariates_shape)",
            "def create_lagged_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, is_training: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model) when `is_training = True`; alternatively, creates the features array `X` to produce a series\\n    of prediction from an already-trained regression model when `is_training = False`. In both cases, a list of time\\n    indices corresponding to each generated observation is also returned.\\n\\n    Notes\\n    -----\\n    Instead of calling `create_lagged_data` directly, it is instead recommended that:\\n        - `create_lagged_training_data` be called if one wishes to create the `X` and `y` arrays\\n        to train a regression model.\\n        - `create_lagged_prediction_data` be called if one wishes to create the `X` array required\\n        to generate a prediction from an already-trained regression model.\\n    This is because even though both of these functions are merely wrappers around `create_lagged_data`, their\\n    call signatures are more easily interpreted than `create_lagged_data`. For example,\\n    `create_lagged_prediction_data` does not accept `output_chunk_length` nor `multi_models` as inputs, since\\n    these inputs are not used when constructing prediction data. Similarly, `create_lagged_prediction_data`\\n    returns only `X` and `times` as outputs, as opposed to returning `y` as `None` along with `X` and `times`.\\n\\n    The `X` array is constructed from the lagged values of up to three separate timeseries:\\n        1. The `target_series`, which contains the values we're trying to predict. A regression model that\\n        uses previous values of the target its predicting is referred to as *auto-regressive*; please refer to\\n        [1]_ for further details about auto-regressive timeseries models.\\n        2. The past covariates series, which contains values that are *not* known into the future. Unlike\\n        the target series, however, past covariates are *not* to be predicted by the regression model.\\n        3. The future covariates (AKA 'exogenous' covariates) series, which contains values that are known\\n        into the future, even beyond the data in `target_series` and `past_covariates`.\\n    See [2]_ for a more detailed discussion about target, past, and future covariates. Conversely, `y` is\\n    comprised only of the lagged values of `target_series`.\\n\\n    The shape of `X` is:\\n        `X.shape = (n_observations, n_lagged_features, n_samples)`,\\n    where `n_observations` equals either the number of time points shared between all specified series,\\n    or `max_samples_per_ts`, whichever is smallest.\\n    The shape of `y` is:\\n        `y.shape = (n_observations, output_chunk_length, n_samples)`,\\n    if `multi_models = True`, otherwise:\\n        `y.shape = (n_observations, 1, n_samples)`.\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure (for `*_lags=[-2,-1]` and\\n    `*_series.n_components = 2`):\\n        lagged_target | lagged_past_covariates | lagged_future_covariates\\n    where each `lagged_*` has the following structure:\\n        lag_-2_comp_1_* | lag_-2_comp_2_* | lag_-1_comp_1_* | lag_-1_comp_2_*\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        lag_+0_comp_1_target | lag_+0_comp_2_target | ... | lag_+3_comp_1_target | lag_+3_comp_2_target\\n\\n    The `lags` and `lags_past_covariates` must contain only values less than or equal to -1. In other words, one\\n    cannot use the value of either of these series at time `t` to predict the value of the target series at the\\n    same time `t`; this is because the values of `target_series` and `past_covariates` at time `t` aren't available\\n    at prediction time, by definition. Conversely, since the values of `future_covariates` are known into the future,\\n    `lags_future_covariates` can contain negative, positive, and/or zero lag values (i.e. we *can* use the values of\\n    `future_covariates` at time `t` or beyond to predict the value of `target_series` at time `t`).\\n\\n    The exact method used to construct `X` and `y` depends on whether all of the specified timeseries are\\n    of the same frequency or not:\\n        - If all specified timeseries are of the same frequency, `strided_moving_window` is used to extract\\n        contiguous time blocks from each timeseries; the lagged variables are then extracted from each window.\\n        - If all specified timeseries are *not* of the same frequency, then `find_shared_times` is first used\\n        to find those times common to all three timeseries, after which the lagged features are extracted by\\n        offsetting the time indices of these common times by the requested lags.\\n    In cases where it can be validly applied, the 'moving window' method is expected to be faster than the\\n    'intersecting time' method. However, in exceptional cases where only a small number of lags are being\\n    extracted, but the difference between the lag values is large (e.g. `lags = [-1, -1000]`), the 'moving\\n    window' method is expected to consume significantly more memory, since it extracts all of the series values\\n    between the maximum and minimum lags as 'windows', before actually extracting the specific requested lag values.\\n\\n    In order for the lagged features of a series to be added to `X`, *both* that series and the corresponding lags\\n    must be specified; if a series is specified without the corresponding lags, that series will be ignored and not\\n    added to `X`. `X` and `y` arrays are constructed independently over the samples dimension (i.e. the second axis)\\n    of each series.\\n\\n    If the provided series are stochastic (i.e. `series.n_components > 1`), then an `X` and `y` array will be\\n    constructed for each sample; the arrays corresponding to each sample are concatenated togather along the `2`nd\\n    axis of `X` and `y`. In other words, `create_lagged_data` is vectorised over the sample axis of the `target_series`,\\n    `past_covariates`, and `future_covariates` inputs. Importantly, if stochastic series are provided, each series must\\n    have the same number of samples, otherwise an error will be thrown.\\n\\n    Each series input (i.e. `target_series`, `past_covariates`, and `future_covariates`) can be specified either as\\n    a single `TimeSeries`, or as a `Sequence` of `TimeSeries`; the specified series must all be of the same type,\\n    however (i.e. either all `TimeSeries` or all `Sequence[TimeSeries]`). If `Sequence[TimeSeries]` are specified,\\n    then a feature matrix `X` and labels array `y` will be constructed using the corresponding `TimeSeries` in\\n    each `Sequence` (i.e. the first `TimeSeries` in each `Sequence` are used to create an `X` and `y`, then\\n    the second `TimeSeries` in each `Sequence` are used to create an `X` and `y`, etc.). If `concatenate = True`,\\n    these `X`'s and `y`'s will be concatenated along the `0`th axis; otherwise, a list of `X` and `y` array will\\n    be returned. Note that `times` is always returned as a `Sequence[pd.Index]`, however, even when\\n    `concatenate = True`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict. Must be specified if `is_training = True`.\\n        Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. Must\\n        best specified if `is_training = True`.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model. Can be\\n        specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs. Can be specified as either a `TimeSeries` or as a `Sequence[TimeSeries]`.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and\\n        `lags_past_covariates`, `lags_future_covariates` values can be positive (i.e. use values *after* time `t`\\n        to predict target at time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or\\n        negative (i.e. use values *before* time `t` to predict target at time `t`). If the lags are provided as\\n        a dictionary, the lags values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n        This input is ignored if `is_training = False`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    is_training\\n        Optionally, specifies whether the constructed lagged data are to be used for training a regression model\\n        (i.e. `is_training = True`), or for generating predictions from an already-trained regression model (i.e.\\n        `is_training = False`). If `is_training = True`, `target_series` and `output_chunk_length` must be specified,\\n        the `multi_models` input is utilised, and a label array `y` is returned. Conversely, if `is_training = False`,\\n        then `target_series` and `output_chunk_length` do not need to be specified, the `multi_models` input is ignored,\\n        and the returned `y` value is `None`.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n    last_static_covariates_shape\\n        The last observed shape of the static covariates. This is ``None`` when `uses_static_covariates`\\n        is ``False``.\\n\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features (and labels if `is_training = True`) can\\n        be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and/or labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If `target_series` and/or `output_chunk_length` are *not* specified when `is_training = True`.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n\\n    References\\n    ----------\\n    .. [1] https://otexts.com/fpp2/AR.html#AR\\n    .. [2] https://unit8.com/resources/time-series-forecasting-using-past-and-future-external-data-with-darts/\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_component_names : return the lagged features names as a list of strings.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` if `is_training = True`.')\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    seq_ts_lens = [len(seq_ts) for seq_ts in (target_series, past_covariates, future_covariates) if seq_ts is not None]\n    seq_ts_lens = set(seq_ts_lens)\n    raise_if(len(seq_ts_lens) > 1, 'Must specify the same number of `TimeSeries` for each series input.')\n    if max_samples_per_ts is None:\n        max_samples_per_ts = inf\n    (X, y, times) = ([], [], [])\n    for i in range(max(seq_ts_lens)):\n        target_i = target_series[i] if target_series else None\n        past_i = past_covariates[i] if past_covariates else None\n        future_i = future_covariates[i] if future_covariates else None\n        if use_moving_windows and _all_equal_freq(target_i, past_i, future_i):\n            (X_i, y_i, times_i) = _create_lagged_data_by_moving_window(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        else:\n            (X_i, y_i, times_i) = _create_lagged_data_by_intersecting_times(target_i, output_chunk_length, past_i, future_i, lags, lags_past_covariates, lags_future_covariates, max_samples_per_ts, multi_models, check_inputs, is_training)\n        (X_i, last_static_covariates_shape) = add_static_covariates_to_lagged_data(features=X_i, target_series=target_i, uses_static_covariates=uses_static_covariates, last_shape=last_static_covariates_shape)\n        X.append(X_i)\n        y.append(y_i)\n        times.append(times_i)\n    if concatenate:\n        X = np.concatenate(X, axis=0)\n    if not is_training:\n        y = None\n    elif concatenate:\n        y = np.concatenate(y, axis=0)\n    return (X, y, times, last_static_covariates_shape)"
        ]
    },
    {
        "func_name": "create_lagged_training_data",
        "original": "def create_lagged_training_data(target_series: Union[TimeSeries, Sequence[TimeSeries]], output_chunk_length: int, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    \"\"\"\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\n    `sklearn` model); the time index values of each observation is also returned.\n\n    Notes\n    -----\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\n    refer to `help(create_lagged_data)`.\n\n    Parameters\n    ----------\n    target_series\n        The series for the regression model to predict.\n    output_chunk_length\n        The number of timesteps ahead into the future the regression model is to predict.\n    past_covariates\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\n    future_covariates\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\n        use as inputs.\n    lags\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\n        component in the target series.\n    lags_past_covariates\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\n        component in the past covariates series.\n    lags_future_covariates\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use values\n        *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags values\n        are specific to each component in the future covariates series.\n    uses_static_covariates\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\n        have identical shapes across all target series.\n    last_static_covariates_shape\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\n        `uses_static_covariates` is ``False``.\n    max_samples_per_ts\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\n        especially in cases where many observations could be generated.\n    multi_models\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\n    check_inputs\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\n        should be set to `True`.\n    use_moving_windows\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\n        details.\n    concatenate\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\n        `Sequence[pd.Index]`, even when `concatenate = True`.\n\n    Returns\n    -------\n    X\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\n    y\n        The constructed labels array. If `multi_models = True`, then `y` is a\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\n    times\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\n\n    Raises\n    ------\n    ValueError\n        If the specified time series do not share any times for which features and labels can be constructed.\n    ValueError\n        If no lags are specified, or if any of the specified lag values are non-negative.\n    ValueError\n        If any of the series are too short to create features and labels for the requested lags and\n        `output_chunk_length` values.\n    ValueError\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\n    \"\"\"\n    return create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, output_chunk_length=output_chunk_length, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, multi_models=multi_models, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=True, concatenate=concatenate)",
        "mutated": [
            "def create_lagged_training_data(target_series: Union[TimeSeries, Sequence[TimeSeries]], output_chunk_length: int, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model); the time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        The series for the regression model to predict.\\n    output_chunk_length\\n        The number of timesteps ahead into the future the regression model is to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use values\\n        *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags values\\n        are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features and labels can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    return create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, output_chunk_length=output_chunk_length, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, multi_models=multi_models, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=True, concatenate=concatenate)",
            "def create_lagged_training_data(target_series: Union[TimeSeries, Sequence[TimeSeries]], output_chunk_length: int, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model); the time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        The series for the regression model to predict.\\n    output_chunk_length\\n        The number of timesteps ahead into the future the regression model is to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use values\\n        *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags values\\n        are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features and labels can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    return create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, output_chunk_length=output_chunk_length, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, multi_models=multi_models, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=True, concatenate=concatenate)",
            "def create_lagged_training_data(target_series: Union[TimeSeries, Sequence[TimeSeries]], output_chunk_length: int, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model); the time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        The series for the regression model to predict.\\n    output_chunk_length\\n        The number of timesteps ahead into the future the regression model is to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use values\\n        *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags values\\n        are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features and labels can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    return create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, output_chunk_length=output_chunk_length, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, multi_models=multi_models, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=True, concatenate=concatenate)",
            "def create_lagged_training_data(target_series: Union[TimeSeries, Sequence[TimeSeries]], output_chunk_length: int, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model); the time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        The series for the regression model to predict.\\n    output_chunk_length\\n        The number of timesteps ahead into the future the regression model is to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use values\\n        *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags values\\n        are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features and labels can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    return create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, output_chunk_length=output_chunk_length, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, multi_models=multi_models, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=True, concatenate=concatenate)",
            "def create_lagged_training_data(target_series: Union[TimeSeries, Sequence[TimeSeries]], output_chunk_length: int, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, multi_models: bool=True, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Union[None, ArrayOrArraySequence], Sequence[pd.Index], Optional[Tuple[int, int]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\\n    `sklearn` model); the time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        The series for the regression model to predict.\\n    output_chunk_length\\n        The number of timesteps ahead into the future the regression model is to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use values\\n        *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags values\\n        are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    multi_models\\n        Optionally, specifies whether the regression model predicts multiple timesteps into the future. If `True`,\\n        then the regression model is assumed to predict all of the timesteps from time `t` to `t+output_chunk_length`.\\n        If `False`, then the regression model is assumed to predict *only* the timestep at `t+output_chunk_length`.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` and `y` should both be returned as single `np.ndarray`s, instead of as\\n        a `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and\\n        `concatenate = False`, `X` and `y` will be lists whose `i`th element corresponds to the feature matrix or label\\n        array formed by the `i`th `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True`\\n        when `Sequence[TimeSeries]` are provided, then `X` and `y` will be arrays created by concatenating all of the\\n        feature/label arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    y\\n        The constructed labels array. If `multi_models = True`, then `y` is a\\n        `(n_observations, output_chunk_length, n_samples)`-shaped array; conversely, if\\n        `multi_models =  False`, then `y` is a `(n_observations, 1, n_samples)`-shaped array.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `y`\\n        is returned as a `Sequence[np.array]`; otherwise, `y` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features and labels can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features and labels for the requested lags and\\n        `output_chunk_length` values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    return create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, output_chunk_length=output_chunk_length, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, multi_models=multi_models, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=True, concatenate=concatenate)"
        ]
    },
    {
        "func_name": "create_lagged_prediction_data",
        "original": "def create_lagged_prediction_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Sequence[pd.Index]]:\n    \"\"\"\n    Creates the features array `X` to produce a series of prediction from an already-trained regression model; the\n    time index values of each observation is also returned.\n\n    Notes\n    -----\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\n    refer to `help(create_lagged_data)`.\n\n    Parameters\n    ----------\n    target_series\n        Optionally, the series for the regression model to predict.\n    past_covariates\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\n    future_covariates\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\n        use as inputs.\n    lags\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\n        component in the target series.\n    lags_past_covariates\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\n        component in the past covariates series.\n    lags_future_covariates\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use\n        values *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags\n        values are specific to each component in the future covariates series.\n    uses_static_covariates\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\n        have identical shapes across all target series.\n    last_static_covariates_shape\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\n        `uses_static_covariates` is ``False``.\n    max_samples_per_ts\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\n        especially in cases where many observations could be generated.\n    check_inputs\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\n        should be set to `True`.\n    use_moving_windows\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\n        details.\n    concatenate\n        Optionally, specifies that `X` should be returned as a single `np.ndarray`, instead of as a\n        `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and `concatenate = False`,\n        `X` will be a list whose `i`th element corresponds to the feature matrix or label array formed by the `i`th\n        `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True` when\n        `Sequence[TimeSeries]` are provided, then `X` will be an array created by concatenating all of the feature\n        arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\n        `Sequence[pd.Index]`, even when `concatenate = True`.\n\n    Returns\n    -------\n    X\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\n    times\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\n\n    Raises\n    ------\n    ValueError\n        If the specified time series do not share any times for which features can be constructed.\n    ValueError\n        If no lags are specified, or if any of the specified lag values are non-negative.\n    ValueError\n        If any of the series are too short to create features for the requested lag values.\n    ValueError\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\n    \"\"\"\n    (X, _, times, _) = create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=False, concatenate=concatenate)\n    return (X, times)",
        "mutated": [
            "def create_lagged_prediction_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Sequence[pd.Index]]:\n    if False:\n        i = 10\n    \"\\n    Creates the features array `X` to produce a series of prediction from an already-trained regression model; the\\n    time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use\\n        values *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags\\n        values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` should be returned as a single `np.ndarray`, instead of as a\\n        `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and `concatenate = False`,\\n        `X` will be a list whose `i`th element corresponds to the feature matrix or label array formed by the `i`th\\n        `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True` when\\n        `Sequence[TimeSeries]` are provided, then `X` will be an array created by concatenating all of the feature\\n        arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features for the requested lag values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    (X, _, times, _) = create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=False, concatenate=concatenate)\n    return (X, times)",
            "def create_lagged_prediction_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Sequence[pd.Index]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Creates the features array `X` to produce a series of prediction from an already-trained regression model; the\\n    time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use\\n        values *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags\\n        values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` should be returned as a single `np.ndarray`, instead of as a\\n        `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and `concatenate = False`,\\n        `X` will be a list whose `i`th element corresponds to the feature matrix or label array formed by the `i`th\\n        `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True` when\\n        `Sequence[TimeSeries]` are provided, then `X` will be an array created by concatenating all of the feature\\n        arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features for the requested lag values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    (X, _, times, _) = create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=False, concatenate=concatenate)\n    return (X, times)",
            "def create_lagged_prediction_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Sequence[pd.Index]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Creates the features array `X` to produce a series of prediction from an already-trained regression model; the\\n    time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use\\n        values *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags\\n        values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` should be returned as a single `np.ndarray`, instead of as a\\n        `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and `concatenate = False`,\\n        `X` will be a list whose `i`th element corresponds to the feature matrix or label array formed by the `i`th\\n        `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True` when\\n        `Sequence[TimeSeries]` are provided, then `X` will be an array created by concatenating all of the feature\\n        arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features for the requested lag values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    (X, _, times, _) = create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=False, concatenate=concatenate)\n    return (X, times)",
            "def create_lagged_prediction_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Sequence[pd.Index]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Creates the features array `X` to produce a series of prediction from an already-trained regression model; the\\n    time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use\\n        values *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags\\n        values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` should be returned as a single `np.ndarray`, instead of as a\\n        `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and `concatenate = False`,\\n        `X` will be a list whose `i`th element corresponds to the feature matrix or label array formed by the `i`th\\n        `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True` when\\n        `Sequence[TimeSeries]` are provided, then `X` will be an array created by concatenating all of the feature\\n        arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features for the requested lag values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    (X, _, times, _) = create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=False, concatenate=concatenate)\n    return (X, times)",
            "def create_lagged_prediction_data(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, uses_static_covariates: bool=True, last_static_covariates_shape: Optional[Tuple[int, int]]=None, max_samples_per_ts: Optional[int]=None, check_inputs: bool=True, use_moving_windows: bool=True, concatenate: bool=True) -> Tuple[ArrayOrArraySequence, Sequence[pd.Index]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Creates the features array `X` to produce a series of prediction from an already-trained regression model; the\\n    time index values of each observation is also returned.\\n\\n    Notes\\n    -----\\n    This function is simply a wrapper around `create_lagged_data`; for further details on the structure of `X`, please\\n    refer to `help(create_lagged_data)`.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`. Each lag value is assumed to be negative (e.g.\\n        `lags = [-3, -1]` will extract `target_series` values which are 3 timesteps and 1 timestep away from\\n        the current value). If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the target series.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features. Like `lags`, each lag value is assumed to\\n        be less than or equal to -1. If the lags are provided as a dictionary, the lags values are specific to each\\n        component in the past covariates series.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features. Unlike `lags` and `lags_past_covariates`,\\n        `lags_future_covariates` values can be positive (i.e. use values *after* time `t` to predict target at\\n        time `t`), zero (i.e. use values *at* time `t` to predict target at time `t`), and/or negative (i.e. use\\n        values *before* time `t` to predict target at time `t`). If the lags are provided as a dictionary, the lags\\n        values are specific to each component in the future covariates series.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all target series.\\n    last_static_covariates_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n    max_samples_per_ts\\n        Optionally, the maximum number of samples to be drawn for training/validation; only the most recent\\n        samples are kept. In theory, specifying a smaller `max_samples_per_ts` should reduce computation time,\\n        especially in cases where many observations could be generated.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    use_moving_windows\\n        Optionally, specifies that the 'moving window' method should be used to construct `X` and `y` if all of the\\n        provided series are of the same frequency. If `use_moving_windows = False`, the 'time intersection' method\\n        will always be used, even when all of the provided series are of the same frequency. In general, setting\\n        to `True` results in faster tabularization at the potential cost of higher memory usage. See Notes for further\\n        details.\\n    concatenate\\n        Optionally, specifies that `X` should be returned as a single `np.ndarray`, instead of as a\\n        `Sequence[np.ndarray]`. If each series input is specified as a `Sequence[TimeSeries]` and `concatenate = False`,\\n        `X` will be a list whose `i`th element corresponds to the feature matrix or label array formed by the `i`th\\n        `TimeSeries` in each `Sequence[TimeSeries]` input. Conversely, if `concatenate = True` when\\n        `Sequence[TimeSeries]` are provided, then `X` will be an array created by concatenating all of the feature\\n        arrays formed by each `TimeSeries` along the `0`th axis. Note that `times` is still returned as\\n        `Sequence[pd.Index]`, even when `concatenate = True`.\\n\\n    Returns\\n    -------\\n    X\\n        The constructed features array(s), with shape `(n_observations, n_lagged_features, n_samples)`.\\n        If the series inputs were specified as `Sequence[TimeSeries]` and `concatenate = False`, then `X`\\n        is returned as a `Sequence[np.array]`; otherwise, `X` is returned as a single `np.array`.\\n    times\\n        The `time_index` of each observation in `X` and `y`, returned as a `Sequence` of `pd.Index`es.\\n        If the series inputs were specified as `Sequence[TimeSeries]`, then the `i`th list element\\n        gives the times of those observations formed using the `i`th `TimeSeries` object in each\\n        `Sequence`. Otherwise, if the series inputs were specified as `TimeSeries`, the only\\n        element is the times of those observations formed from the lone `TimeSeries` inputs.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If the specified time series do not share any times for which features can be constructed.\\n    ValueError\\n        If no lags are specified, or if any of the specified lag values are non-negative.\\n    ValueError\\n        If any of the series are too short to create features for the requested lag values.\\n    ValueError\\n        If the provided series do not share the same type of `time_index` (e.g. `target_series` uses a\\n        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\\n    \"\n    (X, _, times, _) = create_lagged_data(target_series=target_series, past_covariates=past_covariates, future_covariates=future_covariates, lags=lags, lags_past_covariates=lags_past_covariates, lags_future_covariates=lags_future_covariates, uses_static_covariates=uses_static_covariates, last_static_covariates_shape=last_static_covariates_shape, max_samples_per_ts=max_samples_per_ts, check_inputs=check_inputs, use_moving_windows=use_moving_windows, is_training=False, concatenate=concatenate)\n    return (X, times)"
        ]
    },
    {
        "func_name": "add_static_covariates_to_lagged_data",
        "original": "def add_static_covariates_to_lagged_data(features: Union[np.ndarray, Sequence[np.ndarray]], target_series: Union[TimeSeries, Sequence[TimeSeries]], uses_static_covariates: bool=True, last_shape: Optional[Tuple[int, int]]=None) -> Union[np.ndarray, Sequence[np.ndarray]]:\n    \"\"\"\n    Add static covariates to the features' table for RegressionModels.\n    If `uses_static_covariates=True`, all target series used in `fit()` and `predict()` must have static\n    covariates with identical dimensionality. Otherwise, will not consider static covariates.\n\n    The static covariates are added to the right of the lagged features following the convention:\n    with a 2 component series, and 2 static covariates per component ->\n    scov_1_comp_1 | scov_1_comp_2 | scov_2_comp_1 | scov_2_comp_2\n\n    Parameters\n    ----------\n    features\n        The features' numpy array(s) to which the static covariates will be added. Can either be a lone feature\n        matrix or a `Sequence` of feature matrices; in the latter case, static covariates will be appended to\n        each feature matrix in this `Sequence`.\n    target_series\n        The target series from which to read the static covariates.\n    uses_static_covariates\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\n        have identical shapes across all of target series.\n    last_shape\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\n        `uses_static_covariates` is ``False``.\n\n    Returns\n    -------\n    (features, last_shape)\n        The features' array(s) with appended static covariates columns. If the `features` input was passed as a\n        `Sequence` of `np.array`s, then a `Sequence` is also returned; if `features` was passed as an `np.array`,\n        a `np.array` is returned.\n        `last_shape` is the shape of the static covariates.\n\n    \"\"\"\n    if not uses_static_covariates:\n        return (features, last_shape)\n    input_not_list = not isinstance(features, Sequence)\n    if input_not_list:\n        features = [features]\n    target_series = series2seq(target_series)\n    for (idx, ts) in enumerate(target_series):\n        if not ts.has_static_covariates:\n            raise_log(ValueError('Static covariates mismatch across the sequence of target series. Some of the series contain static covariates and others do not.'), logger)\n        else:\n            if last_shape is None:\n                last_shape = ts.static_covariates.shape\n            if ts.static_covariates.shape != last_shape:\n                raise_log(ValueError('Static covariates dimension mismatch across the sequence of target series. The static covariates must have the same number of columns and rows across all target series.'), logger)\n            static_covs = ts.static_covariates.values.flatten(order='F')\n            shape_out = (len(features[idx]), len(static_covs)) if len(features[idx].shape) == 2 else (len(features[idx]), len(static_covs), 1)\n            features[idx] = np.hstack([features[idx], np.broadcast_to(static_covs, shape_out[:2]).reshape(shape_out)])\n    if input_not_list:\n        features = features[0]\n    return (features, last_shape)",
        "mutated": [
            "def add_static_covariates_to_lagged_data(features: Union[np.ndarray, Sequence[np.ndarray]], target_series: Union[TimeSeries, Sequence[TimeSeries]], uses_static_covariates: bool=True, last_shape: Optional[Tuple[int, int]]=None) -> Union[np.ndarray, Sequence[np.ndarray]]:\n    if False:\n        i = 10\n    \"\\n    Add static covariates to the features' table for RegressionModels.\\n    If `uses_static_covariates=True`, all target series used in `fit()` and `predict()` must have static\\n    covariates with identical dimensionality. Otherwise, will not consider static covariates.\\n\\n    The static covariates are added to the right of the lagged features following the convention:\\n    with a 2 component series, and 2 static covariates per component ->\\n    scov_1_comp_1 | scov_1_comp_2 | scov_2_comp_1 | scov_2_comp_2\\n\\n    Parameters\\n    ----------\\n    features\\n        The features' numpy array(s) to which the static covariates will be added. Can either be a lone feature\\n        matrix or a `Sequence` of feature matrices; in the latter case, static covariates will be appended to\\n        each feature matrix in this `Sequence`.\\n    target_series\\n        The target series from which to read the static covariates.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all of target series.\\n    last_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n\\n    Returns\\n    -------\\n    (features, last_shape)\\n        The features' array(s) with appended static covariates columns. If the `features` input was passed as a\\n        `Sequence` of `np.array`s, then a `Sequence` is also returned; if `features` was passed as an `np.array`,\\n        a `np.array` is returned.\\n        `last_shape` is the shape of the static covariates.\\n\\n    \"\n    if not uses_static_covariates:\n        return (features, last_shape)\n    input_not_list = not isinstance(features, Sequence)\n    if input_not_list:\n        features = [features]\n    target_series = series2seq(target_series)\n    for (idx, ts) in enumerate(target_series):\n        if not ts.has_static_covariates:\n            raise_log(ValueError('Static covariates mismatch across the sequence of target series. Some of the series contain static covariates and others do not.'), logger)\n        else:\n            if last_shape is None:\n                last_shape = ts.static_covariates.shape\n            if ts.static_covariates.shape != last_shape:\n                raise_log(ValueError('Static covariates dimension mismatch across the sequence of target series. The static covariates must have the same number of columns and rows across all target series.'), logger)\n            static_covs = ts.static_covariates.values.flatten(order='F')\n            shape_out = (len(features[idx]), len(static_covs)) if len(features[idx].shape) == 2 else (len(features[idx]), len(static_covs), 1)\n            features[idx] = np.hstack([features[idx], np.broadcast_to(static_covs, shape_out[:2]).reshape(shape_out)])\n    if input_not_list:\n        features = features[0]\n    return (features, last_shape)",
            "def add_static_covariates_to_lagged_data(features: Union[np.ndarray, Sequence[np.ndarray]], target_series: Union[TimeSeries, Sequence[TimeSeries]], uses_static_covariates: bool=True, last_shape: Optional[Tuple[int, int]]=None) -> Union[np.ndarray, Sequence[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Add static covariates to the features' table for RegressionModels.\\n    If `uses_static_covariates=True`, all target series used in `fit()` and `predict()` must have static\\n    covariates with identical dimensionality. Otherwise, will not consider static covariates.\\n\\n    The static covariates are added to the right of the lagged features following the convention:\\n    with a 2 component series, and 2 static covariates per component ->\\n    scov_1_comp_1 | scov_1_comp_2 | scov_2_comp_1 | scov_2_comp_2\\n\\n    Parameters\\n    ----------\\n    features\\n        The features' numpy array(s) to which the static covariates will be added. Can either be a lone feature\\n        matrix or a `Sequence` of feature matrices; in the latter case, static covariates will be appended to\\n        each feature matrix in this `Sequence`.\\n    target_series\\n        The target series from which to read the static covariates.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all of target series.\\n    last_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n\\n    Returns\\n    -------\\n    (features, last_shape)\\n        The features' array(s) with appended static covariates columns. If the `features` input was passed as a\\n        `Sequence` of `np.array`s, then a `Sequence` is also returned; if `features` was passed as an `np.array`,\\n        a `np.array` is returned.\\n        `last_shape` is the shape of the static covariates.\\n\\n    \"\n    if not uses_static_covariates:\n        return (features, last_shape)\n    input_not_list = not isinstance(features, Sequence)\n    if input_not_list:\n        features = [features]\n    target_series = series2seq(target_series)\n    for (idx, ts) in enumerate(target_series):\n        if not ts.has_static_covariates:\n            raise_log(ValueError('Static covariates mismatch across the sequence of target series. Some of the series contain static covariates and others do not.'), logger)\n        else:\n            if last_shape is None:\n                last_shape = ts.static_covariates.shape\n            if ts.static_covariates.shape != last_shape:\n                raise_log(ValueError('Static covariates dimension mismatch across the sequence of target series. The static covariates must have the same number of columns and rows across all target series.'), logger)\n            static_covs = ts.static_covariates.values.flatten(order='F')\n            shape_out = (len(features[idx]), len(static_covs)) if len(features[idx].shape) == 2 else (len(features[idx]), len(static_covs), 1)\n            features[idx] = np.hstack([features[idx], np.broadcast_to(static_covs, shape_out[:2]).reshape(shape_out)])\n    if input_not_list:\n        features = features[0]\n    return (features, last_shape)",
            "def add_static_covariates_to_lagged_data(features: Union[np.ndarray, Sequence[np.ndarray]], target_series: Union[TimeSeries, Sequence[TimeSeries]], uses_static_covariates: bool=True, last_shape: Optional[Tuple[int, int]]=None) -> Union[np.ndarray, Sequence[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Add static covariates to the features' table for RegressionModels.\\n    If `uses_static_covariates=True`, all target series used in `fit()` and `predict()` must have static\\n    covariates with identical dimensionality. Otherwise, will not consider static covariates.\\n\\n    The static covariates are added to the right of the lagged features following the convention:\\n    with a 2 component series, and 2 static covariates per component ->\\n    scov_1_comp_1 | scov_1_comp_2 | scov_2_comp_1 | scov_2_comp_2\\n\\n    Parameters\\n    ----------\\n    features\\n        The features' numpy array(s) to which the static covariates will be added. Can either be a lone feature\\n        matrix or a `Sequence` of feature matrices; in the latter case, static covariates will be appended to\\n        each feature matrix in this `Sequence`.\\n    target_series\\n        The target series from which to read the static covariates.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all of target series.\\n    last_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n\\n    Returns\\n    -------\\n    (features, last_shape)\\n        The features' array(s) with appended static covariates columns. If the `features` input was passed as a\\n        `Sequence` of `np.array`s, then a `Sequence` is also returned; if `features` was passed as an `np.array`,\\n        a `np.array` is returned.\\n        `last_shape` is the shape of the static covariates.\\n\\n    \"\n    if not uses_static_covariates:\n        return (features, last_shape)\n    input_not_list = not isinstance(features, Sequence)\n    if input_not_list:\n        features = [features]\n    target_series = series2seq(target_series)\n    for (idx, ts) in enumerate(target_series):\n        if not ts.has_static_covariates:\n            raise_log(ValueError('Static covariates mismatch across the sequence of target series. Some of the series contain static covariates and others do not.'), logger)\n        else:\n            if last_shape is None:\n                last_shape = ts.static_covariates.shape\n            if ts.static_covariates.shape != last_shape:\n                raise_log(ValueError('Static covariates dimension mismatch across the sequence of target series. The static covariates must have the same number of columns and rows across all target series.'), logger)\n            static_covs = ts.static_covariates.values.flatten(order='F')\n            shape_out = (len(features[idx]), len(static_covs)) if len(features[idx].shape) == 2 else (len(features[idx]), len(static_covs), 1)\n            features[idx] = np.hstack([features[idx], np.broadcast_to(static_covs, shape_out[:2]).reshape(shape_out)])\n    if input_not_list:\n        features = features[0]\n    return (features, last_shape)",
            "def add_static_covariates_to_lagged_data(features: Union[np.ndarray, Sequence[np.ndarray]], target_series: Union[TimeSeries, Sequence[TimeSeries]], uses_static_covariates: bool=True, last_shape: Optional[Tuple[int, int]]=None) -> Union[np.ndarray, Sequence[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Add static covariates to the features' table for RegressionModels.\\n    If `uses_static_covariates=True`, all target series used in `fit()` and `predict()` must have static\\n    covariates with identical dimensionality. Otherwise, will not consider static covariates.\\n\\n    The static covariates are added to the right of the lagged features following the convention:\\n    with a 2 component series, and 2 static covariates per component ->\\n    scov_1_comp_1 | scov_1_comp_2 | scov_2_comp_1 | scov_2_comp_2\\n\\n    Parameters\\n    ----------\\n    features\\n        The features' numpy array(s) to which the static covariates will be added. Can either be a lone feature\\n        matrix or a `Sequence` of feature matrices; in the latter case, static covariates will be appended to\\n        each feature matrix in this `Sequence`.\\n    target_series\\n        The target series from which to read the static covariates.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all of target series.\\n    last_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n\\n    Returns\\n    -------\\n    (features, last_shape)\\n        The features' array(s) with appended static covariates columns. If the `features` input was passed as a\\n        `Sequence` of `np.array`s, then a `Sequence` is also returned; if `features` was passed as an `np.array`,\\n        a `np.array` is returned.\\n        `last_shape` is the shape of the static covariates.\\n\\n    \"\n    if not uses_static_covariates:\n        return (features, last_shape)\n    input_not_list = not isinstance(features, Sequence)\n    if input_not_list:\n        features = [features]\n    target_series = series2seq(target_series)\n    for (idx, ts) in enumerate(target_series):\n        if not ts.has_static_covariates:\n            raise_log(ValueError('Static covariates mismatch across the sequence of target series. Some of the series contain static covariates and others do not.'), logger)\n        else:\n            if last_shape is None:\n                last_shape = ts.static_covariates.shape\n            if ts.static_covariates.shape != last_shape:\n                raise_log(ValueError('Static covariates dimension mismatch across the sequence of target series. The static covariates must have the same number of columns and rows across all target series.'), logger)\n            static_covs = ts.static_covariates.values.flatten(order='F')\n            shape_out = (len(features[idx]), len(static_covs)) if len(features[idx].shape) == 2 else (len(features[idx]), len(static_covs), 1)\n            features[idx] = np.hstack([features[idx], np.broadcast_to(static_covs, shape_out[:2]).reshape(shape_out)])\n    if input_not_list:\n        features = features[0]\n    return (features, last_shape)",
            "def add_static_covariates_to_lagged_data(features: Union[np.ndarray, Sequence[np.ndarray]], target_series: Union[TimeSeries, Sequence[TimeSeries]], uses_static_covariates: bool=True, last_shape: Optional[Tuple[int, int]]=None) -> Union[np.ndarray, Sequence[np.ndarray]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Add static covariates to the features' table for RegressionModels.\\n    If `uses_static_covariates=True`, all target series used in `fit()` and `predict()` must have static\\n    covariates with identical dimensionality. Otherwise, will not consider static covariates.\\n\\n    The static covariates are added to the right of the lagged features following the convention:\\n    with a 2 component series, and 2 static covariates per component ->\\n    scov_1_comp_1 | scov_1_comp_2 | scov_2_comp_1 | scov_2_comp_2\\n\\n    Parameters\\n    ----------\\n    features\\n        The features' numpy array(s) to which the static covariates will be added. Can either be a lone feature\\n        matrix or a `Sequence` of feature matrices; in the latter case, static covariates will be appended to\\n        each feature matrix in this `Sequence`.\\n    target_series\\n        The target series from which to read the static covariates.\\n    uses_static_covariates\\n        Whether the model uses/expects static covariates. If `True`, it enforces that static covariates must\\n        have identical shapes across all of target series.\\n    last_shape\\n        Optionally, the last observed shape of the static covariates. This is ``None`` before fitting, or when\\n        `uses_static_covariates` is ``False``.\\n\\n    Returns\\n    -------\\n    (features, last_shape)\\n        The features' array(s) with appended static covariates columns. If the `features` input was passed as a\\n        `Sequence` of `np.array`s, then a `Sequence` is also returned; if `features` was passed as an `np.array`,\\n        a `np.array` is returned.\\n        `last_shape` is the shape of the static covariates.\\n\\n    \"\n    if not uses_static_covariates:\n        return (features, last_shape)\n    input_not_list = not isinstance(features, Sequence)\n    if input_not_list:\n        features = [features]\n    target_series = series2seq(target_series)\n    for (idx, ts) in enumerate(target_series):\n        if not ts.has_static_covariates:\n            raise_log(ValueError('Static covariates mismatch across the sequence of target series. Some of the series contain static covariates and others do not.'), logger)\n        else:\n            if last_shape is None:\n                last_shape = ts.static_covariates.shape\n            if ts.static_covariates.shape != last_shape:\n                raise_log(ValueError('Static covariates dimension mismatch across the sequence of target series. The static covariates must have the same number of columns and rows across all target series.'), logger)\n            static_covs = ts.static_covariates.values.flatten(order='F')\n            shape_out = (len(features[idx]), len(static_covs)) if len(features[idx].shape) == 2 else (len(features[idx]), len(static_covs), 1)\n            features[idx] = np.hstack([features[idx], np.broadcast_to(static_covs, shape_out[:2]).reshape(shape_out)])\n    if input_not_list:\n        features = features[0]\n    return (features, last_shape)"
        ]
    },
    {
        "func_name": "create_lagged_component_names",
        "original": "def create_lagged_component_names(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, concatenate: bool=True, use_static_covariates: bool=False) -> Tuple[List[List[str]], List[List[str]]]:\n    \"\"\"\n    Helper function called to retrieve the name of the features and labels arrays created with\n    `create_lagged_data()`. The order of the features is the following:\n\n    Along the `n_lagged_features` axis, `X` has the following structure:\n        lagged_target | lagged_past_covariates | lagged_future_covariates | static covariates\n\n    For `*_lags=[-2,-1]` and `*_series.n_components = 2` (lags shared across all the components),\n    each `lagged_*` has the following structure (grouped by lags):\n        comp0_*_lag-2 | comp1_*_lag-2 | comp0_*_lag_-1 | comp1_*_lag-1\n    For `*_lags={'comp0':[-2, -1], 'comp1':[-5, -3]}` and `*_series.n_components = 2` (component-\n    specific lags), each `lagged_*` has the following structure (grouped by components):\n        comp0_*_lag-2 | comp0_*_lag-1 | comp1_*_lag_-5 | comp1_*_lag-3\n\n    and for static covariates (2 static covariates acting on 2 target components):\n        cov0_*_target_comp0 | cov0_*_target_comp1 | cov1_*_target_comp0 | cov1_*_target_comp1\n\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\n    `target_series.n_components=2`):\n        comp0_target_lag0 | comp1_target_lag0 | ... | comp0_target_lag3 | comp1_target_lag3\n\n    Note : will only use the component names of the first series from `target_series`, `past_covariates`,\n    `future_covariates`, and static_covariates.\n\n    The naming convention for target, past and future covariates is: ``\"{name}_{type}_lag{i}\"``, where:\n\n        - ``{name}`` the component name of the (first) series\n        - ``{type}`` is the feature type, one of \"target\", \"pastcov\", and \"futcov\"\n        - ``{i}`` is the lag value\n\n    The naming convention for static covariates is: ``\"{name}_statcov_target_{comp}\"``, where:\n\n        - ``{name}`` the static covariate name of the (first) series\n        - ``{comp}`` the target component name of the (first) that the static covariate act on. If the static\n            covariate acts globally on a multivariate target series, will show \"global\".\n\n    Returns\n    -------\n    features_cols_name\n        The names of the lagged features in the `X` array generated by `create_lagged_data()`\n        as a `List[str]`. If `concatenate=True`, also contains the columns names for\n        the `y` array (on the right).\n    labels_cols_name\n        The names of the lagged features in the `y` array generated by `create_lagged_data()`\n         as a `List[str]`.\n\n    See Also\n    --------\n        tabularization.create_lagged_data : generate the lagged features and labels as (list of) Arrays.\n    \"\"\"\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    lagged_feature_names = []\n    label_feature_names = []\n    for (variate, variate_lags, variate_type) in zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], ['target', 'pastcov', 'futcov']):\n        if variate is None or variate_lags is None:\n            continue\n        components = get_single_series(variate).components.tolist()\n        if isinstance(variate_lags, dict):\n            for name in components:\n                lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags[name]]\n        else:\n            lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags for name in components]\n        if variate_type == 'target' and lags:\n            label_feature_names = [f'{name}_target_lag{lag}' for lag in range(output_chunk_length) for name in components]\n    if use_static_covariates:\n        static_covs = get_single_series(target_series).static_covariates\n        names = static_covs.columns.tolist()\n        comps = static_covs.index.tolist()\n        lagged_feature_names += [f'{name}_statcov_target_{comp}' for name in names for comp in comps]\n    if concatenate:\n        lagged_feature_names += label_feature_names\n    return (lagged_feature_names, label_feature_names)",
        "mutated": [
            "def create_lagged_component_names(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, concatenate: bool=True, use_static_covariates: bool=False) -> Tuple[List[List[str]], List[List[str]]]:\n    if False:\n        i = 10\n    '\\n    Helper function called to retrieve the name of the features and labels arrays created with\\n    `create_lagged_data()`. The order of the features is the following:\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure:\\n        lagged_target | lagged_past_covariates | lagged_future_covariates | static covariates\\n\\n    For `*_lags=[-2,-1]` and `*_series.n_components = 2` (lags shared across all the components),\\n    each `lagged_*` has the following structure (grouped by lags):\\n        comp0_*_lag-2 | comp1_*_lag-2 | comp0_*_lag_-1 | comp1_*_lag-1\\n    For `*_lags={\\'comp0\\':[-2, -1], \\'comp1\\':[-5, -3]}` and `*_series.n_components = 2` (component-\\n    specific lags), each `lagged_*` has the following structure (grouped by components):\\n        comp0_*_lag-2 | comp0_*_lag-1 | comp1_*_lag_-5 | comp1_*_lag-3\\n\\n    and for static covariates (2 static covariates acting on 2 target components):\\n        cov0_*_target_comp0 | cov0_*_target_comp1 | cov1_*_target_comp0 | cov1_*_target_comp1\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        comp0_target_lag0 | comp1_target_lag0 | ... | comp0_target_lag3 | comp1_target_lag3\\n\\n    Note : will only use the component names of the first series from `target_series`, `past_covariates`,\\n    `future_covariates`, and static_covariates.\\n\\n    The naming convention for target, past and future covariates is: ``\"{name}_{type}_lag{i}\"``, where:\\n\\n        - ``{name}`` the component name of the (first) series\\n        - ``{type}`` is the feature type, one of \"target\", \"pastcov\", and \"futcov\"\\n        - ``{i}`` is the lag value\\n\\n    The naming convention for static covariates is: ``\"{name}_statcov_target_{comp}\"``, where:\\n\\n        - ``{name}`` the static covariate name of the (first) series\\n        - ``{comp}`` the target component name of the (first) that the static covariate act on. If the static\\n            covariate acts globally on a multivariate target series, will show \"global\".\\n\\n    Returns\\n    -------\\n    features_cols_name\\n        The names of the lagged features in the `X` array generated by `create_lagged_data()`\\n        as a `List[str]`. If `concatenate=True`, also contains the columns names for\\n        the `y` array (on the right).\\n    labels_cols_name\\n        The names of the lagged features in the `y` array generated by `create_lagged_data()`\\n         as a `List[str]`.\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_data : generate the lagged features and labels as (list of) Arrays.\\n    '\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    lagged_feature_names = []\n    label_feature_names = []\n    for (variate, variate_lags, variate_type) in zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], ['target', 'pastcov', 'futcov']):\n        if variate is None or variate_lags is None:\n            continue\n        components = get_single_series(variate).components.tolist()\n        if isinstance(variate_lags, dict):\n            for name in components:\n                lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags[name]]\n        else:\n            lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags for name in components]\n        if variate_type == 'target' and lags:\n            label_feature_names = [f'{name}_target_lag{lag}' for lag in range(output_chunk_length) for name in components]\n    if use_static_covariates:\n        static_covs = get_single_series(target_series).static_covariates\n        names = static_covs.columns.tolist()\n        comps = static_covs.index.tolist()\n        lagged_feature_names += [f'{name}_statcov_target_{comp}' for name in names for comp in comps]\n    if concatenate:\n        lagged_feature_names += label_feature_names\n    return (lagged_feature_names, label_feature_names)",
            "def create_lagged_component_names(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, concatenate: bool=True, use_static_covariates: bool=False) -> Tuple[List[List[str]], List[List[str]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Helper function called to retrieve the name of the features and labels arrays created with\\n    `create_lagged_data()`. The order of the features is the following:\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure:\\n        lagged_target | lagged_past_covariates | lagged_future_covariates | static covariates\\n\\n    For `*_lags=[-2,-1]` and `*_series.n_components = 2` (lags shared across all the components),\\n    each `lagged_*` has the following structure (grouped by lags):\\n        comp0_*_lag-2 | comp1_*_lag-2 | comp0_*_lag_-1 | comp1_*_lag-1\\n    For `*_lags={\\'comp0\\':[-2, -1], \\'comp1\\':[-5, -3]}` and `*_series.n_components = 2` (component-\\n    specific lags), each `lagged_*` has the following structure (grouped by components):\\n        comp0_*_lag-2 | comp0_*_lag-1 | comp1_*_lag_-5 | comp1_*_lag-3\\n\\n    and for static covariates (2 static covariates acting on 2 target components):\\n        cov0_*_target_comp0 | cov0_*_target_comp1 | cov1_*_target_comp0 | cov1_*_target_comp1\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        comp0_target_lag0 | comp1_target_lag0 | ... | comp0_target_lag3 | comp1_target_lag3\\n\\n    Note : will only use the component names of the first series from `target_series`, `past_covariates`,\\n    `future_covariates`, and static_covariates.\\n\\n    The naming convention for target, past and future covariates is: ``\"{name}_{type}_lag{i}\"``, where:\\n\\n        - ``{name}`` the component name of the (first) series\\n        - ``{type}`` is the feature type, one of \"target\", \"pastcov\", and \"futcov\"\\n        - ``{i}`` is the lag value\\n\\n    The naming convention for static covariates is: ``\"{name}_statcov_target_{comp}\"``, where:\\n\\n        - ``{name}`` the static covariate name of the (first) series\\n        - ``{comp}`` the target component name of the (first) that the static covariate act on. If the static\\n            covariate acts globally on a multivariate target series, will show \"global\".\\n\\n    Returns\\n    -------\\n    features_cols_name\\n        The names of the lagged features in the `X` array generated by `create_lagged_data()`\\n        as a `List[str]`. If `concatenate=True`, also contains the columns names for\\n        the `y` array (on the right).\\n    labels_cols_name\\n        The names of the lagged features in the `y` array generated by `create_lagged_data()`\\n         as a `List[str]`.\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_data : generate the lagged features and labels as (list of) Arrays.\\n    '\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    lagged_feature_names = []\n    label_feature_names = []\n    for (variate, variate_lags, variate_type) in zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], ['target', 'pastcov', 'futcov']):\n        if variate is None or variate_lags is None:\n            continue\n        components = get_single_series(variate).components.tolist()\n        if isinstance(variate_lags, dict):\n            for name in components:\n                lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags[name]]\n        else:\n            lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags for name in components]\n        if variate_type == 'target' and lags:\n            label_feature_names = [f'{name}_target_lag{lag}' for lag in range(output_chunk_length) for name in components]\n    if use_static_covariates:\n        static_covs = get_single_series(target_series).static_covariates\n        names = static_covs.columns.tolist()\n        comps = static_covs.index.tolist()\n        lagged_feature_names += [f'{name}_statcov_target_{comp}' for name in names for comp in comps]\n    if concatenate:\n        lagged_feature_names += label_feature_names\n    return (lagged_feature_names, label_feature_names)",
            "def create_lagged_component_names(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, concatenate: bool=True, use_static_covariates: bool=False) -> Tuple[List[List[str]], List[List[str]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Helper function called to retrieve the name of the features and labels arrays created with\\n    `create_lagged_data()`. The order of the features is the following:\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure:\\n        lagged_target | lagged_past_covariates | lagged_future_covariates | static covariates\\n\\n    For `*_lags=[-2,-1]` and `*_series.n_components = 2` (lags shared across all the components),\\n    each `lagged_*` has the following structure (grouped by lags):\\n        comp0_*_lag-2 | comp1_*_lag-2 | comp0_*_lag_-1 | comp1_*_lag-1\\n    For `*_lags={\\'comp0\\':[-2, -1], \\'comp1\\':[-5, -3]}` and `*_series.n_components = 2` (component-\\n    specific lags), each `lagged_*` has the following structure (grouped by components):\\n        comp0_*_lag-2 | comp0_*_lag-1 | comp1_*_lag_-5 | comp1_*_lag-3\\n\\n    and for static covariates (2 static covariates acting on 2 target components):\\n        cov0_*_target_comp0 | cov0_*_target_comp1 | cov1_*_target_comp0 | cov1_*_target_comp1\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        comp0_target_lag0 | comp1_target_lag0 | ... | comp0_target_lag3 | comp1_target_lag3\\n\\n    Note : will only use the component names of the first series from `target_series`, `past_covariates`,\\n    `future_covariates`, and static_covariates.\\n\\n    The naming convention for target, past and future covariates is: ``\"{name}_{type}_lag{i}\"``, where:\\n\\n        - ``{name}`` the component name of the (first) series\\n        - ``{type}`` is the feature type, one of \"target\", \"pastcov\", and \"futcov\"\\n        - ``{i}`` is the lag value\\n\\n    The naming convention for static covariates is: ``\"{name}_statcov_target_{comp}\"``, where:\\n\\n        - ``{name}`` the static covariate name of the (first) series\\n        - ``{comp}`` the target component name of the (first) that the static covariate act on. If the static\\n            covariate acts globally on a multivariate target series, will show \"global\".\\n\\n    Returns\\n    -------\\n    features_cols_name\\n        The names of the lagged features in the `X` array generated by `create_lagged_data()`\\n        as a `List[str]`. If `concatenate=True`, also contains the columns names for\\n        the `y` array (on the right).\\n    labels_cols_name\\n        The names of the lagged features in the `y` array generated by `create_lagged_data()`\\n         as a `List[str]`.\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_data : generate the lagged features and labels as (list of) Arrays.\\n    '\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    lagged_feature_names = []\n    label_feature_names = []\n    for (variate, variate_lags, variate_type) in zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], ['target', 'pastcov', 'futcov']):\n        if variate is None or variate_lags is None:\n            continue\n        components = get_single_series(variate).components.tolist()\n        if isinstance(variate_lags, dict):\n            for name in components:\n                lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags[name]]\n        else:\n            lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags for name in components]\n        if variate_type == 'target' and lags:\n            label_feature_names = [f'{name}_target_lag{lag}' for lag in range(output_chunk_length) for name in components]\n    if use_static_covariates:\n        static_covs = get_single_series(target_series).static_covariates\n        names = static_covs.columns.tolist()\n        comps = static_covs.index.tolist()\n        lagged_feature_names += [f'{name}_statcov_target_{comp}' for name in names for comp in comps]\n    if concatenate:\n        lagged_feature_names += label_feature_names\n    return (lagged_feature_names, label_feature_names)",
            "def create_lagged_component_names(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, concatenate: bool=True, use_static_covariates: bool=False) -> Tuple[List[List[str]], List[List[str]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Helper function called to retrieve the name of the features and labels arrays created with\\n    `create_lagged_data()`. The order of the features is the following:\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure:\\n        lagged_target | lagged_past_covariates | lagged_future_covariates | static covariates\\n\\n    For `*_lags=[-2,-1]` and `*_series.n_components = 2` (lags shared across all the components),\\n    each `lagged_*` has the following structure (grouped by lags):\\n        comp0_*_lag-2 | comp1_*_lag-2 | comp0_*_lag_-1 | comp1_*_lag-1\\n    For `*_lags={\\'comp0\\':[-2, -1], \\'comp1\\':[-5, -3]}` and `*_series.n_components = 2` (component-\\n    specific lags), each `lagged_*` has the following structure (grouped by components):\\n        comp0_*_lag-2 | comp0_*_lag-1 | comp1_*_lag_-5 | comp1_*_lag-3\\n\\n    and for static covariates (2 static covariates acting on 2 target components):\\n        cov0_*_target_comp0 | cov0_*_target_comp1 | cov1_*_target_comp0 | cov1_*_target_comp1\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        comp0_target_lag0 | comp1_target_lag0 | ... | comp0_target_lag3 | comp1_target_lag3\\n\\n    Note : will only use the component names of the first series from `target_series`, `past_covariates`,\\n    `future_covariates`, and static_covariates.\\n\\n    The naming convention for target, past and future covariates is: ``\"{name}_{type}_lag{i}\"``, where:\\n\\n        - ``{name}`` the component name of the (first) series\\n        - ``{type}`` is the feature type, one of \"target\", \"pastcov\", and \"futcov\"\\n        - ``{i}`` is the lag value\\n\\n    The naming convention for static covariates is: ``\"{name}_statcov_target_{comp}\"``, where:\\n\\n        - ``{name}`` the static covariate name of the (first) series\\n        - ``{comp}`` the target component name of the (first) that the static covariate act on. If the static\\n            covariate acts globally on a multivariate target series, will show \"global\".\\n\\n    Returns\\n    -------\\n    features_cols_name\\n        The names of the lagged features in the `X` array generated by `create_lagged_data()`\\n        as a `List[str]`. If `concatenate=True`, also contains the columns names for\\n        the `y` array (on the right).\\n    labels_cols_name\\n        The names of the lagged features in the `y` array generated by `create_lagged_data()`\\n         as a `List[str]`.\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_data : generate the lagged features and labels as (list of) Arrays.\\n    '\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    lagged_feature_names = []\n    label_feature_names = []\n    for (variate, variate_lags, variate_type) in zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], ['target', 'pastcov', 'futcov']):\n        if variate is None or variate_lags is None:\n            continue\n        components = get_single_series(variate).components.tolist()\n        if isinstance(variate_lags, dict):\n            for name in components:\n                lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags[name]]\n        else:\n            lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags for name in components]\n        if variate_type == 'target' and lags:\n            label_feature_names = [f'{name}_target_lag{lag}' for lag in range(output_chunk_length) for name in components]\n    if use_static_covariates:\n        static_covs = get_single_series(target_series).static_covariates\n        names = static_covs.columns.tolist()\n        comps = static_covs.index.tolist()\n        lagged_feature_names += [f'{name}_statcov_target_{comp}' for name in names for comp in comps]\n    if concatenate:\n        lagged_feature_names += label_feature_names\n    return (lagged_feature_names, label_feature_names)",
            "def create_lagged_component_names(target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, concatenate: bool=True, use_static_covariates: bool=False) -> Tuple[List[List[str]], List[List[str]]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Helper function called to retrieve the name of the features and labels arrays created with\\n    `create_lagged_data()`. The order of the features is the following:\\n\\n    Along the `n_lagged_features` axis, `X` has the following structure:\\n        lagged_target | lagged_past_covariates | lagged_future_covariates | static covariates\\n\\n    For `*_lags=[-2,-1]` and `*_series.n_components = 2` (lags shared across all the components),\\n    each `lagged_*` has the following structure (grouped by lags):\\n        comp0_*_lag-2 | comp1_*_lag-2 | comp0_*_lag_-1 | comp1_*_lag-1\\n    For `*_lags={\\'comp0\\':[-2, -1], \\'comp1\\':[-5, -3]}` and `*_series.n_components = 2` (component-\\n    specific lags), each `lagged_*` has the following structure (grouped by components):\\n        comp0_*_lag-2 | comp0_*_lag-1 | comp1_*_lag_-5 | comp1_*_lag-3\\n\\n    and for static covariates (2 static covariates acting on 2 target components):\\n        cov0_*_target_comp0 | cov0_*_target_comp1 | cov1_*_target_comp0 | cov1_*_target_comp1\\n\\n    Along the `n_lagged_labels` axis, `y` has the following structure (for `output_chunk_length=4` and\\n    `target_series.n_components=2`):\\n        comp0_target_lag0 | comp1_target_lag0 | ... | comp0_target_lag3 | comp1_target_lag3\\n\\n    Note : will only use the component names of the first series from `target_series`, `past_covariates`,\\n    `future_covariates`, and static_covariates.\\n\\n    The naming convention for target, past and future covariates is: ``\"{name}_{type}_lag{i}\"``, where:\\n\\n        - ``{name}`` the component name of the (first) series\\n        - ``{type}`` is the feature type, one of \"target\", \"pastcov\", and \"futcov\"\\n        - ``{i}`` is the lag value\\n\\n    The naming convention for static covariates is: ``\"{name}_statcov_target_{comp}\"``, where:\\n\\n        - ``{name}`` the static covariate name of the (first) series\\n        - ``{comp}`` the target component name of the (first) that the static covariate act on. If the static\\n            covariate acts globally on a multivariate target series, will show \"global\".\\n\\n    Returns\\n    -------\\n    features_cols_name\\n        The names of the lagged features in the `X` array generated by `create_lagged_data()`\\n        as a `List[str]`. If `concatenate=True`, also contains the columns names for\\n        the `y` array (on the right).\\n    labels_cols_name\\n        The names of the lagged features in the `y` array generated by `create_lagged_data()`\\n         as a `List[str]`.\\n\\n    See Also\\n    --------\\n        tabularization.create_lagged_data : generate the lagged features and labels as (list of) Arrays.\\n    '\n    target_series = series2seq(target_series)\n    past_covariates = series2seq(past_covariates)\n    future_covariates = series2seq(future_covariates)\n    lagged_feature_names = []\n    label_feature_names = []\n    for (variate, variate_lags, variate_type) in zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], ['target', 'pastcov', 'futcov']):\n        if variate is None or variate_lags is None:\n            continue\n        components = get_single_series(variate).components.tolist()\n        if isinstance(variate_lags, dict):\n            for name in components:\n                lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags[name]]\n        else:\n            lagged_feature_names += [f'{name}_{variate_type}_lag{lag}' for lag in variate_lags for name in components]\n        if variate_type == 'target' and lags:\n            label_feature_names = [f'{name}_target_lag{lag}' for lag in range(output_chunk_length) for name in components]\n    if use_static_covariates:\n        static_covs = get_single_series(target_series).static_covariates\n        names = static_covs.columns.tolist()\n        comps = static_covs.index.tolist()\n        lagged_feature_names += [f'{name}_statcov_target_{comp}' for name in names for comp in comps]\n    if concatenate:\n        lagged_feature_names += label_feature_names\n    return (lagged_feature_names, label_feature_names)"
        ]
    },
    {
        "func_name": "_create_lagged_data_by_moving_window",
        "original": "def _create_lagged_data_by_moving_window(target_series: Optional[TimeSeries], output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, pd.Index]:\n    \"\"\"\n    Helper function called by `create_lagged_data` that computes `X`, `y`, and `times` by\n    extracting 'moving windows' from each series using the `strided_moving_window`\n    function. More specifically, to extract the features of a particular series for an\n    arbitrary time `t`, a 'window' between times `t - max_lag` and `t - min_lag` is\n    extracted, where `max_lag` and `min_lag` are the largest and smallest magnitude lags\n    requested for that particular series. After extracting this window, the requested lag\n    values between these two minimum and maximum lag values can be extracted. Similarly,\n    the labels for time `t` are formed simply by extracting a window between times `t`\n    and `t + output_chunk_length - 1` from the target series. In both cases, the extracted\n    windows can then be reshaped into the correct shape. This approach can only be used if\n    we *can* assume that the specified series are all of the same frequency.\n    \"\"\"\n    (feature_times, min_lags, max_lags) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [max_lag is None for max_lag in max_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    time_bounds = get_shared_times_bounds(*feature_times)\n    raise_if(time_bounds is None, 'Specified series do not share any common times for which features can be created.')\n    freq = _get_freqs(target_series, past_covariates, future_covariates)[0]\n    if isinstance(time_bounds[0], int):\n        times = pd.RangeIndex(start=time_bounds[0], stop=time_bounds[1] + freq, step=freq)\n    else:\n        times = pd.date_range(start=time_bounds[0], end=time_bounds[1], freq=freq)\n    num_samples = len(times)\n    if num_samples > max_samples_per_ts:\n        times = times[-max_samples_per_ts:]\n        num_samples = max_samples_per_ts\n    start_time = times[0]\n    X = []\n    start_time_idx = None\n    target_start_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i, max_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags, max_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if is_target_series or series_and_lags_specified:\n            time_index_i = series_i.time_index\n            if not is_target_series and time_index_i[-1] < start_time:\n                if pd.to_timedelta(series_i.freq, errors='coerce') is not pd.NaT:\n                    start_time_idx = len(time_index_i) - 1 + (start_time - time_index_i[-1]) // series_i.freq\n                else:\n                    start_time_idx = len(time_index_i) - 1 + len(pd.date_range(start=time_index_i[-1] + series_i.freq, end=start_time, freq=series_i.freq))\n            elif not is_target_series and time_index_i[0] >= start_time:\n                start_time_idx = max_lag_i\n            else:\n                start_time_idx = np.searchsorted(time_index_i, start_time)\n        if series_and_lags_specified:\n            window_len = max_lag_i - min_lag_i + 1\n            first_window_start_idx = start_time_idx - max_lag_i\n            first_window_end_idx = first_window_start_idx + window_len\n            vals = series_i.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n            windows = strided_moving_window(vals, window_len, stride=1, axis=0, check_inputs=False)\n            if isinstance(lags_i, list):\n                lags_to_extract = np.array(lags_i, dtype=int) + min_lag_i - 1\n            else:\n                lags_to_extract = [np.array(comp_lags, dtype=int) + min_lag_i - 1 for comp_lags in lags_i.values()]\n            lagged_vals = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n            X.append(lagged_vals)\n        if is_target_series:\n            target_start_time_idx = start_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        first_window_start_idx = target_start_time_idx\n        first_window_end_idx = target_start_time_idx + output_chunk_length\n        vals = target_series.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n        windows = strided_moving_window(vals, window_len=output_chunk_length, stride=1, axis=0, check_inputs=False)\n        lags_to_extract = None if multi_models else -np.ones((1,), dtype=int)\n        y = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n    else:\n        y = None\n    return (X, y, times)",
        "mutated": [
            "def _create_lagged_data_by_moving_window(target_series: Optional[TimeSeries], output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, pd.Index]:\n    if False:\n        i = 10\n    \"\\n    Helper function called by `create_lagged_data` that computes `X`, `y`, and `times` by\\n    extracting 'moving windows' from each series using the `strided_moving_window`\\n    function. More specifically, to extract the features of a particular series for an\\n    arbitrary time `t`, a 'window' between times `t - max_lag` and `t - min_lag` is\\n    extracted, where `max_lag` and `min_lag` are the largest and smallest magnitude lags\\n    requested for that particular series. After extracting this window, the requested lag\\n    values between these two minimum and maximum lag values can be extracted. Similarly,\\n    the labels for time `t` are formed simply by extracting a window between times `t`\\n    and `t + output_chunk_length - 1` from the target series. In both cases, the extracted\\n    windows can then be reshaped into the correct shape. This approach can only be used if\\n    we *can* assume that the specified series are all of the same frequency.\\n    \"\n    (feature_times, min_lags, max_lags) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [max_lag is None for max_lag in max_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    time_bounds = get_shared_times_bounds(*feature_times)\n    raise_if(time_bounds is None, 'Specified series do not share any common times for which features can be created.')\n    freq = _get_freqs(target_series, past_covariates, future_covariates)[0]\n    if isinstance(time_bounds[0], int):\n        times = pd.RangeIndex(start=time_bounds[0], stop=time_bounds[1] + freq, step=freq)\n    else:\n        times = pd.date_range(start=time_bounds[0], end=time_bounds[1], freq=freq)\n    num_samples = len(times)\n    if num_samples > max_samples_per_ts:\n        times = times[-max_samples_per_ts:]\n        num_samples = max_samples_per_ts\n    start_time = times[0]\n    X = []\n    start_time_idx = None\n    target_start_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i, max_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags, max_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if is_target_series or series_and_lags_specified:\n            time_index_i = series_i.time_index\n            if not is_target_series and time_index_i[-1] < start_time:\n                if pd.to_timedelta(series_i.freq, errors='coerce') is not pd.NaT:\n                    start_time_idx = len(time_index_i) - 1 + (start_time - time_index_i[-1]) // series_i.freq\n                else:\n                    start_time_idx = len(time_index_i) - 1 + len(pd.date_range(start=time_index_i[-1] + series_i.freq, end=start_time, freq=series_i.freq))\n            elif not is_target_series and time_index_i[0] >= start_time:\n                start_time_idx = max_lag_i\n            else:\n                start_time_idx = np.searchsorted(time_index_i, start_time)\n        if series_and_lags_specified:\n            window_len = max_lag_i - min_lag_i + 1\n            first_window_start_idx = start_time_idx - max_lag_i\n            first_window_end_idx = first_window_start_idx + window_len\n            vals = series_i.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n            windows = strided_moving_window(vals, window_len, stride=1, axis=0, check_inputs=False)\n            if isinstance(lags_i, list):\n                lags_to_extract = np.array(lags_i, dtype=int) + min_lag_i - 1\n            else:\n                lags_to_extract = [np.array(comp_lags, dtype=int) + min_lag_i - 1 for comp_lags in lags_i.values()]\n            lagged_vals = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n            X.append(lagged_vals)\n        if is_target_series:\n            target_start_time_idx = start_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        first_window_start_idx = target_start_time_idx\n        first_window_end_idx = target_start_time_idx + output_chunk_length\n        vals = target_series.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n        windows = strided_moving_window(vals, window_len=output_chunk_length, stride=1, axis=0, check_inputs=False)\n        lags_to_extract = None if multi_models else -np.ones((1,), dtype=int)\n        y = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n    else:\n        y = None\n    return (X, y, times)",
            "def _create_lagged_data_by_moving_window(target_series: Optional[TimeSeries], output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, pd.Index]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Helper function called by `create_lagged_data` that computes `X`, `y`, and `times` by\\n    extracting 'moving windows' from each series using the `strided_moving_window`\\n    function. More specifically, to extract the features of a particular series for an\\n    arbitrary time `t`, a 'window' between times `t - max_lag` and `t - min_lag` is\\n    extracted, where `max_lag` and `min_lag` are the largest and smallest magnitude lags\\n    requested for that particular series. After extracting this window, the requested lag\\n    values between these two minimum and maximum lag values can be extracted. Similarly,\\n    the labels for time `t` are formed simply by extracting a window between times `t`\\n    and `t + output_chunk_length - 1` from the target series. In both cases, the extracted\\n    windows can then be reshaped into the correct shape. This approach can only be used if\\n    we *can* assume that the specified series are all of the same frequency.\\n    \"\n    (feature_times, min_lags, max_lags) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [max_lag is None for max_lag in max_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    time_bounds = get_shared_times_bounds(*feature_times)\n    raise_if(time_bounds is None, 'Specified series do not share any common times for which features can be created.')\n    freq = _get_freqs(target_series, past_covariates, future_covariates)[0]\n    if isinstance(time_bounds[0], int):\n        times = pd.RangeIndex(start=time_bounds[0], stop=time_bounds[1] + freq, step=freq)\n    else:\n        times = pd.date_range(start=time_bounds[0], end=time_bounds[1], freq=freq)\n    num_samples = len(times)\n    if num_samples > max_samples_per_ts:\n        times = times[-max_samples_per_ts:]\n        num_samples = max_samples_per_ts\n    start_time = times[0]\n    X = []\n    start_time_idx = None\n    target_start_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i, max_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags, max_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if is_target_series or series_and_lags_specified:\n            time_index_i = series_i.time_index\n            if not is_target_series and time_index_i[-1] < start_time:\n                if pd.to_timedelta(series_i.freq, errors='coerce') is not pd.NaT:\n                    start_time_idx = len(time_index_i) - 1 + (start_time - time_index_i[-1]) // series_i.freq\n                else:\n                    start_time_idx = len(time_index_i) - 1 + len(pd.date_range(start=time_index_i[-1] + series_i.freq, end=start_time, freq=series_i.freq))\n            elif not is_target_series and time_index_i[0] >= start_time:\n                start_time_idx = max_lag_i\n            else:\n                start_time_idx = np.searchsorted(time_index_i, start_time)\n        if series_and_lags_specified:\n            window_len = max_lag_i - min_lag_i + 1\n            first_window_start_idx = start_time_idx - max_lag_i\n            first_window_end_idx = first_window_start_idx + window_len\n            vals = series_i.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n            windows = strided_moving_window(vals, window_len, stride=1, axis=0, check_inputs=False)\n            if isinstance(lags_i, list):\n                lags_to_extract = np.array(lags_i, dtype=int) + min_lag_i - 1\n            else:\n                lags_to_extract = [np.array(comp_lags, dtype=int) + min_lag_i - 1 for comp_lags in lags_i.values()]\n            lagged_vals = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n            X.append(lagged_vals)\n        if is_target_series:\n            target_start_time_idx = start_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        first_window_start_idx = target_start_time_idx\n        first_window_end_idx = target_start_time_idx + output_chunk_length\n        vals = target_series.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n        windows = strided_moving_window(vals, window_len=output_chunk_length, stride=1, axis=0, check_inputs=False)\n        lags_to_extract = None if multi_models else -np.ones((1,), dtype=int)\n        y = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n    else:\n        y = None\n    return (X, y, times)",
            "def _create_lagged_data_by_moving_window(target_series: Optional[TimeSeries], output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, pd.Index]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Helper function called by `create_lagged_data` that computes `X`, `y`, and `times` by\\n    extracting 'moving windows' from each series using the `strided_moving_window`\\n    function. More specifically, to extract the features of a particular series for an\\n    arbitrary time `t`, a 'window' between times `t - max_lag` and `t - min_lag` is\\n    extracted, where `max_lag` and `min_lag` are the largest and smallest magnitude lags\\n    requested for that particular series. After extracting this window, the requested lag\\n    values between these two minimum and maximum lag values can be extracted. Similarly,\\n    the labels for time `t` are formed simply by extracting a window between times `t`\\n    and `t + output_chunk_length - 1` from the target series. In both cases, the extracted\\n    windows can then be reshaped into the correct shape. This approach can only be used if\\n    we *can* assume that the specified series are all of the same frequency.\\n    \"\n    (feature_times, min_lags, max_lags) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [max_lag is None for max_lag in max_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    time_bounds = get_shared_times_bounds(*feature_times)\n    raise_if(time_bounds is None, 'Specified series do not share any common times for which features can be created.')\n    freq = _get_freqs(target_series, past_covariates, future_covariates)[0]\n    if isinstance(time_bounds[0], int):\n        times = pd.RangeIndex(start=time_bounds[0], stop=time_bounds[1] + freq, step=freq)\n    else:\n        times = pd.date_range(start=time_bounds[0], end=time_bounds[1], freq=freq)\n    num_samples = len(times)\n    if num_samples > max_samples_per_ts:\n        times = times[-max_samples_per_ts:]\n        num_samples = max_samples_per_ts\n    start_time = times[0]\n    X = []\n    start_time_idx = None\n    target_start_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i, max_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags, max_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if is_target_series or series_and_lags_specified:\n            time_index_i = series_i.time_index\n            if not is_target_series and time_index_i[-1] < start_time:\n                if pd.to_timedelta(series_i.freq, errors='coerce') is not pd.NaT:\n                    start_time_idx = len(time_index_i) - 1 + (start_time - time_index_i[-1]) // series_i.freq\n                else:\n                    start_time_idx = len(time_index_i) - 1 + len(pd.date_range(start=time_index_i[-1] + series_i.freq, end=start_time, freq=series_i.freq))\n            elif not is_target_series and time_index_i[0] >= start_time:\n                start_time_idx = max_lag_i\n            else:\n                start_time_idx = np.searchsorted(time_index_i, start_time)\n        if series_and_lags_specified:\n            window_len = max_lag_i - min_lag_i + 1\n            first_window_start_idx = start_time_idx - max_lag_i\n            first_window_end_idx = first_window_start_idx + window_len\n            vals = series_i.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n            windows = strided_moving_window(vals, window_len, stride=1, axis=0, check_inputs=False)\n            if isinstance(lags_i, list):\n                lags_to_extract = np.array(lags_i, dtype=int) + min_lag_i - 1\n            else:\n                lags_to_extract = [np.array(comp_lags, dtype=int) + min_lag_i - 1 for comp_lags in lags_i.values()]\n            lagged_vals = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n            X.append(lagged_vals)\n        if is_target_series:\n            target_start_time_idx = start_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        first_window_start_idx = target_start_time_idx\n        first_window_end_idx = target_start_time_idx + output_chunk_length\n        vals = target_series.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n        windows = strided_moving_window(vals, window_len=output_chunk_length, stride=1, axis=0, check_inputs=False)\n        lags_to_extract = None if multi_models else -np.ones((1,), dtype=int)\n        y = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n    else:\n        y = None\n    return (X, y, times)",
            "def _create_lagged_data_by_moving_window(target_series: Optional[TimeSeries], output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, pd.Index]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Helper function called by `create_lagged_data` that computes `X`, `y`, and `times` by\\n    extracting 'moving windows' from each series using the `strided_moving_window`\\n    function. More specifically, to extract the features of a particular series for an\\n    arbitrary time `t`, a 'window' between times `t - max_lag` and `t - min_lag` is\\n    extracted, where `max_lag` and `min_lag` are the largest and smallest magnitude lags\\n    requested for that particular series. After extracting this window, the requested lag\\n    values between these two minimum and maximum lag values can be extracted. Similarly,\\n    the labels for time `t` are formed simply by extracting a window between times `t`\\n    and `t + output_chunk_length - 1` from the target series. In both cases, the extracted\\n    windows can then be reshaped into the correct shape. This approach can only be used if\\n    we *can* assume that the specified series are all of the same frequency.\\n    \"\n    (feature_times, min_lags, max_lags) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [max_lag is None for max_lag in max_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    time_bounds = get_shared_times_bounds(*feature_times)\n    raise_if(time_bounds is None, 'Specified series do not share any common times for which features can be created.')\n    freq = _get_freqs(target_series, past_covariates, future_covariates)[0]\n    if isinstance(time_bounds[0], int):\n        times = pd.RangeIndex(start=time_bounds[0], stop=time_bounds[1] + freq, step=freq)\n    else:\n        times = pd.date_range(start=time_bounds[0], end=time_bounds[1], freq=freq)\n    num_samples = len(times)\n    if num_samples > max_samples_per_ts:\n        times = times[-max_samples_per_ts:]\n        num_samples = max_samples_per_ts\n    start_time = times[0]\n    X = []\n    start_time_idx = None\n    target_start_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i, max_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags, max_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if is_target_series or series_and_lags_specified:\n            time_index_i = series_i.time_index\n            if not is_target_series and time_index_i[-1] < start_time:\n                if pd.to_timedelta(series_i.freq, errors='coerce') is not pd.NaT:\n                    start_time_idx = len(time_index_i) - 1 + (start_time - time_index_i[-1]) // series_i.freq\n                else:\n                    start_time_idx = len(time_index_i) - 1 + len(pd.date_range(start=time_index_i[-1] + series_i.freq, end=start_time, freq=series_i.freq))\n            elif not is_target_series and time_index_i[0] >= start_time:\n                start_time_idx = max_lag_i\n            else:\n                start_time_idx = np.searchsorted(time_index_i, start_time)\n        if series_and_lags_specified:\n            window_len = max_lag_i - min_lag_i + 1\n            first_window_start_idx = start_time_idx - max_lag_i\n            first_window_end_idx = first_window_start_idx + window_len\n            vals = series_i.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n            windows = strided_moving_window(vals, window_len, stride=1, axis=0, check_inputs=False)\n            if isinstance(lags_i, list):\n                lags_to_extract = np.array(lags_i, dtype=int) + min_lag_i - 1\n            else:\n                lags_to_extract = [np.array(comp_lags, dtype=int) + min_lag_i - 1 for comp_lags in lags_i.values()]\n            lagged_vals = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n            X.append(lagged_vals)\n        if is_target_series:\n            target_start_time_idx = start_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        first_window_start_idx = target_start_time_idx\n        first_window_end_idx = target_start_time_idx + output_chunk_length\n        vals = target_series.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n        windows = strided_moving_window(vals, window_len=output_chunk_length, stride=1, axis=0, check_inputs=False)\n        lags_to_extract = None if multi_models else -np.ones((1,), dtype=int)\n        y = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n    else:\n        y = None\n    return (X, y, times)",
            "def _create_lagged_data_by_moving_window(target_series: Optional[TimeSeries], output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, pd.Index]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Helper function called by `create_lagged_data` that computes `X`, `y`, and `times` by\\n    extracting 'moving windows' from each series using the `strided_moving_window`\\n    function. More specifically, to extract the features of a particular series for an\\n    arbitrary time `t`, a 'window' between times `t - max_lag` and `t - min_lag` is\\n    extracted, where `max_lag` and `min_lag` are the largest and smallest magnitude lags\\n    requested for that particular series. After extracting this window, the requested lag\\n    values between these two minimum and maximum lag values can be extracted. Similarly,\\n    the labels for time `t` are formed simply by extracting a window between times `t`\\n    and `t + output_chunk_length - 1` from the target series. In both cases, the extracted\\n    windows can then be reshaped into the correct shape. This approach can only be used if\\n    we *can* assume that the specified series are all of the same frequency.\\n    \"\n    (feature_times, min_lags, max_lags) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [max_lag is None for max_lag in max_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    time_bounds = get_shared_times_bounds(*feature_times)\n    raise_if(time_bounds is None, 'Specified series do not share any common times for which features can be created.')\n    freq = _get_freqs(target_series, past_covariates, future_covariates)[0]\n    if isinstance(time_bounds[0], int):\n        times = pd.RangeIndex(start=time_bounds[0], stop=time_bounds[1] + freq, step=freq)\n    else:\n        times = pd.date_range(start=time_bounds[0], end=time_bounds[1], freq=freq)\n    num_samples = len(times)\n    if num_samples > max_samples_per_ts:\n        times = times[-max_samples_per_ts:]\n        num_samples = max_samples_per_ts\n    start_time = times[0]\n    X = []\n    start_time_idx = None\n    target_start_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i, max_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags, max_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if is_target_series or series_and_lags_specified:\n            time_index_i = series_i.time_index\n            if not is_target_series and time_index_i[-1] < start_time:\n                if pd.to_timedelta(series_i.freq, errors='coerce') is not pd.NaT:\n                    start_time_idx = len(time_index_i) - 1 + (start_time - time_index_i[-1]) // series_i.freq\n                else:\n                    start_time_idx = len(time_index_i) - 1 + len(pd.date_range(start=time_index_i[-1] + series_i.freq, end=start_time, freq=series_i.freq))\n            elif not is_target_series and time_index_i[0] >= start_time:\n                start_time_idx = max_lag_i\n            else:\n                start_time_idx = np.searchsorted(time_index_i, start_time)\n        if series_and_lags_specified:\n            window_len = max_lag_i - min_lag_i + 1\n            first_window_start_idx = start_time_idx - max_lag_i\n            first_window_end_idx = first_window_start_idx + window_len\n            vals = series_i.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n            windows = strided_moving_window(vals, window_len, stride=1, axis=0, check_inputs=False)\n            if isinstance(lags_i, list):\n                lags_to_extract = np.array(lags_i, dtype=int) + min_lag_i - 1\n            else:\n                lags_to_extract = [np.array(comp_lags, dtype=int) + min_lag_i - 1 for comp_lags in lags_i.values()]\n            lagged_vals = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n            X.append(lagged_vals)\n        if is_target_series:\n            target_start_time_idx = start_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        first_window_start_idx = target_start_time_idx\n        first_window_end_idx = target_start_time_idx + output_chunk_length\n        vals = target_series.all_values(copy=False)[first_window_start_idx:first_window_end_idx + num_samples - 1, :, :]\n        windows = strided_moving_window(vals, window_len=output_chunk_length, stride=1, axis=0, check_inputs=False)\n        lags_to_extract = None if multi_models else -np.ones((1,), dtype=int)\n        y = _extract_lagged_vals_from_windows(windows, lags_to_extract)\n    else:\n        y = None\n    return (X, y, times)"
        ]
    },
    {
        "func_name": "_extract_lagged_vals_from_windows",
        "original": "def _extract_lagged_vals_from_windows(windows: np.ndarray, lags_to_extract: Optional[Union[np.ndarray, List[np.ndarray]]]=None) -> np.ndarray:\n    \"\"\"\n    Helper function called by `_create_lagged_data_by_moving_window` that\n    reshapes the `windows` formed by `strided_moving_window` from the\n    shape `(num_windows, num_components, num_series, window_len)` to the\n    shape `(num_windows, num_components * window_len, num_series)`. This reshaping\n    is done such that the order of elements along axis 1 matches the pattern\n    described in the docstring of `create_lagged_data`.\n\n    If `lags_to_extract` is not specified, all of the values within each window is extracted.\n    If `lags_to_extract` is specified as an np.ndarray, then only those values within each window that\n    are indexed by `lags_to_extract` will be returned. In such cases, the shape of the returned\n    lagged values is `(num_windows, num_components * lags_to_extract.size, num_series)`. For example,\n    if `lags_to_extract = [-2]`, only the second-to-last values within each window will be extracted.\n    If `lags_to_extract` is specified as a list of np.ndarray, the values will be extracted using the\n    lags provided for each component. In such cases, the shape of the returned lagged values is\n    `(num_windows, sum([comp_lags.size for comp_lags in lags_to_extract]), num_series)`. For example,\n    if `lags_to_extract = [[-2, -1], [-1]]`, the second-to-last and last values of the first component\n    and the last values of the second component within each window will be extracted.\n    \"\"\"\n    if isinstance(lags_to_extract, list):\n        comp_windows = [windows[:, i, :, comp_lags_to_extract] for (i, comp_lags_to_extract) in enumerate(lags_to_extract)]\n        windows = np.concatenate(comp_windows, axis=0)\n        lagged_vals = np.moveaxis(windows, (1, 0, 2), (0, 1, 2))\n    else:\n        if lags_to_extract is not None:\n            windows = windows[:, :, :, lags_to_extract]\n        windows = np.moveaxis(windows, (0, 3, 1, 2), (0, 1, 2, 3))\n        lagged_vals = windows.reshape((windows.shape[0], -1, windows.shape[-1]))\n    return lagged_vals",
        "mutated": [
            "def _extract_lagged_vals_from_windows(windows: np.ndarray, lags_to_extract: Optional[Union[np.ndarray, List[np.ndarray]]]=None) -> np.ndarray:\n    if False:\n        i = 10\n    '\\n    Helper function called by `_create_lagged_data_by_moving_window` that\\n    reshapes the `windows` formed by `strided_moving_window` from the\\n    shape `(num_windows, num_components, num_series, window_len)` to the\\n    shape `(num_windows, num_components * window_len, num_series)`. This reshaping\\n    is done such that the order of elements along axis 1 matches the pattern\\n    described in the docstring of `create_lagged_data`.\\n\\n    If `lags_to_extract` is not specified, all of the values within each window is extracted.\\n    If `lags_to_extract` is specified as an np.ndarray, then only those values within each window that\\n    are indexed by `lags_to_extract` will be returned. In such cases, the shape of the returned\\n    lagged values is `(num_windows, num_components * lags_to_extract.size, num_series)`. For example,\\n    if `lags_to_extract = [-2]`, only the second-to-last values within each window will be extracted.\\n    If `lags_to_extract` is specified as a list of np.ndarray, the values will be extracted using the\\n    lags provided for each component. In such cases, the shape of the returned lagged values is\\n    `(num_windows, sum([comp_lags.size for comp_lags in lags_to_extract]), num_series)`. For example,\\n    if `lags_to_extract = [[-2, -1], [-1]]`, the second-to-last and last values of the first component\\n    and the last values of the second component within each window will be extracted.\\n    '\n    if isinstance(lags_to_extract, list):\n        comp_windows = [windows[:, i, :, comp_lags_to_extract] for (i, comp_lags_to_extract) in enumerate(lags_to_extract)]\n        windows = np.concatenate(comp_windows, axis=0)\n        lagged_vals = np.moveaxis(windows, (1, 0, 2), (0, 1, 2))\n    else:\n        if lags_to_extract is not None:\n            windows = windows[:, :, :, lags_to_extract]\n        windows = np.moveaxis(windows, (0, 3, 1, 2), (0, 1, 2, 3))\n        lagged_vals = windows.reshape((windows.shape[0], -1, windows.shape[-1]))\n    return lagged_vals",
            "def _extract_lagged_vals_from_windows(windows: np.ndarray, lags_to_extract: Optional[Union[np.ndarray, List[np.ndarray]]]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Helper function called by `_create_lagged_data_by_moving_window` that\\n    reshapes the `windows` formed by `strided_moving_window` from the\\n    shape `(num_windows, num_components, num_series, window_len)` to the\\n    shape `(num_windows, num_components * window_len, num_series)`. This reshaping\\n    is done such that the order of elements along axis 1 matches the pattern\\n    described in the docstring of `create_lagged_data`.\\n\\n    If `lags_to_extract` is not specified, all of the values within each window is extracted.\\n    If `lags_to_extract` is specified as an np.ndarray, then only those values within each window that\\n    are indexed by `lags_to_extract` will be returned. In such cases, the shape of the returned\\n    lagged values is `(num_windows, num_components * lags_to_extract.size, num_series)`. For example,\\n    if `lags_to_extract = [-2]`, only the second-to-last values within each window will be extracted.\\n    If `lags_to_extract` is specified as a list of np.ndarray, the values will be extracted using the\\n    lags provided for each component. In such cases, the shape of the returned lagged values is\\n    `(num_windows, sum([comp_lags.size for comp_lags in lags_to_extract]), num_series)`. For example,\\n    if `lags_to_extract = [[-2, -1], [-1]]`, the second-to-last and last values of the first component\\n    and the last values of the second component within each window will be extracted.\\n    '\n    if isinstance(lags_to_extract, list):\n        comp_windows = [windows[:, i, :, comp_lags_to_extract] for (i, comp_lags_to_extract) in enumerate(lags_to_extract)]\n        windows = np.concatenate(comp_windows, axis=0)\n        lagged_vals = np.moveaxis(windows, (1, 0, 2), (0, 1, 2))\n    else:\n        if lags_to_extract is not None:\n            windows = windows[:, :, :, lags_to_extract]\n        windows = np.moveaxis(windows, (0, 3, 1, 2), (0, 1, 2, 3))\n        lagged_vals = windows.reshape((windows.shape[0], -1, windows.shape[-1]))\n    return lagged_vals",
            "def _extract_lagged_vals_from_windows(windows: np.ndarray, lags_to_extract: Optional[Union[np.ndarray, List[np.ndarray]]]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Helper function called by `_create_lagged_data_by_moving_window` that\\n    reshapes the `windows` formed by `strided_moving_window` from the\\n    shape `(num_windows, num_components, num_series, window_len)` to the\\n    shape `(num_windows, num_components * window_len, num_series)`. This reshaping\\n    is done such that the order of elements along axis 1 matches the pattern\\n    described in the docstring of `create_lagged_data`.\\n\\n    If `lags_to_extract` is not specified, all of the values within each window is extracted.\\n    If `lags_to_extract` is specified as an np.ndarray, then only those values within each window that\\n    are indexed by `lags_to_extract` will be returned. In such cases, the shape of the returned\\n    lagged values is `(num_windows, num_components * lags_to_extract.size, num_series)`. For example,\\n    if `lags_to_extract = [-2]`, only the second-to-last values within each window will be extracted.\\n    If `lags_to_extract` is specified as a list of np.ndarray, the values will be extracted using the\\n    lags provided for each component. In such cases, the shape of the returned lagged values is\\n    `(num_windows, sum([comp_lags.size for comp_lags in lags_to_extract]), num_series)`. For example,\\n    if `lags_to_extract = [[-2, -1], [-1]]`, the second-to-last and last values of the first component\\n    and the last values of the second component within each window will be extracted.\\n    '\n    if isinstance(lags_to_extract, list):\n        comp_windows = [windows[:, i, :, comp_lags_to_extract] for (i, comp_lags_to_extract) in enumerate(lags_to_extract)]\n        windows = np.concatenate(comp_windows, axis=0)\n        lagged_vals = np.moveaxis(windows, (1, 0, 2), (0, 1, 2))\n    else:\n        if lags_to_extract is not None:\n            windows = windows[:, :, :, lags_to_extract]\n        windows = np.moveaxis(windows, (0, 3, 1, 2), (0, 1, 2, 3))\n        lagged_vals = windows.reshape((windows.shape[0], -1, windows.shape[-1]))\n    return lagged_vals",
            "def _extract_lagged_vals_from_windows(windows: np.ndarray, lags_to_extract: Optional[Union[np.ndarray, List[np.ndarray]]]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Helper function called by `_create_lagged_data_by_moving_window` that\\n    reshapes the `windows` formed by `strided_moving_window` from the\\n    shape `(num_windows, num_components, num_series, window_len)` to the\\n    shape `(num_windows, num_components * window_len, num_series)`. This reshaping\\n    is done such that the order of elements along axis 1 matches the pattern\\n    described in the docstring of `create_lagged_data`.\\n\\n    If `lags_to_extract` is not specified, all of the values within each window is extracted.\\n    If `lags_to_extract` is specified as an np.ndarray, then only those values within each window that\\n    are indexed by `lags_to_extract` will be returned. In such cases, the shape of the returned\\n    lagged values is `(num_windows, num_components * lags_to_extract.size, num_series)`. For example,\\n    if `lags_to_extract = [-2]`, only the second-to-last values within each window will be extracted.\\n    If `lags_to_extract` is specified as a list of np.ndarray, the values will be extracted using the\\n    lags provided for each component. In such cases, the shape of the returned lagged values is\\n    `(num_windows, sum([comp_lags.size for comp_lags in lags_to_extract]), num_series)`. For example,\\n    if `lags_to_extract = [[-2, -1], [-1]]`, the second-to-last and last values of the first component\\n    and the last values of the second component within each window will be extracted.\\n    '\n    if isinstance(lags_to_extract, list):\n        comp_windows = [windows[:, i, :, comp_lags_to_extract] for (i, comp_lags_to_extract) in enumerate(lags_to_extract)]\n        windows = np.concatenate(comp_windows, axis=0)\n        lagged_vals = np.moveaxis(windows, (1, 0, 2), (0, 1, 2))\n    else:\n        if lags_to_extract is not None:\n            windows = windows[:, :, :, lags_to_extract]\n        windows = np.moveaxis(windows, (0, 3, 1, 2), (0, 1, 2, 3))\n        lagged_vals = windows.reshape((windows.shape[0], -1, windows.shape[-1]))\n    return lagged_vals",
            "def _extract_lagged_vals_from_windows(windows: np.ndarray, lags_to_extract: Optional[Union[np.ndarray, List[np.ndarray]]]=None) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Helper function called by `_create_lagged_data_by_moving_window` that\\n    reshapes the `windows` formed by `strided_moving_window` from the\\n    shape `(num_windows, num_components, num_series, window_len)` to the\\n    shape `(num_windows, num_components * window_len, num_series)`. This reshaping\\n    is done such that the order of elements along axis 1 matches the pattern\\n    described in the docstring of `create_lagged_data`.\\n\\n    If `lags_to_extract` is not specified, all of the values within each window is extracted.\\n    If `lags_to_extract` is specified as an np.ndarray, then only those values within each window that\\n    are indexed by `lags_to_extract` will be returned. In such cases, the shape of the returned\\n    lagged values is `(num_windows, num_components * lags_to_extract.size, num_series)`. For example,\\n    if `lags_to_extract = [-2]`, only the second-to-last values within each window will be extracted.\\n    If `lags_to_extract` is specified as a list of np.ndarray, the values will be extracted using the\\n    lags provided for each component. In such cases, the shape of the returned lagged values is\\n    `(num_windows, sum([comp_lags.size for comp_lags in lags_to_extract]), num_series)`. For example,\\n    if `lags_to_extract = [[-2, -1], [-1]]`, the second-to-last and last values of the first component\\n    and the last values of the second component within each window will be extracted.\\n    '\n    if isinstance(lags_to_extract, list):\n        comp_windows = [windows[:, i, :, comp_lags_to_extract] for (i, comp_lags_to_extract) in enumerate(lags_to_extract)]\n        windows = np.concatenate(comp_windows, axis=0)\n        lagged_vals = np.moveaxis(windows, (1, 0, 2), (0, 1, 2))\n    else:\n        if lags_to_extract is not None:\n            windows = windows[:, :, :, lags_to_extract]\n        windows = np.moveaxis(windows, (0, 3, 1, 2), (0, 1, 2, 3))\n        lagged_vals = windows.reshape((windows.shape[0], -1, windows.shape[-1]))\n    return lagged_vals"
        ]
    },
    {
        "func_name": "_create_lagged_data_by_intersecting_times",
        "original": "def _create_lagged_data_by_intersecting_times(target_series: TimeSeries, output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Sequence[int]], lags_past_covariates: Optional[Sequence[int]], lags_future_covariates: Optional[Sequence[int]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, Union[pd.RangeIndex, pd.DatetimeIndex]]:\n    \"\"\"\n    Helper function called by `_create_lagged_data` that computes `X`, `y`, and `times` by\n    first finding the time points in each series that *could* be used to create features/labels,\n    and then finding which of these 'available' times is shared by all specified series. The lagged\n    values are then extracted by finding the index of each of these 'shared times' in each series,\n    and then offsetting this index by the requested lag value (if constructing `X`) or the requested\n    `output_chunk_length` (if constructing `y`). This approach is used if we *cannot* assume that the\n    specified series are of the same frequency.\n    \"\"\"\n    (feature_times, min_lags, _) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [min_lag is None for min_lag in min_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    shared_times = get_shared_times(*feature_times, sort=True)\n    raise_if(shared_times is None, 'Specified series do not share any common times for which features can be created.')\n    if len(shared_times) > max_samples_per_ts:\n        shared_times = shared_times[-max_samples_per_ts:]\n    X = []\n    shared_time_idx = None\n    label_shared_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if series_and_lags_specified or is_target_series:\n            time_index_i = series_i.time_index\n            add_to_start = not is_target_series and time_index_i[0] > shared_times[0]\n            add_to_end = not is_target_series and time_index_i[-1] < shared_times[-1]\n            if add_to_start or add_to_end:\n                new_start = shared_times[0] if add_to_start else None\n                new_end = shared_times[-1] if add_to_end else None\n                num_prepended = (time_index_i[0] - shared_times[0]) // series_i.freq if add_to_start else 0\n                time_index_i = _extend_time_index(time_index_i, series_i.freq, new_start=new_start, new_end=new_end)\n            else:\n                num_prepended = 0\n            shared_time_idx = np.searchsorted(time_index_i, shared_times).reshape(-1, 1) - num_prepended\n        if series_and_lags_specified:\n            idx_to_get = shared_time_idx + np.array(lags_i, dtype=int)\n            lagged_vals = series_i.all_values(copy=False)[idx_to_get, :, :]\n            lagged_vals = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n            X.append(lagged_vals)\n        if is_target_series:\n            label_shared_time_idx = shared_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        if multi_models:\n            idx_to_get = label_shared_time_idx + np.arange(output_chunk_length)\n        else:\n            idx_to_get = label_shared_time_idx + output_chunk_length - 1\n        lagged_vals = target_series.all_values(copy=False)[idx_to_get, :, :]\n        y = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n    else:\n        y = None\n    return (X, y, shared_times)",
        "mutated": [
            "def _create_lagged_data_by_intersecting_times(target_series: TimeSeries, output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Sequence[int]], lags_past_covariates: Optional[Sequence[int]], lags_future_covariates: Optional[Sequence[int]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, Union[pd.RangeIndex, pd.DatetimeIndex]]:\n    if False:\n        i = 10\n    \"\\n    Helper function called by `_create_lagged_data` that computes `X`, `y`, and `times` by\\n    first finding the time points in each series that *could* be used to create features/labels,\\n    and then finding which of these 'available' times is shared by all specified series. The lagged\\n    values are then extracted by finding the index of each of these 'shared times' in each series,\\n    and then offsetting this index by the requested lag value (if constructing `X`) or the requested\\n    `output_chunk_length` (if constructing `y`). This approach is used if we *cannot* assume that the\\n    specified series are of the same frequency.\\n    \"\n    (feature_times, min_lags, _) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [min_lag is None for min_lag in min_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    shared_times = get_shared_times(*feature_times, sort=True)\n    raise_if(shared_times is None, 'Specified series do not share any common times for which features can be created.')\n    if len(shared_times) > max_samples_per_ts:\n        shared_times = shared_times[-max_samples_per_ts:]\n    X = []\n    shared_time_idx = None\n    label_shared_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if series_and_lags_specified or is_target_series:\n            time_index_i = series_i.time_index\n            add_to_start = not is_target_series and time_index_i[0] > shared_times[0]\n            add_to_end = not is_target_series and time_index_i[-1] < shared_times[-1]\n            if add_to_start or add_to_end:\n                new_start = shared_times[0] if add_to_start else None\n                new_end = shared_times[-1] if add_to_end else None\n                num_prepended = (time_index_i[0] - shared_times[0]) // series_i.freq if add_to_start else 0\n                time_index_i = _extend_time_index(time_index_i, series_i.freq, new_start=new_start, new_end=new_end)\n            else:\n                num_prepended = 0\n            shared_time_idx = np.searchsorted(time_index_i, shared_times).reshape(-1, 1) - num_prepended\n        if series_and_lags_specified:\n            idx_to_get = shared_time_idx + np.array(lags_i, dtype=int)\n            lagged_vals = series_i.all_values(copy=False)[idx_to_get, :, :]\n            lagged_vals = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n            X.append(lagged_vals)\n        if is_target_series:\n            label_shared_time_idx = shared_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        if multi_models:\n            idx_to_get = label_shared_time_idx + np.arange(output_chunk_length)\n        else:\n            idx_to_get = label_shared_time_idx + output_chunk_length - 1\n        lagged_vals = target_series.all_values(copy=False)[idx_to_get, :, :]\n        y = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n    else:\n        y = None\n    return (X, y, shared_times)",
            "def _create_lagged_data_by_intersecting_times(target_series: TimeSeries, output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Sequence[int]], lags_past_covariates: Optional[Sequence[int]], lags_future_covariates: Optional[Sequence[int]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, Union[pd.RangeIndex, pd.DatetimeIndex]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Helper function called by `_create_lagged_data` that computes `X`, `y`, and `times` by\\n    first finding the time points in each series that *could* be used to create features/labels,\\n    and then finding which of these 'available' times is shared by all specified series. The lagged\\n    values are then extracted by finding the index of each of these 'shared times' in each series,\\n    and then offsetting this index by the requested lag value (if constructing `X`) or the requested\\n    `output_chunk_length` (if constructing `y`). This approach is used if we *cannot* assume that the\\n    specified series are of the same frequency.\\n    \"\n    (feature_times, min_lags, _) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [min_lag is None for min_lag in min_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    shared_times = get_shared_times(*feature_times, sort=True)\n    raise_if(shared_times is None, 'Specified series do not share any common times for which features can be created.')\n    if len(shared_times) > max_samples_per_ts:\n        shared_times = shared_times[-max_samples_per_ts:]\n    X = []\n    shared_time_idx = None\n    label_shared_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if series_and_lags_specified or is_target_series:\n            time_index_i = series_i.time_index\n            add_to_start = not is_target_series and time_index_i[0] > shared_times[0]\n            add_to_end = not is_target_series and time_index_i[-1] < shared_times[-1]\n            if add_to_start or add_to_end:\n                new_start = shared_times[0] if add_to_start else None\n                new_end = shared_times[-1] if add_to_end else None\n                num_prepended = (time_index_i[0] - shared_times[0]) // series_i.freq if add_to_start else 0\n                time_index_i = _extend_time_index(time_index_i, series_i.freq, new_start=new_start, new_end=new_end)\n            else:\n                num_prepended = 0\n            shared_time_idx = np.searchsorted(time_index_i, shared_times).reshape(-1, 1) - num_prepended\n        if series_and_lags_specified:\n            idx_to_get = shared_time_idx + np.array(lags_i, dtype=int)\n            lagged_vals = series_i.all_values(copy=False)[idx_to_get, :, :]\n            lagged_vals = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n            X.append(lagged_vals)\n        if is_target_series:\n            label_shared_time_idx = shared_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        if multi_models:\n            idx_to_get = label_shared_time_idx + np.arange(output_chunk_length)\n        else:\n            idx_to_get = label_shared_time_idx + output_chunk_length - 1\n        lagged_vals = target_series.all_values(copy=False)[idx_to_get, :, :]\n        y = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n    else:\n        y = None\n    return (X, y, shared_times)",
            "def _create_lagged_data_by_intersecting_times(target_series: TimeSeries, output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Sequence[int]], lags_past_covariates: Optional[Sequence[int]], lags_future_covariates: Optional[Sequence[int]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, Union[pd.RangeIndex, pd.DatetimeIndex]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Helper function called by `_create_lagged_data` that computes `X`, `y`, and `times` by\\n    first finding the time points in each series that *could* be used to create features/labels,\\n    and then finding which of these 'available' times is shared by all specified series. The lagged\\n    values are then extracted by finding the index of each of these 'shared times' in each series,\\n    and then offsetting this index by the requested lag value (if constructing `X`) or the requested\\n    `output_chunk_length` (if constructing `y`). This approach is used if we *cannot* assume that the\\n    specified series are of the same frequency.\\n    \"\n    (feature_times, min_lags, _) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [min_lag is None for min_lag in min_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    shared_times = get_shared_times(*feature_times, sort=True)\n    raise_if(shared_times is None, 'Specified series do not share any common times for which features can be created.')\n    if len(shared_times) > max_samples_per_ts:\n        shared_times = shared_times[-max_samples_per_ts:]\n    X = []\n    shared_time_idx = None\n    label_shared_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if series_and_lags_specified or is_target_series:\n            time_index_i = series_i.time_index\n            add_to_start = not is_target_series and time_index_i[0] > shared_times[0]\n            add_to_end = not is_target_series and time_index_i[-1] < shared_times[-1]\n            if add_to_start or add_to_end:\n                new_start = shared_times[0] if add_to_start else None\n                new_end = shared_times[-1] if add_to_end else None\n                num_prepended = (time_index_i[0] - shared_times[0]) // series_i.freq if add_to_start else 0\n                time_index_i = _extend_time_index(time_index_i, series_i.freq, new_start=new_start, new_end=new_end)\n            else:\n                num_prepended = 0\n            shared_time_idx = np.searchsorted(time_index_i, shared_times).reshape(-1, 1) - num_prepended\n        if series_and_lags_specified:\n            idx_to_get = shared_time_idx + np.array(lags_i, dtype=int)\n            lagged_vals = series_i.all_values(copy=False)[idx_to_get, :, :]\n            lagged_vals = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n            X.append(lagged_vals)\n        if is_target_series:\n            label_shared_time_idx = shared_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        if multi_models:\n            idx_to_get = label_shared_time_idx + np.arange(output_chunk_length)\n        else:\n            idx_to_get = label_shared_time_idx + output_chunk_length - 1\n        lagged_vals = target_series.all_values(copy=False)[idx_to_get, :, :]\n        y = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n    else:\n        y = None\n    return (X, y, shared_times)",
            "def _create_lagged_data_by_intersecting_times(target_series: TimeSeries, output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Sequence[int]], lags_past_covariates: Optional[Sequence[int]], lags_future_covariates: Optional[Sequence[int]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, Union[pd.RangeIndex, pd.DatetimeIndex]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Helper function called by `_create_lagged_data` that computes `X`, `y`, and `times` by\\n    first finding the time points in each series that *could* be used to create features/labels,\\n    and then finding which of these 'available' times is shared by all specified series. The lagged\\n    values are then extracted by finding the index of each of these 'shared times' in each series,\\n    and then offsetting this index by the requested lag value (if constructing `X`) or the requested\\n    `output_chunk_length` (if constructing `y`). This approach is used if we *cannot* assume that the\\n    specified series are of the same frequency.\\n    \"\n    (feature_times, min_lags, _) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [min_lag is None for min_lag in min_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    shared_times = get_shared_times(*feature_times, sort=True)\n    raise_if(shared_times is None, 'Specified series do not share any common times for which features can be created.')\n    if len(shared_times) > max_samples_per_ts:\n        shared_times = shared_times[-max_samples_per_ts:]\n    X = []\n    shared_time_idx = None\n    label_shared_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if series_and_lags_specified or is_target_series:\n            time_index_i = series_i.time_index\n            add_to_start = not is_target_series and time_index_i[0] > shared_times[0]\n            add_to_end = not is_target_series and time_index_i[-1] < shared_times[-1]\n            if add_to_start or add_to_end:\n                new_start = shared_times[0] if add_to_start else None\n                new_end = shared_times[-1] if add_to_end else None\n                num_prepended = (time_index_i[0] - shared_times[0]) // series_i.freq if add_to_start else 0\n                time_index_i = _extend_time_index(time_index_i, series_i.freq, new_start=new_start, new_end=new_end)\n            else:\n                num_prepended = 0\n            shared_time_idx = np.searchsorted(time_index_i, shared_times).reshape(-1, 1) - num_prepended\n        if series_and_lags_specified:\n            idx_to_get = shared_time_idx + np.array(lags_i, dtype=int)\n            lagged_vals = series_i.all_values(copy=False)[idx_to_get, :, :]\n            lagged_vals = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n            X.append(lagged_vals)\n        if is_target_series:\n            label_shared_time_idx = shared_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        if multi_models:\n            idx_to_get = label_shared_time_idx + np.arange(output_chunk_length)\n        else:\n            idx_to_get = label_shared_time_idx + output_chunk_length - 1\n        lagged_vals = target_series.all_values(copy=False)[idx_to_get, :, :]\n        y = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n    else:\n        y = None\n    return (X, y, shared_times)",
            "def _create_lagged_data_by_intersecting_times(target_series: TimeSeries, output_chunk_length: int, past_covariates: Optional[TimeSeries], future_covariates: Optional[TimeSeries], lags: Optional[Sequence[int]], lags_past_covariates: Optional[Sequence[int]], lags_future_covariates: Optional[Sequence[int]], max_samples_per_ts: Optional[int], multi_models: bool, check_inputs: bool, is_training: bool) -> Tuple[np.ndarray, np.ndarray, Union[pd.RangeIndex, pd.DatetimeIndex]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Helper function called by `_create_lagged_data` that computes `X`, `y`, and `times` by\\n    first finding the time points in each series that *could* be used to create features/labels,\\n    and then finding which of these 'available' times is shared by all specified series. The lagged\\n    values are then extracted by finding the index of each of these 'shared times' in each series,\\n    and then offsetting this index by the requested lag value (if constructing `X`) or the requested\\n    `output_chunk_length` (if constructing `y`). This approach is used if we *cannot* assume that the\\n    specified series are of the same frequency.\\n    \"\n    (feature_times, min_lags, _) = _get_feature_times(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, is_training=is_training, return_min_and_max_lags=True, check_inputs=check_inputs)\n    if check_inputs:\n        series_and_lags_not_specified = [min_lag is None for min_lag in min_lags]\n        raise_if(all(series_and_lags_not_specified), 'Must specify at least one series-lags pair.')\n    shared_times = get_shared_times(*feature_times, sort=True)\n    raise_if(shared_times is None, 'Specified series do not share any common times for which features can be created.')\n    if len(shared_times) > max_samples_per_ts:\n        shared_times = shared_times[-max_samples_per_ts:]\n    X = []\n    shared_time_idx = None\n    label_shared_time_idx = None\n    for (i, (series_i, lags_i, min_lag_i)) in enumerate(zip([target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates], min_lags)):\n        series_and_lags_specified = min_lag_i is not None\n        is_target_series = is_training and i == 0\n        if series_and_lags_specified or is_target_series:\n            time_index_i = series_i.time_index\n            add_to_start = not is_target_series and time_index_i[0] > shared_times[0]\n            add_to_end = not is_target_series and time_index_i[-1] < shared_times[-1]\n            if add_to_start or add_to_end:\n                new_start = shared_times[0] if add_to_start else None\n                new_end = shared_times[-1] if add_to_end else None\n                num_prepended = (time_index_i[0] - shared_times[0]) // series_i.freq if add_to_start else 0\n                time_index_i = _extend_time_index(time_index_i, series_i.freq, new_start=new_start, new_end=new_end)\n            else:\n                num_prepended = 0\n            shared_time_idx = np.searchsorted(time_index_i, shared_times).reshape(-1, 1) - num_prepended\n        if series_and_lags_specified:\n            idx_to_get = shared_time_idx + np.array(lags_i, dtype=int)\n            lagged_vals = series_i.all_values(copy=False)[idx_to_get, :, :]\n            lagged_vals = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n            X.append(lagged_vals)\n        if is_target_series:\n            label_shared_time_idx = shared_time_idx\n    X = np.concatenate(X, axis=1)\n    if is_training:\n        if multi_models:\n            idx_to_get = label_shared_time_idx + np.arange(output_chunk_length)\n        else:\n            idx_to_get = label_shared_time_idx + output_chunk_length - 1\n        lagged_vals = target_series.all_values(copy=False)[idx_to_get, :, :]\n        y = lagged_vals.reshape(lagged_vals.shape[0], -1, lagged_vals.shape[-1])\n    else:\n        y = None\n    return (X, y, shared_times)"
        ]
    },
    {
        "func_name": "_get_feature_times",
        "original": "def _get_feature_times(target_series: Optional[TimeSeries]=None, past_covariates: Optional[TimeSeries]=None, future_covariates: Optional[TimeSeries]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, is_training: bool=True, return_min_and_max_lags: bool=False, check_inputs: bool=True) -> Union[FeatureTimes, Tuple[FeatureTimes, MinLags, MaxLags]]:\n    \"\"\"\n    Returns a tuple containing the times in `target_series`, the times in `past_covariates`, and the times in\n    `future_covariates` that *could* be used to create features. The returned tuple of times can then be passed\n    to `get_shared_times` to compute the 'eligible time points' shared by all of the specified series.\n\n    Notes\n    -----\n    For the purposes of extracting feature times from each series, we define the `min_lag` and `max_lag` of\n    each series to be:\n            `min_lag = -max(lags_*)`,\n            `max_lag = -min(lags_*)`\n    where `lags_*` denotes either `lags`, `lags_past_covariates`, or `lags_future_covariates`.\n\n    For both `lags` and `lags_past_covariates`, `min_lag` and `max_lag` are guaranteed to be positive values,\n    since the values in `lags` and `lags_past_covariates` must all be negative. For these two series then,\n    `min_lag` and `max_lag` represent the smallest and largest magnitude lags requested by the user. For example:\n            `lags = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\n\n    The values contained in `lags_future_covariates`, on the other hand, can be negative, zero, or positive; this\n    means that there are three cases to consider:\n        1. Both `min_lag` and `max_lag` are positive, which means that all the values in `lags_future_covariates`\n        are negative. In this case, `min_lag` and `max_lag` correspond to the to the smallest and largest\n        lag magnitudes respectively. For example:\n                `lags_future_covariates = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\n        2. `min_lag` is non-positive (i.e. zero or negative), but `max_lag` is positive, which means that\n        `lags_future_covariates` contains both negative and non-negative (i.e. zero or positive) lag values.\n        In this case, `abs(min_lag)` corresponds to the magnitude of the largest *non-negative* lag value in\n        `lags_future_covariates`, whilst `max_lag` corresponds to the largest *negative* lag value in\n        `lags_future_covariates`. For example:\n                `lags_future_covariates = [-2, -1, 0, 1, 3] -> min_lag = -3, max_lag = 2`\n        3. Both `min_lag` and `max_lag` are non-positive, which means that `lags_future_covariates` contains\n        only non-negative lag values. In this case, `abs(min_lag)` and `abs(max_lag)`, rather confusingly,\n        correspond to the largest and smallest lag magnitudes respectively. For example:\n                `lags_future_covariates = [1, 2, 3] -> min_lag = -3, max_lag = -1`\n    In all three cases, we have `min_lag <= max_lag`. As a direct consequence:\n        1. `min_lag > 0` is a sufficient condition for `min_lag` and `max_lag` both being positive (i.e. Case 1).\n        2. `max_lag <= 0` is a sufficient condition for `min_lag` and `max_lag` both being non-positive (i.e. Case 2).\n\n    To extract feature times from a `target_series` when `is_training = True`, the following steps are performed:\n        1. The first `max_lag` times of the series are excluded; these times have too few preceeding values to\n        construct features from.\n        2. The last `output_chunk_length - 1` times are excluded; these times have too few succeeding times\n        to construct labels from.\n\n    To extract feature times from a `target_series` when `is_training = False`, the following steps are performed:\n        1. An additional `min_lag` times are appended to the end of the series; although these times are not contained\n        in the original series, we're able to construct features for them since we only need the values of the series\n        from time `t - max_lag` to `t - min_lag` to construct a feature for time `t`.\n        2. The first `max_lag` times of the series are then excluded; these times have too few preceeding values to\n        construct features from.\n    The exact same procedure is performed to extract the feature times from a `past_covariates` series.\n\n    To extract feature times from `future_covariates`, we perform the following steps:\n        1. Depending on the signs of `min_lag` and `max_lag`, additional times are either prepended or appended\n        to the original series. More specifically:\n            a) If `min_lag` and `max_lag` are both positive (i.e. `min_lag > 0`), then an additional `min_lag` times\n            are appended to the end of the series; as previously mentioned, we only need values up to time `t - min_lag`\n            to construct a feature for time `t`.\n            b) If `min_lag` and `max_lag` are both non-positive (i.e. `max_lag < 0`), then an additional `abs(max_lag)`\n            times are prepended to the start of the series; this is because we only need to know the values of the\n            series *after* time `t + abs(max_lag)` to construct a feature for time `t` when we're only extracting\n            positive lags from `future_covariates`.\n            c) If `min_lag` is non-positive and `max_lag` is positive, then *no additional times* are added to the\n            series, since constructing a feature for time `t` requires knowing values from time `t - max_lag` to\n            time `t + abs(min_lag)`; in other words, we need to have access to time `t` itself.\n        2. If `min_lag < 0`, the last `abs(min_lag)` times are excluded, since these values have fewer\n        than `abs(min_lag)` values after them, which means we're unable to construct features for these times.\n        3. If `max_lag > 0`, the first `max_lag` times are excluded, since these values have fewer than `max_lag` values\n        before them, which means we're unable to construct features for these times.\n\n    Some additional behaviours to note about the `_get_feature_times` function are:\n        1. If `return_min_and_max_lags = True`, the smallest and largest lag value for each\n        series is also returned as a pair of tuples.\n        2. For those series which are either unspecified, a `None` value takes the place of\n        that series' feature time, minimum lag values, and maximum lag value.\n        3. If `is_training = True`, then `target_series` and `output_chunk_length` must\n        be provided.\n\n    Parameters\n    ----------\n    target_series\n        Optionally, the series for the regression model to predict.\n    past_covariates\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\n    future_covariates\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\n        use as inputs.\n    lags\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\n        auto-regressive features will *not* be added to `X`.\n    lags_past_covariates\n        Optionally, the lags of `past_covariates` to be used as features.\n    lags_future_covariates\n        Optionally, the lags of `future_covariates` to be used as features.\n    output_chunk_length\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. This is ignored\n        if `is_training = False`.\n    is_training\n        Optionally, specifies that training data is to be generated from the specified series. If `True`,\n        `target_series`, `output_chunk_length`, and `multi_models` must all be specified.\n    check_inputs\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\n        should be set to `True`.\n    return_min_and_max_lags\n        Optionally, specifies whether the largest magnitude lag value for each series should also be returned along with\n        the 'eligible' feature times\n\n    Note: if the lags are provided as a dictionary for the target series or any of the covariates series, the\n    component-specific lags are grouped into a single list to compute the corresponding feature time.\n\n    Returns\n    -------\n    feature_times\n        A tuple containing all the 'eligible feature times' in `target_series`, in `past_covariates`, and in\n        `future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\n        will take the place of that series' eligible times.\n    min_lags\n        Optionally, a tuple containing the smallest lag value in `lags`, `lags_past_covariates`, and\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\n        will take the place of that series' minimum lag values.\n    max_lags\n        Optionally, a tuple containing the largest lag value in `lags`, `lags_past_covariates`, and\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\n        will take the place of that series' maximum lag values.\n\n    Raises\n    ------\n    ValueError\n        If `target_series` and `output_chunk_length` are not both specified if `is_training = True`.\n    ValueError\n        If any of the `lags` inputs contain non-negative values or if none of the `lags` inputs have been specified.\n    ValueError\n        If any of the series are too short for the requested `lags` and/or `output_chunk_length` values.\n    UserWarning\n        If a `lags_*` input is specified without the accompanying time series or vice versa. The only expection to this\n        is when `lags` isn't specified alongside `target_series` when `is_training = True`, since one may wish to fit\n        a regression model without using auto-regressive features.\n\n    \"\"\"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` when `is_training = True`.')\n    if check_inputs:\n        raise_if(not isinstance(output_chunk_length, int) or output_chunk_length < 1, '`output_chunk_length` must be a positive `int`.')\n        _check_lags(lags, lags_past_covariates, lags_future_covariates)\n    (feature_times, min_lags, max_lags) = ([], [], [])\n    for (name_i, series_i, lags_i) in zip(['target_series', 'past_covariates', 'future_covariates'], [target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates]):\n        if isinstance(lags_i, dict):\n            lags_i = list(set(chain(*lags_i.values())))\n        if check_inputs and series_i is not None:\n            _check_series_length(series_i, lags_i, output_chunk_length, is_training, name_i)\n        series_specified = series_i is not None\n        lags_specified = lags_i is not None\n        is_label_series = is_training and name_i == 'target_series'\n        times_i = series_i.time_index if series_specified else None\n        max_lag_i = -min(lags_i) if lags_specified else None\n        min_lag_i = -max(lags_i) if lags_specified else None\n        if is_label_series:\n            end_idx = -output_chunk_length + 1 if output_chunk_length > 1 else None\n            times_i = times_i[:end_idx]\n        elif series_specified and lags_specified:\n            new_start = times_i[0] + series_i.freq * max_lag_i if max_lag_i < 0 else None\n            new_end = times_i[-1] + series_i.freq * min_lag_i if min_lag_i > 0 else None\n            times_i = _extend_time_index(times_i, series_i.freq, new_start=new_start, new_end=new_end)\n        if series_specified and lags_specified:\n            if min_lag_i < 0:\n                times_i = times_i[:min_lag_i]\n            if max_lag_i > 0:\n                times_i = times_i[max_lag_i:]\n        elif not is_label_series and series_specified ^ lags_specified:\n            times_i = max_lag_i = None\n            lags_name = 'lags' if name_i == 'target_series' else f'lags_{name_i}'\n            specified = lags_name if lags_specified else name_i\n            unspecified = name_i if lags_specified else lags_name\n            warnings.warn(f'`{specified}` was specified without accompanying `{unspecified}` and, thus, will be ignored.')\n        feature_times.append(times_i)\n        if series_specified and lags_specified:\n            min_lags.append(min_lag_i)\n            max_lags.append(max_lag_i)\n        else:\n            min_lags.append(None)\n            max_lags.append(None)\n    return (feature_times, min_lags, max_lags) if return_min_and_max_lags else feature_times",
        "mutated": [
            "def _get_feature_times(target_series: Optional[TimeSeries]=None, past_covariates: Optional[TimeSeries]=None, future_covariates: Optional[TimeSeries]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, is_training: bool=True, return_min_and_max_lags: bool=False, check_inputs: bool=True) -> Union[FeatureTimes, Tuple[FeatureTimes, MinLags, MaxLags]]:\n    if False:\n        i = 10\n    \"\\n    Returns a tuple containing the times in `target_series`, the times in `past_covariates`, and the times in\\n    `future_covariates` that *could* be used to create features. The returned tuple of times can then be passed\\n    to `get_shared_times` to compute the 'eligible time points' shared by all of the specified series.\\n\\n    Notes\\n    -----\\n    For the purposes of extracting feature times from each series, we define the `min_lag` and `max_lag` of\\n    each series to be:\\n            `min_lag = -max(lags_*)`,\\n            `max_lag = -min(lags_*)`\\n    where `lags_*` denotes either `lags`, `lags_past_covariates`, or `lags_future_covariates`.\\n\\n    For both `lags` and `lags_past_covariates`, `min_lag` and `max_lag` are guaranteed to be positive values,\\n    since the values in `lags` and `lags_past_covariates` must all be negative. For these two series then,\\n    `min_lag` and `max_lag` represent the smallest and largest magnitude lags requested by the user. For example:\\n            `lags = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n\\n    The values contained in `lags_future_covariates`, on the other hand, can be negative, zero, or positive; this\\n    means that there are three cases to consider:\\n        1. Both `min_lag` and `max_lag` are positive, which means that all the values in `lags_future_covariates`\\n        are negative. In this case, `min_lag` and `max_lag` correspond to the to the smallest and largest\\n        lag magnitudes respectively. For example:\\n                `lags_future_covariates = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n        2. `min_lag` is non-positive (i.e. zero or negative), but `max_lag` is positive, which means that\\n        `lags_future_covariates` contains both negative and non-negative (i.e. zero or positive) lag values.\\n        In this case, `abs(min_lag)` corresponds to the magnitude of the largest *non-negative* lag value in\\n        `lags_future_covariates`, whilst `max_lag` corresponds to the largest *negative* lag value in\\n        `lags_future_covariates`. For example:\\n                `lags_future_covariates = [-2, -1, 0, 1, 3] -> min_lag = -3, max_lag = 2`\\n        3. Both `min_lag` and `max_lag` are non-positive, which means that `lags_future_covariates` contains\\n        only non-negative lag values. In this case, `abs(min_lag)` and `abs(max_lag)`, rather confusingly,\\n        correspond to the largest and smallest lag magnitudes respectively. For example:\\n                `lags_future_covariates = [1, 2, 3] -> min_lag = -3, max_lag = -1`\\n    In all three cases, we have `min_lag <= max_lag`. As a direct consequence:\\n        1. `min_lag > 0` is a sufficient condition for `min_lag` and `max_lag` both being positive (i.e. Case 1).\\n        2. `max_lag <= 0` is a sufficient condition for `min_lag` and `max_lag` both being non-positive (i.e. Case 2).\\n\\n    To extract feature times from a `target_series` when `is_training = True`, the following steps are performed:\\n        1. The first `max_lag` times of the series are excluded; these times have too few preceeding values to\\n        construct features from.\\n        2. The last `output_chunk_length - 1` times are excluded; these times have too few succeeding times\\n        to construct labels from.\\n\\n    To extract feature times from a `target_series` when `is_training = False`, the following steps are performed:\\n        1. An additional `min_lag` times are appended to the end of the series; although these times are not contained\\n        in the original series, we're able to construct features for them since we only need the values of the series\\n        from time `t - max_lag` to `t - min_lag` to construct a feature for time `t`.\\n        2. The first `max_lag` times of the series are then excluded; these times have too few preceeding values to\\n        construct features from.\\n    The exact same procedure is performed to extract the feature times from a `past_covariates` series.\\n\\n    To extract feature times from `future_covariates`, we perform the following steps:\\n        1. Depending on the signs of `min_lag` and `max_lag`, additional times are either prepended or appended\\n        to the original series. More specifically:\\n            a) If `min_lag` and `max_lag` are both positive (i.e. `min_lag > 0`), then an additional `min_lag` times\\n            are appended to the end of the series; as previously mentioned, we only need values up to time `t - min_lag`\\n            to construct a feature for time `t`.\\n            b) If `min_lag` and `max_lag` are both non-positive (i.e. `max_lag < 0`), then an additional `abs(max_lag)`\\n            times are prepended to the start of the series; this is because we only need to know the values of the\\n            series *after* time `t + abs(max_lag)` to construct a feature for time `t` when we're only extracting\\n            positive lags from `future_covariates`.\\n            c) If `min_lag` is non-positive and `max_lag` is positive, then *no additional times* are added to the\\n            series, since constructing a feature for time `t` requires knowing values from time `t - max_lag` to\\n            time `t + abs(min_lag)`; in other words, we need to have access to time `t` itself.\\n        2. If `min_lag < 0`, the last `abs(min_lag)` times are excluded, since these values have fewer\\n        than `abs(min_lag)` values after them, which means we're unable to construct features for these times.\\n        3. If `max_lag > 0`, the first `max_lag` times are excluded, since these values have fewer than `max_lag` values\\n        before them, which means we're unable to construct features for these times.\\n\\n    Some additional behaviours to note about the `_get_feature_times` function are:\\n        1. If `return_min_and_max_lags = True`, the smallest and largest lag value for each\\n        series is also returned as a pair of tuples.\\n        2. For those series which are either unspecified, a `None` value takes the place of\\n        that series' feature time, minimum lag values, and maximum lag value.\\n        3. If `is_training = True`, then `target_series` and `output_chunk_length` must\\n        be provided.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. This is ignored\\n        if `is_training = False`.\\n    is_training\\n        Optionally, specifies that training data is to be generated from the specified series. If `True`,\\n        `target_series`, `output_chunk_length`, and `multi_models` must all be specified.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    return_min_and_max_lags\\n        Optionally, specifies whether the largest magnitude lag value for each series should also be returned along with\\n        the 'eligible' feature times\\n\\n    Note: if the lags are provided as a dictionary for the target series or any of the covariates series, the\\n    component-specific lags are grouped into a single list to compute the corresponding feature time.\\n\\n    Returns\\n    -------\\n    feature_times\\n        A tuple containing all the 'eligible feature times' in `target_series`, in `past_covariates`, and in\\n        `future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' eligible times.\\n    min_lags\\n        Optionally, a tuple containing the smallest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' minimum lag values.\\n    max_lags\\n        Optionally, a tuple containing the largest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' maximum lag values.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `target_series` and `output_chunk_length` are not both specified if `is_training = True`.\\n    ValueError\\n        If any of the `lags` inputs contain non-negative values or if none of the `lags` inputs have been specified.\\n    ValueError\\n        If any of the series are too short for the requested `lags` and/or `output_chunk_length` values.\\n    UserWarning\\n        If a `lags_*` input is specified without the accompanying time series or vice versa. The only expection to this\\n        is when `lags` isn't specified alongside `target_series` when `is_training = True`, since one may wish to fit\\n        a regression model without using auto-regressive features.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` when `is_training = True`.')\n    if check_inputs:\n        raise_if(not isinstance(output_chunk_length, int) or output_chunk_length < 1, '`output_chunk_length` must be a positive `int`.')\n        _check_lags(lags, lags_past_covariates, lags_future_covariates)\n    (feature_times, min_lags, max_lags) = ([], [], [])\n    for (name_i, series_i, lags_i) in zip(['target_series', 'past_covariates', 'future_covariates'], [target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates]):\n        if isinstance(lags_i, dict):\n            lags_i = list(set(chain(*lags_i.values())))\n        if check_inputs and series_i is not None:\n            _check_series_length(series_i, lags_i, output_chunk_length, is_training, name_i)\n        series_specified = series_i is not None\n        lags_specified = lags_i is not None\n        is_label_series = is_training and name_i == 'target_series'\n        times_i = series_i.time_index if series_specified else None\n        max_lag_i = -min(lags_i) if lags_specified else None\n        min_lag_i = -max(lags_i) if lags_specified else None\n        if is_label_series:\n            end_idx = -output_chunk_length + 1 if output_chunk_length > 1 else None\n            times_i = times_i[:end_idx]\n        elif series_specified and lags_specified:\n            new_start = times_i[0] + series_i.freq * max_lag_i if max_lag_i < 0 else None\n            new_end = times_i[-1] + series_i.freq * min_lag_i if min_lag_i > 0 else None\n            times_i = _extend_time_index(times_i, series_i.freq, new_start=new_start, new_end=new_end)\n        if series_specified and lags_specified:\n            if min_lag_i < 0:\n                times_i = times_i[:min_lag_i]\n            if max_lag_i > 0:\n                times_i = times_i[max_lag_i:]\n        elif not is_label_series and series_specified ^ lags_specified:\n            times_i = max_lag_i = None\n            lags_name = 'lags' if name_i == 'target_series' else f'lags_{name_i}'\n            specified = lags_name if lags_specified else name_i\n            unspecified = name_i if lags_specified else lags_name\n            warnings.warn(f'`{specified}` was specified without accompanying `{unspecified}` and, thus, will be ignored.')\n        feature_times.append(times_i)\n        if series_specified and lags_specified:\n            min_lags.append(min_lag_i)\n            max_lags.append(max_lag_i)\n        else:\n            min_lags.append(None)\n            max_lags.append(None)\n    return (feature_times, min_lags, max_lags) if return_min_and_max_lags else feature_times",
            "def _get_feature_times(target_series: Optional[TimeSeries]=None, past_covariates: Optional[TimeSeries]=None, future_covariates: Optional[TimeSeries]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, is_training: bool=True, return_min_and_max_lags: bool=False, check_inputs: bool=True) -> Union[FeatureTimes, Tuple[FeatureTimes, MinLags, MaxLags]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Returns a tuple containing the times in `target_series`, the times in `past_covariates`, and the times in\\n    `future_covariates` that *could* be used to create features. The returned tuple of times can then be passed\\n    to `get_shared_times` to compute the 'eligible time points' shared by all of the specified series.\\n\\n    Notes\\n    -----\\n    For the purposes of extracting feature times from each series, we define the `min_lag` and `max_lag` of\\n    each series to be:\\n            `min_lag = -max(lags_*)`,\\n            `max_lag = -min(lags_*)`\\n    where `lags_*` denotes either `lags`, `lags_past_covariates`, or `lags_future_covariates`.\\n\\n    For both `lags` and `lags_past_covariates`, `min_lag` and `max_lag` are guaranteed to be positive values,\\n    since the values in `lags` and `lags_past_covariates` must all be negative. For these two series then,\\n    `min_lag` and `max_lag` represent the smallest and largest magnitude lags requested by the user. For example:\\n            `lags = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n\\n    The values contained in `lags_future_covariates`, on the other hand, can be negative, zero, or positive; this\\n    means that there are three cases to consider:\\n        1. Both `min_lag` and `max_lag` are positive, which means that all the values in `lags_future_covariates`\\n        are negative. In this case, `min_lag` and `max_lag` correspond to the to the smallest and largest\\n        lag magnitudes respectively. For example:\\n                `lags_future_covariates = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n        2. `min_lag` is non-positive (i.e. zero or negative), but `max_lag` is positive, which means that\\n        `lags_future_covariates` contains both negative and non-negative (i.e. zero or positive) lag values.\\n        In this case, `abs(min_lag)` corresponds to the magnitude of the largest *non-negative* lag value in\\n        `lags_future_covariates`, whilst `max_lag` corresponds to the largest *negative* lag value in\\n        `lags_future_covariates`. For example:\\n                `lags_future_covariates = [-2, -1, 0, 1, 3] -> min_lag = -3, max_lag = 2`\\n        3. Both `min_lag` and `max_lag` are non-positive, which means that `lags_future_covariates` contains\\n        only non-negative lag values. In this case, `abs(min_lag)` and `abs(max_lag)`, rather confusingly,\\n        correspond to the largest and smallest lag magnitudes respectively. For example:\\n                `lags_future_covariates = [1, 2, 3] -> min_lag = -3, max_lag = -1`\\n    In all three cases, we have `min_lag <= max_lag`. As a direct consequence:\\n        1. `min_lag > 0` is a sufficient condition for `min_lag` and `max_lag` both being positive (i.e. Case 1).\\n        2. `max_lag <= 0` is a sufficient condition for `min_lag` and `max_lag` both being non-positive (i.e. Case 2).\\n\\n    To extract feature times from a `target_series` when `is_training = True`, the following steps are performed:\\n        1. The first `max_lag` times of the series are excluded; these times have too few preceeding values to\\n        construct features from.\\n        2. The last `output_chunk_length - 1` times are excluded; these times have too few succeeding times\\n        to construct labels from.\\n\\n    To extract feature times from a `target_series` when `is_training = False`, the following steps are performed:\\n        1. An additional `min_lag` times are appended to the end of the series; although these times are not contained\\n        in the original series, we're able to construct features for them since we only need the values of the series\\n        from time `t - max_lag` to `t - min_lag` to construct a feature for time `t`.\\n        2. The first `max_lag` times of the series are then excluded; these times have too few preceeding values to\\n        construct features from.\\n    The exact same procedure is performed to extract the feature times from a `past_covariates` series.\\n\\n    To extract feature times from `future_covariates`, we perform the following steps:\\n        1. Depending on the signs of `min_lag` and `max_lag`, additional times are either prepended or appended\\n        to the original series. More specifically:\\n            a) If `min_lag` and `max_lag` are both positive (i.e. `min_lag > 0`), then an additional `min_lag` times\\n            are appended to the end of the series; as previously mentioned, we only need values up to time `t - min_lag`\\n            to construct a feature for time `t`.\\n            b) If `min_lag` and `max_lag` are both non-positive (i.e. `max_lag < 0`), then an additional `abs(max_lag)`\\n            times are prepended to the start of the series; this is because we only need to know the values of the\\n            series *after* time `t + abs(max_lag)` to construct a feature for time `t` when we're only extracting\\n            positive lags from `future_covariates`.\\n            c) If `min_lag` is non-positive and `max_lag` is positive, then *no additional times* are added to the\\n            series, since constructing a feature for time `t` requires knowing values from time `t - max_lag` to\\n            time `t + abs(min_lag)`; in other words, we need to have access to time `t` itself.\\n        2. If `min_lag < 0`, the last `abs(min_lag)` times are excluded, since these values have fewer\\n        than `abs(min_lag)` values after them, which means we're unable to construct features for these times.\\n        3. If `max_lag > 0`, the first `max_lag` times are excluded, since these values have fewer than `max_lag` values\\n        before them, which means we're unable to construct features for these times.\\n\\n    Some additional behaviours to note about the `_get_feature_times` function are:\\n        1. If `return_min_and_max_lags = True`, the smallest and largest lag value for each\\n        series is also returned as a pair of tuples.\\n        2. For those series which are either unspecified, a `None` value takes the place of\\n        that series' feature time, minimum lag values, and maximum lag value.\\n        3. If `is_training = True`, then `target_series` and `output_chunk_length` must\\n        be provided.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. This is ignored\\n        if `is_training = False`.\\n    is_training\\n        Optionally, specifies that training data is to be generated from the specified series. If `True`,\\n        `target_series`, `output_chunk_length`, and `multi_models` must all be specified.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    return_min_and_max_lags\\n        Optionally, specifies whether the largest magnitude lag value for each series should also be returned along with\\n        the 'eligible' feature times\\n\\n    Note: if the lags are provided as a dictionary for the target series or any of the covariates series, the\\n    component-specific lags are grouped into a single list to compute the corresponding feature time.\\n\\n    Returns\\n    -------\\n    feature_times\\n        A tuple containing all the 'eligible feature times' in `target_series`, in `past_covariates`, and in\\n        `future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' eligible times.\\n    min_lags\\n        Optionally, a tuple containing the smallest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' minimum lag values.\\n    max_lags\\n        Optionally, a tuple containing the largest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' maximum lag values.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `target_series` and `output_chunk_length` are not both specified if `is_training = True`.\\n    ValueError\\n        If any of the `lags` inputs contain non-negative values or if none of the `lags` inputs have been specified.\\n    ValueError\\n        If any of the series are too short for the requested `lags` and/or `output_chunk_length` values.\\n    UserWarning\\n        If a `lags_*` input is specified without the accompanying time series or vice versa. The only expection to this\\n        is when `lags` isn't specified alongside `target_series` when `is_training = True`, since one may wish to fit\\n        a regression model without using auto-regressive features.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` when `is_training = True`.')\n    if check_inputs:\n        raise_if(not isinstance(output_chunk_length, int) or output_chunk_length < 1, '`output_chunk_length` must be a positive `int`.')\n        _check_lags(lags, lags_past_covariates, lags_future_covariates)\n    (feature_times, min_lags, max_lags) = ([], [], [])\n    for (name_i, series_i, lags_i) in zip(['target_series', 'past_covariates', 'future_covariates'], [target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates]):\n        if isinstance(lags_i, dict):\n            lags_i = list(set(chain(*lags_i.values())))\n        if check_inputs and series_i is not None:\n            _check_series_length(series_i, lags_i, output_chunk_length, is_training, name_i)\n        series_specified = series_i is not None\n        lags_specified = lags_i is not None\n        is_label_series = is_training and name_i == 'target_series'\n        times_i = series_i.time_index if series_specified else None\n        max_lag_i = -min(lags_i) if lags_specified else None\n        min_lag_i = -max(lags_i) if lags_specified else None\n        if is_label_series:\n            end_idx = -output_chunk_length + 1 if output_chunk_length > 1 else None\n            times_i = times_i[:end_idx]\n        elif series_specified and lags_specified:\n            new_start = times_i[0] + series_i.freq * max_lag_i if max_lag_i < 0 else None\n            new_end = times_i[-1] + series_i.freq * min_lag_i if min_lag_i > 0 else None\n            times_i = _extend_time_index(times_i, series_i.freq, new_start=new_start, new_end=new_end)\n        if series_specified and lags_specified:\n            if min_lag_i < 0:\n                times_i = times_i[:min_lag_i]\n            if max_lag_i > 0:\n                times_i = times_i[max_lag_i:]\n        elif not is_label_series and series_specified ^ lags_specified:\n            times_i = max_lag_i = None\n            lags_name = 'lags' if name_i == 'target_series' else f'lags_{name_i}'\n            specified = lags_name if lags_specified else name_i\n            unspecified = name_i if lags_specified else lags_name\n            warnings.warn(f'`{specified}` was specified without accompanying `{unspecified}` and, thus, will be ignored.')\n        feature_times.append(times_i)\n        if series_specified and lags_specified:\n            min_lags.append(min_lag_i)\n            max_lags.append(max_lag_i)\n        else:\n            min_lags.append(None)\n            max_lags.append(None)\n    return (feature_times, min_lags, max_lags) if return_min_and_max_lags else feature_times",
            "def _get_feature_times(target_series: Optional[TimeSeries]=None, past_covariates: Optional[TimeSeries]=None, future_covariates: Optional[TimeSeries]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, is_training: bool=True, return_min_and_max_lags: bool=False, check_inputs: bool=True) -> Union[FeatureTimes, Tuple[FeatureTimes, MinLags, MaxLags]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Returns a tuple containing the times in `target_series`, the times in `past_covariates`, and the times in\\n    `future_covariates` that *could* be used to create features. The returned tuple of times can then be passed\\n    to `get_shared_times` to compute the 'eligible time points' shared by all of the specified series.\\n\\n    Notes\\n    -----\\n    For the purposes of extracting feature times from each series, we define the `min_lag` and `max_lag` of\\n    each series to be:\\n            `min_lag = -max(lags_*)`,\\n            `max_lag = -min(lags_*)`\\n    where `lags_*` denotes either `lags`, `lags_past_covariates`, or `lags_future_covariates`.\\n\\n    For both `lags` and `lags_past_covariates`, `min_lag` and `max_lag` are guaranteed to be positive values,\\n    since the values in `lags` and `lags_past_covariates` must all be negative. For these two series then,\\n    `min_lag` and `max_lag` represent the smallest and largest magnitude lags requested by the user. For example:\\n            `lags = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n\\n    The values contained in `lags_future_covariates`, on the other hand, can be negative, zero, or positive; this\\n    means that there are three cases to consider:\\n        1. Both `min_lag` and `max_lag` are positive, which means that all the values in `lags_future_covariates`\\n        are negative. In this case, `min_lag` and `max_lag` correspond to the to the smallest and largest\\n        lag magnitudes respectively. For example:\\n                `lags_future_covariates = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n        2. `min_lag` is non-positive (i.e. zero or negative), but `max_lag` is positive, which means that\\n        `lags_future_covariates` contains both negative and non-negative (i.e. zero or positive) lag values.\\n        In this case, `abs(min_lag)` corresponds to the magnitude of the largest *non-negative* lag value in\\n        `lags_future_covariates`, whilst `max_lag` corresponds to the largest *negative* lag value in\\n        `lags_future_covariates`. For example:\\n                `lags_future_covariates = [-2, -1, 0, 1, 3] -> min_lag = -3, max_lag = 2`\\n        3. Both `min_lag` and `max_lag` are non-positive, which means that `lags_future_covariates` contains\\n        only non-negative lag values. In this case, `abs(min_lag)` and `abs(max_lag)`, rather confusingly,\\n        correspond to the largest and smallest lag magnitudes respectively. For example:\\n                `lags_future_covariates = [1, 2, 3] -> min_lag = -3, max_lag = -1`\\n    In all three cases, we have `min_lag <= max_lag`. As a direct consequence:\\n        1. `min_lag > 0` is a sufficient condition for `min_lag` and `max_lag` both being positive (i.e. Case 1).\\n        2. `max_lag <= 0` is a sufficient condition for `min_lag` and `max_lag` both being non-positive (i.e. Case 2).\\n\\n    To extract feature times from a `target_series` when `is_training = True`, the following steps are performed:\\n        1. The first `max_lag` times of the series are excluded; these times have too few preceeding values to\\n        construct features from.\\n        2. The last `output_chunk_length - 1` times are excluded; these times have too few succeeding times\\n        to construct labels from.\\n\\n    To extract feature times from a `target_series` when `is_training = False`, the following steps are performed:\\n        1. An additional `min_lag` times are appended to the end of the series; although these times are not contained\\n        in the original series, we're able to construct features for them since we only need the values of the series\\n        from time `t - max_lag` to `t - min_lag` to construct a feature for time `t`.\\n        2. The first `max_lag` times of the series are then excluded; these times have too few preceeding values to\\n        construct features from.\\n    The exact same procedure is performed to extract the feature times from a `past_covariates` series.\\n\\n    To extract feature times from `future_covariates`, we perform the following steps:\\n        1. Depending on the signs of `min_lag` and `max_lag`, additional times are either prepended or appended\\n        to the original series. More specifically:\\n            a) If `min_lag` and `max_lag` are both positive (i.e. `min_lag > 0`), then an additional `min_lag` times\\n            are appended to the end of the series; as previously mentioned, we only need values up to time `t - min_lag`\\n            to construct a feature for time `t`.\\n            b) If `min_lag` and `max_lag` are both non-positive (i.e. `max_lag < 0`), then an additional `abs(max_lag)`\\n            times are prepended to the start of the series; this is because we only need to know the values of the\\n            series *after* time `t + abs(max_lag)` to construct a feature for time `t` when we're only extracting\\n            positive lags from `future_covariates`.\\n            c) If `min_lag` is non-positive and `max_lag` is positive, then *no additional times* are added to the\\n            series, since constructing a feature for time `t` requires knowing values from time `t - max_lag` to\\n            time `t + abs(min_lag)`; in other words, we need to have access to time `t` itself.\\n        2. If `min_lag < 0`, the last `abs(min_lag)` times are excluded, since these values have fewer\\n        than `abs(min_lag)` values after them, which means we're unable to construct features for these times.\\n        3. If `max_lag > 0`, the first `max_lag` times are excluded, since these values have fewer than `max_lag` values\\n        before them, which means we're unable to construct features for these times.\\n\\n    Some additional behaviours to note about the `_get_feature_times` function are:\\n        1. If `return_min_and_max_lags = True`, the smallest and largest lag value for each\\n        series is also returned as a pair of tuples.\\n        2. For those series which are either unspecified, a `None` value takes the place of\\n        that series' feature time, minimum lag values, and maximum lag value.\\n        3. If `is_training = True`, then `target_series` and `output_chunk_length` must\\n        be provided.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. This is ignored\\n        if `is_training = False`.\\n    is_training\\n        Optionally, specifies that training data is to be generated from the specified series. If `True`,\\n        `target_series`, `output_chunk_length`, and `multi_models` must all be specified.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    return_min_and_max_lags\\n        Optionally, specifies whether the largest magnitude lag value for each series should also be returned along with\\n        the 'eligible' feature times\\n\\n    Note: if the lags are provided as a dictionary for the target series or any of the covariates series, the\\n    component-specific lags are grouped into a single list to compute the corresponding feature time.\\n\\n    Returns\\n    -------\\n    feature_times\\n        A tuple containing all the 'eligible feature times' in `target_series`, in `past_covariates`, and in\\n        `future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' eligible times.\\n    min_lags\\n        Optionally, a tuple containing the smallest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' minimum lag values.\\n    max_lags\\n        Optionally, a tuple containing the largest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' maximum lag values.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `target_series` and `output_chunk_length` are not both specified if `is_training = True`.\\n    ValueError\\n        If any of the `lags` inputs contain non-negative values or if none of the `lags` inputs have been specified.\\n    ValueError\\n        If any of the series are too short for the requested `lags` and/or `output_chunk_length` values.\\n    UserWarning\\n        If a `lags_*` input is specified without the accompanying time series or vice versa. The only expection to this\\n        is when `lags` isn't specified alongside `target_series` when `is_training = True`, since one may wish to fit\\n        a regression model without using auto-regressive features.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` when `is_training = True`.')\n    if check_inputs:\n        raise_if(not isinstance(output_chunk_length, int) or output_chunk_length < 1, '`output_chunk_length` must be a positive `int`.')\n        _check_lags(lags, lags_past_covariates, lags_future_covariates)\n    (feature_times, min_lags, max_lags) = ([], [], [])\n    for (name_i, series_i, lags_i) in zip(['target_series', 'past_covariates', 'future_covariates'], [target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates]):\n        if isinstance(lags_i, dict):\n            lags_i = list(set(chain(*lags_i.values())))\n        if check_inputs and series_i is not None:\n            _check_series_length(series_i, lags_i, output_chunk_length, is_training, name_i)\n        series_specified = series_i is not None\n        lags_specified = lags_i is not None\n        is_label_series = is_training and name_i == 'target_series'\n        times_i = series_i.time_index if series_specified else None\n        max_lag_i = -min(lags_i) if lags_specified else None\n        min_lag_i = -max(lags_i) if lags_specified else None\n        if is_label_series:\n            end_idx = -output_chunk_length + 1 if output_chunk_length > 1 else None\n            times_i = times_i[:end_idx]\n        elif series_specified and lags_specified:\n            new_start = times_i[0] + series_i.freq * max_lag_i if max_lag_i < 0 else None\n            new_end = times_i[-1] + series_i.freq * min_lag_i if min_lag_i > 0 else None\n            times_i = _extend_time_index(times_i, series_i.freq, new_start=new_start, new_end=new_end)\n        if series_specified and lags_specified:\n            if min_lag_i < 0:\n                times_i = times_i[:min_lag_i]\n            if max_lag_i > 0:\n                times_i = times_i[max_lag_i:]\n        elif not is_label_series and series_specified ^ lags_specified:\n            times_i = max_lag_i = None\n            lags_name = 'lags' if name_i == 'target_series' else f'lags_{name_i}'\n            specified = lags_name if lags_specified else name_i\n            unspecified = name_i if lags_specified else lags_name\n            warnings.warn(f'`{specified}` was specified without accompanying `{unspecified}` and, thus, will be ignored.')\n        feature_times.append(times_i)\n        if series_specified and lags_specified:\n            min_lags.append(min_lag_i)\n            max_lags.append(max_lag_i)\n        else:\n            min_lags.append(None)\n            max_lags.append(None)\n    return (feature_times, min_lags, max_lags) if return_min_and_max_lags else feature_times",
            "def _get_feature_times(target_series: Optional[TimeSeries]=None, past_covariates: Optional[TimeSeries]=None, future_covariates: Optional[TimeSeries]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, is_training: bool=True, return_min_and_max_lags: bool=False, check_inputs: bool=True) -> Union[FeatureTimes, Tuple[FeatureTimes, MinLags, MaxLags]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Returns a tuple containing the times in `target_series`, the times in `past_covariates`, and the times in\\n    `future_covariates` that *could* be used to create features. The returned tuple of times can then be passed\\n    to `get_shared_times` to compute the 'eligible time points' shared by all of the specified series.\\n\\n    Notes\\n    -----\\n    For the purposes of extracting feature times from each series, we define the `min_lag` and `max_lag` of\\n    each series to be:\\n            `min_lag = -max(lags_*)`,\\n            `max_lag = -min(lags_*)`\\n    where `lags_*` denotes either `lags`, `lags_past_covariates`, or `lags_future_covariates`.\\n\\n    For both `lags` and `lags_past_covariates`, `min_lag` and `max_lag` are guaranteed to be positive values,\\n    since the values in `lags` and `lags_past_covariates` must all be negative. For these two series then,\\n    `min_lag` and `max_lag` represent the smallest and largest magnitude lags requested by the user. For example:\\n            `lags = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n\\n    The values contained in `lags_future_covariates`, on the other hand, can be negative, zero, or positive; this\\n    means that there are three cases to consider:\\n        1. Both `min_lag` and `max_lag` are positive, which means that all the values in `lags_future_covariates`\\n        are negative. In this case, `min_lag` and `max_lag` correspond to the to the smallest and largest\\n        lag magnitudes respectively. For example:\\n                `lags_future_covariates = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n        2. `min_lag` is non-positive (i.e. zero or negative), but `max_lag` is positive, which means that\\n        `lags_future_covariates` contains both negative and non-negative (i.e. zero or positive) lag values.\\n        In this case, `abs(min_lag)` corresponds to the magnitude of the largest *non-negative* lag value in\\n        `lags_future_covariates`, whilst `max_lag` corresponds to the largest *negative* lag value in\\n        `lags_future_covariates`. For example:\\n                `lags_future_covariates = [-2, -1, 0, 1, 3] -> min_lag = -3, max_lag = 2`\\n        3. Both `min_lag` and `max_lag` are non-positive, which means that `lags_future_covariates` contains\\n        only non-negative lag values. In this case, `abs(min_lag)` and `abs(max_lag)`, rather confusingly,\\n        correspond to the largest and smallest lag magnitudes respectively. For example:\\n                `lags_future_covariates = [1, 2, 3] -> min_lag = -3, max_lag = -1`\\n    In all three cases, we have `min_lag <= max_lag`. As a direct consequence:\\n        1. `min_lag > 0` is a sufficient condition for `min_lag` and `max_lag` both being positive (i.e. Case 1).\\n        2. `max_lag <= 0` is a sufficient condition for `min_lag` and `max_lag` both being non-positive (i.e. Case 2).\\n\\n    To extract feature times from a `target_series` when `is_training = True`, the following steps are performed:\\n        1. The first `max_lag` times of the series are excluded; these times have too few preceeding values to\\n        construct features from.\\n        2. The last `output_chunk_length - 1` times are excluded; these times have too few succeeding times\\n        to construct labels from.\\n\\n    To extract feature times from a `target_series` when `is_training = False`, the following steps are performed:\\n        1. An additional `min_lag` times are appended to the end of the series; although these times are not contained\\n        in the original series, we're able to construct features for them since we only need the values of the series\\n        from time `t - max_lag` to `t - min_lag` to construct a feature for time `t`.\\n        2. The first `max_lag` times of the series are then excluded; these times have too few preceeding values to\\n        construct features from.\\n    The exact same procedure is performed to extract the feature times from a `past_covariates` series.\\n\\n    To extract feature times from `future_covariates`, we perform the following steps:\\n        1. Depending on the signs of `min_lag` and `max_lag`, additional times are either prepended or appended\\n        to the original series. More specifically:\\n            a) If `min_lag` and `max_lag` are both positive (i.e. `min_lag > 0`), then an additional `min_lag` times\\n            are appended to the end of the series; as previously mentioned, we only need values up to time `t - min_lag`\\n            to construct a feature for time `t`.\\n            b) If `min_lag` and `max_lag` are both non-positive (i.e. `max_lag < 0`), then an additional `abs(max_lag)`\\n            times are prepended to the start of the series; this is because we only need to know the values of the\\n            series *after* time `t + abs(max_lag)` to construct a feature for time `t` when we're only extracting\\n            positive lags from `future_covariates`.\\n            c) If `min_lag` is non-positive and `max_lag` is positive, then *no additional times* are added to the\\n            series, since constructing a feature for time `t` requires knowing values from time `t - max_lag` to\\n            time `t + abs(min_lag)`; in other words, we need to have access to time `t` itself.\\n        2. If `min_lag < 0`, the last `abs(min_lag)` times are excluded, since these values have fewer\\n        than `abs(min_lag)` values after them, which means we're unable to construct features for these times.\\n        3. If `max_lag > 0`, the first `max_lag` times are excluded, since these values have fewer than `max_lag` values\\n        before them, which means we're unable to construct features for these times.\\n\\n    Some additional behaviours to note about the `_get_feature_times` function are:\\n        1. If `return_min_and_max_lags = True`, the smallest and largest lag value for each\\n        series is also returned as a pair of tuples.\\n        2. For those series which are either unspecified, a `None` value takes the place of\\n        that series' feature time, minimum lag values, and maximum lag value.\\n        3. If `is_training = True`, then `target_series` and `output_chunk_length` must\\n        be provided.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. This is ignored\\n        if `is_training = False`.\\n    is_training\\n        Optionally, specifies that training data is to be generated from the specified series. If `True`,\\n        `target_series`, `output_chunk_length`, and `multi_models` must all be specified.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    return_min_and_max_lags\\n        Optionally, specifies whether the largest magnitude lag value for each series should also be returned along with\\n        the 'eligible' feature times\\n\\n    Note: if the lags are provided as a dictionary for the target series or any of the covariates series, the\\n    component-specific lags are grouped into a single list to compute the corresponding feature time.\\n\\n    Returns\\n    -------\\n    feature_times\\n        A tuple containing all the 'eligible feature times' in `target_series`, in `past_covariates`, and in\\n        `future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' eligible times.\\n    min_lags\\n        Optionally, a tuple containing the smallest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' minimum lag values.\\n    max_lags\\n        Optionally, a tuple containing the largest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' maximum lag values.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `target_series` and `output_chunk_length` are not both specified if `is_training = True`.\\n    ValueError\\n        If any of the `lags` inputs contain non-negative values or if none of the `lags` inputs have been specified.\\n    ValueError\\n        If any of the series are too short for the requested `lags` and/or `output_chunk_length` values.\\n    UserWarning\\n        If a `lags_*` input is specified without the accompanying time series or vice versa. The only expection to this\\n        is when `lags` isn't specified alongside `target_series` when `is_training = True`, since one may wish to fit\\n        a regression model without using auto-regressive features.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` when `is_training = True`.')\n    if check_inputs:\n        raise_if(not isinstance(output_chunk_length, int) or output_chunk_length < 1, '`output_chunk_length` must be a positive `int`.')\n        _check_lags(lags, lags_past_covariates, lags_future_covariates)\n    (feature_times, min_lags, max_lags) = ([], [], [])\n    for (name_i, series_i, lags_i) in zip(['target_series', 'past_covariates', 'future_covariates'], [target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates]):\n        if isinstance(lags_i, dict):\n            lags_i = list(set(chain(*lags_i.values())))\n        if check_inputs and series_i is not None:\n            _check_series_length(series_i, lags_i, output_chunk_length, is_training, name_i)\n        series_specified = series_i is not None\n        lags_specified = lags_i is not None\n        is_label_series = is_training and name_i == 'target_series'\n        times_i = series_i.time_index if series_specified else None\n        max_lag_i = -min(lags_i) if lags_specified else None\n        min_lag_i = -max(lags_i) if lags_specified else None\n        if is_label_series:\n            end_idx = -output_chunk_length + 1 if output_chunk_length > 1 else None\n            times_i = times_i[:end_idx]\n        elif series_specified and lags_specified:\n            new_start = times_i[0] + series_i.freq * max_lag_i if max_lag_i < 0 else None\n            new_end = times_i[-1] + series_i.freq * min_lag_i if min_lag_i > 0 else None\n            times_i = _extend_time_index(times_i, series_i.freq, new_start=new_start, new_end=new_end)\n        if series_specified and lags_specified:\n            if min_lag_i < 0:\n                times_i = times_i[:min_lag_i]\n            if max_lag_i > 0:\n                times_i = times_i[max_lag_i:]\n        elif not is_label_series and series_specified ^ lags_specified:\n            times_i = max_lag_i = None\n            lags_name = 'lags' if name_i == 'target_series' else f'lags_{name_i}'\n            specified = lags_name if lags_specified else name_i\n            unspecified = name_i if lags_specified else lags_name\n            warnings.warn(f'`{specified}` was specified without accompanying `{unspecified}` and, thus, will be ignored.')\n        feature_times.append(times_i)\n        if series_specified and lags_specified:\n            min_lags.append(min_lag_i)\n            max_lags.append(max_lag_i)\n        else:\n            min_lags.append(None)\n            max_lags.append(None)\n    return (feature_times, min_lags, max_lags) if return_min_and_max_lags else feature_times",
            "def _get_feature_times(target_series: Optional[TimeSeries]=None, past_covariates: Optional[TimeSeries]=None, future_covariates: Optional[TimeSeries]=None, lags: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]=None, output_chunk_length: int=1, is_training: bool=True, return_min_and_max_lags: bool=False, check_inputs: bool=True) -> Union[FeatureTimes, Tuple[FeatureTimes, MinLags, MaxLags]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Returns a tuple containing the times in `target_series`, the times in `past_covariates`, and the times in\\n    `future_covariates` that *could* be used to create features. The returned tuple of times can then be passed\\n    to `get_shared_times` to compute the 'eligible time points' shared by all of the specified series.\\n\\n    Notes\\n    -----\\n    For the purposes of extracting feature times from each series, we define the `min_lag` and `max_lag` of\\n    each series to be:\\n            `min_lag = -max(lags_*)`,\\n            `max_lag = -min(lags_*)`\\n    where `lags_*` denotes either `lags`, `lags_past_covariates`, or `lags_future_covariates`.\\n\\n    For both `lags` and `lags_past_covariates`, `min_lag` and `max_lag` are guaranteed to be positive values,\\n    since the values in `lags` and `lags_past_covariates` must all be negative. For these two series then,\\n    `min_lag` and `max_lag` represent the smallest and largest magnitude lags requested by the user. For example:\\n            `lags = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n\\n    The values contained in `lags_future_covariates`, on the other hand, can be negative, zero, or positive; this\\n    means that there are three cases to consider:\\n        1. Both `min_lag` and `max_lag` are positive, which means that all the values in `lags_future_covariates`\\n        are negative. In this case, `min_lag` and `max_lag` correspond to the to the smallest and largest\\n        lag magnitudes respectively. For example:\\n                `lags_future_covariates = [-3, -2, -1] -> min_lag = 1, max_lag = 3`\\n        2. `min_lag` is non-positive (i.e. zero or negative), but `max_lag` is positive, which means that\\n        `lags_future_covariates` contains both negative and non-negative (i.e. zero or positive) lag values.\\n        In this case, `abs(min_lag)` corresponds to the magnitude of the largest *non-negative* lag value in\\n        `lags_future_covariates`, whilst `max_lag` corresponds to the largest *negative* lag value in\\n        `lags_future_covariates`. For example:\\n                `lags_future_covariates = [-2, -1, 0, 1, 3] -> min_lag = -3, max_lag = 2`\\n        3. Both `min_lag` and `max_lag` are non-positive, which means that `lags_future_covariates` contains\\n        only non-negative lag values. In this case, `abs(min_lag)` and `abs(max_lag)`, rather confusingly,\\n        correspond to the largest and smallest lag magnitudes respectively. For example:\\n                `lags_future_covariates = [1, 2, 3] -> min_lag = -3, max_lag = -1`\\n    In all three cases, we have `min_lag <= max_lag`. As a direct consequence:\\n        1. `min_lag > 0` is a sufficient condition for `min_lag` and `max_lag` both being positive (i.e. Case 1).\\n        2. `max_lag <= 0` is a sufficient condition for `min_lag` and `max_lag` both being non-positive (i.e. Case 2).\\n\\n    To extract feature times from a `target_series` when `is_training = True`, the following steps are performed:\\n        1. The first `max_lag` times of the series are excluded; these times have too few preceeding values to\\n        construct features from.\\n        2. The last `output_chunk_length - 1` times are excluded; these times have too few succeeding times\\n        to construct labels from.\\n\\n    To extract feature times from a `target_series` when `is_training = False`, the following steps are performed:\\n        1. An additional `min_lag` times are appended to the end of the series; although these times are not contained\\n        in the original series, we're able to construct features for them since we only need the values of the series\\n        from time `t - max_lag` to `t - min_lag` to construct a feature for time `t`.\\n        2. The first `max_lag` times of the series are then excluded; these times have too few preceeding values to\\n        construct features from.\\n    The exact same procedure is performed to extract the feature times from a `past_covariates` series.\\n\\n    To extract feature times from `future_covariates`, we perform the following steps:\\n        1. Depending on the signs of `min_lag` and `max_lag`, additional times are either prepended or appended\\n        to the original series. More specifically:\\n            a) If `min_lag` and `max_lag` are both positive (i.e. `min_lag > 0`), then an additional `min_lag` times\\n            are appended to the end of the series; as previously mentioned, we only need values up to time `t - min_lag`\\n            to construct a feature for time `t`.\\n            b) If `min_lag` and `max_lag` are both non-positive (i.e. `max_lag < 0`), then an additional `abs(max_lag)`\\n            times are prepended to the start of the series; this is because we only need to know the values of the\\n            series *after* time `t + abs(max_lag)` to construct a feature for time `t` when we're only extracting\\n            positive lags from `future_covariates`.\\n            c) If `min_lag` is non-positive and `max_lag` is positive, then *no additional times* are added to the\\n            series, since constructing a feature for time `t` requires knowing values from time `t - max_lag` to\\n            time `t + abs(min_lag)`; in other words, we need to have access to time `t` itself.\\n        2. If `min_lag < 0`, the last `abs(min_lag)` times are excluded, since these values have fewer\\n        than `abs(min_lag)` values after them, which means we're unable to construct features for these times.\\n        3. If `max_lag > 0`, the first `max_lag` times are excluded, since these values have fewer than `max_lag` values\\n        before them, which means we're unable to construct features for these times.\\n\\n    Some additional behaviours to note about the `_get_feature_times` function are:\\n        1. If `return_min_and_max_lags = True`, the smallest and largest lag value for each\\n        series is also returned as a pair of tuples.\\n        2. For those series which are either unspecified, a `None` value takes the place of\\n        that series' feature time, minimum lag values, and maximum lag value.\\n        3. If `is_training = True`, then `target_series` and `output_chunk_length` must\\n        be provided.\\n\\n    Parameters\\n    ----------\\n    target_series\\n        Optionally, the series for the regression model to predict.\\n    past_covariates\\n        Optionally, the past covariates series that the regression model will use as inputs. Unlike the\\n        `target_series`, `past_covariates` are *not* to be predicted by the regression model.\\n    future_covariates\\n        Optionally, the future covariates (i.e. exogenous covariates) series that the regression model will\\n        use as inputs.\\n    lags\\n        Optionally, the lags of the target series to be used as (auto-regressive) features. If not specified,\\n        auto-regressive features will *not* be added to `X`.\\n    lags_past_covariates\\n        Optionally, the lags of `past_covariates` to be used as features.\\n    lags_future_covariates\\n        Optionally, the lags of `future_covariates` to be used as features.\\n    output_chunk_length\\n        Optionally, the number of timesteps ahead into the future the regression model is to predict. This is ignored\\n        if `is_training = False`.\\n    is_training\\n        Optionally, specifies that training data is to be generated from the specified series. If `True`,\\n        `target_series`, `output_chunk_length`, and `multi_models` must all be specified.\\n    check_inputs\\n        Optionally, specifies that the `lags_*` and `series_*` inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__` of a class), otherwise\\n        should be set to `True`.\\n    return_min_and_max_lags\\n        Optionally, specifies whether the largest magnitude lag value for each series should also be returned along with\\n        the 'eligible' feature times\\n\\n    Note: if the lags are provided as a dictionary for the target series or any of the covariates series, the\\n    component-specific lags are grouped into a single list to compute the corresponding feature time.\\n\\n    Returns\\n    -------\\n    feature_times\\n        A tuple containing all the 'eligible feature times' in `target_series`, in `past_covariates`, and in\\n        `future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' eligible times.\\n    min_lags\\n        Optionally, a tuple containing the smallest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' minimum lag values.\\n    max_lags\\n        Optionally, a tuple containing the largest lag value in `lags`, `lags_past_covariates`, and\\n        `lags_future_covariates`, in that order. If a particular series-lag pair isn't fully specified, then a `None`\\n        will take the place of that series' maximum lag values.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `target_series` and `output_chunk_length` are not both specified if `is_training = True`.\\n    ValueError\\n        If any of the `lags` inputs contain non-negative values or if none of the `lags` inputs have been specified.\\n    ValueError\\n        If any of the series are too short for the requested `lags` and/or `output_chunk_length` values.\\n    UserWarning\\n        If a `lags_*` input is specified without the accompanying time series or vice versa. The only expection to this\\n        is when `lags` isn't specified alongside `target_series` when `is_training = True`, since one may wish to fit\\n        a regression model without using auto-regressive features.\\n\\n    \"\n    raise_if(is_training and target_series is None, 'Must specify `target_series` when `is_training = True`.')\n    if check_inputs:\n        raise_if(not isinstance(output_chunk_length, int) or output_chunk_length < 1, '`output_chunk_length` must be a positive `int`.')\n        _check_lags(lags, lags_past_covariates, lags_future_covariates)\n    (feature_times, min_lags, max_lags) = ([], [], [])\n    for (name_i, series_i, lags_i) in zip(['target_series', 'past_covariates', 'future_covariates'], [target_series, past_covariates, future_covariates], [lags, lags_past_covariates, lags_future_covariates]):\n        if isinstance(lags_i, dict):\n            lags_i = list(set(chain(*lags_i.values())))\n        if check_inputs and series_i is not None:\n            _check_series_length(series_i, lags_i, output_chunk_length, is_training, name_i)\n        series_specified = series_i is not None\n        lags_specified = lags_i is not None\n        is_label_series = is_training and name_i == 'target_series'\n        times_i = series_i.time_index if series_specified else None\n        max_lag_i = -min(lags_i) if lags_specified else None\n        min_lag_i = -max(lags_i) if lags_specified else None\n        if is_label_series:\n            end_idx = -output_chunk_length + 1 if output_chunk_length > 1 else None\n            times_i = times_i[:end_idx]\n        elif series_specified and lags_specified:\n            new_start = times_i[0] + series_i.freq * max_lag_i if max_lag_i < 0 else None\n            new_end = times_i[-1] + series_i.freq * min_lag_i if min_lag_i > 0 else None\n            times_i = _extend_time_index(times_i, series_i.freq, new_start=new_start, new_end=new_end)\n        if series_specified and lags_specified:\n            if min_lag_i < 0:\n                times_i = times_i[:min_lag_i]\n            if max_lag_i > 0:\n                times_i = times_i[max_lag_i:]\n        elif not is_label_series and series_specified ^ lags_specified:\n            times_i = max_lag_i = None\n            lags_name = 'lags' if name_i == 'target_series' else f'lags_{name_i}'\n            specified = lags_name if lags_specified else name_i\n            unspecified = name_i if lags_specified else lags_name\n            warnings.warn(f'`{specified}` was specified without accompanying `{unspecified}` and, thus, will be ignored.')\n        feature_times.append(times_i)\n        if series_specified and lags_specified:\n            min_lags.append(min_lag_i)\n            max_lags.append(max_lag_i)\n        else:\n            min_lags.append(None)\n            max_lags.append(None)\n    return (feature_times, min_lags, max_lags) if return_min_and_max_lags else feature_times"
        ]
    },
    {
        "func_name": "intersection_func",
        "original": "def intersection_func(series_or_times_1, series_or_times_2):\n    times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n    times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n    return times_1.intersection(times_2, sort=sort)",
        "mutated": [
            "def intersection_func(series_or_times_1, series_or_times_2):\n    if False:\n        i = 10\n    times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n    times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n    return times_1.intersection(times_2, sort=sort)",
            "def intersection_func(series_or_times_1, series_or_times_2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n    times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n    return times_1.intersection(times_2, sort=sort)",
            "def intersection_func(series_or_times_1, series_or_times_2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n    times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n    return times_1.intersection(times_2, sort=sort)",
            "def intersection_func(series_or_times_1, series_or_times_2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n    times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n    return times_1.intersection(times_2, sort=sort)",
            "def intersection_func(series_or_times_1, series_or_times_2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n    times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n    return times_1.intersection(times_2, sort=sort)"
        ]
    },
    {
        "func_name": "get_shared_times",
        "original": "def get_shared_times(*series_or_times: Union[TimeSeries, pd.Index, None], sort: bool=True) -> pd.Index:\n    \"\"\"\n    Returns the times shared by all of the specified `TimeSeries` or time indexes (i.e. the intersection of all\n    these times). If `sort = True`, then these shared times are sorted from earliest to latest. Any `TimeSeries` or\n    time indices in `series_or_times` that aren't specified (i.e. are `None`) are simply ignored.\n\n    Parameters\n    ----------\n    series_or_times\n        The `TimeSeries` and/or time indices that should 'intersected'.\n    sort\n        Optionally, specifies that the returned shared times should be sorted from earliest to latest.\n\n    Returns\n    -------\n    shared_times\n        The time indices present in all of the specified `TimeSeries` and/or time indices.\n\n    Raises\n    ------\n    TypeError\n        If the specified `TimeSeries` and/or time indices do not all share the same type of time index (i.e. must\n        either be all `pd.DatetimeIndex` or all `pd.RangeIndex`).\n    \"\"\"\n    sort = None if sort else False\n\n    def intersection_func(series_or_times_1, series_or_times_2):\n        times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n        times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n        return times_1.intersection(times_2, sort=sort)\n    specified_inputs = [series for series in series_or_times if series is not None]\n    if not specified_inputs:\n        shared_times = None\n    elif len(specified_inputs) == 1:\n        shared_times = specified_inputs[0].time_index if isinstance(specified_inputs[0], TimeSeries) else specified_inputs[0]\n        shared_times = None if len(shared_times) == 0 else shared_times\n    else:\n        shared_times = reduce(intersection_func, specified_inputs)\n        if shared_times.empty:\n            shared_times = None\n            times_types = [type(ts.time_index if isinstance(ts, TimeSeries) else ts) for ts in specified_inputs]\n            raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n    return shared_times",
        "mutated": [
            "def get_shared_times(*series_or_times: Union[TimeSeries, pd.Index, None], sort: bool=True) -> pd.Index:\n    if False:\n        i = 10\n    \"\\n    Returns the times shared by all of the specified `TimeSeries` or time indexes (i.e. the intersection of all\\n    these times). If `sort = True`, then these shared times are sorted from earliest to latest. Any `TimeSeries` or\\n    time indices in `series_or_times` that aren't specified (i.e. are `None`) are simply ignored.\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or time indices that should 'intersected'.\\n    sort\\n        Optionally, specifies that the returned shared times should be sorted from earliest to latest.\\n\\n    Returns\\n    -------\\n    shared_times\\n        The time indices present in all of the specified `TimeSeries` and/or time indices.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the specified `TimeSeries` and/or time indices do not all share the same type of time index (i.e. must\\n        either be all `pd.DatetimeIndex` or all `pd.RangeIndex`).\\n    \"\n    sort = None if sort else False\n\n    def intersection_func(series_or_times_1, series_or_times_2):\n        times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n        times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n        return times_1.intersection(times_2, sort=sort)\n    specified_inputs = [series for series in series_or_times if series is not None]\n    if not specified_inputs:\n        shared_times = None\n    elif len(specified_inputs) == 1:\n        shared_times = specified_inputs[0].time_index if isinstance(specified_inputs[0], TimeSeries) else specified_inputs[0]\n        shared_times = None if len(shared_times) == 0 else shared_times\n    else:\n        shared_times = reduce(intersection_func, specified_inputs)\n        if shared_times.empty:\n            shared_times = None\n            times_types = [type(ts.time_index if isinstance(ts, TimeSeries) else ts) for ts in specified_inputs]\n            raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n    return shared_times",
            "def get_shared_times(*series_or_times: Union[TimeSeries, pd.Index, None], sort: bool=True) -> pd.Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Returns the times shared by all of the specified `TimeSeries` or time indexes (i.e. the intersection of all\\n    these times). If `sort = True`, then these shared times are sorted from earliest to latest. Any `TimeSeries` or\\n    time indices in `series_or_times` that aren't specified (i.e. are `None`) are simply ignored.\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or time indices that should 'intersected'.\\n    sort\\n        Optionally, specifies that the returned shared times should be sorted from earliest to latest.\\n\\n    Returns\\n    -------\\n    shared_times\\n        The time indices present in all of the specified `TimeSeries` and/or time indices.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the specified `TimeSeries` and/or time indices do not all share the same type of time index (i.e. must\\n        either be all `pd.DatetimeIndex` or all `pd.RangeIndex`).\\n    \"\n    sort = None if sort else False\n\n    def intersection_func(series_or_times_1, series_or_times_2):\n        times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n        times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n        return times_1.intersection(times_2, sort=sort)\n    specified_inputs = [series for series in series_or_times if series is not None]\n    if not specified_inputs:\n        shared_times = None\n    elif len(specified_inputs) == 1:\n        shared_times = specified_inputs[0].time_index if isinstance(specified_inputs[0], TimeSeries) else specified_inputs[0]\n        shared_times = None if len(shared_times) == 0 else shared_times\n    else:\n        shared_times = reduce(intersection_func, specified_inputs)\n        if shared_times.empty:\n            shared_times = None\n            times_types = [type(ts.time_index if isinstance(ts, TimeSeries) else ts) for ts in specified_inputs]\n            raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n    return shared_times",
            "def get_shared_times(*series_or_times: Union[TimeSeries, pd.Index, None], sort: bool=True) -> pd.Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Returns the times shared by all of the specified `TimeSeries` or time indexes (i.e. the intersection of all\\n    these times). If `sort = True`, then these shared times are sorted from earliest to latest. Any `TimeSeries` or\\n    time indices in `series_or_times` that aren't specified (i.e. are `None`) are simply ignored.\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or time indices that should 'intersected'.\\n    sort\\n        Optionally, specifies that the returned shared times should be sorted from earliest to latest.\\n\\n    Returns\\n    -------\\n    shared_times\\n        The time indices present in all of the specified `TimeSeries` and/or time indices.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the specified `TimeSeries` and/or time indices do not all share the same type of time index (i.e. must\\n        either be all `pd.DatetimeIndex` or all `pd.RangeIndex`).\\n    \"\n    sort = None if sort else False\n\n    def intersection_func(series_or_times_1, series_or_times_2):\n        times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n        times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n        return times_1.intersection(times_2, sort=sort)\n    specified_inputs = [series for series in series_or_times if series is not None]\n    if not specified_inputs:\n        shared_times = None\n    elif len(specified_inputs) == 1:\n        shared_times = specified_inputs[0].time_index if isinstance(specified_inputs[0], TimeSeries) else specified_inputs[0]\n        shared_times = None if len(shared_times) == 0 else shared_times\n    else:\n        shared_times = reduce(intersection_func, specified_inputs)\n        if shared_times.empty:\n            shared_times = None\n            times_types = [type(ts.time_index if isinstance(ts, TimeSeries) else ts) for ts in specified_inputs]\n            raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n    return shared_times",
            "def get_shared_times(*series_or_times: Union[TimeSeries, pd.Index, None], sort: bool=True) -> pd.Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Returns the times shared by all of the specified `TimeSeries` or time indexes (i.e. the intersection of all\\n    these times). If `sort = True`, then these shared times are sorted from earliest to latest. Any `TimeSeries` or\\n    time indices in `series_or_times` that aren't specified (i.e. are `None`) are simply ignored.\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or time indices that should 'intersected'.\\n    sort\\n        Optionally, specifies that the returned shared times should be sorted from earliest to latest.\\n\\n    Returns\\n    -------\\n    shared_times\\n        The time indices present in all of the specified `TimeSeries` and/or time indices.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the specified `TimeSeries` and/or time indices do not all share the same type of time index (i.e. must\\n        either be all `pd.DatetimeIndex` or all `pd.RangeIndex`).\\n    \"\n    sort = None if sort else False\n\n    def intersection_func(series_or_times_1, series_or_times_2):\n        times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n        times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n        return times_1.intersection(times_2, sort=sort)\n    specified_inputs = [series for series in series_or_times if series is not None]\n    if not specified_inputs:\n        shared_times = None\n    elif len(specified_inputs) == 1:\n        shared_times = specified_inputs[0].time_index if isinstance(specified_inputs[0], TimeSeries) else specified_inputs[0]\n        shared_times = None if len(shared_times) == 0 else shared_times\n    else:\n        shared_times = reduce(intersection_func, specified_inputs)\n        if shared_times.empty:\n            shared_times = None\n            times_types = [type(ts.time_index if isinstance(ts, TimeSeries) else ts) for ts in specified_inputs]\n            raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n    return shared_times",
            "def get_shared_times(*series_or_times: Union[TimeSeries, pd.Index, None], sort: bool=True) -> pd.Index:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Returns the times shared by all of the specified `TimeSeries` or time indexes (i.e. the intersection of all\\n    these times). If `sort = True`, then these shared times are sorted from earliest to latest. Any `TimeSeries` or\\n    time indices in `series_or_times` that aren't specified (i.e. are `None`) are simply ignored.\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or time indices that should 'intersected'.\\n    sort\\n        Optionally, specifies that the returned shared times should be sorted from earliest to latest.\\n\\n    Returns\\n    -------\\n    shared_times\\n        The time indices present in all of the specified `TimeSeries` and/or time indices.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the specified `TimeSeries` and/or time indices do not all share the same type of time index (i.e. must\\n        either be all `pd.DatetimeIndex` or all `pd.RangeIndex`).\\n    \"\n    sort = None if sort else False\n\n    def intersection_func(series_or_times_1, series_or_times_2):\n        times_1 = series_or_times_1.time_index if isinstance(series_or_times_1, TimeSeries) else series_or_times_1\n        times_2 = series_or_times_2.time_index if isinstance(series_or_times_2, TimeSeries) else series_or_times_2\n        return times_1.intersection(times_2, sort=sort)\n    specified_inputs = [series for series in series_or_times if series is not None]\n    if not specified_inputs:\n        shared_times = None\n    elif len(specified_inputs) == 1:\n        shared_times = specified_inputs[0].time_index if isinstance(specified_inputs[0], TimeSeries) else specified_inputs[0]\n        shared_times = None if len(shared_times) == 0 else shared_times\n    else:\n        shared_times = reduce(intersection_func, specified_inputs)\n        if shared_times.empty:\n            shared_times = None\n            times_types = [type(ts.time_index if isinstance(ts, TimeSeries) else ts) for ts in specified_inputs]\n            raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n    return shared_times"
        ]
    },
    {
        "func_name": "get_shared_times_bounds",
        "original": "def get_shared_times_bounds(*series_or_times: Sequence[Union[TimeSeries, pd.Index, None]]) -> Union[Tuple[pd.Index, pd.Index], None]:\n    \"\"\"\n    Returns the latest `start_time` and the earliest `end_time` among all of the non-`None` `series_or_times`;\n    these are (non-tight) lower and upper `bounds` on the intersection of all these `series_or_times` respectively.\n    If no potential overlap exists between all of the specified series, `None` is returned instead.\n\n    Notes\n    -----\n    If all of the specified `series_or_times` are of the same frequency, then `get_shared_times_bounds`\n    returns tight `bounds` (i.e. the earliest and latest time within the intersection of all the timeseries\n    is returned). To see this, suppose we have three equal-frequency series with observations made at different\n    times:\n        Series 1: ------\n        Series 2:    ------\n        Series 3:  ------\n    Here, each `-` denotes an observation at a specific time. In this example, `find_time_overlap_bounds` will\n    return the times at `LB` and `UB`:\n                    LB\n        Series 1: ---|---|\n        Series 2:    |---|---\n        Series 3:  --|---|-\n                         UB\n    If the specified timeseries are *not* all of the same frequency, then the returned `bounds` is potentially non-tight\n    (i.e. `LB <= intersection.start_time() < intersection.end_time() <= UB`, where `intersection` are the times shared\n    by all specified timeseries)\n\n    Parameters\n    ----------\n    series_or_times\n        The `TimeSeries` and/or `pd.Index` values to compute intersection `bounds` for; any provided `None` values\n        are ignored.\n\n    Returns\n    -------\n    bounds\n        Tuple containing the latest `start_time` and earliest `end time` among all specified `timeseries`, in that\n        order. If no potential overlap exists between the specified series, then `None` is returned instead. Similarly,\n        if no non-`None` `series_or_times` were specified, `None` is returned.\n\n    Raises\n    ------\n    TypeError\n        If the series and/or times in `series_or_times` don't all share the same type of `time_index`\n        (i.e. either all `pd.DatetimeIndex` or `pd.RangeIndex`).\n\n    \"\"\"\n    (start_times, end_times) = ([], [])\n    for val in series_or_times:\n        if val is not None and len(val) > 0:\n            start_times.append(val.start_time() if isinstance(val, TimeSeries) else val[0])\n            end_times.append(val.end_time() if isinstance(val, TimeSeries) else val[-1])\n    if not start_times:\n        bounds = None\n    else:\n        times_types = [type(time) for time in start_times]\n        raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n        bounds = (max(start_times), min(end_times)) if start_times else (1, -1)\n        if bounds[1] < bounds[0]:\n            bounds = None\n    return bounds",
        "mutated": [
            "def get_shared_times_bounds(*series_or_times: Sequence[Union[TimeSeries, pd.Index, None]]) -> Union[Tuple[pd.Index, pd.Index], None]:\n    if False:\n        i = 10\n    \"\\n    Returns the latest `start_time` and the earliest `end_time` among all of the non-`None` `series_or_times`;\\n    these are (non-tight) lower and upper `bounds` on the intersection of all these `series_or_times` respectively.\\n    If no potential overlap exists between all of the specified series, `None` is returned instead.\\n\\n    Notes\\n    -----\\n    If all of the specified `series_or_times` are of the same frequency, then `get_shared_times_bounds`\\n    returns tight `bounds` (i.e. the earliest and latest time within the intersection of all the timeseries\\n    is returned). To see this, suppose we have three equal-frequency series with observations made at different\\n    times:\\n        Series 1: ------\\n        Series 2:    ------\\n        Series 3:  ------\\n    Here, each `-` denotes an observation at a specific time. In this example, `find_time_overlap_bounds` will\\n    return the times at `LB` and `UB`:\\n                    LB\\n        Series 1: ---|---|\\n        Series 2:    |---|---\\n        Series 3:  --|---|-\\n                         UB\\n    If the specified timeseries are *not* all of the same frequency, then the returned `bounds` is potentially non-tight\\n    (i.e. `LB <= intersection.start_time() < intersection.end_time() <= UB`, where `intersection` are the times shared\\n    by all specified timeseries)\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or `pd.Index` values to compute intersection `bounds` for; any provided `None` values\\n        are ignored.\\n\\n    Returns\\n    -------\\n    bounds\\n        Tuple containing the latest `start_time` and earliest `end time` among all specified `timeseries`, in that\\n        order. If no potential overlap exists between the specified series, then `None` is returned instead. Similarly,\\n        if no non-`None` `series_or_times` were specified, `None` is returned.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the series and/or times in `series_or_times` don't all share the same type of `time_index`\\n        (i.e. either all `pd.DatetimeIndex` or `pd.RangeIndex`).\\n\\n    \"\n    (start_times, end_times) = ([], [])\n    for val in series_or_times:\n        if val is not None and len(val) > 0:\n            start_times.append(val.start_time() if isinstance(val, TimeSeries) else val[0])\n            end_times.append(val.end_time() if isinstance(val, TimeSeries) else val[-1])\n    if not start_times:\n        bounds = None\n    else:\n        times_types = [type(time) for time in start_times]\n        raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n        bounds = (max(start_times), min(end_times)) if start_times else (1, -1)\n        if bounds[1] < bounds[0]:\n            bounds = None\n    return bounds",
            "def get_shared_times_bounds(*series_or_times: Sequence[Union[TimeSeries, pd.Index, None]]) -> Union[Tuple[pd.Index, pd.Index], None]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Returns the latest `start_time` and the earliest `end_time` among all of the non-`None` `series_or_times`;\\n    these are (non-tight) lower and upper `bounds` on the intersection of all these `series_or_times` respectively.\\n    If no potential overlap exists between all of the specified series, `None` is returned instead.\\n\\n    Notes\\n    -----\\n    If all of the specified `series_or_times` are of the same frequency, then `get_shared_times_bounds`\\n    returns tight `bounds` (i.e. the earliest and latest time within the intersection of all the timeseries\\n    is returned). To see this, suppose we have three equal-frequency series with observations made at different\\n    times:\\n        Series 1: ------\\n        Series 2:    ------\\n        Series 3:  ------\\n    Here, each `-` denotes an observation at a specific time. In this example, `find_time_overlap_bounds` will\\n    return the times at `LB` and `UB`:\\n                    LB\\n        Series 1: ---|---|\\n        Series 2:    |---|---\\n        Series 3:  --|---|-\\n                         UB\\n    If the specified timeseries are *not* all of the same frequency, then the returned `bounds` is potentially non-tight\\n    (i.e. `LB <= intersection.start_time() < intersection.end_time() <= UB`, where `intersection` are the times shared\\n    by all specified timeseries)\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or `pd.Index` values to compute intersection `bounds` for; any provided `None` values\\n        are ignored.\\n\\n    Returns\\n    -------\\n    bounds\\n        Tuple containing the latest `start_time` and earliest `end time` among all specified `timeseries`, in that\\n        order. If no potential overlap exists between the specified series, then `None` is returned instead. Similarly,\\n        if no non-`None` `series_or_times` were specified, `None` is returned.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the series and/or times in `series_or_times` don't all share the same type of `time_index`\\n        (i.e. either all `pd.DatetimeIndex` or `pd.RangeIndex`).\\n\\n    \"\n    (start_times, end_times) = ([], [])\n    for val in series_or_times:\n        if val is not None and len(val) > 0:\n            start_times.append(val.start_time() if isinstance(val, TimeSeries) else val[0])\n            end_times.append(val.end_time() if isinstance(val, TimeSeries) else val[-1])\n    if not start_times:\n        bounds = None\n    else:\n        times_types = [type(time) for time in start_times]\n        raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n        bounds = (max(start_times), min(end_times)) if start_times else (1, -1)\n        if bounds[1] < bounds[0]:\n            bounds = None\n    return bounds",
            "def get_shared_times_bounds(*series_or_times: Sequence[Union[TimeSeries, pd.Index, None]]) -> Union[Tuple[pd.Index, pd.Index], None]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Returns the latest `start_time` and the earliest `end_time` among all of the non-`None` `series_or_times`;\\n    these are (non-tight) lower and upper `bounds` on the intersection of all these `series_or_times` respectively.\\n    If no potential overlap exists between all of the specified series, `None` is returned instead.\\n\\n    Notes\\n    -----\\n    If all of the specified `series_or_times` are of the same frequency, then `get_shared_times_bounds`\\n    returns tight `bounds` (i.e. the earliest and latest time within the intersection of all the timeseries\\n    is returned). To see this, suppose we have three equal-frequency series with observations made at different\\n    times:\\n        Series 1: ------\\n        Series 2:    ------\\n        Series 3:  ------\\n    Here, each `-` denotes an observation at a specific time. In this example, `find_time_overlap_bounds` will\\n    return the times at `LB` and `UB`:\\n                    LB\\n        Series 1: ---|---|\\n        Series 2:    |---|---\\n        Series 3:  --|---|-\\n                         UB\\n    If the specified timeseries are *not* all of the same frequency, then the returned `bounds` is potentially non-tight\\n    (i.e. `LB <= intersection.start_time() < intersection.end_time() <= UB`, where `intersection` are the times shared\\n    by all specified timeseries)\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or `pd.Index` values to compute intersection `bounds` for; any provided `None` values\\n        are ignored.\\n\\n    Returns\\n    -------\\n    bounds\\n        Tuple containing the latest `start_time` and earliest `end time` among all specified `timeseries`, in that\\n        order. If no potential overlap exists between the specified series, then `None` is returned instead. Similarly,\\n        if no non-`None` `series_or_times` were specified, `None` is returned.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the series and/or times in `series_or_times` don't all share the same type of `time_index`\\n        (i.e. either all `pd.DatetimeIndex` or `pd.RangeIndex`).\\n\\n    \"\n    (start_times, end_times) = ([], [])\n    for val in series_or_times:\n        if val is not None and len(val) > 0:\n            start_times.append(val.start_time() if isinstance(val, TimeSeries) else val[0])\n            end_times.append(val.end_time() if isinstance(val, TimeSeries) else val[-1])\n    if not start_times:\n        bounds = None\n    else:\n        times_types = [type(time) for time in start_times]\n        raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n        bounds = (max(start_times), min(end_times)) if start_times else (1, -1)\n        if bounds[1] < bounds[0]:\n            bounds = None\n    return bounds",
            "def get_shared_times_bounds(*series_or_times: Sequence[Union[TimeSeries, pd.Index, None]]) -> Union[Tuple[pd.Index, pd.Index], None]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Returns the latest `start_time` and the earliest `end_time` among all of the non-`None` `series_or_times`;\\n    these are (non-tight) lower and upper `bounds` on the intersection of all these `series_or_times` respectively.\\n    If no potential overlap exists between all of the specified series, `None` is returned instead.\\n\\n    Notes\\n    -----\\n    If all of the specified `series_or_times` are of the same frequency, then `get_shared_times_bounds`\\n    returns tight `bounds` (i.e. the earliest and latest time within the intersection of all the timeseries\\n    is returned). To see this, suppose we have three equal-frequency series with observations made at different\\n    times:\\n        Series 1: ------\\n        Series 2:    ------\\n        Series 3:  ------\\n    Here, each `-` denotes an observation at a specific time. In this example, `find_time_overlap_bounds` will\\n    return the times at `LB` and `UB`:\\n                    LB\\n        Series 1: ---|---|\\n        Series 2:    |---|---\\n        Series 3:  --|---|-\\n                         UB\\n    If the specified timeseries are *not* all of the same frequency, then the returned `bounds` is potentially non-tight\\n    (i.e. `LB <= intersection.start_time() < intersection.end_time() <= UB`, where `intersection` are the times shared\\n    by all specified timeseries)\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or `pd.Index` values to compute intersection `bounds` for; any provided `None` values\\n        are ignored.\\n\\n    Returns\\n    -------\\n    bounds\\n        Tuple containing the latest `start_time` and earliest `end time` among all specified `timeseries`, in that\\n        order. If no potential overlap exists between the specified series, then `None` is returned instead. Similarly,\\n        if no non-`None` `series_or_times` were specified, `None` is returned.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the series and/or times in `series_or_times` don't all share the same type of `time_index`\\n        (i.e. either all `pd.DatetimeIndex` or `pd.RangeIndex`).\\n\\n    \"\n    (start_times, end_times) = ([], [])\n    for val in series_or_times:\n        if val is not None and len(val) > 0:\n            start_times.append(val.start_time() if isinstance(val, TimeSeries) else val[0])\n            end_times.append(val.end_time() if isinstance(val, TimeSeries) else val[-1])\n    if not start_times:\n        bounds = None\n    else:\n        times_types = [type(time) for time in start_times]\n        raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n        bounds = (max(start_times), min(end_times)) if start_times else (1, -1)\n        if bounds[1] < bounds[0]:\n            bounds = None\n    return bounds",
            "def get_shared_times_bounds(*series_or_times: Sequence[Union[TimeSeries, pd.Index, None]]) -> Union[Tuple[pd.Index, pd.Index], None]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Returns the latest `start_time` and the earliest `end_time` among all of the non-`None` `series_or_times`;\\n    these are (non-tight) lower and upper `bounds` on the intersection of all these `series_or_times` respectively.\\n    If no potential overlap exists between all of the specified series, `None` is returned instead.\\n\\n    Notes\\n    -----\\n    If all of the specified `series_or_times` are of the same frequency, then `get_shared_times_bounds`\\n    returns tight `bounds` (i.e. the earliest and latest time within the intersection of all the timeseries\\n    is returned). To see this, suppose we have three equal-frequency series with observations made at different\\n    times:\\n        Series 1: ------\\n        Series 2:    ------\\n        Series 3:  ------\\n    Here, each `-` denotes an observation at a specific time. In this example, `find_time_overlap_bounds` will\\n    return the times at `LB` and `UB`:\\n                    LB\\n        Series 1: ---|---|\\n        Series 2:    |---|---\\n        Series 3:  --|---|-\\n                         UB\\n    If the specified timeseries are *not* all of the same frequency, then the returned `bounds` is potentially non-tight\\n    (i.e. `LB <= intersection.start_time() < intersection.end_time() <= UB`, where `intersection` are the times shared\\n    by all specified timeseries)\\n\\n    Parameters\\n    ----------\\n    series_or_times\\n        The `TimeSeries` and/or `pd.Index` values to compute intersection `bounds` for; any provided `None` values\\n        are ignored.\\n\\n    Returns\\n    -------\\n    bounds\\n        Tuple containing the latest `start_time` and earliest `end time` among all specified `timeseries`, in that\\n        order. If no potential overlap exists between the specified series, then `None` is returned instead. Similarly,\\n        if no non-`None` `series_or_times` were specified, `None` is returned.\\n\\n    Raises\\n    ------\\n    TypeError\\n        If the series and/or times in `series_or_times` don't all share the same type of `time_index`\\n        (i.e. either all `pd.DatetimeIndex` or `pd.RangeIndex`).\\n\\n    \"\n    (start_times, end_times) = ([], [])\n    for val in series_or_times:\n        if val is not None and len(val) > 0:\n            start_times.append(val.start_time() if isinstance(val, TimeSeries) else val[0])\n            end_times.append(val.end_time() if isinstance(val, TimeSeries) else val[-1])\n    if not start_times:\n        bounds = None\n    else:\n        times_types = [type(time) for time in start_times]\n        raise_if_not(len(set(times_types)) == 1, 'Specified series and/or times must all have the same type of `time_index` (i.e. all `pd.RangeIndex` or all `pd.DatetimeIndex`).')\n        bounds = (max(start_times), min(end_times)) if start_times else (1, -1)\n        if bounds[1] < bounds[0]:\n            bounds = None\n    return bounds"
        ]
    },
    {
        "func_name": "strided_moving_window",
        "original": "def strided_moving_window(x: np.ndarray, window_len: int, stride: int=1, axis: int=0, check_inputs: bool=True) -> np.ndarray:\n    \"\"\"\n    Extracts moving window views of an `x` array along a specified `axis`, where each window is of length `window_len`\n    and consecutive windows are separated by `stride` indices. The total number of extracted windows equals\n    `num_windows = (x.shape[axis] - window_len)//stride + 1`.\n\n    Notes\n    -----\n    This function is similar to `sliding_window_view` in `np.lib.stride_tricks`, except that:\n        1. `strided_moving_window` allows for consecutive windows to be separated by a specified `stride`,\n        whilst `sliding_window_view` does not.\n        2. `strided_moving_window` can only operate along a single axis, whereas `sliding_window_view` can\n        operate along multiple axes.\n    Additionally, unlike `sliding_window_view`, using `strided_moving_window` doesn't require `numpy >= 1.20.0`.\n\n    Parameters\n    ----------\n    x\n        The array from which to extract moving windows.\n    window_len\n        The size of the extracted moving windows.\n    stride\n        Optionally, the separation between consecutive windows.\n    axis\n        Optionally, the axis along which the moving windows should be extracted.\n    check_inputs\n        Optionally, specifies whether inputs should be checked for validity. Should be set\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__`\n        of a class), otherwise should be set to `True`. See [1]_ for further details.\n\n    Returns\n    -------\n    windows\n        The moving windows extracted from `x`. The extracted windows are stacked along the last axis, and the\n        `axis` along which the windows were extracted is 'trimmed' such that its length equals the number of\n        extracted windows. More specifically, `windows.shape = x_trimmed_shape + (window_len,)`, where\n        `x_trimmed_shape` equals `x.shape`, except that `x_trimmed_shape[axis] = num_windows`.\n\n    Raises\n    ------\n    ValueError\n        If `check_inputs = True` and `window_len` is not positive.\n    ValueError\n        If `check_inputs = True` and `stride` is not positive.\n    ValueError\n        If `check_inputs = True` and `axis` is greater than `x.ndim`.\n    ValueError\n        If `check_inputs = True` and `window_len` is larger than `x.shape[axis]`.\n\n    References\n    ----------\n    .. [1] https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html\n    \"\"\"\n    if check_inputs:\n        raise_if(not isinstance(stride, int) or stride < 1, '`stride` must be a positive `int`.')\n        raise_if(not isinstance(window_len, int) or window_len < 1, '`window_len` must be a positive `int`.')\n        raise_if(not isinstance(axis, int) or axis > x.ndim - 1 or axis < -x.ndim, '`axis` must be an `int` that is less than `x.ndim`.')\n        raise_if(window_len > x.shape[axis], '`window_len` must be less than or equal to x.shape[axis].')\n    num_windows = (x.shape[axis] - window_len) // stride + 1\n    new_shape = list(x.shape)\n    new_shape[axis] = num_windows\n    new_shape = tuple(new_shape) + (window_len,)\n    out_strides = list(x.strides) + [x.strides[axis]]\n    out_strides[axis] = stride * out_strides[axis]\n    out_strides = tuple(out_strides)\n    return as_strided(x, shape=new_shape, strides=out_strides)",
        "mutated": [
            "def strided_moving_window(x: np.ndarray, window_len: int, stride: int=1, axis: int=0, check_inputs: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n    \"\\n    Extracts moving window views of an `x` array along a specified `axis`, where each window is of length `window_len`\\n    and consecutive windows are separated by `stride` indices. The total number of extracted windows equals\\n    `num_windows = (x.shape[axis] - window_len)//stride + 1`.\\n\\n    Notes\\n    -----\\n    This function is similar to `sliding_window_view` in `np.lib.stride_tricks`, except that:\\n        1. `strided_moving_window` allows for consecutive windows to be separated by a specified `stride`,\\n        whilst `sliding_window_view` does not.\\n        2. `strided_moving_window` can only operate along a single axis, whereas `sliding_window_view` can\\n        operate along multiple axes.\\n    Additionally, unlike `sliding_window_view`, using `strided_moving_window` doesn't require `numpy >= 1.20.0`.\\n\\n    Parameters\\n    ----------\\n    x\\n        The array from which to extract moving windows.\\n    window_len\\n        The size of the extracted moving windows.\\n    stride\\n        Optionally, the separation between consecutive windows.\\n    axis\\n        Optionally, the axis along which the moving windows should be extracted.\\n    check_inputs\\n        Optionally, specifies whether inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__`\\n        of a class), otherwise should be set to `True`. See [1]_ for further details.\\n\\n    Returns\\n    -------\\n    windows\\n        The moving windows extracted from `x`. The extracted windows are stacked along the last axis, and the\\n        `axis` along which the windows were extracted is 'trimmed' such that its length equals the number of\\n        extracted windows. More specifically, `windows.shape = x_trimmed_shape + (window_len,)`, where\\n        `x_trimmed_shape` equals `x.shape`, except that `x_trimmed_shape[axis] = num_windows`.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `check_inputs = True` and `window_len` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `stride` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `axis` is greater than `x.ndim`.\\n    ValueError\\n        If `check_inputs = True` and `window_len` is larger than `x.shape[axis]`.\\n\\n    References\\n    ----------\\n    .. [1] https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html\\n    \"\n    if check_inputs:\n        raise_if(not isinstance(stride, int) or stride < 1, '`stride` must be a positive `int`.')\n        raise_if(not isinstance(window_len, int) or window_len < 1, '`window_len` must be a positive `int`.')\n        raise_if(not isinstance(axis, int) or axis > x.ndim - 1 or axis < -x.ndim, '`axis` must be an `int` that is less than `x.ndim`.')\n        raise_if(window_len > x.shape[axis], '`window_len` must be less than or equal to x.shape[axis].')\n    num_windows = (x.shape[axis] - window_len) // stride + 1\n    new_shape = list(x.shape)\n    new_shape[axis] = num_windows\n    new_shape = tuple(new_shape) + (window_len,)\n    out_strides = list(x.strides) + [x.strides[axis]]\n    out_strides[axis] = stride * out_strides[axis]\n    out_strides = tuple(out_strides)\n    return as_strided(x, shape=new_shape, strides=out_strides)",
            "def strided_moving_window(x: np.ndarray, window_len: int, stride: int=1, axis: int=0, check_inputs: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Extracts moving window views of an `x` array along a specified `axis`, where each window is of length `window_len`\\n    and consecutive windows are separated by `stride` indices. The total number of extracted windows equals\\n    `num_windows = (x.shape[axis] - window_len)//stride + 1`.\\n\\n    Notes\\n    -----\\n    This function is similar to `sliding_window_view` in `np.lib.stride_tricks`, except that:\\n        1. `strided_moving_window` allows for consecutive windows to be separated by a specified `stride`,\\n        whilst `sliding_window_view` does not.\\n        2. `strided_moving_window` can only operate along a single axis, whereas `sliding_window_view` can\\n        operate along multiple axes.\\n    Additionally, unlike `sliding_window_view`, using `strided_moving_window` doesn't require `numpy >= 1.20.0`.\\n\\n    Parameters\\n    ----------\\n    x\\n        The array from which to extract moving windows.\\n    window_len\\n        The size of the extracted moving windows.\\n    stride\\n        Optionally, the separation between consecutive windows.\\n    axis\\n        Optionally, the axis along which the moving windows should be extracted.\\n    check_inputs\\n        Optionally, specifies whether inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__`\\n        of a class), otherwise should be set to `True`. See [1]_ for further details.\\n\\n    Returns\\n    -------\\n    windows\\n        The moving windows extracted from `x`. The extracted windows are stacked along the last axis, and the\\n        `axis` along which the windows were extracted is 'trimmed' such that its length equals the number of\\n        extracted windows. More specifically, `windows.shape = x_trimmed_shape + (window_len,)`, where\\n        `x_trimmed_shape` equals `x.shape`, except that `x_trimmed_shape[axis] = num_windows`.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `check_inputs = True` and `window_len` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `stride` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `axis` is greater than `x.ndim`.\\n    ValueError\\n        If `check_inputs = True` and `window_len` is larger than `x.shape[axis]`.\\n\\n    References\\n    ----------\\n    .. [1] https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html\\n    \"\n    if check_inputs:\n        raise_if(not isinstance(stride, int) or stride < 1, '`stride` must be a positive `int`.')\n        raise_if(not isinstance(window_len, int) or window_len < 1, '`window_len` must be a positive `int`.')\n        raise_if(not isinstance(axis, int) or axis > x.ndim - 1 or axis < -x.ndim, '`axis` must be an `int` that is less than `x.ndim`.')\n        raise_if(window_len > x.shape[axis], '`window_len` must be less than or equal to x.shape[axis].')\n    num_windows = (x.shape[axis] - window_len) // stride + 1\n    new_shape = list(x.shape)\n    new_shape[axis] = num_windows\n    new_shape = tuple(new_shape) + (window_len,)\n    out_strides = list(x.strides) + [x.strides[axis]]\n    out_strides[axis] = stride * out_strides[axis]\n    out_strides = tuple(out_strides)\n    return as_strided(x, shape=new_shape, strides=out_strides)",
            "def strided_moving_window(x: np.ndarray, window_len: int, stride: int=1, axis: int=0, check_inputs: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Extracts moving window views of an `x` array along a specified `axis`, where each window is of length `window_len`\\n    and consecutive windows are separated by `stride` indices. The total number of extracted windows equals\\n    `num_windows = (x.shape[axis] - window_len)//stride + 1`.\\n\\n    Notes\\n    -----\\n    This function is similar to `sliding_window_view` in `np.lib.stride_tricks`, except that:\\n        1. `strided_moving_window` allows for consecutive windows to be separated by a specified `stride`,\\n        whilst `sliding_window_view` does not.\\n        2. `strided_moving_window` can only operate along a single axis, whereas `sliding_window_view` can\\n        operate along multiple axes.\\n    Additionally, unlike `sliding_window_view`, using `strided_moving_window` doesn't require `numpy >= 1.20.0`.\\n\\n    Parameters\\n    ----------\\n    x\\n        The array from which to extract moving windows.\\n    window_len\\n        The size of the extracted moving windows.\\n    stride\\n        Optionally, the separation between consecutive windows.\\n    axis\\n        Optionally, the axis along which the moving windows should be extracted.\\n    check_inputs\\n        Optionally, specifies whether inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__`\\n        of a class), otherwise should be set to `True`. See [1]_ for further details.\\n\\n    Returns\\n    -------\\n    windows\\n        The moving windows extracted from `x`. The extracted windows are stacked along the last axis, and the\\n        `axis` along which the windows were extracted is 'trimmed' such that its length equals the number of\\n        extracted windows. More specifically, `windows.shape = x_trimmed_shape + (window_len,)`, where\\n        `x_trimmed_shape` equals `x.shape`, except that `x_trimmed_shape[axis] = num_windows`.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `check_inputs = True` and `window_len` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `stride` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `axis` is greater than `x.ndim`.\\n    ValueError\\n        If `check_inputs = True` and `window_len` is larger than `x.shape[axis]`.\\n\\n    References\\n    ----------\\n    .. [1] https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html\\n    \"\n    if check_inputs:\n        raise_if(not isinstance(stride, int) or stride < 1, '`stride` must be a positive `int`.')\n        raise_if(not isinstance(window_len, int) or window_len < 1, '`window_len` must be a positive `int`.')\n        raise_if(not isinstance(axis, int) or axis > x.ndim - 1 or axis < -x.ndim, '`axis` must be an `int` that is less than `x.ndim`.')\n        raise_if(window_len > x.shape[axis], '`window_len` must be less than or equal to x.shape[axis].')\n    num_windows = (x.shape[axis] - window_len) // stride + 1\n    new_shape = list(x.shape)\n    new_shape[axis] = num_windows\n    new_shape = tuple(new_shape) + (window_len,)\n    out_strides = list(x.strides) + [x.strides[axis]]\n    out_strides[axis] = stride * out_strides[axis]\n    out_strides = tuple(out_strides)\n    return as_strided(x, shape=new_shape, strides=out_strides)",
            "def strided_moving_window(x: np.ndarray, window_len: int, stride: int=1, axis: int=0, check_inputs: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Extracts moving window views of an `x` array along a specified `axis`, where each window is of length `window_len`\\n    and consecutive windows are separated by `stride` indices. The total number of extracted windows equals\\n    `num_windows = (x.shape[axis] - window_len)//stride + 1`.\\n\\n    Notes\\n    -----\\n    This function is similar to `sliding_window_view` in `np.lib.stride_tricks`, except that:\\n        1. `strided_moving_window` allows for consecutive windows to be separated by a specified `stride`,\\n        whilst `sliding_window_view` does not.\\n        2. `strided_moving_window` can only operate along a single axis, whereas `sliding_window_view` can\\n        operate along multiple axes.\\n    Additionally, unlike `sliding_window_view`, using `strided_moving_window` doesn't require `numpy >= 1.20.0`.\\n\\n    Parameters\\n    ----------\\n    x\\n        The array from which to extract moving windows.\\n    window_len\\n        The size of the extracted moving windows.\\n    stride\\n        Optionally, the separation between consecutive windows.\\n    axis\\n        Optionally, the axis along which the moving windows should be extracted.\\n    check_inputs\\n        Optionally, specifies whether inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__`\\n        of a class), otherwise should be set to `True`. See [1]_ for further details.\\n\\n    Returns\\n    -------\\n    windows\\n        The moving windows extracted from `x`. The extracted windows are stacked along the last axis, and the\\n        `axis` along which the windows were extracted is 'trimmed' such that its length equals the number of\\n        extracted windows. More specifically, `windows.shape = x_trimmed_shape + (window_len,)`, where\\n        `x_trimmed_shape` equals `x.shape`, except that `x_trimmed_shape[axis] = num_windows`.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `check_inputs = True` and `window_len` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `stride` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `axis` is greater than `x.ndim`.\\n    ValueError\\n        If `check_inputs = True` and `window_len` is larger than `x.shape[axis]`.\\n\\n    References\\n    ----------\\n    .. [1] https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html\\n    \"\n    if check_inputs:\n        raise_if(not isinstance(stride, int) or stride < 1, '`stride` must be a positive `int`.')\n        raise_if(not isinstance(window_len, int) or window_len < 1, '`window_len` must be a positive `int`.')\n        raise_if(not isinstance(axis, int) or axis > x.ndim - 1 or axis < -x.ndim, '`axis` must be an `int` that is less than `x.ndim`.')\n        raise_if(window_len > x.shape[axis], '`window_len` must be less than or equal to x.shape[axis].')\n    num_windows = (x.shape[axis] - window_len) // stride + 1\n    new_shape = list(x.shape)\n    new_shape[axis] = num_windows\n    new_shape = tuple(new_shape) + (window_len,)\n    out_strides = list(x.strides) + [x.strides[axis]]\n    out_strides[axis] = stride * out_strides[axis]\n    out_strides = tuple(out_strides)\n    return as_strided(x, shape=new_shape, strides=out_strides)",
            "def strided_moving_window(x: np.ndarray, window_len: int, stride: int=1, axis: int=0, check_inputs: bool=True) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Extracts moving window views of an `x` array along a specified `axis`, where each window is of length `window_len`\\n    and consecutive windows are separated by `stride` indices. The total number of extracted windows equals\\n    `num_windows = (x.shape[axis] - window_len)//stride + 1`.\\n\\n    Notes\\n    -----\\n    This function is similar to `sliding_window_view` in `np.lib.stride_tricks`, except that:\\n        1. `strided_moving_window` allows for consecutive windows to be separated by a specified `stride`,\\n        whilst `sliding_window_view` does not.\\n        2. `strided_moving_window` can only operate along a single axis, whereas `sliding_window_view` can\\n        operate along multiple axes.\\n    Additionally, unlike `sliding_window_view`, using `strided_moving_window` doesn't require `numpy >= 1.20.0`.\\n\\n    Parameters\\n    ----------\\n    x\\n        The array from which to extract moving windows.\\n    window_len\\n        The size of the extracted moving windows.\\n    stride\\n        Optionally, the separation between consecutive windows.\\n    axis\\n        Optionally, the axis along which the moving windows should be extracted.\\n    check_inputs\\n        Optionally, specifies whether inputs should be checked for validity. Should be set\\n        to `False` if inputs have already been checked for validity (e.g. inside the `__init__`\\n        of a class), otherwise should be set to `True`. See [1]_ for further details.\\n\\n    Returns\\n    -------\\n    windows\\n        The moving windows extracted from `x`. The extracted windows are stacked along the last axis, and the\\n        `axis` along which the windows were extracted is 'trimmed' such that its length equals the number of\\n        extracted windows. More specifically, `windows.shape = x_trimmed_shape + (window_len,)`, where\\n        `x_trimmed_shape` equals `x.shape`, except that `x_trimmed_shape[axis] = num_windows`.\\n\\n    Raises\\n    ------\\n    ValueError\\n        If `check_inputs = True` and `window_len` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `stride` is not positive.\\n    ValueError\\n        If `check_inputs = True` and `axis` is greater than `x.ndim`.\\n    ValueError\\n        If `check_inputs = True` and `window_len` is larger than `x.shape[axis]`.\\n\\n    References\\n    ----------\\n    .. [1] https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html\\n    \"\n    if check_inputs:\n        raise_if(not isinstance(stride, int) or stride < 1, '`stride` must be a positive `int`.')\n        raise_if(not isinstance(window_len, int) or window_len < 1, '`window_len` must be a positive `int`.')\n        raise_if(not isinstance(axis, int) or axis > x.ndim - 1 or axis < -x.ndim, '`axis` must be an `int` that is less than `x.ndim`.')\n        raise_if(window_len > x.shape[axis], '`window_len` must be less than or equal to x.shape[axis].')\n    num_windows = (x.shape[axis] - window_len) // stride + 1\n    new_shape = list(x.shape)\n    new_shape[axis] = num_windows\n    new_shape = tuple(new_shape) + (window_len,)\n    out_strides = list(x.strides) + [x.strides[axis]]\n    out_strides[axis] = stride * out_strides[axis]\n    out_strides = tuple(out_strides)\n    return as_strided(x, shape=new_shape, strides=out_strides)"
        ]
    },
    {
        "func_name": "_extend_time_index",
        "original": "def _extend_time_index(time_index: pd.Index, freq: Union[int, str], new_start: Optional[pd.Timestamp]=None, new_end: Optional[pd.Timestamp]=None):\n    \"\"\"\n    Extends a `time_index` of frequency `freq` such that it now ends at time `new_end`;\n    the fastest way to do this is actually to create a new time index from scratch.\n    \"\"\"\n    is_range_idx = isinstance(freq, int)\n    if new_start is None:\n        new_start = time_index[0]\n    if new_end is None:\n        new_end = time_index[-1]\n    if is_range_idx:\n        time_index = pd.RangeIndex(start=new_start, stop=new_end + freq, step=freq)\n    else:\n        time_index = pd.date_range(start=new_start, end=new_end, freq=freq)\n    return time_index",
        "mutated": [
            "def _extend_time_index(time_index: pd.Index, freq: Union[int, str], new_start: Optional[pd.Timestamp]=None, new_end: Optional[pd.Timestamp]=None):\n    if False:\n        i = 10\n    '\\n    Extends a `time_index` of frequency `freq` such that it now ends at time `new_end`;\\n    the fastest way to do this is actually to create a new time index from scratch.\\n    '\n    is_range_idx = isinstance(freq, int)\n    if new_start is None:\n        new_start = time_index[0]\n    if new_end is None:\n        new_end = time_index[-1]\n    if is_range_idx:\n        time_index = pd.RangeIndex(start=new_start, stop=new_end + freq, step=freq)\n    else:\n        time_index = pd.date_range(start=new_start, end=new_end, freq=freq)\n    return time_index",
            "def _extend_time_index(time_index: pd.Index, freq: Union[int, str], new_start: Optional[pd.Timestamp]=None, new_end: Optional[pd.Timestamp]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Extends a `time_index` of frequency `freq` such that it now ends at time `new_end`;\\n    the fastest way to do this is actually to create a new time index from scratch.\\n    '\n    is_range_idx = isinstance(freq, int)\n    if new_start is None:\n        new_start = time_index[0]\n    if new_end is None:\n        new_end = time_index[-1]\n    if is_range_idx:\n        time_index = pd.RangeIndex(start=new_start, stop=new_end + freq, step=freq)\n    else:\n        time_index = pd.date_range(start=new_start, end=new_end, freq=freq)\n    return time_index",
            "def _extend_time_index(time_index: pd.Index, freq: Union[int, str], new_start: Optional[pd.Timestamp]=None, new_end: Optional[pd.Timestamp]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Extends a `time_index` of frequency `freq` such that it now ends at time `new_end`;\\n    the fastest way to do this is actually to create a new time index from scratch.\\n    '\n    is_range_idx = isinstance(freq, int)\n    if new_start is None:\n        new_start = time_index[0]\n    if new_end is None:\n        new_end = time_index[-1]\n    if is_range_idx:\n        time_index = pd.RangeIndex(start=new_start, stop=new_end + freq, step=freq)\n    else:\n        time_index = pd.date_range(start=new_start, end=new_end, freq=freq)\n    return time_index",
            "def _extend_time_index(time_index: pd.Index, freq: Union[int, str], new_start: Optional[pd.Timestamp]=None, new_end: Optional[pd.Timestamp]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Extends a `time_index` of frequency `freq` such that it now ends at time `new_end`;\\n    the fastest way to do this is actually to create a new time index from scratch.\\n    '\n    is_range_idx = isinstance(freq, int)\n    if new_start is None:\n        new_start = time_index[0]\n    if new_end is None:\n        new_end = time_index[-1]\n    if is_range_idx:\n        time_index = pd.RangeIndex(start=new_start, stop=new_end + freq, step=freq)\n    else:\n        time_index = pd.date_range(start=new_start, end=new_end, freq=freq)\n    return time_index",
            "def _extend_time_index(time_index: pd.Index, freq: Union[int, str], new_start: Optional[pd.Timestamp]=None, new_end: Optional[pd.Timestamp]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Extends a `time_index` of frequency `freq` such that it now ends at time `new_end`;\\n    the fastest way to do this is actually to create a new time index from scratch.\\n    '\n    is_range_idx = isinstance(freq, int)\n    if new_start is None:\n        new_start = time_index[0]\n    if new_end is None:\n        new_end = time_index[-1]\n    if is_range_idx:\n        time_index = pd.RangeIndex(start=new_start, stop=new_end + freq, step=freq)\n    else:\n        time_index = pd.date_range(start=new_start, end=new_end, freq=freq)\n    return time_index"
        ]
    },
    {
        "func_name": "_get_freqs",
        "original": "def _get_freqs(*series: Union[TimeSeries, None]):\n    \"\"\"\n    Returns list with the frequency of all of the specified (i.e. non-`None`) `series`.\n    \"\"\"\n    freqs = []\n    for ts in series:\n        if ts is not None:\n            freqs.append(ts.freq)\n    return freqs",
        "mutated": [
            "def _get_freqs(*series: Union[TimeSeries, None]):\n    if False:\n        i = 10\n    '\\n    Returns list with the frequency of all of the specified (i.e. non-`None`) `series`.\\n    '\n    freqs = []\n    for ts in series:\n        if ts is not None:\n            freqs.append(ts.freq)\n    return freqs",
            "def _get_freqs(*series: Union[TimeSeries, None]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Returns list with the frequency of all of the specified (i.e. non-`None`) `series`.\\n    '\n    freqs = []\n    for ts in series:\n        if ts is not None:\n            freqs.append(ts.freq)\n    return freqs",
            "def _get_freqs(*series: Union[TimeSeries, None]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Returns list with the frequency of all of the specified (i.e. non-`None`) `series`.\\n    '\n    freqs = []\n    for ts in series:\n        if ts is not None:\n            freqs.append(ts.freq)\n    return freqs",
            "def _get_freqs(*series: Union[TimeSeries, None]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Returns list with the frequency of all of the specified (i.e. non-`None`) `series`.\\n    '\n    freqs = []\n    for ts in series:\n        if ts is not None:\n            freqs.append(ts.freq)\n    return freqs",
            "def _get_freqs(*series: Union[TimeSeries, None]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Returns list with the frequency of all of the specified (i.e. non-`None`) `series`.\\n    '\n    freqs = []\n    for ts in series:\n        if ts is not None:\n            freqs.append(ts.freq)\n    return freqs"
        ]
    },
    {
        "func_name": "_all_equal_freq",
        "original": "def _all_equal_freq(*series: Union[TimeSeries, None]) -> bool:\n    \"\"\"\n    Returns `True` is all of the specified (i.e. non-`None`) `series` have the same frequency.\n    \"\"\"\n    freqs = _get_freqs(*series)\n    return len(set(freqs)) == 1",
        "mutated": [
            "def _all_equal_freq(*series: Union[TimeSeries, None]) -> bool:\n    if False:\n        i = 10\n    '\\n    Returns `True` is all of the specified (i.e. non-`None`) `series` have the same frequency.\\n    '\n    freqs = _get_freqs(*series)\n    return len(set(freqs)) == 1",
            "def _all_equal_freq(*series: Union[TimeSeries, None]) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Returns `True` is all of the specified (i.e. non-`None`) `series` have the same frequency.\\n    '\n    freqs = _get_freqs(*series)\n    return len(set(freqs)) == 1",
            "def _all_equal_freq(*series: Union[TimeSeries, None]) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Returns `True` is all of the specified (i.e. non-`None`) `series` have the same frequency.\\n    '\n    freqs = _get_freqs(*series)\n    return len(set(freqs)) == 1",
            "def _all_equal_freq(*series: Union[TimeSeries, None]) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Returns `True` is all of the specified (i.e. non-`None`) `series` have the same frequency.\\n    '\n    freqs = _get_freqs(*series)\n    return len(set(freqs)) == 1",
            "def _all_equal_freq(*series: Union[TimeSeries, None]) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Returns `True` is all of the specified (i.e. non-`None`) `series` have the same frequency.\\n    '\n    freqs = _get_freqs(*series)\n    return len(set(freqs)) == 1"
        ]
    },
    {
        "func_name": "_check_lags",
        "original": "def _check_lags(lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]) -> None:\n    \"\"\"\n    Throws `ValueError` if any `lag` values aren't negative OR if no lags have been specified.\n    \"\"\"\n    all_lags = [lags, lags_past_covariates, lags_future_covariates]\n    suffixes = ['', '_past_covariates', '_future_covariates']\n    lags_is_none = []\n    for (i, (suffix, lags_i)) in enumerate(zip(suffixes, all_lags)):\n        lags_is_none.append(lags_i is None)\n        if not lags_is_none[-1]:\n            is_target_or_past = i < 2\n            max_lag = -1 if is_target_or_past else inf\n            if isinstance(lags_i, dict):\n                lags_i = list(set(chain(*lags_i.values())))\n            raise_if(any((lag > max_lag or not isinstance(lag, int) for lag in lags_i)), f'`lags{suffix}` must be a `Sequence` or `Dict` containing only `int` values less than {max_lag + 1}.')\n    raise_if(all(lags_is_none), 'Must specify at least one of: `lags`, `lags_past_covariates`, `lags_future_covariates`.')\n    return None",
        "mutated": [
            "def _check_lags(lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]) -> None:\n    if False:\n        i = 10\n    \"\\n    Throws `ValueError` if any `lag` values aren't negative OR if no lags have been specified.\\n    \"\n    all_lags = [lags, lags_past_covariates, lags_future_covariates]\n    suffixes = ['', '_past_covariates', '_future_covariates']\n    lags_is_none = []\n    for (i, (suffix, lags_i)) in enumerate(zip(suffixes, all_lags)):\n        lags_is_none.append(lags_i is None)\n        if not lags_is_none[-1]:\n            is_target_or_past = i < 2\n            max_lag = -1 if is_target_or_past else inf\n            if isinstance(lags_i, dict):\n                lags_i = list(set(chain(*lags_i.values())))\n            raise_if(any((lag > max_lag or not isinstance(lag, int) for lag in lags_i)), f'`lags{suffix}` must be a `Sequence` or `Dict` containing only `int` values less than {max_lag + 1}.')\n    raise_if(all(lags_is_none), 'Must specify at least one of: `lags`, `lags_past_covariates`, `lags_future_covariates`.')\n    return None",
            "def _check_lags(lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Throws `ValueError` if any `lag` values aren't negative OR if no lags have been specified.\\n    \"\n    all_lags = [lags, lags_past_covariates, lags_future_covariates]\n    suffixes = ['', '_past_covariates', '_future_covariates']\n    lags_is_none = []\n    for (i, (suffix, lags_i)) in enumerate(zip(suffixes, all_lags)):\n        lags_is_none.append(lags_i is None)\n        if not lags_is_none[-1]:\n            is_target_or_past = i < 2\n            max_lag = -1 if is_target_or_past else inf\n            if isinstance(lags_i, dict):\n                lags_i = list(set(chain(*lags_i.values())))\n            raise_if(any((lag > max_lag or not isinstance(lag, int) for lag in lags_i)), f'`lags{suffix}` must be a `Sequence` or `Dict` containing only `int` values less than {max_lag + 1}.')\n    raise_if(all(lags_is_none), 'Must specify at least one of: `lags`, `lags_past_covariates`, `lags_future_covariates`.')\n    return None",
            "def _check_lags(lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Throws `ValueError` if any `lag` values aren't negative OR if no lags have been specified.\\n    \"\n    all_lags = [lags, lags_past_covariates, lags_future_covariates]\n    suffixes = ['', '_past_covariates', '_future_covariates']\n    lags_is_none = []\n    for (i, (suffix, lags_i)) in enumerate(zip(suffixes, all_lags)):\n        lags_is_none.append(lags_i is None)\n        if not lags_is_none[-1]:\n            is_target_or_past = i < 2\n            max_lag = -1 if is_target_or_past else inf\n            if isinstance(lags_i, dict):\n                lags_i = list(set(chain(*lags_i.values())))\n            raise_if(any((lag > max_lag or not isinstance(lag, int) for lag in lags_i)), f'`lags{suffix}` must be a `Sequence` or `Dict` containing only `int` values less than {max_lag + 1}.')\n    raise_if(all(lags_is_none), 'Must specify at least one of: `lags`, `lags_past_covariates`, `lags_future_covariates`.')\n    return None",
            "def _check_lags(lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Throws `ValueError` if any `lag` values aren't negative OR if no lags have been specified.\\n    \"\n    all_lags = [lags, lags_past_covariates, lags_future_covariates]\n    suffixes = ['', '_past_covariates', '_future_covariates']\n    lags_is_none = []\n    for (i, (suffix, lags_i)) in enumerate(zip(suffixes, all_lags)):\n        lags_is_none.append(lags_i is None)\n        if not lags_is_none[-1]:\n            is_target_or_past = i < 2\n            max_lag = -1 if is_target_or_past else inf\n            if isinstance(lags_i, dict):\n                lags_i = list(set(chain(*lags_i.values())))\n            raise_if(any((lag > max_lag or not isinstance(lag, int) for lag in lags_i)), f'`lags{suffix}` must be a `Sequence` or `Dict` containing only `int` values less than {max_lag + 1}.')\n    raise_if(all(lags_is_none), 'Must specify at least one of: `lags`, `lags_past_covariates`, `lags_future_covariates`.')\n    return None",
            "def _check_lags(lags: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_past_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]], lags_future_covariates: Optional[Union[Sequence[int], Dict[str, List[int]]]]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Throws `ValueError` if any `lag` values aren't negative OR if no lags have been specified.\\n    \"\n    all_lags = [lags, lags_past_covariates, lags_future_covariates]\n    suffixes = ['', '_past_covariates', '_future_covariates']\n    lags_is_none = []\n    for (i, (suffix, lags_i)) in enumerate(zip(suffixes, all_lags)):\n        lags_is_none.append(lags_i is None)\n        if not lags_is_none[-1]:\n            is_target_or_past = i < 2\n            max_lag = -1 if is_target_or_past else inf\n            if isinstance(lags_i, dict):\n                lags_i = list(set(chain(*lags_i.values())))\n            raise_if(any((lag > max_lag or not isinstance(lag, int) for lag in lags_i)), f'`lags{suffix}` must be a `Sequence` or `Dict` containing only `int` values less than {max_lag + 1}.')\n    raise_if(all(lags_is_none), 'Must specify at least one of: `lags`, `lags_past_covariates`, `lags_future_covariates`.')\n    return None"
        ]
    },
    {
        "func_name": "_check_series_length",
        "original": "def _check_series_length(series: TimeSeries, lags: Union[None, Sequence[int]], output_chunk_length: int, is_training: bool, name: Literal['target_series', 'past_covariates', 'future_covariates']) -> None:\n    \"\"\"\n    Throws `ValueError` if `series` is too short for specified `lags` and, when `is_training`, `output_chunk_length`.\n    \"\"\"\n    is_target = name == 'target_series'\n    is_label_series = is_training and is_target\n    lags_specified = lags is not None\n    (minimum_len, minimum_len_str) = (None, None)\n    if is_label_series:\n        minimum_len_str = '-min(lags) + output_chunk_length' if lags_specified else 'output_chunk_length'\n        minimum_len = -min(lags) + output_chunk_length if lags_specified else output_chunk_length\n    elif lags_specified:\n        lags_name = 'lags' if name == 'target_series' else f'lags_{name}'\n        minimum_len_str = f'-min({lags_name}) + max({lags_name}) + 1'\n        minimum_len = -min(lags) + max(lags) + 1\n    if lags_specified:\n        raise_if(series.n_timesteps < minimum_len, f'`{name}` must have at least `{minimum_len_str}` = {minimum_len} timesteps; instead, it only has {series.n_timesteps}.')\n    return None",
        "mutated": [
            "def _check_series_length(series: TimeSeries, lags: Union[None, Sequence[int]], output_chunk_length: int, is_training: bool, name: Literal['target_series', 'past_covariates', 'future_covariates']) -> None:\n    if False:\n        i = 10\n    '\\n    Throws `ValueError` if `series` is too short for specified `lags` and, when `is_training`, `output_chunk_length`.\\n    '\n    is_target = name == 'target_series'\n    is_label_series = is_training and is_target\n    lags_specified = lags is not None\n    (minimum_len, minimum_len_str) = (None, None)\n    if is_label_series:\n        minimum_len_str = '-min(lags) + output_chunk_length' if lags_specified else 'output_chunk_length'\n        minimum_len = -min(lags) + output_chunk_length if lags_specified else output_chunk_length\n    elif lags_specified:\n        lags_name = 'lags' if name == 'target_series' else f'lags_{name}'\n        minimum_len_str = f'-min({lags_name}) + max({lags_name}) + 1'\n        minimum_len = -min(lags) + max(lags) + 1\n    if lags_specified:\n        raise_if(series.n_timesteps < minimum_len, f'`{name}` must have at least `{minimum_len_str}` = {minimum_len} timesteps; instead, it only has {series.n_timesteps}.')\n    return None",
            "def _check_series_length(series: TimeSeries, lags: Union[None, Sequence[int]], output_chunk_length: int, is_training: bool, name: Literal['target_series', 'past_covariates', 'future_covariates']) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Throws `ValueError` if `series` is too short for specified `lags` and, when `is_training`, `output_chunk_length`.\\n    '\n    is_target = name == 'target_series'\n    is_label_series = is_training and is_target\n    lags_specified = lags is not None\n    (minimum_len, minimum_len_str) = (None, None)\n    if is_label_series:\n        minimum_len_str = '-min(lags) + output_chunk_length' if lags_specified else 'output_chunk_length'\n        minimum_len = -min(lags) + output_chunk_length if lags_specified else output_chunk_length\n    elif lags_specified:\n        lags_name = 'lags' if name == 'target_series' else f'lags_{name}'\n        minimum_len_str = f'-min({lags_name}) + max({lags_name}) + 1'\n        minimum_len = -min(lags) + max(lags) + 1\n    if lags_specified:\n        raise_if(series.n_timesteps < minimum_len, f'`{name}` must have at least `{minimum_len_str}` = {minimum_len} timesteps; instead, it only has {series.n_timesteps}.')\n    return None",
            "def _check_series_length(series: TimeSeries, lags: Union[None, Sequence[int]], output_chunk_length: int, is_training: bool, name: Literal['target_series', 'past_covariates', 'future_covariates']) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Throws `ValueError` if `series` is too short for specified `lags` and, when `is_training`, `output_chunk_length`.\\n    '\n    is_target = name == 'target_series'\n    is_label_series = is_training and is_target\n    lags_specified = lags is not None\n    (minimum_len, minimum_len_str) = (None, None)\n    if is_label_series:\n        minimum_len_str = '-min(lags) + output_chunk_length' if lags_specified else 'output_chunk_length'\n        minimum_len = -min(lags) + output_chunk_length if lags_specified else output_chunk_length\n    elif lags_specified:\n        lags_name = 'lags' if name == 'target_series' else f'lags_{name}'\n        minimum_len_str = f'-min({lags_name}) + max({lags_name}) + 1'\n        minimum_len = -min(lags) + max(lags) + 1\n    if lags_specified:\n        raise_if(series.n_timesteps < minimum_len, f'`{name}` must have at least `{minimum_len_str}` = {minimum_len} timesteps; instead, it only has {series.n_timesteps}.')\n    return None",
            "def _check_series_length(series: TimeSeries, lags: Union[None, Sequence[int]], output_chunk_length: int, is_training: bool, name: Literal['target_series', 'past_covariates', 'future_covariates']) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Throws `ValueError` if `series` is too short for specified `lags` and, when `is_training`, `output_chunk_length`.\\n    '\n    is_target = name == 'target_series'\n    is_label_series = is_training and is_target\n    lags_specified = lags is not None\n    (minimum_len, minimum_len_str) = (None, None)\n    if is_label_series:\n        minimum_len_str = '-min(lags) + output_chunk_length' if lags_specified else 'output_chunk_length'\n        minimum_len = -min(lags) + output_chunk_length if lags_specified else output_chunk_length\n    elif lags_specified:\n        lags_name = 'lags' if name == 'target_series' else f'lags_{name}'\n        minimum_len_str = f'-min({lags_name}) + max({lags_name}) + 1'\n        minimum_len = -min(lags) + max(lags) + 1\n    if lags_specified:\n        raise_if(series.n_timesteps < minimum_len, f'`{name}` must have at least `{minimum_len_str}` = {minimum_len} timesteps; instead, it only has {series.n_timesteps}.')\n    return None",
            "def _check_series_length(series: TimeSeries, lags: Union[None, Sequence[int]], output_chunk_length: int, is_training: bool, name: Literal['target_series', 'past_covariates', 'future_covariates']) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Throws `ValueError` if `series` is too short for specified `lags` and, when `is_training`, `output_chunk_length`.\\n    '\n    is_target = name == 'target_series'\n    is_label_series = is_training and is_target\n    lags_specified = lags is not None\n    (minimum_len, minimum_len_str) = (None, None)\n    if is_label_series:\n        minimum_len_str = '-min(lags) + output_chunk_length' if lags_specified else 'output_chunk_length'\n        minimum_len = -min(lags) + output_chunk_length if lags_specified else output_chunk_length\n    elif lags_specified:\n        lags_name = 'lags' if name == 'target_series' else f'lags_{name}'\n        minimum_len_str = f'-min({lags_name}) + max({lags_name}) + 1'\n        minimum_len = -min(lags) + max(lags) + 1\n    if lags_specified:\n        raise_if(series.n_timesteps < minimum_len, f'`{name}` must have at least `{minimum_len_str}` = {minimum_len} timesteps; instead, it only has {series.n_timesteps}.')\n    return None"
        ]
    }
]