[
    {
        "func_name": "test_local_model",
        "original": "@unittest.skipIf(not TEST_CUDA, 'no cuda')\ndef test_local_model(self):\n    \"\"\"\n        Minimal test case to check the memory tracker can collect the expected\n        memory stats at operator level, as well as can print the summary result\n        without crash.\n        \"\"\"\n    torch.manual_seed(0)\n    model = nn.Sequential(nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=False), nn.AdaptiveAvgPool2d(output_size=(1, 1))), nn.Flatten(start_dim=1), nn.Sequential(nn.Linear(64, 2), nn.ReLU(inplace=True))).cuda()\n    tracker = MemoryTracker()\n    tracker.start_monitor(model)\n    x = torch.randn(size=(2, 3, 224, 224), device=torch.device('cuda'))\n    target = torch.LongTensor([0, 1]).cuda()\n    criterion = nn.CrossEntropyLoss()\n    criterion(model(x), target).backward()\n    self.assertTrue(len(tracker._hooks) > 0)\n    tracker.stop()\n    self.assertTrue(len(tracker._hooks) == 0)\n    path = 'memory.trace'\n    tracker.save_stats(path)\n    tracker.load(path)\n    tracker.summary()\n    if os.path.exists(path):\n        os.remove(path)\n    self.assertTrue(tracker._op_index > 0)\n    self.assertTrue(len(tracker._operator_names) > 0)\n    self.assertEqual(len(tracker.memories_allocated), tracker._op_index)\n    self.assertEqual(len(tracker.memories_active), tracker._op_index)\n    self.assertEqual(len(tracker.memories_reserved), tracker._op_index)\n    self.assertTrue(len(tracker._markers) == 2)\n    self.assertTrue(tracker._cur_module_name != '')\n    self.assertTrue(hasattr(tracker, '_num_cuda_retries'))",
        "mutated": [
            "@unittest.skipIf(not TEST_CUDA, 'no cuda')\ndef test_local_model(self):\n    if False:\n        i = 10\n    '\\n        Minimal test case to check the memory tracker can collect the expected\\n        memory stats at operator level, as well as can print the summary result\\n        without crash.\\n        '\n    torch.manual_seed(0)\n    model = nn.Sequential(nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=False), nn.AdaptiveAvgPool2d(output_size=(1, 1))), nn.Flatten(start_dim=1), nn.Sequential(nn.Linear(64, 2), nn.ReLU(inplace=True))).cuda()\n    tracker = MemoryTracker()\n    tracker.start_monitor(model)\n    x = torch.randn(size=(2, 3, 224, 224), device=torch.device('cuda'))\n    target = torch.LongTensor([0, 1]).cuda()\n    criterion = nn.CrossEntropyLoss()\n    criterion(model(x), target).backward()\n    self.assertTrue(len(tracker._hooks) > 0)\n    tracker.stop()\n    self.assertTrue(len(tracker._hooks) == 0)\n    path = 'memory.trace'\n    tracker.save_stats(path)\n    tracker.load(path)\n    tracker.summary()\n    if os.path.exists(path):\n        os.remove(path)\n    self.assertTrue(tracker._op_index > 0)\n    self.assertTrue(len(tracker._operator_names) > 0)\n    self.assertEqual(len(tracker.memories_allocated), tracker._op_index)\n    self.assertEqual(len(tracker.memories_active), tracker._op_index)\n    self.assertEqual(len(tracker.memories_reserved), tracker._op_index)\n    self.assertTrue(len(tracker._markers) == 2)\n    self.assertTrue(tracker._cur_module_name != '')\n    self.assertTrue(hasattr(tracker, '_num_cuda_retries'))",
            "@unittest.skipIf(not TEST_CUDA, 'no cuda')\ndef test_local_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Minimal test case to check the memory tracker can collect the expected\\n        memory stats at operator level, as well as can print the summary result\\n        without crash.\\n        '\n    torch.manual_seed(0)\n    model = nn.Sequential(nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=False), nn.AdaptiveAvgPool2d(output_size=(1, 1))), nn.Flatten(start_dim=1), nn.Sequential(nn.Linear(64, 2), nn.ReLU(inplace=True))).cuda()\n    tracker = MemoryTracker()\n    tracker.start_monitor(model)\n    x = torch.randn(size=(2, 3, 224, 224), device=torch.device('cuda'))\n    target = torch.LongTensor([0, 1]).cuda()\n    criterion = nn.CrossEntropyLoss()\n    criterion(model(x), target).backward()\n    self.assertTrue(len(tracker._hooks) > 0)\n    tracker.stop()\n    self.assertTrue(len(tracker._hooks) == 0)\n    path = 'memory.trace'\n    tracker.save_stats(path)\n    tracker.load(path)\n    tracker.summary()\n    if os.path.exists(path):\n        os.remove(path)\n    self.assertTrue(tracker._op_index > 0)\n    self.assertTrue(len(tracker._operator_names) > 0)\n    self.assertEqual(len(tracker.memories_allocated), tracker._op_index)\n    self.assertEqual(len(tracker.memories_active), tracker._op_index)\n    self.assertEqual(len(tracker.memories_reserved), tracker._op_index)\n    self.assertTrue(len(tracker._markers) == 2)\n    self.assertTrue(tracker._cur_module_name != '')\n    self.assertTrue(hasattr(tracker, '_num_cuda_retries'))",
            "@unittest.skipIf(not TEST_CUDA, 'no cuda')\ndef test_local_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Minimal test case to check the memory tracker can collect the expected\\n        memory stats at operator level, as well as can print the summary result\\n        without crash.\\n        '\n    torch.manual_seed(0)\n    model = nn.Sequential(nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=False), nn.AdaptiveAvgPool2d(output_size=(1, 1))), nn.Flatten(start_dim=1), nn.Sequential(nn.Linear(64, 2), nn.ReLU(inplace=True))).cuda()\n    tracker = MemoryTracker()\n    tracker.start_monitor(model)\n    x = torch.randn(size=(2, 3, 224, 224), device=torch.device('cuda'))\n    target = torch.LongTensor([0, 1]).cuda()\n    criterion = nn.CrossEntropyLoss()\n    criterion(model(x), target).backward()\n    self.assertTrue(len(tracker._hooks) > 0)\n    tracker.stop()\n    self.assertTrue(len(tracker._hooks) == 0)\n    path = 'memory.trace'\n    tracker.save_stats(path)\n    tracker.load(path)\n    tracker.summary()\n    if os.path.exists(path):\n        os.remove(path)\n    self.assertTrue(tracker._op_index > 0)\n    self.assertTrue(len(tracker._operator_names) > 0)\n    self.assertEqual(len(tracker.memories_allocated), tracker._op_index)\n    self.assertEqual(len(tracker.memories_active), tracker._op_index)\n    self.assertEqual(len(tracker.memories_reserved), tracker._op_index)\n    self.assertTrue(len(tracker._markers) == 2)\n    self.assertTrue(tracker._cur_module_name != '')\n    self.assertTrue(hasattr(tracker, '_num_cuda_retries'))",
            "@unittest.skipIf(not TEST_CUDA, 'no cuda')\ndef test_local_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Minimal test case to check the memory tracker can collect the expected\\n        memory stats at operator level, as well as can print the summary result\\n        without crash.\\n        '\n    torch.manual_seed(0)\n    model = nn.Sequential(nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=False), nn.AdaptiveAvgPool2d(output_size=(1, 1))), nn.Flatten(start_dim=1), nn.Sequential(nn.Linear(64, 2), nn.ReLU(inplace=True))).cuda()\n    tracker = MemoryTracker()\n    tracker.start_monitor(model)\n    x = torch.randn(size=(2, 3, 224, 224), device=torch.device('cuda'))\n    target = torch.LongTensor([0, 1]).cuda()\n    criterion = nn.CrossEntropyLoss()\n    criterion(model(x), target).backward()\n    self.assertTrue(len(tracker._hooks) > 0)\n    tracker.stop()\n    self.assertTrue(len(tracker._hooks) == 0)\n    path = 'memory.trace'\n    tracker.save_stats(path)\n    tracker.load(path)\n    tracker.summary()\n    if os.path.exists(path):\n        os.remove(path)\n    self.assertTrue(tracker._op_index > 0)\n    self.assertTrue(len(tracker._operator_names) > 0)\n    self.assertEqual(len(tracker.memories_allocated), tracker._op_index)\n    self.assertEqual(len(tracker.memories_active), tracker._op_index)\n    self.assertEqual(len(tracker.memories_reserved), tracker._op_index)\n    self.assertTrue(len(tracker._markers) == 2)\n    self.assertTrue(tracker._cur_module_name != '')\n    self.assertTrue(hasattr(tracker, '_num_cuda_retries'))",
            "@unittest.skipIf(not TEST_CUDA, 'no cuda')\ndef test_local_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Minimal test case to check the memory tracker can collect the expected\\n        memory stats at operator level, as well as can print the summary result\\n        without crash.\\n        '\n    torch.manual_seed(0)\n    model = nn.Sequential(nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=False), nn.AdaptiveAvgPool2d(output_size=(1, 1))), nn.Flatten(start_dim=1), nn.Sequential(nn.Linear(64, 2), nn.ReLU(inplace=True))).cuda()\n    tracker = MemoryTracker()\n    tracker.start_monitor(model)\n    x = torch.randn(size=(2, 3, 224, 224), device=torch.device('cuda'))\n    target = torch.LongTensor([0, 1]).cuda()\n    criterion = nn.CrossEntropyLoss()\n    criterion(model(x), target).backward()\n    self.assertTrue(len(tracker._hooks) > 0)\n    tracker.stop()\n    self.assertTrue(len(tracker._hooks) == 0)\n    path = 'memory.trace'\n    tracker.save_stats(path)\n    tracker.load(path)\n    tracker.summary()\n    if os.path.exists(path):\n        os.remove(path)\n    self.assertTrue(tracker._op_index > 0)\n    self.assertTrue(len(tracker._operator_names) > 0)\n    self.assertEqual(len(tracker.memories_allocated), tracker._op_index)\n    self.assertEqual(len(tracker.memories_active), tracker._op_index)\n    self.assertEqual(len(tracker.memories_reserved), tracker._op_index)\n    self.assertTrue(len(tracker._markers) == 2)\n    self.assertTrue(tracker._cur_module_name != '')\n    self.assertTrue(hasattr(tracker, '_num_cuda_retries'))"
        ]
    }
]