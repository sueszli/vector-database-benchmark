[
    {
        "func_name": "get_estimator_and_data",
        "original": "def get_estimator_and_data():\n    if args.problem == 'classification':\n        (X, y) = make_classification(args.n_samples * 2, n_features=args.n_features, n_classes=args.n_classes, n_clusters_per_class=1, n_informative=args.n_features // 2, random_state=0)\n        return (X, y, HistGradientBoostingClassifier)\n    elif args.problem == 'regression':\n        (X, y) = make_regression(args.n_samples_max * 2, n_features=args.n_features, random_state=0)\n        return (X, y, HistGradientBoostingRegressor)",
        "mutated": [
            "def get_estimator_and_data():\n    if False:\n        i = 10\n    if args.problem == 'classification':\n        (X, y) = make_classification(args.n_samples * 2, n_features=args.n_features, n_classes=args.n_classes, n_clusters_per_class=1, n_informative=args.n_features // 2, random_state=0)\n        return (X, y, HistGradientBoostingClassifier)\n    elif args.problem == 'regression':\n        (X, y) = make_regression(args.n_samples_max * 2, n_features=args.n_features, random_state=0)\n        return (X, y, HistGradientBoostingRegressor)",
            "def get_estimator_and_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if args.problem == 'classification':\n        (X, y) = make_classification(args.n_samples * 2, n_features=args.n_features, n_classes=args.n_classes, n_clusters_per_class=1, n_informative=args.n_features // 2, random_state=0)\n        return (X, y, HistGradientBoostingClassifier)\n    elif args.problem == 'regression':\n        (X, y) = make_regression(args.n_samples_max * 2, n_features=args.n_features, random_state=0)\n        return (X, y, HistGradientBoostingRegressor)",
            "def get_estimator_and_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if args.problem == 'classification':\n        (X, y) = make_classification(args.n_samples * 2, n_features=args.n_features, n_classes=args.n_classes, n_clusters_per_class=1, n_informative=args.n_features // 2, random_state=0)\n        return (X, y, HistGradientBoostingClassifier)\n    elif args.problem == 'regression':\n        (X, y) = make_regression(args.n_samples_max * 2, n_features=args.n_features, random_state=0)\n        return (X, y, HistGradientBoostingRegressor)",
            "def get_estimator_and_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if args.problem == 'classification':\n        (X, y) = make_classification(args.n_samples * 2, n_features=args.n_features, n_classes=args.n_classes, n_clusters_per_class=1, n_informative=args.n_features // 2, random_state=0)\n        return (X, y, HistGradientBoostingClassifier)\n    elif args.problem == 'regression':\n        (X, y) = make_regression(args.n_samples_max * 2, n_features=args.n_features, random_state=0)\n        return (X, y, HistGradientBoostingRegressor)",
            "def get_estimator_and_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if args.problem == 'classification':\n        (X, y) = make_classification(args.n_samples * 2, n_features=args.n_features, n_classes=args.n_classes, n_clusters_per_class=1, n_informative=args.n_features // 2, random_state=0)\n        return (X, y, HistGradientBoostingClassifier)\n    elif args.problem == 'regression':\n        (X, y) = make_regression(args.n_samples_max * 2, n_features=args.n_features, random_state=0)\n        return (X, y, HistGradientBoostingRegressor)"
        ]
    },
    {
        "func_name": "one_run",
        "original": "def one_run(n_threads, n_samples):\n    X_train = X_train_[:n_samples]\n    X_test = X_test_[:n_samples]\n    y_train = y_train_[:n_samples]\n    y_test = y_test_[:n_samples]\n    if sample_weight is not None:\n        sample_weight_train = sample_weight_train_[:n_samples]\n    else:\n        sample_weight_train = None\n    assert X_train.shape[0] == n_samples\n    assert X_test.shape[0] == n_samples\n    print('Fitting a sklearn model...')\n    tic = time()\n    est = sklearn.base.clone(sklearn_est)\n    with threadpool_limits(n_threads, user_api='openmp'):\n        est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        sklearn_fit_duration = time() - tic\n        tic = time()\n        sklearn_score = est.score(X_test, y_test)\n        sklearn_score_duration = time() - tic\n    print('score: {:.4f}'.format(sklearn_score))\n    print('fit duration: {:.3f}s,'.format(sklearn_fit_duration))\n    print('score duration: {:.3f}s,'.format(sklearn_score_duration))\n    lightgbm_score = None\n    lightgbm_fit_duration = None\n    lightgbm_score_duration = None\n    if args.lightgbm:\n        print('Fitting a LightGBM model...')\n        lightgbm_est = get_equivalent_estimator(est, lib='lightgbm', n_classes=args.n_classes)\n        lightgbm_est.set_params(num_threads=n_threads)\n        tic = time()\n        lightgbm_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        lightgbm_fit_duration = time() - tic\n        tic = time()\n        lightgbm_score = lightgbm_est.score(X_test, y_test)\n        lightgbm_score_duration = time() - tic\n        print('score: {:.4f}'.format(lightgbm_score))\n        print('fit duration: {:.3f}s,'.format(lightgbm_fit_duration))\n        print('score duration: {:.3f}s,'.format(lightgbm_score_duration))\n    xgb_score = None\n    xgb_fit_duration = None\n    xgb_score_duration = None\n    if args.xgboost:\n        print('Fitting an XGBoost model...')\n        xgb_est = get_equivalent_estimator(est, lib='xgboost', n_classes=args.n_classes)\n        xgb_est.set_params(nthread=n_threads)\n        tic = time()\n        xgb_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        xgb_fit_duration = time() - tic\n        tic = time()\n        xgb_score = xgb_est.score(X_test, y_test)\n        xgb_score_duration = time() - tic\n        print('score: {:.4f}'.format(xgb_score))\n        print('fit duration: {:.3f}s,'.format(xgb_fit_duration))\n        print('score duration: {:.3f}s,'.format(xgb_score_duration))\n    cat_score = None\n    cat_fit_duration = None\n    cat_score_duration = None\n    if args.catboost:\n        print('Fitting a CatBoost model...')\n        cat_est = get_equivalent_estimator(est, lib='catboost', n_classes=args.n_classes)\n        cat_est.set_params(thread_count=n_threads)\n        tic = time()\n        cat_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        cat_fit_duration = time() - tic\n        tic = time()\n        cat_score = cat_est.score(X_test, y_test)\n        cat_score_duration = time() - tic\n        print('score: {:.4f}'.format(cat_score))\n        print('fit duration: {:.3f}s,'.format(cat_fit_duration))\n        print('score duration: {:.3f}s,'.format(cat_score_duration))\n    return (sklearn_score, sklearn_fit_duration, sklearn_score_duration, lightgbm_score, lightgbm_fit_duration, lightgbm_score_duration, xgb_score, xgb_fit_duration, xgb_score_duration, cat_score, cat_fit_duration, cat_score_duration)",
        "mutated": [
            "def one_run(n_threads, n_samples):\n    if False:\n        i = 10\n    X_train = X_train_[:n_samples]\n    X_test = X_test_[:n_samples]\n    y_train = y_train_[:n_samples]\n    y_test = y_test_[:n_samples]\n    if sample_weight is not None:\n        sample_weight_train = sample_weight_train_[:n_samples]\n    else:\n        sample_weight_train = None\n    assert X_train.shape[0] == n_samples\n    assert X_test.shape[0] == n_samples\n    print('Fitting a sklearn model...')\n    tic = time()\n    est = sklearn.base.clone(sklearn_est)\n    with threadpool_limits(n_threads, user_api='openmp'):\n        est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        sklearn_fit_duration = time() - tic\n        tic = time()\n        sklearn_score = est.score(X_test, y_test)\n        sklearn_score_duration = time() - tic\n    print('score: {:.4f}'.format(sklearn_score))\n    print('fit duration: {:.3f}s,'.format(sklearn_fit_duration))\n    print('score duration: {:.3f}s,'.format(sklearn_score_duration))\n    lightgbm_score = None\n    lightgbm_fit_duration = None\n    lightgbm_score_duration = None\n    if args.lightgbm:\n        print('Fitting a LightGBM model...')\n        lightgbm_est = get_equivalent_estimator(est, lib='lightgbm', n_classes=args.n_classes)\n        lightgbm_est.set_params(num_threads=n_threads)\n        tic = time()\n        lightgbm_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        lightgbm_fit_duration = time() - tic\n        tic = time()\n        lightgbm_score = lightgbm_est.score(X_test, y_test)\n        lightgbm_score_duration = time() - tic\n        print('score: {:.4f}'.format(lightgbm_score))\n        print('fit duration: {:.3f}s,'.format(lightgbm_fit_duration))\n        print('score duration: {:.3f}s,'.format(lightgbm_score_duration))\n    xgb_score = None\n    xgb_fit_duration = None\n    xgb_score_duration = None\n    if args.xgboost:\n        print('Fitting an XGBoost model...')\n        xgb_est = get_equivalent_estimator(est, lib='xgboost', n_classes=args.n_classes)\n        xgb_est.set_params(nthread=n_threads)\n        tic = time()\n        xgb_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        xgb_fit_duration = time() - tic\n        tic = time()\n        xgb_score = xgb_est.score(X_test, y_test)\n        xgb_score_duration = time() - tic\n        print('score: {:.4f}'.format(xgb_score))\n        print('fit duration: {:.3f}s,'.format(xgb_fit_duration))\n        print('score duration: {:.3f}s,'.format(xgb_score_duration))\n    cat_score = None\n    cat_fit_duration = None\n    cat_score_duration = None\n    if args.catboost:\n        print('Fitting a CatBoost model...')\n        cat_est = get_equivalent_estimator(est, lib='catboost', n_classes=args.n_classes)\n        cat_est.set_params(thread_count=n_threads)\n        tic = time()\n        cat_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        cat_fit_duration = time() - tic\n        tic = time()\n        cat_score = cat_est.score(X_test, y_test)\n        cat_score_duration = time() - tic\n        print('score: {:.4f}'.format(cat_score))\n        print('fit duration: {:.3f}s,'.format(cat_fit_duration))\n        print('score duration: {:.3f}s,'.format(cat_score_duration))\n    return (sklearn_score, sklearn_fit_duration, sklearn_score_duration, lightgbm_score, lightgbm_fit_duration, lightgbm_score_duration, xgb_score, xgb_fit_duration, xgb_score_duration, cat_score, cat_fit_duration, cat_score_duration)",
            "def one_run(n_threads, n_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    X_train = X_train_[:n_samples]\n    X_test = X_test_[:n_samples]\n    y_train = y_train_[:n_samples]\n    y_test = y_test_[:n_samples]\n    if sample_weight is not None:\n        sample_weight_train = sample_weight_train_[:n_samples]\n    else:\n        sample_weight_train = None\n    assert X_train.shape[0] == n_samples\n    assert X_test.shape[0] == n_samples\n    print('Fitting a sklearn model...')\n    tic = time()\n    est = sklearn.base.clone(sklearn_est)\n    with threadpool_limits(n_threads, user_api='openmp'):\n        est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        sklearn_fit_duration = time() - tic\n        tic = time()\n        sklearn_score = est.score(X_test, y_test)\n        sklearn_score_duration = time() - tic\n    print('score: {:.4f}'.format(sklearn_score))\n    print('fit duration: {:.3f}s,'.format(sklearn_fit_duration))\n    print('score duration: {:.3f}s,'.format(sklearn_score_duration))\n    lightgbm_score = None\n    lightgbm_fit_duration = None\n    lightgbm_score_duration = None\n    if args.lightgbm:\n        print('Fitting a LightGBM model...')\n        lightgbm_est = get_equivalent_estimator(est, lib='lightgbm', n_classes=args.n_classes)\n        lightgbm_est.set_params(num_threads=n_threads)\n        tic = time()\n        lightgbm_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        lightgbm_fit_duration = time() - tic\n        tic = time()\n        lightgbm_score = lightgbm_est.score(X_test, y_test)\n        lightgbm_score_duration = time() - tic\n        print('score: {:.4f}'.format(lightgbm_score))\n        print('fit duration: {:.3f}s,'.format(lightgbm_fit_duration))\n        print('score duration: {:.3f}s,'.format(lightgbm_score_duration))\n    xgb_score = None\n    xgb_fit_duration = None\n    xgb_score_duration = None\n    if args.xgboost:\n        print('Fitting an XGBoost model...')\n        xgb_est = get_equivalent_estimator(est, lib='xgboost', n_classes=args.n_classes)\n        xgb_est.set_params(nthread=n_threads)\n        tic = time()\n        xgb_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        xgb_fit_duration = time() - tic\n        tic = time()\n        xgb_score = xgb_est.score(X_test, y_test)\n        xgb_score_duration = time() - tic\n        print('score: {:.4f}'.format(xgb_score))\n        print('fit duration: {:.3f}s,'.format(xgb_fit_duration))\n        print('score duration: {:.3f}s,'.format(xgb_score_duration))\n    cat_score = None\n    cat_fit_duration = None\n    cat_score_duration = None\n    if args.catboost:\n        print('Fitting a CatBoost model...')\n        cat_est = get_equivalent_estimator(est, lib='catboost', n_classes=args.n_classes)\n        cat_est.set_params(thread_count=n_threads)\n        tic = time()\n        cat_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        cat_fit_duration = time() - tic\n        tic = time()\n        cat_score = cat_est.score(X_test, y_test)\n        cat_score_duration = time() - tic\n        print('score: {:.4f}'.format(cat_score))\n        print('fit duration: {:.3f}s,'.format(cat_fit_duration))\n        print('score duration: {:.3f}s,'.format(cat_score_duration))\n    return (sklearn_score, sklearn_fit_duration, sklearn_score_duration, lightgbm_score, lightgbm_fit_duration, lightgbm_score_duration, xgb_score, xgb_fit_duration, xgb_score_duration, cat_score, cat_fit_duration, cat_score_duration)",
            "def one_run(n_threads, n_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    X_train = X_train_[:n_samples]\n    X_test = X_test_[:n_samples]\n    y_train = y_train_[:n_samples]\n    y_test = y_test_[:n_samples]\n    if sample_weight is not None:\n        sample_weight_train = sample_weight_train_[:n_samples]\n    else:\n        sample_weight_train = None\n    assert X_train.shape[0] == n_samples\n    assert X_test.shape[0] == n_samples\n    print('Fitting a sklearn model...')\n    tic = time()\n    est = sklearn.base.clone(sklearn_est)\n    with threadpool_limits(n_threads, user_api='openmp'):\n        est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        sklearn_fit_duration = time() - tic\n        tic = time()\n        sklearn_score = est.score(X_test, y_test)\n        sklearn_score_duration = time() - tic\n    print('score: {:.4f}'.format(sklearn_score))\n    print('fit duration: {:.3f}s,'.format(sklearn_fit_duration))\n    print('score duration: {:.3f}s,'.format(sklearn_score_duration))\n    lightgbm_score = None\n    lightgbm_fit_duration = None\n    lightgbm_score_duration = None\n    if args.lightgbm:\n        print('Fitting a LightGBM model...')\n        lightgbm_est = get_equivalent_estimator(est, lib='lightgbm', n_classes=args.n_classes)\n        lightgbm_est.set_params(num_threads=n_threads)\n        tic = time()\n        lightgbm_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        lightgbm_fit_duration = time() - tic\n        tic = time()\n        lightgbm_score = lightgbm_est.score(X_test, y_test)\n        lightgbm_score_duration = time() - tic\n        print('score: {:.4f}'.format(lightgbm_score))\n        print('fit duration: {:.3f}s,'.format(lightgbm_fit_duration))\n        print('score duration: {:.3f}s,'.format(lightgbm_score_duration))\n    xgb_score = None\n    xgb_fit_duration = None\n    xgb_score_duration = None\n    if args.xgboost:\n        print('Fitting an XGBoost model...')\n        xgb_est = get_equivalent_estimator(est, lib='xgboost', n_classes=args.n_classes)\n        xgb_est.set_params(nthread=n_threads)\n        tic = time()\n        xgb_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        xgb_fit_duration = time() - tic\n        tic = time()\n        xgb_score = xgb_est.score(X_test, y_test)\n        xgb_score_duration = time() - tic\n        print('score: {:.4f}'.format(xgb_score))\n        print('fit duration: {:.3f}s,'.format(xgb_fit_duration))\n        print('score duration: {:.3f}s,'.format(xgb_score_duration))\n    cat_score = None\n    cat_fit_duration = None\n    cat_score_duration = None\n    if args.catboost:\n        print('Fitting a CatBoost model...')\n        cat_est = get_equivalent_estimator(est, lib='catboost', n_classes=args.n_classes)\n        cat_est.set_params(thread_count=n_threads)\n        tic = time()\n        cat_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        cat_fit_duration = time() - tic\n        tic = time()\n        cat_score = cat_est.score(X_test, y_test)\n        cat_score_duration = time() - tic\n        print('score: {:.4f}'.format(cat_score))\n        print('fit duration: {:.3f}s,'.format(cat_fit_duration))\n        print('score duration: {:.3f}s,'.format(cat_score_duration))\n    return (sklearn_score, sklearn_fit_duration, sklearn_score_duration, lightgbm_score, lightgbm_fit_duration, lightgbm_score_duration, xgb_score, xgb_fit_duration, xgb_score_duration, cat_score, cat_fit_duration, cat_score_duration)",
            "def one_run(n_threads, n_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    X_train = X_train_[:n_samples]\n    X_test = X_test_[:n_samples]\n    y_train = y_train_[:n_samples]\n    y_test = y_test_[:n_samples]\n    if sample_weight is not None:\n        sample_weight_train = sample_weight_train_[:n_samples]\n    else:\n        sample_weight_train = None\n    assert X_train.shape[0] == n_samples\n    assert X_test.shape[0] == n_samples\n    print('Fitting a sklearn model...')\n    tic = time()\n    est = sklearn.base.clone(sklearn_est)\n    with threadpool_limits(n_threads, user_api='openmp'):\n        est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        sklearn_fit_duration = time() - tic\n        tic = time()\n        sklearn_score = est.score(X_test, y_test)\n        sklearn_score_duration = time() - tic\n    print('score: {:.4f}'.format(sklearn_score))\n    print('fit duration: {:.3f}s,'.format(sklearn_fit_duration))\n    print('score duration: {:.3f}s,'.format(sklearn_score_duration))\n    lightgbm_score = None\n    lightgbm_fit_duration = None\n    lightgbm_score_duration = None\n    if args.lightgbm:\n        print('Fitting a LightGBM model...')\n        lightgbm_est = get_equivalent_estimator(est, lib='lightgbm', n_classes=args.n_classes)\n        lightgbm_est.set_params(num_threads=n_threads)\n        tic = time()\n        lightgbm_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        lightgbm_fit_duration = time() - tic\n        tic = time()\n        lightgbm_score = lightgbm_est.score(X_test, y_test)\n        lightgbm_score_duration = time() - tic\n        print('score: {:.4f}'.format(lightgbm_score))\n        print('fit duration: {:.3f}s,'.format(lightgbm_fit_duration))\n        print('score duration: {:.3f}s,'.format(lightgbm_score_duration))\n    xgb_score = None\n    xgb_fit_duration = None\n    xgb_score_duration = None\n    if args.xgboost:\n        print('Fitting an XGBoost model...')\n        xgb_est = get_equivalent_estimator(est, lib='xgboost', n_classes=args.n_classes)\n        xgb_est.set_params(nthread=n_threads)\n        tic = time()\n        xgb_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        xgb_fit_duration = time() - tic\n        tic = time()\n        xgb_score = xgb_est.score(X_test, y_test)\n        xgb_score_duration = time() - tic\n        print('score: {:.4f}'.format(xgb_score))\n        print('fit duration: {:.3f}s,'.format(xgb_fit_duration))\n        print('score duration: {:.3f}s,'.format(xgb_score_duration))\n    cat_score = None\n    cat_fit_duration = None\n    cat_score_duration = None\n    if args.catboost:\n        print('Fitting a CatBoost model...')\n        cat_est = get_equivalent_estimator(est, lib='catboost', n_classes=args.n_classes)\n        cat_est.set_params(thread_count=n_threads)\n        tic = time()\n        cat_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        cat_fit_duration = time() - tic\n        tic = time()\n        cat_score = cat_est.score(X_test, y_test)\n        cat_score_duration = time() - tic\n        print('score: {:.4f}'.format(cat_score))\n        print('fit duration: {:.3f}s,'.format(cat_fit_duration))\n        print('score duration: {:.3f}s,'.format(cat_score_duration))\n    return (sklearn_score, sklearn_fit_duration, sklearn_score_duration, lightgbm_score, lightgbm_fit_duration, lightgbm_score_duration, xgb_score, xgb_fit_duration, xgb_score_duration, cat_score, cat_fit_duration, cat_score_duration)",
            "def one_run(n_threads, n_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    X_train = X_train_[:n_samples]\n    X_test = X_test_[:n_samples]\n    y_train = y_train_[:n_samples]\n    y_test = y_test_[:n_samples]\n    if sample_weight is not None:\n        sample_weight_train = sample_weight_train_[:n_samples]\n    else:\n        sample_weight_train = None\n    assert X_train.shape[0] == n_samples\n    assert X_test.shape[0] == n_samples\n    print('Fitting a sklearn model...')\n    tic = time()\n    est = sklearn.base.clone(sklearn_est)\n    with threadpool_limits(n_threads, user_api='openmp'):\n        est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        sklearn_fit_duration = time() - tic\n        tic = time()\n        sklearn_score = est.score(X_test, y_test)\n        sklearn_score_duration = time() - tic\n    print('score: {:.4f}'.format(sklearn_score))\n    print('fit duration: {:.3f}s,'.format(sklearn_fit_duration))\n    print('score duration: {:.3f}s,'.format(sklearn_score_duration))\n    lightgbm_score = None\n    lightgbm_fit_duration = None\n    lightgbm_score_duration = None\n    if args.lightgbm:\n        print('Fitting a LightGBM model...')\n        lightgbm_est = get_equivalent_estimator(est, lib='lightgbm', n_classes=args.n_classes)\n        lightgbm_est.set_params(num_threads=n_threads)\n        tic = time()\n        lightgbm_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        lightgbm_fit_duration = time() - tic\n        tic = time()\n        lightgbm_score = lightgbm_est.score(X_test, y_test)\n        lightgbm_score_duration = time() - tic\n        print('score: {:.4f}'.format(lightgbm_score))\n        print('fit duration: {:.3f}s,'.format(lightgbm_fit_duration))\n        print('score duration: {:.3f}s,'.format(lightgbm_score_duration))\n    xgb_score = None\n    xgb_fit_duration = None\n    xgb_score_duration = None\n    if args.xgboost:\n        print('Fitting an XGBoost model...')\n        xgb_est = get_equivalent_estimator(est, lib='xgboost', n_classes=args.n_classes)\n        xgb_est.set_params(nthread=n_threads)\n        tic = time()\n        xgb_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        xgb_fit_duration = time() - tic\n        tic = time()\n        xgb_score = xgb_est.score(X_test, y_test)\n        xgb_score_duration = time() - tic\n        print('score: {:.4f}'.format(xgb_score))\n        print('fit duration: {:.3f}s,'.format(xgb_fit_duration))\n        print('score duration: {:.3f}s,'.format(xgb_score_duration))\n    cat_score = None\n    cat_fit_duration = None\n    cat_score_duration = None\n    if args.catboost:\n        print('Fitting a CatBoost model...')\n        cat_est = get_equivalent_estimator(est, lib='catboost', n_classes=args.n_classes)\n        cat_est.set_params(thread_count=n_threads)\n        tic = time()\n        cat_est.fit(X_train, y_train, sample_weight=sample_weight_train)\n        cat_fit_duration = time() - tic\n        tic = time()\n        cat_score = cat_est.score(X_test, y_test)\n        cat_score_duration = time() - tic\n        print('score: {:.4f}'.format(cat_score))\n        print('fit duration: {:.3f}s,'.format(cat_fit_duration))\n        print('score duration: {:.3f}s,'.format(cat_score_duration))\n    return (sklearn_score, sklearn_fit_duration, sklearn_score_duration, lightgbm_score, lightgbm_fit_duration, lightgbm_score_duration, xgb_score, xgb_fit_duration, xgb_score_duration, cat_score, cat_fit_duration, cat_score_duration)"
        ]
    }
]