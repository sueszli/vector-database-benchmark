[
    {
        "func_name": "prepare",
        "original": "def prepare(cfg, use_arg_parser=True):\n    cfg.MB_SIZE = 1\n    cfg.NUM_CHANNELS = 3\n    cfg.OUTPUT_PATH = os.path.join(abs_path, 'Output')\n    cfg['DATA'].MAP_FILE_PATH = os.path.join(abs_path, cfg['DATA'].MAP_FILE_PATH)\n    running_locally = os.path.exists(cfg['DATA'].MAP_FILE_PATH)\n    if running_locally:\n        os.chdir(cfg['DATA'].MAP_FILE_PATH)\n        if not os.path.exists(os.path.join(abs_path, 'Output')):\n            os.makedirs(os.path.join(abs_path, 'Output'))\n        if not os.path.exists(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET)):\n            os.makedirs(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET))\n    else:\n        cfg['CNTK'].DEBUG_OUTPUT = False\n        cfg.VISUALIZE_RESULTS = False\n    if use_arg_parser:\n        parse_arguments(cfg)\n    data_path = cfg['DATA'].MAP_FILE_PATH\n    if not os.path.isdir(data_path):\n        raise RuntimeError('Directory %s does not exist' % data_path)\n    cfg['DATA'].CLASS_MAP_FILE = os.path.join(data_path, cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].TRAIN_MAP_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_MAP_FILE)\n    cfg['DATA'].TEST_MAP_FILE = os.path.join(data_path, cfg['DATA'].TEST_MAP_FILE)\n    cfg['DATA'].TRAIN_ROI_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_ROI_FILE)\n    cfg['DATA'].TEST_ROI_FILE = os.path.join(data_path, cfg['DATA'].TEST_ROI_FILE)\n    cfg['MODEL_PATH'] = os.path.join(cfg.OUTPUT_PATH, 'faster_rcnn_eval_{}_{}.model'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage'))\n    cfg['BASE_MODEL_PATH'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '..', 'PretrainedModels', cfg['MODEL'].BASE_MODEL_FILE)\n    cfg['DATA'].CLASSES = parse_class_map_file(cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].NUM_CLASSES = len(cfg['DATA'].CLASSES)\n    if cfg['CNTK'].FAST_MODE:\n        cfg['CNTK'].E2E_MAX_EPOCHS = 1\n        cfg['CNTK'].RPN_EPOCHS = 1\n        cfg['CNTK'].FRCN_EPOCHS = 1\n    if cfg['CNTK'].FORCE_DETERMINISTIC:\n        force_deterministic_algorithms()\n    np.random.seed(seed=cfg.RND_SEED)\n    if False and cfg['CNTK'].DEBUG_OUTPUT:\n        print('Using the following parameters:')\n        print('Flip image       : {}'.format(cfg['TRAIN'].USE_FLIPPED))\n        print('Train conv layers: {}'.format(cfg.TRAIN_CONV_LAYERS))\n        print('Random seed      : {}'.format(cfg.RND_SEED))\n        print('Momentum per MB  : {}'.format(cfg['CNTK'].MOMENTUM_PER_MB))\n        if cfg['CNTK'].TRAIN_E2E:\n            print('E2E epochs       : {}'.format(cfg['CNTK'].E2E_MAX_EPOCHS))\n        else:\n            print('RPN lr factor    : {}'.format(cfg['CNTK'].RPN_LR_FACTOR))\n            print('RPN epochs       : {}'.format(cfg['CNTK'].RPN_EPOCHS))\n            print('FRCN lr factor   : {}'.format(cfg['CNTK'].FRCN_LR_FACTOR))\n            print('FRCN epochs      : {}'.format(cfg['CNTK'].FRCN_EPOCHS))",
        "mutated": [
            "def prepare(cfg, use_arg_parser=True):\n    if False:\n        i = 10\n    cfg.MB_SIZE = 1\n    cfg.NUM_CHANNELS = 3\n    cfg.OUTPUT_PATH = os.path.join(abs_path, 'Output')\n    cfg['DATA'].MAP_FILE_PATH = os.path.join(abs_path, cfg['DATA'].MAP_FILE_PATH)\n    running_locally = os.path.exists(cfg['DATA'].MAP_FILE_PATH)\n    if running_locally:\n        os.chdir(cfg['DATA'].MAP_FILE_PATH)\n        if not os.path.exists(os.path.join(abs_path, 'Output')):\n            os.makedirs(os.path.join(abs_path, 'Output'))\n        if not os.path.exists(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET)):\n            os.makedirs(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET))\n    else:\n        cfg['CNTK'].DEBUG_OUTPUT = False\n        cfg.VISUALIZE_RESULTS = False\n    if use_arg_parser:\n        parse_arguments(cfg)\n    data_path = cfg['DATA'].MAP_FILE_PATH\n    if not os.path.isdir(data_path):\n        raise RuntimeError('Directory %s does not exist' % data_path)\n    cfg['DATA'].CLASS_MAP_FILE = os.path.join(data_path, cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].TRAIN_MAP_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_MAP_FILE)\n    cfg['DATA'].TEST_MAP_FILE = os.path.join(data_path, cfg['DATA'].TEST_MAP_FILE)\n    cfg['DATA'].TRAIN_ROI_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_ROI_FILE)\n    cfg['DATA'].TEST_ROI_FILE = os.path.join(data_path, cfg['DATA'].TEST_ROI_FILE)\n    cfg['MODEL_PATH'] = os.path.join(cfg.OUTPUT_PATH, 'faster_rcnn_eval_{}_{}.model'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage'))\n    cfg['BASE_MODEL_PATH'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '..', 'PretrainedModels', cfg['MODEL'].BASE_MODEL_FILE)\n    cfg['DATA'].CLASSES = parse_class_map_file(cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].NUM_CLASSES = len(cfg['DATA'].CLASSES)\n    if cfg['CNTK'].FAST_MODE:\n        cfg['CNTK'].E2E_MAX_EPOCHS = 1\n        cfg['CNTK'].RPN_EPOCHS = 1\n        cfg['CNTK'].FRCN_EPOCHS = 1\n    if cfg['CNTK'].FORCE_DETERMINISTIC:\n        force_deterministic_algorithms()\n    np.random.seed(seed=cfg.RND_SEED)\n    if False and cfg['CNTK'].DEBUG_OUTPUT:\n        print('Using the following parameters:')\n        print('Flip image       : {}'.format(cfg['TRAIN'].USE_FLIPPED))\n        print('Train conv layers: {}'.format(cfg.TRAIN_CONV_LAYERS))\n        print('Random seed      : {}'.format(cfg.RND_SEED))\n        print('Momentum per MB  : {}'.format(cfg['CNTK'].MOMENTUM_PER_MB))\n        if cfg['CNTK'].TRAIN_E2E:\n            print('E2E epochs       : {}'.format(cfg['CNTK'].E2E_MAX_EPOCHS))\n        else:\n            print('RPN lr factor    : {}'.format(cfg['CNTK'].RPN_LR_FACTOR))\n            print('RPN epochs       : {}'.format(cfg['CNTK'].RPN_EPOCHS))\n            print('FRCN lr factor   : {}'.format(cfg['CNTK'].FRCN_LR_FACTOR))\n            print('FRCN epochs      : {}'.format(cfg['CNTK'].FRCN_EPOCHS))",
            "def prepare(cfg, use_arg_parser=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cfg.MB_SIZE = 1\n    cfg.NUM_CHANNELS = 3\n    cfg.OUTPUT_PATH = os.path.join(abs_path, 'Output')\n    cfg['DATA'].MAP_FILE_PATH = os.path.join(abs_path, cfg['DATA'].MAP_FILE_PATH)\n    running_locally = os.path.exists(cfg['DATA'].MAP_FILE_PATH)\n    if running_locally:\n        os.chdir(cfg['DATA'].MAP_FILE_PATH)\n        if not os.path.exists(os.path.join(abs_path, 'Output')):\n            os.makedirs(os.path.join(abs_path, 'Output'))\n        if not os.path.exists(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET)):\n            os.makedirs(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET))\n    else:\n        cfg['CNTK'].DEBUG_OUTPUT = False\n        cfg.VISUALIZE_RESULTS = False\n    if use_arg_parser:\n        parse_arguments(cfg)\n    data_path = cfg['DATA'].MAP_FILE_PATH\n    if not os.path.isdir(data_path):\n        raise RuntimeError('Directory %s does not exist' % data_path)\n    cfg['DATA'].CLASS_MAP_FILE = os.path.join(data_path, cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].TRAIN_MAP_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_MAP_FILE)\n    cfg['DATA'].TEST_MAP_FILE = os.path.join(data_path, cfg['DATA'].TEST_MAP_FILE)\n    cfg['DATA'].TRAIN_ROI_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_ROI_FILE)\n    cfg['DATA'].TEST_ROI_FILE = os.path.join(data_path, cfg['DATA'].TEST_ROI_FILE)\n    cfg['MODEL_PATH'] = os.path.join(cfg.OUTPUT_PATH, 'faster_rcnn_eval_{}_{}.model'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage'))\n    cfg['BASE_MODEL_PATH'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '..', 'PretrainedModels', cfg['MODEL'].BASE_MODEL_FILE)\n    cfg['DATA'].CLASSES = parse_class_map_file(cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].NUM_CLASSES = len(cfg['DATA'].CLASSES)\n    if cfg['CNTK'].FAST_MODE:\n        cfg['CNTK'].E2E_MAX_EPOCHS = 1\n        cfg['CNTK'].RPN_EPOCHS = 1\n        cfg['CNTK'].FRCN_EPOCHS = 1\n    if cfg['CNTK'].FORCE_DETERMINISTIC:\n        force_deterministic_algorithms()\n    np.random.seed(seed=cfg.RND_SEED)\n    if False and cfg['CNTK'].DEBUG_OUTPUT:\n        print('Using the following parameters:')\n        print('Flip image       : {}'.format(cfg['TRAIN'].USE_FLIPPED))\n        print('Train conv layers: {}'.format(cfg.TRAIN_CONV_LAYERS))\n        print('Random seed      : {}'.format(cfg.RND_SEED))\n        print('Momentum per MB  : {}'.format(cfg['CNTK'].MOMENTUM_PER_MB))\n        if cfg['CNTK'].TRAIN_E2E:\n            print('E2E epochs       : {}'.format(cfg['CNTK'].E2E_MAX_EPOCHS))\n        else:\n            print('RPN lr factor    : {}'.format(cfg['CNTK'].RPN_LR_FACTOR))\n            print('RPN epochs       : {}'.format(cfg['CNTK'].RPN_EPOCHS))\n            print('FRCN lr factor   : {}'.format(cfg['CNTK'].FRCN_LR_FACTOR))\n            print('FRCN epochs      : {}'.format(cfg['CNTK'].FRCN_EPOCHS))",
            "def prepare(cfg, use_arg_parser=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cfg.MB_SIZE = 1\n    cfg.NUM_CHANNELS = 3\n    cfg.OUTPUT_PATH = os.path.join(abs_path, 'Output')\n    cfg['DATA'].MAP_FILE_PATH = os.path.join(abs_path, cfg['DATA'].MAP_FILE_PATH)\n    running_locally = os.path.exists(cfg['DATA'].MAP_FILE_PATH)\n    if running_locally:\n        os.chdir(cfg['DATA'].MAP_FILE_PATH)\n        if not os.path.exists(os.path.join(abs_path, 'Output')):\n            os.makedirs(os.path.join(abs_path, 'Output'))\n        if not os.path.exists(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET)):\n            os.makedirs(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET))\n    else:\n        cfg['CNTK'].DEBUG_OUTPUT = False\n        cfg.VISUALIZE_RESULTS = False\n    if use_arg_parser:\n        parse_arguments(cfg)\n    data_path = cfg['DATA'].MAP_FILE_PATH\n    if not os.path.isdir(data_path):\n        raise RuntimeError('Directory %s does not exist' % data_path)\n    cfg['DATA'].CLASS_MAP_FILE = os.path.join(data_path, cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].TRAIN_MAP_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_MAP_FILE)\n    cfg['DATA'].TEST_MAP_FILE = os.path.join(data_path, cfg['DATA'].TEST_MAP_FILE)\n    cfg['DATA'].TRAIN_ROI_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_ROI_FILE)\n    cfg['DATA'].TEST_ROI_FILE = os.path.join(data_path, cfg['DATA'].TEST_ROI_FILE)\n    cfg['MODEL_PATH'] = os.path.join(cfg.OUTPUT_PATH, 'faster_rcnn_eval_{}_{}.model'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage'))\n    cfg['BASE_MODEL_PATH'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '..', 'PretrainedModels', cfg['MODEL'].BASE_MODEL_FILE)\n    cfg['DATA'].CLASSES = parse_class_map_file(cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].NUM_CLASSES = len(cfg['DATA'].CLASSES)\n    if cfg['CNTK'].FAST_MODE:\n        cfg['CNTK'].E2E_MAX_EPOCHS = 1\n        cfg['CNTK'].RPN_EPOCHS = 1\n        cfg['CNTK'].FRCN_EPOCHS = 1\n    if cfg['CNTK'].FORCE_DETERMINISTIC:\n        force_deterministic_algorithms()\n    np.random.seed(seed=cfg.RND_SEED)\n    if False and cfg['CNTK'].DEBUG_OUTPUT:\n        print('Using the following parameters:')\n        print('Flip image       : {}'.format(cfg['TRAIN'].USE_FLIPPED))\n        print('Train conv layers: {}'.format(cfg.TRAIN_CONV_LAYERS))\n        print('Random seed      : {}'.format(cfg.RND_SEED))\n        print('Momentum per MB  : {}'.format(cfg['CNTK'].MOMENTUM_PER_MB))\n        if cfg['CNTK'].TRAIN_E2E:\n            print('E2E epochs       : {}'.format(cfg['CNTK'].E2E_MAX_EPOCHS))\n        else:\n            print('RPN lr factor    : {}'.format(cfg['CNTK'].RPN_LR_FACTOR))\n            print('RPN epochs       : {}'.format(cfg['CNTK'].RPN_EPOCHS))\n            print('FRCN lr factor   : {}'.format(cfg['CNTK'].FRCN_LR_FACTOR))\n            print('FRCN epochs      : {}'.format(cfg['CNTK'].FRCN_EPOCHS))",
            "def prepare(cfg, use_arg_parser=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cfg.MB_SIZE = 1\n    cfg.NUM_CHANNELS = 3\n    cfg.OUTPUT_PATH = os.path.join(abs_path, 'Output')\n    cfg['DATA'].MAP_FILE_PATH = os.path.join(abs_path, cfg['DATA'].MAP_FILE_PATH)\n    running_locally = os.path.exists(cfg['DATA'].MAP_FILE_PATH)\n    if running_locally:\n        os.chdir(cfg['DATA'].MAP_FILE_PATH)\n        if not os.path.exists(os.path.join(abs_path, 'Output')):\n            os.makedirs(os.path.join(abs_path, 'Output'))\n        if not os.path.exists(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET)):\n            os.makedirs(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET))\n    else:\n        cfg['CNTK'].DEBUG_OUTPUT = False\n        cfg.VISUALIZE_RESULTS = False\n    if use_arg_parser:\n        parse_arguments(cfg)\n    data_path = cfg['DATA'].MAP_FILE_PATH\n    if not os.path.isdir(data_path):\n        raise RuntimeError('Directory %s does not exist' % data_path)\n    cfg['DATA'].CLASS_MAP_FILE = os.path.join(data_path, cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].TRAIN_MAP_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_MAP_FILE)\n    cfg['DATA'].TEST_MAP_FILE = os.path.join(data_path, cfg['DATA'].TEST_MAP_FILE)\n    cfg['DATA'].TRAIN_ROI_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_ROI_FILE)\n    cfg['DATA'].TEST_ROI_FILE = os.path.join(data_path, cfg['DATA'].TEST_ROI_FILE)\n    cfg['MODEL_PATH'] = os.path.join(cfg.OUTPUT_PATH, 'faster_rcnn_eval_{}_{}.model'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage'))\n    cfg['BASE_MODEL_PATH'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '..', 'PretrainedModels', cfg['MODEL'].BASE_MODEL_FILE)\n    cfg['DATA'].CLASSES = parse_class_map_file(cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].NUM_CLASSES = len(cfg['DATA'].CLASSES)\n    if cfg['CNTK'].FAST_MODE:\n        cfg['CNTK'].E2E_MAX_EPOCHS = 1\n        cfg['CNTK'].RPN_EPOCHS = 1\n        cfg['CNTK'].FRCN_EPOCHS = 1\n    if cfg['CNTK'].FORCE_DETERMINISTIC:\n        force_deterministic_algorithms()\n    np.random.seed(seed=cfg.RND_SEED)\n    if False and cfg['CNTK'].DEBUG_OUTPUT:\n        print('Using the following parameters:')\n        print('Flip image       : {}'.format(cfg['TRAIN'].USE_FLIPPED))\n        print('Train conv layers: {}'.format(cfg.TRAIN_CONV_LAYERS))\n        print('Random seed      : {}'.format(cfg.RND_SEED))\n        print('Momentum per MB  : {}'.format(cfg['CNTK'].MOMENTUM_PER_MB))\n        if cfg['CNTK'].TRAIN_E2E:\n            print('E2E epochs       : {}'.format(cfg['CNTK'].E2E_MAX_EPOCHS))\n        else:\n            print('RPN lr factor    : {}'.format(cfg['CNTK'].RPN_LR_FACTOR))\n            print('RPN epochs       : {}'.format(cfg['CNTK'].RPN_EPOCHS))\n            print('FRCN lr factor   : {}'.format(cfg['CNTK'].FRCN_LR_FACTOR))\n            print('FRCN epochs      : {}'.format(cfg['CNTK'].FRCN_EPOCHS))",
            "def prepare(cfg, use_arg_parser=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cfg.MB_SIZE = 1\n    cfg.NUM_CHANNELS = 3\n    cfg.OUTPUT_PATH = os.path.join(abs_path, 'Output')\n    cfg['DATA'].MAP_FILE_PATH = os.path.join(abs_path, cfg['DATA'].MAP_FILE_PATH)\n    running_locally = os.path.exists(cfg['DATA'].MAP_FILE_PATH)\n    if running_locally:\n        os.chdir(cfg['DATA'].MAP_FILE_PATH)\n        if not os.path.exists(os.path.join(abs_path, 'Output')):\n            os.makedirs(os.path.join(abs_path, 'Output'))\n        if not os.path.exists(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET)):\n            os.makedirs(os.path.join(abs_path, 'Output', cfg['DATA'].DATASET))\n    else:\n        cfg['CNTK'].DEBUG_OUTPUT = False\n        cfg.VISUALIZE_RESULTS = False\n    if use_arg_parser:\n        parse_arguments(cfg)\n    data_path = cfg['DATA'].MAP_FILE_PATH\n    if not os.path.isdir(data_path):\n        raise RuntimeError('Directory %s does not exist' % data_path)\n    cfg['DATA'].CLASS_MAP_FILE = os.path.join(data_path, cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].TRAIN_MAP_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_MAP_FILE)\n    cfg['DATA'].TEST_MAP_FILE = os.path.join(data_path, cfg['DATA'].TEST_MAP_FILE)\n    cfg['DATA'].TRAIN_ROI_FILE = os.path.join(data_path, cfg['DATA'].TRAIN_ROI_FILE)\n    cfg['DATA'].TEST_ROI_FILE = os.path.join(data_path, cfg['DATA'].TEST_ROI_FILE)\n    cfg['MODEL_PATH'] = os.path.join(cfg.OUTPUT_PATH, 'faster_rcnn_eval_{}_{}.model'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage'))\n    cfg['BASE_MODEL_PATH'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', '..', '..', 'PretrainedModels', cfg['MODEL'].BASE_MODEL_FILE)\n    cfg['DATA'].CLASSES = parse_class_map_file(cfg['DATA'].CLASS_MAP_FILE)\n    cfg['DATA'].NUM_CLASSES = len(cfg['DATA'].CLASSES)\n    if cfg['CNTK'].FAST_MODE:\n        cfg['CNTK'].E2E_MAX_EPOCHS = 1\n        cfg['CNTK'].RPN_EPOCHS = 1\n        cfg['CNTK'].FRCN_EPOCHS = 1\n    if cfg['CNTK'].FORCE_DETERMINISTIC:\n        force_deterministic_algorithms()\n    np.random.seed(seed=cfg.RND_SEED)\n    if False and cfg['CNTK'].DEBUG_OUTPUT:\n        print('Using the following parameters:')\n        print('Flip image       : {}'.format(cfg['TRAIN'].USE_FLIPPED))\n        print('Train conv layers: {}'.format(cfg.TRAIN_CONV_LAYERS))\n        print('Random seed      : {}'.format(cfg.RND_SEED))\n        print('Momentum per MB  : {}'.format(cfg['CNTK'].MOMENTUM_PER_MB))\n        if cfg['CNTK'].TRAIN_E2E:\n            print('E2E epochs       : {}'.format(cfg['CNTK'].E2E_MAX_EPOCHS))\n        else:\n            print('RPN lr factor    : {}'.format(cfg['CNTK'].RPN_LR_FACTOR))\n            print('RPN epochs       : {}'.format(cfg['CNTK'].RPN_EPOCHS))\n            print('FRCN lr factor   : {}'.format(cfg['CNTK'].FRCN_LR_FACTOR))\n            print('FRCN epochs      : {}'.format(cfg['CNTK'].FRCN_EPOCHS))"
        ]
    },
    {
        "func_name": "parse_arguments",
        "original": "def parse_arguments(cfg):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=cfg['DATA'].MAP_FILE_PATH)\n    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default=cfg['CNTK'].E2E_MAX_EPOCHS)\n    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default=cfg['CNTK'].MB_SIZE)\n    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default=cfg['CNTK'].NUM_TRAIN_IMAGES)\n    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n    parser.add_argument('-device', '--device', type=int, help='Force to run the script on a specified device', required=False, default=None)\n    parser.add_argument('-rpnLrFactor', '--rpnLrFactor', type=float, help='Scale factor for rpn lr schedule', required=False)\n    parser.add_argument('-frcnLrFactor', '--frcnLrFactor', type=float, help='Scale factor for frcn lr schedule', required=False)\n    parser.add_argument('-e2eLrFactor', '--e2eLrFactor', type=float, help='Scale factor for e2e lr schedule', required=False)\n    parser.add_argument('-momentumPerMb', '--momentumPerMb', type=float, help='momentum per minibatch', required=False)\n    parser.add_argument('-e2eEpochs', '--e2eEpochs', type=int, help='number of epochs for e2e training', required=False)\n    parser.add_argument('-rpnEpochs', '--rpnEpochs', type=int, help='number of epochs for rpn training', required=False)\n    parser.add_argument('-frcnEpochs', '--frcnEpochs', type=int, help='number of epochs for frcn training', required=False)\n    parser.add_argument('-rndSeed', '--rndSeed', type=int, help='the random seed', required=False)\n    parser.add_argument('-trainConv', '--trainConv', type=int, help='whether to train conv layers', required=False)\n    parser.add_argument('-trainE2E', '--trainE2E', type=int, help='whether to train e2e (otherwise 4 stage)', required=False)\n    args = vars(parser.parse_args())\n    if args['rpnLrFactor'] is not None:\n        cfg['MODEL'].RPN_LR_FACTOR = args['rpnLrFactor']\n    if args['frcnLrFactor'] is not None:\n        cfg['MODEL'].FRCN_LR_FACTOR = args['frcnLrFactor']\n    if args['e2eLrFactor'] is not None:\n        cfg['MODEL'].E2E_LR_FACTOR = args['e2eLrFactor']\n    if args['e2eEpochs'] is not None:\n        cfg['CNTK'].E2E_MAX_EPOCHS = args['e2eEpochs']\n    if args['rpnEpochs'] is not None:\n        cfg['CNTK'].RPN_EPOCHS = args['rpnEpochs']\n    if args['frcnEpochs'] is not None:\n        cfg['CNTK'].FRCN_EPOCHS = args['frcnEpochs']\n    if args['momentumPerMb'] is not None:\n        cfg['CNTK'].MOMENTUM_PER_MB = args['momentumPerMb']\n    if args['rndSeed'] is not None:\n        cfg.RND_SEED = args['rndSeed']\n    if args['trainConv'] is not None:\n        cfg.TRAIN_CONV_LAYERS = True if args['trainConv'] == 1 else False\n    if args['trainE2E'] is not None:\n        cfg.TRAIN_E2E = True if args['trainE2E'] == 1 else False\n    if args['datadir'] is not None:\n        cfg['DATA'].MAP_FILE_PATH = args['datadir']\n    if args['outputdir'] is not None:\n        cfg.OUTPUT_PATH = args['outputdir']\n    if args['logdir'] is not None:\n        log_dir = args['logdir']\n    if args['device'] is not None:\n        if Communicator.rank() == 0:\n            cntk.device.try_set_default_device(cntk.device.gpu(args['device']))\n        else:\n            cntk.device.try_set_default_device(cntk.device.cpu())",
        "mutated": [
            "def parse_arguments(cfg):\n    if False:\n        i = 10\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=cfg['DATA'].MAP_FILE_PATH)\n    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default=cfg['CNTK'].E2E_MAX_EPOCHS)\n    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default=cfg['CNTK'].MB_SIZE)\n    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default=cfg['CNTK'].NUM_TRAIN_IMAGES)\n    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n    parser.add_argument('-device', '--device', type=int, help='Force to run the script on a specified device', required=False, default=None)\n    parser.add_argument('-rpnLrFactor', '--rpnLrFactor', type=float, help='Scale factor for rpn lr schedule', required=False)\n    parser.add_argument('-frcnLrFactor', '--frcnLrFactor', type=float, help='Scale factor for frcn lr schedule', required=False)\n    parser.add_argument('-e2eLrFactor', '--e2eLrFactor', type=float, help='Scale factor for e2e lr schedule', required=False)\n    parser.add_argument('-momentumPerMb', '--momentumPerMb', type=float, help='momentum per minibatch', required=False)\n    parser.add_argument('-e2eEpochs', '--e2eEpochs', type=int, help='number of epochs for e2e training', required=False)\n    parser.add_argument('-rpnEpochs', '--rpnEpochs', type=int, help='number of epochs for rpn training', required=False)\n    parser.add_argument('-frcnEpochs', '--frcnEpochs', type=int, help='number of epochs for frcn training', required=False)\n    parser.add_argument('-rndSeed', '--rndSeed', type=int, help='the random seed', required=False)\n    parser.add_argument('-trainConv', '--trainConv', type=int, help='whether to train conv layers', required=False)\n    parser.add_argument('-trainE2E', '--trainE2E', type=int, help='whether to train e2e (otherwise 4 stage)', required=False)\n    args = vars(parser.parse_args())\n    if args['rpnLrFactor'] is not None:\n        cfg['MODEL'].RPN_LR_FACTOR = args['rpnLrFactor']\n    if args['frcnLrFactor'] is not None:\n        cfg['MODEL'].FRCN_LR_FACTOR = args['frcnLrFactor']\n    if args['e2eLrFactor'] is not None:\n        cfg['MODEL'].E2E_LR_FACTOR = args['e2eLrFactor']\n    if args['e2eEpochs'] is not None:\n        cfg['CNTK'].E2E_MAX_EPOCHS = args['e2eEpochs']\n    if args['rpnEpochs'] is not None:\n        cfg['CNTK'].RPN_EPOCHS = args['rpnEpochs']\n    if args['frcnEpochs'] is not None:\n        cfg['CNTK'].FRCN_EPOCHS = args['frcnEpochs']\n    if args['momentumPerMb'] is not None:\n        cfg['CNTK'].MOMENTUM_PER_MB = args['momentumPerMb']\n    if args['rndSeed'] is not None:\n        cfg.RND_SEED = args['rndSeed']\n    if args['trainConv'] is not None:\n        cfg.TRAIN_CONV_LAYERS = True if args['trainConv'] == 1 else False\n    if args['trainE2E'] is not None:\n        cfg.TRAIN_E2E = True if args['trainE2E'] == 1 else False\n    if args['datadir'] is not None:\n        cfg['DATA'].MAP_FILE_PATH = args['datadir']\n    if args['outputdir'] is not None:\n        cfg.OUTPUT_PATH = args['outputdir']\n    if args['logdir'] is not None:\n        log_dir = args['logdir']\n    if args['device'] is not None:\n        if Communicator.rank() == 0:\n            cntk.device.try_set_default_device(cntk.device.gpu(args['device']))\n        else:\n            cntk.device.try_set_default_device(cntk.device.cpu())",
            "def parse_arguments(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=cfg['DATA'].MAP_FILE_PATH)\n    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default=cfg['CNTK'].E2E_MAX_EPOCHS)\n    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default=cfg['CNTK'].MB_SIZE)\n    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default=cfg['CNTK'].NUM_TRAIN_IMAGES)\n    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n    parser.add_argument('-device', '--device', type=int, help='Force to run the script on a specified device', required=False, default=None)\n    parser.add_argument('-rpnLrFactor', '--rpnLrFactor', type=float, help='Scale factor for rpn lr schedule', required=False)\n    parser.add_argument('-frcnLrFactor', '--frcnLrFactor', type=float, help='Scale factor for frcn lr schedule', required=False)\n    parser.add_argument('-e2eLrFactor', '--e2eLrFactor', type=float, help='Scale factor for e2e lr schedule', required=False)\n    parser.add_argument('-momentumPerMb', '--momentumPerMb', type=float, help='momentum per minibatch', required=False)\n    parser.add_argument('-e2eEpochs', '--e2eEpochs', type=int, help='number of epochs for e2e training', required=False)\n    parser.add_argument('-rpnEpochs', '--rpnEpochs', type=int, help='number of epochs for rpn training', required=False)\n    parser.add_argument('-frcnEpochs', '--frcnEpochs', type=int, help='number of epochs for frcn training', required=False)\n    parser.add_argument('-rndSeed', '--rndSeed', type=int, help='the random seed', required=False)\n    parser.add_argument('-trainConv', '--trainConv', type=int, help='whether to train conv layers', required=False)\n    parser.add_argument('-trainE2E', '--trainE2E', type=int, help='whether to train e2e (otherwise 4 stage)', required=False)\n    args = vars(parser.parse_args())\n    if args['rpnLrFactor'] is not None:\n        cfg['MODEL'].RPN_LR_FACTOR = args['rpnLrFactor']\n    if args['frcnLrFactor'] is not None:\n        cfg['MODEL'].FRCN_LR_FACTOR = args['frcnLrFactor']\n    if args['e2eLrFactor'] is not None:\n        cfg['MODEL'].E2E_LR_FACTOR = args['e2eLrFactor']\n    if args['e2eEpochs'] is not None:\n        cfg['CNTK'].E2E_MAX_EPOCHS = args['e2eEpochs']\n    if args['rpnEpochs'] is not None:\n        cfg['CNTK'].RPN_EPOCHS = args['rpnEpochs']\n    if args['frcnEpochs'] is not None:\n        cfg['CNTK'].FRCN_EPOCHS = args['frcnEpochs']\n    if args['momentumPerMb'] is not None:\n        cfg['CNTK'].MOMENTUM_PER_MB = args['momentumPerMb']\n    if args['rndSeed'] is not None:\n        cfg.RND_SEED = args['rndSeed']\n    if args['trainConv'] is not None:\n        cfg.TRAIN_CONV_LAYERS = True if args['trainConv'] == 1 else False\n    if args['trainE2E'] is not None:\n        cfg.TRAIN_E2E = True if args['trainE2E'] == 1 else False\n    if args['datadir'] is not None:\n        cfg['DATA'].MAP_FILE_PATH = args['datadir']\n    if args['outputdir'] is not None:\n        cfg.OUTPUT_PATH = args['outputdir']\n    if args['logdir'] is not None:\n        log_dir = args['logdir']\n    if args['device'] is not None:\n        if Communicator.rank() == 0:\n            cntk.device.try_set_default_device(cntk.device.gpu(args['device']))\n        else:\n            cntk.device.try_set_default_device(cntk.device.cpu())",
            "def parse_arguments(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=cfg['DATA'].MAP_FILE_PATH)\n    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default=cfg['CNTK'].E2E_MAX_EPOCHS)\n    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default=cfg['CNTK'].MB_SIZE)\n    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default=cfg['CNTK'].NUM_TRAIN_IMAGES)\n    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n    parser.add_argument('-device', '--device', type=int, help='Force to run the script on a specified device', required=False, default=None)\n    parser.add_argument('-rpnLrFactor', '--rpnLrFactor', type=float, help='Scale factor for rpn lr schedule', required=False)\n    parser.add_argument('-frcnLrFactor', '--frcnLrFactor', type=float, help='Scale factor for frcn lr schedule', required=False)\n    parser.add_argument('-e2eLrFactor', '--e2eLrFactor', type=float, help='Scale factor for e2e lr schedule', required=False)\n    parser.add_argument('-momentumPerMb', '--momentumPerMb', type=float, help='momentum per minibatch', required=False)\n    parser.add_argument('-e2eEpochs', '--e2eEpochs', type=int, help='number of epochs for e2e training', required=False)\n    parser.add_argument('-rpnEpochs', '--rpnEpochs', type=int, help='number of epochs for rpn training', required=False)\n    parser.add_argument('-frcnEpochs', '--frcnEpochs', type=int, help='number of epochs for frcn training', required=False)\n    parser.add_argument('-rndSeed', '--rndSeed', type=int, help='the random seed', required=False)\n    parser.add_argument('-trainConv', '--trainConv', type=int, help='whether to train conv layers', required=False)\n    parser.add_argument('-trainE2E', '--trainE2E', type=int, help='whether to train e2e (otherwise 4 stage)', required=False)\n    args = vars(parser.parse_args())\n    if args['rpnLrFactor'] is not None:\n        cfg['MODEL'].RPN_LR_FACTOR = args['rpnLrFactor']\n    if args['frcnLrFactor'] is not None:\n        cfg['MODEL'].FRCN_LR_FACTOR = args['frcnLrFactor']\n    if args['e2eLrFactor'] is not None:\n        cfg['MODEL'].E2E_LR_FACTOR = args['e2eLrFactor']\n    if args['e2eEpochs'] is not None:\n        cfg['CNTK'].E2E_MAX_EPOCHS = args['e2eEpochs']\n    if args['rpnEpochs'] is not None:\n        cfg['CNTK'].RPN_EPOCHS = args['rpnEpochs']\n    if args['frcnEpochs'] is not None:\n        cfg['CNTK'].FRCN_EPOCHS = args['frcnEpochs']\n    if args['momentumPerMb'] is not None:\n        cfg['CNTK'].MOMENTUM_PER_MB = args['momentumPerMb']\n    if args['rndSeed'] is not None:\n        cfg.RND_SEED = args['rndSeed']\n    if args['trainConv'] is not None:\n        cfg.TRAIN_CONV_LAYERS = True if args['trainConv'] == 1 else False\n    if args['trainE2E'] is not None:\n        cfg.TRAIN_E2E = True if args['trainE2E'] == 1 else False\n    if args['datadir'] is not None:\n        cfg['DATA'].MAP_FILE_PATH = args['datadir']\n    if args['outputdir'] is not None:\n        cfg.OUTPUT_PATH = args['outputdir']\n    if args['logdir'] is not None:\n        log_dir = args['logdir']\n    if args['device'] is not None:\n        if Communicator.rank() == 0:\n            cntk.device.try_set_default_device(cntk.device.gpu(args['device']))\n        else:\n            cntk.device.try_set_default_device(cntk.device.cpu())",
            "def parse_arguments(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=cfg['DATA'].MAP_FILE_PATH)\n    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default=cfg['CNTK'].E2E_MAX_EPOCHS)\n    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default=cfg['CNTK'].MB_SIZE)\n    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default=cfg['CNTK'].NUM_TRAIN_IMAGES)\n    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n    parser.add_argument('-device', '--device', type=int, help='Force to run the script on a specified device', required=False, default=None)\n    parser.add_argument('-rpnLrFactor', '--rpnLrFactor', type=float, help='Scale factor for rpn lr schedule', required=False)\n    parser.add_argument('-frcnLrFactor', '--frcnLrFactor', type=float, help='Scale factor for frcn lr schedule', required=False)\n    parser.add_argument('-e2eLrFactor', '--e2eLrFactor', type=float, help='Scale factor for e2e lr schedule', required=False)\n    parser.add_argument('-momentumPerMb', '--momentumPerMb', type=float, help='momentum per minibatch', required=False)\n    parser.add_argument('-e2eEpochs', '--e2eEpochs', type=int, help='number of epochs for e2e training', required=False)\n    parser.add_argument('-rpnEpochs', '--rpnEpochs', type=int, help='number of epochs for rpn training', required=False)\n    parser.add_argument('-frcnEpochs', '--frcnEpochs', type=int, help='number of epochs for frcn training', required=False)\n    parser.add_argument('-rndSeed', '--rndSeed', type=int, help='the random seed', required=False)\n    parser.add_argument('-trainConv', '--trainConv', type=int, help='whether to train conv layers', required=False)\n    parser.add_argument('-trainE2E', '--trainE2E', type=int, help='whether to train e2e (otherwise 4 stage)', required=False)\n    args = vars(parser.parse_args())\n    if args['rpnLrFactor'] is not None:\n        cfg['MODEL'].RPN_LR_FACTOR = args['rpnLrFactor']\n    if args['frcnLrFactor'] is not None:\n        cfg['MODEL'].FRCN_LR_FACTOR = args['frcnLrFactor']\n    if args['e2eLrFactor'] is not None:\n        cfg['MODEL'].E2E_LR_FACTOR = args['e2eLrFactor']\n    if args['e2eEpochs'] is not None:\n        cfg['CNTK'].E2E_MAX_EPOCHS = args['e2eEpochs']\n    if args['rpnEpochs'] is not None:\n        cfg['CNTK'].RPN_EPOCHS = args['rpnEpochs']\n    if args['frcnEpochs'] is not None:\n        cfg['CNTK'].FRCN_EPOCHS = args['frcnEpochs']\n    if args['momentumPerMb'] is not None:\n        cfg['CNTK'].MOMENTUM_PER_MB = args['momentumPerMb']\n    if args['rndSeed'] is not None:\n        cfg.RND_SEED = args['rndSeed']\n    if args['trainConv'] is not None:\n        cfg.TRAIN_CONV_LAYERS = True if args['trainConv'] == 1 else False\n    if args['trainE2E'] is not None:\n        cfg.TRAIN_E2E = True if args['trainE2E'] == 1 else False\n    if args['datadir'] is not None:\n        cfg['DATA'].MAP_FILE_PATH = args['datadir']\n    if args['outputdir'] is not None:\n        cfg.OUTPUT_PATH = args['outputdir']\n    if args['logdir'] is not None:\n        log_dir = args['logdir']\n    if args['device'] is not None:\n        if Communicator.rank() == 0:\n            cntk.device.try_set_default_device(cntk.device.gpu(args['device']))\n        else:\n            cntk.device.try_set_default_device(cntk.device.cpu())",
            "def parse_arguments(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-datadir', '--datadir', help='Data directory where the ImageNet dataset is located', required=False, default=cfg['DATA'].MAP_FILE_PATH)\n    parser.add_argument('-outputdir', '--outputdir', help='Output directory for checkpoints and models', required=False, default=None)\n    parser.add_argument('-logdir', '--logdir', help='Log file', required=False, default=None)\n    parser.add_argument('-n', '--num_epochs', help='Total number of epochs to train', type=int, required=False, default=cfg['CNTK'].E2E_MAX_EPOCHS)\n    parser.add_argument('-m', '--minibatch_size', help='Minibatch size', type=int, required=False, default=cfg['CNTK'].MB_SIZE)\n    parser.add_argument('-e', '--epoch_size', help='Epoch size', type=int, required=False, default=cfg['CNTK'].NUM_TRAIN_IMAGES)\n    parser.add_argument('-q', '--quantized_bits', help='Number of quantized bits used for gradient aggregation', type=int, required=False, default='32')\n    parser.add_argument('-r', '--restart', help='Indicating whether to restart from scratch (instead of restart from checkpoint file by default)', action='store_true')\n    parser.add_argument('-device', '--device', type=int, help='Force to run the script on a specified device', required=False, default=None)\n    parser.add_argument('-rpnLrFactor', '--rpnLrFactor', type=float, help='Scale factor for rpn lr schedule', required=False)\n    parser.add_argument('-frcnLrFactor', '--frcnLrFactor', type=float, help='Scale factor for frcn lr schedule', required=False)\n    parser.add_argument('-e2eLrFactor', '--e2eLrFactor', type=float, help='Scale factor for e2e lr schedule', required=False)\n    parser.add_argument('-momentumPerMb', '--momentumPerMb', type=float, help='momentum per minibatch', required=False)\n    parser.add_argument('-e2eEpochs', '--e2eEpochs', type=int, help='number of epochs for e2e training', required=False)\n    parser.add_argument('-rpnEpochs', '--rpnEpochs', type=int, help='number of epochs for rpn training', required=False)\n    parser.add_argument('-frcnEpochs', '--frcnEpochs', type=int, help='number of epochs for frcn training', required=False)\n    parser.add_argument('-rndSeed', '--rndSeed', type=int, help='the random seed', required=False)\n    parser.add_argument('-trainConv', '--trainConv', type=int, help='whether to train conv layers', required=False)\n    parser.add_argument('-trainE2E', '--trainE2E', type=int, help='whether to train e2e (otherwise 4 stage)', required=False)\n    args = vars(parser.parse_args())\n    if args['rpnLrFactor'] is not None:\n        cfg['MODEL'].RPN_LR_FACTOR = args['rpnLrFactor']\n    if args['frcnLrFactor'] is not None:\n        cfg['MODEL'].FRCN_LR_FACTOR = args['frcnLrFactor']\n    if args['e2eLrFactor'] is not None:\n        cfg['MODEL'].E2E_LR_FACTOR = args['e2eLrFactor']\n    if args['e2eEpochs'] is not None:\n        cfg['CNTK'].E2E_MAX_EPOCHS = args['e2eEpochs']\n    if args['rpnEpochs'] is not None:\n        cfg['CNTK'].RPN_EPOCHS = args['rpnEpochs']\n    if args['frcnEpochs'] is not None:\n        cfg['CNTK'].FRCN_EPOCHS = args['frcnEpochs']\n    if args['momentumPerMb'] is not None:\n        cfg['CNTK'].MOMENTUM_PER_MB = args['momentumPerMb']\n    if args['rndSeed'] is not None:\n        cfg.RND_SEED = args['rndSeed']\n    if args['trainConv'] is not None:\n        cfg.TRAIN_CONV_LAYERS = True if args['trainConv'] == 1 else False\n    if args['trainE2E'] is not None:\n        cfg.TRAIN_E2E = True if args['trainE2E'] == 1 else False\n    if args['datadir'] is not None:\n        cfg['DATA'].MAP_FILE_PATH = args['datadir']\n    if args['outputdir'] is not None:\n        cfg.OUTPUT_PATH = args['outputdir']\n    if args['logdir'] is not None:\n        log_dir = args['logdir']\n    if args['device'] is not None:\n        if Communicator.rank() == 0:\n            cntk.device.try_set_default_device(cntk.device.gpu(args['device']))\n        else:\n            cntk.device.try_set_default_device(cntk.device.cpu())"
        ]
    },
    {
        "func_name": "create_faster_rcnn_model",
        "original": "def create_faster_rcnn_model(features, scaled_gt_boxes, dims_input, cfg):\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    conv_layers = clone_conv_layers(base_model, cfg)\n    fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], clone_method=CloneMethod.clone)\n    feat_norm = features - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    conv_out = conv_layers(feat_norm)\n    (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_input, cfg)\n    (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg)\n    (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n    detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n    loss = rpn_losses + detection_losses\n    pred_error = classification_error(cls_score, label_targets, axis=1)\n    return (loss, pred_error)",
        "mutated": [
            "def create_faster_rcnn_model(features, scaled_gt_boxes, dims_input, cfg):\n    if False:\n        i = 10\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    conv_layers = clone_conv_layers(base_model, cfg)\n    fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], clone_method=CloneMethod.clone)\n    feat_norm = features - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    conv_out = conv_layers(feat_norm)\n    (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_input, cfg)\n    (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg)\n    (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n    detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n    loss = rpn_losses + detection_losses\n    pred_error = classification_error(cls_score, label_targets, axis=1)\n    return (loss, pred_error)",
            "def create_faster_rcnn_model(features, scaled_gt_boxes, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    conv_layers = clone_conv_layers(base_model, cfg)\n    fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], clone_method=CloneMethod.clone)\n    feat_norm = features - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    conv_out = conv_layers(feat_norm)\n    (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_input, cfg)\n    (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg)\n    (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n    detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n    loss = rpn_losses + detection_losses\n    pred_error = classification_error(cls_score, label_targets, axis=1)\n    return (loss, pred_error)",
            "def create_faster_rcnn_model(features, scaled_gt_boxes, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    conv_layers = clone_conv_layers(base_model, cfg)\n    fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], clone_method=CloneMethod.clone)\n    feat_norm = features - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    conv_out = conv_layers(feat_norm)\n    (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_input, cfg)\n    (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg)\n    (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n    detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n    loss = rpn_losses + detection_losses\n    pred_error = classification_error(cls_score, label_targets, axis=1)\n    return (loss, pred_error)",
            "def create_faster_rcnn_model(features, scaled_gt_boxes, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    conv_layers = clone_conv_layers(base_model, cfg)\n    fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], clone_method=CloneMethod.clone)\n    feat_norm = features - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    conv_out = conv_layers(feat_norm)\n    (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_input, cfg)\n    (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg)\n    (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n    detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n    loss = rpn_losses + detection_losses\n    pred_error = classification_error(cls_score, label_targets, axis=1)\n    return (loss, pred_error)",
            "def create_faster_rcnn_model(features, scaled_gt_boxes, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    conv_layers = clone_conv_layers(base_model, cfg)\n    fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], clone_method=CloneMethod.clone)\n    feat_norm = features - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    conv_out = conv_layers(feat_norm)\n    (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_input, cfg)\n    (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg)\n    (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n    detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n    loss = rpn_losses + detection_losses\n    pred_error = classification_error(cls_score, label_targets, axis=1)\n    return (loss, pred_error)"
        ]
    },
    {
        "func_name": "create_faster_rcnn_eval_model",
        "original": "def create_faster_rcnn_eval_model(model, image_input, dims_input, cfg, rpn_model=None):\n    print('creating eval model')\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    conv_layers = clone_model(model, [cfg['MODEL'].FEATURE_NODE_NAME], [last_conv_node_name], CloneMethod.freeze)\n    conv_out = conv_layers(image_input)\n    model_with_rpn = model if rpn_model is None else rpn_model\n    rpn = clone_model(model_with_rpn, [last_conv_node_name], ['rpn_cls_prob_reshape', 'rpn_bbox_pred'], CloneMethod.freeze)\n    rpn_out = rpn(conv_out)\n    rpn_rois = create_proposal_layer(rpn_out.outputs[0], rpn_out.outputs[1], dims_input, cfg)\n    roi_fc_layers = clone_model(model, [last_conv_node_name, 'rpn_target_rois'], ['cls_score', 'bbox_regr'], CloneMethod.freeze)\n    pred_net = roi_fc_layers(conv_out, rpn_rois)\n    cls_score = pred_net.outputs[0]\n    bbox_regr = pred_net.outputs[1]\n    if cfg.BBOX_NORMALIZE_TARGETS:\n        num_boxes = int(bbox_regr.shape[1] / 4)\n        bbox_normalize_means = np.array(cfg.BBOX_NORMALIZE_MEANS * num_boxes)\n        bbox_normalize_stds = np.array(cfg.BBOX_NORMALIZE_STDS * num_boxes)\n        bbox_regr = plus(element_times(bbox_regr, bbox_normalize_stds), bbox_normalize_means, name='bbox_regr')\n    cls_pred = softmax(cls_score, axis=1, name='cls_pred')\n    eval_model = combine([cls_pred, rpn_rois, bbox_regr])\n    return eval_model",
        "mutated": [
            "def create_faster_rcnn_eval_model(model, image_input, dims_input, cfg, rpn_model=None):\n    if False:\n        i = 10\n    print('creating eval model')\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    conv_layers = clone_model(model, [cfg['MODEL'].FEATURE_NODE_NAME], [last_conv_node_name], CloneMethod.freeze)\n    conv_out = conv_layers(image_input)\n    model_with_rpn = model if rpn_model is None else rpn_model\n    rpn = clone_model(model_with_rpn, [last_conv_node_name], ['rpn_cls_prob_reshape', 'rpn_bbox_pred'], CloneMethod.freeze)\n    rpn_out = rpn(conv_out)\n    rpn_rois = create_proposal_layer(rpn_out.outputs[0], rpn_out.outputs[1], dims_input, cfg)\n    roi_fc_layers = clone_model(model, [last_conv_node_name, 'rpn_target_rois'], ['cls_score', 'bbox_regr'], CloneMethod.freeze)\n    pred_net = roi_fc_layers(conv_out, rpn_rois)\n    cls_score = pred_net.outputs[0]\n    bbox_regr = pred_net.outputs[1]\n    if cfg.BBOX_NORMALIZE_TARGETS:\n        num_boxes = int(bbox_regr.shape[1] / 4)\n        bbox_normalize_means = np.array(cfg.BBOX_NORMALIZE_MEANS * num_boxes)\n        bbox_normalize_stds = np.array(cfg.BBOX_NORMALIZE_STDS * num_boxes)\n        bbox_regr = plus(element_times(bbox_regr, bbox_normalize_stds), bbox_normalize_means, name='bbox_regr')\n    cls_pred = softmax(cls_score, axis=1, name='cls_pred')\n    eval_model = combine([cls_pred, rpn_rois, bbox_regr])\n    return eval_model",
            "def create_faster_rcnn_eval_model(model, image_input, dims_input, cfg, rpn_model=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    print('creating eval model')\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    conv_layers = clone_model(model, [cfg['MODEL'].FEATURE_NODE_NAME], [last_conv_node_name], CloneMethod.freeze)\n    conv_out = conv_layers(image_input)\n    model_with_rpn = model if rpn_model is None else rpn_model\n    rpn = clone_model(model_with_rpn, [last_conv_node_name], ['rpn_cls_prob_reshape', 'rpn_bbox_pred'], CloneMethod.freeze)\n    rpn_out = rpn(conv_out)\n    rpn_rois = create_proposal_layer(rpn_out.outputs[0], rpn_out.outputs[1], dims_input, cfg)\n    roi_fc_layers = clone_model(model, [last_conv_node_name, 'rpn_target_rois'], ['cls_score', 'bbox_regr'], CloneMethod.freeze)\n    pred_net = roi_fc_layers(conv_out, rpn_rois)\n    cls_score = pred_net.outputs[0]\n    bbox_regr = pred_net.outputs[1]\n    if cfg.BBOX_NORMALIZE_TARGETS:\n        num_boxes = int(bbox_regr.shape[1] / 4)\n        bbox_normalize_means = np.array(cfg.BBOX_NORMALIZE_MEANS * num_boxes)\n        bbox_normalize_stds = np.array(cfg.BBOX_NORMALIZE_STDS * num_boxes)\n        bbox_regr = plus(element_times(bbox_regr, bbox_normalize_stds), bbox_normalize_means, name='bbox_regr')\n    cls_pred = softmax(cls_score, axis=1, name='cls_pred')\n    eval_model = combine([cls_pred, rpn_rois, bbox_regr])\n    return eval_model",
            "def create_faster_rcnn_eval_model(model, image_input, dims_input, cfg, rpn_model=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    print('creating eval model')\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    conv_layers = clone_model(model, [cfg['MODEL'].FEATURE_NODE_NAME], [last_conv_node_name], CloneMethod.freeze)\n    conv_out = conv_layers(image_input)\n    model_with_rpn = model if rpn_model is None else rpn_model\n    rpn = clone_model(model_with_rpn, [last_conv_node_name], ['rpn_cls_prob_reshape', 'rpn_bbox_pred'], CloneMethod.freeze)\n    rpn_out = rpn(conv_out)\n    rpn_rois = create_proposal_layer(rpn_out.outputs[0], rpn_out.outputs[1], dims_input, cfg)\n    roi_fc_layers = clone_model(model, [last_conv_node_name, 'rpn_target_rois'], ['cls_score', 'bbox_regr'], CloneMethod.freeze)\n    pred_net = roi_fc_layers(conv_out, rpn_rois)\n    cls_score = pred_net.outputs[0]\n    bbox_regr = pred_net.outputs[1]\n    if cfg.BBOX_NORMALIZE_TARGETS:\n        num_boxes = int(bbox_regr.shape[1] / 4)\n        bbox_normalize_means = np.array(cfg.BBOX_NORMALIZE_MEANS * num_boxes)\n        bbox_normalize_stds = np.array(cfg.BBOX_NORMALIZE_STDS * num_boxes)\n        bbox_regr = plus(element_times(bbox_regr, bbox_normalize_stds), bbox_normalize_means, name='bbox_regr')\n    cls_pred = softmax(cls_score, axis=1, name='cls_pred')\n    eval_model = combine([cls_pred, rpn_rois, bbox_regr])\n    return eval_model",
            "def create_faster_rcnn_eval_model(model, image_input, dims_input, cfg, rpn_model=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    print('creating eval model')\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    conv_layers = clone_model(model, [cfg['MODEL'].FEATURE_NODE_NAME], [last_conv_node_name], CloneMethod.freeze)\n    conv_out = conv_layers(image_input)\n    model_with_rpn = model if rpn_model is None else rpn_model\n    rpn = clone_model(model_with_rpn, [last_conv_node_name], ['rpn_cls_prob_reshape', 'rpn_bbox_pred'], CloneMethod.freeze)\n    rpn_out = rpn(conv_out)\n    rpn_rois = create_proposal_layer(rpn_out.outputs[0], rpn_out.outputs[1], dims_input, cfg)\n    roi_fc_layers = clone_model(model, [last_conv_node_name, 'rpn_target_rois'], ['cls_score', 'bbox_regr'], CloneMethod.freeze)\n    pred_net = roi_fc_layers(conv_out, rpn_rois)\n    cls_score = pred_net.outputs[0]\n    bbox_regr = pred_net.outputs[1]\n    if cfg.BBOX_NORMALIZE_TARGETS:\n        num_boxes = int(bbox_regr.shape[1] / 4)\n        bbox_normalize_means = np.array(cfg.BBOX_NORMALIZE_MEANS * num_boxes)\n        bbox_normalize_stds = np.array(cfg.BBOX_NORMALIZE_STDS * num_boxes)\n        bbox_regr = plus(element_times(bbox_regr, bbox_normalize_stds), bbox_normalize_means, name='bbox_regr')\n    cls_pred = softmax(cls_score, axis=1, name='cls_pred')\n    eval_model = combine([cls_pred, rpn_rois, bbox_regr])\n    return eval_model",
            "def create_faster_rcnn_eval_model(model, image_input, dims_input, cfg, rpn_model=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    print('creating eval model')\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    conv_layers = clone_model(model, [cfg['MODEL'].FEATURE_NODE_NAME], [last_conv_node_name], CloneMethod.freeze)\n    conv_out = conv_layers(image_input)\n    model_with_rpn = model if rpn_model is None else rpn_model\n    rpn = clone_model(model_with_rpn, [last_conv_node_name], ['rpn_cls_prob_reshape', 'rpn_bbox_pred'], CloneMethod.freeze)\n    rpn_out = rpn(conv_out)\n    rpn_rois = create_proposal_layer(rpn_out.outputs[0], rpn_out.outputs[1], dims_input, cfg)\n    roi_fc_layers = clone_model(model, [last_conv_node_name, 'rpn_target_rois'], ['cls_score', 'bbox_regr'], CloneMethod.freeze)\n    pred_net = roi_fc_layers(conv_out, rpn_rois)\n    cls_score = pred_net.outputs[0]\n    bbox_regr = pred_net.outputs[1]\n    if cfg.BBOX_NORMALIZE_TARGETS:\n        num_boxes = int(bbox_regr.shape[1] / 4)\n        bbox_normalize_means = np.array(cfg.BBOX_NORMALIZE_MEANS * num_boxes)\n        bbox_normalize_stds = np.array(cfg.BBOX_NORMALIZE_STDS * num_boxes)\n        bbox_regr = plus(element_times(bbox_regr, bbox_normalize_stds), bbox_normalize_means, name='bbox_regr')\n    cls_pred = softmax(cls_score, axis=1, name='cls_pred')\n    eval_model = combine([cls_pred, rpn_rois, bbox_regr])\n    return eval_model"
        ]
    },
    {
        "func_name": "filter",
        "original": "def filter(x):\n    return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')",
        "mutated": [
            "def filter(x):\n    if False:\n        i = 10\n    return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')",
            "def filter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')",
            "def filter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')",
            "def filter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')",
            "def filter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')"
        ]
    },
    {
        "func_name": "converter",
        "original": "def converter(x):\n    layer_config = copy.deepcopy(x.attributes)\n    return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')",
        "mutated": [
            "def converter(x):\n    if False:\n        i = 10\n    layer_config = copy.deepcopy(x.attributes)\n    return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')",
            "def converter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    layer_config = copy.deepcopy(x.attributes)\n    return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')",
            "def converter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    layer_config = copy.deepcopy(x.attributes)\n    return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')",
            "def converter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    layer_config = copy.deepcopy(x.attributes)\n    return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')",
            "def converter(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    layer_config = copy.deepcopy(x.attributes)\n    return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')"
        ]
    },
    {
        "func_name": "store_eval_model_with_native_udf",
        "original": "def store_eval_model_with_native_udf(eval_model, cfg):\n    import copy\n    sys.path.append(os.path.join(abs_path, '..', '..', 'Extensibility', 'ProposalLayer'))\n    cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n\n    def filter(x):\n        return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')\n\n    def converter(x):\n        layer_config = copy.deepcopy(x.attributes)\n        return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')\n    model_w_native_udf = cntk.misc.convert(eval_model, filter, converter)\n    model_path = cfg['MODEL_PATH']\n    new_model_path = model_path[:-6] + '_native.model'\n    model_w_native_udf.save(new_model_path)\n    print('Stored eval model with native UDF to {}'.format(new_model_path))",
        "mutated": [
            "def store_eval_model_with_native_udf(eval_model, cfg):\n    if False:\n        i = 10\n    import copy\n    sys.path.append(os.path.join(abs_path, '..', '..', 'Extensibility', 'ProposalLayer'))\n    cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n\n    def filter(x):\n        return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')\n\n    def converter(x):\n        layer_config = copy.deepcopy(x.attributes)\n        return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')\n    model_w_native_udf = cntk.misc.convert(eval_model, filter, converter)\n    model_path = cfg['MODEL_PATH']\n    new_model_path = model_path[:-6] + '_native.model'\n    model_w_native_udf.save(new_model_path)\n    print('Stored eval model with native UDF to {}'.format(new_model_path))",
            "def store_eval_model_with_native_udf(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import copy\n    sys.path.append(os.path.join(abs_path, '..', '..', 'Extensibility', 'ProposalLayer'))\n    cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n\n    def filter(x):\n        return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')\n\n    def converter(x):\n        layer_config = copy.deepcopy(x.attributes)\n        return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')\n    model_w_native_udf = cntk.misc.convert(eval_model, filter, converter)\n    model_path = cfg['MODEL_PATH']\n    new_model_path = model_path[:-6] + '_native.model'\n    model_w_native_udf.save(new_model_path)\n    print('Stored eval model with native UDF to {}'.format(new_model_path))",
            "def store_eval_model_with_native_udf(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import copy\n    sys.path.append(os.path.join(abs_path, '..', '..', 'Extensibility', 'ProposalLayer'))\n    cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n\n    def filter(x):\n        return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')\n\n    def converter(x):\n        layer_config = copy.deepcopy(x.attributes)\n        return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')\n    model_w_native_udf = cntk.misc.convert(eval_model, filter, converter)\n    model_path = cfg['MODEL_PATH']\n    new_model_path = model_path[:-6] + '_native.model'\n    model_w_native_udf.save(new_model_path)\n    print('Stored eval model with native UDF to {}'.format(new_model_path))",
            "def store_eval_model_with_native_udf(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import copy\n    sys.path.append(os.path.join(abs_path, '..', '..', 'Extensibility', 'ProposalLayer'))\n    cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n\n    def filter(x):\n        return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')\n\n    def converter(x):\n        layer_config = copy.deepcopy(x.attributes)\n        return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')\n    model_w_native_udf = cntk.misc.convert(eval_model, filter, converter)\n    model_path = cfg['MODEL_PATH']\n    new_model_path = model_path[:-6] + '_native.model'\n    model_w_native_udf.save(new_model_path)\n    print('Stored eval model with native UDF to {}'.format(new_model_path))",
            "def store_eval_model_with_native_udf(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import copy\n    sys.path.append(os.path.join(abs_path, '..', '..', 'Extensibility', 'ProposalLayer'))\n    cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n\n    def filter(x):\n        return type(x) == cntk.Function and x.op_name == 'UserFunction' and (x.name == 'ProposalLayer')\n\n    def converter(x):\n        layer_config = copy.deepcopy(x.attributes)\n        return cntk.ops.native_user_function('ProposalLayerOp', list(x.inputs), layer_config, 'native_proposal_layer')\n    model_w_native_udf = cntk.misc.convert(eval_model, filter, converter)\n    model_path = cfg['MODEL_PATH']\n    new_model_path = model_path[:-6] + '_native.model'\n    model_w_native_udf.save(new_model_path)\n    print('Stored eval model with native UDF to {}'.format(new_model_path))"
        ]
    },
    {
        "func_name": "compute_rpn_proposals",
        "original": "def compute_rpn_proposals(rpn_model, image_input, roi_input, dims_input, cfg):\n    num_images = cfg['DATA'].NUM_TRAIN_IMAGES\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, max_images=num_images, randomize=False, use_flipping=False, proposal_provider=None)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input, od_minibatch_source.dims_si: dims_input}\n    buffered_proposals = [None for _ in range(num_images)]\n    sample_count = 0\n    while sample_count < num_images:\n        data = od_minibatch_source.next_minibatch(1, input_map=input_map)\n        output = rpn_model.eval(data)\n        out_dict = dict([(k.name, k) for k in output])\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        buffered_proposals[sample_count] = np.round(out_rpn_rois).astype(np.int16)\n        sample_count += 1\n        if sample_count % 500 == 0:\n            print('Buffered proposals for {} samples'.format(sample_count))\n    return buffered_proposals",
        "mutated": [
            "def compute_rpn_proposals(rpn_model, image_input, roi_input, dims_input, cfg):\n    if False:\n        i = 10\n    num_images = cfg['DATA'].NUM_TRAIN_IMAGES\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, max_images=num_images, randomize=False, use_flipping=False, proposal_provider=None)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input, od_minibatch_source.dims_si: dims_input}\n    buffered_proposals = [None for _ in range(num_images)]\n    sample_count = 0\n    while sample_count < num_images:\n        data = od_minibatch_source.next_minibatch(1, input_map=input_map)\n        output = rpn_model.eval(data)\n        out_dict = dict([(k.name, k) for k in output])\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        buffered_proposals[sample_count] = np.round(out_rpn_rois).astype(np.int16)\n        sample_count += 1\n        if sample_count % 500 == 0:\n            print('Buffered proposals for {} samples'.format(sample_count))\n    return buffered_proposals",
            "def compute_rpn_proposals(rpn_model, image_input, roi_input, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    num_images = cfg['DATA'].NUM_TRAIN_IMAGES\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, max_images=num_images, randomize=False, use_flipping=False, proposal_provider=None)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input, od_minibatch_source.dims_si: dims_input}\n    buffered_proposals = [None for _ in range(num_images)]\n    sample_count = 0\n    while sample_count < num_images:\n        data = od_minibatch_source.next_minibatch(1, input_map=input_map)\n        output = rpn_model.eval(data)\n        out_dict = dict([(k.name, k) for k in output])\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        buffered_proposals[sample_count] = np.round(out_rpn_rois).astype(np.int16)\n        sample_count += 1\n        if sample_count % 500 == 0:\n            print('Buffered proposals for {} samples'.format(sample_count))\n    return buffered_proposals",
            "def compute_rpn_proposals(rpn_model, image_input, roi_input, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    num_images = cfg['DATA'].NUM_TRAIN_IMAGES\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, max_images=num_images, randomize=False, use_flipping=False, proposal_provider=None)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input, od_minibatch_source.dims_si: dims_input}\n    buffered_proposals = [None for _ in range(num_images)]\n    sample_count = 0\n    while sample_count < num_images:\n        data = od_minibatch_source.next_minibatch(1, input_map=input_map)\n        output = rpn_model.eval(data)\n        out_dict = dict([(k.name, k) for k in output])\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        buffered_proposals[sample_count] = np.round(out_rpn_rois).astype(np.int16)\n        sample_count += 1\n        if sample_count % 500 == 0:\n            print('Buffered proposals for {} samples'.format(sample_count))\n    return buffered_proposals",
            "def compute_rpn_proposals(rpn_model, image_input, roi_input, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    num_images = cfg['DATA'].NUM_TRAIN_IMAGES\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, max_images=num_images, randomize=False, use_flipping=False, proposal_provider=None)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input, od_minibatch_source.dims_si: dims_input}\n    buffered_proposals = [None for _ in range(num_images)]\n    sample_count = 0\n    while sample_count < num_images:\n        data = od_minibatch_source.next_minibatch(1, input_map=input_map)\n        output = rpn_model.eval(data)\n        out_dict = dict([(k.name, k) for k in output])\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        buffered_proposals[sample_count] = np.round(out_rpn_rois).astype(np.int16)\n        sample_count += 1\n        if sample_count % 500 == 0:\n            print('Buffered proposals for {} samples'.format(sample_count))\n    return buffered_proposals",
            "def compute_rpn_proposals(rpn_model, image_input, roi_input, dims_input, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    num_images = cfg['DATA'].NUM_TRAIN_IMAGES\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, max_images=num_images, randomize=False, use_flipping=False, proposal_provider=None)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input, od_minibatch_source.dims_si: dims_input}\n    buffered_proposals = [None for _ in range(num_images)]\n    sample_count = 0\n    while sample_count < num_images:\n        data = od_minibatch_source.next_minibatch(1, input_map=input_map)\n        output = rpn_model.eval(data)\n        out_dict = dict([(k.name, k) for k in output])\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        buffered_proposals[sample_count] = np.round(out_rpn_rois).astype(np.int16)\n        sample_count += 1\n        if sample_count % 500 == 0:\n            print('Buffered proposals for {} samples'.format(sample_count))\n    return buffered_proposals"
        ]
    },
    {
        "func_name": "train_faster_rcnn",
        "original": "def train_faster_rcnn(cfg):\n    model_path = cfg['MODEL_PATH']\n    if os.path.exists(model_path) and cfg['CNTK'].MAKE_MODE:\n        print('Loading existing model from %s' % model_path)\n        eval_model = load_model(model_path)\n    else:\n        if cfg['CNTK'].TRAIN_E2E:\n            eval_model = train_faster_rcnn_e2e(cfg)\n        else:\n            eval_model = train_faster_rcnn_alternating(cfg)\n        eval_model.save(model_path)\n        if cfg['CNTK'].DEBUG_OUTPUT:\n            plot(eval_model, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_eval_{}_{}.{}'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage', cfg['CNTK'].GRAPH_TYPE)))\n        print('Stored eval model at %s' % model_path)\n    return eval_model",
        "mutated": [
            "def train_faster_rcnn(cfg):\n    if False:\n        i = 10\n    model_path = cfg['MODEL_PATH']\n    if os.path.exists(model_path) and cfg['CNTK'].MAKE_MODE:\n        print('Loading existing model from %s' % model_path)\n        eval_model = load_model(model_path)\n    else:\n        if cfg['CNTK'].TRAIN_E2E:\n            eval_model = train_faster_rcnn_e2e(cfg)\n        else:\n            eval_model = train_faster_rcnn_alternating(cfg)\n        eval_model.save(model_path)\n        if cfg['CNTK'].DEBUG_OUTPUT:\n            plot(eval_model, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_eval_{}_{}.{}'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage', cfg['CNTK'].GRAPH_TYPE)))\n        print('Stored eval model at %s' % model_path)\n    return eval_model",
            "def train_faster_rcnn(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    model_path = cfg['MODEL_PATH']\n    if os.path.exists(model_path) and cfg['CNTK'].MAKE_MODE:\n        print('Loading existing model from %s' % model_path)\n        eval_model = load_model(model_path)\n    else:\n        if cfg['CNTK'].TRAIN_E2E:\n            eval_model = train_faster_rcnn_e2e(cfg)\n        else:\n            eval_model = train_faster_rcnn_alternating(cfg)\n        eval_model.save(model_path)\n        if cfg['CNTK'].DEBUG_OUTPUT:\n            plot(eval_model, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_eval_{}_{}.{}'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage', cfg['CNTK'].GRAPH_TYPE)))\n        print('Stored eval model at %s' % model_path)\n    return eval_model",
            "def train_faster_rcnn(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    model_path = cfg['MODEL_PATH']\n    if os.path.exists(model_path) and cfg['CNTK'].MAKE_MODE:\n        print('Loading existing model from %s' % model_path)\n        eval_model = load_model(model_path)\n    else:\n        if cfg['CNTK'].TRAIN_E2E:\n            eval_model = train_faster_rcnn_e2e(cfg)\n        else:\n            eval_model = train_faster_rcnn_alternating(cfg)\n        eval_model.save(model_path)\n        if cfg['CNTK'].DEBUG_OUTPUT:\n            plot(eval_model, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_eval_{}_{}.{}'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage', cfg['CNTK'].GRAPH_TYPE)))\n        print('Stored eval model at %s' % model_path)\n    return eval_model",
            "def train_faster_rcnn(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    model_path = cfg['MODEL_PATH']\n    if os.path.exists(model_path) and cfg['CNTK'].MAKE_MODE:\n        print('Loading existing model from %s' % model_path)\n        eval_model = load_model(model_path)\n    else:\n        if cfg['CNTK'].TRAIN_E2E:\n            eval_model = train_faster_rcnn_e2e(cfg)\n        else:\n            eval_model = train_faster_rcnn_alternating(cfg)\n        eval_model.save(model_path)\n        if cfg['CNTK'].DEBUG_OUTPUT:\n            plot(eval_model, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_eval_{}_{}.{}'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage', cfg['CNTK'].GRAPH_TYPE)))\n        print('Stored eval model at %s' % model_path)\n    return eval_model",
            "def train_faster_rcnn(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    model_path = cfg['MODEL_PATH']\n    if os.path.exists(model_path) and cfg['CNTK'].MAKE_MODE:\n        print('Loading existing model from %s' % model_path)\n        eval_model = load_model(model_path)\n    else:\n        if cfg['CNTK'].TRAIN_E2E:\n            eval_model = train_faster_rcnn_e2e(cfg)\n        else:\n            eval_model = train_faster_rcnn_alternating(cfg)\n        eval_model.save(model_path)\n        if cfg['CNTK'].DEBUG_OUTPUT:\n            plot(eval_model, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_eval_{}_{}.{}'.format(cfg['MODEL'].BASE_MODEL, 'e2e' if cfg['CNTK'].TRAIN_E2E else '4stage', cfg['CNTK'].GRAPH_TYPE)))\n        print('Stored eval model at %s' % model_path)\n    return eval_model"
        ]
    },
    {
        "func_name": "train_faster_rcnn_e2e",
        "original": "def train_faster_rcnn_e2e(cfg):\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    (loss, pred_error) = create_faster_rcnn_model(image_input, roi_input, dims_node, cfg)\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n        plot(loss, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_e2e.' + cfg['CNTK'].GRAPH_TYPE))\n    e2e_lr_factor = cfg['MODEL'].E2E_LR_FACTOR\n    e2e_lr_per_sample_scaled = [x * e2e_lr_factor for x in cfg['CNTK'].E2E_LR_PER_SAMPLE]\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('lr_per_sample:      {}'.format(e2e_lr_per_sample_scaled))\n    train_model(image_input, roi_input, dims_input, loss, pred_error, e2e_lr_per_sample_scaled, mm_schedule, cfg['CNTK'].L2_REG_WEIGHT, cfg['CNTK'].E2E_MAX_EPOCHS, cfg)\n    return create_faster_rcnn_eval_model(loss, image_input, dims_input, cfg)",
        "mutated": [
            "def train_faster_rcnn_e2e(cfg):\n    if False:\n        i = 10\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    (loss, pred_error) = create_faster_rcnn_model(image_input, roi_input, dims_node, cfg)\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n        plot(loss, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_e2e.' + cfg['CNTK'].GRAPH_TYPE))\n    e2e_lr_factor = cfg['MODEL'].E2E_LR_FACTOR\n    e2e_lr_per_sample_scaled = [x * e2e_lr_factor for x in cfg['CNTK'].E2E_LR_PER_SAMPLE]\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('lr_per_sample:      {}'.format(e2e_lr_per_sample_scaled))\n    train_model(image_input, roi_input, dims_input, loss, pred_error, e2e_lr_per_sample_scaled, mm_schedule, cfg['CNTK'].L2_REG_WEIGHT, cfg['CNTK'].E2E_MAX_EPOCHS, cfg)\n    return create_faster_rcnn_eval_model(loss, image_input, dims_input, cfg)",
            "def train_faster_rcnn_e2e(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    (loss, pred_error) = create_faster_rcnn_model(image_input, roi_input, dims_node, cfg)\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n        plot(loss, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_e2e.' + cfg['CNTK'].GRAPH_TYPE))\n    e2e_lr_factor = cfg['MODEL'].E2E_LR_FACTOR\n    e2e_lr_per_sample_scaled = [x * e2e_lr_factor for x in cfg['CNTK'].E2E_LR_PER_SAMPLE]\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('lr_per_sample:      {}'.format(e2e_lr_per_sample_scaled))\n    train_model(image_input, roi_input, dims_input, loss, pred_error, e2e_lr_per_sample_scaled, mm_schedule, cfg['CNTK'].L2_REG_WEIGHT, cfg['CNTK'].E2E_MAX_EPOCHS, cfg)\n    return create_faster_rcnn_eval_model(loss, image_input, dims_input, cfg)",
            "def train_faster_rcnn_e2e(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    (loss, pred_error) = create_faster_rcnn_model(image_input, roi_input, dims_node, cfg)\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n        plot(loss, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_e2e.' + cfg['CNTK'].GRAPH_TYPE))\n    e2e_lr_factor = cfg['MODEL'].E2E_LR_FACTOR\n    e2e_lr_per_sample_scaled = [x * e2e_lr_factor for x in cfg['CNTK'].E2E_LR_PER_SAMPLE]\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('lr_per_sample:      {}'.format(e2e_lr_per_sample_scaled))\n    train_model(image_input, roi_input, dims_input, loss, pred_error, e2e_lr_per_sample_scaled, mm_schedule, cfg['CNTK'].L2_REG_WEIGHT, cfg['CNTK'].E2E_MAX_EPOCHS, cfg)\n    return create_faster_rcnn_eval_model(loss, image_input, dims_input, cfg)",
            "def train_faster_rcnn_e2e(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    (loss, pred_error) = create_faster_rcnn_model(image_input, roi_input, dims_node, cfg)\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n        plot(loss, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_e2e.' + cfg['CNTK'].GRAPH_TYPE))\n    e2e_lr_factor = cfg['MODEL'].E2E_LR_FACTOR\n    e2e_lr_per_sample_scaled = [x * e2e_lr_factor for x in cfg['CNTK'].E2E_LR_PER_SAMPLE]\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('lr_per_sample:      {}'.format(e2e_lr_per_sample_scaled))\n    train_model(image_input, roi_input, dims_input, loss, pred_error, e2e_lr_per_sample_scaled, mm_schedule, cfg['CNTK'].L2_REG_WEIGHT, cfg['CNTK'].E2E_MAX_EPOCHS, cfg)\n    return create_faster_rcnn_eval_model(loss, image_input, dims_input, cfg)",
            "def train_faster_rcnn_e2e(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    (loss, pred_error) = create_faster_rcnn_model(image_input, roi_input, dims_node, cfg)\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n        plot(loss, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_e2e.' + cfg['CNTK'].GRAPH_TYPE))\n    e2e_lr_factor = cfg['MODEL'].E2E_LR_FACTOR\n    e2e_lr_per_sample_scaled = [x * e2e_lr_factor for x in cfg['CNTK'].E2E_LR_PER_SAMPLE]\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('lr_per_sample:      {}'.format(e2e_lr_per_sample_scaled))\n    train_model(image_input, roi_input, dims_input, loss, pred_error, e2e_lr_per_sample_scaled, mm_schedule, cfg['CNTK'].L2_REG_WEIGHT, cfg['CNTK'].E2E_MAX_EPOCHS, cfg)\n    return create_faster_rcnn_eval_model(loss, image_input, dims_input, cfg)"
        ]
    },
    {
        "func_name": "train_faster_rcnn_alternating",
        "original": "def train_faster_rcnn_alternating(cfg):\n    \"\"\"\n        4-Step Alternating Training scheme from the Faster R-CNN paper:\n        \n        # Create initial network, only rpn, without detection network\n            # --> train only the rpn (and conv3_1 and up for VGG16)\n        # buffer region proposals from rpn\n        # Create full network, initialize conv layers with imagenet, use buffered proposals\n            # --> train only detection network (and conv3_1 and up for VGG16)\n        # Keep conv weights from detection network and fix them\n            # --> train only rpn\n        # buffer region proposals from rpn\n        # Keep conv and rpn weights from step 3 and fix them\n            # --> train only detection network\n    \"\"\"\n    test_pre = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    test_post = cfg['TEST'].RPN_POST_NMS_TOP_N\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    cfg['TEST'].RPN_POST_NMS_TOP_N = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    rpn_lr_factor = cfg['MODEL'].RPN_LR_FACTOR\n    rpn_lr_per_sample_scaled = [x * rpn_lr_factor for x in cfg['CNTK'].RPN_LR_PER_SAMPLE]\n    frcn_lr_factor = cfg['MODEL'].FRCN_LR_FACTOR\n    frcn_lr_per_sample_scaled = [x * frcn_lr_factor for x in cfg['CNTK'].FRCN_LR_PER_SAMPLE]\n    l2_reg_weight = cfg['CNTK'].L2_REG_WEIGHT\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    rpn_epochs = cfg['CNTK'].RPN_EPOCHS\n    frcn_epochs = cfg['CNTK'].FRCN_EPOCHS\n    feature_node_name = cfg['MODEL'].FEATURE_NODE_NAME\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('rpn_lr_per_sample:  {}'.format(rpn_lr_per_sample_scaled))\n    print('frcn_lr_per_sample: {}'.format(frcn_lr_per_sample_scaled))\n    debug_output = cfg['CNTK'].DEBUG_OUTPUT\n    if debug_output:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=feature_node_name)\n    feat_norm = image_input - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    scaled_gt_boxes = alias(roi_input, name='roi_input')\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    rpn_rois_input = input_variable((cfg['TRAIN'].RPN_POST_NMS_TOP_N, 4), dynamic_axes=[Axis.default_batch_axis()])\n    rpn_rois_buf = alias(rpn_rois_input, name='rpn_rois')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    print('stage 1a - rpn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_node, cfg)\n        stage1_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage1_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 1a - buffering rpn proposals')\n    buffered_proposals_s1 = compute_rpn_proposals(stage1_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 1b - frcn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois_buf, scaled_gt_boxes, cfg)\n        fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], CloneMethod.clone)\n        (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n        detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n        pred_error = classification_error(cls_score, label_targets, axis=1, name='pred_error')\n        stage1_frcn_network = combine([rois, cls_score, bbox_pred, detection_losses, pred_error])\n        if debug_output:\n            plot(stage1_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s1)\n        buffered_proposals_s1 = None\n    print('stage 2a - rpn')\n    if True:\n        conv_layers = clone_model(stage1_frcn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        rpn = clone_model(stage1_rpn_network, [last_conv_node_name, 'roi_input', 'dims_input'], ['rpn_rois', 'rpn_losses'], CloneMethod.clone)\n        rpn_net = rpn(conv_out, dims_node, scaled_gt_boxes)\n        rpn_rois = rpn_net.outputs[0]\n        rpn_losses = rpn_net.outputs[1]\n        stage2_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage2_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 2a - buffering rpn proposals')\n    buffered_proposals_s2 = compute_rpn_proposals(stage2_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 2b - frcn')\n    if True:\n        conv_layers = clone_model(stage2_rpn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        frcn = clone_model(stage1_frcn_network, [last_conv_node_name, 'rpn_rois', 'roi_input'], ['cls_score', 'bbox_regr', 'rpn_target_rois', 'detection_losses', 'pred_error'], CloneMethod.clone)\n        stage2_frcn_network = frcn(conv_out, rpn_rois_buf, scaled_gt_boxes)\n        detection_losses = stage2_frcn_network.outputs[3]\n        pred_error = stage2_frcn_network.outputs[4]\n        if debug_output:\n            plot(stage2_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s2)\n        buffered_proposals_s2 = None\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = test_pre\n    cfg['TEST'].RPN_POST_NMS_TOP_N = test_post\n    return create_faster_rcnn_eval_model(stage2_frcn_network, image_input, dims_input, cfg, rpn_model=stage2_rpn_network)",
        "mutated": [
            "def train_faster_rcnn_alternating(cfg):\n    if False:\n        i = 10\n    '\\n        4-Step Alternating Training scheme from the Faster R-CNN paper:\\n        \\n        # Create initial network, only rpn, without detection network\\n            # --> train only the rpn (and conv3_1 and up for VGG16)\\n        # buffer region proposals from rpn\\n        # Create full network, initialize conv layers with imagenet, use buffered proposals\\n            # --> train only detection network (and conv3_1 and up for VGG16)\\n        # Keep conv weights from detection network and fix them\\n            # --> train only rpn\\n        # buffer region proposals from rpn\\n        # Keep conv and rpn weights from step 3 and fix them\\n            # --> train only detection network\\n    '\n    test_pre = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    test_post = cfg['TEST'].RPN_POST_NMS_TOP_N\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    cfg['TEST'].RPN_POST_NMS_TOP_N = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    rpn_lr_factor = cfg['MODEL'].RPN_LR_FACTOR\n    rpn_lr_per_sample_scaled = [x * rpn_lr_factor for x in cfg['CNTK'].RPN_LR_PER_SAMPLE]\n    frcn_lr_factor = cfg['MODEL'].FRCN_LR_FACTOR\n    frcn_lr_per_sample_scaled = [x * frcn_lr_factor for x in cfg['CNTK'].FRCN_LR_PER_SAMPLE]\n    l2_reg_weight = cfg['CNTK'].L2_REG_WEIGHT\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    rpn_epochs = cfg['CNTK'].RPN_EPOCHS\n    frcn_epochs = cfg['CNTK'].FRCN_EPOCHS\n    feature_node_name = cfg['MODEL'].FEATURE_NODE_NAME\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('rpn_lr_per_sample:  {}'.format(rpn_lr_per_sample_scaled))\n    print('frcn_lr_per_sample: {}'.format(frcn_lr_per_sample_scaled))\n    debug_output = cfg['CNTK'].DEBUG_OUTPUT\n    if debug_output:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=feature_node_name)\n    feat_norm = image_input - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    scaled_gt_boxes = alias(roi_input, name='roi_input')\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    rpn_rois_input = input_variable((cfg['TRAIN'].RPN_POST_NMS_TOP_N, 4), dynamic_axes=[Axis.default_batch_axis()])\n    rpn_rois_buf = alias(rpn_rois_input, name='rpn_rois')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    print('stage 1a - rpn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_node, cfg)\n        stage1_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage1_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 1a - buffering rpn proposals')\n    buffered_proposals_s1 = compute_rpn_proposals(stage1_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 1b - frcn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois_buf, scaled_gt_boxes, cfg)\n        fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], CloneMethod.clone)\n        (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n        detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n        pred_error = classification_error(cls_score, label_targets, axis=1, name='pred_error')\n        stage1_frcn_network = combine([rois, cls_score, bbox_pred, detection_losses, pred_error])\n        if debug_output:\n            plot(stage1_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s1)\n        buffered_proposals_s1 = None\n    print('stage 2a - rpn')\n    if True:\n        conv_layers = clone_model(stage1_frcn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        rpn = clone_model(stage1_rpn_network, [last_conv_node_name, 'roi_input', 'dims_input'], ['rpn_rois', 'rpn_losses'], CloneMethod.clone)\n        rpn_net = rpn(conv_out, dims_node, scaled_gt_boxes)\n        rpn_rois = rpn_net.outputs[0]\n        rpn_losses = rpn_net.outputs[1]\n        stage2_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage2_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 2a - buffering rpn proposals')\n    buffered_proposals_s2 = compute_rpn_proposals(stage2_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 2b - frcn')\n    if True:\n        conv_layers = clone_model(stage2_rpn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        frcn = clone_model(stage1_frcn_network, [last_conv_node_name, 'rpn_rois', 'roi_input'], ['cls_score', 'bbox_regr', 'rpn_target_rois', 'detection_losses', 'pred_error'], CloneMethod.clone)\n        stage2_frcn_network = frcn(conv_out, rpn_rois_buf, scaled_gt_boxes)\n        detection_losses = stage2_frcn_network.outputs[3]\n        pred_error = stage2_frcn_network.outputs[4]\n        if debug_output:\n            plot(stage2_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s2)\n        buffered_proposals_s2 = None\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = test_pre\n    cfg['TEST'].RPN_POST_NMS_TOP_N = test_post\n    return create_faster_rcnn_eval_model(stage2_frcn_network, image_input, dims_input, cfg, rpn_model=stage2_rpn_network)",
            "def train_faster_rcnn_alternating(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        4-Step Alternating Training scheme from the Faster R-CNN paper:\\n        \\n        # Create initial network, only rpn, without detection network\\n            # --> train only the rpn (and conv3_1 and up for VGG16)\\n        # buffer region proposals from rpn\\n        # Create full network, initialize conv layers with imagenet, use buffered proposals\\n            # --> train only detection network (and conv3_1 and up for VGG16)\\n        # Keep conv weights from detection network and fix them\\n            # --> train only rpn\\n        # buffer region proposals from rpn\\n        # Keep conv and rpn weights from step 3 and fix them\\n            # --> train only detection network\\n    '\n    test_pre = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    test_post = cfg['TEST'].RPN_POST_NMS_TOP_N\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    cfg['TEST'].RPN_POST_NMS_TOP_N = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    rpn_lr_factor = cfg['MODEL'].RPN_LR_FACTOR\n    rpn_lr_per_sample_scaled = [x * rpn_lr_factor for x in cfg['CNTK'].RPN_LR_PER_SAMPLE]\n    frcn_lr_factor = cfg['MODEL'].FRCN_LR_FACTOR\n    frcn_lr_per_sample_scaled = [x * frcn_lr_factor for x in cfg['CNTK'].FRCN_LR_PER_SAMPLE]\n    l2_reg_weight = cfg['CNTK'].L2_REG_WEIGHT\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    rpn_epochs = cfg['CNTK'].RPN_EPOCHS\n    frcn_epochs = cfg['CNTK'].FRCN_EPOCHS\n    feature_node_name = cfg['MODEL'].FEATURE_NODE_NAME\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('rpn_lr_per_sample:  {}'.format(rpn_lr_per_sample_scaled))\n    print('frcn_lr_per_sample: {}'.format(frcn_lr_per_sample_scaled))\n    debug_output = cfg['CNTK'].DEBUG_OUTPUT\n    if debug_output:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=feature_node_name)\n    feat_norm = image_input - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    scaled_gt_boxes = alias(roi_input, name='roi_input')\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    rpn_rois_input = input_variable((cfg['TRAIN'].RPN_POST_NMS_TOP_N, 4), dynamic_axes=[Axis.default_batch_axis()])\n    rpn_rois_buf = alias(rpn_rois_input, name='rpn_rois')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    print('stage 1a - rpn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_node, cfg)\n        stage1_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage1_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 1a - buffering rpn proposals')\n    buffered_proposals_s1 = compute_rpn_proposals(stage1_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 1b - frcn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois_buf, scaled_gt_boxes, cfg)\n        fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], CloneMethod.clone)\n        (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n        detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n        pred_error = classification_error(cls_score, label_targets, axis=1, name='pred_error')\n        stage1_frcn_network = combine([rois, cls_score, bbox_pred, detection_losses, pred_error])\n        if debug_output:\n            plot(stage1_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s1)\n        buffered_proposals_s1 = None\n    print('stage 2a - rpn')\n    if True:\n        conv_layers = clone_model(stage1_frcn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        rpn = clone_model(stage1_rpn_network, [last_conv_node_name, 'roi_input', 'dims_input'], ['rpn_rois', 'rpn_losses'], CloneMethod.clone)\n        rpn_net = rpn(conv_out, dims_node, scaled_gt_boxes)\n        rpn_rois = rpn_net.outputs[0]\n        rpn_losses = rpn_net.outputs[1]\n        stage2_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage2_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 2a - buffering rpn proposals')\n    buffered_proposals_s2 = compute_rpn_proposals(stage2_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 2b - frcn')\n    if True:\n        conv_layers = clone_model(stage2_rpn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        frcn = clone_model(stage1_frcn_network, [last_conv_node_name, 'rpn_rois', 'roi_input'], ['cls_score', 'bbox_regr', 'rpn_target_rois', 'detection_losses', 'pred_error'], CloneMethod.clone)\n        stage2_frcn_network = frcn(conv_out, rpn_rois_buf, scaled_gt_boxes)\n        detection_losses = stage2_frcn_network.outputs[3]\n        pred_error = stage2_frcn_network.outputs[4]\n        if debug_output:\n            plot(stage2_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s2)\n        buffered_proposals_s2 = None\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = test_pre\n    cfg['TEST'].RPN_POST_NMS_TOP_N = test_post\n    return create_faster_rcnn_eval_model(stage2_frcn_network, image_input, dims_input, cfg, rpn_model=stage2_rpn_network)",
            "def train_faster_rcnn_alternating(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        4-Step Alternating Training scheme from the Faster R-CNN paper:\\n        \\n        # Create initial network, only rpn, without detection network\\n            # --> train only the rpn (and conv3_1 and up for VGG16)\\n        # buffer region proposals from rpn\\n        # Create full network, initialize conv layers with imagenet, use buffered proposals\\n            # --> train only detection network (and conv3_1 and up for VGG16)\\n        # Keep conv weights from detection network and fix them\\n            # --> train only rpn\\n        # buffer region proposals from rpn\\n        # Keep conv and rpn weights from step 3 and fix them\\n            # --> train only detection network\\n    '\n    test_pre = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    test_post = cfg['TEST'].RPN_POST_NMS_TOP_N\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    cfg['TEST'].RPN_POST_NMS_TOP_N = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    rpn_lr_factor = cfg['MODEL'].RPN_LR_FACTOR\n    rpn_lr_per_sample_scaled = [x * rpn_lr_factor for x in cfg['CNTK'].RPN_LR_PER_SAMPLE]\n    frcn_lr_factor = cfg['MODEL'].FRCN_LR_FACTOR\n    frcn_lr_per_sample_scaled = [x * frcn_lr_factor for x in cfg['CNTK'].FRCN_LR_PER_SAMPLE]\n    l2_reg_weight = cfg['CNTK'].L2_REG_WEIGHT\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    rpn_epochs = cfg['CNTK'].RPN_EPOCHS\n    frcn_epochs = cfg['CNTK'].FRCN_EPOCHS\n    feature_node_name = cfg['MODEL'].FEATURE_NODE_NAME\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('rpn_lr_per_sample:  {}'.format(rpn_lr_per_sample_scaled))\n    print('frcn_lr_per_sample: {}'.format(frcn_lr_per_sample_scaled))\n    debug_output = cfg['CNTK'].DEBUG_OUTPUT\n    if debug_output:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=feature_node_name)\n    feat_norm = image_input - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    scaled_gt_boxes = alias(roi_input, name='roi_input')\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    rpn_rois_input = input_variable((cfg['TRAIN'].RPN_POST_NMS_TOP_N, 4), dynamic_axes=[Axis.default_batch_axis()])\n    rpn_rois_buf = alias(rpn_rois_input, name='rpn_rois')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    print('stage 1a - rpn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_node, cfg)\n        stage1_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage1_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 1a - buffering rpn proposals')\n    buffered_proposals_s1 = compute_rpn_proposals(stage1_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 1b - frcn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois_buf, scaled_gt_boxes, cfg)\n        fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], CloneMethod.clone)\n        (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n        detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n        pred_error = classification_error(cls_score, label_targets, axis=1, name='pred_error')\n        stage1_frcn_network = combine([rois, cls_score, bbox_pred, detection_losses, pred_error])\n        if debug_output:\n            plot(stage1_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s1)\n        buffered_proposals_s1 = None\n    print('stage 2a - rpn')\n    if True:\n        conv_layers = clone_model(stage1_frcn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        rpn = clone_model(stage1_rpn_network, [last_conv_node_name, 'roi_input', 'dims_input'], ['rpn_rois', 'rpn_losses'], CloneMethod.clone)\n        rpn_net = rpn(conv_out, dims_node, scaled_gt_boxes)\n        rpn_rois = rpn_net.outputs[0]\n        rpn_losses = rpn_net.outputs[1]\n        stage2_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage2_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 2a - buffering rpn proposals')\n    buffered_proposals_s2 = compute_rpn_proposals(stage2_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 2b - frcn')\n    if True:\n        conv_layers = clone_model(stage2_rpn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        frcn = clone_model(stage1_frcn_network, [last_conv_node_name, 'rpn_rois', 'roi_input'], ['cls_score', 'bbox_regr', 'rpn_target_rois', 'detection_losses', 'pred_error'], CloneMethod.clone)\n        stage2_frcn_network = frcn(conv_out, rpn_rois_buf, scaled_gt_boxes)\n        detection_losses = stage2_frcn_network.outputs[3]\n        pred_error = stage2_frcn_network.outputs[4]\n        if debug_output:\n            plot(stage2_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s2)\n        buffered_proposals_s2 = None\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = test_pre\n    cfg['TEST'].RPN_POST_NMS_TOP_N = test_post\n    return create_faster_rcnn_eval_model(stage2_frcn_network, image_input, dims_input, cfg, rpn_model=stage2_rpn_network)",
            "def train_faster_rcnn_alternating(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        4-Step Alternating Training scheme from the Faster R-CNN paper:\\n        \\n        # Create initial network, only rpn, without detection network\\n            # --> train only the rpn (and conv3_1 and up for VGG16)\\n        # buffer region proposals from rpn\\n        # Create full network, initialize conv layers with imagenet, use buffered proposals\\n            # --> train only detection network (and conv3_1 and up for VGG16)\\n        # Keep conv weights from detection network and fix them\\n            # --> train only rpn\\n        # buffer region proposals from rpn\\n        # Keep conv and rpn weights from step 3 and fix them\\n            # --> train only detection network\\n    '\n    test_pre = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    test_post = cfg['TEST'].RPN_POST_NMS_TOP_N\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    cfg['TEST'].RPN_POST_NMS_TOP_N = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    rpn_lr_factor = cfg['MODEL'].RPN_LR_FACTOR\n    rpn_lr_per_sample_scaled = [x * rpn_lr_factor for x in cfg['CNTK'].RPN_LR_PER_SAMPLE]\n    frcn_lr_factor = cfg['MODEL'].FRCN_LR_FACTOR\n    frcn_lr_per_sample_scaled = [x * frcn_lr_factor for x in cfg['CNTK'].FRCN_LR_PER_SAMPLE]\n    l2_reg_weight = cfg['CNTK'].L2_REG_WEIGHT\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    rpn_epochs = cfg['CNTK'].RPN_EPOCHS\n    frcn_epochs = cfg['CNTK'].FRCN_EPOCHS\n    feature_node_name = cfg['MODEL'].FEATURE_NODE_NAME\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('rpn_lr_per_sample:  {}'.format(rpn_lr_per_sample_scaled))\n    print('frcn_lr_per_sample: {}'.format(frcn_lr_per_sample_scaled))\n    debug_output = cfg['CNTK'].DEBUG_OUTPUT\n    if debug_output:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=feature_node_name)\n    feat_norm = image_input - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    scaled_gt_boxes = alias(roi_input, name='roi_input')\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    rpn_rois_input = input_variable((cfg['TRAIN'].RPN_POST_NMS_TOP_N, 4), dynamic_axes=[Axis.default_batch_axis()])\n    rpn_rois_buf = alias(rpn_rois_input, name='rpn_rois')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    print('stage 1a - rpn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_node, cfg)\n        stage1_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage1_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 1a - buffering rpn proposals')\n    buffered_proposals_s1 = compute_rpn_proposals(stage1_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 1b - frcn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois_buf, scaled_gt_boxes, cfg)\n        fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], CloneMethod.clone)\n        (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n        detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n        pred_error = classification_error(cls_score, label_targets, axis=1, name='pred_error')\n        stage1_frcn_network = combine([rois, cls_score, bbox_pred, detection_losses, pred_error])\n        if debug_output:\n            plot(stage1_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s1)\n        buffered_proposals_s1 = None\n    print('stage 2a - rpn')\n    if True:\n        conv_layers = clone_model(stage1_frcn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        rpn = clone_model(stage1_rpn_network, [last_conv_node_name, 'roi_input', 'dims_input'], ['rpn_rois', 'rpn_losses'], CloneMethod.clone)\n        rpn_net = rpn(conv_out, dims_node, scaled_gt_boxes)\n        rpn_rois = rpn_net.outputs[0]\n        rpn_losses = rpn_net.outputs[1]\n        stage2_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage2_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 2a - buffering rpn proposals')\n    buffered_proposals_s2 = compute_rpn_proposals(stage2_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 2b - frcn')\n    if True:\n        conv_layers = clone_model(stage2_rpn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        frcn = clone_model(stage1_frcn_network, [last_conv_node_name, 'rpn_rois', 'roi_input'], ['cls_score', 'bbox_regr', 'rpn_target_rois', 'detection_losses', 'pred_error'], CloneMethod.clone)\n        stage2_frcn_network = frcn(conv_out, rpn_rois_buf, scaled_gt_boxes)\n        detection_losses = stage2_frcn_network.outputs[3]\n        pred_error = stage2_frcn_network.outputs[4]\n        if debug_output:\n            plot(stage2_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s2)\n        buffered_proposals_s2 = None\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = test_pre\n    cfg['TEST'].RPN_POST_NMS_TOP_N = test_post\n    return create_faster_rcnn_eval_model(stage2_frcn_network, image_input, dims_input, cfg, rpn_model=stage2_rpn_network)",
            "def train_faster_rcnn_alternating(cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        4-Step Alternating Training scheme from the Faster R-CNN paper:\\n        \\n        # Create initial network, only rpn, without detection network\\n            # --> train only the rpn (and conv3_1 and up for VGG16)\\n        # buffer region proposals from rpn\\n        # Create full network, initialize conv layers with imagenet, use buffered proposals\\n            # --> train only detection network (and conv3_1 and up for VGG16)\\n        # Keep conv weights from detection network and fix them\\n            # --> train only rpn\\n        # buffer region proposals from rpn\\n        # Keep conv and rpn weights from step 3 and fix them\\n            # --> train only detection network\\n    '\n    test_pre = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    test_post = cfg['TEST'].RPN_POST_NMS_TOP_N\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    cfg['TEST'].RPN_POST_NMS_TOP_N = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    rpn_lr_factor = cfg['MODEL'].RPN_LR_FACTOR\n    rpn_lr_per_sample_scaled = [x * rpn_lr_factor for x in cfg['CNTK'].RPN_LR_PER_SAMPLE]\n    frcn_lr_factor = cfg['MODEL'].FRCN_LR_FACTOR\n    frcn_lr_per_sample_scaled = [x * frcn_lr_factor for x in cfg['CNTK'].FRCN_LR_PER_SAMPLE]\n    l2_reg_weight = cfg['CNTK'].L2_REG_WEIGHT\n    mm_schedule = momentum_schedule(cfg['CNTK'].MOMENTUM_PER_MB)\n    rpn_epochs = cfg['CNTK'].RPN_EPOCHS\n    frcn_epochs = cfg['CNTK'].FRCN_EPOCHS\n    feature_node_name = cfg['MODEL'].FEATURE_NODE_NAME\n    last_conv_node_name = cfg['MODEL'].LAST_CONV_NODE_NAME\n    print('Using base model:   {}'.format(cfg['MODEL'].BASE_MODEL))\n    print('rpn_lr_per_sample:  {}'.format(rpn_lr_per_sample_scaled))\n    print('frcn_lr_per_sample: {}'.format(frcn_lr_per_sample_scaled))\n    debug_output = cfg['CNTK'].DEBUG_OUTPUT\n    if debug_output:\n        print('Storing graphs and models to %s.' % cfg.OUTPUT_PATH)\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=feature_node_name)\n    feat_norm = image_input - Constant([[[v]] for v in cfg['MODEL'].IMG_PAD_COLOR])\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    scaled_gt_boxes = alias(roi_input, name='roi_input')\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    dims_node = alias(dims_input, name='dims_input')\n    rpn_rois_input = input_variable((cfg['TRAIN'].RPN_POST_NMS_TOP_N, 4), dynamic_axes=[Axis.default_batch_axis()])\n    rpn_rois_buf = alias(rpn_rois_input, name='rpn_rois')\n    base_model = load_model(cfg['BASE_MODEL_PATH'])\n    print('stage 1a - rpn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rpn_rois, rpn_losses) = create_rpn(conv_out, scaled_gt_boxes, dims_node, cfg)\n        stage1_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage1_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 1a - buffering rpn proposals')\n    buffered_proposals_s1 = compute_rpn_proposals(stage1_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 1b - frcn')\n    if True:\n        conv_layers = clone_conv_layers(base_model, cfg)\n        conv_out = conv_layers(feat_norm)\n        (rois, label_targets, bbox_targets, bbox_inside_weights) = create_proposal_target_layer(rpn_rois_buf, scaled_gt_boxes, cfg)\n        fc_layers = clone_model(base_model, [cfg['MODEL'].POOL_NODE_NAME], [cfg['MODEL'].LAST_HIDDEN_NODE_NAME], CloneMethod.clone)\n        (cls_score, bbox_pred) = create_fast_rcnn_predictor(conv_out, rois, fc_layers, cfg)\n        detection_losses = create_detection_losses(cls_score, label_targets, bbox_pred, rois, bbox_targets, bbox_inside_weights, cfg)\n        pred_error = classification_error(cls_score, label_targets, axis=1, name='pred_error')\n        stage1_frcn_network = combine([rois, cls_score, bbox_pred, detection_losses, pred_error])\n        if debug_output:\n            plot(stage1_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage1b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s1)\n        buffered_proposals_s1 = None\n    print('stage 2a - rpn')\n    if True:\n        conv_layers = clone_model(stage1_frcn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        rpn = clone_model(stage1_rpn_network, [last_conv_node_name, 'roi_input', 'dims_input'], ['rpn_rois', 'rpn_losses'], CloneMethod.clone)\n        rpn_net = rpn(conv_out, dims_node, scaled_gt_boxes)\n        rpn_rois = rpn_net.outputs[0]\n        rpn_losses = rpn_net.outputs[1]\n        stage2_rpn_network = combine([rpn_rois, rpn_losses])\n        if debug_output:\n            plot(stage2_rpn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2a_rpn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, rpn_losses, rpn_losses, rpn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, rpn_epochs, cfg)\n    print('stage 2a - buffering rpn proposals')\n    buffered_proposals_s2 = compute_rpn_proposals(stage2_rpn_network, image_input, roi_input, dims_input, cfg)\n    print('stage 2b - frcn')\n    if True:\n        conv_layers = clone_model(stage2_rpn_network, [feature_node_name], [last_conv_node_name], CloneMethod.freeze)\n        conv_out = conv_layers(image_input)\n        frcn = clone_model(stage1_frcn_network, [last_conv_node_name, 'rpn_rois', 'roi_input'], ['cls_score', 'bbox_regr', 'rpn_target_rois', 'detection_losses', 'pred_error'], CloneMethod.clone)\n        stage2_frcn_network = frcn(conv_out, rpn_rois_buf, scaled_gt_boxes)\n        detection_losses = stage2_frcn_network.outputs[3]\n        pred_error = stage2_frcn_network.outputs[4]\n        if debug_output:\n            plot(stage2_frcn_network, os.path.join(cfg.OUTPUT_PATH, 'graph_frcn_train_stage2b_frcn.' + cfg['CNTK'].GRAPH_TYPE))\n        train_model(image_input, roi_input, dims_input, detection_losses, pred_error, frcn_lr_per_sample_scaled, mm_schedule, l2_reg_weight, frcn_epochs, cfg, rpn_rois_input=rpn_rois_input, buffered_rpn_proposals=buffered_proposals_s2)\n        buffered_proposals_s2 = None\n    cfg['TEST'].RPN_PRE_NMS_TOP_N = test_pre\n    cfg['TEST'].RPN_POST_NMS_TOP_N = test_post\n    return create_faster_rcnn_eval_model(stage2_frcn_network, image_input, dims_input, cfg, rpn_model=stage2_rpn_network)"
        ]
    },
    {
        "func_name": "train_model",
        "original": "def train_model(image_input, roi_input, dims_input, loss, pred_error, lr_per_sample, mm_schedule, l2_reg_weight, epochs_to_train, cfg, rpn_rois_input=None, buffered_rpn_proposals=None):\n    if isinstance(loss, cntk.Variable):\n        loss = combine([loss])\n    params = loss.parameters\n    biases = [p for p in params if '.b' in p.name or 'b' == p.name]\n    others = [p for p in params if not p in biases]\n    bias_lr_mult = cfg['CNTK'].BIAS_LR_MULT\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('biases')\n        for p in biases:\n            print(p)\n        print('others')\n        for p in others:\n            print(p)\n        print('bias_lr_mult: {}'.format(bias_lr_mult))\n    lr_schedule = learning_parameter_schedule_per_sample(lr_per_sample)\n    learner = momentum_sgd(others, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    bias_lr_per_sample = [v * bias_lr_mult for v in lr_per_sample]\n    bias_lr_schedule = learning_parameter_schedule_per_sample(bias_lr_per_sample)\n    bias_learner = momentum_sgd(biases, bias_lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    trainer = Trainer(None, (loss, pred_error), [learner, bias_learner])\n    print('Training model for %s epochs.' % epochs_to_train)\n    log_number_of_parameters(loss)\n    if buffered_rpn_proposals is not None:\n        proposal_provider = ProposalProvider.fromlist(buffered_rpn_proposals, requires_scaling=False)\n    else:\n        proposal_provider = None\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=True, use_flipping=cfg['TRAIN'].USE_FLIPPED, max_images=cfg['DATA'].NUM_TRAIN_IMAGES, proposal_provider=proposal_provider)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input}\n    if buffered_rpn_proposals is not None:\n        input_map[od_minibatch_source.proposals_si] = rpn_rois_input\n    else:\n        input_map[od_minibatch_source.dims_si] = dims_input\n    progress_printer = ProgressPrinter(tag='Training', num_epochs=epochs_to_train, gen_heartbeat=True)\n    for epoch in range(epochs_to_train):\n        sample_count = 0\n        while sample_count < cfg['DATA'].NUM_TRAIN_IMAGES:\n            data = od_minibatch_source.next_minibatch(min(cfg.MB_SIZE, cfg['DATA'].NUM_TRAIN_IMAGES - sample_count), input_map=input_map)\n            trainer.train_minibatch(data)\n            sample_count += trainer.previous_minibatch_sample_count\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n            if sample_count % 100 == 0:\n                print('Processed {} samples'.format(sample_count))\n        progress_printer.epoch_summary(with_metric=True)",
        "mutated": [
            "def train_model(image_input, roi_input, dims_input, loss, pred_error, lr_per_sample, mm_schedule, l2_reg_weight, epochs_to_train, cfg, rpn_rois_input=None, buffered_rpn_proposals=None):\n    if False:\n        i = 10\n    if isinstance(loss, cntk.Variable):\n        loss = combine([loss])\n    params = loss.parameters\n    biases = [p for p in params if '.b' in p.name or 'b' == p.name]\n    others = [p for p in params if not p in biases]\n    bias_lr_mult = cfg['CNTK'].BIAS_LR_MULT\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('biases')\n        for p in biases:\n            print(p)\n        print('others')\n        for p in others:\n            print(p)\n        print('bias_lr_mult: {}'.format(bias_lr_mult))\n    lr_schedule = learning_parameter_schedule_per_sample(lr_per_sample)\n    learner = momentum_sgd(others, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    bias_lr_per_sample = [v * bias_lr_mult for v in lr_per_sample]\n    bias_lr_schedule = learning_parameter_schedule_per_sample(bias_lr_per_sample)\n    bias_learner = momentum_sgd(biases, bias_lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    trainer = Trainer(None, (loss, pred_error), [learner, bias_learner])\n    print('Training model for %s epochs.' % epochs_to_train)\n    log_number_of_parameters(loss)\n    if buffered_rpn_proposals is not None:\n        proposal_provider = ProposalProvider.fromlist(buffered_rpn_proposals, requires_scaling=False)\n    else:\n        proposal_provider = None\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=True, use_flipping=cfg['TRAIN'].USE_FLIPPED, max_images=cfg['DATA'].NUM_TRAIN_IMAGES, proposal_provider=proposal_provider)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input}\n    if buffered_rpn_proposals is not None:\n        input_map[od_minibatch_source.proposals_si] = rpn_rois_input\n    else:\n        input_map[od_minibatch_source.dims_si] = dims_input\n    progress_printer = ProgressPrinter(tag='Training', num_epochs=epochs_to_train, gen_heartbeat=True)\n    for epoch in range(epochs_to_train):\n        sample_count = 0\n        while sample_count < cfg['DATA'].NUM_TRAIN_IMAGES:\n            data = od_minibatch_source.next_minibatch(min(cfg.MB_SIZE, cfg['DATA'].NUM_TRAIN_IMAGES - sample_count), input_map=input_map)\n            trainer.train_minibatch(data)\n            sample_count += trainer.previous_minibatch_sample_count\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n            if sample_count % 100 == 0:\n                print('Processed {} samples'.format(sample_count))\n        progress_printer.epoch_summary(with_metric=True)",
            "def train_model(image_input, roi_input, dims_input, loss, pred_error, lr_per_sample, mm_schedule, l2_reg_weight, epochs_to_train, cfg, rpn_rois_input=None, buffered_rpn_proposals=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(loss, cntk.Variable):\n        loss = combine([loss])\n    params = loss.parameters\n    biases = [p for p in params if '.b' in p.name or 'b' == p.name]\n    others = [p for p in params if not p in biases]\n    bias_lr_mult = cfg['CNTK'].BIAS_LR_MULT\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('biases')\n        for p in biases:\n            print(p)\n        print('others')\n        for p in others:\n            print(p)\n        print('bias_lr_mult: {}'.format(bias_lr_mult))\n    lr_schedule = learning_parameter_schedule_per_sample(lr_per_sample)\n    learner = momentum_sgd(others, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    bias_lr_per_sample = [v * bias_lr_mult for v in lr_per_sample]\n    bias_lr_schedule = learning_parameter_schedule_per_sample(bias_lr_per_sample)\n    bias_learner = momentum_sgd(biases, bias_lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    trainer = Trainer(None, (loss, pred_error), [learner, bias_learner])\n    print('Training model for %s epochs.' % epochs_to_train)\n    log_number_of_parameters(loss)\n    if buffered_rpn_proposals is not None:\n        proposal_provider = ProposalProvider.fromlist(buffered_rpn_proposals, requires_scaling=False)\n    else:\n        proposal_provider = None\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=True, use_flipping=cfg['TRAIN'].USE_FLIPPED, max_images=cfg['DATA'].NUM_TRAIN_IMAGES, proposal_provider=proposal_provider)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input}\n    if buffered_rpn_proposals is not None:\n        input_map[od_minibatch_source.proposals_si] = rpn_rois_input\n    else:\n        input_map[od_minibatch_source.dims_si] = dims_input\n    progress_printer = ProgressPrinter(tag='Training', num_epochs=epochs_to_train, gen_heartbeat=True)\n    for epoch in range(epochs_to_train):\n        sample_count = 0\n        while sample_count < cfg['DATA'].NUM_TRAIN_IMAGES:\n            data = od_minibatch_source.next_minibatch(min(cfg.MB_SIZE, cfg['DATA'].NUM_TRAIN_IMAGES - sample_count), input_map=input_map)\n            trainer.train_minibatch(data)\n            sample_count += trainer.previous_minibatch_sample_count\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n            if sample_count % 100 == 0:\n                print('Processed {} samples'.format(sample_count))\n        progress_printer.epoch_summary(with_metric=True)",
            "def train_model(image_input, roi_input, dims_input, loss, pred_error, lr_per_sample, mm_schedule, l2_reg_weight, epochs_to_train, cfg, rpn_rois_input=None, buffered_rpn_proposals=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(loss, cntk.Variable):\n        loss = combine([loss])\n    params = loss.parameters\n    biases = [p for p in params if '.b' in p.name or 'b' == p.name]\n    others = [p for p in params if not p in biases]\n    bias_lr_mult = cfg['CNTK'].BIAS_LR_MULT\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('biases')\n        for p in biases:\n            print(p)\n        print('others')\n        for p in others:\n            print(p)\n        print('bias_lr_mult: {}'.format(bias_lr_mult))\n    lr_schedule = learning_parameter_schedule_per_sample(lr_per_sample)\n    learner = momentum_sgd(others, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    bias_lr_per_sample = [v * bias_lr_mult for v in lr_per_sample]\n    bias_lr_schedule = learning_parameter_schedule_per_sample(bias_lr_per_sample)\n    bias_learner = momentum_sgd(biases, bias_lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    trainer = Trainer(None, (loss, pred_error), [learner, bias_learner])\n    print('Training model for %s epochs.' % epochs_to_train)\n    log_number_of_parameters(loss)\n    if buffered_rpn_proposals is not None:\n        proposal_provider = ProposalProvider.fromlist(buffered_rpn_proposals, requires_scaling=False)\n    else:\n        proposal_provider = None\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=True, use_flipping=cfg['TRAIN'].USE_FLIPPED, max_images=cfg['DATA'].NUM_TRAIN_IMAGES, proposal_provider=proposal_provider)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input}\n    if buffered_rpn_proposals is not None:\n        input_map[od_minibatch_source.proposals_si] = rpn_rois_input\n    else:\n        input_map[od_minibatch_source.dims_si] = dims_input\n    progress_printer = ProgressPrinter(tag='Training', num_epochs=epochs_to_train, gen_heartbeat=True)\n    for epoch in range(epochs_to_train):\n        sample_count = 0\n        while sample_count < cfg['DATA'].NUM_TRAIN_IMAGES:\n            data = od_minibatch_source.next_minibatch(min(cfg.MB_SIZE, cfg['DATA'].NUM_TRAIN_IMAGES - sample_count), input_map=input_map)\n            trainer.train_minibatch(data)\n            sample_count += trainer.previous_minibatch_sample_count\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n            if sample_count % 100 == 0:\n                print('Processed {} samples'.format(sample_count))\n        progress_printer.epoch_summary(with_metric=True)",
            "def train_model(image_input, roi_input, dims_input, loss, pred_error, lr_per_sample, mm_schedule, l2_reg_weight, epochs_to_train, cfg, rpn_rois_input=None, buffered_rpn_proposals=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(loss, cntk.Variable):\n        loss = combine([loss])\n    params = loss.parameters\n    biases = [p for p in params if '.b' in p.name or 'b' == p.name]\n    others = [p for p in params if not p in biases]\n    bias_lr_mult = cfg['CNTK'].BIAS_LR_MULT\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('biases')\n        for p in biases:\n            print(p)\n        print('others')\n        for p in others:\n            print(p)\n        print('bias_lr_mult: {}'.format(bias_lr_mult))\n    lr_schedule = learning_parameter_schedule_per_sample(lr_per_sample)\n    learner = momentum_sgd(others, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    bias_lr_per_sample = [v * bias_lr_mult for v in lr_per_sample]\n    bias_lr_schedule = learning_parameter_schedule_per_sample(bias_lr_per_sample)\n    bias_learner = momentum_sgd(biases, bias_lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    trainer = Trainer(None, (loss, pred_error), [learner, bias_learner])\n    print('Training model for %s epochs.' % epochs_to_train)\n    log_number_of_parameters(loss)\n    if buffered_rpn_proposals is not None:\n        proposal_provider = ProposalProvider.fromlist(buffered_rpn_proposals, requires_scaling=False)\n    else:\n        proposal_provider = None\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=True, use_flipping=cfg['TRAIN'].USE_FLIPPED, max_images=cfg['DATA'].NUM_TRAIN_IMAGES, proposal_provider=proposal_provider)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input}\n    if buffered_rpn_proposals is not None:\n        input_map[od_minibatch_source.proposals_si] = rpn_rois_input\n    else:\n        input_map[od_minibatch_source.dims_si] = dims_input\n    progress_printer = ProgressPrinter(tag='Training', num_epochs=epochs_to_train, gen_heartbeat=True)\n    for epoch in range(epochs_to_train):\n        sample_count = 0\n        while sample_count < cfg['DATA'].NUM_TRAIN_IMAGES:\n            data = od_minibatch_source.next_minibatch(min(cfg.MB_SIZE, cfg['DATA'].NUM_TRAIN_IMAGES - sample_count), input_map=input_map)\n            trainer.train_minibatch(data)\n            sample_count += trainer.previous_minibatch_sample_count\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n            if sample_count % 100 == 0:\n                print('Processed {} samples'.format(sample_count))\n        progress_printer.epoch_summary(with_metric=True)",
            "def train_model(image_input, roi_input, dims_input, loss, pred_error, lr_per_sample, mm_schedule, l2_reg_weight, epochs_to_train, cfg, rpn_rois_input=None, buffered_rpn_proposals=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(loss, cntk.Variable):\n        loss = combine([loss])\n    params = loss.parameters\n    biases = [p for p in params if '.b' in p.name or 'b' == p.name]\n    others = [p for p in params if not p in biases]\n    bias_lr_mult = cfg['CNTK'].BIAS_LR_MULT\n    if cfg['CNTK'].DEBUG_OUTPUT:\n        print('biases')\n        for p in biases:\n            print(p)\n        print('others')\n        for p in others:\n            print(p)\n        print('bias_lr_mult: {}'.format(bias_lr_mult))\n    lr_schedule = learning_parameter_schedule_per_sample(lr_per_sample)\n    learner = momentum_sgd(others, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    bias_lr_per_sample = [v * bias_lr_mult for v in lr_per_sample]\n    bias_lr_schedule = learning_parameter_schedule_per_sample(bias_lr_per_sample)\n    bias_learner = momentum_sgd(biases, bias_lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight, unit_gain=False, use_mean_gradient=True)\n    trainer = Trainer(None, (loss, pred_error), [learner, bias_learner])\n    print('Training model for %s epochs.' % epochs_to_train)\n    log_number_of_parameters(loss)\n    if buffered_rpn_proposals is not None:\n        proposal_provider = ProposalProvider.fromlist(buffered_rpn_proposals, requires_scaling=False)\n    else:\n        proposal_provider = None\n    od_minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TRAIN_MAP_FILE, cfg['DATA'].TRAIN_ROI_FILE, num_classes=cfg['DATA'].NUM_CLASSES, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=True, use_flipping=cfg['TRAIN'].USE_FLIPPED, max_images=cfg['DATA'].NUM_TRAIN_IMAGES, proposal_provider=proposal_provider)\n    input_map = {od_minibatch_source.image_si: image_input, od_minibatch_source.roi_si: roi_input}\n    if buffered_rpn_proposals is not None:\n        input_map[od_minibatch_source.proposals_si] = rpn_rois_input\n    else:\n        input_map[od_minibatch_source.dims_si] = dims_input\n    progress_printer = ProgressPrinter(tag='Training', num_epochs=epochs_to_train, gen_heartbeat=True)\n    for epoch in range(epochs_to_train):\n        sample_count = 0\n        while sample_count < cfg['DATA'].NUM_TRAIN_IMAGES:\n            data = od_minibatch_source.next_minibatch(min(cfg.MB_SIZE, cfg['DATA'].NUM_TRAIN_IMAGES - sample_count), input_map=input_map)\n            trainer.train_minibatch(data)\n            sample_count += trainer.previous_minibatch_sample_count\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n            if sample_count % 100 == 0:\n                print('Processed {} samples'.format(sample_count))\n        progress_printer.epoch_summary(with_metric=True)"
        ]
    }
]