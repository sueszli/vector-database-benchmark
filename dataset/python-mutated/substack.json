[
    {
        "func_name": "_extract_embed_urls",
        "original": "@classmethod\ndef _extract_embed_urls(cls, url, webpage):\n    if not re.search('<script[^>]+src=[\"\\\\\\']https://substackcdn.com/[^\"\\\\\\']+\\\\.js', webpage):\n        return\n    mobj = re.search('{[^}]*\\\\\\\\?[\"\\\\\\']subdomain\\\\\\\\?[\"\\\\\\']\\\\s*:\\\\s*\\\\\\\\?[\"\\\\\\'](?P<subdomain>[^\\\\\\\\\"\\\\\\']+)', webpage)\n    if mobj:\n        parsed = urllib.parse.urlparse(url)\n        yield parsed._replace(netloc=f\"{mobj.group('subdomain')}.substack.com\").geturl()\n        raise cls.StopExtraction()",
        "mutated": [
            "@classmethod\ndef _extract_embed_urls(cls, url, webpage):\n    if False:\n        i = 10\n    if not re.search('<script[^>]+src=[\"\\\\\\']https://substackcdn.com/[^\"\\\\\\']+\\\\.js', webpage):\n        return\n    mobj = re.search('{[^}]*\\\\\\\\?[\"\\\\\\']subdomain\\\\\\\\?[\"\\\\\\']\\\\s*:\\\\s*\\\\\\\\?[\"\\\\\\'](?P<subdomain>[^\\\\\\\\\"\\\\\\']+)', webpage)\n    if mobj:\n        parsed = urllib.parse.urlparse(url)\n        yield parsed._replace(netloc=f\"{mobj.group('subdomain')}.substack.com\").geturl()\n        raise cls.StopExtraction()",
            "@classmethod\ndef _extract_embed_urls(cls, url, webpage):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not re.search('<script[^>]+src=[\"\\\\\\']https://substackcdn.com/[^\"\\\\\\']+\\\\.js', webpage):\n        return\n    mobj = re.search('{[^}]*\\\\\\\\?[\"\\\\\\']subdomain\\\\\\\\?[\"\\\\\\']\\\\s*:\\\\s*\\\\\\\\?[\"\\\\\\'](?P<subdomain>[^\\\\\\\\\"\\\\\\']+)', webpage)\n    if mobj:\n        parsed = urllib.parse.urlparse(url)\n        yield parsed._replace(netloc=f\"{mobj.group('subdomain')}.substack.com\").geturl()\n        raise cls.StopExtraction()",
            "@classmethod\ndef _extract_embed_urls(cls, url, webpage):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not re.search('<script[^>]+src=[\"\\\\\\']https://substackcdn.com/[^\"\\\\\\']+\\\\.js', webpage):\n        return\n    mobj = re.search('{[^}]*\\\\\\\\?[\"\\\\\\']subdomain\\\\\\\\?[\"\\\\\\']\\\\s*:\\\\s*\\\\\\\\?[\"\\\\\\'](?P<subdomain>[^\\\\\\\\\"\\\\\\']+)', webpage)\n    if mobj:\n        parsed = urllib.parse.urlparse(url)\n        yield parsed._replace(netloc=f\"{mobj.group('subdomain')}.substack.com\").geturl()\n        raise cls.StopExtraction()",
            "@classmethod\ndef _extract_embed_urls(cls, url, webpage):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not re.search('<script[^>]+src=[\"\\\\\\']https://substackcdn.com/[^\"\\\\\\']+\\\\.js', webpage):\n        return\n    mobj = re.search('{[^}]*\\\\\\\\?[\"\\\\\\']subdomain\\\\\\\\?[\"\\\\\\']\\\\s*:\\\\s*\\\\\\\\?[\"\\\\\\'](?P<subdomain>[^\\\\\\\\\"\\\\\\']+)', webpage)\n    if mobj:\n        parsed = urllib.parse.urlparse(url)\n        yield parsed._replace(netloc=f\"{mobj.group('subdomain')}.substack.com\").geturl()\n        raise cls.StopExtraction()",
            "@classmethod\ndef _extract_embed_urls(cls, url, webpage):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not re.search('<script[^>]+src=[\"\\\\\\']https://substackcdn.com/[^\"\\\\\\']+\\\\.js', webpage):\n        return\n    mobj = re.search('{[^}]*\\\\\\\\?[\"\\\\\\']subdomain\\\\\\\\?[\"\\\\\\']\\\\s*:\\\\s*\\\\\\\\?[\"\\\\\\'](?P<subdomain>[^\\\\\\\\\"\\\\\\']+)', webpage)\n    if mobj:\n        parsed = urllib.parse.urlparse(url)\n        yield parsed._replace(netloc=f\"{mobj.group('subdomain')}.substack.com\").geturl()\n        raise cls.StopExtraction()"
        ]
    },
    {
        "func_name": "_extract_video_formats",
        "original": "def _extract_video_formats(self, video_id, url):\n    (formats, subtitles) = ([], {})\n    for video_format in ('hls', 'mp4'):\n        video_url = urllib.parse.urljoin(url, f'/api/v1/video/upload/{video_id}/src?type={video_format}')\n        if video_format == 'hls':\n            (fmts, subs) = self._extract_m3u8_formats_and_subtitles(video_url, video_id, 'mp4', fatal=False)\n            formats.extend(fmts)\n            self._merge_subtitles(subs, target=subtitles)\n        else:\n            formats.append({'url': video_url, 'ext': video_format})\n    return (formats, subtitles)",
        "mutated": [
            "def _extract_video_formats(self, video_id, url):\n    if False:\n        i = 10\n    (formats, subtitles) = ([], {})\n    for video_format in ('hls', 'mp4'):\n        video_url = urllib.parse.urljoin(url, f'/api/v1/video/upload/{video_id}/src?type={video_format}')\n        if video_format == 'hls':\n            (fmts, subs) = self._extract_m3u8_formats_and_subtitles(video_url, video_id, 'mp4', fatal=False)\n            formats.extend(fmts)\n            self._merge_subtitles(subs, target=subtitles)\n        else:\n            formats.append({'url': video_url, 'ext': video_format})\n    return (formats, subtitles)",
            "def _extract_video_formats(self, video_id, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (formats, subtitles) = ([], {})\n    for video_format in ('hls', 'mp4'):\n        video_url = urllib.parse.urljoin(url, f'/api/v1/video/upload/{video_id}/src?type={video_format}')\n        if video_format == 'hls':\n            (fmts, subs) = self._extract_m3u8_formats_and_subtitles(video_url, video_id, 'mp4', fatal=False)\n            formats.extend(fmts)\n            self._merge_subtitles(subs, target=subtitles)\n        else:\n            formats.append({'url': video_url, 'ext': video_format})\n    return (formats, subtitles)",
            "def _extract_video_formats(self, video_id, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (formats, subtitles) = ([], {})\n    for video_format in ('hls', 'mp4'):\n        video_url = urllib.parse.urljoin(url, f'/api/v1/video/upload/{video_id}/src?type={video_format}')\n        if video_format == 'hls':\n            (fmts, subs) = self._extract_m3u8_formats_and_subtitles(video_url, video_id, 'mp4', fatal=False)\n            formats.extend(fmts)\n            self._merge_subtitles(subs, target=subtitles)\n        else:\n            formats.append({'url': video_url, 'ext': video_format})\n    return (formats, subtitles)",
            "def _extract_video_formats(self, video_id, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (formats, subtitles) = ([], {})\n    for video_format in ('hls', 'mp4'):\n        video_url = urllib.parse.urljoin(url, f'/api/v1/video/upload/{video_id}/src?type={video_format}')\n        if video_format == 'hls':\n            (fmts, subs) = self._extract_m3u8_formats_and_subtitles(video_url, video_id, 'mp4', fatal=False)\n            formats.extend(fmts)\n            self._merge_subtitles(subs, target=subtitles)\n        else:\n            formats.append({'url': video_url, 'ext': video_format})\n    return (formats, subtitles)",
            "def _extract_video_formats(self, video_id, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (formats, subtitles) = ([], {})\n    for video_format in ('hls', 'mp4'):\n        video_url = urllib.parse.urljoin(url, f'/api/v1/video/upload/{video_id}/src?type={video_format}')\n        if video_format == 'hls':\n            (fmts, subs) = self._extract_m3u8_formats_and_subtitles(video_url, video_id, 'mp4', fatal=False)\n            formats.extend(fmts)\n            self._merge_subtitles(subs, target=subtitles)\n        else:\n            formats.append({'url': video_url, 'ext': video_format})\n    return (formats, subtitles)"
        ]
    },
    {
        "func_name": "_real_extract",
        "original": "def _real_extract(self, url):\n    (display_id, username) = self._match_valid_url(url).group('id', 'username')\n    webpage = self._download_webpage(url, display_id)\n    webpage_info = self._parse_json(self._search_json('window\\\\._preloads\\\\s*=\\\\s*JSON\\\\.parse\\\\(', webpage, 'json string', display_id, transform_source=js_to_json, contains_pattern='\"{(?s:.+)}\"'), display_id)\n    canonical_url = url\n    domain = traverse_obj(webpage_info, ('domainInfo', 'customDomain', {str}))\n    if domain:\n        canonical_url = urllib.parse.urlparse(url)._replace(netloc=domain).geturl()\n    post_type = webpage_info['post']['type']\n    (formats, subtitles) = ([], {})\n    if post_type == 'podcast':\n        (formats, subtitles) = ([{'url': webpage_info['post']['podcast_url']}], {})\n    elif post_type == 'video':\n        (formats, subtitles) = self._extract_video_formats(webpage_info['post']['videoUpload']['id'], canonical_url)\n    else:\n        self.raise_no_formats(f'Page type \"{post_type}\" is not supported')\n    return {'id': str(webpage_info['post']['id']), 'formats': formats, 'subtitles': subtitles, 'title': traverse_obj(webpage_info, ('post', 'title')), 'description': traverse_obj(webpage_info, ('post', 'description')), 'thumbnail': traverse_obj(webpage_info, ('post', 'cover_image')), 'uploader': traverse_obj(webpage_info, ('pub', 'name')), 'uploader_id': str_or_none(traverse_obj(webpage_info, ('post', 'publication_id'))), 'webpage_url': canonical_url}",
        "mutated": [
            "def _real_extract(self, url):\n    if False:\n        i = 10\n    (display_id, username) = self._match_valid_url(url).group('id', 'username')\n    webpage = self._download_webpage(url, display_id)\n    webpage_info = self._parse_json(self._search_json('window\\\\._preloads\\\\s*=\\\\s*JSON\\\\.parse\\\\(', webpage, 'json string', display_id, transform_source=js_to_json, contains_pattern='\"{(?s:.+)}\"'), display_id)\n    canonical_url = url\n    domain = traverse_obj(webpage_info, ('domainInfo', 'customDomain', {str}))\n    if domain:\n        canonical_url = urllib.parse.urlparse(url)._replace(netloc=domain).geturl()\n    post_type = webpage_info['post']['type']\n    (formats, subtitles) = ([], {})\n    if post_type == 'podcast':\n        (formats, subtitles) = ([{'url': webpage_info['post']['podcast_url']}], {})\n    elif post_type == 'video':\n        (formats, subtitles) = self._extract_video_formats(webpage_info['post']['videoUpload']['id'], canonical_url)\n    else:\n        self.raise_no_formats(f'Page type \"{post_type}\" is not supported')\n    return {'id': str(webpage_info['post']['id']), 'formats': formats, 'subtitles': subtitles, 'title': traverse_obj(webpage_info, ('post', 'title')), 'description': traverse_obj(webpage_info, ('post', 'description')), 'thumbnail': traverse_obj(webpage_info, ('post', 'cover_image')), 'uploader': traverse_obj(webpage_info, ('pub', 'name')), 'uploader_id': str_or_none(traverse_obj(webpage_info, ('post', 'publication_id'))), 'webpage_url': canonical_url}",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (display_id, username) = self._match_valid_url(url).group('id', 'username')\n    webpage = self._download_webpage(url, display_id)\n    webpage_info = self._parse_json(self._search_json('window\\\\._preloads\\\\s*=\\\\s*JSON\\\\.parse\\\\(', webpage, 'json string', display_id, transform_source=js_to_json, contains_pattern='\"{(?s:.+)}\"'), display_id)\n    canonical_url = url\n    domain = traverse_obj(webpage_info, ('domainInfo', 'customDomain', {str}))\n    if domain:\n        canonical_url = urllib.parse.urlparse(url)._replace(netloc=domain).geturl()\n    post_type = webpage_info['post']['type']\n    (formats, subtitles) = ([], {})\n    if post_type == 'podcast':\n        (formats, subtitles) = ([{'url': webpage_info['post']['podcast_url']}], {})\n    elif post_type == 'video':\n        (formats, subtitles) = self._extract_video_formats(webpage_info['post']['videoUpload']['id'], canonical_url)\n    else:\n        self.raise_no_formats(f'Page type \"{post_type}\" is not supported')\n    return {'id': str(webpage_info['post']['id']), 'formats': formats, 'subtitles': subtitles, 'title': traverse_obj(webpage_info, ('post', 'title')), 'description': traverse_obj(webpage_info, ('post', 'description')), 'thumbnail': traverse_obj(webpage_info, ('post', 'cover_image')), 'uploader': traverse_obj(webpage_info, ('pub', 'name')), 'uploader_id': str_or_none(traverse_obj(webpage_info, ('post', 'publication_id'))), 'webpage_url': canonical_url}",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (display_id, username) = self._match_valid_url(url).group('id', 'username')\n    webpage = self._download_webpage(url, display_id)\n    webpage_info = self._parse_json(self._search_json('window\\\\._preloads\\\\s*=\\\\s*JSON\\\\.parse\\\\(', webpage, 'json string', display_id, transform_source=js_to_json, contains_pattern='\"{(?s:.+)}\"'), display_id)\n    canonical_url = url\n    domain = traverse_obj(webpage_info, ('domainInfo', 'customDomain', {str}))\n    if domain:\n        canonical_url = urllib.parse.urlparse(url)._replace(netloc=domain).geturl()\n    post_type = webpage_info['post']['type']\n    (formats, subtitles) = ([], {})\n    if post_type == 'podcast':\n        (formats, subtitles) = ([{'url': webpage_info['post']['podcast_url']}], {})\n    elif post_type == 'video':\n        (formats, subtitles) = self._extract_video_formats(webpage_info['post']['videoUpload']['id'], canonical_url)\n    else:\n        self.raise_no_formats(f'Page type \"{post_type}\" is not supported')\n    return {'id': str(webpage_info['post']['id']), 'formats': formats, 'subtitles': subtitles, 'title': traverse_obj(webpage_info, ('post', 'title')), 'description': traverse_obj(webpage_info, ('post', 'description')), 'thumbnail': traverse_obj(webpage_info, ('post', 'cover_image')), 'uploader': traverse_obj(webpage_info, ('pub', 'name')), 'uploader_id': str_or_none(traverse_obj(webpage_info, ('post', 'publication_id'))), 'webpage_url': canonical_url}",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (display_id, username) = self._match_valid_url(url).group('id', 'username')\n    webpage = self._download_webpage(url, display_id)\n    webpage_info = self._parse_json(self._search_json('window\\\\._preloads\\\\s*=\\\\s*JSON\\\\.parse\\\\(', webpage, 'json string', display_id, transform_source=js_to_json, contains_pattern='\"{(?s:.+)}\"'), display_id)\n    canonical_url = url\n    domain = traverse_obj(webpage_info, ('domainInfo', 'customDomain', {str}))\n    if domain:\n        canonical_url = urllib.parse.urlparse(url)._replace(netloc=domain).geturl()\n    post_type = webpage_info['post']['type']\n    (formats, subtitles) = ([], {})\n    if post_type == 'podcast':\n        (formats, subtitles) = ([{'url': webpage_info['post']['podcast_url']}], {})\n    elif post_type == 'video':\n        (formats, subtitles) = self._extract_video_formats(webpage_info['post']['videoUpload']['id'], canonical_url)\n    else:\n        self.raise_no_formats(f'Page type \"{post_type}\" is not supported')\n    return {'id': str(webpage_info['post']['id']), 'formats': formats, 'subtitles': subtitles, 'title': traverse_obj(webpage_info, ('post', 'title')), 'description': traverse_obj(webpage_info, ('post', 'description')), 'thumbnail': traverse_obj(webpage_info, ('post', 'cover_image')), 'uploader': traverse_obj(webpage_info, ('pub', 'name')), 'uploader_id': str_or_none(traverse_obj(webpage_info, ('post', 'publication_id'))), 'webpage_url': canonical_url}",
            "def _real_extract(self, url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (display_id, username) = self._match_valid_url(url).group('id', 'username')\n    webpage = self._download_webpage(url, display_id)\n    webpage_info = self._parse_json(self._search_json('window\\\\._preloads\\\\s*=\\\\s*JSON\\\\.parse\\\\(', webpage, 'json string', display_id, transform_source=js_to_json, contains_pattern='\"{(?s:.+)}\"'), display_id)\n    canonical_url = url\n    domain = traverse_obj(webpage_info, ('domainInfo', 'customDomain', {str}))\n    if domain:\n        canonical_url = urllib.parse.urlparse(url)._replace(netloc=domain).geturl()\n    post_type = webpage_info['post']['type']\n    (formats, subtitles) = ([], {})\n    if post_type == 'podcast':\n        (formats, subtitles) = ([{'url': webpage_info['post']['podcast_url']}], {})\n    elif post_type == 'video':\n        (formats, subtitles) = self._extract_video_formats(webpage_info['post']['videoUpload']['id'], canonical_url)\n    else:\n        self.raise_no_formats(f'Page type \"{post_type}\" is not supported')\n    return {'id': str(webpage_info['post']['id']), 'formats': formats, 'subtitles': subtitles, 'title': traverse_obj(webpage_info, ('post', 'title')), 'description': traverse_obj(webpage_info, ('post', 'description')), 'thumbnail': traverse_obj(webpage_info, ('post', 'cover_image')), 'uploader': traverse_obj(webpage_info, ('pub', 'name')), 'uploader_id': str_or_none(traverse_obj(webpage_info, ('post', 'publication_id'))), 'webpage_url': canonical_url}"
        ]
    }
]