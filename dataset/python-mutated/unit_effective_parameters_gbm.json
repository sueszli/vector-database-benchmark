[
    {
        "func_name": "test_gbm_effective_parameters",
        "original": "def test_gbm_effective_parameters():\n    cars = h2o.import_file(path=pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    cars['economy_20mpg'] = cars['economy_20mpg'].asfactor()\n    cars['year'] = cars['year'].asfactor()\n    predictors = ['displacement', 'power', 'weight', 'acceleration', 'year']\n    response = 'economy_20mpg'\n    (train, valid) = cars.split_frame(ratios=[0.8], seed=1234)\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5, distribution='bernoulli', stopping_metric='logloss', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] == gbm2.parms['stopping_metric']['actual_value']\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] is None\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n    assert gbm1.parms['fold_assignment']['actual_value'] == gbm2.parms['fold_assignment']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    try:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'false'))\n        gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n        gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n        gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n        assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n        assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n        assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n        assert gbm1.parms['stopping_metric']['actual_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['actual_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['actual_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['actual_value'] == 'AUTO'\n    finally:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'true'))\n    frame = h2o.import_file(path=pyunit_utils.locate('smalldata/prostate/prostate.csv'))\n    frame.pop('ID')\n    frame[frame['VOL'], 'VOL'] = None\n    frame[frame['GLEASON'], 'GLEASON'] = None\n    r = frame.runif()\n    train = frame[r < 0.8]\n    test = frame[r >= 0.8]\n    gbm = H2OGradientBoostingEstimator(ntrees=5, max_depth=3)\n    gbm.train(x=list(range(2, train.ncol)), y='CAPSULE', training_frame=train, validation_frame=test)\n    assert gbm.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm.parms['categorical_encoding']['actual_value'] == 'Enum'",
        "mutated": [
            "def test_gbm_effective_parameters():\n    if False:\n        i = 10\n    cars = h2o.import_file(path=pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    cars['economy_20mpg'] = cars['economy_20mpg'].asfactor()\n    cars['year'] = cars['year'].asfactor()\n    predictors = ['displacement', 'power', 'weight', 'acceleration', 'year']\n    response = 'economy_20mpg'\n    (train, valid) = cars.split_frame(ratios=[0.8], seed=1234)\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5, distribution='bernoulli', stopping_metric='logloss', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] == gbm2.parms['stopping_metric']['actual_value']\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] is None\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n    assert gbm1.parms['fold_assignment']['actual_value'] == gbm2.parms['fold_assignment']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    try:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'false'))\n        gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n        gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n        gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n        assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n        assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n        assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n        assert gbm1.parms['stopping_metric']['actual_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['actual_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['actual_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['actual_value'] == 'AUTO'\n    finally:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'true'))\n    frame = h2o.import_file(path=pyunit_utils.locate('smalldata/prostate/prostate.csv'))\n    frame.pop('ID')\n    frame[frame['VOL'], 'VOL'] = None\n    frame[frame['GLEASON'], 'GLEASON'] = None\n    r = frame.runif()\n    train = frame[r < 0.8]\n    test = frame[r >= 0.8]\n    gbm = H2OGradientBoostingEstimator(ntrees=5, max_depth=3)\n    gbm.train(x=list(range(2, train.ncol)), y='CAPSULE', training_frame=train, validation_frame=test)\n    assert gbm.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm.parms['categorical_encoding']['actual_value'] == 'Enum'",
            "def test_gbm_effective_parameters():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cars = h2o.import_file(path=pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    cars['economy_20mpg'] = cars['economy_20mpg'].asfactor()\n    cars['year'] = cars['year'].asfactor()\n    predictors = ['displacement', 'power', 'weight', 'acceleration', 'year']\n    response = 'economy_20mpg'\n    (train, valid) = cars.split_frame(ratios=[0.8], seed=1234)\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5, distribution='bernoulli', stopping_metric='logloss', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] == gbm2.parms['stopping_metric']['actual_value']\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] is None\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n    assert gbm1.parms['fold_assignment']['actual_value'] == gbm2.parms['fold_assignment']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    try:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'false'))\n        gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n        gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n        gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n        assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n        assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n        assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n        assert gbm1.parms['stopping_metric']['actual_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['actual_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['actual_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['actual_value'] == 'AUTO'\n    finally:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'true'))\n    frame = h2o.import_file(path=pyunit_utils.locate('smalldata/prostate/prostate.csv'))\n    frame.pop('ID')\n    frame[frame['VOL'], 'VOL'] = None\n    frame[frame['GLEASON'], 'GLEASON'] = None\n    r = frame.runif()\n    train = frame[r < 0.8]\n    test = frame[r >= 0.8]\n    gbm = H2OGradientBoostingEstimator(ntrees=5, max_depth=3)\n    gbm.train(x=list(range(2, train.ncol)), y='CAPSULE', training_frame=train, validation_frame=test)\n    assert gbm.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm.parms['categorical_encoding']['actual_value'] == 'Enum'",
            "def test_gbm_effective_parameters():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cars = h2o.import_file(path=pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    cars['economy_20mpg'] = cars['economy_20mpg'].asfactor()\n    cars['year'] = cars['year'].asfactor()\n    predictors = ['displacement', 'power', 'weight', 'acceleration', 'year']\n    response = 'economy_20mpg'\n    (train, valid) = cars.split_frame(ratios=[0.8], seed=1234)\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5, distribution='bernoulli', stopping_metric='logloss', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] == gbm2.parms['stopping_metric']['actual_value']\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] is None\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n    assert gbm1.parms['fold_assignment']['actual_value'] == gbm2.parms['fold_assignment']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    try:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'false'))\n        gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n        gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n        gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n        assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n        assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n        assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n        assert gbm1.parms['stopping_metric']['actual_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['actual_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['actual_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['actual_value'] == 'AUTO'\n    finally:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'true'))\n    frame = h2o.import_file(path=pyunit_utils.locate('smalldata/prostate/prostate.csv'))\n    frame.pop('ID')\n    frame[frame['VOL'], 'VOL'] = None\n    frame[frame['GLEASON'], 'GLEASON'] = None\n    r = frame.runif()\n    train = frame[r < 0.8]\n    test = frame[r >= 0.8]\n    gbm = H2OGradientBoostingEstimator(ntrees=5, max_depth=3)\n    gbm.train(x=list(range(2, train.ncol)), y='CAPSULE', training_frame=train, validation_frame=test)\n    assert gbm.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm.parms['categorical_encoding']['actual_value'] == 'Enum'",
            "def test_gbm_effective_parameters():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cars = h2o.import_file(path=pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    cars['economy_20mpg'] = cars['economy_20mpg'].asfactor()\n    cars['year'] = cars['year'].asfactor()\n    predictors = ['displacement', 'power', 'weight', 'acceleration', 'year']\n    response = 'economy_20mpg'\n    (train, valid) = cars.split_frame(ratios=[0.8], seed=1234)\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5, distribution='bernoulli', stopping_metric='logloss', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] == gbm2.parms['stopping_metric']['actual_value']\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] is None\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n    assert gbm1.parms['fold_assignment']['actual_value'] == gbm2.parms['fold_assignment']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    try:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'false'))\n        gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n        gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n        gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n        assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n        assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n        assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n        assert gbm1.parms['stopping_metric']['actual_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['actual_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['actual_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['actual_value'] == 'AUTO'\n    finally:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'true'))\n    frame = h2o.import_file(path=pyunit_utils.locate('smalldata/prostate/prostate.csv'))\n    frame.pop('ID')\n    frame[frame['VOL'], 'VOL'] = None\n    frame[frame['GLEASON'], 'GLEASON'] = None\n    r = frame.runif()\n    train = frame[r < 0.8]\n    test = frame[r >= 0.8]\n    gbm = H2OGradientBoostingEstimator(ntrees=5, max_depth=3)\n    gbm.train(x=list(range(2, train.ncol)), y='CAPSULE', training_frame=train, validation_frame=test)\n    assert gbm.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm.parms['categorical_encoding']['actual_value'] == 'Enum'",
            "def test_gbm_effective_parameters():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cars = h2o.import_file(path=pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    cars['economy_20mpg'] = cars['economy_20mpg'].asfactor()\n    cars['year'] = cars['year'].asfactor()\n    predictors = ['displacement', 'power', 'weight', 'acceleration', 'year']\n    response = 'economy_20mpg'\n    (train, valid) = cars.split_frame(ratios=[0.8], seed=1234)\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, stopping_rounds=3, score_tree_interval=5, distribution='bernoulli', stopping_metric='logloss', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] == gbm2.parms['stopping_metric']['actual_value']\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n    gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n    gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n    np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n    assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n    assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n    assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n    assert gbm1.parms['stopping_metric']['actual_value'] is None\n    assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n    assert gbm1.parms['histogram_type']['actual_value'] == gbm2.parms['histogram_type']['actual_value']\n    assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n    assert gbm1.parms['fold_assignment']['actual_value'] == gbm2.parms['fold_assignment']['actual_value']\n    assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm1.parms['categorical_encoding']['actual_value'] == gbm2.parms['categorical_encoding']['actual_value']\n    try:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'false'))\n        gbm1 = H2OGradientBoostingEstimator(seed=1234, nfolds=5)\n        gbm1.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        gbm2 = H2OGradientBoostingEstimator(seed=1234, nfolds=5, fold_assignment='Random', distribution='bernoulli', histogram_type='UniformAdaptive', categorical_encoding='Enum')\n        gbm2.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n        np.testing.assert_almost_equal(gbm1.logloss(), gbm2.logloss())\n        assert gbm1.parms['distribution']['input_value'] == 'AUTO'\n        assert gbm1.parms['distribution']['actual_value'] == gbm2.parms['distribution']['actual_value']\n        assert gbm1.parms['stopping_metric']['input_value'] == 'AUTO'\n        assert gbm1.parms['stopping_metric']['actual_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['input_value'] == 'AUTO'\n        assert gbm1.parms['histogram_type']['actual_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['input_value'] == 'AUTO'\n        assert gbm1.parms['fold_assignment']['actual_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['input_value'] == 'AUTO'\n        assert gbm1.parms['categorical_encoding']['actual_value'] == 'AUTO'\n    finally:\n        h2o.rapids('(setproperty \"{}\" \"{}\")'.format('sys.ai.h2o.algos.evaluate_auto_model_parameters', 'true'))\n    frame = h2o.import_file(path=pyunit_utils.locate('smalldata/prostate/prostate.csv'))\n    frame.pop('ID')\n    frame[frame['VOL'], 'VOL'] = None\n    frame[frame['GLEASON'], 'GLEASON'] = None\n    r = frame.runif()\n    train = frame[r < 0.8]\n    test = frame[r >= 0.8]\n    gbm = H2OGradientBoostingEstimator(ntrees=5, max_depth=3)\n    gbm.train(x=list(range(2, train.ncol)), y='CAPSULE', training_frame=train, validation_frame=test)\n    assert gbm.parms['categorical_encoding']['input_value'] == 'AUTO'\n    assert gbm.parms['categorical_encoding']['actual_value'] == 'Enum'"
        ]
    }
]