[
    {
        "func_name": "make_dagster_job_from_airflow_dag",
        "original": "def make_dagster_job_from_airflow_dag(dag: DAG, tags: Optional[Mapping[str, str]]=None, connections: Optional[List[Connection]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]={}) -> JobDefinition:\n    \"\"\"Construct a Dagster job corresponding to a given Airflow DAG.\n\n    Tasks in the resulting job will execute the ``execute()`` method on the corresponding\n    Airflow Operator. Dagster, any dependencies required by Airflow Operators, and the module\n    containing your DAG definition must be available in the Python environment within which your\n    Dagster solids execute.\n\n    To set Airflow's ``execution_date`` for use with Airflow Operator's ``execute()`` methods,\n    either:\n\n    1. (Best for ad hoc runs) Execute job directly. This will set execution_date to the\n        time (in UTC) of the run.\n\n    2. Add ``{'airflow_execution_date': utc_date_string}`` to the job tags. This will override\n        behavior from (1).\n\n        .. code-block:: python\n\n            my_dagster_job = make_dagster_job_from_airflow_dag(\n                    dag=dag,\n                    tags={'airflow_execution_date': utc_execution_date_str}\n            )\n            my_dagster_job.execute_in_process()\n\n    3. (Recommended) Add ``{'airflow_execution_date': utc_date_string}`` to the run tags,\n        such as in the Dagster UI. This will override behavior from (1) and (2)\n\n\n    We apply normalized_name() to the dag id and task ids when generating job name and op\n    names to ensure that names conform to Dagster's naming conventions.\n\n    Args:\n        dag (DAG): The Airflow DAG to compile into a Dagster job\n        tags (Dict[str, Field]): Job tags. Optionally include\n            `tags={'airflow_execution_date': utc_date_string}` to specify execution_date used within\n            execution of Airflow Operators.\n        connections (List[Connection]): List of Airflow Connections to be created in the Ephemeral\n            Airflow DB, if use_emphemeral_airflow_db is False this will be ignored.\n\n    Returns:\n        JobDefinition: The generated Dagster job\n\n    \"\"\"\n    check.inst_param(dag, 'dag', DAG)\n    tags = check.opt_mapping_param(tags, 'tags')\n    connections = check.opt_list_param(connections, 'connections', of_type=Connection)\n    mutated_tags = dict(tags)\n    if IS_AIRFLOW_INGEST_PIPELINE_STR not in tags:\n        mutated_tags[IS_AIRFLOW_INGEST_PIPELINE_STR] = 'true'\n    mutated_tags = validate_tags(mutated_tags)\n    (node_dependencies, node_defs) = get_graph_definition_args(dag=dag)\n    graph_def = GraphDefinition(name=normalized_name(dag.dag_id), description='', node_defs=node_defs, dependencies=node_dependencies, tags=mutated_tags)\n    if resource_defs is None or 'airflow_db' not in resource_defs:\n        resource_defs = dict(resource_defs) if resource_defs else {}\n        resource_defs['airflow_db'] = make_ephemeral_airflow_db_resource(connections=connections)\n    job_def = JobDefinition(name=normalized_name(dag.dag_id), description='', graph_def=graph_def, resource_defs=resource_defs, tags=mutated_tags, metadata={}, op_retry_policy=None, version_strategy=None)\n    return job_def",
        "mutated": [
            "def make_dagster_job_from_airflow_dag(dag: DAG, tags: Optional[Mapping[str, str]]=None, connections: Optional[List[Connection]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]={}) -> JobDefinition:\n    if False:\n        i = 10\n    \"Construct a Dagster job corresponding to a given Airflow DAG.\\n\\n    Tasks in the resulting job will execute the ``execute()`` method on the corresponding\\n    Airflow Operator. Dagster, any dependencies required by Airflow Operators, and the module\\n    containing your DAG definition must be available in the Python environment within which your\\n    Dagster solids execute.\\n\\n    To set Airflow's ``execution_date`` for use with Airflow Operator's ``execute()`` methods,\\n    either:\\n\\n    1. (Best for ad hoc runs) Execute job directly. This will set execution_date to the\\n        time (in UTC) of the run.\\n\\n    2. Add ``{'airflow_execution_date': utc_date_string}`` to the job tags. This will override\\n        behavior from (1).\\n\\n        .. code-block:: python\\n\\n            my_dagster_job = make_dagster_job_from_airflow_dag(\\n                    dag=dag,\\n                    tags={'airflow_execution_date': utc_execution_date_str}\\n            )\\n            my_dagster_job.execute_in_process()\\n\\n    3. (Recommended) Add ``{'airflow_execution_date': utc_date_string}`` to the run tags,\\n        such as in the Dagster UI. This will override behavior from (1) and (2)\\n\\n\\n    We apply normalized_name() to the dag id and task ids when generating job name and op\\n    names to ensure that names conform to Dagster's naming conventions.\\n\\n    Args:\\n        dag (DAG): The Airflow DAG to compile into a Dagster job\\n        tags (Dict[str, Field]): Job tags. Optionally include\\n            `tags={'airflow_execution_date': utc_date_string}` to specify execution_date used within\\n            execution of Airflow Operators.\\n        connections (List[Connection]): List of Airflow Connections to be created in the Ephemeral\\n            Airflow DB, if use_emphemeral_airflow_db is False this will be ignored.\\n\\n    Returns:\\n        JobDefinition: The generated Dagster job\\n\\n    \"\n    check.inst_param(dag, 'dag', DAG)\n    tags = check.opt_mapping_param(tags, 'tags')\n    connections = check.opt_list_param(connections, 'connections', of_type=Connection)\n    mutated_tags = dict(tags)\n    if IS_AIRFLOW_INGEST_PIPELINE_STR not in tags:\n        mutated_tags[IS_AIRFLOW_INGEST_PIPELINE_STR] = 'true'\n    mutated_tags = validate_tags(mutated_tags)\n    (node_dependencies, node_defs) = get_graph_definition_args(dag=dag)\n    graph_def = GraphDefinition(name=normalized_name(dag.dag_id), description='', node_defs=node_defs, dependencies=node_dependencies, tags=mutated_tags)\n    if resource_defs is None or 'airflow_db' not in resource_defs:\n        resource_defs = dict(resource_defs) if resource_defs else {}\n        resource_defs['airflow_db'] = make_ephemeral_airflow_db_resource(connections=connections)\n    job_def = JobDefinition(name=normalized_name(dag.dag_id), description='', graph_def=graph_def, resource_defs=resource_defs, tags=mutated_tags, metadata={}, op_retry_policy=None, version_strategy=None)\n    return job_def",
            "def make_dagster_job_from_airflow_dag(dag: DAG, tags: Optional[Mapping[str, str]]=None, connections: Optional[List[Connection]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]={}) -> JobDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Construct a Dagster job corresponding to a given Airflow DAG.\\n\\n    Tasks in the resulting job will execute the ``execute()`` method on the corresponding\\n    Airflow Operator. Dagster, any dependencies required by Airflow Operators, and the module\\n    containing your DAG definition must be available in the Python environment within which your\\n    Dagster solids execute.\\n\\n    To set Airflow's ``execution_date`` for use with Airflow Operator's ``execute()`` methods,\\n    either:\\n\\n    1. (Best for ad hoc runs) Execute job directly. This will set execution_date to the\\n        time (in UTC) of the run.\\n\\n    2. Add ``{'airflow_execution_date': utc_date_string}`` to the job tags. This will override\\n        behavior from (1).\\n\\n        .. code-block:: python\\n\\n            my_dagster_job = make_dagster_job_from_airflow_dag(\\n                    dag=dag,\\n                    tags={'airflow_execution_date': utc_execution_date_str}\\n            )\\n            my_dagster_job.execute_in_process()\\n\\n    3. (Recommended) Add ``{'airflow_execution_date': utc_date_string}`` to the run tags,\\n        such as in the Dagster UI. This will override behavior from (1) and (2)\\n\\n\\n    We apply normalized_name() to the dag id and task ids when generating job name and op\\n    names to ensure that names conform to Dagster's naming conventions.\\n\\n    Args:\\n        dag (DAG): The Airflow DAG to compile into a Dagster job\\n        tags (Dict[str, Field]): Job tags. Optionally include\\n            `tags={'airflow_execution_date': utc_date_string}` to specify execution_date used within\\n            execution of Airflow Operators.\\n        connections (List[Connection]): List of Airflow Connections to be created in the Ephemeral\\n            Airflow DB, if use_emphemeral_airflow_db is False this will be ignored.\\n\\n    Returns:\\n        JobDefinition: The generated Dagster job\\n\\n    \"\n    check.inst_param(dag, 'dag', DAG)\n    tags = check.opt_mapping_param(tags, 'tags')\n    connections = check.opt_list_param(connections, 'connections', of_type=Connection)\n    mutated_tags = dict(tags)\n    if IS_AIRFLOW_INGEST_PIPELINE_STR not in tags:\n        mutated_tags[IS_AIRFLOW_INGEST_PIPELINE_STR] = 'true'\n    mutated_tags = validate_tags(mutated_tags)\n    (node_dependencies, node_defs) = get_graph_definition_args(dag=dag)\n    graph_def = GraphDefinition(name=normalized_name(dag.dag_id), description='', node_defs=node_defs, dependencies=node_dependencies, tags=mutated_tags)\n    if resource_defs is None or 'airflow_db' not in resource_defs:\n        resource_defs = dict(resource_defs) if resource_defs else {}\n        resource_defs['airflow_db'] = make_ephemeral_airflow_db_resource(connections=connections)\n    job_def = JobDefinition(name=normalized_name(dag.dag_id), description='', graph_def=graph_def, resource_defs=resource_defs, tags=mutated_tags, metadata={}, op_retry_policy=None, version_strategy=None)\n    return job_def",
            "def make_dagster_job_from_airflow_dag(dag: DAG, tags: Optional[Mapping[str, str]]=None, connections: Optional[List[Connection]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]={}) -> JobDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Construct a Dagster job corresponding to a given Airflow DAG.\\n\\n    Tasks in the resulting job will execute the ``execute()`` method on the corresponding\\n    Airflow Operator. Dagster, any dependencies required by Airflow Operators, and the module\\n    containing your DAG definition must be available in the Python environment within which your\\n    Dagster solids execute.\\n\\n    To set Airflow's ``execution_date`` for use with Airflow Operator's ``execute()`` methods,\\n    either:\\n\\n    1. (Best for ad hoc runs) Execute job directly. This will set execution_date to the\\n        time (in UTC) of the run.\\n\\n    2. Add ``{'airflow_execution_date': utc_date_string}`` to the job tags. This will override\\n        behavior from (1).\\n\\n        .. code-block:: python\\n\\n            my_dagster_job = make_dagster_job_from_airflow_dag(\\n                    dag=dag,\\n                    tags={'airflow_execution_date': utc_execution_date_str}\\n            )\\n            my_dagster_job.execute_in_process()\\n\\n    3. (Recommended) Add ``{'airflow_execution_date': utc_date_string}`` to the run tags,\\n        such as in the Dagster UI. This will override behavior from (1) and (2)\\n\\n\\n    We apply normalized_name() to the dag id and task ids when generating job name and op\\n    names to ensure that names conform to Dagster's naming conventions.\\n\\n    Args:\\n        dag (DAG): The Airflow DAG to compile into a Dagster job\\n        tags (Dict[str, Field]): Job tags. Optionally include\\n            `tags={'airflow_execution_date': utc_date_string}` to specify execution_date used within\\n            execution of Airflow Operators.\\n        connections (List[Connection]): List of Airflow Connections to be created in the Ephemeral\\n            Airflow DB, if use_emphemeral_airflow_db is False this will be ignored.\\n\\n    Returns:\\n        JobDefinition: The generated Dagster job\\n\\n    \"\n    check.inst_param(dag, 'dag', DAG)\n    tags = check.opt_mapping_param(tags, 'tags')\n    connections = check.opt_list_param(connections, 'connections', of_type=Connection)\n    mutated_tags = dict(tags)\n    if IS_AIRFLOW_INGEST_PIPELINE_STR not in tags:\n        mutated_tags[IS_AIRFLOW_INGEST_PIPELINE_STR] = 'true'\n    mutated_tags = validate_tags(mutated_tags)\n    (node_dependencies, node_defs) = get_graph_definition_args(dag=dag)\n    graph_def = GraphDefinition(name=normalized_name(dag.dag_id), description='', node_defs=node_defs, dependencies=node_dependencies, tags=mutated_tags)\n    if resource_defs is None or 'airflow_db' not in resource_defs:\n        resource_defs = dict(resource_defs) if resource_defs else {}\n        resource_defs['airflow_db'] = make_ephemeral_airflow_db_resource(connections=connections)\n    job_def = JobDefinition(name=normalized_name(dag.dag_id), description='', graph_def=graph_def, resource_defs=resource_defs, tags=mutated_tags, metadata={}, op_retry_policy=None, version_strategy=None)\n    return job_def",
            "def make_dagster_job_from_airflow_dag(dag: DAG, tags: Optional[Mapping[str, str]]=None, connections: Optional[List[Connection]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]={}) -> JobDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Construct a Dagster job corresponding to a given Airflow DAG.\\n\\n    Tasks in the resulting job will execute the ``execute()`` method on the corresponding\\n    Airflow Operator. Dagster, any dependencies required by Airflow Operators, and the module\\n    containing your DAG definition must be available in the Python environment within which your\\n    Dagster solids execute.\\n\\n    To set Airflow's ``execution_date`` for use with Airflow Operator's ``execute()`` methods,\\n    either:\\n\\n    1. (Best for ad hoc runs) Execute job directly. This will set execution_date to the\\n        time (in UTC) of the run.\\n\\n    2. Add ``{'airflow_execution_date': utc_date_string}`` to the job tags. This will override\\n        behavior from (1).\\n\\n        .. code-block:: python\\n\\n            my_dagster_job = make_dagster_job_from_airflow_dag(\\n                    dag=dag,\\n                    tags={'airflow_execution_date': utc_execution_date_str}\\n            )\\n            my_dagster_job.execute_in_process()\\n\\n    3. (Recommended) Add ``{'airflow_execution_date': utc_date_string}`` to the run tags,\\n        such as in the Dagster UI. This will override behavior from (1) and (2)\\n\\n\\n    We apply normalized_name() to the dag id and task ids when generating job name and op\\n    names to ensure that names conform to Dagster's naming conventions.\\n\\n    Args:\\n        dag (DAG): The Airflow DAG to compile into a Dagster job\\n        tags (Dict[str, Field]): Job tags. Optionally include\\n            `tags={'airflow_execution_date': utc_date_string}` to specify execution_date used within\\n            execution of Airflow Operators.\\n        connections (List[Connection]): List of Airflow Connections to be created in the Ephemeral\\n            Airflow DB, if use_emphemeral_airflow_db is False this will be ignored.\\n\\n    Returns:\\n        JobDefinition: The generated Dagster job\\n\\n    \"\n    check.inst_param(dag, 'dag', DAG)\n    tags = check.opt_mapping_param(tags, 'tags')\n    connections = check.opt_list_param(connections, 'connections', of_type=Connection)\n    mutated_tags = dict(tags)\n    if IS_AIRFLOW_INGEST_PIPELINE_STR not in tags:\n        mutated_tags[IS_AIRFLOW_INGEST_PIPELINE_STR] = 'true'\n    mutated_tags = validate_tags(mutated_tags)\n    (node_dependencies, node_defs) = get_graph_definition_args(dag=dag)\n    graph_def = GraphDefinition(name=normalized_name(dag.dag_id), description='', node_defs=node_defs, dependencies=node_dependencies, tags=mutated_tags)\n    if resource_defs is None or 'airflow_db' not in resource_defs:\n        resource_defs = dict(resource_defs) if resource_defs else {}\n        resource_defs['airflow_db'] = make_ephemeral_airflow_db_resource(connections=connections)\n    job_def = JobDefinition(name=normalized_name(dag.dag_id), description='', graph_def=graph_def, resource_defs=resource_defs, tags=mutated_tags, metadata={}, op_retry_policy=None, version_strategy=None)\n    return job_def",
            "def make_dagster_job_from_airflow_dag(dag: DAG, tags: Optional[Mapping[str, str]]=None, connections: Optional[List[Connection]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]={}) -> JobDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Construct a Dagster job corresponding to a given Airflow DAG.\\n\\n    Tasks in the resulting job will execute the ``execute()`` method on the corresponding\\n    Airflow Operator. Dagster, any dependencies required by Airflow Operators, and the module\\n    containing your DAG definition must be available in the Python environment within which your\\n    Dagster solids execute.\\n\\n    To set Airflow's ``execution_date`` for use with Airflow Operator's ``execute()`` methods,\\n    either:\\n\\n    1. (Best for ad hoc runs) Execute job directly. This will set execution_date to the\\n        time (in UTC) of the run.\\n\\n    2. Add ``{'airflow_execution_date': utc_date_string}`` to the job tags. This will override\\n        behavior from (1).\\n\\n        .. code-block:: python\\n\\n            my_dagster_job = make_dagster_job_from_airflow_dag(\\n                    dag=dag,\\n                    tags={'airflow_execution_date': utc_execution_date_str}\\n            )\\n            my_dagster_job.execute_in_process()\\n\\n    3. (Recommended) Add ``{'airflow_execution_date': utc_date_string}`` to the run tags,\\n        such as in the Dagster UI. This will override behavior from (1) and (2)\\n\\n\\n    We apply normalized_name() to the dag id and task ids when generating job name and op\\n    names to ensure that names conform to Dagster's naming conventions.\\n\\n    Args:\\n        dag (DAG): The Airflow DAG to compile into a Dagster job\\n        tags (Dict[str, Field]): Job tags. Optionally include\\n            `tags={'airflow_execution_date': utc_date_string}` to specify execution_date used within\\n            execution of Airflow Operators.\\n        connections (List[Connection]): List of Airflow Connections to be created in the Ephemeral\\n            Airflow DB, if use_emphemeral_airflow_db is False this will be ignored.\\n\\n    Returns:\\n        JobDefinition: The generated Dagster job\\n\\n    \"\n    check.inst_param(dag, 'dag', DAG)\n    tags = check.opt_mapping_param(tags, 'tags')\n    connections = check.opt_list_param(connections, 'connections', of_type=Connection)\n    mutated_tags = dict(tags)\n    if IS_AIRFLOW_INGEST_PIPELINE_STR not in tags:\n        mutated_tags[IS_AIRFLOW_INGEST_PIPELINE_STR] = 'true'\n    mutated_tags = validate_tags(mutated_tags)\n    (node_dependencies, node_defs) = get_graph_definition_args(dag=dag)\n    graph_def = GraphDefinition(name=normalized_name(dag.dag_id), description='', node_defs=node_defs, dependencies=node_dependencies, tags=mutated_tags)\n    if resource_defs is None or 'airflow_db' not in resource_defs:\n        resource_defs = dict(resource_defs) if resource_defs else {}\n        resource_defs['airflow_db'] = make_ephemeral_airflow_db_resource(connections=connections)\n    job_def = JobDefinition(name=normalized_name(dag.dag_id), description='', graph_def=graph_def, resource_defs=resource_defs, tags=mutated_tags, metadata={}, op_retry_policy=None, version_strategy=None)\n    return job_def"
        ]
    }
]