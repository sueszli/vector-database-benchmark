[
    {
        "func_name": "__init__",
        "original": "def __init__(self) -> None:\n    self.output_file = ''\n    self.html = False\n    self.gpu = False",
        "mutated": [
            "def __init__(self) -> None:\n    if False:\n        i = 10\n    self.output_file = ''\n    self.html = False\n    self.gpu = False",
            "def __init__(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.output_file = ''\n    self.html = False\n    self.gpu = False",
            "def __init__(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.output_file = ''\n    self.html = False\n    self.gpu = False",
            "def __init__(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.output_file = ''\n    self.html = False\n    self.gpu = False",
            "def __init__(self) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.output_file = ''\n    self.html = False\n    self.gpu = False"
        ]
    },
    {
        "func_name": "output_top_memory",
        "original": "def output_top_memory(self, title: str, console: Console, mallocs: Dict[LineNumber, float]) -> None:\n    if mallocs:\n        printed_header = False\n        number = 1\n        print_top_mallocs_count = 5\n        print_top_mallocs_threshold_mb = 1\n        for (malloc_lineno, value) in mallocs.items():\n            if value <= print_top_mallocs_threshold_mb:\n                break\n            if number > print_top_mallocs_count:\n                break\n            if not printed_header:\n                console.print(title)\n                printed_header = True\n            output_str = f'({str(number)}) {malloc_lineno:5.0f}: {mallocs[malloc_lineno]:5.0f} MB'\n            console.print(Markdown(output_str, style=self.memory_color))\n            number += 1",
        "mutated": [
            "def output_top_memory(self, title: str, console: Console, mallocs: Dict[LineNumber, float]) -> None:\n    if False:\n        i = 10\n    if mallocs:\n        printed_header = False\n        number = 1\n        print_top_mallocs_count = 5\n        print_top_mallocs_threshold_mb = 1\n        for (malloc_lineno, value) in mallocs.items():\n            if value <= print_top_mallocs_threshold_mb:\n                break\n            if number > print_top_mallocs_count:\n                break\n            if not printed_header:\n                console.print(title)\n                printed_header = True\n            output_str = f'({str(number)}) {malloc_lineno:5.0f}: {mallocs[malloc_lineno]:5.0f} MB'\n            console.print(Markdown(output_str, style=self.memory_color))\n            number += 1",
            "def output_top_memory(self, title: str, console: Console, mallocs: Dict[LineNumber, float]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if mallocs:\n        printed_header = False\n        number = 1\n        print_top_mallocs_count = 5\n        print_top_mallocs_threshold_mb = 1\n        for (malloc_lineno, value) in mallocs.items():\n            if value <= print_top_mallocs_threshold_mb:\n                break\n            if number > print_top_mallocs_count:\n                break\n            if not printed_header:\n                console.print(title)\n                printed_header = True\n            output_str = f'({str(number)}) {malloc_lineno:5.0f}: {mallocs[malloc_lineno]:5.0f} MB'\n            console.print(Markdown(output_str, style=self.memory_color))\n            number += 1",
            "def output_top_memory(self, title: str, console: Console, mallocs: Dict[LineNumber, float]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if mallocs:\n        printed_header = False\n        number = 1\n        print_top_mallocs_count = 5\n        print_top_mallocs_threshold_mb = 1\n        for (malloc_lineno, value) in mallocs.items():\n            if value <= print_top_mallocs_threshold_mb:\n                break\n            if number > print_top_mallocs_count:\n                break\n            if not printed_header:\n                console.print(title)\n                printed_header = True\n            output_str = f'({str(number)}) {malloc_lineno:5.0f}: {mallocs[malloc_lineno]:5.0f} MB'\n            console.print(Markdown(output_str, style=self.memory_color))\n            number += 1",
            "def output_top_memory(self, title: str, console: Console, mallocs: Dict[LineNumber, float]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if mallocs:\n        printed_header = False\n        number = 1\n        print_top_mallocs_count = 5\n        print_top_mallocs_threshold_mb = 1\n        for (malloc_lineno, value) in mallocs.items():\n            if value <= print_top_mallocs_threshold_mb:\n                break\n            if number > print_top_mallocs_count:\n                break\n            if not printed_header:\n                console.print(title)\n                printed_header = True\n            output_str = f'({str(number)}) {malloc_lineno:5.0f}: {mallocs[malloc_lineno]:5.0f} MB'\n            console.print(Markdown(output_str, style=self.memory_color))\n            number += 1",
            "def output_top_memory(self, title: str, console: Console, mallocs: Dict[LineNumber, float]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if mallocs:\n        printed_header = False\n        number = 1\n        print_top_mallocs_count = 5\n        print_top_mallocs_threshold_mb = 1\n        for (malloc_lineno, value) in mallocs.items():\n            if value <= print_top_mallocs_threshold_mb:\n                break\n            if number > print_top_mallocs_count:\n                break\n            if not printed_header:\n                console.print(title)\n                printed_header = True\n            output_str = f'({str(number)}) {malloc_lineno:5.0f}: {mallocs[malloc_lineno]:5.0f} MB'\n            console.print(Markdown(output_str, style=self.memory_color))\n            number += 1"
        ]
    },
    {
        "func_name": "output_profile_line",
        "original": "def output_profile_line(self, json: ScaleneJSON, fname: Filename, line_no: LineNumber, line: SyntaxLine, console: Console, tbl: Table, stats: ScaleneStatistics, profile_this_code: Callable[[Filename, LineNumber], bool], force_print: bool=False, suppress_lineno_print: bool=False, is_function_summary: bool=False, profile_memory: bool=False, reduced_profile: bool=False) -> bool:\n    \"\"\"Print at most one line of the profile (true == printed one).\"\"\"\n    obj = json.output_profile_line(fname=fname, fname_print=fname, line_no=line_no, line=line, stats=stats, profile_this_code=profile_this_code, force_print=force_print)\n    if not obj:\n        return False\n    if -1 < obj['n_peak_mb'] < 1:\n        obj['n_peak_mb'] = 0\n    n_cpu_percent_c_str: str = '' if obj['n_cpu_percent_c'] < 1 else f\"{obj['n_cpu_percent_c']:5.0f}%\"\n    n_gpu_percent_str: str = '' if obj['n_gpu_percent'] < 1 else f\"{obj['n_gpu_percent']:3.0f}%\"\n    n_cpu_percent_python_str: str = '' if obj['n_cpu_percent_python'] < 1 else f\"{obj['n_cpu_percent_python']:5.0f}%\"\n    n_growth_mem_str = ''\n    if obj['n_peak_mb'] < 1024:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb']:5.0f}M\"\n    else:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb'] / 1024:5.2f}G\"\n    sys_str: str = '' if obj['n_sys_percent'] < 1 else f\"{obj['n_sys_percent']:4.0f}%\"\n    if not is_function_summary:\n        print_line_no = '' if suppress_lineno_print else str(line_no)\n    else:\n        print_line_no = '' if fname not in stats.firstline_map else str(stats.firstline_map[fname])\n    if profile_memory:\n        spark_str: str = ''\n        samples = obj['memory_samples']\n        if len(samples) > ScaleneOutput.max_sparkline_len_line:\n            random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_line))\n        else:\n            random_samples = samples\n        sparkline_samples = [random_samples[i][1] * obj['n_usage_fraction'] for i in range(len(random_samples))]\n        if random_samples:\n            (_, _, spark_str) = sparkline.generate(sparkline_samples, 0, stats.max_footprint)\n        ncpps: Any = ''\n        ncpcs: Any = ''\n        nufs: Any = ''\n        ngpus: Any = ''\n        n_usage_fraction_str: str = '' if obj['n_usage_fraction'] < 0.01 else f\"{100 * obj['n_usage_fraction']:4.0f}%\"\n        if obj['n_usage_fraction'] >= self.highlight_percentage or obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            nufs = Text.assemble((spark_str + n_usage_fraction_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n            nufs = spark_str + n_usage_fraction_str\n        if reduced_profile and (not ncpps + ncpcs + nufs + ngpus):\n            return False\n        n_python_fraction_str: str = '' if obj['n_python_fraction'] < 0.01 else f\"{obj['n_python_fraction'] * 100:4.0f}%\"\n        n_copy_mb_s_str: str = '' if obj['n_copy_mb_s'] < 0.5 else f\"{obj['n_copy_mb_s']:6.0f}\"\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n    else:\n        if obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n        if reduced_profile and (not ncpps + ncpcs + ngpus):\n            return False\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, line)\n    return True",
        "mutated": [
            "def output_profile_line(self, json: ScaleneJSON, fname: Filename, line_no: LineNumber, line: SyntaxLine, console: Console, tbl: Table, stats: ScaleneStatistics, profile_this_code: Callable[[Filename, LineNumber], bool], force_print: bool=False, suppress_lineno_print: bool=False, is_function_summary: bool=False, profile_memory: bool=False, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n    'Print at most one line of the profile (true == printed one).'\n    obj = json.output_profile_line(fname=fname, fname_print=fname, line_no=line_no, line=line, stats=stats, profile_this_code=profile_this_code, force_print=force_print)\n    if not obj:\n        return False\n    if -1 < obj['n_peak_mb'] < 1:\n        obj['n_peak_mb'] = 0\n    n_cpu_percent_c_str: str = '' if obj['n_cpu_percent_c'] < 1 else f\"{obj['n_cpu_percent_c']:5.0f}%\"\n    n_gpu_percent_str: str = '' if obj['n_gpu_percent'] < 1 else f\"{obj['n_gpu_percent']:3.0f}%\"\n    n_cpu_percent_python_str: str = '' if obj['n_cpu_percent_python'] < 1 else f\"{obj['n_cpu_percent_python']:5.0f}%\"\n    n_growth_mem_str = ''\n    if obj['n_peak_mb'] < 1024:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb']:5.0f}M\"\n    else:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb'] / 1024:5.2f}G\"\n    sys_str: str = '' if obj['n_sys_percent'] < 1 else f\"{obj['n_sys_percent']:4.0f}%\"\n    if not is_function_summary:\n        print_line_no = '' if suppress_lineno_print else str(line_no)\n    else:\n        print_line_no = '' if fname not in stats.firstline_map else str(stats.firstline_map[fname])\n    if profile_memory:\n        spark_str: str = ''\n        samples = obj['memory_samples']\n        if len(samples) > ScaleneOutput.max_sparkline_len_line:\n            random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_line))\n        else:\n            random_samples = samples\n        sparkline_samples = [random_samples[i][1] * obj['n_usage_fraction'] for i in range(len(random_samples))]\n        if random_samples:\n            (_, _, spark_str) = sparkline.generate(sparkline_samples, 0, stats.max_footprint)\n        ncpps: Any = ''\n        ncpcs: Any = ''\n        nufs: Any = ''\n        ngpus: Any = ''\n        n_usage_fraction_str: str = '' if obj['n_usage_fraction'] < 0.01 else f\"{100 * obj['n_usage_fraction']:4.0f}%\"\n        if obj['n_usage_fraction'] >= self.highlight_percentage or obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            nufs = Text.assemble((spark_str + n_usage_fraction_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n            nufs = spark_str + n_usage_fraction_str\n        if reduced_profile and (not ncpps + ncpcs + nufs + ngpus):\n            return False\n        n_python_fraction_str: str = '' if obj['n_python_fraction'] < 0.01 else f\"{obj['n_python_fraction'] * 100:4.0f}%\"\n        n_copy_mb_s_str: str = '' if obj['n_copy_mb_s'] < 0.5 else f\"{obj['n_copy_mb_s']:6.0f}\"\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n    else:\n        if obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n        if reduced_profile and (not ncpps + ncpcs + ngpus):\n            return False\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, line)\n    return True",
            "def output_profile_line(self, json: ScaleneJSON, fname: Filename, line_no: LineNumber, line: SyntaxLine, console: Console, tbl: Table, stats: ScaleneStatistics, profile_this_code: Callable[[Filename, LineNumber], bool], force_print: bool=False, suppress_lineno_print: bool=False, is_function_summary: bool=False, profile_memory: bool=False, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Print at most one line of the profile (true == printed one).'\n    obj = json.output_profile_line(fname=fname, fname_print=fname, line_no=line_no, line=line, stats=stats, profile_this_code=profile_this_code, force_print=force_print)\n    if not obj:\n        return False\n    if -1 < obj['n_peak_mb'] < 1:\n        obj['n_peak_mb'] = 0\n    n_cpu_percent_c_str: str = '' if obj['n_cpu_percent_c'] < 1 else f\"{obj['n_cpu_percent_c']:5.0f}%\"\n    n_gpu_percent_str: str = '' if obj['n_gpu_percent'] < 1 else f\"{obj['n_gpu_percent']:3.0f}%\"\n    n_cpu_percent_python_str: str = '' if obj['n_cpu_percent_python'] < 1 else f\"{obj['n_cpu_percent_python']:5.0f}%\"\n    n_growth_mem_str = ''\n    if obj['n_peak_mb'] < 1024:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb']:5.0f}M\"\n    else:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb'] / 1024:5.2f}G\"\n    sys_str: str = '' if obj['n_sys_percent'] < 1 else f\"{obj['n_sys_percent']:4.0f}%\"\n    if not is_function_summary:\n        print_line_no = '' if suppress_lineno_print else str(line_no)\n    else:\n        print_line_no = '' if fname not in stats.firstline_map else str(stats.firstline_map[fname])\n    if profile_memory:\n        spark_str: str = ''\n        samples = obj['memory_samples']\n        if len(samples) > ScaleneOutput.max_sparkline_len_line:\n            random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_line))\n        else:\n            random_samples = samples\n        sparkline_samples = [random_samples[i][1] * obj['n_usage_fraction'] for i in range(len(random_samples))]\n        if random_samples:\n            (_, _, spark_str) = sparkline.generate(sparkline_samples, 0, stats.max_footprint)\n        ncpps: Any = ''\n        ncpcs: Any = ''\n        nufs: Any = ''\n        ngpus: Any = ''\n        n_usage_fraction_str: str = '' if obj['n_usage_fraction'] < 0.01 else f\"{100 * obj['n_usage_fraction']:4.0f}%\"\n        if obj['n_usage_fraction'] >= self.highlight_percentage or obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            nufs = Text.assemble((spark_str + n_usage_fraction_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n            nufs = spark_str + n_usage_fraction_str\n        if reduced_profile and (not ncpps + ncpcs + nufs + ngpus):\n            return False\n        n_python_fraction_str: str = '' if obj['n_python_fraction'] < 0.01 else f\"{obj['n_python_fraction'] * 100:4.0f}%\"\n        n_copy_mb_s_str: str = '' if obj['n_copy_mb_s'] < 0.5 else f\"{obj['n_copy_mb_s']:6.0f}\"\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n    else:\n        if obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n        if reduced_profile and (not ncpps + ncpcs + ngpus):\n            return False\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, line)\n    return True",
            "def output_profile_line(self, json: ScaleneJSON, fname: Filename, line_no: LineNumber, line: SyntaxLine, console: Console, tbl: Table, stats: ScaleneStatistics, profile_this_code: Callable[[Filename, LineNumber], bool], force_print: bool=False, suppress_lineno_print: bool=False, is_function_summary: bool=False, profile_memory: bool=False, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Print at most one line of the profile (true == printed one).'\n    obj = json.output_profile_line(fname=fname, fname_print=fname, line_no=line_no, line=line, stats=stats, profile_this_code=profile_this_code, force_print=force_print)\n    if not obj:\n        return False\n    if -1 < obj['n_peak_mb'] < 1:\n        obj['n_peak_mb'] = 0\n    n_cpu_percent_c_str: str = '' if obj['n_cpu_percent_c'] < 1 else f\"{obj['n_cpu_percent_c']:5.0f}%\"\n    n_gpu_percent_str: str = '' if obj['n_gpu_percent'] < 1 else f\"{obj['n_gpu_percent']:3.0f}%\"\n    n_cpu_percent_python_str: str = '' if obj['n_cpu_percent_python'] < 1 else f\"{obj['n_cpu_percent_python']:5.0f}%\"\n    n_growth_mem_str = ''\n    if obj['n_peak_mb'] < 1024:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb']:5.0f}M\"\n    else:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb'] / 1024:5.2f}G\"\n    sys_str: str = '' if obj['n_sys_percent'] < 1 else f\"{obj['n_sys_percent']:4.0f}%\"\n    if not is_function_summary:\n        print_line_no = '' if suppress_lineno_print else str(line_no)\n    else:\n        print_line_no = '' if fname not in stats.firstline_map else str(stats.firstline_map[fname])\n    if profile_memory:\n        spark_str: str = ''\n        samples = obj['memory_samples']\n        if len(samples) > ScaleneOutput.max_sparkline_len_line:\n            random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_line))\n        else:\n            random_samples = samples\n        sparkline_samples = [random_samples[i][1] * obj['n_usage_fraction'] for i in range(len(random_samples))]\n        if random_samples:\n            (_, _, spark_str) = sparkline.generate(sparkline_samples, 0, stats.max_footprint)\n        ncpps: Any = ''\n        ncpcs: Any = ''\n        nufs: Any = ''\n        ngpus: Any = ''\n        n_usage_fraction_str: str = '' if obj['n_usage_fraction'] < 0.01 else f\"{100 * obj['n_usage_fraction']:4.0f}%\"\n        if obj['n_usage_fraction'] >= self.highlight_percentage or obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            nufs = Text.assemble((spark_str + n_usage_fraction_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n            nufs = spark_str + n_usage_fraction_str\n        if reduced_profile and (not ncpps + ncpcs + nufs + ngpus):\n            return False\n        n_python_fraction_str: str = '' if obj['n_python_fraction'] < 0.01 else f\"{obj['n_python_fraction'] * 100:4.0f}%\"\n        n_copy_mb_s_str: str = '' if obj['n_copy_mb_s'] < 0.5 else f\"{obj['n_copy_mb_s']:6.0f}\"\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n    else:\n        if obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n        if reduced_profile and (not ncpps + ncpcs + ngpus):\n            return False\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, line)\n    return True",
            "def output_profile_line(self, json: ScaleneJSON, fname: Filename, line_no: LineNumber, line: SyntaxLine, console: Console, tbl: Table, stats: ScaleneStatistics, profile_this_code: Callable[[Filename, LineNumber], bool], force_print: bool=False, suppress_lineno_print: bool=False, is_function_summary: bool=False, profile_memory: bool=False, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Print at most one line of the profile (true == printed one).'\n    obj = json.output_profile_line(fname=fname, fname_print=fname, line_no=line_no, line=line, stats=stats, profile_this_code=profile_this_code, force_print=force_print)\n    if not obj:\n        return False\n    if -1 < obj['n_peak_mb'] < 1:\n        obj['n_peak_mb'] = 0\n    n_cpu_percent_c_str: str = '' if obj['n_cpu_percent_c'] < 1 else f\"{obj['n_cpu_percent_c']:5.0f}%\"\n    n_gpu_percent_str: str = '' if obj['n_gpu_percent'] < 1 else f\"{obj['n_gpu_percent']:3.0f}%\"\n    n_cpu_percent_python_str: str = '' if obj['n_cpu_percent_python'] < 1 else f\"{obj['n_cpu_percent_python']:5.0f}%\"\n    n_growth_mem_str = ''\n    if obj['n_peak_mb'] < 1024:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb']:5.0f}M\"\n    else:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb'] / 1024:5.2f}G\"\n    sys_str: str = '' if obj['n_sys_percent'] < 1 else f\"{obj['n_sys_percent']:4.0f}%\"\n    if not is_function_summary:\n        print_line_no = '' if suppress_lineno_print else str(line_no)\n    else:\n        print_line_no = '' if fname not in stats.firstline_map else str(stats.firstline_map[fname])\n    if profile_memory:\n        spark_str: str = ''\n        samples = obj['memory_samples']\n        if len(samples) > ScaleneOutput.max_sparkline_len_line:\n            random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_line))\n        else:\n            random_samples = samples\n        sparkline_samples = [random_samples[i][1] * obj['n_usage_fraction'] for i in range(len(random_samples))]\n        if random_samples:\n            (_, _, spark_str) = sparkline.generate(sparkline_samples, 0, stats.max_footprint)\n        ncpps: Any = ''\n        ncpcs: Any = ''\n        nufs: Any = ''\n        ngpus: Any = ''\n        n_usage_fraction_str: str = '' if obj['n_usage_fraction'] < 0.01 else f\"{100 * obj['n_usage_fraction']:4.0f}%\"\n        if obj['n_usage_fraction'] >= self.highlight_percentage or obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            nufs = Text.assemble((spark_str + n_usage_fraction_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n            nufs = spark_str + n_usage_fraction_str\n        if reduced_profile and (not ncpps + ncpcs + nufs + ngpus):\n            return False\n        n_python_fraction_str: str = '' if obj['n_python_fraction'] < 0.01 else f\"{obj['n_python_fraction'] * 100:4.0f}%\"\n        n_copy_mb_s_str: str = '' if obj['n_copy_mb_s'] < 0.5 else f\"{obj['n_copy_mb_s']:6.0f}\"\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n    else:\n        if obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n        if reduced_profile and (not ncpps + ncpcs + ngpus):\n            return False\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, line)\n    return True",
            "def output_profile_line(self, json: ScaleneJSON, fname: Filename, line_no: LineNumber, line: SyntaxLine, console: Console, tbl: Table, stats: ScaleneStatistics, profile_this_code: Callable[[Filename, LineNumber], bool], force_print: bool=False, suppress_lineno_print: bool=False, is_function_summary: bool=False, profile_memory: bool=False, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Print at most one line of the profile (true == printed one).'\n    obj = json.output_profile_line(fname=fname, fname_print=fname, line_no=line_no, line=line, stats=stats, profile_this_code=profile_this_code, force_print=force_print)\n    if not obj:\n        return False\n    if -1 < obj['n_peak_mb'] < 1:\n        obj['n_peak_mb'] = 0\n    n_cpu_percent_c_str: str = '' if obj['n_cpu_percent_c'] < 1 else f\"{obj['n_cpu_percent_c']:5.0f}%\"\n    n_gpu_percent_str: str = '' if obj['n_gpu_percent'] < 1 else f\"{obj['n_gpu_percent']:3.0f}%\"\n    n_cpu_percent_python_str: str = '' if obj['n_cpu_percent_python'] < 1 else f\"{obj['n_cpu_percent_python']:5.0f}%\"\n    n_growth_mem_str = ''\n    if obj['n_peak_mb'] < 1024:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb']:5.0f}M\"\n    else:\n        n_growth_mem_str = '' if not obj['n_peak_mb'] and (not obj['n_usage_fraction']) else f\"{obj['n_peak_mb'] / 1024:5.2f}G\"\n    sys_str: str = '' if obj['n_sys_percent'] < 1 else f\"{obj['n_sys_percent']:4.0f}%\"\n    if not is_function_summary:\n        print_line_no = '' if suppress_lineno_print else str(line_no)\n    else:\n        print_line_no = '' if fname not in stats.firstline_map else str(stats.firstline_map[fname])\n    if profile_memory:\n        spark_str: str = ''\n        samples = obj['memory_samples']\n        if len(samples) > ScaleneOutput.max_sparkline_len_line:\n            random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_line))\n        else:\n            random_samples = samples\n        sparkline_samples = [random_samples[i][1] * obj['n_usage_fraction'] for i in range(len(random_samples))]\n        if random_samples:\n            (_, _, spark_str) = sparkline.generate(sparkline_samples, 0, stats.max_footprint)\n        ncpps: Any = ''\n        ncpcs: Any = ''\n        nufs: Any = ''\n        ngpus: Any = ''\n        n_usage_fraction_str: str = '' if obj['n_usage_fraction'] < 0.01 else f\"{100 * obj['n_usage_fraction']:4.0f}%\"\n        if obj['n_usage_fraction'] >= self.highlight_percentage or obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            nufs = Text.assemble((spark_str + n_usage_fraction_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n            nufs = spark_str + n_usage_fraction_str\n        if reduced_profile and (not ncpps + ncpcs + nufs + ngpus):\n            return False\n        n_python_fraction_str: str = '' if obj['n_python_fraction'] < 0.01 else f\"{obj['n_python_fraction'] * 100:4.0f}%\"\n        n_copy_mb_s_str: str = '' if obj['n_copy_mb_s'] < 0.5 else f\"{obj['n_copy_mb_s']:6.0f}\"\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, n_python_fraction_str, n_growth_mem_str, nufs, n_copy_mb_s_str, line)\n    else:\n        if obj['n_cpu_percent_c'] + obj['n_cpu_percent_python'] + obj['n_gpu_percent'] >= self.highlight_percentage:\n            ncpps = Text.assemble((n_cpu_percent_python_str, self.highlight_color))\n            ncpcs = Text.assemble((n_cpu_percent_c_str, self.highlight_color))\n            ngpus = Text.assemble((n_gpu_percent_str, self.highlight_color))\n        else:\n            ncpps = n_cpu_percent_python_str\n            ncpcs = n_cpu_percent_c_str\n            ngpus = n_gpu_percent_str\n        if reduced_profile and (not ncpps + ncpcs + ngpus):\n            return False\n        if self.gpu:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, ngpus, line)\n        else:\n            tbl.add_row(print_line_no, ncpps, ncpcs, sys_str, line)\n    return True"
        ]
    },
    {
        "func_name": "output_profiles",
        "original": "def output_profiles(self, column_width: int, stats: ScaleneStatistics, pid: int, profile_this_code: Callable[[Filename, LineNumber], bool], python_alias_dir: Path, program_path: Path, program_args: Optional[List[str]], profile_memory: bool=True, reduced_profile: bool=False) -> bool:\n    \"\"\"Write the profile out.\"\"\"\n    json = ScaleneJSON()\n    json.gpu = self.gpu\n    if not pid:\n        stats.merge_stats(python_alias_dir)\n    if not stats.total_cpu_samples and (not stats.total_memory_malloc_samples) and (not stats.total_memory_free_samples):\n        return False\n    all_instrumented_files: List[Filename] = list(set(list(stats.cpu_samples_python.keys()) + list(stats.cpu_samples_c.keys()) + list(stats.memory_free_samples.keys()) + list(stats.memory_malloc_samples.keys())))\n    if not all_instrumented_files:\n        return False\n    mem_usage_line: Union[Text, str] = ''\n    growth_rate = 0.0\n    if profile_memory:\n        samples = stats.memory_footprint_samples\n        if len(samples) > 0:\n            if len(samples) > ScaleneOutput.max_sparkline_len_file:\n                random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_file))\n            else:\n                random_samples = samples\n            sparkline_samples = [item[1] for item in random_samples]\n            (_, _, spark_str) = sparkline.generate(sparkline_samples[:ScaleneOutput.max_sparkline_len_file], 0, stats.max_footprint)\n            if stats.allocation_velocity[1] > 0:\n                growth_rate = 100.0 * stats.allocation_velocity[0] / stats.allocation_velocity[1]\n            mem_usage_line = Text.assemble('Memory usage: ', (spark_str, self.memory_color), f' (max: {ScaleneJSON.memory_consumed_str(stats.max_footprint)}, growth rate: {growth_rate:3.0f}%)\\n')\n    null = tempfile.TemporaryFile(mode='w+')\n    console = Console(width=column_width, record=True, force_terminal=True, file=null, force_jupyter=False)\n    report_files: List[Filename] = []\n    for fname in sorted(all_instrumented_files, key=lambda f: (-stats.cpu_samples[f], f)):\n        fname = Filename(fname)\n        try:\n            percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples\n        except ZeroDivisionError:\n            percent_cpu_time = 0\n        if stats.malloc_samples[fname] < ScaleneJSON.malloc_threshold and percent_cpu_time < ScaleneJSON.cpu_percent_threshold:\n            continue\n        report_files.append(fname)\n    if pid:\n        stats.output_stats(pid, python_alias_dir)\n        return True\n    if not report_files:\n        return False\n    for fname in report_files:\n        fname_print = fname\n        import re\n        if (result := re.match('_ipython-input-([0-9]+)-.*', fname_print)):\n            fname_print = Filename(f'[{result.group(1)}]')\n        percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples if stats.total_cpu_samples else 0\n        new_title = mem_usage_line + f'{fname_print}: % of time = {percent_cpu_time:6.2f}% ({ScaleneJSON.time_consumed_str(percent_cpu_time / 100.0 * stats.elapsed_time * 1000.0)}) out of {ScaleneJSON.time_consumed_str(stats.elapsed_time * 1000.0)}.'\n        mem_usage_line = ''\n        tbl = Table(box=box.MINIMAL_HEAVY_HEAD, title=new_title, collapse_padding=True, width=column_width - 1)\n        tbl.add_column(Markdown('Line', style='dim'), style='dim', justify='right', no_wrap=True, width=4)\n        tbl.add_column(Markdown('Time  ' + '\\n' + '_Python_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_native_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_system_', style='blue'), style='blue', no_wrap=True, width=6)\n        if self.gpu:\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_GPU_', style=self.gpu_color), style=self.gpu_color, no_wrap=True, width=6)\n        other_columns_width = 0\n        if profile_memory:\n            tbl.add_column(Markdown('Memory  \\n_Python_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=7)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_peak_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=6)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \\n_timeline_/%', style=self.memory_color), style=self.memory_color, no_wrap=True, width=15)\n            tbl.add_column(Markdown('Copy  \\n_(MB/s)_', style=self.copy_volume_color), style=self.copy_volume_color, no_wrap=True, width=6)\n            other_columns_width = 75 + (6 if self.gpu else 0)\n        else:\n            other_columns_width = 37 + (5 if self.gpu else 0)\n        tbl.add_column('\\n' + fname_print, width=column_width - other_columns_width, no_wrap=True)\n        if fname == '<BOGUS>':\n            continue\n        if not fname:\n            continue\n        full_fname = os.path.normpath(os.path.join(program_path, fname))\n        try:\n            with open(full_fname, 'r') as source_file:\n                code_lines = source_file.read()\n        except (FileNotFoundError, OSError):\n            continue\n        did_print = True\n        syntax_highlighted = Syntax(code_lines, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n        capture_console = Console(width=column_width - other_columns_width, force_terminal=True)\n        formatted_lines = [SyntaxLine(segments) for segments in capture_console.render_lines(syntax_highlighted)]\n        for (line_no, line) in enumerate(formatted_lines, start=1):\n            old_did_print = did_print\n            did_print = self.output_profile_line(json=json, fname=fname, line_no=LineNumber(line_no), line=line, console=console, tbl=tbl, stats=stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=False, suppress_lineno_print=False, is_function_summary=False, reduced_profile=reduced_profile)\n            if old_did_print and (not did_print):\n                tbl.add_row('...')\n            old_did_print = did_print\n        fn_stats = stats.build_function_stats(fname)\n        print_fn_summary = False\n        all_samples = set()\n        all_samples |= set(fn_stats.cpu_samples_python.keys())\n        all_samples |= set(fn_stats.cpu_samples_c.keys())\n        all_samples |= set(fn_stats.memory_malloc_samples.keys())\n        all_samples |= set(fn_stats.memory_free_samples.keys())\n        for fn_name in all_samples:\n            if fn_name == fname:\n                continue\n            print_fn_summary = True\n            break\n        if print_fn_summary:\n            try:\n                tbl.add_row(None, end_section=True)\n            except TypeError:\n                tbl.add_row(None)\n            txt = Text.assemble(f'function summary for {fname_print}', style='bold italic')\n            if profile_memory:\n                if self.gpu:\n                    tbl.add_row('', '', '', '', '', '', '', '', '', txt)\n                else:\n                    tbl.add_row('', '', '', '', '', '', '', '', txt)\n            elif self.gpu:\n                tbl.add_row('', '', '', '', '', txt)\n            else:\n                tbl.add_row('', '', '', '', txt)\n            for fn_name in sorted(fn_stats.cpu_samples_python, key=lambda k: stats.firstline_map[k]):\n                if fn_name == fname:\n                    continue\n                syntax_highlighted = Syntax(fn_name, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n                self.output_profile_line(json=json, fname=fn_name, line_no=LineNumber(1), line=syntax_highlighted, console=console, tbl=tbl, stats=fn_stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=True, suppress_lineno_print=True, is_function_summary=True, reduced_profile=reduced_profile)\n        console.print(tbl)\n        avg_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            n_malloc_mb = stats.memory_aggregate_footprint[fname][line_no]\n            if (count := stats.memory_malloc_count[fname][line_no]):\n                avg_mallocs[line_no] = n_malloc_mb / count\n            else:\n                avg_mallocs[line_no] = n_malloc_mb\n        avg_mallocs = OrderedDict(sorted(avg_mallocs.items(), key=itemgetter(1), reverse=True))\n        peak_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            peak_mallocs[line_no] = stats.memory_max_footprint[fname][line_no]\n        peak_mallocs = OrderedDict(sorted(peak_mallocs.items(), key=itemgetter(1), reverse=True))\n        self.output_top_memory('Top AVERAGE memory consumption, by line:', console, avg_mallocs)\n        self.output_top_memory('Top PEAK memory consumption, by line:', console, peak_mallocs)\n        leaks = ScaleneLeakAnalysis.compute_leaks(growth_rate, stats, avg_mallocs, fname)\n        if len(leaks) > 0:\n            for leak in sorted(leaks, key=itemgetter(1), reverse=True):\n                output_str = f'Possible memory leak identified at line {str(leak[0])} (estimated likelihood: {leak[1] * 100:3.0f}%, velocity: {leak[2] / stats.elapsed_time:3.0f} MB/s)'\n                console.print(output_str)\n    if self.html:\n        md = Markdown('generated by the [scalene](https://github.com/plasma-umass/scalene) profiler')\n        console.print(md)\n        if not self.output_file:\n            self.output_file = '/dev/stdout'\n        console.save_html(self.output_file, clear=False)\n    elif self.output_file:\n        console.save_text(self.output_file, styles=False, clear=False)\n    else:\n        sys.stdout.write(console.export_text(styles=True))\n    return True",
        "mutated": [
            "def output_profiles(self, column_width: int, stats: ScaleneStatistics, pid: int, profile_this_code: Callable[[Filename, LineNumber], bool], python_alias_dir: Path, program_path: Path, program_args: Optional[List[str]], profile_memory: bool=True, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n    'Write the profile out.'\n    json = ScaleneJSON()\n    json.gpu = self.gpu\n    if not pid:\n        stats.merge_stats(python_alias_dir)\n    if not stats.total_cpu_samples and (not stats.total_memory_malloc_samples) and (not stats.total_memory_free_samples):\n        return False\n    all_instrumented_files: List[Filename] = list(set(list(stats.cpu_samples_python.keys()) + list(stats.cpu_samples_c.keys()) + list(stats.memory_free_samples.keys()) + list(stats.memory_malloc_samples.keys())))\n    if not all_instrumented_files:\n        return False\n    mem_usage_line: Union[Text, str] = ''\n    growth_rate = 0.0\n    if profile_memory:\n        samples = stats.memory_footprint_samples\n        if len(samples) > 0:\n            if len(samples) > ScaleneOutput.max_sparkline_len_file:\n                random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_file))\n            else:\n                random_samples = samples\n            sparkline_samples = [item[1] for item in random_samples]\n            (_, _, spark_str) = sparkline.generate(sparkline_samples[:ScaleneOutput.max_sparkline_len_file], 0, stats.max_footprint)\n            if stats.allocation_velocity[1] > 0:\n                growth_rate = 100.0 * stats.allocation_velocity[0] / stats.allocation_velocity[1]\n            mem_usage_line = Text.assemble('Memory usage: ', (spark_str, self.memory_color), f' (max: {ScaleneJSON.memory_consumed_str(stats.max_footprint)}, growth rate: {growth_rate:3.0f}%)\\n')\n    null = tempfile.TemporaryFile(mode='w+')\n    console = Console(width=column_width, record=True, force_terminal=True, file=null, force_jupyter=False)\n    report_files: List[Filename] = []\n    for fname in sorted(all_instrumented_files, key=lambda f: (-stats.cpu_samples[f], f)):\n        fname = Filename(fname)\n        try:\n            percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples\n        except ZeroDivisionError:\n            percent_cpu_time = 0\n        if stats.malloc_samples[fname] < ScaleneJSON.malloc_threshold and percent_cpu_time < ScaleneJSON.cpu_percent_threshold:\n            continue\n        report_files.append(fname)\n    if pid:\n        stats.output_stats(pid, python_alias_dir)\n        return True\n    if not report_files:\n        return False\n    for fname in report_files:\n        fname_print = fname\n        import re\n        if (result := re.match('_ipython-input-([0-9]+)-.*', fname_print)):\n            fname_print = Filename(f'[{result.group(1)}]')\n        percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples if stats.total_cpu_samples else 0\n        new_title = mem_usage_line + f'{fname_print}: % of time = {percent_cpu_time:6.2f}% ({ScaleneJSON.time_consumed_str(percent_cpu_time / 100.0 * stats.elapsed_time * 1000.0)}) out of {ScaleneJSON.time_consumed_str(stats.elapsed_time * 1000.0)}.'\n        mem_usage_line = ''\n        tbl = Table(box=box.MINIMAL_HEAVY_HEAD, title=new_title, collapse_padding=True, width=column_width - 1)\n        tbl.add_column(Markdown('Line', style='dim'), style='dim', justify='right', no_wrap=True, width=4)\n        tbl.add_column(Markdown('Time  ' + '\\n' + '_Python_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_native_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_system_', style='blue'), style='blue', no_wrap=True, width=6)\n        if self.gpu:\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_GPU_', style=self.gpu_color), style=self.gpu_color, no_wrap=True, width=6)\n        other_columns_width = 0\n        if profile_memory:\n            tbl.add_column(Markdown('Memory  \\n_Python_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=7)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_peak_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=6)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \\n_timeline_/%', style=self.memory_color), style=self.memory_color, no_wrap=True, width=15)\n            tbl.add_column(Markdown('Copy  \\n_(MB/s)_', style=self.copy_volume_color), style=self.copy_volume_color, no_wrap=True, width=6)\n            other_columns_width = 75 + (6 if self.gpu else 0)\n        else:\n            other_columns_width = 37 + (5 if self.gpu else 0)\n        tbl.add_column('\\n' + fname_print, width=column_width - other_columns_width, no_wrap=True)\n        if fname == '<BOGUS>':\n            continue\n        if not fname:\n            continue\n        full_fname = os.path.normpath(os.path.join(program_path, fname))\n        try:\n            with open(full_fname, 'r') as source_file:\n                code_lines = source_file.read()\n        except (FileNotFoundError, OSError):\n            continue\n        did_print = True\n        syntax_highlighted = Syntax(code_lines, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n        capture_console = Console(width=column_width - other_columns_width, force_terminal=True)\n        formatted_lines = [SyntaxLine(segments) for segments in capture_console.render_lines(syntax_highlighted)]\n        for (line_no, line) in enumerate(formatted_lines, start=1):\n            old_did_print = did_print\n            did_print = self.output_profile_line(json=json, fname=fname, line_no=LineNumber(line_no), line=line, console=console, tbl=tbl, stats=stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=False, suppress_lineno_print=False, is_function_summary=False, reduced_profile=reduced_profile)\n            if old_did_print and (not did_print):\n                tbl.add_row('...')\n            old_did_print = did_print\n        fn_stats = stats.build_function_stats(fname)\n        print_fn_summary = False\n        all_samples = set()\n        all_samples |= set(fn_stats.cpu_samples_python.keys())\n        all_samples |= set(fn_stats.cpu_samples_c.keys())\n        all_samples |= set(fn_stats.memory_malloc_samples.keys())\n        all_samples |= set(fn_stats.memory_free_samples.keys())\n        for fn_name in all_samples:\n            if fn_name == fname:\n                continue\n            print_fn_summary = True\n            break\n        if print_fn_summary:\n            try:\n                tbl.add_row(None, end_section=True)\n            except TypeError:\n                tbl.add_row(None)\n            txt = Text.assemble(f'function summary for {fname_print}', style='bold italic')\n            if profile_memory:\n                if self.gpu:\n                    tbl.add_row('', '', '', '', '', '', '', '', '', txt)\n                else:\n                    tbl.add_row('', '', '', '', '', '', '', '', txt)\n            elif self.gpu:\n                tbl.add_row('', '', '', '', '', txt)\n            else:\n                tbl.add_row('', '', '', '', txt)\n            for fn_name in sorted(fn_stats.cpu_samples_python, key=lambda k: stats.firstline_map[k]):\n                if fn_name == fname:\n                    continue\n                syntax_highlighted = Syntax(fn_name, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n                self.output_profile_line(json=json, fname=fn_name, line_no=LineNumber(1), line=syntax_highlighted, console=console, tbl=tbl, stats=fn_stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=True, suppress_lineno_print=True, is_function_summary=True, reduced_profile=reduced_profile)\n        console.print(tbl)\n        avg_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            n_malloc_mb = stats.memory_aggregate_footprint[fname][line_no]\n            if (count := stats.memory_malloc_count[fname][line_no]):\n                avg_mallocs[line_no] = n_malloc_mb / count\n            else:\n                avg_mallocs[line_no] = n_malloc_mb\n        avg_mallocs = OrderedDict(sorted(avg_mallocs.items(), key=itemgetter(1), reverse=True))\n        peak_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            peak_mallocs[line_no] = stats.memory_max_footprint[fname][line_no]\n        peak_mallocs = OrderedDict(sorted(peak_mallocs.items(), key=itemgetter(1), reverse=True))\n        self.output_top_memory('Top AVERAGE memory consumption, by line:', console, avg_mallocs)\n        self.output_top_memory('Top PEAK memory consumption, by line:', console, peak_mallocs)\n        leaks = ScaleneLeakAnalysis.compute_leaks(growth_rate, stats, avg_mallocs, fname)\n        if len(leaks) > 0:\n            for leak in sorted(leaks, key=itemgetter(1), reverse=True):\n                output_str = f'Possible memory leak identified at line {str(leak[0])} (estimated likelihood: {leak[1] * 100:3.0f}%, velocity: {leak[2] / stats.elapsed_time:3.0f} MB/s)'\n                console.print(output_str)\n    if self.html:\n        md = Markdown('generated by the [scalene](https://github.com/plasma-umass/scalene) profiler')\n        console.print(md)\n        if not self.output_file:\n            self.output_file = '/dev/stdout'\n        console.save_html(self.output_file, clear=False)\n    elif self.output_file:\n        console.save_text(self.output_file, styles=False, clear=False)\n    else:\n        sys.stdout.write(console.export_text(styles=True))\n    return True",
            "def output_profiles(self, column_width: int, stats: ScaleneStatistics, pid: int, profile_this_code: Callable[[Filename, LineNumber], bool], python_alias_dir: Path, program_path: Path, program_args: Optional[List[str]], profile_memory: bool=True, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Write the profile out.'\n    json = ScaleneJSON()\n    json.gpu = self.gpu\n    if not pid:\n        stats.merge_stats(python_alias_dir)\n    if not stats.total_cpu_samples and (not stats.total_memory_malloc_samples) and (not stats.total_memory_free_samples):\n        return False\n    all_instrumented_files: List[Filename] = list(set(list(stats.cpu_samples_python.keys()) + list(stats.cpu_samples_c.keys()) + list(stats.memory_free_samples.keys()) + list(stats.memory_malloc_samples.keys())))\n    if not all_instrumented_files:\n        return False\n    mem_usage_line: Union[Text, str] = ''\n    growth_rate = 0.0\n    if profile_memory:\n        samples = stats.memory_footprint_samples\n        if len(samples) > 0:\n            if len(samples) > ScaleneOutput.max_sparkline_len_file:\n                random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_file))\n            else:\n                random_samples = samples\n            sparkline_samples = [item[1] for item in random_samples]\n            (_, _, spark_str) = sparkline.generate(sparkline_samples[:ScaleneOutput.max_sparkline_len_file], 0, stats.max_footprint)\n            if stats.allocation_velocity[1] > 0:\n                growth_rate = 100.0 * stats.allocation_velocity[0] / stats.allocation_velocity[1]\n            mem_usage_line = Text.assemble('Memory usage: ', (spark_str, self.memory_color), f' (max: {ScaleneJSON.memory_consumed_str(stats.max_footprint)}, growth rate: {growth_rate:3.0f}%)\\n')\n    null = tempfile.TemporaryFile(mode='w+')\n    console = Console(width=column_width, record=True, force_terminal=True, file=null, force_jupyter=False)\n    report_files: List[Filename] = []\n    for fname in sorted(all_instrumented_files, key=lambda f: (-stats.cpu_samples[f], f)):\n        fname = Filename(fname)\n        try:\n            percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples\n        except ZeroDivisionError:\n            percent_cpu_time = 0\n        if stats.malloc_samples[fname] < ScaleneJSON.malloc_threshold and percent_cpu_time < ScaleneJSON.cpu_percent_threshold:\n            continue\n        report_files.append(fname)\n    if pid:\n        stats.output_stats(pid, python_alias_dir)\n        return True\n    if not report_files:\n        return False\n    for fname in report_files:\n        fname_print = fname\n        import re\n        if (result := re.match('_ipython-input-([0-9]+)-.*', fname_print)):\n            fname_print = Filename(f'[{result.group(1)}]')\n        percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples if stats.total_cpu_samples else 0\n        new_title = mem_usage_line + f'{fname_print}: % of time = {percent_cpu_time:6.2f}% ({ScaleneJSON.time_consumed_str(percent_cpu_time / 100.0 * stats.elapsed_time * 1000.0)}) out of {ScaleneJSON.time_consumed_str(stats.elapsed_time * 1000.0)}.'\n        mem_usage_line = ''\n        tbl = Table(box=box.MINIMAL_HEAVY_HEAD, title=new_title, collapse_padding=True, width=column_width - 1)\n        tbl.add_column(Markdown('Line', style='dim'), style='dim', justify='right', no_wrap=True, width=4)\n        tbl.add_column(Markdown('Time  ' + '\\n' + '_Python_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_native_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_system_', style='blue'), style='blue', no_wrap=True, width=6)\n        if self.gpu:\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_GPU_', style=self.gpu_color), style=self.gpu_color, no_wrap=True, width=6)\n        other_columns_width = 0\n        if profile_memory:\n            tbl.add_column(Markdown('Memory  \\n_Python_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=7)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_peak_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=6)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \\n_timeline_/%', style=self.memory_color), style=self.memory_color, no_wrap=True, width=15)\n            tbl.add_column(Markdown('Copy  \\n_(MB/s)_', style=self.copy_volume_color), style=self.copy_volume_color, no_wrap=True, width=6)\n            other_columns_width = 75 + (6 if self.gpu else 0)\n        else:\n            other_columns_width = 37 + (5 if self.gpu else 0)\n        tbl.add_column('\\n' + fname_print, width=column_width - other_columns_width, no_wrap=True)\n        if fname == '<BOGUS>':\n            continue\n        if not fname:\n            continue\n        full_fname = os.path.normpath(os.path.join(program_path, fname))\n        try:\n            with open(full_fname, 'r') as source_file:\n                code_lines = source_file.read()\n        except (FileNotFoundError, OSError):\n            continue\n        did_print = True\n        syntax_highlighted = Syntax(code_lines, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n        capture_console = Console(width=column_width - other_columns_width, force_terminal=True)\n        formatted_lines = [SyntaxLine(segments) for segments in capture_console.render_lines(syntax_highlighted)]\n        for (line_no, line) in enumerate(formatted_lines, start=1):\n            old_did_print = did_print\n            did_print = self.output_profile_line(json=json, fname=fname, line_no=LineNumber(line_no), line=line, console=console, tbl=tbl, stats=stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=False, suppress_lineno_print=False, is_function_summary=False, reduced_profile=reduced_profile)\n            if old_did_print and (not did_print):\n                tbl.add_row('...')\n            old_did_print = did_print\n        fn_stats = stats.build_function_stats(fname)\n        print_fn_summary = False\n        all_samples = set()\n        all_samples |= set(fn_stats.cpu_samples_python.keys())\n        all_samples |= set(fn_stats.cpu_samples_c.keys())\n        all_samples |= set(fn_stats.memory_malloc_samples.keys())\n        all_samples |= set(fn_stats.memory_free_samples.keys())\n        for fn_name in all_samples:\n            if fn_name == fname:\n                continue\n            print_fn_summary = True\n            break\n        if print_fn_summary:\n            try:\n                tbl.add_row(None, end_section=True)\n            except TypeError:\n                tbl.add_row(None)\n            txt = Text.assemble(f'function summary for {fname_print}', style='bold italic')\n            if profile_memory:\n                if self.gpu:\n                    tbl.add_row('', '', '', '', '', '', '', '', '', txt)\n                else:\n                    tbl.add_row('', '', '', '', '', '', '', '', txt)\n            elif self.gpu:\n                tbl.add_row('', '', '', '', '', txt)\n            else:\n                tbl.add_row('', '', '', '', txt)\n            for fn_name in sorted(fn_stats.cpu_samples_python, key=lambda k: stats.firstline_map[k]):\n                if fn_name == fname:\n                    continue\n                syntax_highlighted = Syntax(fn_name, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n                self.output_profile_line(json=json, fname=fn_name, line_no=LineNumber(1), line=syntax_highlighted, console=console, tbl=tbl, stats=fn_stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=True, suppress_lineno_print=True, is_function_summary=True, reduced_profile=reduced_profile)\n        console.print(tbl)\n        avg_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            n_malloc_mb = stats.memory_aggregate_footprint[fname][line_no]\n            if (count := stats.memory_malloc_count[fname][line_no]):\n                avg_mallocs[line_no] = n_malloc_mb / count\n            else:\n                avg_mallocs[line_no] = n_malloc_mb\n        avg_mallocs = OrderedDict(sorted(avg_mallocs.items(), key=itemgetter(1), reverse=True))\n        peak_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            peak_mallocs[line_no] = stats.memory_max_footprint[fname][line_no]\n        peak_mallocs = OrderedDict(sorted(peak_mallocs.items(), key=itemgetter(1), reverse=True))\n        self.output_top_memory('Top AVERAGE memory consumption, by line:', console, avg_mallocs)\n        self.output_top_memory('Top PEAK memory consumption, by line:', console, peak_mallocs)\n        leaks = ScaleneLeakAnalysis.compute_leaks(growth_rate, stats, avg_mallocs, fname)\n        if len(leaks) > 0:\n            for leak in sorted(leaks, key=itemgetter(1), reverse=True):\n                output_str = f'Possible memory leak identified at line {str(leak[0])} (estimated likelihood: {leak[1] * 100:3.0f}%, velocity: {leak[2] / stats.elapsed_time:3.0f} MB/s)'\n                console.print(output_str)\n    if self.html:\n        md = Markdown('generated by the [scalene](https://github.com/plasma-umass/scalene) profiler')\n        console.print(md)\n        if not self.output_file:\n            self.output_file = '/dev/stdout'\n        console.save_html(self.output_file, clear=False)\n    elif self.output_file:\n        console.save_text(self.output_file, styles=False, clear=False)\n    else:\n        sys.stdout.write(console.export_text(styles=True))\n    return True",
            "def output_profiles(self, column_width: int, stats: ScaleneStatistics, pid: int, profile_this_code: Callable[[Filename, LineNumber], bool], python_alias_dir: Path, program_path: Path, program_args: Optional[List[str]], profile_memory: bool=True, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Write the profile out.'\n    json = ScaleneJSON()\n    json.gpu = self.gpu\n    if not pid:\n        stats.merge_stats(python_alias_dir)\n    if not stats.total_cpu_samples and (not stats.total_memory_malloc_samples) and (not stats.total_memory_free_samples):\n        return False\n    all_instrumented_files: List[Filename] = list(set(list(stats.cpu_samples_python.keys()) + list(stats.cpu_samples_c.keys()) + list(stats.memory_free_samples.keys()) + list(stats.memory_malloc_samples.keys())))\n    if not all_instrumented_files:\n        return False\n    mem_usage_line: Union[Text, str] = ''\n    growth_rate = 0.0\n    if profile_memory:\n        samples = stats.memory_footprint_samples\n        if len(samples) > 0:\n            if len(samples) > ScaleneOutput.max_sparkline_len_file:\n                random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_file))\n            else:\n                random_samples = samples\n            sparkline_samples = [item[1] for item in random_samples]\n            (_, _, spark_str) = sparkline.generate(sparkline_samples[:ScaleneOutput.max_sparkline_len_file], 0, stats.max_footprint)\n            if stats.allocation_velocity[1] > 0:\n                growth_rate = 100.0 * stats.allocation_velocity[0] / stats.allocation_velocity[1]\n            mem_usage_line = Text.assemble('Memory usage: ', (spark_str, self.memory_color), f' (max: {ScaleneJSON.memory_consumed_str(stats.max_footprint)}, growth rate: {growth_rate:3.0f}%)\\n')\n    null = tempfile.TemporaryFile(mode='w+')\n    console = Console(width=column_width, record=True, force_terminal=True, file=null, force_jupyter=False)\n    report_files: List[Filename] = []\n    for fname in sorted(all_instrumented_files, key=lambda f: (-stats.cpu_samples[f], f)):\n        fname = Filename(fname)\n        try:\n            percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples\n        except ZeroDivisionError:\n            percent_cpu_time = 0\n        if stats.malloc_samples[fname] < ScaleneJSON.malloc_threshold and percent_cpu_time < ScaleneJSON.cpu_percent_threshold:\n            continue\n        report_files.append(fname)\n    if pid:\n        stats.output_stats(pid, python_alias_dir)\n        return True\n    if not report_files:\n        return False\n    for fname in report_files:\n        fname_print = fname\n        import re\n        if (result := re.match('_ipython-input-([0-9]+)-.*', fname_print)):\n            fname_print = Filename(f'[{result.group(1)}]')\n        percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples if stats.total_cpu_samples else 0\n        new_title = mem_usage_line + f'{fname_print}: % of time = {percent_cpu_time:6.2f}% ({ScaleneJSON.time_consumed_str(percent_cpu_time / 100.0 * stats.elapsed_time * 1000.0)}) out of {ScaleneJSON.time_consumed_str(stats.elapsed_time * 1000.0)}.'\n        mem_usage_line = ''\n        tbl = Table(box=box.MINIMAL_HEAVY_HEAD, title=new_title, collapse_padding=True, width=column_width - 1)\n        tbl.add_column(Markdown('Line', style='dim'), style='dim', justify='right', no_wrap=True, width=4)\n        tbl.add_column(Markdown('Time  ' + '\\n' + '_Python_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_native_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_system_', style='blue'), style='blue', no_wrap=True, width=6)\n        if self.gpu:\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_GPU_', style=self.gpu_color), style=self.gpu_color, no_wrap=True, width=6)\n        other_columns_width = 0\n        if profile_memory:\n            tbl.add_column(Markdown('Memory  \\n_Python_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=7)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_peak_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=6)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \\n_timeline_/%', style=self.memory_color), style=self.memory_color, no_wrap=True, width=15)\n            tbl.add_column(Markdown('Copy  \\n_(MB/s)_', style=self.copy_volume_color), style=self.copy_volume_color, no_wrap=True, width=6)\n            other_columns_width = 75 + (6 if self.gpu else 0)\n        else:\n            other_columns_width = 37 + (5 if self.gpu else 0)\n        tbl.add_column('\\n' + fname_print, width=column_width - other_columns_width, no_wrap=True)\n        if fname == '<BOGUS>':\n            continue\n        if not fname:\n            continue\n        full_fname = os.path.normpath(os.path.join(program_path, fname))\n        try:\n            with open(full_fname, 'r') as source_file:\n                code_lines = source_file.read()\n        except (FileNotFoundError, OSError):\n            continue\n        did_print = True\n        syntax_highlighted = Syntax(code_lines, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n        capture_console = Console(width=column_width - other_columns_width, force_terminal=True)\n        formatted_lines = [SyntaxLine(segments) for segments in capture_console.render_lines(syntax_highlighted)]\n        for (line_no, line) in enumerate(formatted_lines, start=1):\n            old_did_print = did_print\n            did_print = self.output_profile_line(json=json, fname=fname, line_no=LineNumber(line_no), line=line, console=console, tbl=tbl, stats=stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=False, suppress_lineno_print=False, is_function_summary=False, reduced_profile=reduced_profile)\n            if old_did_print and (not did_print):\n                tbl.add_row('...')\n            old_did_print = did_print\n        fn_stats = stats.build_function_stats(fname)\n        print_fn_summary = False\n        all_samples = set()\n        all_samples |= set(fn_stats.cpu_samples_python.keys())\n        all_samples |= set(fn_stats.cpu_samples_c.keys())\n        all_samples |= set(fn_stats.memory_malloc_samples.keys())\n        all_samples |= set(fn_stats.memory_free_samples.keys())\n        for fn_name in all_samples:\n            if fn_name == fname:\n                continue\n            print_fn_summary = True\n            break\n        if print_fn_summary:\n            try:\n                tbl.add_row(None, end_section=True)\n            except TypeError:\n                tbl.add_row(None)\n            txt = Text.assemble(f'function summary for {fname_print}', style='bold italic')\n            if profile_memory:\n                if self.gpu:\n                    tbl.add_row('', '', '', '', '', '', '', '', '', txt)\n                else:\n                    tbl.add_row('', '', '', '', '', '', '', '', txt)\n            elif self.gpu:\n                tbl.add_row('', '', '', '', '', txt)\n            else:\n                tbl.add_row('', '', '', '', txt)\n            for fn_name in sorted(fn_stats.cpu_samples_python, key=lambda k: stats.firstline_map[k]):\n                if fn_name == fname:\n                    continue\n                syntax_highlighted = Syntax(fn_name, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n                self.output_profile_line(json=json, fname=fn_name, line_no=LineNumber(1), line=syntax_highlighted, console=console, tbl=tbl, stats=fn_stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=True, suppress_lineno_print=True, is_function_summary=True, reduced_profile=reduced_profile)\n        console.print(tbl)\n        avg_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            n_malloc_mb = stats.memory_aggregate_footprint[fname][line_no]\n            if (count := stats.memory_malloc_count[fname][line_no]):\n                avg_mallocs[line_no] = n_malloc_mb / count\n            else:\n                avg_mallocs[line_no] = n_malloc_mb\n        avg_mallocs = OrderedDict(sorted(avg_mallocs.items(), key=itemgetter(1), reverse=True))\n        peak_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            peak_mallocs[line_no] = stats.memory_max_footprint[fname][line_no]\n        peak_mallocs = OrderedDict(sorted(peak_mallocs.items(), key=itemgetter(1), reverse=True))\n        self.output_top_memory('Top AVERAGE memory consumption, by line:', console, avg_mallocs)\n        self.output_top_memory('Top PEAK memory consumption, by line:', console, peak_mallocs)\n        leaks = ScaleneLeakAnalysis.compute_leaks(growth_rate, stats, avg_mallocs, fname)\n        if len(leaks) > 0:\n            for leak in sorted(leaks, key=itemgetter(1), reverse=True):\n                output_str = f'Possible memory leak identified at line {str(leak[0])} (estimated likelihood: {leak[1] * 100:3.0f}%, velocity: {leak[2] / stats.elapsed_time:3.0f} MB/s)'\n                console.print(output_str)\n    if self.html:\n        md = Markdown('generated by the [scalene](https://github.com/plasma-umass/scalene) profiler')\n        console.print(md)\n        if not self.output_file:\n            self.output_file = '/dev/stdout'\n        console.save_html(self.output_file, clear=False)\n    elif self.output_file:\n        console.save_text(self.output_file, styles=False, clear=False)\n    else:\n        sys.stdout.write(console.export_text(styles=True))\n    return True",
            "def output_profiles(self, column_width: int, stats: ScaleneStatistics, pid: int, profile_this_code: Callable[[Filename, LineNumber], bool], python_alias_dir: Path, program_path: Path, program_args: Optional[List[str]], profile_memory: bool=True, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Write the profile out.'\n    json = ScaleneJSON()\n    json.gpu = self.gpu\n    if not pid:\n        stats.merge_stats(python_alias_dir)\n    if not stats.total_cpu_samples and (not stats.total_memory_malloc_samples) and (not stats.total_memory_free_samples):\n        return False\n    all_instrumented_files: List[Filename] = list(set(list(stats.cpu_samples_python.keys()) + list(stats.cpu_samples_c.keys()) + list(stats.memory_free_samples.keys()) + list(stats.memory_malloc_samples.keys())))\n    if not all_instrumented_files:\n        return False\n    mem_usage_line: Union[Text, str] = ''\n    growth_rate = 0.0\n    if profile_memory:\n        samples = stats.memory_footprint_samples\n        if len(samples) > 0:\n            if len(samples) > ScaleneOutput.max_sparkline_len_file:\n                random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_file))\n            else:\n                random_samples = samples\n            sparkline_samples = [item[1] for item in random_samples]\n            (_, _, spark_str) = sparkline.generate(sparkline_samples[:ScaleneOutput.max_sparkline_len_file], 0, stats.max_footprint)\n            if stats.allocation_velocity[1] > 0:\n                growth_rate = 100.0 * stats.allocation_velocity[0] / stats.allocation_velocity[1]\n            mem_usage_line = Text.assemble('Memory usage: ', (spark_str, self.memory_color), f' (max: {ScaleneJSON.memory_consumed_str(stats.max_footprint)}, growth rate: {growth_rate:3.0f}%)\\n')\n    null = tempfile.TemporaryFile(mode='w+')\n    console = Console(width=column_width, record=True, force_terminal=True, file=null, force_jupyter=False)\n    report_files: List[Filename] = []\n    for fname in sorted(all_instrumented_files, key=lambda f: (-stats.cpu_samples[f], f)):\n        fname = Filename(fname)\n        try:\n            percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples\n        except ZeroDivisionError:\n            percent_cpu_time = 0\n        if stats.malloc_samples[fname] < ScaleneJSON.malloc_threshold and percent_cpu_time < ScaleneJSON.cpu_percent_threshold:\n            continue\n        report_files.append(fname)\n    if pid:\n        stats.output_stats(pid, python_alias_dir)\n        return True\n    if not report_files:\n        return False\n    for fname in report_files:\n        fname_print = fname\n        import re\n        if (result := re.match('_ipython-input-([0-9]+)-.*', fname_print)):\n            fname_print = Filename(f'[{result.group(1)}]')\n        percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples if stats.total_cpu_samples else 0\n        new_title = mem_usage_line + f'{fname_print}: % of time = {percent_cpu_time:6.2f}% ({ScaleneJSON.time_consumed_str(percent_cpu_time / 100.0 * stats.elapsed_time * 1000.0)}) out of {ScaleneJSON.time_consumed_str(stats.elapsed_time * 1000.0)}.'\n        mem_usage_line = ''\n        tbl = Table(box=box.MINIMAL_HEAVY_HEAD, title=new_title, collapse_padding=True, width=column_width - 1)\n        tbl.add_column(Markdown('Line', style='dim'), style='dim', justify='right', no_wrap=True, width=4)\n        tbl.add_column(Markdown('Time  ' + '\\n' + '_Python_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_native_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_system_', style='blue'), style='blue', no_wrap=True, width=6)\n        if self.gpu:\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_GPU_', style=self.gpu_color), style=self.gpu_color, no_wrap=True, width=6)\n        other_columns_width = 0\n        if profile_memory:\n            tbl.add_column(Markdown('Memory  \\n_Python_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=7)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_peak_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=6)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \\n_timeline_/%', style=self.memory_color), style=self.memory_color, no_wrap=True, width=15)\n            tbl.add_column(Markdown('Copy  \\n_(MB/s)_', style=self.copy_volume_color), style=self.copy_volume_color, no_wrap=True, width=6)\n            other_columns_width = 75 + (6 if self.gpu else 0)\n        else:\n            other_columns_width = 37 + (5 if self.gpu else 0)\n        tbl.add_column('\\n' + fname_print, width=column_width - other_columns_width, no_wrap=True)\n        if fname == '<BOGUS>':\n            continue\n        if not fname:\n            continue\n        full_fname = os.path.normpath(os.path.join(program_path, fname))\n        try:\n            with open(full_fname, 'r') as source_file:\n                code_lines = source_file.read()\n        except (FileNotFoundError, OSError):\n            continue\n        did_print = True\n        syntax_highlighted = Syntax(code_lines, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n        capture_console = Console(width=column_width - other_columns_width, force_terminal=True)\n        formatted_lines = [SyntaxLine(segments) for segments in capture_console.render_lines(syntax_highlighted)]\n        for (line_no, line) in enumerate(formatted_lines, start=1):\n            old_did_print = did_print\n            did_print = self.output_profile_line(json=json, fname=fname, line_no=LineNumber(line_no), line=line, console=console, tbl=tbl, stats=stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=False, suppress_lineno_print=False, is_function_summary=False, reduced_profile=reduced_profile)\n            if old_did_print and (not did_print):\n                tbl.add_row('...')\n            old_did_print = did_print\n        fn_stats = stats.build_function_stats(fname)\n        print_fn_summary = False\n        all_samples = set()\n        all_samples |= set(fn_stats.cpu_samples_python.keys())\n        all_samples |= set(fn_stats.cpu_samples_c.keys())\n        all_samples |= set(fn_stats.memory_malloc_samples.keys())\n        all_samples |= set(fn_stats.memory_free_samples.keys())\n        for fn_name in all_samples:\n            if fn_name == fname:\n                continue\n            print_fn_summary = True\n            break\n        if print_fn_summary:\n            try:\n                tbl.add_row(None, end_section=True)\n            except TypeError:\n                tbl.add_row(None)\n            txt = Text.assemble(f'function summary for {fname_print}', style='bold italic')\n            if profile_memory:\n                if self.gpu:\n                    tbl.add_row('', '', '', '', '', '', '', '', '', txt)\n                else:\n                    tbl.add_row('', '', '', '', '', '', '', '', txt)\n            elif self.gpu:\n                tbl.add_row('', '', '', '', '', txt)\n            else:\n                tbl.add_row('', '', '', '', txt)\n            for fn_name in sorted(fn_stats.cpu_samples_python, key=lambda k: stats.firstline_map[k]):\n                if fn_name == fname:\n                    continue\n                syntax_highlighted = Syntax(fn_name, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n                self.output_profile_line(json=json, fname=fn_name, line_no=LineNumber(1), line=syntax_highlighted, console=console, tbl=tbl, stats=fn_stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=True, suppress_lineno_print=True, is_function_summary=True, reduced_profile=reduced_profile)\n        console.print(tbl)\n        avg_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            n_malloc_mb = stats.memory_aggregate_footprint[fname][line_no]\n            if (count := stats.memory_malloc_count[fname][line_no]):\n                avg_mallocs[line_no] = n_malloc_mb / count\n            else:\n                avg_mallocs[line_no] = n_malloc_mb\n        avg_mallocs = OrderedDict(sorted(avg_mallocs.items(), key=itemgetter(1), reverse=True))\n        peak_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            peak_mallocs[line_no] = stats.memory_max_footprint[fname][line_no]\n        peak_mallocs = OrderedDict(sorted(peak_mallocs.items(), key=itemgetter(1), reverse=True))\n        self.output_top_memory('Top AVERAGE memory consumption, by line:', console, avg_mallocs)\n        self.output_top_memory('Top PEAK memory consumption, by line:', console, peak_mallocs)\n        leaks = ScaleneLeakAnalysis.compute_leaks(growth_rate, stats, avg_mallocs, fname)\n        if len(leaks) > 0:\n            for leak in sorted(leaks, key=itemgetter(1), reverse=True):\n                output_str = f'Possible memory leak identified at line {str(leak[0])} (estimated likelihood: {leak[1] * 100:3.0f}%, velocity: {leak[2] / stats.elapsed_time:3.0f} MB/s)'\n                console.print(output_str)\n    if self.html:\n        md = Markdown('generated by the [scalene](https://github.com/plasma-umass/scalene) profiler')\n        console.print(md)\n        if not self.output_file:\n            self.output_file = '/dev/stdout'\n        console.save_html(self.output_file, clear=False)\n    elif self.output_file:\n        console.save_text(self.output_file, styles=False, clear=False)\n    else:\n        sys.stdout.write(console.export_text(styles=True))\n    return True",
            "def output_profiles(self, column_width: int, stats: ScaleneStatistics, pid: int, profile_this_code: Callable[[Filename, LineNumber], bool], python_alias_dir: Path, program_path: Path, program_args: Optional[List[str]], profile_memory: bool=True, reduced_profile: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Write the profile out.'\n    json = ScaleneJSON()\n    json.gpu = self.gpu\n    if not pid:\n        stats.merge_stats(python_alias_dir)\n    if not stats.total_cpu_samples and (not stats.total_memory_malloc_samples) and (not stats.total_memory_free_samples):\n        return False\n    all_instrumented_files: List[Filename] = list(set(list(stats.cpu_samples_python.keys()) + list(stats.cpu_samples_c.keys()) + list(stats.memory_free_samples.keys()) + list(stats.memory_malloc_samples.keys())))\n    if not all_instrumented_files:\n        return False\n    mem_usage_line: Union[Text, str] = ''\n    growth_rate = 0.0\n    if profile_memory:\n        samples = stats.memory_footprint_samples\n        if len(samples) > 0:\n            if len(samples) > ScaleneOutput.max_sparkline_len_file:\n                random_samples = sorted(random.sample(samples, ScaleneOutput.max_sparkline_len_file))\n            else:\n                random_samples = samples\n            sparkline_samples = [item[1] for item in random_samples]\n            (_, _, spark_str) = sparkline.generate(sparkline_samples[:ScaleneOutput.max_sparkline_len_file], 0, stats.max_footprint)\n            if stats.allocation_velocity[1] > 0:\n                growth_rate = 100.0 * stats.allocation_velocity[0] / stats.allocation_velocity[1]\n            mem_usage_line = Text.assemble('Memory usage: ', (spark_str, self.memory_color), f' (max: {ScaleneJSON.memory_consumed_str(stats.max_footprint)}, growth rate: {growth_rate:3.0f}%)\\n')\n    null = tempfile.TemporaryFile(mode='w+')\n    console = Console(width=column_width, record=True, force_terminal=True, file=null, force_jupyter=False)\n    report_files: List[Filename] = []\n    for fname in sorted(all_instrumented_files, key=lambda f: (-stats.cpu_samples[f], f)):\n        fname = Filename(fname)\n        try:\n            percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples\n        except ZeroDivisionError:\n            percent_cpu_time = 0\n        if stats.malloc_samples[fname] < ScaleneJSON.malloc_threshold and percent_cpu_time < ScaleneJSON.cpu_percent_threshold:\n            continue\n        report_files.append(fname)\n    if pid:\n        stats.output_stats(pid, python_alias_dir)\n        return True\n    if not report_files:\n        return False\n    for fname in report_files:\n        fname_print = fname\n        import re\n        if (result := re.match('_ipython-input-([0-9]+)-.*', fname_print)):\n            fname_print = Filename(f'[{result.group(1)}]')\n        percent_cpu_time = 100 * stats.cpu_samples[fname] / stats.total_cpu_samples if stats.total_cpu_samples else 0\n        new_title = mem_usage_line + f'{fname_print}: % of time = {percent_cpu_time:6.2f}% ({ScaleneJSON.time_consumed_str(percent_cpu_time / 100.0 * stats.elapsed_time * 1000.0)}) out of {ScaleneJSON.time_consumed_str(stats.elapsed_time * 1000.0)}.'\n        mem_usage_line = ''\n        tbl = Table(box=box.MINIMAL_HEAVY_HEAD, title=new_title, collapse_padding=True, width=column_width - 1)\n        tbl.add_column(Markdown('Line', style='dim'), style='dim', justify='right', no_wrap=True, width=4)\n        tbl.add_column(Markdown('Time  ' + '\\n' + '_Python_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_native_', style='blue'), style='blue', no_wrap=True, width=6)\n        tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_system_', style='blue'), style='blue', no_wrap=True, width=6)\n        if self.gpu:\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_GPU_', style=self.gpu_color), style=self.gpu_color, no_wrap=True, width=6)\n        other_columns_width = 0\n        if profile_memory:\n            tbl.add_column(Markdown('Memory  \\n_Python_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=7)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013  \\n_peak_', style=self.memory_color), style=self.memory_color, no_wrap=True, width=6)\n            tbl.add_column(Markdown('\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \\n_timeline_/%', style=self.memory_color), style=self.memory_color, no_wrap=True, width=15)\n            tbl.add_column(Markdown('Copy  \\n_(MB/s)_', style=self.copy_volume_color), style=self.copy_volume_color, no_wrap=True, width=6)\n            other_columns_width = 75 + (6 if self.gpu else 0)\n        else:\n            other_columns_width = 37 + (5 if self.gpu else 0)\n        tbl.add_column('\\n' + fname_print, width=column_width - other_columns_width, no_wrap=True)\n        if fname == '<BOGUS>':\n            continue\n        if not fname:\n            continue\n        full_fname = os.path.normpath(os.path.join(program_path, fname))\n        try:\n            with open(full_fname, 'r') as source_file:\n                code_lines = source_file.read()\n        except (FileNotFoundError, OSError):\n            continue\n        did_print = True\n        syntax_highlighted = Syntax(code_lines, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n        capture_console = Console(width=column_width - other_columns_width, force_terminal=True)\n        formatted_lines = [SyntaxLine(segments) for segments in capture_console.render_lines(syntax_highlighted)]\n        for (line_no, line) in enumerate(formatted_lines, start=1):\n            old_did_print = did_print\n            did_print = self.output_profile_line(json=json, fname=fname, line_no=LineNumber(line_no), line=line, console=console, tbl=tbl, stats=stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=False, suppress_lineno_print=False, is_function_summary=False, reduced_profile=reduced_profile)\n            if old_did_print and (not did_print):\n                tbl.add_row('...')\n            old_did_print = did_print\n        fn_stats = stats.build_function_stats(fname)\n        print_fn_summary = False\n        all_samples = set()\n        all_samples |= set(fn_stats.cpu_samples_python.keys())\n        all_samples |= set(fn_stats.cpu_samples_c.keys())\n        all_samples |= set(fn_stats.memory_malloc_samples.keys())\n        all_samples |= set(fn_stats.memory_free_samples.keys())\n        for fn_name in all_samples:\n            if fn_name == fname:\n                continue\n            print_fn_summary = True\n            break\n        if print_fn_summary:\n            try:\n                tbl.add_row(None, end_section=True)\n            except TypeError:\n                tbl.add_row(None)\n            txt = Text.assemble(f'function summary for {fname_print}', style='bold italic')\n            if profile_memory:\n                if self.gpu:\n                    tbl.add_row('', '', '', '', '', '', '', '', '', txt)\n                else:\n                    tbl.add_row('', '', '', '', '', '', '', '', txt)\n            elif self.gpu:\n                tbl.add_row('', '', '', '', '', txt)\n            else:\n                tbl.add_row('', '', '', '', txt)\n            for fn_name in sorted(fn_stats.cpu_samples_python, key=lambda k: stats.firstline_map[k]):\n                if fn_name == fname:\n                    continue\n                syntax_highlighted = Syntax(fn_name, 'python', theme='default' if self.html else 'vim', line_numbers=False, code_width=None)\n                self.output_profile_line(json=json, fname=fn_name, line_no=LineNumber(1), line=syntax_highlighted, console=console, tbl=tbl, stats=fn_stats, profile_this_code=profile_this_code, profile_memory=profile_memory, force_print=True, suppress_lineno_print=True, is_function_summary=True, reduced_profile=reduced_profile)\n        console.print(tbl)\n        avg_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            n_malloc_mb = stats.memory_aggregate_footprint[fname][line_no]\n            if (count := stats.memory_malloc_count[fname][line_no]):\n                avg_mallocs[line_no] = n_malloc_mb / count\n            else:\n                avg_mallocs[line_no] = n_malloc_mb\n        avg_mallocs = OrderedDict(sorted(avg_mallocs.items(), key=itemgetter(1), reverse=True))\n        peak_mallocs: Dict[LineNumber, float] = defaultdict(float)\n        for line_no in stats.bytei_map[fname]:\n            peak_mallocs[line_no] = stats.memory_max_footprint[fname][line_no]\n        peak_mallocs = OrderedDict(sorted(peak_mallocs.items(), key=itemgetter(1), reverse=True))\n        self.output_top_memory('Top AVERAGE memory consumption, by line:', console, avg_mallocs)\n        self.output_top_memory('Top PEAK memory consumption, by line:', console, peak_mallocs)\n        leaks = ScaleneLeakAnalysis.compute_leaks(growth_rate, stats, avg_mallocs, fname)\n        if len(leaks) > 0:\n            for leak in sorted(leaks, key=itemgetter(1), reverse=True):\n                output_str = f'Possible memory leak identified at line {str(leak[0])} (estimated likelihood: {leak[1] * 100:3.0f}%, velocity: {leak[2] / stats.elapsed_time:3.0f} MB/s)'\n                console.print(output_str)\n    if self.html:\n        md = Markdown('generated by the [scalene](https://github.com/plasma-umass/scalene) profiler')\n        console.print(md)\n        if not self.output_file:\n            self.output_file = '/dev/stdout'\n        console.save_html(self.output_file, clear=False)\n    elif self.output_file:\n        console.save_text(self.output_file, styles=False, clear=False)\n    else:\n        sys.stdout.write(console.export_text(styles=True))\n    return True"
        ]
    }
]