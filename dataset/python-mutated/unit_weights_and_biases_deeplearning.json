[
    {
        "func_name": "weights_and_biases",
        "original": "def weights_and_biases():\n    print('Test checks if Deep Learning weights and biases are accessible from R')\n    covtype = h2o.upload_file(pyunit_utils.locate('smalldata/covtype/covtype.20k.data'))\n    covtype[54] = covtype[54].asfactor()\n    dlmodel = H2ODeepLearningEstimator(hidden=[17, 191], epochs=1, balance_classes=False, reproducible=True, seed=1234, export_weights_and_biases=True)\n    dlmodel.train(x=list(range(54)), y=54, training_frame=covtype)\n    print(dlmodel)\n    weights1 = dlmodel.weights(0)\n    weights2 = dlmodel.weights(1)\n    weights3 = dlmodel.weights(2)\n    biases1 = dlmodel.biases(0)\n    biases2 = dlmodel.biases(1)\n    biases3 = dlmodel.biases(2)\n    w1c = weights1.ncol\n    w1r = weights1.nrow\n    assert w1c == 52, 'wrong dimensionality! expected {0}, but got {1}.'.format(52, w1c)\n    assert w1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w1r)\n    w2c = weights2.ncol\n    w2r = weights2.nrow\n    assert w2c == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w2c)\n    assert w2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w2r)\n    w3c = weights3.ncol\n    w3r = weights3.nrow\n    assert w3c == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w3c)\n    assert w3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, w3r)\n    b1c = biases1.ncol\n    b1r = biases1.nrow\n    assert b1c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b1c)\n    assert b1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, b1r)\n    b2c = biases2.ncol\n    b2r = biases2.nrow\n    assert b2c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b2c)\n    assert b2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, b2r)\n    b3c = biases3.ncol\n    b3r = biases3.nrow\n    assert b3c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b3c)\n    assert b3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, b3r)\n    df = h2o.import_file(pyunit_utils.locate('smalldata/iris/iris.csv'))\n    dl1 = H2ODeepLearningEstimator(hidden=[10, 10], export_weights_and_biases=True)\n    dl1.train(x=list(range(4)), y=4, training_frame=df)\n    p1 = dl1.predict(df)\n    ll1 = dl1.model_performance(df).logloss()\n    print(ll1)\n    w1 = dl1.weights(0)\n    w2 = dl1.weights(1)\n    w3 = dl1.weights(2)\n    b1 = dl1.biases(0)\n    b2 = dl1.biases(1)\n    b3 = dl1.biases(2)\n    dl2 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, w2, w3], initial_biases=[b1, b2, b3], epochs=0)\n    dl2.train(x=list(range(4)), y=4, training_frame=df)\n    p2 = dl2.predict(df)\n    ll2 = dl2.model_performance(df).logloss()\n    print(ll2)\n    assert abs(p1[:, 1:4] - p2[:, 1:4]).max() < 1e-06\n    assert abs(ll2 - ll1) < 1e-06\n    dl3 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, None, w3], initial_biases=[b1, b2, None], epochs=10)\n    dl3.train(x=list(range(4)), y=4, training_frame=df)\n    ll3 = dl3.model_performance(df).logloss()\n    dl4 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1 * 1.1, w2 * 0.9, w3.sqrt()], initial_biases=[b1, b2, None], epochs=10)\n    dl4.train(x=list(range(4)), y=4, training_frame=df)\n    ll4 = dl4.model_performance(df).logloss()",
        "mutated": [
            "def weights_and_biases():\n    if False:\n        i = 10\n    print('Test checks if Deep Learning weights and biases are accessible from R')\n    covtype = h2o.upload_file(pyunit_utils.locate('smalldata/covtype/covtype.20k.data'))\n    covtype[54] = covtype[54].asfactor()\n    dlmodel = H2ODeepLearningEstimator(hidden=[17, 191], epochs=1, balance_classes=False, reproducible=True, seed=1234, export_weights_and_biases=True)\n    dlmodel.train(x=list(range(54)), y=54, training_frame=covtype)\n    print(dlmodel)\n    weights1 = dlmodel.weights(0)\n    weights2 = dlmodel.weights(1)\n    weights3 = dlmodel.weights(2)\n    biases1 = dlmodel.biases(0)\n    biases2 = dlmodel.biases(1)\n    biases3 = dlmodel.biases(2)\n    w1c = weights1.ncol\n    w1r = weights1.nrow\n    assert w1c == 52, 'wrong dimensionality! expected {0}, but got {1}.'.format(52, w1c)\n    assert w1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w1r)\n    w2c = weights2.ncol\n    w2r = weights2.nrow\n    assert w2c == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w2c)\n    assert w2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w2r)\n    w3c = weights3.ncol\n    w3r = weights3.nrow\n    assert w3c == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w3c)\n    assert w3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, w3r)\n    b1c = biases1.ncol\n    b1r = biases1.nrow\n    assert b1c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b1c)\n    assert b1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, b1r)\n    b2c = biases2.ncol\n    b2r = biases2.nrow\n    assert b2c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b2c)\n    assert b2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, b2r)\n    b3c = biases3.ncol\n    b3r = biases3.nrow\n    assert b3c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b3c)\n    assert b3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, b3r)\n    df = h2o.import_file(pyunit_utils.locate('smalldata/iris/iris.csv'))\n    dl1 = H2ODeepLearningEstimator(hidden=[10, 10], export_weights_and_biases=True)\n    dl1.train(x=list(range(4)), y=4, training_frame=df)\n    p1 = dl1.predict(df)\n    ll1 = dl1.model_performance(df).logloss()\n    print(ll1)\n    w1 = dl1.weights(0)\n    w2 = dl1.weights(1)\n    w3 = dl1.weights(2)\n    b1 = dl1.biases(0)\n    b2 = dl1.biases(1)\n    b3 = dl1.biases(2)\n    dl2 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, w2, w3], initial_biases=[b1, b2, b3], epochs=0)\n    dl2.train(x=list(range(4)), y=4, training_frame=df)\n    p2 = dl2.predict(df)\n    ll2 = dl2.model_performance(df).logloss()\n    print(ll2)\n    assert abs(p1[:, 1:4] - p2[:, 1:4]).max() < 1e-06\n    assert abs(ll2 - ll1) < 1e-06\n    dl3 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, None, w3], initial_biases=[b1, b2, None], epochs=10)\n    dl3.train(x=list(range(4)), y=4, training_frame=df)\n    ll3 = dl3.model_performance(df).logloss()\n    dl4 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1 * 1.1, w2 * 0.9, w3.sqrt()], initial_biases=[b1, b2, None], epochs=10)\n    dl4.train(x=list(range(4)), y=4, training_frame=df)\n    ll4 = dl4.model_performance(df).logloss()",
            "def weights_and_biases():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    print('Test checks if Deep Learning weights and biases are accessible from R')\n    covtype = h2o.upload_file(pyunit_utils.locate('smalldata/covtype/covtype.20k.data'))\n    covtype[54] = covtype[54].asfactor()\n    dlmodel = H2ODeepLearningEstimator(hidden=[17, 191], epochs=1, balance_classes=False, reproducible=True, seed=1234, export_weights_and_biases=True)\n    dlmodel.train(x=list(range(54)), y=54, training_frame=covtype)\n    print(dlmodel)\n    weights1 = dlmodel.weights(0)\n    weights2 = dlmodel.weights(1)\n    weights3 = dlmodel.weights(2)\n    biases1 = dlmodel.biases(0)\n    biases2 = dlmodel.biases(1)\n    biases3 = dlmodel.biases(2)\n    w1c = weights1.ncol\n    w1r = weights1.nrow\n    assert w1c == 52, 'wrong dimensionality! expected {0}, but got {1}.'.format(52, w1c)\n    assert w1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w1r)\n    w2c = weights2.ncol\n    w2r = weights2.nrow\n    assert w2c == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w2c)\n    assert w2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w2r)\n    w3c = weights3.ncol\n    w3r = weights3.nrow\n    assert w3c == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w3c)\n    assert w3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, w3r)\n    b1c = biases1.ncol\n    b1r = biases1.nrow\n    assert b1c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b1c)\n    assert b1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, b1r)\n    b2c = biases2.ncol\n    b2r = biases2.nrow\n    assert b2c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b2c)\n    assert b2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, b2r)\n    b3c = biases3.ncol\n    b3r = biases3.nrow\n    assert b3c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b3c)\n    assert b3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, b3r)\n    df = h2o.import_file(pyunit_utils.locate('smalldata/iris/iris.csv'))\n    dl1 = H2ODeepLearningEstimator(hidden=[10, 10], export_weights_and_biases=True)\n    dl1.train(x=list(range(4)), y=4, training_frame=df)\n    p1 = dl1.predict(df)\n    ll1 = dl1.model_performance(df).logloss()\n    print(ll1)\n    w1 = dl1.weights(0)\n    w2 = dl1.weights(1)\n    w3 = dl1.weights(2)\n    b1 = dl1.biases(0)\n    b2 = dl1.biases(1)\n    b3 = dl1.biases(2)\n    dl2 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, w2, w3], initial_biases=[b1, b2, b3], epochs=0)\n    dl2.train(x=list(range(4)), y=4, training_frame=df)\n    p2 = dl2.predict(df)\n    ll2 = dl2.model_performance(df).logloss()\n    print(ll2)\n    assert abs(p1[:, 1:4] - p2[:, 1:4]).max() < 1e-06\n    assert abs(ll2 - ll1) < 1e-06\n    dl3 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, None, w3], initial_biases=[b1, b2, None], epochs=10)\n    dl3.train(x=list(range(4)), y=4, training_frame=df)\n    ll3 = dl3.model_performance(df).logloss()\n    dl4 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1 * 1.1, w2 * 0.9, w3.sqrt()], initial_biases=[b1, b2, None], epochs=10)\n    dl4.train(x=list(range(4)), y=4, training_frame=df)\n    ll4 = dl4.model_performance(df).logloss()",
            "def weights_and_biases():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    print('Test checks if Deep Learning weights and biases are accessible from R')\n    covtype = h2o.upload_file(pyunit_utils.locate('smalldata/covtype/covtype.20k.data'))\n    covtype[54] = covtype[54].asfactor()\n    dlmodel = H2ODeepLearningEstimator(hidden=[17, 191], epochs=1, balance_classes=False, reproducible=True, seed=1234, export_weights_and_biases=True)\n    dlmodel.train(x=list(range(54)), y=54, training_frame=covtype)\n    print(dlmodel)\n    weights1 = dlmodel.weights(0)\n    weights2 = dlmodel.weights(1)\n    weights3 = dlmodel.weights(2)\n    biases1 = dlmodel.biases(0)\n    biases2 = dlmodel.biases(1)\n    biases3 = dlmodel.biases(2)\n    w1c = weights1.ncol\n    w1r = weights1.nrow\n    assert w1c == 52, 'wrong dimensionality! expected {0}, but got {1}.'.format(52, w1c)\n    assert w1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w1r)\n    w2c = weights2.ncol\n    w2r = weights2.nrow\n    assert w2c == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w2c)\n    assert w2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w2r)\n    w3c = weights3.ncol\n    w3r = weights3.nrow\n    assert w3c == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w3c)\n    assert w3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, w3r)\n    b1c = biases1.ncol\n    b1r = biases1.nrow\n    assert b1c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b1c)\n    assert b1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, b1r)\n    b2c = biases2.ncol\n    b2r = biases2.nrow\n    assert b2c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b2c)\n    assert b2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, b2r)\n    b3c = biases3.ncol\n    b3r = biases3.nrow\n    assert b3c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b3c)\n    assert b3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, b3r)\n    df = h2o.import_file(pyunit_utils.locate('smalldata/iris/iris.csv'))\n    dl1 = H2ODeepLearningEstimator(hidden=[10, 10], export_weights_and_biases=True)\n    dl1.train(x=list(range(4)), y=4, training_frame=df)\n    p1 = dl1.predict(df)\n    ll1 = dl1.model_performance(df).logloss()\n    print(ll1)\n    w1 = dl1.weights(0)\n    w2 = dl1.weights(1)\n    w3 = dl1.weights(2)\n    b1 = dl1.biases(0)\n    b2 = dl1.biases(1)\n    b3 = dl1.biases(2)\n    dl2 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, w2, w3], initial_biases=[b1, b2, b3], epochs=0)\n    dl2.train(x=list(range(4)), y=4, training_frame=df)\n    p2 = dl2.predict(df)\n    ll2 = dl2.model_performance(df).logloss()\n    print(ll2)\n    assert abs(p1[:, 1:4] - p2[:, 1:4]).max() < 1e-06\n    assert abs(ll2 - ll1) < 1e-06\n    dl3 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, None, w3], initial_biases=[b1, b2, None], epochs=10)\n    dl3.train(x=list(range(4)), y=4, training_frame=df)\n    ll3 = dl3.model_performance(df).logloss()\n    dl4 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1 * 1.1, w2 * 0.9, w3.sqrt()], initial_biases=[b1, b2, None], epochs=10)\n    dl4.train(x=list(range(4)), y=4, training_frame=df)\n    ll4 = dl4.model_performance(df).logloss()",
            "def weights_and_biases():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    print('Test checks if Deep Learning weights and biases are accessible from R')\n    covtype = h2o.upload_file(pyunit_utils.locate('smalldata/covtype/covtype.20k.data'))\n    covtype[54] = covtype[54].asfactor()\n    dlmodel = H2ODeepLearningEstimator(hidden=[17, 191], epochs=1, balance_classes=False, reproducible=True, seed=1234, export_weights_and_biases=True)\n    dlmodel.train(x=list(range(54)), y=54, training_frame=covtype)\n    print(dlmodel)\n    weights1 = dlmodel.weights(0)\n    weights2 = dlmodel.weights(1)\n    weights3 = dlmodel.weights(2)\n    biases1 = dlmodel.biases(0)\n    biases2 = dlmodel.biases(1)\n    biases3 = dlmodel.biases(2)\n    w1c = weights1.ncol\n    w1r = weights1.nrow\n    assert w1c == 52, 'wrong dimensionality! expected {0}, but got {1}.'.format(52, w1c)\n    assert w1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w1r)\n    w2c = weights2.ncol\n    w2r = weights2.nrow\n    assert w2c == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w2c)\n    assert w2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w2r)\n    w3c = weights3.ncol\n    w3r = weights3.nrow\n    assert w3c == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w3c)\n    assert w3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, w3r)\n    b1c = biases1.ncol\n    b1r = biases1.nrow\n    assert b1c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b1c)\n    assert b1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, b1r)\n    b2c = biases2.ncol\n    b2r = biases2.nrow\n    assert b2c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b2c)\n    assert b2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, b2r)\n    b3c = biases3.ncol\n    b3r = biases3.nrow\n    assert b3c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b3c)\n    assert b3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, b3r)\n    df = h2o.import_file(pyunit_utils.locate('smalldata/iris/iris.csv'))\n    dl1 = H2ODeepLearningEstimator(hidden=[10, 10], export_weights_and_biases=True)\n    dl1.train(x=list(range(4)), y=4, training_frame=df)\n    p1 = dl1.predict(df)\n    ll1 = dl1.model_performance(df).logloss()\n    print(ll1)\n    w1 = dl1.weights(0)\n    w2 = dl1.weights(1)\n    w3 = dl1.weights(2)\n    b1 = dl1.biases(0)\n    b2 = dl1.biases(1)\n    b3 = dl1.biases(2)\n    dl2 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, w2, w3], initial_biases=[b1, b2, b3], epochs=0)\n    dl2.train(x=list(range(4)), y=4, training_frame=df)\n    p2 = dl2.predict(df)\n    ll2 = dl2.model_performance(df).logloss()\n    print(ll2)\n    assert abs(p1[:, 1:4] - p2[:, 1:4]).max() < 1e-06\n    assert abs(ll2 - ll1) < 1e-06\n    dl3 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, None, w3], initial_biases=[b1, b2, None], epochs=10)\n    dl3.train(x=list(range(4)), y=4, training_frame=df)\n    ll3 = dl3.model_performance(df).logloss()\n    dl4 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1 * 1.1, w2 * 0.9, w3.sqrt()], initial_biases=[b1, b2, None], epochs=10)\n    dl4.train(x=list(range(4)), y=4, training_frame=df)\n    ll4 = dl4.model_performance(df).logloss()",
            "def weights_and_biases():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    print('Test checks if Deep Learning weights and biases are accessible from R')\n    covtype = h2o.upload_file(pyunit_utils.locate('smalldata/covtype/covtype.20k.data'))\n    covtype[54] = covtype[54].asfactor()\n    dlmodel = H2ODeepLearningEstimator(hidden=[17, 191], epochs=1, balance_classes=False, reproducible=True, seed=1234, export_weights_and_biases=True)\n    dlmodel.train(x=list(range(54)), y=54, training_frame=covtype)\n    print(dlmodel)\n    weights1 = dlmodel.weights(0)\n    weights2 = dlmodel.weights(1)\n    weights3 = dlmodel.weights(2)\n    biases1 = dlmodel.biases(0)\n    biases2 = dlmodel.biases(1)\n    biases3 = dlmodel.biases(2)\n    w1c = weights1.ncol\n    w1r = weights1.nrow\n    assert w1c == 52, 'wrong dimensionality! expected {0}, but got {1}.'.format(52, w1c)\n    assert w1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w1r)\n    w2c = weights2.ncol\n    w2r = weights2.nrow\n    assert w2c == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, w2c)\n    assert w2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w2r)\n    w3c = weights3.ncol\n    w3r = weights3.nrow\n    assert w3c == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, w3c)\n    assert w3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, w3r)\n    b1c = biases1.ncol\n    b1r = biases1.nrow\n    assert b1c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b1c)\n    assert b1r == 17, 'wrong dimensionality! expected {0}, but got {1}.'.format(17, b1r)\n    b2c = biases2.ncol\n    b2r = biases2.nrow\n    assert b2c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b2c)\n    assert b2r == 191, 'wrong dimensionality! expected {0}, but got {1}.'.format(191, b2r)\n    b3c = biases3.ncol\n    b3r = biases3.nrow\n    assert b3c == 1, 'wrong dimensionality! expected {0}, but got {1}.'.format(1, b3c)\n    assert b3r == 7, 'wrong dimensionality! expected {0}, but got {1}.'.format(7, b3r)\n    df = h2o.import_file(pyunit_utils.locate('smalldata/iris/iris.csv'))\n    dl1 = H2ODeepLearningEstimator(hidden=[10, 10], export_weights_and_biases=True)\n    dl1.train(x=list(range(4)), y=4, training_frame=df)\n    p1 = dl1.predict(df)\n    ll1 = dl1.model_performance(df).logloss()\n    print(ll1)\n    w1 = dl1.weights(0)\n    w2 = dl1.weights(1)\n    w3 = dl1.weights(2)\n    b1 = dl1.biases(0)\n    b2 = dl1.biases(1)\n    b3 = dl1.biases(2)\n    dl2 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, w2, w3], initial_biases=[b1, b2, b3], epochs=0)\n    dl2.train(x=list(range(4)), y=4, training_frame=df)\n    p2 = dl2.predict(df)\n    ll2 = dl2.model_performance(df).logloss()\n    print(ll2)\n    assert abs(p1[:, 1:4] - p2[:, 1:4]).max() < 1e-06\n    assert abs(ll2 - ll1) < 1e-06\n    dl3 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1, None, w3], initial_biases=[b1, b2, None], epochs=10)\n    dl3.train(x=list(range(4)), y=4, training_frame=df)\n    ll3 = dl3.model_performance(df).logloss()\n    dl4 = H2ODeepLearningEstimator(hidden=[10, 10], initial_weights=[w1 * 1.1, w2 * 0.9, w3.sqrt()], initial_biases=[b1, b2, None], epochs=10)\n    dl4.train(x=list(range(4)), y=4, training_frame=df)\n    ll4 = dl4.model_performance(df).logloss()"
        ]
    }
]