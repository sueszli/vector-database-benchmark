[
    {
        "func_name": "convert_to_line_delimits",
        "original": "def convert_to_line_delimits(s: str) -> str:\n    \"\"\"\n    Helper function that converts JSON lists to line delimited JSON.\n    \"\"\"\n    if not s[0] == '[' and s[-1] == ']':\n        return s\n    s = s[1:-1]\n    return convert_json_to_lines(s)",
        "mutated": [
            "def convert_to_line_delimits(s: str) -> str:\n    if False:\n        i = 10\n    '\\n    Helper function that converts JSON lists to line delimited JSON.\\n    '\n    if not s[0] == '[' and s[-1] == ']':\n        return s\n    s = s[1:-1]\n    return convert_json_to_lines(s)",
            "def convert_to_line_delimits(s: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Helper function that converts JSON lists to line delimited JSON.\\n    '\n    if not s[0] == '[' and s[-1] == ']':\n        return s\n    s = s[1:-1]\n    return convert_json_to_lines(s)",
            "def convert_to_line_delimits(s: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Helper function that converts JSON lists to line delimited JSON.\\n    '\n    if not s[0] == '[' and s[-1] == ']':\n        return s\n    s = s[1:-1]\n    return convert_json_to_lines(s)",
            "def convert_to_line_delimits(s: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Helper function that converts JSON lists to line delimited JSON.\\n    '\n    if not s[0] == '[' and s[-1] == ']':\n        return s\n    s = s[1:-1]\n    return convert_json_to_lines(s)",
            "def convert_to_line_delimits(s: str) -> str:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Helper function that converts JSON lists to line delimited JSON.\\n    '\n    if not s[0] == '[' and s[-1] == ']':\n        return s\n    s = s[1:-1]\n    return convert_json_to_lines(s)"
        ]
    },
    {
        "func_name": "nested_to_record",
        "original": "def nested_to_record(ds, prefix: str='', sep: str='.', level: int=0, max_level: int | None=None):\n    \"\"\"\n    A simplified json_normalize\n\n    Converts a nested dict into a flat dict (\"record\"), unlike json_normalize,\n    it does not attempt to extract a subset of the data.\n\n    Parameters\n    ----------\n    ds : dict or list of dicts\n    prefix: the prefix, optional, default: \"\"\n    sep : str, default '.'\n        Nested records will generate names separated by sep,\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\n    level: int, optional, default: 0\n        The number of levels in the json string.\n\n    max_level: int, optional, default: None\n        The max depth to normalize.\n\n    Returns\n    -------\n    d - dict or list of dicts, matching `ds`\n\n    Examples\n    --------\n    >>> nested_to_record(\n    ...     dict(flat1=1, dict1=dict(c=1, d=2), nested=dict(e=dict(c=1, d=2), d=2))\n    ... )\n    {'flat1': 1, 'dict1.c': 1, 'dict1.d': 2, 'nested.e.c': 1, 'nested.e.d': 2, 'nested.d': 2}\n    \"\"\"\n    singleton = False\n    if isinstance(ds, dict):\n        ds = [ds]\n        singleton = True\n    new_ds = []\n    for d in ds:\n        new_d = copy.deepcopy(d)\n        for (k, v) in d.items():\n            if not isinstance(k, str):\n                k = str(k)\n            if level == 0:\n                newkey = k\n            else:\n                newkey = prefix + sep + k\n            if not isinstance(v, dict) or (max_level is not None and level >= max_level):\n                if level != 0:\n                    v = new_d.pop(k)\n                    new_d[newkey] = v\n                continue\n            v = new_d.pop(k)\n            new_d.update(nested_to_record(v, newkey, sep, level + 1, max_level))\n        new_ds.append(new_d)\n    if singleton:\n        return new_ds[0]\n    return new_ds",
        "mutated": [
            "def nested_to_record(ds, prefix: str='', sep: str='.', level: int=0, max_level: int | None=None):\n    if False:\n        i = 10\n    '\\n    A simplified json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike json_normalize,\\n    it does not attempt to extract a subset of the data.\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    prefix: the prefix, optional, default: \"\"\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n    level: int, optional, default: 0\\n        The number of levels in the json string.\\n\\n    max_level: int, optional, default: None\\n        The max depth to normalize.\\n\\n    Returns\\n    -------\\n    d - dict or list of dicts, matching `ds`\\n\\n    Examples\\n    --------\\n    >>> nested_to_record(\\n    ...     dict(flat1=1, dict1=dict(c=1, d=2), nested=dict(e=dict(c=1, d=2), d=2))\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n    '\n    singleton = False\n    if isinstance(ds, dict):\n        ds = [ds]\n        singleton = True\n    new_ds = []\n    for d in ds:\n        new_d = copy.deepcopy(d)\n        for (k, v) in d.items():\n            if not isinstance(k, str):\n                k = str(k)\n            if level == 0:\n                newkey = k\n            else:\n                newkey = prefix + sep + k\n            if not isinstance(v, dict) or (max_level is not None and level >= max_level):\n                if level != 0:\n                    v = new_d.pop(k)\n                    new_d[newkey] = v\n                continue\n            v = new_d.pop(k)\n            new_d.update(nested_to_record(v, newkey, sep, level + 1, max_level))\n        new_ds.append(new_d)\n    if singleton:\n        return new_ds[0]\n    return new_ds",
            "def nested_to_record(ds, prefix: str='', sep: str='.', level: int=0, max_level: int | None=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    A simplified json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike json_normalize,\\n    it does not attempt to extract a subset of the data.\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    prefix: the prefix, optional, default: \"\"\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n    level: int, optional, default: 0\\n        The number of levels in the json string.\\n\\n    max_level: int, optional, default: None\\n        The max depth to normalize.\\n\\n    Returns\\n    -------\\n    d - dict or list of dicts, matching `ds`\\n\\n    Examples\\n    --------\\n    >>> nested_to_record(\\n    ...     dict(flat1=1, dict1=dict(c=1, d=2), nested=dict(e=dict(c=1, d=2), d=2))\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n    '\n    singleton = False\n    if isinstance(ds, dict):\n        ds = [ds]\n        singleton = True\n    new_ds = []\n    for d in ds:\n        new_d = copy.deepcopy(d)\n        for (k, v) in d.items():\n            if not isinstance(k, str):\n                k = str(k)\n            if level == 0:\n                newkey = k\n            else:\n                newkey = prefix + sep + k\n            if not isinstance(v, dict) or (max_level is not None and level >= max_level):\n                if level != 0:\n                    v = new_d.pop(k)\n                    new_d[newkey] = v\n                continue\n            v = new_d.pop(k)\n            new_d.update(nested_to_record(v, newkey, sep, level + 1, max_level))\n        new_ds.append(new_d)\n    if singleton:\n        return new_ds[0]\n    return new_ds",
            "def nested_to_record(ds, prefix: str='', sep: str='.', level: int=0, max_level: int | None=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    A simplified json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike json_normalize,\\n    it does not attempt to extract a subset of the data.\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    prefix: the prefix, optional, default: \"\"\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n    level: int, optional, default: 0\\n        The number of levels in the json string.\\n\\n    max_level: int, optional, default: None\\n        The max depth to normalize.\\n\\n    Returns\\n    -------\\n    d - dict or list of dicts, matching `ds`\\n\\n    Examples\\n    --------\\n    >>> nested_to_record(\\n    ...     dict(flat1=1, dict1=dict(c=1, d=2), nested=dict(e=dict(c=1, d=2), d=2))\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n    '\n    singleton = False\n    if isinstance(ds, dict):\n        ds = [ds]\n        singleton = True\n    new_ds = []\n    for d in ds:\n        new_d = copy.deepcopy(d)\n        for (k, v) in d.items():\n            if not isinstance(k, str):\n                k = str(k)\n            if level == 0:\n                newkey = k\n            else:\n                newkey = prefix + sep + k\n            if not isinstance(v, dict) or (max_level is not None and level >= max_level):\n                if level != 0:\n                    v = new_d.pop(k)\n                    new_d[newkey] = v\n                continue\n            v = new_d.pop(k)\n            new_d.update(nested_to_record(v, newkey, sep, level + 1, max_level))\n        new_ds.append(new_d)\n    if singleton:\n        return new_ds[0]\n    return new_ds",
            "def nested_to_record(ds, prefix: str='', sep: str='.', level: int=0, max_level: int | None=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    A simplified json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike json_normalize,\\n    it does not attempt to extract a subset of the data.\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    prefix: the prefix, optional, default: \"\"\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n    level: int, optional, default: 0\\n        The number of levels in the json string.\\n\\n    max_level: int, optional, default: None\\n        The max depth to normalize.\\n\\n    Returns\\n    -------\\n    d - dict or list of dicts, matching `ds`\\n\\n    Examples\\n    --------\\n    >>> nested_to_record(\\n    ...     dict(flat1=1, dict1=dict(c=1, d=2), nested=dict(e=dict(c=1, d=2), d=2))\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n    '\n    singleton = False\n    if isinstance(ds, dict):\n        ds = [ds]\n        singleton = True\n    new_ds = []\n    for d in ds:\n        new_d = copy.deepcopy(d)\n        for (k, v) in d.items():\n            if not isinstance(k, str):\n                k = str(k)\n            if level == 0:\n                newkey = k\n            else:\n                newkey = prefix + sep + k\n            if not isinstance(v, dict) or (max_level is not None and level >= max_level):\n                if level != 0:\n                    v = new_d.pop(k)\n                    new_d[newkey] = v\n                continue\n            v = new_d.pop(k)\n            new_d.update(nested_to_record(v, newkey, sep, level + 1, max_level))\n        new_ds.append(new_d)\n    if singleton:\n        return new_ds[0]\n    return new_ds",
            "def nested_to_record(ds, prefix: str='', sep: str='.', level: int=0, max_level: int | None=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    A simplified json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike json_normalize,\\n    it does not attempt to extract a subset of the data.\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    prefix: the prefix, optional, default: \"\"\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n    level: int, optional, default: 0\\n        The number of levels in the json string.\\n\\n    max_level: int, optional, default: None\\n        The max depth to normalize.\\n\\n    Returns\\n    -------\\n    d - dict or list of dicts, matching `ds`\\n\\n    Examples\\n    --------\\n    >>> nested_to_record(\\n    ...     dict(flat1=1, dict1=dict(c=1, d=2), nested=dict(e=dict(c=1, d=2), d=2))\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n    '\n    singleton = False\n    if isinstance(ds, dict):\n        ds = [ds]\n        singleton = True\n    new_ds = []\n    for d in ds:\n        new_d = copy.deepcopy(d)\n        for (k, v) in d.items():\n            if not isinstance(k, str):\n                k = str(k)\n            if level == 0:\n                newkey = k\n            else:\n                newkey = prefix + sep + k\n            if not isinstance(v, dict) or (max_level is not None and level >= max_level):\n                if level != 0:\n                    v = new_d.pop(k)\n                    new_d[newkey] = v\n                continue\n            v = new_d.pop(k)\n            new_d.update(nested_to_record(v, newkey, sep, level + 1, max_level))\n        new_ds.append(new_d)\n    if singleton:\n        return new_ds[0]\n    return new_ds"
        ]
    },
    {
        "func_name": "_normalise_json",
        "original": "def _normalise_json(data: Any, key_string: str, normalized_dict: dict[str, Any], separator: str) -> dict[str, Any]:\n    \"\"\"\n    Main recursive function\n    Designed for the most basic use case of pd.json_normalize(data)\n    intended as a performance improvement, see #15621\n\n    Parameters\n    ----------\n    data : Any\n        Type dependent on types contained within nested Json\n    key_string : str\n        New key (with separator(s) in) for data\n    normalized_dict : dict\n        The new normalized/flattened Json dict\n    separator : str, default '.'\n        Nested records will generate names separated by sep,\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\n    \"\"\"\n    if isinstance(data, dict):\n        for (key, value) in data.items():\n            new_key = f'{key_string}{separator}{key}'\n            if not key_string:\n                new_key = new_key.removeprefix(separator)\n            _normalise_json(data=value, key_string=new_key, normalized_dict=normalized_dict, separator=separator)\n    else:\n        normalized_dict[key_string] = data\n    return normalized_dict",
        "mutated": [
            "def _normalise_json(data: Any, key_string: str, normalized_dict: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n    \"\\n    Main recursive function\\n    Designed for the most basic use case of pd.json_normalize(data)\\n    intended as a performance improvement, see #15621\\n\\n    Parameters\\n    ----------\\n    data : Any\\n        Type dependent on types contained within nested Json\\n    key_string : str\\n        New key (with separator(s) in) for data\\n    normalized_dict : dict\\n        The new normalized/flattened Json dict\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n    \"\n    if isinstance(data, dict):\n        for (key, value) in data.items():\n            new_key = f'{key_string}{separator}{key}'\n            if not key_string:\n                new_key = new_key.removeprefix(separator)\n            _normalise_json(data=value, key_string=new_key, normalized_dict=normalized_dict, separator=separator)\n    else:\n        normalized_dict[key_string] = data\n    return normalized_dict",
            "def _normalise_json(data: Any, key_string: str, normalized_dict: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Main recursive function\\n    Designed for the most basic use case of pd.json_normalize(data)\\n    intended as a performance improvement, see #15621\\n\\n    Parameters\\n    ----------\\n    data : Any\\n        Type dependent on types contained within nested Json\\n    key_string : str\\n        New key (with separator(s) in) for data\\n    normalized_dict : dict\\n        The new normalized/flattened Json dict\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n    \"\n    if isinstance(data, dict):\n        for (key, value) in data.items():\n            new_key = f'{key_string}{separator}{key}'\n            if not key_string:\n                new_key = new_key.removeprefix(separator)\n            _normalise_json(data=value, key_string=new_key, normalized_dict=normalized_dict, separator=separator)\n    else:\n        normalized_dict[key_string] = data\n    return normalized_dict",
            "def _normalise_json(data: Any, key_string: str, normalized_dict: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Main recursive function\\n    Designed for the most basic use case of pd.json_normalize(data)\\n    intended as a performance improvement, see #15621\\n\\n    Parameters\\n    ----------\\n    data : Any\\n        Type dependent on types contained within nested Json\\n    key_string : str\\n        New key (with separator(s) in) for data\\n    normalized_dict : dict\\n        The new normalized/flattened Json dict\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n    \"\n    if isinstance(data, dict):\n        for (key, value) in data.items():\n            new_key = f'{key_string}{separator}{key}'\n            if not key_string:\n                new_key = new_key.removeprefix(separator)\n            _normalise_json(data=value, key_string=new_key, normalized_dict=normalized_dict, separator=separator)\n    else:\n        normalized_dict[key_string] = data\n    return normalized_dict",
            "def _normalise_json(data: Any, key_string: str, normalized_dict: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Main recursive function\\n    Designed for the most basic use case of pd.json_normalize(data)\\n    intended as a performance improvement, see #15621\\n\\n    Parameters\\n    ----------\\n    data : Any\\n        Type dependent on types contained within nested Json\\n    key_string : str\\n        New key (with separator(s) in) for data\\n    normalized_dict : dict\\n        The new normalized/flattened Json dict\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n    \"\n    if isinstance(data, dict):\n        for (key, value) in data.items():\n            new_key = f'{key_string}{separator}{key}'\n            if not key_string:\n                new_key = new_key.removeprefix(separator)\n            _normalise_json(data=value, key_string=new_key, normalized_dict=normalized_dict, separator=separator)\n    else:\n        normalized_dict[key_string] = data\n    return normalized_dict",
            "def _normalise_json(data: Any, key_string: str, normalized_dict: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Main recursive function\\n    Designed for the most basic use case of pd.json_normalize(data)\\n    intended as a performance improvement, see #15621\\n\\n    Parameters\\n    ----------\\n    data : Any\\n        Type dependent on types contained within nested Json\\n    key_string : str\\n        New key (with separator(s) in) for data\\n    normalized_dict : dict\\n        The new normalized/flattened Json dict\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n    \"\n    if isinstance(data, dict):\n        for (key, value) in data.items():\n            new_key = f'{key_string}{separator}{key}'\n            if not key_string:\n                new_key = new_key.removeprefix(separator)\n            _normalise_json(data=value, key_string=new_key, normalized_dict=normalized_dict, separator=separator)\n    else:\n        normalized_dict[key_string] = data\n    return normalized_dict"
        ]
    },
    {
        "func_name": "_normalise_json_ordered",
        "original": "def _normalise_json_ordered(data: dict[str, Any], separator: str) -> dict[str, Any]:\n    \"\"\"\n    Order the top level keys and then recursively go to depth\n\n    Parameters\n    ----------\n    data : dict or list of dicts\n    separator : str, default '.'\n        Nested records will generate names separated by sep,\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\n\n    Returns\n    -------\n    dict or list of dicts, matching `normalised_json_object`\n    \"\"\"\n    top_dict_ = {k: v for (k, v) in data.items() if not isinstance(v, dict)}\n    nested_dict_ = _normalise_json(data={k: v for (k, v) in data.items() if isinstance(v, dict)}, key_string='', normalized_dict={}, separator=separator)\n    return {**top_dict_, **nested_dict_}",
        "mutated": [
            "def _normalise_json_ordered(data: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n    \"\\n    Order the top level keys and then recursively go to depth\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    dict or list of dicts, matching `normalised_json_object`\\n    \"\n    top_dict_ = {k: v for (k, v) in data.items() if not isinstance(v, dict)}\n    nested_dict_ = _normalise_json(data={k: v for (k, v) in data.items() if isinstance(v, dict)}, key_string='', normalized_dict={}, separator=separator)\n    return {**top_dict_, **nested_dict_}",
            "def _normalise_json_ordered(data: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Order the top level keys and then recursively go to depth\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    dict or list of dicts, matching `normalised_json_object`\\n    \"\n    top_dict_ = {k: v for (k, v) in data.items() if not isinstance(v, dict)}\n    nested_dict_ = _normalise_json(data={k: v for (k, v) in data.items() if isinstance(v, dict)}, key_string='', normalized_dict={}, separator=separator)\n    return {**top_dict_, **nested_dict_}",
            "def _normalise_json_ordered(data: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Order the top level keys and then recursively go to depth\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    dict or list of dicts, matching `normalised_json_object`\\n    \"\n    top_dict_ = {k: v for (k, v) in data.items() if not isinstance(v, dict)}\n    nested_dict_ = _normalise_json(data={k: v for (k, v) in data.items() if isinstance(v, dict)}, key_string='', normalized_dict={}, separator=separator)\n    return {**top_dict_, **nested_dict_}",
            "def _normalise_json_ordered(data: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Order the top level keys and then recursively go to depth\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    dict or list of dicts, matching `normalised_json_object`\\n    \"\n    top_dict_ = {k: v for (k, v) in data.items() if not isinstance(v, dict)}\n    nested_dict_ = _normalise_json(data={k: v for (k, v) in data.items() if isinstance(v, dict)}, key_string='', normalized_dict={}, separator=separator)\n    return {**top_dict_, **nested_dict_}",
            "def _normalise_json_ordered(data: dict[str, Any], separator: str) -> dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Order the top level keys and then recursively go to depth\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n    separator : str, default '.'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    dict or list of dicts, matching `normalised_json_object`\\n    \"\n    top_dict_ = {k: v for (k, v) in data.items() if not isinstance(v, dict)}\n    nested_dict_ = _normalise_json(data={k: v for (k, v) in data.items() if isinstance(v, dict)}, key_string='', normalized_dict={}, separator=separator)\n    return {**top_dict_, **nested_dict_}"
        ]
    },
    {
        "func_name": "_simple_json_normalize",
        "original": "def _simple_json_normalize(ds: dict | list[dict], sep: str='.') -> dict | list[dict] | Any:\n    \"\"\"\n    A optimized basic json_normalize\n\n    Converts a nested dict into a flat dict (\"record\"), unlike\n    json_normalize and nested_to_record it doesn't do anything clever.\n    But for the most basic use cases it enhances performance.\n    E.g. pd.json_normalize(data)\n\n    Parameters\n    ----------\n    ds : dict or list of dicts\n    sep : str, default '.'\n        Nested records will generate names separated by sep,\n        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\n\n    Returns\n    -------\n    frame : DataFrame\n    d - dict or list of dicts, matching `normalised_json_object`\n\n    Examples\n    --------\n    >>> _simple_json_normalize(\n    ...     {\n    ...         \"flat1\": 1,\n    ...         \"dict1\": {\"c\": 1, \"d\": 2},\n    ...         \"nested\": {\"e\": {\"c\": 1, \"d\": 2}, \"d\": 2},\n    ...     }\n    ... )\n    {'flat1': 1, 'dict1.c': 1, 'dict1.d': 2, 'nested.e.c': 1, 'nested.e.d': 2, 'nested.d': 2}\n\n    \"\"\"\n    normalised_json_object = {}\n    if isinstance(ds, dict):\n        normalised_json_object = _normalise_json_ordered(data=ds, separator=sep)\n    elif isinstance(ds, list):\n        normalised_json_list = [_simple_json_normalize(row, sep=sep) for row in ds]\n        return normalised_json_list\n    return normalised_json_object",
        "mutated": [
            "def _simple_json_normalize(ds: dict | list[dict], sep: str='.') -> dict | list[dict] | Any:\n    if False:\n        i = 10\n    '\\n    A optimized basic json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike\\n    json_normalize and nested_to_record it doesn\\'t do anything clever.\\n    But for the most basic use cases it enhances performance.\\n    E.g. pd.json_normalize(data)\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    d - dict or list of dicts, matching `normalised_json_object`\\n\\n    Examples\\n    --------\\n    >>> _simple_json_normalize(\\n    ...     {\\n    ...         \"flat1\": 1,\\n    ...         \"dict1\": {\"c\": 1, \"d\": 2},\\n    ...         \"nested\": {\"e\": {\"c\": 1, \"d\": 2}, \"d\": 2},\\n    ...     }\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n\\n    '\n    normalised_json_object = {}\n    if isinstance(ds, dict):\n        normalised_json_object = _normalise_json_ordered(data=ds, separator=sep)\n    elif isinstance(ds, list):\n        normalised_json_list = [_simple_json_normalize(row, sep=sep) for row in ds]\n        return normalised_json_list\n    return normalised_json_object",
            "def _simple_json_normalize(ds: dict | list[dict], sep: str='.') -> dict | list[dict] | Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    A optimized basic json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike\\n    json_normalize and nested_to_record it doesn\\'t do anything clever.\\n    But for the most basic use cases it enhances performance.\\n    E.g. pd.json_normalize(data)\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    d - dict or list of dicts, matching `normalised_json_object`\\n\\n    Examples\\n    --------\\n    >>> _simple_json_normalize(\\n    ...     {\\n    ...         \"flat1\": 1,\\n    ...         \"dict1\": {\"c\": 1, \"d\": 2},\\n    ...         \"nested\": {\"e\": {\"c\": 1, \"d\": 2}, \"d\": 2},\\n    ...     }\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n\\n    '\n    normalised_json_object = {}\n    if isinstance(ds, dict):\n        normalised_json_object = _normalise_json_ordered(data=ds, separator=sep)\n    elif isinstance(ds, list):\n        normalised_json_list = [_simple_json_normalize(row, sep=sep) for row in ds]\n        return normalised_json_list\n    return normalised_json_object",
            "def _simple_json_normalize(ds: dict | list[dict], sep: str='.') -> dict | list[dict] | Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    A optimized basic json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike\\n    json_normalize and nested_to_record it doesn\\'t do anything clever.\\n    But for the most basic use cases it enhances performance.\\n    E.g. pd.json_normalize(data)\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    d - dict or list of dicts, matching `normalised_json_object`\\n\\n    Examples\\n    --------\\n    >>> _simple_json_normalize(\\n    ...     {\\n    ...         \"flat1\": 1,\\n    ...         \"dict1\": {\"c\": 1, \"d\": 2},\\n    ...         \"nested\": {\"e\": {\"c\": 1, \"d\": 2}, \"d\": 2},\\n    ...     }\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n\\n    '\n    normalised_json_object = {}\n    if isinstance(ds, dict):\n        normalised_json_object = _normalise_json_ordered(data=ds, separator=sep)\n    elif isinstance(ds, list):\n        normalised_json_list = [_simple_json_normalize(row, sep=sep) for row in ds]\n        return normalised_json_list\n    return normalised_json_object",
            "def _simple_json_normalize(ds: dict | list[dict], sep: str='.') -> dict | list[dict] | Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    A optimized basic json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike\\n    json_normalize and nested_to_record it doesn\\'t do anything clever.\\n    But for the most basic use cases it enhances performance.\\n    E.g. pd.json_normalize(data)\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    d - dict or list of dicts, matching `normalised_json_object`\\n\\n    Examples\\n    --------\\n    >>> _simple_json_normalize(\\n    ...     {\\n    ...         \"flat1\": 1,\\n    ...         \"dict1\": {\"c\": 1, \"d\": 2},\\n    ...         \"nested\": {\"e\": {\"c\": 1, \"d\": 2}, \"d\": 2},\\n    ...     }\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n\\n    '\n    normalised_json_object = {}\n    if isinstance(ds, dict):\n        normalised_json_object = _normalise_json_ordered(data=ds, separator=sep)\n    elif isinstance(ds, list):\n        normalised_json_list = [_simple_json_normalize(row, sep=sep) for row in ds]\n        return normalised_json_list\n    return normalised_json_object",
            "def _simple_json_normalize(ds: dict | list[dict], sep: str='.') -> dict | list[dict] | Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    A optimized basic json_normalize\\n\\n    Converts a nested dict into a flat dict (\"record\"), unlike\\n    json_normalize and nested_to_record it doesn\\'t do anything clever.\\n    But for the most basic use cases it enhances performance.\\n    E.g. pd.json_normalize(data)\\n\\n    Parameters\\n    ----------\\n    ds : dict or list of dicts\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep,\\n        e.g., for sep=\\'.\\', { \\'foo\\' : { \\'bar\\' : 0 } } -> foo.bar\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    d - dict or list of dicts, matching `normalised_json_object`\\n\\n    Examples\\n    --------\\n    >>> _simple_json_normalize(\\n    ...     {\\n    ...         \"flat1\": 1,\\n    ...         \"dict1\": {\"c\": 1, \"d\": 2},\\n    ...         \"nested\": {\"e\": {\"c\": 1, \"d\": 2}, \"d\": 2},\\n    ...     }\\n    ... )\\n    {\\'flat1\\': 1, \\'dict1.c\\': 1, \\'dict1.d\\': 2, \\'nested.e.c\\': 1, \\'nested.e.d\\': 2, \\'nested.d\\': 2}\\n\\n    '\n    normalised_json_object = {}\n    if isinstance(ds, dict):\n        normalised_json_object = _normalise_json_ordered(data=ds, separator=sep)\n    elif isinstance(ds, list):\n        normalised_json_list = [_simple_json_normalize(row, sep=sep) for row in ds]\n        return normalised_json_list\n    return normalised_json_object"
        ]
    },
    {
        "func_name": "_pull_field",
        "original": "def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n    \"\"\"Internal function to pull field\"\"\"\n    result = js\n    try:\n        if isinstance(spec, list):\n            for field in spec:\n                if result is None:\n                    raise KeyError(field)\n                result = result[field]\n        else:\n            result = result[spec]\n    except KeyError as e:\n        if extract_record:\n            raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n        if errors == 'ignore':\n            return np.nan\n        else:\n            raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n    return result",
        "mutated": [
            "def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n    if False:\n        i = 10\n    'Internal function to pull field'\n    result = js\n    try:\n        if isinstance(spec, list):\n            for field in spec:\n                if result is None:\n                    raise KeyError(field)\n                result = result[field]\n        else:\n            result = result[spec]\n    except KeyError as e:\n        if extract_record:\n            raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n        if errors == 'ignore':\n            return np.nan\n        else:\n            raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n    return result",
            "def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Internal function to pull field'\n    result = js\n    try:\n        if isinstance(spec, list):\n            for field in spec:\n                if result is None:\n                    raise KeyError(field)\n                result = result[field]\n        else:\n            result = result[spec]\n    except KeyError as e:\n        if extract_record:\n            raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n        if errors == 'ignore':\n            return np.nan\n        else:\n            raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n    return result",
            "def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Internal function to pull field'\n    result = js\n    try:\n        if isinstance(spec, list):\n            for field in spec:\n                if result is None:\n                    raise KeyError(field)\n                result = result[field]\n        else:\n            result = result[spec]\n    except KeyError as e:\n        if extract_record:\n            raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n        if errors == 'ignore':\n            return np.nan\n        else:\n            raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n    return result",
            "def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Internal function to pull field'\n    result = js\n    try:\n        if isinstance(spec, list):\n            for field in spec:\n                if result is None:\n                    raise KeyError(field)\n                result = result[field]\n        else:\n            result = result[spec]\n    except KeyError as e:\n        if extract_record:\n            raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n        if errors == 'ignore':\n            return np.nan\n        else:\n            raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n    return result",
            "def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Internal function to pull field'\n    result = js\n    try:\n        if isinstance(spec, list):\n            for field in spec:\n                if result is None:\n                    raise KeyError(field)\n                result = result[field]\n        else:\n            result = result[spec]\n    except KeyError as e:\n        if extract_record:\n            raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n        if errors == 'ignore':\n            return np.nan\n        else:\n            raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n    return result"
        ]
    },
    {
        "func_name": "_pull_records",
        "original": "def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n    \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n    result = _pull_field(js, spec, extract_record=True)\n    if not isinstance(result, list):\n        if pd.isnull(result):\n            result = []\n        else:\n            raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n    return result",
        "mutated": [
            "def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n    if False:\n        i = 10\n    '\\n        Internal function to pull field for records, and similar to\\n        _pull_field, but require to return list. And will raise error\\n        if has non iterable value.\\n        '\n    result = _pull_field(js, spec, extract_record=True)\n    if not isinstance(result, list):\n        if pd.isnull(result):\n            result = []\n        else:\n            raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n    return result",
            "def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Internal function to pull field for records, and similar to\\n        _pull_field, but require to return list. And will raise error\\n        if has non iterable value.\\n        '\n    result = _pull_field(js, spec, extract_record=True)\n    if not isinstance(result, list):\n        if pd.isnull(result):\n            result = []\n        else:\n            raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n    return result",
            "def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Internal function to pull field for records, and similar to\\n        _pull_field, but require to return list. And will raise error\\n        if has non iterable value.\\n        '\n    result = _pull_field(js, spec, extract_record=True)\n    if not isinstance(result, list):\n        if pd.isnull(result):\n            result = []\n        else:\n            raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n    return result",
            "def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Internal function to pull field for records, and similar to\\n        _pull_field, but require to return list. And will raise error\\n        if has non iterable value.\\n        '\n    result = _pull_field(js, spec, extract_record=True)\n    if not isinstance(result, list):\n        if pd.isnull(result):\n            result = []\n        else:\n            raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n    return result",
            "def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Internal function to pull field for records, and similar to\\n        _pull_field, but require to return list. And will raise error\\n        if has non iterable value.\\n        '\n    result = _pull_field(js, spec, extract_record=True)\n    if not isinstance(result, list):\n        if pd.isnull(result):\n            result = []\n        else:\n            raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n    return result"
        ]
    },
    {
        "func_name": "_recursive_extract",
        "original": "def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n    if isinstance(data, dict):\n        data = [data]\n    if len(path) > 1:\n        for obj in data:\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 == len(val):\n                    seen_meta[key] = _pull_field(obj, val[-1])\n            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n    else:\n        for obj in data:\n            recs = _pull_records(obj, path[0])\n            recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n            lengths.append(len(recs))\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 > len(val):\n                    meta_val = seen_meta[key]\n                else:\n                    meta_val = _pull_field(obj, val[level:])\n                meta_vals[key].append(meta_val)\n            records.extend(recs)",
        "mutated": [
            "def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n    if False:\n        i = 10\n    if isinstance(data, dict):\n        data = [data]\n    if len(path) > 1:\n        for obj in data:\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 == len(val):\n                    seen_meta[key] = _pull_field(obj, val[-1])\n            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n    else:\n        for obj in data:\n            recs = _pull_records(obj, path[0])\n            recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n            lengths.append(len(recs))\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 > len(val):\n                    meta_val = seen_meta[key]\n                else:\n                    meta_val = _pull_field(obj, val[level:])\n                meta_vals[key].append(meta_val)\n            records.extend(recs)",
            "def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(data, dict):\n        data = [data]\n    if len(path) > 1:\n        for obj in data:\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 == len(val):\n                    seen_meta[key] = _pull_field(obj, val[-1])\n            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n    else:\n        for obj in data:\n            recs = _pull_records(obj, path[0])\n            recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n            lengths.append(len(recs))\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 > len(val):\n                    meta_val = seen_meta[key]\n                else:\n                    meta_val = _pull_field(obj, val[level:])\n                meta_vals[key].append(meta_val)\n            records.extend(recs)",
            "def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(data, dict):\n        data = [data]\n    if len(path) > 1:\n        for obj in data:\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 == len(val):\n                    seen_meta[key] = _pull_field(obj, val[-1])\n            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n    else:\n        for obj in data:\n            recs = _pull_records(obj, path[0])\n            recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n            lengths.append(len(recs))\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 > len(val):\n                    meta_val = seen_meta[key]\n                else:\n                    meta_val = _pull_field(obj, val[level:])\n                meta_vals[key].append(meta_val)\n            records.extend(recs)",
            "def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(data, dict):\n        data = [data]\n    if len(path) > 1:\n        for obj in data:\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 == len(val):\n                    seen_meta[key] = _pull_field(obj, val[-1])\n            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n    else:\n        for obj in data:\n            recs = _pull_records(obj, path[0])\n            recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n            lengths.append(len(recs))\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 > len(val):\n                    meta_val = seen_meta[key]\n                else:\n                    meta_val = _pull_field(obj, val[level:])\n                meta_vals[key].append(meta_val)\n            records.extend(recs)",
            "def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(data, dict):\n        data = [data]\n    if len(path) > 1:\n        for obj in data:\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 == len(val):\n                    seen_meta[key] = _pull_field(obj, val[-1])\n            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n    else:\n        for obj in data:\n            recs = _pull_records(obj, path[0])\n            recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n            lengths.append(len(recs))\n            for (val, key) in zip(_meta, meta_keys):\n                if level + 1 > len(val):\n                    meta_val = seen_meta[key]\n                else:\n                    meta_val = _pull_field(obj, val[level:])\n                meta_vals[key].append(meta_val)\n            records.extend(recs)"
        ]
    },
    {
        "func_name": "json_normalize",
        "original": "def json_normalize(data: dict | list[dict], record_path: str | list | None=None, meta: str | list[str | list[str]] | None=None, meta_prefix: str | None=None, record_prefix: str | None=None, errors: IgnoreRaise='raise', sep: str='.', max_level: int | None=None) -> DataFrame:\n    \"\"\"\n    Normalize semi-structured JSON data into a flat table.\n\n    Parameters\n    ----------\n    data : dict or list of dicts\n        Unserialized JSON objects.\n    record_path : str or list of str, default None\n        Path in each object to list of records. If not passed, data will be\n        assumed to be an array of records.\n    meta : list of paths (str or list of str), default None\n        Fields to use as metadata for each record in resulting table.\n    meta_prefix : str, default None\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\n        meta is ['foo', 'bar'].\n    record_prefix : str, default None\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\n        path to records is ['foo', 'bar'].\n    errors : {'raise', 'ignore'}, default 'raise'\n        Configures error handling.\n\n        * 'ignore' : will ignore KeyError if keys listed in meta are not\n          always present.\n        * 'raise' : will raise KeyError if keys listed in meta are not\n          always present.\n    sep : str, default '.'\n        Nested records will generate names separated by sep.\n        e.g., for sep='.', {'foo': {'bar': 0}} -> foo.bar.\n    max_level : int, default None\n        Max number of levels(depth of dict) to normalize.\n        if None, normalizes all levels.\n\n    Returns\n    -------\n    frame : DataFrame\n    Normalize semi-structured JSON data into a flat table.\n\n    Examples\n    --------\n    >>> data = [\n    ...     {\"id\": 1, \"name\": {\"first\": \"Coleen\", \"last\": \"Volk\"}},\n    ...     {\"name\": {\"given\": \"Mark\", \"family\": \"Regner\"}},\n    ...     {\"id\": 2, \"name\": \"Faye Raker\"},\n    ... ]\n    >>> pd.json_normalize(data)\n        id name.first name.last name.given name.family        name\n    0  1.0     Coleen      Volk        NaN         NaN         NaN\n    1  NaN        NaN       NaN       Mark      Regner         NaN\n    2  2.0        NaN       NaN        NaN         NaN  Faye Raker\n\n    >>> data = [\n    ...     {\n    ...         \"id\": 1,\n    ...         \"name\": \"Cole Volk\",\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\n    ...     },\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\n    ...     {\n    ...         \"id\": 2,\n    ...         \"name\": \"Faye Raker\",\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\n    ...     },\n    ... ]\n    >>> pd.json_normalize(data, max_level=0)\n        id        name                        fitness\n    0  1.0   Cole Volk  {'height': 130, 'weight': 60}\n    1  NaN    Mark Reg  {'height': 130, 'weight': 60}\n    2  2.0  Faye Raker  {'height': 130, 'weight': 60}\n\n    Normalizes nested data up to level 1.\n\n    >>> data = [\n    ...     {\n    ...         \"id\": 1,\n    ...         \"name\": \"Cole Volk\",\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\n    ...     },\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\n    ...     {\n    ...         \"id\": 2,\n    ...         \"name\": \"Faye Raker\",\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\n    ...     },\n    ... ]\n    >>> pd.json_normalize(data, max_level=1)\n        id        name  fitness.height  fitness.weight\n    0  1.0   Cole Volk             130              60\n    1  NaN    Mark Reg             130              60\n    2  2.0  Faye Raker             130              60\n\n    >>> data = [\n    ...     {\n    ...         \"state\": \"Florida\",\n    ...         \"shortname\": \"FL\",\n    ...         \"info\": {\"governor\": \"Rick Scott\"},\n    ...         \"counties\": [\n    ...             {\"name\": \"Dade\", \"population\": 12345},\n    ...             {\"name\": \"Broward\", \"population\": 40000},\n    ...             {\"name\": \"Palm Beach\", \"population\": 60000},\n    ...         ],\n    ...     },\n    ...     {\n    ...         \"state\": \"Ohio\",\n    ...         \"shortname\": \"OH\",\n    ...         \"info\": {\"governor\": \"John Kasich\"},\n    ...         \"counties\": [\n    ...             {\"name\": \"Summit\", \"population\": 1234},\n    ...             {\"name\": \"Cuyahoga\", \"population\": 1337},\n    ...         ],\n    ...     },\n    ... ]\n    >>> result = pd.json_normalize(\n    ...     data, \"counties\", [\"state\", \"shortname\", [\"info\", \"governor\"]]\n    ... )\n    >>> result\n             name  population    state shortname info.governor\n    0        Dade       12345   Florida    FL    Rick Scott\n    1     Broward       40000   Florida    FL    Rick Scott\n    2  Palm Beach       60000   Florida    FL    Rick Scott\n    3      Summit        1234   Ohio       OH    John Kasich\n    4    Cuyahoga        1337   Ohio       OH    John Kasich\n\n    >>> data = {\"A\": [1, 2]}\n    >>> pd.json_normalize(data, \"A\", record_prefix=\"Prefix.\")\n        Prefix.0\n    0          1\n    1          2\n\n    Returns normalized data with columns prefixed with the given string.\n    \"\"\"\n\n    def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n        \"\"\"Internal function to pull field\"\"\"\n        result = js\n        try:\n            if isinstance(spec, list):\n                for field in spec:\n                    if result is None:\n                        raise KeyError(field)\n                    result = result[field]\n            else:\n                result = result[spec]\n        except KeyError as e:\n            if extract_record:\n                raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n            if errors == 'ignore':\n                return np.nan\n            else:\n                raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n        return result\n\n    def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n        \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n        result = _pull_field(js, spec, extract_record=True)\n        if not isinstance(result, list):\n            if pd.isnull(result):\n                result = []\n            else:\n                raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n        return result\n    if isinstance(data, list) and (not data):\n        return DataFrame()\n    elif isinstance(data, dict):\n        data = [data]\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, str)):\n        data = list(data)\n    else:\n        raise NotImplementedError\n    if record_path is None and meta is None and (meta_prefix is None) and (record_prefix is None) and (max_level is None):\n        return DataFrame(_simple_json_normalize(data, sep=sep))\n    if record_path is None:\n        if any(([isinstance(x, dict) for x in y.values()] for y in data)):\n            data = nested_to_record(data, sep=sep, max_level=max_level)\n        return DataFrame(data)\n    elif not isinstance(record_path, list):\n        record_path = [record_path]\n    if meta is None:\n        meta = []\n    elif not isinstance(meta, list):\n        meta = [meta]\n    _meta = [m if isinstance(m, list) else [m] for m in meta]\n    records: list = []\n    lengths = []\n    meta_vals: DefaultDict = defaultdict(list)\n    meta_keys = [sep.join(val) for val in _meta]\n\n    def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n        if isinstance(data, dict):\n            data = [data]\n        if len(path) > 1:\n            for obj in data:\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 == len(val):\n                        seen_meta[key] = _pull_field(obj, val[-1])\n                _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n        else:\n            for obj in data:\n                recs = _pull_records(obj, path[0])\n                recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n                lengths.append(len(recs))\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 > len(val):\n                        meta_val = seen_meta[key]\n                    else:\n                        meta_val = _pull_field(obj, val[level:])\n                    meta_vals[key].append(meta_val)\n                records.extend(recs)\n    _recursive_extract(data, record_path, {}, level=0)\n    result = DataFrame(records)\n    if record_prefix is not None:\n        result = result.rename(columns=lambda x: f'{record_prefix}{x}')\n    for (k, v) in meta_vals.items():\n        if meta_prefix is not None:\n            k = meta_prefix + k\n        if k in result:\n            raise ValueError(f'Conflicting metadata name {k}, need distinguishing prefix ')\n        values = np.array(v, dtype=object)\n        if values.ndim > 1:\n            values = np.empty((len(v),), dtype=object)\n            for (i, v) in enumerate(v):\n                values[i] = v\n        result[k] = values.repeat(lengths)\n    return result",
        "mutated": [
            "def json_normalize(data: dict | list[dict], record_path: str | list | None=None, meta: str | list[str | list[str]] | None=None, meta_prefix: str | None=None, record_prefix: str | None=None, errors: IgnoreRaise='raise', sep: str='.', max_level: int | None=None) -> DataFrame:\n    if False:\n        i = 10\n    '\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n        Unserialized JSON objects.\\n    record_path : str or list of str, default None\\n        Path in each object to list of records. If not passed, data will be\\n        assumed to be an array of records.\\n    meta : list of paths (str or list of str), default None\\n        Fields to use as metadata for each record in resulting table.\\n    meta_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        meta is [\\'foo\\', \\'bar\\'].\\n    record_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        path to records is [\\'foo\\', \\'bar\\'].\\n    errors : {\\'raise\\', \\'ignore\\'}, default \\'raise\\'\\n        Configures error handling.\\n\\n        * \\'ignore\\' : will ignore KeyError if keys listed in meta are not\\n          always present.\\n        * \\'raise\\' : will raise KeyError if keys listed in meta are not\\n          always present.\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep.\\n        e.g., for sep=\\'.\\', {\\'foo\\': {\\'bar\\': 0}} -> foo.bar.\\n    max_level : int, default None\\n        Max number of levels(depth of dict) to normalize.\\n        if None, normalizes all levels.\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Examples\\n    --------\\n    >>> data = [\\n    ...     {\"id\": 1, \"name\": {\"first\": \"Coleen\", \"last\": \"Volk\"}},\\n    ...     {\"name\": {\"given\": \"Mark\", \"family\": \"Regner\"}},\\n    ...     {\"id\": 2, \"name\": \"Faye Raker\"},\\n    ... ]\\n    >>> pd.json_normalize(data)\\n        id name.first name.last name.given name.family        name\\n    0  1.0     Coleen      Volk        NaN         NaN         NaN\\n    1  NaN        NaN       NaN       Mark      Regner         NaN\\n    2  2.0        NaN       NaN        NaN         NaN  Faye Raker\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=0)\\n        id        name                        fitness\\n    0  1.0   Cole Volk  {\\'height\\': 130, \\'weight\\': 60}\\n    1  NaN    Mark Reg  {\\'height\\': 130, \\'weight\\': 60}\\n    2  2.0  Faye Raker  {\\'height\\': 130, \\'weight\\': 60}\\n\\n    Normalizes nested data up to level 1.\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=1)\\n        id        name  fitness.height  fitness.weight\\n    0  1.0   Cole Volk             130              60\\n    1  NaN    Mark Reg             130              60\\n    2  2.0  Faye Raker             130              60\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"state\": \"Florida\",\\n    ...         \"shortname\": \"FL\",\\n    ...         \"info\": {\"governor\": \"Rick Scott\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Dade\", \"population\": 12345},\\n    ...             {\"name\": \"Broward\", \"population\": 40000},\\n    ...             {\"name\": \"Palm Beach\", \"population\": 60000},\\n    ...         ],\\n    ...     },\\n    ...     {\\n    ...         \"state\": \"Ohio\",\\n    ...         \"shortname\": \"OH\",\\n    ...         \"info\": {\"governor\": \"John Kasich\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Summit\", \"population\": 1234},\\n    ...             {\"name\": \"Cuyahoga\", \"population\": 1337},\\n    ...         ],\\n    ...     },\\n    ... ]\\n    >>> result = pd.json_normalize(\\n    ...     data, \"counties\", [\"state\", \"shortname\", [\"info\", \"governor\"]]\\n    ... )\\n    >>> result\\n             name  population    state shortname info.governor\\n    0        Dade       12345   Florida    FL    Rick Scott\\n    1     Broward       40000   Florida    FL    Rick Scott\\n    2  Palm Beach       60000   Florida    FL    Rick Scott\\n    3      Summit        1234   Ohio       OH    John Kasich\\n    4    Cuyahoga        1337   Ohio       OH    John Kasich\\n\\n    >>> data = {\"A\": [1, 2]}\\n    >>> pd.json_normalize(data, \"A\", record_prefix=\"Prefix.\")\\n        Prefix.0\\n    0          1\\n    1          2\\n\\n    Returns normalized data with columns prefixed with the given string.\\n    '\n\n    def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n        \"\"\"Internal function to pull field\"\"\"\n        result = js\n        try:\n            if isinstance(spec, list):\n                for field in spec:\n                    if result is None:\n                        raise KeyError(field)\n                    result = result[field]\n            else:\n                result = result[spec]\n        except KeyError as e:\n            if extract_record:\n                raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n            if errors == 'ignore':\n                return np.nan\n            else:\n                raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n        return result\n\n    def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n        \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n        result = _pull_field(js, spec, extract_record=True)\n        if not isinstance(result, list):\n            if pd.isnull(result):\n                result = []\n            else:\n                raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n        return result\n    if isinstance(data, list) and (not data):\n        return DataFrame()\n    elif isinstance(data, dict):\n        data = [data]\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, str)):\n        data = list(data)\n    else:\n        raise NotImplementedError\n    if record_path is None and meta is None and (meta_prefix is None) and (record_prefix is None) and (max_level is None):\n        return DataFrame(_simple_json_normalize(data, sep=sep))\n    if record_path is None:\n        if any(([isinstance(x, dict) for x in y.values()] for y in data)):\n            data = nested_to_record(data, sep=sep, max_level=max_level)\n        return DataFrame(data)\n    elif not isinstance(record_path, list):\n        record_path = [record_path]\n    if meta is None:\n        meta = []\n    elif not isinstance(meta, list):\n        meta = [meta]\n    _meta = [m if isinstance(m, list) else [m] for m in meta]\n    records: list = []\n    lengths = []\n    meta_vals: DefaultDict = defaultdict(list)\n    meta_keys = [sep.join(val) for val in _meta]\n\n    def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n        if isinstance(data, dict):\n            data = [data]\n        if len(path) > 1:\n            for obj in data:\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 == len(val):\n                        seen_meta[key] = _pull_field(obj, val[-1])\n                _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n        else:\n            for obj in data:\n                recs = _pull_records(obj, path[0])\n                recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n                lengths.append(len(recs))\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 > len(val):\n                        meta_val = seen_meta[key]\n                    else:\n                        meta_val = _pull_field(obj, val[level:])\n                    meta_vals[key].append(meta_val)\n                records.extend(recs)\n    _recursive_extract(data, record_path, {}, level=0)\n    result = DataFrame(records)\n    if record_prefix is not None:\n        result = result.rename(columns=lambda x: f'{record_prefix}{x}')\n    for (k, v) in meta_vals.items():\n        if meta_prefix is not None:\n            k = meta_prefix + k\n        if k in result:\n            raise ValueError(f'Conflicting metadata name {k}, need distinguishing prefix ')\n        values = np.array(v, dtype=object)\n        if values.ndim > 1:\n            values = np.empty((len(v),), dtype=object)\n            for (i, v) in enumerate(v):\n                values[i] = v\n        result[k] = values.repeat(lengths)\n    return result",
            "def json_normalize(data: dict | list[dict], record_path: str | list | None=None, meta: str | list[str | list[str]] | None=None, meta_prefix: str | None=None, record_prefix: str | None=None, errors: IgnoreRaise='raise', sep: str='.', max_level: int | None=None) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n        Unserialized JSON objects.\\n    record_path : str or list of str, default None\\n        Path in each object to list of records. If not passed, data will be\\n        assumed to be an array of records.\\n    meta : list of paths (str or list of str), default None\\n        Fields to use as metadata for each record in resulting table.\\n    meta_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        meta is [\\'foo\\', \\'bar\\'].\\n    record_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        path to records is [\\'foo\\', \\'bar\\'].\\n    errors : {\\'raise\\', \\'ignore\\'}, default \\'raise\\'\\n        Configures error handling.\\n\\n        * \\'ignore\\' : will ignore KeyError if keys listed in meta are not\\n          always present.\\n        * \\'raise\\' : will raise KeyError if keys listed in meta are not\\n          always present.\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep.\\n        e.g., for sep=\\'.\\', {\\'foo\\': {\\'bar\\': 0}} -> foo.bar.\\n    max_level : int, default None\\n        Max number of levels(depth of dict) to normalize.\\n        if None, normalizes all levels.\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Examples\\n    --------\\n    >>> data = [\\n    ...     {\"id\": 1, \"name\": {\"first\": \"Coleen\", \"last\": \"Volk\"}},\\n    ...     {\"name\": {\"given\": \"Mark\", \"family\": \"Regner\"}},\\n    ...     {\"id\": 2, \"name\": \"Faye Raker\"},\\n    ... ]\\n    >>> pd.json_normalize(data)\\n        id name.first name.last name.given name.family        name\\n    0  1.0     Coleen      Volk        NaN         NaN         NaN\\n    1  NaN        NaN       NaN       Mark      Regner         NaN\\n    2  2.0        NaN       NaN        NaN         NaN  Faye Raker\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=0)\\n        id        name                        fitness\\n    0  1.0   Cole Volk  {\\'height\\': 130, \\'weight\\': 60}\\n    1  NaN    Mark Reg  {\\'height\\': 130, \\'weight\\': 60}\\n    2  2.0  Faye Raker  {\\'height\\': 130, \\'weight\\': 60}\\n\\n    Normalizes nested data up to level 1.\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=1)\\n        id        name  fitness.height  fitness.weight\\n    0  1.0   Cole Volk             130              60\\n    1  NaN    Mark Reg             130              60\\n    2  2.0  Faye Raker             130              60\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"state\": \"Florida\",\\n    ...         \"shortname\": \"FL\",\\n    ...         \"info\": {\"governor\": \"Rick Scott\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Dade\", \"population\": 12345},\\n    ...             {\"name\": \"Broward\", \"population\": 40000},\\n    ...             {\"name\": \"Palm Beach\", \"population\": 60000},\\n    ...         ],\\n    ...     },\\n    ...     {\\n    ...         \"state\": \"Ohio\",\\n    ...         \"shortname\": \"OH\",\\n    ...         \"info\": {\"governor\": \"John Kasich\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Summit\", \"population\": 1234},\\n    ...             {\"name\": \"Cuyahoga\", \"population\": 1337},\\n    ...         ],\\n    ...     },\\n    ... ]\\n    >>> result = pd.json_normalize(\\n    ...     data, \"counties\", [\"state\", \"shortname\", [\"info\", \"governor\"]]\\n    ... )\\n    >>> result\\n             name  population    state shortname info.governor\\n    0        Dade       12345   Florida    FL    Rick Scott\\n    1     Broward       40000   Florida    FL    Rick Scott\\n    2  Palm Beach       60000   Florida    FL    Rick Scott\\n    3      Summit        1234   Ohio       OH    John Kasich\\n    4    Cuyahoga        1337   Ohio       OH    John Kasich\\n\\n    >>> data = {\"A\": [1, 2]}\\n    >>> pd.json_normalize(data, \"A\", record_prefix=\"Prefix.\")\\n        Prefix.0\\n    0          1\\n    1          2\\n\\n    Returns normalized data with columns prefixed with the given string.\\n    '\n\n    def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n        \"\"\"Internal function to pull field\"\"\"\n        result = js\n        try:\n            if isinstance(spec, list):\n                for field in spec:\n                    if result is None:\n                        raise KeyError(field)\n                    result = result[field]\n            else:\n                result = result[spec]\n        except KeyError as e:\n            if extract_record:\n                raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n            if errors == 'ignore':\n                return np.nan\n            else:\n                raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n        return result\n\n    def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n        \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n        result = _pull_field(js, spec, extract_record=True)\n        if not isinstance(result, list):\n            if pd.isnull(result):\n                result = []\n            else:\n                raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n        return result\n    if isinstance(data, list) and (not data):\n        return DataFrame()\n    elif isinstance(data, dict):\n        data = [data]\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, str)):\n        data = list(data)\n    else:\n        raise NotImplementedError\n    if record_path is None and meta is None and (meta_prefix is None) and (record_prefix is None) and (max_level is None):\n        return DataFrame(_simple_json_normalize(data, sep=sep))\n    if record_path is None:\n        if any(([isinstance(x, dict) for x in y.values()] for y in data)):\n            data = nested_to_record(data, sep=sep, max_level=max_level)\n        return DataFrame(data)\n    elif not isinstance(record_path, list):\n        record_path = [record_path]\n    if meta is None:\n        meta = []\n    elif not isinstance(meta, list):\n        meta = [meta]\n    _meta = [m if isinstance(m, list) else [m] for m in meta]\n    records: list = []\n    lengths = []\n    meta_vals: DefaultDict = defaultdict(list)\n    meta_keys = [sep.join(val) for val in _meta]\n\n    def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n        if isinstance(data, dict):\n            data = [data]\n        if len(path) > 1:\n            for obj in data:\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 == len(val):\n                        seen_meta[key] = _pull_field(obj, val[-1])\n                _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n        else:\n            for obj in data:\n                recs = _pull_records(obj, path[0])\n                recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n                lengths.append(len(recs))\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 > len(val):\n                        meta_val = seen_meta[key]\n                    else:\n                        meta_val = _pull_field(obj, val[level:])\n                    meta_vals[key].append(meta_val)\n                records.extend(recs)\n    _recursive_extract(data, record_path, {}, level=0)\n    result = DataFrame(records)\n    if record_prefix is not None:\n        result = result.rename(columns=lambda x: f'{record_prefix}{x}')\n    for (k, v) in meta_vals.items():\n        if meta_prefix is not None:\n            k = meta_prefix + k\n        if k in result:\n            raise ValueError(f'Conflicting metadata name {k}, need distinguishing prefix ')\n        values = np.array(v, dtype=object)\n        if values.ndim > 1:\n            values = np.empty((len(v),), dtype=object)\n            for (i, v) in enumerate(v):\n                values[i] = v\n        result[k] = values.repeat(lengths)\n    return result",
            "def json_normalize(data: dict | list[dict], record_path: str | list | None=None, meta: str | list[str | list[str]] | None=None, meta_prefix: str | None=None, record_prefix: str | None=None, errors: IgnoreRaise='raise', sep: str='.', max_level: int | None=None) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n        Unserialized JSON objects.\\n    record_path : str or list of str, default None\\n        Path in each object to list of records. If not passed, data will be\\n        assumed to be an array of records.\\n    meta : list of paths (str or list of str), default None\\n        Fields to use as metadata for each record in resulting table.\\n    meta_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        meta is [\\'foo\\', \\'bar\\'].\\n    record_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        path to records is [\\'foo\\', \\'bar\\'].\\n    errors : {\\'raise\\', \\'ignore\\'}, default \\'raise\\'\\n        Configures error handling.\\n\\n        * \\'ignore\\' : will ignore KeyError if keys listed in meta are not\\n          always present.\\n        * \\'raise\\' : will raise KeyError if keys listed in meta are not\\n          always present.\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep.\\n        e.g., for sep=\\'.\\', {\\'foo\\': {\\'bar\\': 0}} -> foo.bar.\\n    max_level : int, default None\\n        Max number of levels(depth of dict) to normalize.\\n        if None, normalizes all levels.\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Examples\\n    --------\\n    >>> data = [\\n    ...     {\"id\": 1, \"name\": {\"first\": \"Coleen\", \"last\": \"Volk\"}},\\n    ...     {\"name\": {\"given\": \"Mark\", \"family\": \"Regner\"}},\\n    ...     {\"id\": 2, \"name\": \"Faye Raker\"},\\n    ... ]\\n    >>> pd.json_normalize(data)\\n        id name.first name.last name.given name.family        name\\n    0  1.0     Coleen      Volk        NaN         NaN         NaN\\n    1  NaN        NaN       NaN       Mark      Regner         NaN\\n    2  2.0        NaN       NaN        NaN         NaN  Faye Raker\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=0)\\n        id        name                        fitness\\n    0  1.0   Cole Volk  {\\'height\\': 130, \\'weight\\': 60}\\n    1  NaN    Mark Reg  {\\'height\\': 130, \\'weight\\': 60}\\n    2  2.0  Faye Raker  {\\'height\\': 130, \\'weight\\': 60}\\n\\n    Normalizes nested data up to level 1.\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=1)\\n        id        name  fitness.height  fitness.weight\\n    0  1.0   Cole Volk             130              60\\n    1  NaN    Mark Reg             130              60\\n    2  2.0  Faye Raker             130              60\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"state\": \"Florida\",\\n    ...         \"shortname\": \"FL\",\\n    ...         \"info\": {\"governor\": \"Rick Scott\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Dade\", \"population\": 12345},\\n    ...             {\"name\": \"Broward\", \"population\": 40000},\\n    ...             {\"name\": \"Palm Beach\", \"population\": 60000},\\n    ...         ],\\n    ...     },\\n    ...     {\\n    ...         \"state\": \"Ohio\",\\n    ...         \"shortname\": \"OH\",\\n    ...         \"info\": {\"governor\": \"John Kasich\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Summit\", \"population\": 1234},\\n    ...             {\"name\": \"Cuyahoga\", \"population\": 1337},\\n    ...         ],\\n    ...     },\\n    ... ]\\n    >>> result = pd.json_normalize(\\n    ...     data, \"counties\", [\"state\", \"shortname\", [\"info\", \"governor\"]]\\n    ... )\\n    >>> result\\n             name  population    state shortname info.governor\\n    0        Dade       12345   Florida    FL    Rick Scott\\n    1     Broward       40000   Florida    FL    Rick Scott\\n    2  Palm Beach       60000   Florida    FL    Rick Scott\\n    3      Summit        1234   Ohio       OH    John Kasich\\n    4    Cuyahoga        1337   Ohio       OH    John Kasich\\n\\n    >>> data = {\"A\": [1, 2]}\\n    >>> pd.json_normalize(data, \"A\", record_prefix=\"Prefix.\")\\n        Prefix.0\\n    0          1\\n    1          2\\n\\n    Returns normalized data with columns prefixed with the given string.\\n    '\n\n    def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n        \"\"\"Internal function to pull field\"\"\"\n        result = js\n        try:\n            if isinstance(spec, list):\n                for field in spec:\n                    if result is None:\n                        raise KeyError(field)\n                    result = result[field]\n            else:\n                result = result[spec]\n        except KeyError as e:\n            if extract_record:\n                raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n            if errors == 'ignore':\n                return np.nan\n            else:\n                raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n        return result\n\n    def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n        \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n        result = _pull_field(js, spec, extract_record=True)\n        if not isinstance(result, list):\n            if pd.isnull(result):\n                result = []\n            else:\n                raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n        return result\n    if isinstance(data, list) and (not data):\n        return DataFrame()\n    elif isinstance(data, dict):\n        data = [data]\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, str)):\n        data = list(data)\n    else:\n        raise NotImplementedError\n    if record_path is None and meta is None and (meta_prefix is None) and (record_prefix is None) and (max_level is None):\n        return DataFrame(_simple_json_normalize(data, sep=sep))\n    if record_path is None:\n        if any(([isinstance(x, dict) for x in y.values()] for y in data)):\n            data = nested_to_record(data, sep=sep, max_level=max_level)\n        return DataFrame(data)\n    elif not isinstance(record_path, list):\n        record_path = [record_path]\n    if meta is None:\n        meta = []\n    elif not isinstance(meta, list):\n        meta = [meta]\n    _meta = [m if isinstance(m, list) else [m] for m in meta]\n    records: list = []\n    lengths = []\n    meta_vals: DefaultDict = defaultdict(list)\n    meta_keys = [sep.join(val) for val in _meta]\n\n    def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n        if isinstance(data, dict):\n            data = [data]\n        if len(path) > 1:\n            for obj in data:\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 == len(val):\n                        seen_meta[key] = _pull_field(obj, val[-1])\n                _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n        else:\n            for obj in data:\n                recs = _pull_records(obj, path[0])\n                recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n                lengths.append(len(recs))\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 > len(val):\n                        meta_val = seen_meta[key]\n                    else:\n                        meta_val = _pull_field(obj, val[level:])\n                    meta_vals[key].append(meta_val)\n                records.extend(recs)\n    _recursive_extract(data, record_path, {}, level=0)\n    result = DataFrame(records)\n    if record_prefix is not None:\n        result = result.rename(columns=lambda x: f'{record_prefix}{x}')\n    for (k, v) in meta_vals.items():\n        if meta_prefix is not None:\n            k = meta_prefix + k\n        if k in result:\n            raise ValueError(f'Conflicting metadata name {k}, need distinguishing prefix ')\n        values = np.array(v, dtype=object)\n        if values.ndim > 1:\n            values = np.empty((len(v),), dtype=object)\n            for (i, v) in enumerate(v):\n                values[i] = v\n        result[k] = values.repeat(lengths)\n    return result",
            "def json_normalize(data: dict | list[dict], record_path: str | list | None=None, meta: str | list[str | list[str]] | None=None, meta_prefix: str | None=None, record_prefix: str | None=None, errors: IgnoreRaise='raise', sep: str='.', max_level: int | None=None) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n        Unserialized JSON objects.\\n    record_path : str or list of str, default None\\n        Path in each object to list of records. If not passed, data will be\\n        assumed to be an array of records.\\n    meta : list of paths (str or list of str), default None\\n        Fields to use as metadata for each record in resulting table.\\n    meta_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        meta is [\\'foo\\', \\'bar\\'].\\n    record_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        path to records is [\\'foo\\', \\'bar\\'].\\n    errors : {\\'raise\\', \\'ignore\\'}, default \\'raise\\'\\n        Configures error handling.\\n\\n        * \\'ignore\\' : will ignore KeyError if keys listed in meta are not\\n          always present.\\n        * \\'raise\\' : will raise KeyError if keys listed in meta are not\\n          always present.\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep.\\n        e.g., for sep=\\'.\\', {\\'foo\\': {\\'bar\\': 0}} -> foo.bar.\\n    max_level : int, default None\\n        Max number of levels(depth of dict) to normalize.\\n        if None, normalizes all levels.\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Examples\\n    --------\\n    >>> data = [\\n    ...     {\"id\": 1, \"name\": {\"first\": \"Coleen\", \"last\": \"Volk\"}},\\n    ...     {\"name\": {\"given\": \"Mark\", \"family\": \"Regner\"}},\\n    ...     {\"id\": 2, \"name\": \"Faye Raker\"},\\n    ... ]\\n    >>> pd.json_normalize(data)\\n        id name.first name.last name.given name.family        name\\n    0  1.0     Coleen      Volk        NaN         NaN         NaN\\n    1  NaN        NaN       NaN       Mark      Regner         NaN\\n    2  2.0        NaN       NaN        NaN         NaN  Faye Raker\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=0)\\n        id        name                        fitness\\n    0  1.0   Cole Volk  {\\'height\\': 130, \\'weight\\': 60}\\n    1  NaN    Mark Reg  {\\'height\\': 130, \\'weight\\': 60}\\n    2  2.0  Faye Raker  {\\'height\\': 130, \\'weight\\': 60}\\n\\n    Normalizes nested data up to level 1.\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=1)\\n        id        name  fitness.height  fitness.weight\\n    0  1.0   Cole Volk             130              60\\n    1  NaN    Mark Reg             130              60\\n    2  2.0  Faye Raker             130              60\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"state\": \"Florida\",\\n    ...         \"shortname\": \"FL\",\\n    ...         \"info\": {\"governor\": \"Rick Scott\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Dade\", \"population\": 12345},\\n    ...             {\"name\": \"Broward\", \"population\": 40000},\\n    ...             {\"name\": \"Palm Beach\", \"population\": 60000},\\n    ...         ],\\n    ...     },\\n    ...     {\\n    ...         \"state\": \"Ohio\",\\n    ...         \"shortname\": \"OH\",\\n    ...         \"info\": {\"governor\": \"John Kasich\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Summit\", \"population\": 1234},\\n    ...             {\"name\": \"Cuyahoga\", \"population\": 1337},\\n    ...         ],\\n    ...     },\\n    ... ]\\n    >>> result = pd.json_normalize(\\n    ...     data, \"counties\", [\"state\", \"shortname\", [\"info\", \"governor\"]]\\n    ... )\\n    >>> result\\n             name  population    state shortname info.governor\\n    0        Dade       12345   Florida    FL    Rick Scott\\n    1     Broward       40000   Florida    FL    Rick Scott\\n    2  Palm Beach       60000   Florida    FL    Rick Scott\\n    3      Summit        1234   Ohio       OH    John Kasich\\n    4    Cuyahoga        1337   Ohio       OH    John Kasich\\n\\n    >>> data = {\"A\": [1, 2]}\\n    >>> pd.json_normalize(data, \"A\", record_prefix=\"Prefix.\")\\n        Prefix.0\\n    0          1\\n    1          2\\n\\n    Returns normalized data with columns prefixed with the given string.\\n    '\n\n    def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n        \"\"\"Internal function to pull field\"\"\"\n        result = js\n        try:\n            if isinstance(spec, list):\n                for field in spec:\n                    if result is None:\n                        raise KeyError(field)\n                    result = result[field]\n            else:\n                result = result[spec]\n        except KeyError as e:\n            if extract_record:\n                raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n            if errors == 'ignore':\n                return np.nan\n            else:\n                raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n        return result\n\n    def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n        \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n        result = _pull_field(js, spec, extract_record=True)\n        if not isinstance(result, list):\n            if pd.isnull(result):\n                result = []\n            else:\n                raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n        return result\n    if isinstance(data, list) and (not data):\n        return DataFrame()\n    elif isinstance(data, dict):\n        data = [data]\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, str)):\n        data = list(data)\n    else:\n        raise NotImplementedError\n    if record_path is None and meta is None and (meta_prefix is None) and (record_prefix is None) and (max_level is None):\n        return DataFrame(_simple_json_normalize(data, sep=sep))\n    if record_path is None:\n        if any(([isinstance(x, dict) for x in y.values()] for y in data)):\n            data = nested_to_record(data, sep=sep, max_level=max_level)\n        return DataFrame(data)\n    elif not isinstance(record_path, list):\n        record_path = [record_path]\n    if meta is None:\n        meta = []\n    elif not isinstance(meta, list):\n        meta = [meta]\n    _meta = [m if isinstance(m, list) else [m] for m in meta]\n    records: list = []\n    lengths = []\n    meta_vals: DefaultDict = defaultdict(list)\n    meta_keys = [sep.join(val) for val in _meta]\n\n    def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n        if isinstance(data, dict):\n            data = [data]\n        if len(path) > 1:\n            for obj in data:\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 == len(val):\n                        seen_meta[key] = _pull_field(obj, val[-1])\n                _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n        else:\n            for obj in data:\n                recs = _pull_records(obj, path[0])\n                recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n                lengths.append(len(recs))\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 > len(val):\n                        meta_val = seen_meta[key]\n                    else:\n                        meta_val = _pull_field(obj, val[level:])\n                    meta_vals[key].append(meta_val)\n                records.extend(recs)\n    _recursive_extract(data, record_path, {}, level=0)\n    result = DataFrame(records)\n    if record_prefix is not None:\n        result = result.rename(columns=lambda x: f'{record_prefix}{x}')\n    for (k, v) in meta_vals.items():\n        if meta_prefix is not None:\n            k = meta_prefix + k\n        if k in result:\n            raise ValueError(f'Conflicting metadata name {k}, need distinguishing prefix ')\n        values = np.array(v, dtype=object)\n        if values.ndim > 1:\n            values = np.empty((len(v),), dtype=object)\n            for (i, v) in enumerate(v):\n                values[i] = v\n        result[k] = values.repeat(lengths)\n    return result",
            "def json_normalize(data: dict | list[dict], record_path: str | list | None=None, meta: str | list[str | list[str]] | None=None, meta_prefix: str | None=None, record_prefix: str | None=None, errors: IgnoreRaise='raise', sep: str='.', max_level: int | None=None) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Parameters\\n    ----------\\n    data : dict or list of dicts\\n        Unserialized JSON objects.\\n    record_path : str or list of str, default None\\n        Path in each object to list of records. If not passed, data will be\\n        assumed to be an array of records.\\n    meta : list of paths (str or list of str), default None\\n        Fields to use as metadata for each record in resulting table.\\n    meta_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        meta is [\\'foo\\', \\'bar\\'].\\n    record_prefix : str, default None\\n        If True, prefix records with dotted (?) path, e.g. foo.bar.field if\\n        path to records is [\\'foo\\', \\'bar\\'].\\n    errors : {\\'raise\\', \\'ignore\\'}, default \\'raise\\'\\n        Configures error handling.\\n\\n        * \\'ignore\\' : will ignore KeyError if keys listed in meta are not\\n          always present.\\n        * \\'raise\\' : will raise KeyError if keys listed in meta are not\\n          always present.\\n    sep : str, default \\'.\\'\\n        Nested records will generate names separated by sep.\\n        e.g., for sep=\\'.\\', {\\'foo\\': {\\'bar\\': 0}} -> foo.bar.\\n    max_level : int, default None\\n        Max number of levels(depth of dict) to normalize.\\n        if None, normalizes all levels.\\n\\n    Returns\\n    -------\\n    frame : DataFrame\\n    Normalize semi-structured JSON data into a flat table.\\n\\n    Examples\\n    --------\\n    >>> data = [\\n    ...     {\"id\": 1, \"name\": {\"first\": \"Coleen\", \"last\": \"Volk\"}},\\n    ...     {\"name\": {\"given\": \"Mark\", \"family\": \"Regner\"}},\\n    ...     {\"id\": 2, \"name\": \"Faye Raker\"},\\n    ... ]\\n    >>> pd.json_normalize(data)\\n        id name.first name.last name.given name.family        name\\n    0  1.0     Coleen      Volk        NaN         NaN         NaN\\n    1  NaN        NaN       NaN       Mark      Regner         NaN\\n    2  2.0        NaN       NaN        NaN         NaN  Faye Raker\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=0)\\n        id        name                        fitness\\n    0  1.0   Cole Volk  {\\'height\\': 130, \\'weight\\': 60}\\n    1  NaN    Mark Reg  {\\'height\\': 130, \\'weight\\': 60}\\n    2  2.0  Faye Raker  {\\'height\\': 130, \\'weight\\': 60}\\n\\n    Normalizes nested data up to level 1.\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"id\": 1,\\n    ...         \"name\": \"Cole Volk\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ...     {\"name\": \"Mark Reg\", \"fitness\": {\"height\": 130, \"weight\": 60}},\\n    ...     {\\n    ...         \"id\": 2,\\n    ...         \"name\": \"Faye Raker\",\\n    ...         \"fitness\": {\"height\": 130, \"weight\": 60},\\n    ...     },\\n    ... ]\\n    >>> pd.json_normalize(data, max_level=1)\\n        id        name  fitness.height  fitness.weight\\n    0  1.0   Cole Volk             130              60\\n    1  NaN    Mark Reg             130              60\\n    2  2.0  Faye Raker             130              60\\n\\n    >>> data = [\\n    ...     {\\n    ...         \"state\": \"Florida\",\\n    ...         \"shortname\": \"FL\",\\n    ...         \"info\": {\"governor\": \"Rick Scott\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Dade\", \"population\": 12345},\\n    ...             {\"name\": \"Broward\", \"population\": 40000},\\n    ...             {\"name\": \"Palm Beach\", \"population\": 60000},\\n    ...         ],\\n    ...     },\\n    ...     {\\n    ...         \"state\": \"Ohio\",\\n    ...         \"shortname\": \"OH\",\\n    ...         \"info\": {\"governor\": \"John Kasich\"},\\n    ...         \"counties\": [\\n    ...             {\"name\": \"Summit\", \"population\": 1234},\\n    ...             {\"name\": \"Cuyahoga\", \"population\": 1337},\\n    ...         ],\\n    ...     },\\n    ... ]\\n    >>> result = pd.json_normalize(\\n    ...     data, \"counties\", [\"state\", \"shortname\", [\"info\", \"governor\"]]\\n    ... )\\n    >>> result\\n             name  population    state shortname info.governor\\n    0        Dade       12345   Florida    FL    Rick Scott\\n    1     Broward       40000   Florida    FL    Rick Scott\\n    2  Palm Beach       60000   Florida    FL    Rick Scott\\n    3      Summit        1234   Ohio       OH    John Kasich\\n    4    Cuyahoga        1337   Ohio       OH    John Kasich\\n\\n    >>> data = {\"A\": [1, 2]}\\n    >>> pd.json_normalize(data, \"A\", record_prefix=\"Prefix.\")\\n        Prefix.0\\n    0          1\\n    1          2\\n\\n    Returns normalized data with columns prefixed with the given string.\\n    '\n\n    def _pull_field(js: dict[str, Any], spec: list | str, extract_record: bool=False) -> Scalar | Iterable:\n        \"\"\"Internal function to pull field\"\"\"\n        result = js\n        try:\n            if isinstance(spec, list):\n                for field in spec:\n                    if result is None:\n                        raise KeyError(field)\n                    result = result[field]\n            else:\n                result = result[spec]\n        except KeyError as e:\n            if extract_record:\n                raise KeyError(f'Key {e} not found. If specifying a record_path, all elements of data should have the path.') from e\n            if errors == 'ignore':\n                return np.nan\n            else:\n                raise KeyError(f\"Key {e} not found. To replace missing values of {e} with np.nan, pass in errors='ignore'\") from e\n        return result\n\n    def _pull_records(js: dict[str, Any], spec: list | str) -> list:\n        \"\"\"\n        Internal function to pull field for records, and similar to\n        _pull_field, but require to return list. And will raise error\n        if has non iterable value.\n        \"\"\"\n        result = _pull_field(js, spec, extract_record=True)\n        if not isinstance(result, list):\n            if pd.isnull(result):\n                result = []\n            else:\n                raise TypeError(f'{js} has non list value {result} for path {spec}. Must be list or null.')\n        return result\n    if isinstance(data, list) and (not data):\n        return DataFrame()\n    elif isinstance(data, dict):\n        data = [data]\n    elif isinstance(data, abc.Iterable) and (not isinstance(data, str)):\n        data = list(data)\n    else:\n        raise NotImplementedError\n    if record_path is None and meta is None and (meta_prefix is None) and (record_prefix is None) and (max_level is None):\n        return DataFrame(_simple_json_normalize(data, sep=sep))\n    if record_path is None:\n        if any(([isinstance(x, dict) for x in y.values()] for y in data)):\n            data = nested_to_record(data, sep=sep, max_level=max_level)\n        return DataFrame(data)\n    elif not isinstance(record_path, list):\n        record_path = [record_path]\n    if meta is None:\n        meta = []\n    elif not isinstance(meta, list):\n        meta = [meta]\n    _meta = [m if isinstance(m, list) else [m] for m in meta]\n    records: list = []\n    lengths = []\n    meta_vals: DefaultDict = defaultdict(list)\n    meta_keys = [sep.join(val) for val in _meta]\n\n    def _recursive_extract(data, path, seen_meta, level: int=0) -> None:\n        if isinstance(data, dict):\n            data = [data]\n        if len(path) > 1:\n            for obj in data:\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 == len(val):\n                        seen_meta[key] = _pull_field(obj, val[-1])\n                _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)\n        else:\n            for obj in data:\n                recs = _pull_records(obj, path[0])\n                recs = [nested_to_record(r, sep=sep, max_level=max_level) if isinstance(r, dict) else r for r in recs]\n                lengths.append(len(recs))\n                for (val, key) in zip(_meta, meta_keys):\n                    if level + 1 > len(val):\n                        meta_val = seen_meta[key]\n                    else:\n                        meta_val = _pull_field(obj, val[level:])\n                    meta_vals[key].append(meta_val)\n                records.extend(recs)\n    _recursive_extract(data, record_path, {}, level=0)\n    result = DataFrame(records)\n    if record_prefix is not None:\n        result = result.rename(columns=lambda x: f'{record_prefix}{x}')\n    for (k, v) in meta_vals.items():\n        if meta_prefix is not None:\n            k = meta_prefix + k\n        if k in result:\n            raise ValueError(f'Conflicting metadata name {k}, need distinguishing prefix ')\n        values = np.array(v, dtype=object)\n        if values.ndim > 1:\n            values = np.empty((len(v),), dtype=object)\n            for (i, v) in enumerate(v):\n                values[i] = v\n        result[k] = values.repeat(lengths)\n    return result"
        ]
    }
]