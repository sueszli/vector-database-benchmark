[
    {
        "func_name": "__init__",
        "original": "def __init__(self):\n    super().__init__()\n    self.linear1 = Linear(10, 10)\n    self.lienar2 = Linear(10, 20)\n    self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.batch_norm_1 = BatchNorm(10)\n    self.batch_norm_2 = BatchNorm(10)\n    self.emb1 = paddle.nn.Embedding(1000, 100)\n    self.emb2 = paddle.nn.Embedding(2000, 200)\n    self.layer_norm_1 = paddle.nn.LayerNorm([10])\n    self.layer_norm_2 = paddle.nn.LayerNorm(10)\n    self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n    self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n    self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n    self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')",
        "mutated": [
            "def __init__(self):\n    if False:\n        i = 10\n    super().__init__()\n    self.linear1 = Linear(10, 10)\n    self.lienar2 = Linear(10, 20)\n    self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.batch_norm_1 = BatchNorm(10)\n    self.batch_norm_2 = BatchNorm(10)\n    self.emb1 = paddle.nn.Embedding(1000, 100)\n    self.emb2 = paddle.nn.Embedding(2000, 200)\n    self.layer_norm_1 = paddle.nn.LayerNorm([10])\n    self.layer_norm_2 = paddle.nn.LayerNorm(10)\n    self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n    self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n    self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n    self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__()\n    self.linear1 = Linear(10, 10)\n    self.lienar2 = Linear(10, 20)\n    self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.batch_norm_1 = BatchNorm(10)\n    self.batch_norm_2 = BatchNorm(10)\n    self.emb1 = paddle.nn.Embedding(1000, 100)\n    self.emb2 = paddle.nn.Embedding(2000, 200)\n    self.layer_norm_1 = paddle.nn.LayerNorm([10])\n    self.layer_norm_2 = paddle.nn.LayerNorm(10)\n    self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n    self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n    self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n    self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__()\n    self.linear1 = Linear(10, 10)\n    self.lienar2 = Linear(10, 20)\n    self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.batch_norm_1 = BatchNorm(10)\n    self.batch_norm_2 = BatchNorm(10)\n    self.emb1 = paddle.nn.Embedding(1000, 100)\n    self.emb2 = paddle.nn.Embedding(2000, 200)\n    self.layer_norm_1 = paddle.nn.LayerNorm([10])\n    self.layer_norm_2 = paddle.nn.LayerNorm(10)\n    self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n    self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n    self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n    self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__()\n    self.linear1 = Linear(10, 10)\n    self.lienar2 = Linear(10, 20)\n    self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.batch_norm_1 = BatchNorm(10)\n    self.batch_norm_2 = BatchNorm(10)\n    self.emb1 = paddle.nn.Embedding(1000, 100)\n    self.emb2 = paddle.nn.Embedding(2000, 200)\n    self.layer_norm_1 = paddle.nn.LayerNorm([10])\n    self.layer_norm_2 = paddle.nn.LayerNorm(10)\n    self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n    self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n    self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n    self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__()\n    self.linear1 = Linear(10, 10)\n    self.lienar2 = Linear(10, 20)\n    self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n    self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n    self.batch_norm_1 = BatchNorm(10)\n    self.batch_norm_2 = BatchNorm(10)\n    self.emb1 = paddle.nn.Embedding(1000, 100)\n    self.emb2 = paddle.nn.Embedding(2000, 200)\n    self.layer_norm_1 = paddle.nn.LayerNorm([10])\n    self.layer_norm_2 = paddle.nn.LayerNorm(10)\n    self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n    self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n    self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n    self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')"
        ]
    },
    {
        "func_name": "testLoadStaticModel",
        "original": "def testLoadStaticModel(self):\n    temp_dir = tempfile.TemporaryDirectory()\n    a = paddle.static.data(name='a', shape=[10, 10])\n    conv_in = paddle.static.data(name='conv_in', shape=[None, 10, 10, 10])\n    fc_out1 = paddle.static.nn.fc(a, 10)\n    fc_out2 = paddle.static.nn.fc(a, 20)\n    conv_out_1 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv_out_2 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_in = paddle.static.data(name='conv3d_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_out_1 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_out_2 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    batchnorm_in = paddle.static.data(name='batchnorm_in', shape=[None, 10], dtype='float32')\n    batchnorm_out_1 = paddle.static.nn.batch_norm(batchnorm_in)\n    batchnorm_out_2 = paddle.static.nn.batch_norm(batchnorm_in)\n    emb_in = paddle.static.data(name='emb_in', shape=[None, 10], dtype='int64')\n    emb_out_1 = paddle.static.nn.embedding(emb_in, [1000, 100])\n    emb_out_2 = paddle.static.nn.embedding(emb_in, [2000, 200])\n    layernorm = paddle.static.data(name='ln', shape=[None, 10], dtype='float32')\n    layernorm_1 = paddle.static.nn.layer_norm(layernorm)\n    layernorm_2 = paddle.static.nn.layer_norm(layernorm)\n    nce_in = paddle.static.data(name='nce_in', shape=[None, 100], dtype='float32')\n    nce_label = paddle.static.data(name='nce_label', shape=[None, 10], dtype='int64')\n    nce_out_1 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    nce_out_2 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    prelu_in = paddle.static.data(name='prelu_in', shape=[None, 5, 10, 10], dtype='float32')\n    prelu_out_1 = paddle.static.nn.prelu(prelu_in, 'channel')\n    prelu_out_2 = paddle.static.nn.prelu(prelu_in, 'channel')\n    bilinear_tensor_pro_x = paddle.static.data('t1', shape=[None, 5], dtype='float32')\n    bilinear_tensor_pro_y = paddle.static.data('t2', shape=[None, 4], dtype='float32')\n    bilinear_tensor_pro_out_1 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    bilinear_tensor_pro_out_2 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    conv2d_trans_in = paddle.static.data(name='conv2d_trans_in', shape=[None, 10, 10, 10])\n    conv2d_trans_out_1 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv2d_trans_out_2 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_trans_in = paddle.static.data(name='conv3d_trans_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_trans_out_1 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_trans_out_2 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    groupnorm_in = paddle.static.data(name='groupnorm_in', shape=[None, 8, 32, 32], dtype='float32')\n    groupnorm_out1 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    groupnorm_out2 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    \"\\n        spec_norm = paddle.static.data(name='spec_norm', shape=[2, 8, 32, 32], dtype='float32')\\n        spe_norm_out_1 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        spe_norm_out_2 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        \"\n    para1 = paddle.create_parameter([100, 100], 'float32', name='weight_test_1')\n    para2 = paddle.create_parameter([20, 200], 'float32', name='weight_test_2')\n    para_list = base.default_main_program().list_vars()\n    exe = base.Executor(base.CPUPlace() if not base.is_compiled_with_cuda() else base.CUDAPlace(0))\n    out = exe.run(framework.default_startup_program())\n    paddle.static.save(framework.default_main_program(), os.path.join(temp_dir.name, 'test_1'))\n    para_dict = paddle.static.load_program_state(os.path.join(temp_dir.name, 'test_1'))\n    new_dict = {}\n    for (k, v) in para_dict.items():\n        if k.startswith('fc'):\n            name = k.replace('fc', 'linear', 1)\n            new_dict[name] = v\n        else:\n            new_dict[k] = v\n    with base.dygraph.guard():\n\n        class MyTest(paddle.nn.Layer):\n\n            def __init__(self):\n                super().__init__()\n                self.linear1 = Linear(10, 10)\n                self.lienar2 = Linear(10, 20)\n                self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.batch_norm_1 = BatchNorm(10)\n                self.batch_norm_2 = BatchNorm(10)\n                self.emb1 = paddle.nn.Embedding(1000, 100)\n                self.emb2 = paddle.nn.Embedding(2000, 200)\n                self.layer_norm_1 = paddle.nn.LayerNorm([10])\n                self.layer_norm_2 = paddle.nn.LayerNorm(10)\n                self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n                self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n                self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n                self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')\n        my_test = MyTest()\n        my_test.set_dict(new_dict, use_structured_name=False)\n        for (k, v) in my_test.state_dict().items():\n            np.testing.assert_array_equal(v.numpy(), new_dict[v.name])\n    temp_dir.cleanup()",
        "mutated": [
            "def testLoadStaticModel(self):\n    if False:\n        i = 10\n    temp_dir = tempfile.TemporaryDirectory()\n    a = paddle.static.data(name='a', shape=[10, 10])\n    conv_in = paddle.static.data(name='conv_in', shape=[None, 10, 10, 10])\n    fc_out1 = paddle.static.nn.fc(a, 10)\n    fc_out2 = paddle.static.nn.fc(a, 20)\n    conv_out_1 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv_out_2 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_in = paddle.static.data(name='conv3d_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_out_1 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_out_2 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    batchnorm_in = paddle.static.data(name='batchnorm_in', shape=[None, 10], dtype='float32')\n    batchnorm_out_1 = paddle.static.nn.batch_norm(batchnorm_in)\n    batchnorm_out_2 = paddle.static.nn.batch_norm(batchnorm_in)\n    emb_in = paddle.static.data(name='emb_in', shape=[None, 10], dtype='int64')\n    emb_out_1 = paddle.static.nn.embedding(emb_in, [1000, 100])\n    emb_out_2 = paddle.static.nn.embedding(emb_in, [2000, 200])\n    layernorm = paddle.static.data(name='ln', shape=[None, 10], dtype='float32')\n    layernorm_1 = paddle.static.nn.layer_norm(layernorm)\n    layernorm_2 = paddle.static.nn.layer_norm(layernorm)\n    nce_in = paddle.static.data(name='nce_in', shape=[None, 100], dtype='float32')\n    nce_label = paddle.static.data(name='nce_label', shape=[None, 10], dtype='int64')\n    nce_out_1 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    nce_out_2 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    prelu_in = paddle.static.data(name='prelu_in', shape=[None, 5, 10, 10], dtype='float32')\n    prelu_out_1 = paddle.static.nn.prelu(prelu_in, 'channel')\n    prelu_out_2 = paddle.static.nn.prelu(prelu_in, 'channel')\n    bilinear_tensor_pro_x = paddle.static.data('t1', shape=[None, 5], dtype='float32')\n    bilinear_tensor_pro_y = paddle.static.data('t2', shape=[None, 4], dtype='float32')\n    bilinear_tensor_pro_out_1 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    bilinear_tensor_pro_out_2 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    conv2d_trans_in = paddle.static.data(name='conv2d_trans_in', shape=[None, 10, 10, 10])\n    conv2d_trans_out_1 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv2d_trans_out_2 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_trans_in = paddle.static.data(name='conv3d_trans_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_trans_out_1 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_trans_out_2 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    groupnorm_in = paddle.static.data(name='groupnorm_in', shape=[None, 8, 32, 32], dtype='float32')\n    groupnorm_out1 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    groupnorm_out2 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    \"\\n        spec_norm = paddle.static.data(name='spec_norm', shape=[2, 8, 32, 32], dtype='float32')\\n        spe_norm_out_1 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        spe_norm_out_2 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        \"\n    para1 = paddle.create_parameter([100, 100], 'float32', name='weight_test_1')\n    para2 = paddle.create_parameter([20, 200], 'float32', name='weight_test_2')\n    para_list = base.default_main_program().list_vars()\n    exe = base.Executor(base.CPUPlace() if not base.is_compiled_with_cuda() else base.CUDAPlace(0))\n    out = exe.run(framework.default_startup_program())\n    paddle.static.save(framework.default_main_program(), os.path.join(temp_dir.name, 'test_1'))\n    para_dict = paddle.static.load_program_state(os.path.join(temp_dir.name, 'test_1'))\n    new_dict = {}\n    for (k, v) in para_dict.items():\n        if k.startswith('fc'):\n            name = k.replace('fc', 'linear', 1)\n            new_dict[name] = v\n        else:\n            new_dict[k] = v\n    with base.dygraph.guard():\n\n        class MyTest(paddle.nn.Layer):\n\n            def __init__(self):\n                super().__init__()\n                self.linear1 = Linear(10, 10)\n                self.lienar2 = Linear(10, 20)\n                self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.batch_norm_1 = BatchNorm(10)\n                self.batch_norm_2 = BatchNorm(10)\n                self.emb1 = paddle.nn.Embedding(1000, 100)\n                self.emb2 = paddle.nn.Embedding(2000, 200)\n                self.layer_norm_1 = paddle.nn.LayerNorm([10])\n                self.layer_norm_2 = paddle.nn.LayerNorm(10)\n                self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n                self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n                self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n                self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')\n        my_test = MyTest()\n        my_test.set_dict(new_dict, use_structured_name=False)\n        for (k, v) in my_test.state_dict().items():\n            np.testing.assert_array_equal(v.numpy(), new_dict[v.name])\n    temp_dir.cleanup()",
            "def testLoadStaticModel(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    temp_dir = tempfile.TemporaryDirectory()\n    a = paddle.static.data(name='a', shape=[10, 10])\n    conv_in = paddle.static.data(name='conv_in', shape=[None, 10, 10, 10])\n    fc_out1 = paddle.static.nn.fc(a, 10)\n    fc_out2 = paddle.static.nn.fc(a, 20)\n    conv_out_1 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv_out_2 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_in = paddle.static.data(name='conv3d_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_out_1 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_out_2 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    batchnorm_in = paddle.static.data(name='batchnorm_in', shape=[None, 10], dtype='float32')\n    batchnorm_out_1 = paddle.static.nn.batch_norm(batchnorm_in)\n    batchnorm_out_2 = paddle.static.nn.batch_norm(batchnorm_in)\n    emb_in = paddle.static.data(name='emb_in', shape=[None, 10], dtype='int64')\n    emb_out_1 = paddle.static.nn.embedding(emb_in, [1000, 100])\n    emb_out_2 = paddle.static.nn.embedding(emb_in, [2000, 200])\n    layernorm = paddle.static.data(name='ln', shape=[None, 10], dtype='float32')\n    layernorm_1 = paddle.static.nn.layer_norm(layernorm)\n    layernorm_2 = paddle.static.nn.layer_norm(layernorm)\n    nce_in = paddle.static.data(name='nce_in', shape=[None, 100], dtype='float32')\n    nce_label = paddle.static.data(name='nce_label', shape=[None, 10], dtype='int64')\n    nce_out_1 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    nce_out_2 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    prelu_in = paddle.static.data(name='prelu_in', shape=[None, 5, 10, 10], dtype='float32')\n    prelu_out_1 = paddle.static.nn.prelu(prelu_in, 'channel')\n    prelu_out_2 = paddle.static.nn.prelu(prelu_in, 'channel')\n    bilinear_tensor_pro_x = paddle.static.data('t1', shape=[None, 5], dtype='float32')\n    bilinear_tensor_pro_y = paddle.static.data('t2', shape=[None, 4], dtype='float32')\n    bilinear_tensor_pro_out_1 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    bilinear_tensor_pro_out_2 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    conv2d_trans_in = paddle.static.data(name='conv2d_trans_in', shape=[None, 10, 10, 10])\n    conv2d_trans_out_1 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv2d_trans_out_2 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_trans_in = paddle.static.data(name='conv3d_trans_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_trans_out_1 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_trans_out_2 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    groupnorm_in = paddle.static.data(name='groupnorm_in', shape=[None, 8, 32, 32], dtype='float32')\n    groupnorm_out1 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    groupnorm_out2 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    \"\\n        spec_norm = paddle.static.data(name='spec_norm', shape=[2, 8, 32, 32], dtype='float32')\\n        spe_norm_out_1 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        spe_norm_out_2 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        \"\n    para1 = paddle.create_parameter([100, 100], 'float32', name='weight_test_1')\n    para2 = paddle.create_parameter([20, 200], 'float32', name='weight_test_2')\n    para_list = base.default_main_program().list_vars()\n    exe = base.Executor(base.CPUPlace() if not base.is_compiled_with_cuda() else base.CUDAPlace(0))\n    out = exe.run(framework.default_startup_program())\n    paddle.static.save(framework.default_main_program(), os.path.join(temp_dir.name, 'test_1'))\n    para_dict = paddle.static.load_program_state(os.path.join(temp_dir.name, 'test_1'))\n    new_dict = {}\n    for (k, v) in para_dict.items():\n        if k.startswith('fc'):\n            name = k.replace('fc', 'linear', 1)\n            new_dict[name] = v\n        else:\n            new_dict[k] = v\n    with base.dygraph.guard():\n\n        class MyTest(paddle.nn.Layer):\n\n            def __init__(self):\n                super().__init__()\n                self.linear1 = Linear(10, 10)\n                self.lienar2 = Linear(10, 20)\n                self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.batch_norm_1 = BatchNorm(10)\n                self.batch_norm_2 = BatchNorm(10)\n                self.emb1 = paddle.nn.Embedding(1000, 100)\n                self.emb2 = paddle.nn.Embedding(2000, 200)\n                self.layer_norm_1 = paddle.nn.LayerNorm([10])\n                self.layer_norm_2 = paddle.nn.LayerNorm(10)\n                self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n                self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n                self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n                self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')\n        my_test = MyTest()\n        my_test.set_dict(new_dict, use_structured_name=False)\n        for (k, v) in my_test.state_dict().items():\n            np.testing.assert_array_equal(v.numpy(), new_dict[v.name])\n    temp_dir.cleanup()",
            "def testLoadStaticModel(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    temp_dir = tempfile.TemporaryDirectory()\n    a = paddle.static.data(name='a', shape=[10, 10])\n    conv_in = paddle.static.data(name='conv_in', shape=[None, 10, 10, 10])\n    fc_out1 = paddle.static.nn.fc(a, 10)\n    fc_out2 = paddle.static.nn.fc(a, 20)\n    conv_out_1 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv_out_2 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_in = paddle.static.data(name='conv3d_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_out_1 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_out_2 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    batchnorm_in = paddle.static.data(name='batchnorm_in', shape=[None, 10], dtype='float32')\n    batchnorm_out_1 = paddle.static.nn.batch_norm(batchnorm_in)\n    batchnorm_out_2 = paddle.static.nn.batch_norm(batchnorm_in)\n    emb_in = paddle.static.data(name='emb_in', shape=[None, 10], dtype='int64')\n    emb_out_1 = paddle.static.nn.embedding(emb_in, [1000, 100])\n    emb_out_2 = paddle.static.nn.embedding(emb_in, [2000, 200])\n    layernorm = paddle.static.data(name='ln', shape=[None, 10], dtype='float32')\n    layernorm_1 = paddle.static.nn.layer_norm(layernorm)\n    layernorm_2 = paddle.static.nn.layer_norm(layernorm)\n    nce_in = paddle.static.data(name='nce_in', shape=[None, 100], dtype='float32')\n    nce_label = paddle.static.data(name='nce_label', shape=[None, 10], dtype='int64')\n    nce_out_1 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    nce_out_2 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    prelu_in = paddle.static.data(name='prelu_in', shape=[None, 5, 10, 10], dtype='float32')\n    prelu_out_1 = paddle.static.nn.prelu(prelu_in, 'channel')\n    prelu_out_2 = paddle.static.nn.prelu(prelu_in, 'channel')\n    bilinear_tensor_pro_x = paddle.static.data('t1', shape=[None, 5], dtype='float32')\n    bilinear_tensor_pro_y = paddle.static.data('t2', shape=[None, 4], dtype='float32')\n    bilinear_tensor_pro_out_1 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    bilinear_tensor_pro_out_2 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    conv2d_trans_in = paddle.static.data(name='conv2d_trans_in', shape=[None, 10, 10, 10])\n    conv2d_trans_out_1 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv2d_trans_out_2 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_trans_in = paddle.static.data(name='conv3d_trans_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_trans_out_1 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_trans_out_2 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    groupnorm_in = paddle.static.data(name='groupnorm_in', shape=[None, 8, 32, 32], dtype='float32')\n    groupnorm_out1 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    groupnorm_out2 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    \"\\n        spec_norm = paddle.static.data(name='spec_norm', shape=[2, 8, 32, 32], dtype='float32')\\n        spe_norm_out_1 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        spe_norm_out_2 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        \"\n    para1 = paddle.create_parameter([100, 100], 'float32', name='weight_test_1')\n    para2 = paddle.create_parameter([20, 200], 'float32', name='weight_test_2')\n    para_list = base.default_main_program().list_vars()\n    exe = base.Executor(base.CPUPlace() if not base.is_compiled_with_cuda() else base.CUDAPlace(0))\n    out = exe.run(framework.default_startup_program())\n    paddle.static.save(framework.default_main_program(), os.path.join(temp_dir.name, 'test_1'))\n    para_dict = paddle.static.load_program_state(os.path.join(temp_dir.name, 'test_1'))\n    new_dict = {}\n    for (k, v) in para_dict.items():\n        if k.startswith('fc'):\n            name = k.replace('fc', 'linear', 1)\n            new_dict[name] = v\n        else:\n            new_dict[k] = v\n    with base.dygraph.guard():\n\n        class MyTest(paddle.nn.Layer):\n\n            def __init__(self):\n                super().__init__()\n                self.linear1 = Linear(10, 10)\n                self.lienar2 = Linear(10, 20)\n                self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.batch_norm_1 = BatchNorm(10)\n                self.batch_norm_2 = BatchNorm(10)\n                self.emb1 = paddle.nn.Embedding(1000, 100)\n                self.emb2 = paddle.nn.Embedding(2000, 200)\n                self.layer_norm_1 = paddle.nn.LayerNorm([10])\n                self.layer_norm_2 = paddle.nn.LayerNorm(10)\n                self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n                self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n                self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n                self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')\n        my_test = MyTest()\n        my_test.set_dict(new_dict, use_structured_name=False)\n        for (k, v) in my_test.state_dict().items():\n            np.testing.assert_array_equal(v.numpy(), new_dict[v.name])\n    temp_dir.cleanup()",
            "def testLoadStaticModel(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    temp_dir = tempfile.TemporaryDirectory()\n    a = paddle.static.data(name='a', shape=[10, 10])\n    conv_in = paddle.static.data(name='conv_in', shape=[None, 10, 10, 10])\n    fc_out1 = paddle.static.nn.fc(a, 10)\n    fc_out2 = paddle.static.nn.fc(a, 20)\n    conv_out_1 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv_out_2 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_in = paddle.static.data(name='conv3d_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_out_1 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_out_2 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    batchnorm_in = paddle.static.data(name='batchnorm_in', shape=[None, 10], dtype='float32')\n    batchnorm_out_1 = paddle.static.nn.batch_norm(batchnorm_in)\n    batchnorm_out_2 = paddle.static.nn.batch_norm(batchnorm_in)\n    emb_in = paddle.static.data(name='emb_in', shape=[None, 10], dtype='int64')\n    emb_out_1 = paddle.static.nn.embedding(emb_in, [1000, 100])\n    emb_out_2 = paddle.static.nn.embedding(emb_in, [2000, 200])\n    layernorm = paddle.static.data(name='ln', shape=[None, 10], dtype='float32')\n    layernorm_1 = paddle.static.nn.layer_norm(layernorm)\n    layernorm_2 = paddle.static.nn.layer_norm(layernorm)\n    nce_in = paddle.static.data(name='nce_in', shape=[None, 100], dtype='float32')\n    nce_label = paddle.static.data(name='nce_label', shape=[None, 10], dtype='int64')\n    nce_out_1 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    nce_out_2 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    prelu_in = paddle.static.data(name='prelu_in', shape=[None, 5, 10, 10], dtype='float32')\n    prelu_out_1 = paddle.static.nn.prelu(prelu_in, 'channel')\n    prelu_out_2 = paddle.static.nn.prelu(prelu_in, 'channel')\n    bilinear_tensor_pro_x = paddle.static.data('t1', shape=[None, 5], dtype='float32')\n    bilinear_tensor_pro_y = paddle.static.data('t2', shape=[None, 4], dtype='float32')\n    bilinear_tensor_pro_out_1 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    bilinear_tensor_pro_out_2 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    conv2d_trans_in = paddle.static.data(name='conv2d_trans_in', shape=[None, 10, 10, 10])\n    conv2d_trans_out_1 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv2d_trans_out_2 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_trans_in = paddle.static.data(name='conv3d_trans_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_trans_out_1 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_trans_out_2 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    groupnorm_in = paddle.static.data(name='groupnorm_in', shape=[None, 8, 32, 32], dtype='float32')\n    groupnorm_out1 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    groupnorm_out2 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    \"\\n        spec_norm = paddle.static.data(name='spec_norm', shape=[2, 8, 32, 32], dtype='float32')\\n        spe_norm_out_1 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        spe_norm_out_2 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        \"\n    para1 = paddle.create_parameter([100, 100], 'float32', name='weight_test_1')\n    para2 = paddle.create_parameter([20, 200], 'float32', name='weight_test_2')\n    para_list = base.default_main_program().list_vars()\n    exe = base.Executor(base.CPUPlace() if not base.is_compiled_with_cuda() else base.CUDAPlace(0))\n    out = exe.run(framework.default_startup_program())\n    paddle.static.save(framework.default_main_program(), os.path.join(temp_dir.name, 'test_1'))\n    para_dict = paddle.static.load_program_state(os.path.join(temp_dir.name, 'test_1'))\n    new_dict = {}\n    for (k, v) in para_dict.items():\n        if k.startswith('fc'):\n            name = k.replace('fc', 'linear', 1)\n            new_dict[name] = v\n        else:\n            new_dict[k] = v\n    with base.dygraph.guard():\n\n        class MyTest(paddle.nn.Layer):\n\n            def __init__(self):\n                super().__init__()\n                self.linear1 = Linear(10, 10)\n                self.lienar2 = Linear(10, 20)\n                self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.batch_norm_1 = BatchNorm(10)\n                self.batch_norm_2 = BatchNorm(10)\n                self.emb1 = paddle.nn.Embedding(1000, 100)\n                self.emb2 = paddle.nn.Embedding(2000, 200)\n                self.layer_norm_1 = paddle.nn.LayerNorm([10])\n                self.layer_norm_2 = paddle.nn.LayerNorm(10)\n                self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n                self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n                self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n                self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')\n        my_test = MyTest()\n        my_test.set_dict(new_dict, use_structured_name=False)\n        for (k, v) in my_test.state_dict().items():\n            np.testing.assert_array_equal(v.numpy(), new_dict[v.name])\n    temp_dir.cleanup()",
            "def testLoadStaticModel(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    temp_dir = tempfile.TemporaryDirectory()\n    a = paddle.static.data(name='a', shape=[10, 10])\n    conv_in = paddle.static.data(name='conv_in', shape=[None, 10, 10, 10])\n    fc_out1 = paddle.static.nn.fc(a, 10)\n    fc_out2 = paddle.static.nn.fc(a, 20)\n    conv_out_1 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv_out_2 = paddle.static.nn.conv2d(conv_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_in = paddle.static.data(name='conv3d_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_out_1 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_out_2 = paddle.static.nn.conv3d(input=conv3d_in, num_filters=2, filter_size=3, act='relu')\n    batchnorm_in = paddle.static.data(name='batchnorm_in', shape=[None, 10], dtype='float32')\n    batchnorm_out_1 = paddle.static.nn.batch_norm(batchnorm_in)\n    batchnorm_out_2 = paddle.static.nn.batch_norm(batchnorm_in)\n    emb_in = paddle.static.data(name='emb_in', shape=[None, 10], dtype='int64')\n    emb_out_1 = paddle.static.nn.embedding(emb_in, [1000, 100])\n    emb_out_2 = paddle.static.nn.embedding(emb_in, [2000, 200])\n    layernorm = paddle.static.data(name='ln', shape=[None, 10], dtype='float32')\n    layernorm_1 = paddle.static.nn.layer_norm(layernorm)\n    layernorm_2 = paddle.static.nn.layer_norm(layernorm)\n    nce_in = paddle.static.data(name='nce_in', shape=[None, 100], dtype='float32')\n    nce_label = paddle.static.data(name='nce_label', shape=[None, 10], dtype='int64')\n    nce_out_1 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    nce_out_2 = paddle.static.nn.nce(nce_in, nce_label, 10000)\n    prelu_in = paddle.static.data(name='prelu_in', shape=[None, 5, 10, 10], dtype='float32')\n    prelu_out_1 = paddle.static.nn.prelu(prelu_in, 'channel')\n    prelu_out_2 = paddle.static.nn.prelu(prelu_in, 'channel')\n    bilinear_tensor_pro_x = paddle.static.data('t1', shape=[None, 5], dtype='float32')\n    bilinear_tensor_pro_y = paddle.static.data('t2', shape=[None, 4], dtype='float32')\n    bilinear_tensor_pro_out_1 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    bilinear_tensor_pro_out_2 = paddle.static.nn.common.bilinear_tensor_product(x=bilinear_tensor_pro_x, y=bilinear_tensor_pro_y, size=1000)\n    conv2d_trans_in = paddle.static.data(name='conv2d_trans_in', shape=[None, 10, 10, 10])\n    conv2d_trans_out_1 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv2d_trans_out_2 = paddle.static.nn.conv2d_transpose(conv2d_trans_in, num_filters=10, filter_size=5, act='relu')\n    conv3d_trans_in = paddle.static.data(name='conv3d_trans_in', shape=[None, 3, 12, 32, 32], dtype='float32')\n    conv3d_trans_out_1 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    conv3d_trans_out_2 = paddle.static.nn.conv3d_transpose(input=conv3d_trans_in, num_filters=2, filter_size=3, act='relu')\n    groupnorm_in = paddle.static.data(name='groupnorm_in', shape=[None, 8, 32, 32], dtype='float32')\n    groupnorm_out1 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    groupnorm_out2 = paddle.static.nn.group_norm(input=groupnorm_in, groups=4, param_attr=True, bias_attr=True)\n    \"\\n        spec_norm = paddle.static.data(name='spec_norm', shape=[2, 8, 32, 32], dtype='float32')\\n        spe_norm_out_1 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        spe_norm_out_2 = paddle.static.nn.spectral_norm(weight=spec_norm, dim=1, power_iters=2)\\n        \"\n    para1 = paddle.create_parameter([100, 100], 'float32', name='weight_test_1')\n    para2 = paddle.create_parameter([20, 200], 'float32', name='weight_test_2')\n    para_list = base.default_main_program().list_vars()\n    exe = base.Executor(base.CPUPlace() if not base.is_compiled_with_cuda() else base.CUDAPlace(0))\n    out = exe.run(framework.default_startup_program())\n    paddle.static.save(framework.default_main_program(), os.path.join(temp_dir.name, 'test_1'))\n    para_dict = paddle.static.load_program_state(os.path.join(temp_dir.name, 'test_1'))\n    new_dict = {}\n    for (k, v) in para_dict.items():\n        if k.startswith('fc'):\n            name = k.replace('fc', 'linear', 1)\n            new_dict[name] = v\n        else:\n            new_dict[k] = v\n    with base.dygraph.guard():\n\n        class MyTest(paddle.nn.Layer):\n\n            def __init__(self):\n                super().__init__()\n                self.linear1 = Linear(10, 10)\n                self.lienar2 = Linear(10, 20)\n                self.conv2d_1 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv2d_2 = paddle.nn.Conv2D(in_channels=10, out_channels=10, kernel_size=5)\n                self.conv3d_1 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.conv3d_2 = paddle.nn.Conv3D(in_channels=3, out_channels=2, kernel_size=3)\n                self.batch_norm_1 = BatchNorm(10)\n                self.batch_norm_2 = BatchNorm(10)\n                self.emb1 = paddle.nn.Embedding(1000, 100)\n                self.emb2 = paddle.nn.Embedding(2000, 200)\n                self.layer_norm_1 = paddle.nn.LayerNorm([10])\n                self.layer_norm_2 = paddle.nn.LayerNorm(10)\n                self.group_norm1 = paddle.nn.GroupNorm(4, 8)\n                self.gourp_norm2 = paddle.nn.GroupNorm(4, 8)\n                self.w_1 = self.create_parameter([100, 100], dtype='float32', attr='weight_test_1')\n                self.w_2 = self.create_parameter([20, 200], dtype='float32', attr='weight_test_2')\n        my_test = MyTest()\n        my_test.set_dict(new_dict, use_structured_name=False)\n        for (k, v) in my_test.state_dict().items():\n            np.testing.assert_array_equal(v.numpy(), new_dict[v.name])\n    temp_dir.cleanup()"
        ]
    }
]