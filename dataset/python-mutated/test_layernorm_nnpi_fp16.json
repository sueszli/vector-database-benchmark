[
    {
        "func_name": "test_layernorm",
        "original": "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_layernorm(self, seed, batch_size, size, epsilon, elementwise_affine):\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormFakeFP16NNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchBlob('Y')\n    dims1 = np.array([1, *dims])\n    X_glow = X.reshape(dims1)\n    workspace.FeedBlob('X', X_glow)\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchBlob('Y')\n    if not np.allclose(Y_glow, Y_c2):\n        diff_Y = np.abs(Y_glow - Y_c2)\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
        "mutated": [
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_layernorm(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormFakeFP16NNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchBlob('Y')\n    dims1 = np.array([1, *dims])\n    X_glow = X.reshape(dims1)\n    workspace.FeedBlob('X', X_glow)\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchBlob('Y')\n    if not np.allclose(Y_glow, Y_c2):\n        diff_Y = np.abs(Y_glow - Y_c2)\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_layernorm(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormFakeFP16NNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchBlob('Y')\n    dims1 = np.array([1, *dims])\n    X_glow = X.reshape(dims1)\n    workspace.FeedBlob('X', X_glow)\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchBlob('Y')\n    if not np.allclose(Y_glow, Y_c2):\n        diff_Y = np.abs(Y_glow - Y_c2)\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_layernorm(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormFakeFP16NNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchBlob('Y')\n    dims1 = np.array([1, *dims])\n    X_glow = X.reshape(dims1)\n    workspace.FeedBlob('X', X_glow)\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchBlob('Y')\n    if not np.allclose(Y_glow, Y_c2):\n        diff_Y = np.abs(Y_glow - Y_c2)\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_layernorm(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormFakeFP16NNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchBlob('Y')\n    dims1 = np.array([1, *dims])\n    X_glow = X.reshape(dims1)\n    workspace.FeedBlob('X', X_glow)\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchBlob('Y')\n    if not np.allclose(Y_glow, Y_c2):\n        diff_Y = np.abs(Y_glow - Y_c2)\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_layernorm(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y', 'mean', 'rstd'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormFakeFP16NNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchBlob('Y')\n    dims1 = np.array([1, *dims])\n    X_glow = X.reshape(dims1)\n    workspace.FeedBlob('X', X_glow)\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchBlob('Y')\n    if not np.allclose(Y_glow, Y_c2):\n        diff_Y = np.abs(Y_glow - Y_c2)\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0"
        ]
    },
    {
        "func_name": "_get_scale_zp",
        "original": "def _get_scale_zp(self, tensor):\n    tensor_max = np.max(tensor)\n    tensor_min = min(0, np.min(tensor))\n    scale = np.float32(np.float16((tensor_max - tensor_min) / 255.0))\n    if scale < 1e-06:\n        scale = np.float32(1e-06)\n    zero_point = 0 - tensor_min / scale\n    zero_point = int(round(np.clip(zero_point, 0, 255.0)))\n    return (scale, zero_point)",
        "mutated": [
            "def _get_scale_zp(self, tensor):\n    if False:\n        i = 10\n    tensor_max = np.max(tensor)\n    tensor_min = min(0, np.min(tensor))\n    scale = np.float32(np.float16((tensor_max - tensor_min) / 255.0))\n    if scale < 1e-06:\n        scale = np.float32(1e-06)\n    zero_point = 0 - tensor_min / scale\n    zero_point = int(round(np.clip(zero_point, 0, 255.0)))\n    return (scale, zero_point)",
            "def _get_scale_zp(self, tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    tensor_max = np.max(tensor)\n    tensor_min = min(0, np.min(tensor))\n    scale = np.float32(np.float16((tensor_max - tensor_min) / 255.0))\n    if scale < 1e-06:\n        scale = np.float32(1e-06)\n    zero_point = 0 - tensor_min / scale\n    zero_point = int(round(np.clip(zero_point, 0, 255.0)))\n    return (scale, zero_point)",
            "def _get_scale_zp(self, tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    tensor_max = np.max(tensor)\n    tensor_min = min(0, np.min(tensor))\n    scale = np.float32(np.float16((tensor_max - tensor_min) / 255.0))\n    if scale < 1e-06:\n        scale = np.float32(1e-06)\n    zero_point = 0 - tensor_min / scale\n    zero_point = int(round(np.clip(zero_point, 0, 255.0)))\n    return (scale, zero_point)",
            "def _get_scale_zp(self, tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    tensor_max = np.max(tensor)\n    tensor_min = min(0, np.min(tensor))\n    scale = np.float32(np.float16((tensor_max - tensor_min) / 255.0))\n    if scale < 1e-06:\n        scale = np.float32(1e-06)\n    zero_point = 0 - tensor_min / scale\n    zero_point = int(round(np.clip(zero_point, 0, 255.0)))\n    return (scale, zero_point)",
            "def _get_scale_zp(self, tensor):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    tensor_max = np.max(tensor)\n    tensor_min = min(0, np.min(tensor))\n    scale = np.float32(np.float16((tensor_max - tensor_min) / 255.0))\n    if scale < 1e-06:\n        scale = np.float32(1e-06)\n    zero_point = 0 - tensor_min / scale\n    zero_point = int(round(np.clip(zero_point, 0, 255.0)))\n    return (scale, zero_point)"
        ]
    },
    {
        "func_name": "_layernorm_transform",
        "original": "def _layernorm_transform(self, X):\n    mean = np.mean(X, axis=1)\n    mean_exp = np.outer(mean, np.ones(X.shape[1]))\n    std = np.std(X, axis=1)\n    std_exp = np.outer(std, np.ones(X.shape[1]))\n    Y = (X - mean_exp) / std_exp\n    return Y",
        "mutated": [
            "def _layernorm_transform(self, X):\n    if False:\n        i = 10\n    mean = np.mean(X, axis=1)\n    mean_exp = np.outer(mean, np.ones(X.shape[1]))\n    std = np.std(X, axis=1)\n    std_exp = np.outer(std, np.ones(X.shape[1]))\n    Y = (X - mean_exp) / std_exp\n    return Y",
            "def _layernorm_transform(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    mean = np.mean(X, axis=1)\n    mean_exp = np.outer(mean, np.ones(X.shape[1]))\n    std = np.std(X, axis=1)\n    std_exp = np.outer(std, np.ones(X.shape[1]))\n    Y = (X - mean_exp) / std_exp\n    return Y",
            "def _layernorm_transform(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    mean = np.mean(X, axis=1)\n    mean_exp = np.outer(mean, np.ones(X.shape[1]))\n    std = np.std(X, axis=1)\n    std_exp = np.outer(std, np.ones(X.shape[1]))\n    Y = (X - mean_exp) / std_exp\n    return Y",
            "def _layernorm_transform(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    mean = np.mean(X, axis=1)\n    mean_exp = np.outer(mean, np.ones(X.shape[1]))\n    std = np.std(X, axis=1)\n    std_exp = np.outer(std, np.ones(X.shape[1]))\n    Y = (X - mean_exp) / std_exp\n    return Y",
            "def _layernorm_transform(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    mean = np.mean(X, axis=1)\n    mean_exp = np.outer(mean, np.ones(X.shape[1]))\n    std = np.std(X, axis=1)\n    std_exp = np.outer(std, np.ones(X.shape[1]))\n    Y = (X - mean_exp) / std_exp\n    return Y"
        ]
    },
    {
        "func_name": "test_fused_ln_quantize",
        "original": "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_fused_ln_quantize(self, seed, batch_size, size, epsilon, elementwise_affine):\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    Y = self._layernorm_transform(X)\n    (scale, zp) = self._get_scale_zp(Y)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y_q'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net.op.add().CopyFrom(core.CreateOperator('Int8Quantize', ['Y'], ['Y_q'], Y_scale=scale, Y_zero_point=zp))\n    print(pred_net)\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y_q'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormInt8QuantizeFakeNNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y_q', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine, Y_scale=scale, Y_zero_point=zp))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchInt8Blob('Y_q')\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchInt8Blob('Y_q')\n    if not np.allclose(Y_glow.data, Y_c2.data) or Y_glow.scale != Y_c2.scale or Y_glow.zero_point != Y_c2.zero_point:\n        diff_Y = np.abs(Y_glow.data.astype(np.float32) - Y_c2.data.astype(np.float32))\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
        "mutated": [
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_fused_ln_quantize(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    Y = self._layernorm_transform(X)\n    (scale, zp) = self._get_scale_zp(Y)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y_q'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net.op.add().CopyFrom(core.CreateOperator('Int8Quantize', ['Y'], ['Y_q'], Y_scale=scale, Y_zero_point=zp))\n    print(pred_net)\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y_q'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormInt8QuantizeFakeNNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y_q', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine, Y_scale=scale, Y_zero_point=zp))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchInt8Blob('Y_q')\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchInt8Blob('Y_q')\n    if not np.allclose(Y_glow.data, Y_c2.data) or Y_glow.scale != Y_c2.scale or Y_glow.zero_point != Y_c2.zero_point:\n        diff_Y = np.abs(Y_glow.data.astype(np.float32) - Y_c2.data.astype(np.float32))\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_fused_ln_quantize(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    Y = self._layernorm_transform(X)\n    (scale, zp) = self._get_scale_zp(Y)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y_q'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net.op.add().CopyFrom(core.CreateOperator('Int8Quantize', ['Y'], ['Y_q'], Y_scale=scale, Y_zero_point=zp))\n    print(pred_net)\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y_q'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormInt8QuantizeFakeNNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y_q', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine, Y_scale=scale, Y_zero_point=zp))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchInt8Blob('Y_q')\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchInt8Blob('Y_q')\n    if not np.allclose(Y_glow.data, Y_c2.data) or Y_glow.scale != Y_c2.scale or Y_glow.zero_point != Y_c2.zero_point:\n        diff_Y = np.abs(Y_glow.data.astype(np.float32) - Y_c2.data.astype(np.float32))\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_fused_ln_quantize(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    Y = self._layernorm_transform(X)\n    (scale, zp) = self._get_scale_zp(Y)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y_q'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net.op.add().CopyFrom(core.CreateOperator('Int8Quantize', ['Y'], ['Y_q'], Y_scale=scale, Y_zero_point=zp))\n    print(pred_net)\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y_q'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormInt8QuantizeFakeNNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y_q', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine, Y_scale=scale, Y_zero_point=zp))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchInt8Blob('Y_q')\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchInt8Blob('Y_q')\n    if not np.allclose(Y_glow.data, Y_c2.data) or Y_glow.scale != Y_c2.scale or Y_glow.zero_point != Y_c2.zero_point:\n        diff_Y = np.abs(Y_glow.data.astype(np.float32) - Y_c2.data.astype(np.float32))\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_fused_ln_quantize(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    Y = self._layernorm_transform(X)\n    (scale, zp) = self._get_scale_zp(Y)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y_q'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net.op.add().CopyFrom(core.CreateOperator('Int8Quantize', ['Y'], ['Y_q'], Y_scale=scale, Y_zero_point=zp))\n    print(pred_net)\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y_q'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormInt8QuantizeFakeNNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y_q', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine, Y_scale=scale, Y_zero_point=zp))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchInt8Blob('Y_q')\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchInt8Blob('Y_q')\n    if not np.allclose(Y_glow.data, Y_c2.data) or Y_glow.scale != Y_c2.scale or Y_glow.zero_point != Y_c2.zero_point:\n        diff_Y = np.abs(Y_glow.data.astype(np.float32) - Y_c2.data.astype(np.float32))\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0",
            "@given(seed=st.integers(0, 65535), batch_size=st.integers(min_value=1, max_value=50), size=st.integers(min_value=2, max_value=128), epsilon=st.floats(min_value=0.0001, max_value=0.001), elementwise_affine=st.booleans())\n@settings(deadline=datetime.timedelta(seconds=10))\ndef test_fused_ln_quantize(self, seed, batch_size, size, epsilon, elementwise_affine):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np.random.seed(seed)\n    workspace.ResetWorkspace()\n    axis = 1\n    dims = np.array([batch_size, size])\n    X = np.random.uniform(size=dims).astype(np.float32) - 0.5\n    gamma = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    beta = np.random.randn(*X.shape[axis:]).astype(np.float32)\n    Y = self._layernorm_transform(X)\n    (scale, zp) = self._get_scale_zp(Y)\n    pred_net = caffe2_pb2.NetDef()\n    pred_net.name = 'pred'\n    pred_net.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net.external_output.extend(['Y_q'])\n    pred_net.op.add().CopyFrom(core.CreateOperator('LayerNorm', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine))\n    pred_net.op.add().CopyFrom(core.CreateOperator('Int8Quantize', ['Y'], ['Y_q'], Y_scale=scale, Y_zero_point=zp))\n    print(pred_net)\n    pred_net_ref = caffe2_pb2.NetDef()\n    pred_net_ref.name = 'pred_ref'\n    pred_net_ref.external_input.extend(['X', 'gamma', 'beta'])\n    pred_net_ref.external_output.extend(['Y_q'])\n    pred_net_ref.op.add().CopyFrom(core.CreateOperator('LayerNormInt8QuantizeFakeNNPI', ['X', 'gamma', 'beta'] if elementwise_affine else ['X'], ['Y_q', 'mean', 'rstd'], axis=axis, epsilon=epsilon, elementwise_affine=elementwise_affine, Y_scale=scale, Y_zero_point=zp))\n    shape_hits = {'X': X.shape, 'gamma': gamma.shape, 'beta': beta.shape}\n    pred_net_onnxified = onnxifi_caffe2_net(pred_net, shape_hits, debug=True, adjust_batch=True, use_onnx=False)\n    num_onnxified_ops = sum((1 if o.type == 'Onnxifi' else 0 for o in pred_net_onnxified.op))\n    np.testing.assert_equal(num_onnxified_ops, 1)\n    workspace.FeedBlob('X', X)\n    workspace.FeedBlob('gamma', gamma)\n    workspace.FeedBlob('beta', beta)\n    workspace.CreateNet(pred_net_ref)\n    workspace.CreateNet(pred_net_onnxified)\n    workspace.RunNet(pred_net_ref.name)\n    Y_c2 = workspace.FetchInt8Blob('Y_q')\n    workspace.RunNet(pred_net_onnxified.name)\n    Y_glow = workspace.FetchInt8Blob('Y_q')\n    if not np.allclose(Y_glow.data, Y_c2.data) or Y_glow.scale != Y_c2.scale or Y_glow.zero_point != Y_c2.zero_point:\n        diff_Y = np.abs(Y_glow.data.astype(np.float32) - Y_c2.data.astype(np.float32))\n        print_test_debug_info('layernorm', {'seed': seed, 'size': size, 'batch_size': batch_size, 'epsilon': epsilon, 'gamma': gamma, 'beta': beta, 'elementwise_affine': elementwise_affine, 'X': X, 'Y_glow': Y_glow, 'Y_c2': Y_c2, 'diff_Y': diff_Y})\n        assert 0"
        ]
    }
]