[
    {
        "func_name": "__init__",
        "original": "def __init__(self, m1, m2):\n    W = init_weights((m1, m2))\n    bi = np.zeros(m2, dtype=np.float32)\n    bo = np.zeros(m1, dtype=np.float32)\n    self.W = theano.shared(W)\n    self.bi = theano.shared(bi)\n    self.bo = theano.shared(bo)\n    self.params = [self.W, self.bi, self.bo]",
        "mutated": [
            "def __init__(self, m1, m2):\n    if False:\n        i = 10\n    W = init_weights((m1, m2))\n    bi = np.zeros(m2, dtype=np.float32)\n    bo = np.zeros(m1, dtype=np.float32)\n    self.W = theano.shared(W)\n    self.bi = theano.shared(bi)\n    self.bo = theano.shared(bo)\n    self.params = [self.W, self.bi, self.bo]",
            "def __init__(self, m1, m2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    W = init_weights((m1, m2))\n    bi = np.zeros(m2, dtype=np.float32)\n    bo = np.zeros(m1, dtype=np.float32)\n    self.W = theano.shared(W)\n    self.bi = theano.shared(bi)\n    self.bo = theano.shared(bo)\n    self.params = [self.W, self.bi, self.bo]",
            "def __init__(self, m1, m2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    W = init_weights((m1, m2))\n    bi = np.zeros(m2, dtype=np.float32)\n    bo = np.zeros(m1, dtype=np.float32)\n    self.W = theano.shared(W)\n    self.bi = theano.shared(bi)\n    self.bo = theano.shared(bo)\n    self.params = [self.W, self.bi, self.bo]",
            "def __init__(self, m1, m2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    W = init_weights((m1, m2))\n    bi = np.zeros(m2, dtype=np.float32)\n    bo = np.zeros(m1, dtype=np.float32)\n    self.W = theano.shared(W)\n    self.bi = theano.shared(bi)\n    self.bo = theano.shared(bo)\n    self.params = [self.W, self.bi, self.bo]",
            "def __init__(self, m1, m2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    W = init_weights((m1, m2))\n    bi = np.zeros(m2, dtype=np.float32)\n    bo = np.zeros(m1, dtype=np.float32)\n    self.W = theano.shared(W)\n    self.bi = theano.shared(bi)\n    self.bo = theano.shared(bo)\n    self.params = [self.W, self.bi, self.bo]"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, X):\n    return T.nnet.sigmoid(X.dot(self.W) + self.bi)",
        "mutated": [
            "def forward(self, X):\n    if False:\n        i = 10\n    return T.nnet.sigmoid(X.dot(self.W) + self.bi)",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return T.nnet.sigmoid(X.dot(self.W) + self.bi)",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return T.nnet.sigmoid(X.dot(self.W) + self.bi)",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return T.nnet.sigmoid(X.dot(self.W) + self.bi)",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return T.nnet.sigmoid(X.dot(self.W) + self.bi)"
        ]
    },
    {
        "func_name": "forwardT",
        "original": "def forwardT(self, X):\n    return T.nnet.sigmoid(X.dot(self.W.T) + self.bo)",
        "mutated": [
            "def forwardT(self, X):\n    if False:\n        i = 10\n    return T.nnet.sigmoid(X.dot(self.W.T) + self.bo)",
            "def forwardT(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return T.nnet.sigmoid(X.dot(self.W.T) + self.bo)",
            "def forwardT(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return T.nnet.sigmoid(X.dot(self.W.T) + self.bo)",
            "def forwardT(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return T.nnet.sigmoid(X.dot(self.W.T) + self.bo)",
            "def forwardT(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return T.nnet.sigmoid(X.dot(self.W.T) + self.bo)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, hidden_layer_sizes):\n    self.hidden_layer_sizes = hidden_layer_sizes",
        "mutated": [
            "def __init__(self, hidden_layer_sizes):\n    if False:\n        i = 10\n    self.hidden_layer_sizes = hidden_layer_sizes",
            "def __init__(self, hidden_layer_sizes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.hidden_layer_sizes = hidden_layer_sizes",
            "def __init__(self, hidden_layer_sizes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.hidden_layer_sizes = hidden_layer_sizes",
            "def __init__(self, hidden_layer_sizes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.hidden_layer_sizes = hidden_layer_sizes",
            "def __init__(self, hidden_layer_sizes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.hidden_layer_sizes = hidden_layer_sizes"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, X, learning_rate=0.5, mu=0.99, epochs=50, batch_sz=100, show_fig=False):\n    learning_rate = np.float32(learning_rate)\n    mu = np.float32(mu)\n    (N, D) = X.shape\n    n_batches = N // batch_sz\n    mi = D\n    self.layers = []\n    self.params = []\n    for mo in self.hidden_layer_sizes:\n        layer = Layer(mi, mo)\n        self.layers.append(layer)\n        self.params += layer.params\n        mi = mo\n    X_in = T.matrix('X')\n    X_hat = self.forward(X_in)\n    cost = -(X_in * T.log(X_hat) + (1 - X_in) * T.log(1 - X_hat)).mean()\n    cost_op = theano.function(inputs=[X_in], outputs=cost)\n    updates = momentum_updates(cost, self.params, mu, learning_rate)\n    train_op = theano.function(inputs=[X_in], outputs=cost, updates=updates)\n    costs = []\n    for i in range(epochs):\n        print('epoch:', i)\n        X = shuffle(X)\n        for j in range(n_batches):\n            batch = X[j * batch_sz:j * batch_sz + batch_sz]\n            c = train_op(batch)\n            if j % 100 == 0:\n                print('j / n_batches:', j, '/', n_batches, 'cost:', c)\n            costs.append(c)\n    if show_fig:\n        plt.plot(costs)\n        plt.show()",
        "mutated": [
            "def fit(self, X, learning_rate=0.5, mu=0.99, epochs=50, batch_sz=100, show_fig=False):\n    if False:\n        i = 10\n    learning_rate = np.float32(learning_rate)\n    mu = np.float32(mu)\n    (N, D) = X.shape\n    n_batches = N // batch_sz\n    mi = D\n    self.layers = []\n    self.params = []\n    for mo in self.hidden_layer_sizes:\n        layer = Layer(mi, mo)\n        self.layers.append(layer)\n        self.params += layer.params\n        mi = mo\n    X_in = T.matrix('X')\n    X_hat = self.forward(X_in)\n    cost = -(X_in * T.log(X_hat) + (1 - X_in) * T.log(1 - X_hat)).mean()\n    cost_op = theano.function(inputs=[X_in], outputs=cost)\n    updates = momentum_updates(cost, self.params, mu, learning_rate)\n    train_op = theano.function(inputs=[X_in], outputs=cost, updates=updates)\n    costs = []\n    for i in range(epochs):\n        print('epoch:', i)\n        X = shuffle(X)\n        for j in range(n_batches):\n            batch = X[j * batch_sz:j * batch_sz + batch_sz]\n            c = train_op(batch)\n            if j % 100 == 0:\n                print('j / n_batches:', j, '/', n_batches, 'cost:', c)\n            costs.append(c)\n    if show_fig:\n        plt.plot(costs)\n        plt.show()",
            "def fit(self, X, learning_rate=0.5, mu=0.99, epochs=50, batch_sz=100, show_fig=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    learning_rate = np.float32(learning_rate)\n    mu = np.float32(mu)\n    (N, D) = X.shape\n    n_batches = N // batch_sz\n    mi = D\n    self.layers = []\n    self.params = []\n    for mo in self.hidden_layer_sizes:\n        layer = Layer(mi, mo)\n        self.layers.append(layer)\n        self.params += layer.params\n        mi = mo\n    X_in = T.matrix('X')\n    X_hat = self.forward(X_in)\n    cost = -(X_in * T.log(X_hat) + (1 - X_in) * T.log(1 - X_hat)).mean()\n    cost_op = theano.function(inputs=[X_in], outputs=cost)\n    updates = momentum_updates(cost, self.params, mu, learning_rate)\n    train_op = theano.function(inputs=[X_in], outputs=cost, updates=updates)\n    costs = []\n    for i in range(epochs):\n        print('epoch:', i)\n        X = shuffle(X)\n        for j in range(n_batches):\n            batch = X[j * batch_sz:j * batch_sz + batch_sz]\n            c = train_op(batch)\n            if j % 100 == 0:\n                print('j / n_batches:', j, '/', n_batches, 'cost:', c)\n            costs.append(c)\n    if show_fig:\n        plt.plot(costs)\n        plt.show()",
            "def fit(self, X, learning_rate=0.5, mu=0.99, epochs=50, batch_sz=100, show_fig=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    learning_rate = np.float32(learning_rate)\n    mu = np.float32(mu)\n    (N, D) = X.shape\n    n_batches = N // batch_sz\n    mi = D\n    self.layers = []\n    self.params = []\n    for mo in self.hidden_layer_sizes:\n        layer = Layer(mi, mo)\n        self.layers.append(layer)\n        self.params += layer.params\n        mi = mo\n    X_in = T.matrix('X')\n    X_hat = self.forward(X_in)\n    cost = -(X_in * T.log(X_hat) + (1 - X_in) * T.log(1 - X_hat)).mean()\n    cost_op = theano.function(inputs=[X_in], outputs=cost)\n    updates = momentum_updates(cost, self.params, mu, learning_rate)\n    train_op = theano.function(inputs=[X_in], outputs=cost, updates=updates)\n    costs = []\n    for i in range(epochs):\n        print('epoch:', i)\n        X = shuffle(X)\n        for j in range(n_batches):\n            batch = X[j * batch_sz:j * batch_sz + batch_sz]\n            c = train_op(batch)\n            if j % 100 == 0:\n                print('j / n_batches:', j, '/', n_batches, 'cost:', c)\n            costs.append(c)\n    if show_fig:\n        plt.plot(costs)\n        plt.show()",
            "def fit(self, X, learning_rate=0.5, mu=0.99, epochs=50, batch_sz=100, show_fig=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    learning_rate = np.float32(learning_rate)\n    mu = np.float32(mu)\n    (N, D) = X.shape\n    n_batches = N // batch_sz\n    mi = D\n    self.layers = []\n    self.params = []\n    for mo in self.hidden_layer_sizes:\n        layer = Layer(mi, mo)\n        self.layers.append(layer)\n        self.params += layer.params\n        mi = mo\n    X_in = T.matrix('X')\n    X_hat = self.forward(X_in)\n    cost = -(X_in * T.log(X_hat) + (1 - X_in) * T.log(1 - X_hat)).mean()\n    cost_op = theano.function(inputs=[X_in], outputs=cost)\n    updates = momentum_updates(cost, self.params, mu, learning_rate)\n    train_op = theano.function(inputs=[X_in], outputs=cost, updates=updates)\n    costs = []\n    for i in range(epochs):\n        print('epoch:', i)\n        X = shuffle(X)\n        for j in range(n_batches):\n            batch = X[j * batch_sz:j * batch_sz + batch_sz]\n            c = train_op(batch)\n            if j % 100 == 0:\n                print('j / n_batches:', j, '/', n_batches, 'cost:', c)\n            costs.append(c)\n    if show_fig:\n        plt.plot(costs)\n        plt.show()",
            "def fit(self, X, learning_rate=0.5, mu=0.99, epochs=50, batch_sz=100, show_fig=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    learning_rate = np.float32(learning_rate)\n    mu = np.float32(mu)\n    (N, D) = X.shape\n    n_batches = N // batch_sz\n    mi = D\n    self.layers = []\n    self.params = []\n    for mo in self.hidden_layer_sizes:\n        layer = Layer(mi, mo)\n        self.layers.append(layer)\n        self.params += layer.params\n        mi = mo\n    X_in = T.matrix('X')\n    X_hat = self.forward(X_in)\n    cost = -(X_in * T.log(X_hat) + (1 - X_in) * T.log(1 - X_hat)).mean()\n    cost_op = theano.function(inputs=[X_in], outputs=cost)\n    updates = momentum_updates(cost, self.params, mu, learning_rate)\n    train_op = theano.function(inputs=[X_in], outputs=cost, updates=updates)\n    costs = []\n    for i in range(epochs):\n        print('epoch:', i)\n        X = shuffle(X)\n        for j in range(n_batches):\n            batch = X[j * batch_sz:j * batch_sz + batch_sz]\n            c = train_op(batch)\n            if j % 100 == 0:\n                print('j / n_batches:', j, '/', n_batches, 'cost:', c)\n            costs.append(c)\n    if show_fig:\n        plt.plot(costs)\n        plt.show()"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, X):\n    Z = X\n    for layer in self.layers:\n        Z = layer.forward(Z)\n    self.map2center = theano.function(inputs=[X], outputs=Z)\n    for i in range(len(self.layers) - 1, -1, -1):\n        Z = self.layers[i].forwardT(Z)\n    return Z",
        "mutated": [
            "def forward(self, X):\n    if False:\n        i = 10\n    Z = X\n    for layer in self.layers:\n        Z = layer.forward(Z)\n    self.map2center = theano.function(inputs=[X], outputs=Z)\n    for i in range(len(self.layers) - 1, -1, -1):\n        Z = self.layers[i].forwardT(Z)\n    return Z",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    Z = X\n    for layer in self.layers:\n        Z = layer.forward(Z)\n    self.map2center = theano.function(inputs=[X], outputs=Z)\n    for i in range(len(self.layers) - 1, -1, -1):\n        Z = self.layers[i].forwardT(Z)\n    return Z",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    Z = X\n    for layer in self.layers:\n        Z = layer.forward(Z)\n    self.map2center = theano.function(inputs=[X], outputs=Z)\n    for i in range(len(self.layers) - 1, -1, -1):\n        Z = self.layers[i].forwardT(Z)\n    return Z",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    Z = X\n    for layer in self.layers:\n        Z = layer.forward(Z)\n    self.map2center = theano.function(inputs=[X], outputs=Z)\n    for i in range(len(self.layers) - 1, -1, -1):\n        Z = self.layers[i].forwardT(Z)\n    return Z",
            "def forward(self, X):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    Z = X\n    for layer in self.layers:\n        Z = layer.forward(Z)\n    self.map2center = theano.function(inputs=[X], outputs=Z)\n    for i in range(len(self.layers) - 1, -1, -1):\n        Z = self.layers[i].forwardT(Z)\n    return Z"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    (Xtrain, Ytrain, Xtest, Ytest) = getKaggleMNIST()\n    dae = DeepAutoEncoder([500, 300, 2])\n    dae.fit(Xtrain)\n    mapping = dae.map2center(Xtrain)\n    plt.scatter(mapping[:, 0], mapping[:, 1], c=Ytrain, s=100, alpha=0.5)\n    plt.show()\n    gmm = GaussianMixture(n_components=10)\n    gmm.fit(Xtrain)\n    print('Finished GMM training')\n    responsibilities_full = gmm.predict_proba(Xtrain)\n    print('full purity:', purity(Ytrain, responsibilities_full))\n    gmm.fit(mapping)\n    responsibilities_reduced = gmm.predict_proba(mapping)\n    print('reduced purity:', purity(Ytrain, responsibilities_reduced))",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    (Xtrain, Ytrain, Xtest, Ytest) = getKaggleMNIST()\n    dae = DeepAutoEncoder([500, 300, 2])\n    dae.fit(Xtrain)\n    mapping = dae.map2center(Xtrain)\n    plt.scatter(mapping[:, 0], mapping[:, 1], c=Ytrain, s=100, alpha=0.5)\n    plt.show()\n    gmm = GaussianMixture(n_components=10)\n    gmm.fit(Xtrain)\n    print('Finished GMM training')\n    responsibilities_full = gmm.predict_proba(Xtrain)\n    print('full purity:', purity(Ytrain, responsibilities_full))\n    gmm.fit(mapping)\n    responsibilities_reduced = gmm.predict_proba(mapping)\n    print('reduced purity:', purity(Ytrain, responsibilities_reduced))",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (Xtrain, Ytrain, Xtest, Ytest) = getKaggleMNIST()\n    dae = DeepAutoEncoder([500, 300, 2])\n    dae.fit(Xtrain)\n    mapping = dae.map2center(Xtrain)\n    plt.scatter(mapping[:, 0], mapping[:, 1], c=Ytrain, s=100, alpha=0.5)\n    plt.show()\n    gmm = GaussianMixture(n_components=10)\n    gmm.fit(Xtrain)\n    print('Finished GMM training')\n    responsibilities_full = gmm.predict_proba(Xtrain)\n    print('full purity:', purity(Ytrain, responsibilities_full))\n    gmm.fit(mapping)\n    responsibilities_reduced = gmm.predict_proba(mapping)\n    print('reduced purity:', purity(Ytrain, responsibilities_reduced))",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (Xtrain, Ytrain, Xtest, Ytest) = getKaggleMNIST()\n    dae = DeepAutoEncoder([500, 300, 2])\n    dae.fit(Xtrain)\n    mapping = dae.map2center(Xtrain)\n    plt.scatter(mapping[:, 0], mapping[:, 1], c=Ytrain, s=100, alpha=0.5)\n    plt.show()\n    gmm = GaussianMixture(n_components=10)\n    gmm.fit(Xtrain)\n    print('Finished GMM training')\n    responsibilities_full = gmm.predict_proba(Xtrain)\n    print('full purity:', purity(Ytrain, responsibilities_full))\n    gmm.fit(mapping)\n    responsibilities_reduced = gmm.predict_proba(mapping)\n    print('reduced purity:', purity(Ytrain, responsibilities_reduced))",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (Xtrain, Ytrain, Xtest, Ytest) = getKaggleMNIST()\n    dae = DeepAutoEncoder([500, 300, 2])\n    dae.fit(Xtrain)\n    mapping = dae.map2center(Xtrain)\n    plt.scatter(mapping[:, 0], mapping[:, 1], c=Ytrain, s=100, alpha=0.5)\n    plt.show()\n    gmm = GaussianMixture(n_components=10)\n    gmm.fit(Xtrain)\n    print('Finished GMM training')\n    responsibilities_full = gmm.predict_proba(Xtrain)\n    print('full purity:', purity(Ytrain, responsibilities_full))\n    gmm.fit(mapping)\n    responsibilities_reduced = gmm.predict_proba(mapping)\n    print('reduced purity:', purity(Ytrain, responsibilities_reduced))",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (Xtrain, Ytrain, Xtest, Ytest) = getKaggleMNIST()\n    dae = DeepAutoEncoder([500, 300, 2])\n    dae.fit(Xtrain)\n    mapping = dae.map2center(Xtrain)\n    plt.scatter(mapping[:, 0], mapping[:, 1], c=Ytrain, s=100, alpha=0.5)\n    plt.show()\n    gmm = GaussianMixture(n_components=10)\n    gmm.fit(Xtrain)\n    print('Finished GMM training')\n    responsibilities_full = gmm.predict_proba(Xtrain)\n    print('full purity:', purity(Ytrain, responsibilities_full))\n    gmm.fit(mapping)\n    responsibilities_reduced = gmm.predict_proba(mapping)\n    print('reduced purity:', purity(Ytrain, responsibilities_reduced))"
        ]
    }
]