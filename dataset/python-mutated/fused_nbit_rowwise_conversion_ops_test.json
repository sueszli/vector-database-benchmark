[
    {
        "func_name": "bytes_to_half_floats",
        "original": "def bytes_to_half_floats(byte_matrix):\n    floats = np.empty([np.shape(byte_matrix)[0], 1], dtype=np.float16)\n    for (i, byte_values) in enumerate(byte_matrix):\n        (floats[i],) = np.frombuffer(memoryview(byte_values).tobytes(), dtype=np.float16)\n    return floats",
        "mutated": [
            "def bytes_to_half_floats(byte_matrix):\n    if False:\n        i = 10\n    floats = np.empty([np.shape(byte_matrix)[0], 1], dtype=np.float16)\n    for (i, byte_values) in enumerate(byte_matrix):\n        (floats[i],) = np.frombuffer(memoryview(byte_values).tobytes(), dtype=np.float16)\n    return floats",
            "def bytes_to_half_floats(byte_matrix):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    floats = np.empty([np.shape(byte_matrix)[0], 1], dtype=np.float16)\n    for (i, byte_values) in enumerate(byte_matrix):\n        (floats[i],) = np.frombuffer(memoryview(byte_values).tobytes(), dtype=np.float16)\n    return floats",
            "def bytes_to_half_floats(byte_matrix):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    floats = np.empty([np.shape(byte_matrix)[0], 1], dtype=np.float16)\n    for (i, byte_values) in enumerate(byte_matrix):\n        (floats[i],) = np.frombuffer(memoryview(byte_values).tobytes(), dtype=np.float16)\n    return floats",
            "def bytes_to_half_floats(byte_matrix):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    floats = np.empty([np.shape(byte_matrix)[0], 1], dtype=np.float16)\n    for (i, byte_values) in enumerate(byte_matrix):\n        (floats[i],) = np.frombuffer(memoryview(byte_values).tobytes(), dtype=np.float16)\n    return floats",
            "def bytes_to_half_floats(byte_matrix):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    floats = np.empty([np.shape(byte_matrix)[0], 1], dtype=np.float16)\n    for (i, byte_values) in enumerate(byte_matrix):\n        (floats[i],) = np.frombuffer(memoryview(byte_values).tobytes(), dtype=np.float16)\n    return floats"
        ]
    },
    {
        "func_name": "half_floats_to_bytes",
        "original": "def half_floats_to_bytes(floats):\n    byte_matrix = np.empty([np.shape(floats)[0], 2], dtype=np.uint8)\n    for (i, value) in enumerate(floats):\n        assert isinstance(value, np.float16), (value, floats)\n        byte_matrix[i] = np.frombuffer(memoryview(np.array([value])).tobytes(), dtype=np.uint8)\n    return byte_matrix",
        "mutated": [
            "def half_floats_to_bytes(floats):\n    if False:\n        i = 10\n    byte_matrix = np.empty([np.shape(floats)[0], 2], dtype=np.uint8)\n    for (i, value) in enumerate(floats):\n        assert isinstance(value, np.float16), (value, floats)\n        byte_matrix[i] = np.frombuffer(memoryview(np.array([value])).tobytes(), dtype=np.uint8)\n    return byte_matrix",
            "def half_floats_to_bytes(floats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    byte_matrix = np.empty([np.shape(floats)[0], 2], dtype=np.uint8)\n    for (i, value) in enumerate(floats):\n        assert isinstance(value, np.float16), (value, floats)\n        byte_matrix[i] = np.frombuffer(memoryview(np.array([value])).tobytes(), dtype=np.uint8)\n    return byte_matrix",
            "def half_floats_to_bytes(floats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    byte_matrix = np.empty([np.shape(floats)[0], 2], dtype=np.uint8)\n    for (i, value) in enumerate(floats):\n        assert isinstance(value, np.float16), (value, floats)\n        byte_matrix[i] = np.frombuffer(memoryview(np.array([value])).tobytes(), dtype=np.uint8)\n    return byte_matrix",
            "def half_floats_to_bytes(floats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    byte_matrix = np.empty([np.shape(floats)[0], 2], dtype=np.uint8)\n    for (i, value) in enumerate(floats):\n        assert isinstance(value, np.float16), (value, floats)\n        byte_matrix[i] = np.frombuffer(memoryview(np.array([value])).tobytes(), dtype=np.uint8)\n    return byte_matrix",
            "def half_floats_to_bytes(floats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    byte_matrix = np.empty([np.shape(floats)[0], 2], dtype=np.uint8)\n    for (i, value) in enumerate(floats):\n        assert isinstance(value, np.float16), (value, floats)\n        byte_matrix[i] = np.frombuffer(memoryview(np.array([value])).tobytes(), dtype=np.uint8)\n    return byte_matrix"
        ]
    },
    {
        "func_name": "int8_to_bytes",
        "original": "def int8_to_bytes(int8s):\n    byte_matrix = np.empty([np.shape(int8s)[0], 1], dtype=np.uint8)\n    for (i, value) in enumerate(int8s):\n        assert isinstance(value, np.int8), (value, int8s)\n        as_bytes = struct.pack('b', value)\n        if isinstance(as_bytes[0], int):\n            byte_matrix[i] = list(as_bytes)\n        else:\n            byte_matrix[i] = [ord(i) for i in as_bytes]\n    return byte_matrix",
        "mutated": [
            "def int8_to_bytes(int8s):\n    if False:\n        i = 10\n    byte_matrix = np.empty([np.shape(int8s)[0], 1], dtype=np.uint8)\n    for (i, value) in enumerate(int8s):\n        assert isinstance(value, np.int8), (value, int8s)\n        as_bytes = struct.pack('b', value)\n        if isinstance(as_bytes[0], int):\n            byte_matrix[i] = list(as_bytes)\n        else:\n            byte_matrix[i] = [ord(i) for i in as_bytes]\n    return byte_matrix",
            "def int8_to_bytes(int8s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    byte_matrix = np.empty([np.shape(int8s)[0], 1], dtype=np.uint8)\n    for (i, value) in enumerate(int8s):\n        assert isinstance(value, np.int8), (value, int8s)\n        as_bytes = struct.pack('b', value)\n        if isinstance(as_bytes[0], int):\n            byte_matrix[i] = list(as_bytes)\n        else:\n            byte_matrix[i] = [ord(i) for i in as_bytes]\n    return byte_matrix",
            "def int8_to_bytes(int8s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    byte_matrix = np.empty([np.shape(int8s)[0], 1], dtype=np.uint8)\n    for (i, value) in enumerate(int8s):\n        assert isinstance(value, np.int8), (value, int8s)\n        as_bytes = struct.pack('b', value)\n        if isinstance(as_bytes[0], int):\n            byte_matrix[i] = list(as_bytes)\n        else:\n            byte_matrix[i] = [ord(i) for i in as_bytes]\n    return byte_matrix",
            "def int8_to_bytes(int8s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    byte_matrix = np.empty([np.shape(int8s)[0], 1], dtype=np.uint8)\n    for (i, value) in enumerate(int8s):\n        assert isinstance(value, np.int8), (value, int8s)\n        as_bytes = struct.pack('b', value)\n        if isinstance(as_bytes[0], int):\n            byte_matrix[i] = list(as_bytes)\n        else:\n            byte_matrix[i] = [ord(i) for i in as_bytes]\n    return byte_matrix",
            "def int8_to_bytes(int8s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    byte_matrix = np.empty([np.shape(int8s)[0], 1], dtype=np.uint8)\n    for (i, value) in enumerate(int8s):\n        assert isinstance(value, np.int8), (value, int8s)\n        as_bytes = struct.pack('b', value)\n        if isinstance(as_bytes[0], int):\n            byte_matrix[i] = list(as_bytes)\n        else:\n            byte_matrix[i] = [ord(i) for i in as_bytes]\n    return byte_matrix"
        ]
    },
    {
        "func_name": "fused_rowwise_nbit_quantize_reference",
        "original": "def fused_rowwise_nbit_quantize_reference(data, bit):\n    minimum = np.min(data, axis=1).astype(np.float16).astype(np.float32)\n    maximum = np.max(data, axis=1)\n    span = maximum - minimum\n    qmax = (1 << bit) - 1\n    scale = (span / qmax).astype(np.float16).astype(np.float32)\n    bias = np.zeros(data.shape[0])\n    quantized_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        bias[i] = minimum[i]\n        inverse_scale = 1.0 if scale[i] == 0.0 else 1 / scale[i]\n        if scale[i] == 0.0 or math.isinf(inverse_scale):\n            scale[i] = 1.0\n            inverse_scale = 1.0\n        quantized_data[i] = np.clip(np.round((data[i, :] - minimum[i]) * inverse_scale), 0, qmax)\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    packed_dim = (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    packed_data = np.zeros([data.shape[0], packed_dim]).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            if j % num_elem_per_byte == 0:\n                packed_data[i, j // num_elem_per_byte] = quantized_data[i, j]\n            else:\n                packed_data[i, j // num_elem_per_byte] += quantized_data[i, j] << j % num_elem_per_byte * bit\n    scale_bytes = half_floats_to_bytes(scale.astype(np.float16))\n    bias_bytes = half_floats_to_bytes(bias.astype(np.float16))\n    return np.concatenate([packed_data, scale_bytes, bias_bytes], axis=1)",
        "mutated": [
            "def fused_rowwise_nbit_quantize_reference(data, bit):\n    if False:\n        i = 10\n    minimum = np.min(data, axis=1).astype(np.float16).astype(np.float32)\n    maximum = np.max(data, axis=1)\n    span = maximum - minimum\n    qmax = (1 << bit) - 1\n    scale = (span / qmax).astype(np.float16).astype(np.float32)\n    bias = np.zeros(data.shape[0])\n    quantized_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        bias[i] = minimum[i]\n        inverse_scale = 1.0 if scale[i] == 0.0 else 1 / scale[i]\n        if scale[i] == 0.0 or math.isinf(inverse_scale):\n            scale[i] = 1.0\n            inverse_scale = 1.0\n        quantized_data[i] = np.clip(np.round((data[i, :] - minimum[i]) * inverse_scale), 0, qmax)\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    packed_dim = (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    packed_data = np.zeros([data.shape[0], packed_dim]).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            if j % num_elem_per_byte == 0:\n                packed_data[i, j // num_elem_per_byte] = quantized_data[i, j]\n            else:\n                packed_data[i, j // num_elem_per_byte] += quantized_data[i, j] << j % num_elem_per_byte * bit\n    scale_bytes = half_floats_to_bytes(scale.astype(np.float16))\n    bias_bytes = half_floats_to_bytes(bias.astype(np.float16))\n    return np.concatenate([packed_data, scale_bytes, bias_bytes], axis=1)",
            "def fused_rowwise_nbit_quantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    minimum = np.min(data, axis=1).astype(np.float16).astype(np.float32)\n    maximum = np.max(data, axis=1)\n    span = maximum - minimum\n    qmax = (1 << bit) - 1\n    scale = (span / qmax).astype(np.float16).astype(np.float32)\n    bias = np.zeros(data.shape[0])\n    quantized_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        bias[i] = minimum[i]\n        inverse_scale = 1.0 if scale[i] == 0.0 else 1 / scale[i]\n        if scale[i] == 0.0 or math.isinf(inverse_scale):\n            scale[i] = 1.0\n            inverse_scale = 1.0\n        quantized_data[i] = np.clip(np.round((data[i, :] - minimum[i]) * inverse_scale), 0, qmax)\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    packed_dim = (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    packed_data = np.zeros([data.shape[0], packed_dim]).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            if j % num_elem_per_byte == 0:\n                packed_data[i, j // num_elem_per_byte] = quantized_data[i, j]\n            else:\n                packed_data[i, j // num_elem_per_byte] += quantized_data[i, j] << j % num_elem_per_byte * bit\n    scale_bytes = half_floats_to_bytes(scale.astype(np.float16))\n    bias_bytes = half_floats_to_bytes(bias.astype(np.float16))\n    return np.concatenate([packed_data, scale_bytes, bias_bytes], axis=1)",
            "def fused_rowwise_nbit_quantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    minimum = np.min(data, axis=1).astype(np.float16).astype(np.float32)\n    maximum = np.max(data, axis=1)\n    span = maximum - minimum\n    qmax = (1 << bit) - 1\n    scale = (span / qmax).astype(np.float16).astype(np.float32)\n    bias = np.zeros(data.shape[0])\n    quantized_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        bias[i] = minimum[i]\n        inverse_scale = 1.0 if scale[i] == 0.0 else 1 / scale[i]\n        if scale[i] == 0.0 or math.isinf(inverse_scale):\n            scale[i] = 1.0\n            inverse_scale = 1.0\n        quantized_data[i] = np.clip(np.round((data[i, :] - minimum[i]) * inverse_scale), 0, qmax)\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    packed_dim = (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    packed_data = np.zeros([data.shape[0], packed_dim]).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            if j % num_elem_per_byte == 0:\n                packed_data[i, j // num_elem_per_byte] = quantized_data[i, j]\n            else:\n                packed_data[i, j // num_elem_per_byte] += quantized_data[i, j] << j % num_elem_per_byte * bit\n    scale_bytes = half_floats_to_bytes(scale.astype(np.float16))\n    bias_bytes = half_floats_to_bytes(bias.astype(np.float16))\n    return np.concatenate([packed_data, scale_bytes, bias_bytes], axis=1)",
            "def fused_rowwise_nbit_quantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    minimum = np.min(data, axis=1).astype(np.float16).astype(np.float32)\n    maximum = np.max(data, axis=1)\n    span = maximum - minimum\n    qmax = (1 << bit) - 1\n    scale = (span / qmax).astype(np.float16).astype(np.float32)\n    bias = np.zeros(data.shape[0])\n    quantized_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        bias[i] = minimum[i]\n        inverse_scale = 1.0 if scale[i] == 0.0 else 1 / scale[i]\n        if scale[i] == 0.0 or math.isinf(inverse_scale):\n            scale[i] = 1.0\n            inverse_scale = 1.0\n        quantized_data[i] = np.clip(np.round((data[i, :] - minimum[i]) * inverse_scale), 0, qmax)\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    packed_dim = (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    packed_data = np.zeros([data.shape[0], packed_dim]).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            if j % num_elem_per_byte == 0:\n                packed_data[i, j // num_elem_per_byte] = quantized_data[i, j]\n            else:\n                packed_data[i, j // num_elem_per_byte] += quantized_data[i, j] << j % num_elem_per_byte * bit\n    scale_bytes = half_floats_to_bytes(scale.astype(np.float16))\n    bias_bytes = half_floats_to_bytes(bias.astype(np.float16))\n    return np.concatenate([packed_data, scale_bytes, bias_bytes], axis=1)",
            "def fused_rowwise_nbit_quantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    minimum = np.min(data, axis=1).astype(np.float16).astype(np.float32)\n    maximum = np.max(data, axis=1)\n    span = maximum - minimum\n    qmax = (1 << bit) - 1\n    scale = (span / qmax).astype(np.float16).astype(np.float32)\n    bias = np.zeros(data.shape[0])\n    quantized_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        bias[i] = minimum[i]\n        inverse_scale = 1.0 if scale[i] == 0.0 else 1 / scale[i]\n        if scale[i] == 0.0 or math.isinf(inverse_scale):\n            scale[i] = 1.0\n            inverse_scale = 1.0\n        quantized_data[i] = np.clip(np.round((data[i, :] - minimum[i]) * inverse_scale), 0, qmax)\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    packed_dim = (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    packed_data = np.zeros([data.shape[0], packed_dim]).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            if j % num_elem_per_byte == 0:\n                packed_data[i, j // num_elem_per_byte] = quantized_data[i, j]\n            else:\n                packed_data[i, j // num_elem_per_byte] += quantized_data[i, j] << j % num_elem_per_byte * bit\n    scale_bytes = half_floats_to_bytes(scale.astype(np.float16))\n    bias_bytes = half_floats_to_bytes(bias.astype(np.float16))\n    return np.concatenate([packed_data, scale_bytes, bias_bytes], axis=1)"
        ]
    },
    {
        "func_name": "fused_rowwise_nbit_quantize_dequantize_reference",
        "original": "def fused_rowwise_nbit_quantize_dequantize_reference(data, bit):\n    fused_quantized = fused_rowwise_nbit_quantize_reference(data, bit)\n    scale = bytes_to_half_floats(fused_quantized[:, -4:-2].astype(np.uint8)).astype(np.float32)\n    bias = bytes_to_half_floats(fused_quantized[:, -2:].astype(np.uint8)).astype(np.float32)\n    quantized_data = fused_quantized[:, :-4]\n    packed_dim = fused_quantized.shape[1] - 4\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    assert packed_dim == (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    unpacked_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            unpacked_data[i, j] = quantized_data[i, j // num_elem_per_byte] >> j % num_elem_per_byte * bit & (1 << bit) - 1\n    return scale * unpacked_data + bias",
        "mutated": [
            "def fused_rowwise_nbit_quantize_dequantize_reference(data, bit):\n    if False:\n        i = 10\n    fused_quantized = fused_rowwise_nbit_quantize_reference(data, bit)\n    scale = bytes_to_half_floats(fused_quantized[:, -4:-2].astype(np.uint8)).astype(np.float32)\n    bias = bytes_to_half_floats(fused_quantized[:, -2:].astype(np.uint8)).astype(np.float32)\n    quantized_data = fused_quantized[:, :-4]\n    packed_dim = fused_quantized.shape[1] - 4\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    assert packed_dim == (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    unpacked_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            unpacked_data[i, j] = quantized_data[i, j // num_elem_per_byte] >> j % num_elem_per_byte * bit & (1 << bit) - 1\n    return scale * unpacked_data + bias",
            "def fused_rowwise_nbit_quantize_dequantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    fused_quantized = fused_rowwise_nbit_quantize_reference(data, bit)\n    scale = bytes_to_half_floats(fused_quantized[:, -4:-2].astype(np.uint8)).astype(np.float32)\n    bias = bytes_to_half_floats(fused_quantized[:, -2:].astype(np.uint8)).astype(np.float32)\n    quantized_data = fused_quantized[:, :-4]\n    packed_dim = fused_quantized.shape[1] - 4\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    assert packed_dim == (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    unpacked_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            unpacked_data[i, j] = quantized_data[i, j // num_elem_per_byte] >> j % num_elem_per_byte * bit & (1 << bit) - 1\n    return scale * unpacked_data + bias",
            "def fused_rowwise_nbit_quantize_dequantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    fused_quantized = fused_rowwise_nbit_quantize_reference(data, bit)\n    scale = bytes_to_half_floats(fused_quantized[:, -4:-2].astype(np.uint8)).astype(np.float32)\n    bias = bytes_to_half_floats(fused_quantized[:, -2:].astype(np.uint8)).astype(np.float32)\n    quantized_data = fused_quantized[:, :-4]\n    packed_dim = fused_quantized.shape[1] - 4\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    assert packed_dim == (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    unpacked_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            unpacked_data[i, j] = quantized_data[i, j // num_elem_per_byte] >> j % num_elem_per_byte * bit & (1 << bit) - 1\n    return scale * unpacked_data + bias",
            "def fused_rowwise_nbit_quantize_dequantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    fused_quantized = fused_rowwise_nbit_quantize_reference(data, bit)\n    scale = bytes_to_half_floats(fused_quantized[:, -4:-2].astype(np.uint8)).astype(np.float32)\n    bias = bytes_to_half_floats(fused_quantized[:, -2:].astype(np.uint8)).astype(np.float32)\n    quantized_data = fused_quantized[:, :-4]\n    packed_dim = fused_quantized.shape[1] - 4\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    assert packed_dim == (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    unpacked_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            unpacked_data[i, j] = quantized_data[i, j // num_elem_per_byte] >> j % num_elem_per_byte * bit & (1 << bit) - 1\n    return scale * unpacked_data + bias",
            "def fused_rowwise_nbit_quantize_dequantize_reference(data, bit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    fused_quantized = fused_rowwise_nbit_quantize_reference(data, bit)\n    scale = bytes_to_half_floats(fused_quantized[:, -4:-2].astype(np.uint8)).astype(np.float32)\n    bias = bytes_to_half_floats(fused_quantized[:, -2:].astype(np.uint8)).astype(np.float32)\n    quantized_data = fused_quantized[:, :-4]\n    packed_dim = fused_quantized.shape[1] - 4\n    assert 8 % bit == 0\n    num_elem_per_byte = 8 // bit\n    assert packed_dim == (data.shape[1] + num_elem_per_byte - 1) // num_elem_per_byte\n    unpacked_data = np.zeros(data.shape).astype(np.uint8)\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            unpacked_data[i, j] = quantized_data[i, j // num_elem_per_byte] >> j % num_elem_per_byte * bit & (1 << bit) - 1\n    return scale * unpacked_data + bias"
        ]
    },
    {
        "func_name": "test_quantize_op",
        "original": "@given(input_data=hu.tensor(min_dim=2, max_dim=2), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_op(self, input_data, bit_rate):\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    reference = fused_rowwise_nbit_quantize_reference(input_data.astype(np.float32), bit_rate)\n    interleaved_dim = input_data.shape[1] // num_elem_per_byte\n    np.testing.assert_array_equal(quantized_data[:, :interleaved_dim], reference[:, :interleaved_dim])\n    np.testing.assert_array_almost_equal(bytes_to_half_floats(quantized_data[:, interleaved_dim:interleaved_dim + 2]), bytes_to_half_floats(reference[:, interleaved_dim:interleaved_dim + 2]))\n    np.testing.assert_array_equal(quantized_data[:, interleaved_dim + 2], reference[:, interleaved_dim + 2])",
        "mutated": [
            "@given(input_data=hu.tensor(min_dim=2, max_dim=2), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_op(self, input_data, bit_rate):\n    if False:\n        i = 10\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    reference = fused_rowwise_nbit_quantize_reference(input_data.astype(np.float32), bit_rate)\n    interleaved_dim = input_data.shape[1] // num_elem_per_byte\n    np.testing.assert_array_equal(quantized_data[:, :interleaved_dim], reference[:, :interleaved_dim])\n    np.testing.assert_array_almost_equal(bytes_to_half_floats(quantized_data[:, interleaved_dim:interleaved_dim + 2]), bytes_to_half_floats(reference[:, interleaved_dim:interleaved_dim + 2]))\n    np.testing.assert_array_equal(quantized_data[:, interleaved_dim + 2], reference[:, interleaved_dim + 2])",
            "@given(input_data=hu.tensor(min_dim=2, max_dim=2), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_op(self, input_data, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    reference = fused_rowwise_nbit_quantize_reference(input_data.astype(np.float32), bit_rate)\n    interleaved_dim = input_data.shape[1] // num_elem_per_byte\n    np.testing.assert_array_equal(quantized_data[:, :interleaved_dim], reference[:, :interleaved_dim])\n    np.testing.assert_array_almost_equal(bytes_to_half_floats(quantized_data[:, interleaved_dim:interleaved_dim + 2]), bytes_to_half_floats(reference[:, interleaved_dim:interleaved_dim + 2]))\n    np.testing.assert_array_equal(quantized_data[:, interleaved_dim + 2], reference[:, interleaved_dim + 2])",
            "@given(input_data=hu.tensor(min_dim=2, max_dim=2), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_op(self, input_data, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    reference = fused_rowwise_nbit_quantize_reference(input_data.astype(np.float32), bit_rate)\n    interleaved_dim = input_data.shape[1] // num_elem_per_byte\n    np.testing.assert_array_equal(quantized_data[:, :interleaved_dim], reference[:, :interleaved_dim])\n    np.testing.assert_array_almost_equal(bytes_to_half_floats(quantized_data[:, interleaved_dim:interleaved_dim + 2]), bytes_to_half_floats(reference[:, interleaved_dim:interleaved_dim + 2]))\n    np.testing.assert_array_equal(quantized_data[:, interleaved_dim + 2], reference[:, interleaved_dim + 2])",
            "@given(input_data=hu.tensor(min_dim=2, max_dim=2), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_op(self, input_data, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    reference = fused_rowwise_nbit_quantize_reference(input_data.astype(np.float32), bit_rate)\n    interleaved_dim = input_data.shape[1] // num_elem_per_byte\n    np.testing.assert_array_equal(quantized_data[:, :interleaved_dim], reference[:, :interleaved_dim])\n    np.testing.assert_array_almost_equal(bytes_to_half_floats(quantized_data[:, interleaved_dim:interleaved_dim + 2]), bytes_to_half_floats(reference[:, interleaved_dim:interleaved_dim + 2]))\n    np.testing.assert_array_equal(quantized_data[:, interleaved_dim + 2], reference[:, interleaved_dim + 2])",
            "@given(input_data=hu.tensor(min_dim=2, max_dim=2), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_op(self, input_data, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    reference = fused_rowwise_nbit_quantize_reference(input_data.astype(np.float32), bit_rate)\n    interleaved_dim = input_data.shape[1] // num_elem_per_byte\n    np.testing.assert_array_equal(quantized_data[:, :interleaved_dim], reference[:, :interleaved_dim])\n    np.testing.assert_array_almost_equal(bytes_to_half_floats(quantized_data[:, interleaved_dim:interleaved_dim + 2]), bytes_to_half_floats(reference[:, interleaved_dim:interleaved_dim + 2]))\n    np.testing.assert_array_equal(quantized_data[:, interleaved_dim + 2], reference[:, interleaved_dim + 2])"
        ]
    },
    {
        "func_name": "test_quantize_and_dequantize_op",
        "original": "@given(batch_size=st.integers(1, 100), block_size=st.integers(1, 100), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_and_dequantize_op(self, batch_size, block_size, bit_rate):\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    input_data = np.random.rand(batch_size, block_size).astype(np.float32)\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    dequantize = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', ['quantized_data'], ['dequantized_data'])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.RunOperatorOnce(dequantize)\n    dequantized_data = workspace.FetchBlob('dequantized_data')\n    reference = fused_rowwise_nbit_quantize_dequantize_reference(input_data, bit_rate)\n    np.testing.assert_array_almost_equal(dequantized_data, reference)",
        "mutated": [
            "@given(batch_size=st.integers(1, 100), block_size=st.integers(1, 100), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_and_dequantize_op(self, batch_size, block_size, bit_rate):\n    if False:\n        i = 10\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    input_data = np.random.rand(batch_size, block_size).astype(np.float32)\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    dequantize = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', ['quantized_data'], ['dequantized_data'])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.RunOperatorOnce(dequantize)\n    dequantized_data = workspace.FetchBlob('dequantized_data')\n    reference = fused_rowwise_nbit_quantize_dequantize_reference(input_data, bit_rate)\n    np.testing.assert_array_almost_equal(dequantized_data, reference)",
            "@given(batch_size=st.integers(1, 100), block_size=st.integers(1, 100), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_and_dequantize_op(self, batch_size, block_size, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    input_data = np.random.rand(batch_size, block_size).astype(np.float32)\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    dequantize = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', ['quantized_data'], ['dequantized_data'])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.RunOperatorOnce(dequantize)\n    dequantized_data = workspace.FetchBlob('dequantized_data')\n    reference = fused_rowwise_nbit_quantize_dequantize_reference(input_data, bit_rate)\n    np.testing.assert_array_almost_equal(dequantized_data, reference)",
            "@given(batch_size=st.integers(1, 100), block_size=st.integers(1, 100), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_and_dequantize_op(self, batch_size, block_size, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    input_data = np.random.rand(batch_size, block_size).astype(np.float32)\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    dequantize = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', ['quantized_data'], ['dequantized_data'])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.RunOperatorOnce(dequantize)\n    dequantized_data = workspace.FetchBlob('dequantized_data')\n    reference = fused_rowwise_nbit_quantize_dequantize_reference(input_data, bit_rate)\n    np.testing.assert_array_almost_equal(dequantized_data, reference)",
            "@given(batch_size=st.integers(1, 100), block_size=st.integers(1, 100), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_and_dequantize_op(self, batch_size, block_size, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    input_data = np.random.rand(batch_size, block_size).astype(np.float32)\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    dequantize = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', ['quantized_data'], ['dequantized_data'])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.RunOperatorOnce(dequantize)\n    dequantized_data = workspace.FetchBlob('dequantized_data')\n    reference = fused_rowwise_nbit_quantize_dequantize_reference(input_data, bit_rate)\n    np.testing.assert_array_almost_equal(dequantized_data, reference)",
            "@given(batch_size=st.integers(1, 100), block_size=st.integers(1, 100), bit_rate=st.sampled_from([2, 4]))\ndef test_quantize_and_dequantize_op(self, batch_size, block_size, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    input_data = np.random.rand(batch_size, block_size).astype(np.float32)\n    assume(input_data.shape[1] % num_elem_per_byte == 0)\n    quantize = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', ['input_data'], ['quantized_data'])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(quantize)\n    quantized_data = workspace.FetchBlob('quantized_data')\n    dequantize = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', ['quantized_data'], ['dequantized_data'])\n    workspace.FeedBlob('quantized_data', quantized_data)\n    workspace.RunOperatorOnce(dequantize)\n    dequantized_data = workspace.FetchBlob('dequantized_data')\n    reference = fused_rowwise_nbit_quantize_dequantize_reference(input_data, bit_rate)\n    np.testing.assert_array_almost_equal(dequantized_data, reference)"
        ]
    },
    {
        "func_name": "ErrorThresholdRow",
        "original": "def ErrorThresholdRow(X, bit_rate):\n    min_elem = np.min(X, axis=1)\n    max_elem = np.max(X, axis=1)\n    bias = np.float16(min_elem)\n    scale = np.float16((max_elem - bias) / ((1 << bit_rate) - 1))\n    max_round_error = scale / 2\n    max_clip_error = np.maximum(np.abs(min_elem - bias), np.abs(scale * ((1 << bit_rate) - 1) + bias - max_elem))\n    thres = np.maximum(max_round_error, max_clip_error) * 1.1\n    return thres",
        "mutated": [
            "def ErrorThresholdRow(X, bit_rate):\n    if False:\n        i = 10\n    min_elem = np.min(X, axis=1)\n    max_elem = np.max(X, axis=1)\n    bias = np.float16(min_elem)\n    scale = np.float16((max_elem - bias) / ((1 << bit_rate) - 1))\n    max_round_error = scale / 2\n    max_clip_error = np.maximum(np.abs(min_elem - bias), np.abs(scale * ((1 << bit_rate) - 1) + bias - max_elem))\n    thres = np.maximum(max_round_error, max_clip_error) * 1.1\n    return thres",
            "def ErrorThresholdRow(X, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    min_elem = np.min(X, axis=1)\n    max_elem = np.max(X, axis=1)\n    bias = np.float16(min_elem)\n    scale = np.float16((max_elem - bias) / ((1 << bit_rate) - 1))\n    max_round_error = scale / 2\n    max_clip_error = np.maximum(np.abs(min_elem - bias), np.abs(scale * ((1 << bit_rate) - 1) + bias - max_elem))\n    thres = np.maximum(max_round_error, max_clip_error) * 1.1\n    return thres",
            "def ErrorThresholdRow(X, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    min_elem = np.min(X, axis=1)\n    max_elem = np.max(X, axis=1)\n    bias = np.float16(min_elem)\n    scale = np.float16((max_elem - bias) / ((1 << bit_rate) - 1))\n    max_round_error = scale / 2\n    max_clip_error = np.maximum(np.abs(min_elem - bias), np.abs(scale * ((1 << bit_rate) - 1) + bias - max_elem))\n    thres = np.maximum(max_round_error, max_clip_error) * 1.1\n    return thres",
            "def ErrorThresholdRow(X, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    min_elem = np.min(X, axis=1)\n    max_elem = np.max(X, axis=1)\n    bias = np.float16(min_elem)\n    scale = np.float16((max_elem - bias) / ((1 << bit_rate) - 1))\n    max_round_error = scale / 2\n    max_clip_error = np.maximum(np.abs(min_elem - bias), np.abs(scale * ((1 << bit_rate) - 1) + bias - max_elem))\n    thres = np.maximum(max_round_error, max_clip_error) * 1.1\n    return thres",
            "def ErrorThresholdRow(X, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    min_elem = np.min(X, axis=1)\n    max_elem = np.max(X, axis=1)\n    bias = np.float16(min_elem)\n    scale = np.float16((max_elem - bias) / ((1 << bit_rate) - 1))\n    max_round_error = scale / 2\n    max_clip_error = np.maximum(np.abs(min_elem - bias), np.abs(scale * ((1 << bit_rate) - 1) + bias - max_elem))\n    thres = np.maximum(max_round_error, max_clip_error) * 1.1\n    return thres"
        ]
    },
    {
        "func_name": "testNBit",
        "original": "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=10000)\ndef testNBit(self, bit_rate):\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    blocksize = np.random.randint(2, 1000)\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('minmax_quantized_data', 'minmax_dequantized_data')\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('greedy_quantized_data', 'greedy_dequantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    err_thres = ErrorThresholdRow(input_data, bit_rate)\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    for i in range(err_thres.size):\n        assert np.sum(diff_minmax[i, :] > err_thres[i]) == 0, 'error at row {} too high (diff_minmax[i, :] {} diff_minmax[i, :] > err_thres[i] {} err_thres[i] {}'.format(i, diff_minmax[i, :], diff_minmax[i, :] > err_thres[i], err_thres[i])\n        l2_minmax_err = np.linalg.norm(diff_minmax[i, :])\n        l2_greedy_err = np.linalg.norm(diff_greedy[i, :])\n        assert l2_greedy_err <= l2_minmax_err * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {} (input_data[i,:] {} minmax_dequantized_data[i,:] {} greedy_dequantized_data[i,:] {}'.format(l2_greedy_err, i, l2_minmax_err, input_data[i, :], minmax_dequantized_data[i, :], greedy_dequantized_data[i, :])",
        "mutated": [
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=10000)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    blocksize = np.random.randint(2, 1000)\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('minmax_quantized_data', 'minmax_dequantized_data')\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('greedy_quantized_data', 'greedy_dequantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    err_thres = ErrorThresholdRow(input_data, bit_rate)\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    for i in range(err_thres.size):\n        assert np.sum(diff_minmax[i, :] > err_thres[i]) == 0, 'error at row {} too high (diff_minmax[i, :] {} diff_minmax[i, :] > err_thres[i] {} err_thres[i] {}'.format(i, diff_minmax[i, :], diff_minmax[i, :] > err_thres[i], err_thres[i])\n        l2_minmax_err = np.linalg.norm(diff_minmax[i, :])\n        l2_greedy_err = np.linalg.norm(diff_greedy[i, :])\n        assert l2_greedy_err <= l2_minmax_err * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {} (input_data[i,:] {} minmax_dequantized_data[i,:] {} greedy_dequantized_data[i,:] {}'.format(l2_greedy_err, i, l2_minmax_err, input_data[i, :], minmax_dequantized_data[i, :], greedy_dequantized_data[i, :])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=10000)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    blocksize = np.random.randint(2, 1000)\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('minmax_quantized_data', 'minmax_dequantized_data')\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('greedy_quantized_data', 'greedy_dequantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    err_thres = ErrorThresholdRow(input_data, bit_rate)\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    for i in range(err_thres.size):\n        assert np.sum(diff_minmax[i, :] > err_thres[i]) == 0, 'error at row {} too high (diff_minmax[i, :] {} diff_minmax[i, :] > err_thres[i] {} err_thres[i] {}'.format(i, diff_minmax[i, :], diff_minmax[i, :] > err_thres[i], err_thres[i])\n        l2_minmax_err = np.linalg.norm(diff_minmax[i, :])\n        l2_greedy_err = np.linalg.norm(diff_greedy[i, :])\n        assert l2_greedy_err <= l2_minmax_err * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {} (input_data[i,:] {} minmax_dequantized_data[i,:] {} greedy_dequantized_data[i,:] {}'.format(l2_greedy_err, i, l2_minmax_err, input_data[i, :], minmax_dequantized_data[i, :], greedy_dequantized_data[i, :])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=10000)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    blocksize = np.random.randint(2, 1000)\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('minmax_quantized_data', 'minmax_dequantized_data')\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('greedy_quantized_data', 'greedy_dequantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    err_thres = ErrorThresholdRow(input_data, bit_rate)\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    for i in range(err_thres.size):\n        assert np.sum(diff_minmax[i, :] > err_thres[i]) == 0, 'error at row {} too high (diff_minmax[i, :] {} diff_minmax[i, :] > err_thres[i] {} err_thres[i] {}'.format(i, diff_minmax[i, :], diff_minmax[i, :] > err_thres[i], err_thres[i])\n        l2_minmax_err = np.linalg.norm(diff_minmax[i, :])\n        l2_greedy_err = np.linalg.norm(diff_greedy[i, :])\n        assert l2_greedy_err <= l2_minmax_err * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {} (input_data[i,:] {} minmax_dequantized_data[i,:] {} greedy_dequantized_data[i,:] {}'.format(l2_greedy_err, i, l2_minmax_err, input_data[i, :], minmax_dequantized_data[i, :], greedy_dequantized_data[i, :])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=10000)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    blocksize = np.random.randint(2, 1000)\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('minmax_quantized_data', 'minmax_dequantized_data')\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('greedy_quantized_data', 'greedy_dequantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    err_thres = ErrorThresholdRow(input_data, bit_rate)\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    for i in range(err_thres.size):\n        assert np.sum(diff_minmax[i, :] > err_thres[i]) == 0, 'error at row {} too high (diff_minmax[i, :] {} diff_minmax[i, :] > err_thres[i] {} err_thres[i] {}'.format(i, diff_minmax[i, :], diff_minmax[i, :] > err_thres[i], err_thres[i])\n        l2_minmax_err = np.linalg.norm(diff_minmax[i, :])\n        l2_greedy_err = np.linalg.norm(diff_greedy[i, :])\n        assert l2_greedy_err <= l2_minmax_err * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {} (input_data[i,:] {} minmax_dequantized_data[i,:] {} greedy_dequantized_data[i,:] {}'.format(l2_greedy_err, i, l2_minmax_err, input_data[i, :], minmax_dequantized_data[i, :], greedy_dequantized_data[i, :])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=10000)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    blocksize = np.random.randint(2, 1000)\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('minmax_quantized_data', 'minmax_dequantized_data')\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitFakeRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    net.Fused8BitRowwiseQuantizedToFloat('greedy_quantized_data', 'greedy_dequantized_data')\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    err_thres = ErrorThresholdRow(input_data, bit_rate)\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    for i in range(err_thres.size):\n        assert np.sum(diff_minmax[i, :] > err_thres[i]) == 0, 'error at row {} too high (diff_minmax[i, :] {} diff_minmax[i, :] > err_thres[i] {} err_thres[i] {}'.format(i, diff_minmax[i, :], diff_minmax[i, :] > err_thres[i], err_thres[i])\n        l2_minmax_err = np.linalg.norm(diff_minmax[i, :])\n        l2_greedy_err = np.linalg.norm(diff_greedy[i, :])\n        assert l2_greedy_err <= l2_minmax_err * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {} (input_data[i,:] {} minmax_dequantized_data[i,:] {} greedy_dequantized_data[i,:] {}'.format(l2_greedy_err, i, l2_minmax_err, input_data[i, :], minmax_dequantized_data[i, :], greedy_dequantized_data[i, :])"
        ]
    },
    {
        "func_name": "testNBit",
        "original": "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=None, max_examples=50)\ndef testNBit(self, bit_rate):\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    blocksize = np.random.randint(2, 500) * num_elem_per_byte\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'minmax_quantized_data', 'minmax_dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'greedy_quantized_data', 'greedy_dequantized_data')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    l2_minmax = np.linalg.norm(input_data - minmax_dequantized_data, axis=1)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    l2_greedy = np.linalg.norm(input_data - greedy_dequantized_data, axis=1)\n    for i in range(input_data.shape[0]):\n        (xmin, xmax) = param_search_greedy(input_data[i, :], bit_rate, n_bins=200, ratio=0.16)\n        (X_q_ref, l2_greedy_ref) = _compress_uniform_simplified(input_data[i, :], bit_rate, xmin, xmax, fp16_scale_bias=True)\n        l2_discrepancy = np.abs(l2_greedy[i] - l2_greedy_ref) / input_data.shape[1]\n        assert l2_discrepancy < 1e-05, 'l2_discrepancy between C++ and Python greedy algorithm {} at row {} is too high (actual l2 err {} ref l2 err {} actual {} ref {})'.format(l2_discrepancy, i, l2_greedy[i], l2_greedy_ref, greedy_dequantized_data[i, :], X_q_ref)\n        assert l2_greedy[i] <= l2_minmax[i] * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {}'.format(l2_greedy[i], i, l2_minmax[i])",
        "mutated": [
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=None, max_examples=50)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    blocksize = np.random.randint(2, 500) * num_elem_per_byte\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'minmax_quantized_data', 'minmax_dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'greedy_quantized_data', 'greedy_dequantized_data')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    l2_minmax = np.linalg.norm(input_data - minmax_dequantized_data, axis=1)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    l2_greedy = np.linalg.norm(input_data - greedy_dequantized_data, axis=1)\n    for i in range(input_data.shape[0]):\n        (xmin, xmax) = param_search_greedy(input_data[i, :], bit_rate, n_bins=200, ratio=0.16)\n        (X_q_ref, l2_greedy_ref) = _compress_uniform_simplified(input_data[i, :], bit_rate, xmin, xmax, fp16_scale_bias=True)\n        l2_discrepancy = np.abs(l2_greedy[i] - l2_greedy_ref) / input_data.shape[1]\n        assert l2_discrepancy < 1e-05, 'l2_discrepancy between C++ and Python greedy algorithm {} at row {} is too high (actual l2 err {} ref l2 err {} actual {} ref {})'.format(l2_discrepancy, i, l2_greedy[i], l2_greedy_ref, greedy_dequantized_data[i, :], X_q_ref)\n        assert l2_greedy[i] <= l2_minmax[i] * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {}'.format(l2_greedy[i], i, l2_minmax[i])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=None, max_examples=50)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    blocksize = np.random.randint(2, 500) * num_elem_per_byte\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'minmax_quantized_data', 'minmax_dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'greedy_quantized_data', 'greedy_dequantized_data')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    l2_minmax = np.linalg.norm(input_data - minmax_dequantized_data, axis=1)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    l2_greedy = np.linalg.norm(input_data - greedy_dequantized_data, axis=1)\n    for i in range(input_data.shape[0]):\n        (xmin, xmax) = param_search_greedy(input_data[i, :], bit_rate, n_bins=200, ratio=0.16)\n        (X_q_ref, l2_greedy_ref) = _compress_uniform_simplified(input_data[i, :], bit_rate, xmin, xmax, fp16_scale_bias=True)\n        l2_discrepancy = np.abs(l2_greedy[i] - l2_greedy_ref) / input_data.shape[1]\n        assert l2_discrepancy < 1e-05, 'l2_discrepancy between C++ and Python greedy algorithm {} at row {} is too high (actual l2 err {} ref l2 err {} actual {} ref {})'.format(l2_discrepancy, i, l2_greedy[i], l2_greedy_ref, greedy_dequantized_data[i, :], X_q_ref)\n        assert l2_greedy[i] <= l2_minmax[i] * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {}'.format(l2_greedy[i], i, l2_minmax[i])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=None, max_examples=50)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    blocksize = np.random.randint(2, 500) * num_elem_per_byte\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'minmax_quantized_data', 'minmax_dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'greedy_quantized_data', 'greedy_dequantized_data')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    l2_minmax = np.linalg.norm(input_data - minmax_dequantized_data, axis=1)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    l2_greedy = np.linalg.norm(input_data - greedy_dequantized_data, axis=1)\n    for i in range(input_data.shape[0]):\n        (xmin, xmax) = param_search_greedy(input_data[i, :], bit_rate, n_bins=200, ratio=0.16)\n        (X_q_ref, l2_greedy_ref) = _compress_uniform_simplified(input_data[i, :], bit_rate, xmin, xmax, fp16_scale_bias=True)\n        l2_discrepancy = np.abs(l2_greedy[i] - l2_greedy_ref) / input_data.shape[1]\n        assert l2_discrepancy < 1e-05, 'l2_discrepancy between C++ and Python greedy algorithm {} at row {} is too high (actual l2 err {} ref l2 err {} actual {} ref {})'.format(l2_discrepancy, i, l2_greedy[i], l2_greedy_ref, greedy_dequantized_data[i, :], X_q_ref)\n        assert l2_greedy[i] <= l2_minmax[i] * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {}'.format(l2_greedy[i], i, l2_minmax[i])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=None, max_examples=50)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    blocksize = np.random.randint(2, 500) * num_elem_per_byte\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'minmax_quantized_data', 'minmax_dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'greedy_quantized_data', 'greedy_dequantized_data')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    l2_minmax = np.linalg.norm(input_data - minmax_dequantized_data, axis=1)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    l2_greedy = np.linalg.norm(input_data - greedy_dequantized_data, axis=1)\n    for i in range(input_data.shape[0]):\n        (xmin, xmax) = param_search_greedy(input_data[i, :], bit_rate, n_bins=200, ratio=0.16)\n        (X_q_ref, l2_greedy_ref) = _compress_uniform_simplified(input_data[i, :], bit_rate, xmin, xmax, fp16_scale_bias=True)\n        l2_discrepancy = np.abs(l2_greedy[i] - l2_greedy_ref) / input_data.shape[1]\n        assert l2_discrepancy < 1e-05, 'l2_discrepancy between C++ and Python greedy algorithm {} at row {} is too high (actual l2 err {} ref l2 err {} actual {} ref {})'.format(l2_discrepancy, i, l2_greedy[i], l2_greedy_ref, greedy_dequantized_data[i, :], X_q_ref)\n        assert l2_greedy[i] <= l2_minmax[i] * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {}'.format(l2_greedy[i], i, l2_minmax[i])",
            "@given(bit_rate=st.sampled_from([2, 4]))\n@settings(deadline=None, max_examples=50)\ndef testNBit(self, bit_rate):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    net = core.Net('bench')\n    batchsize = np.random.randint(2, 1000)\n    assert 8 % bit_rate == 0\n    num_elem_per_byte = 8 // bit_rate\n    blocksize = np.random.randint(2, 500) * num_elem_per_byte\n    input_data = np.random.rand(batchsize, blocksize).astype(np.float32)\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'minmax_quantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'minmax_quantized_data', 'minmax_dequantized_data')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('FloatToFused' + str(bit_rate) + 'BitRowwiseQuantized', 'input_data', 'greedy_quantized_data', engine='GREEDY')\n    net.Proto().op.extend([op])\n    op = core.CreateOperator('Fused' + str(bit_rate) + 'BitRowwiseQuantizedToFloat', 'greedy_quantized_data', 'greedy_dequantized_data')\n    net.Proto().op.extend([op])\n    workspace.FeedBlob('input_data', input_data)\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(net)\n    minmax_dequantized_data = workspace.FetchBlob('minmax_dequantized_data')\n    greedy_dequantized_data = workspace.FetchBlob('greedy_dequantized_data')\n    diff_minmax = np.abs(input_data - minmax_dequantized_data)\n    l2_minmax = np.linalg.norm(input_data - minmax_dequantized_data, axis=1)\n    diff_greedy = np.abs(input_data - greedy_dequantized_data)\n    l2_greedy = np.linalg.norm(input_data - greedy_dequantized_data, axis=1)\n    for i in range(input_data.shape[0]):\n        (xmin, xmax) = param_search_greedy(input_data[i, :], bit_rate, n_bins=200, ratio=0.16)\n        (X_q_ref, l2_greedy_ref) = _compress_uniform_simplified(input_data[i, :], bit_rate, xmin, xmax, fp16_scale_bias=True)\n        l2_discrepancy = np.abs(l2_greedy[i] - l2_greedy_ref) / input_data.shape[1]\n        assert l2_discrepancy < 1e-05, 'l2_discrepancy between C++ and Python greedy algorithm {} at row {} is too high (actual l2 err {} ref l2 err {} actual {} ref {})'.format(l2_discrepancy, i, l2_greedy[i], l2_greedy_ref, greedy_dequantized_data[i, :], X_q_ref)\n        assert l2_greedy[i] <= l2_minmax[i] * 1.03, 'L2 quantization error using greedy algorithm {} at row {} is bigger than error using minmax {}'.format(l2_greedy[i], i, l2_minmax[i])"
        ]
    }
]