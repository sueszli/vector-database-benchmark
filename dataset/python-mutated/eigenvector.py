"""Functions for computing eigenvector centrality."""
import math
import networkx as nx
from networkx.utils import not_implemented_for
__all__ = ['eigenvector_centrality', 'eigenvector_centrality_numpy']

@not_implemented_for('multigraph')
@nx._dispatch(edge_attrs='weight')
def eigenvector_centrality(G, max_iter=100, tol=1e-06, nstart=None, weight=None):
    if False:
        i = 10
        return i + 15
    'Compute the eigenvector centrality for the graph G.\n\n    Eigenvector centrality computes the centrality for a node by adding\n    the centrality of its predecessors. The centrality for node $i$ is the\n    $i$-th element of a left eigenvector associated with the eigenvalue $\\lambda$\n    of maximum modulus that is positive. Such an eigenvector $x$ is\n    defined up to a multiplicative constant by the equation\n\n    .. math::\n\n         \\lambda x^T = x^T A,\n\n    where $A$ is the adjacency matrix of the graph G. By definition of\n    row-column product, the equation above is equivalent to\n\n    .. math::\n\n        \\lambda x_i = \\sum_{j\\to i}x_j.\n\n    That is, adding the eigenvector centralities of the predecessors of\n    $i$ one obtains the eigenvector centrality of $i$ multiplied by\n    $\\lambda$. In the case of undirected graphs, $x$ also solves the familiar\n    right-eigenvector equation $Ax = \\lambda x$.\n\n    By virtue of the Perron–Frobenius theorem [1]_, if G is strongly\n    connected there is a unique eigenvector $x$, and all its entries\n    are strictly positive.\n\n    If G is not strongly connected there might be several left\n    eigenvectors associated with $\\lambda$, and some of their elements\n    might be zero.\n\n    Parameters\n    ----------\n    G : graph\n      A networkx graph.\n\n    max_iter : integer, optional (default=100)\n      Maximum number of power iterations.\n\n    tol : float, optional (default=1.0e-6)\n      Error tolerance (in Euclidean norm) used to check convergence in\n      power iteration.\n\n    nstart : dictionary, optional (default=None)\n      Starting value of power iteration for each node. Must have a nonzero\n      projection on the desired eigenvector for the power method to converge.\n      If None, this implementation uses an all-ones vector, which is a safe\n      choice.\n\n    weight : None or string, optional (default=None)\n      If None, all edge weights are considered equal. Otherwise holds the\n      name of the edge attribute used as weight. In this measure the\n      weight is interpreted as the connection strength.\n\n    Returns\n    -------\n    nodes : dictionary\n       Dictionary of nodes with eigenvector centrality as the value. The\n       associated vector has unit Euclidean norm and the values are\n       nonegative.\n\n    Examples\n    --------\n    >>> G = nx.path_graph(4)\n    >>> centrality = nx.eigenvector_centrality(G)\n    >>> sorted((v, f"{c:0.2f}") for v, c in centrality.items())\n    [(0, \'0.37\'), (1, \'0.60\'), (2, \'0.60\'), (3, \'0.37\')]\n\n    Raises\n    ------\n    NetworkXPointlessConcept\n        If the graph G is the null graph.\n\n    NetworkXError\n        If each value in `nstart` is zero.\n\n    PowerIterationFailedConvergence\n        If the algorithm fails to converge to the specified tolerance\n        within the specified number of iterations of the power iteration\n        method.\n\n    See Also\n    --------\n    eigenvector_centrality_numpy\n    :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`\n    :func:`~networkx.algorithms.link_analysis.hits_alg.hits`\n\n    Notes\n    -----\n    Eigenvector centrality was introduced by Landau [2]_ for chess\n    tournaments. It was later rediscovered by Wei [3]_ and then\n    popularized by Kendall [4]_ in the context of sport ranking. Berge\n    introduced a general definition for graphs based on social connections\n    [5]_. Bonacich [6]_ reintroduced again eigenvector centrality and made\n    it popular in link analysis.\n\n    This function computes the left dominant eigenvector, which corresponds\n    to adding the centrality of predecessors: this is the usual approach.\n    To add the centrality of successors first reverse the graph with\n    ``G.reverse()``.\n\n    The implementation uses power iteration [7]_ to compute a dominant\n    eigenvector starting from the provided vector `nstart`. Convergence is\n    guaranteed as long as `nstart` has a nonzero projection on a dominant\n    eigenvector, which certainly happens using the default value.\n\n    The method stops when the change in the computed vector between two\n    iterations is smaller than an error tolerance of ``G.number_of_nodes()\n    * tol`` or after ``max_iter`` iterations, but in the second case it\n    raises an exception.\n\n    This implementation uses $(A + I)$ rather than the adjacency matrix\n    $A$ because the change preserves eigenvectors, but it shifts the\n    spectrum, thus guaranteeing convergence even for networks with\n    negative eigenvalues of maximum modulus.\n\n    References\n    ----------\n    .. [1] Abraham Berman and Robert J. Plemmons.\n       "Nonnegative Matrices in the Mathematical Sciences."\n       Classics in Applied Mathematics. SIAM, 1994.\n\n    .. [2] Edmund Landau.\n       "Zur relativen Wertbemessung der Turnierresultate."\n       Deutsches Wochenschach, 11:366–369, 1895.\n\n    .. [3] Teh-Hsing Wei.\n       "The Algebraic Foundations of Ranking Theory."\n       PhD thesis, University of Cambridge, 1952.\n\n    .. [4] Maurice G. Kendall.\n       "Further contributions to the theory of paired comparisons."\n       Biometrics, 11(1):43–62, 1955.\n       https://www.jstor.org/stable/3001479\n\n    .. [5] Claude Berge\n       "Théorie des graphes et ses applications."\n       Dunod, Paris, France, 1958.\n\n    .. [6] Phillip Bonacich.\n       "Technique for analyzing overlapping memberships."\n       Sociological Methodology, 4:176–185, 1972.\n       https://www.jstor.org/stable/270732\n\n    .. [7] Power iteration:: https://en.wikipedia.org/wiki/Power_iteration\n\n    '
    if len(G) == 0:
        raise nx.NetworkXPointlessConcept('cannot compute centrality for the null graph')
    if nstart is None:
        nstart = {v: 1 for v in G}
    if all((v == 0 for v in nstart.values())):
        raise nx.NetworkXError('initial vector cannot have all zero values')
    nstart_sum = sum(nstart.values())
    x = {k: v / nstart_sum for (k, v) in nstart.items()}
    nnodes = G.number_of_nodes()
    for _ in range(max_iter):
        xlast = x
        x = xlast.copy()
        for n in x:
            for nbr in G[n]:
                w = G[n][nbr].get(weight, 1) if weight else 1
                x[nbr] += xlast[n] * w
        norm = math.hypot(*x.values()) or 1
        x = {k: v / norm for (k, v) in x.items()}
        if sum((abs(x[n] - xlast[n]) for n in x)) < nnodes * tol:
            return x
    raise nx.PowerIterationFailedConvergence(max_iter)

@nx._dispatch(edge_attrs='weight')
def eigenvector_centrality_numpy(G, weight=None, max_iter=50, tol=0):
    if False:
        print('Hello World!')
    'Compute the eigenvector centrality for the graph G.\n\n    Eigenvector centrality computes the centrality for a node by adding\n    the centrality of its predecessors. The centrality for node $i$ is the\n    $i$-th element of a left eigenvector associated with the eigenvalue $\\lambda$\n    of maximum modulus that is positive. Such an eigenvector $x$ is\n    defined up to a multiplicative constant by the equation\n\n    .. math::\n\n         \\lambda x^T = x^T A,\n\n    where $A$ is the adjacency matrix of the graph G. By definition of\n    row-column product, the equation above is equivalent to\n\n    .. math::\n\n        \\lambda x_i = \\sum_{j\\to i}x_j.\n\n    That is, adding the eigenvector centralities of the predecessors of\n    $i$ one obtains the eigenvector centrality of $i$ multiplied by\n    $\\lambda$. In the case of undirected graphs, $x$ also solves the familiar\n    right-eigenvector equation $Ax = \\lambda x$.\n\n    By virtue of the Perron–Frobenius theorem [1]_, if G is strongly\n    connected there is a unique eigenvector $x$, and all its entries\n    are strictly positive.\n\n    If G is not strongly connected there might be several left\n    eigenvectors associated with $\\lambda$, and some of their elements\n    might be zero.\n\n    Parameters\n    ----------\n    G : graph\n      A networkx graph.\n\n    max_iter : integer, optional (default=50)\n      Maximum number of Arnoldi update iterations allowed.\n\n    tol : float, optional (default=0)\n      Relative accuracy for eigenvalues (stopping criterion).\n      The default value of 0 implies machine precision.\n\n    weight : None or string, optional (default=None)\n      If None, all edge weights are considered equal. Otherwise holds the\n      name of the edge attribute used as weight. In this measure the\n      weight is interpreted as the connection strength.\n\n    Returns\n    -------\n    nodes : dictionary\n       Dictionary of nodes with eigenvector centrality as the value. The\n       associated vector has unit Euclidean norm and the values are\n       nonegative.\n\n    Examples\n    --------\n    >>> G = nx.path_graph(4)\n    >>> centrality = nx.eigenvector_centrality_numpy(G)\n    >>> print([f"{node} {centrality[node]:0.2f}" for node in centrality])\n    [\'0 0.37\', \'1 0.60\', \'2 0.60\', \'3 0.37\']\n\n    Raises\n    ------\n    NetworkXPointlessConcept\n        If the graph G is the null graph.\n\n    ArpackNoConvergence\n        When the requested convergence is not obtained. The currently\n        converged eigenvalues and eigenvectors can be found as\n        eigenvalues and eigenvectors attributes of the exception object.\n\n    See Also\n    --------\n    :func:`scipy.sparse.linalg.eigs`\n    eigenvector_centrality\n    :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`\n    :func:`~networkx.algorithms.link_analysis.hits_alg.hits`\n\n    Notes\n    -----\n    Eigenvector centrality was introduced by Landau [2]_ for chess\n    tournaments. It was later rediscovered by Wei [3]_ and then\n    popularized by Kendall [4]_ in the context of sport ranking. Berge\n    introduced a general definition for graphs based on social connections\n    [5]_. Bonacich [6]_ reintroduced again eigenvector centrality and made\n    it popular in link analysis.\n\n    This function computes the left dominant eigenvector, which corresponds\n    to adding the centrality of predecessors: this is the usual approach.\n    To add the centrality of successors first reverse the graph with\n    ``G.reverse()``.\n\n    This implementation uses the\n    :func:`SciPy sparse eigenvalue solver<scipy.sparse.linalg.eigs>` (ARPACK)\n    to find the largest eigenvalue/eigenvector pair using Arnoldi iterations\n    [7]_.\n\n    References\n    ----------\n    .. [1] Abraham Berman and Robert J. Plemmons.\n       "Nonnegative Matrices in the Mathematical Sciences."\n       Classics in Applied Mathematics. SIAM, 1994.\n\n    .. [2] Edmund Landau.\n       "Zur relativen Wertbemessung der Turnierresultate."\n       Deutsches Wochenschach, 11:366–369, 1895.\n\n    .. [3] Teh-Hsing Wei.\n       "The Algebraic Foundations of Ranking Theory."\n       PhD thesis, University of Cambridge, 1952.\n\n    .. [4] Maurice G. Kendall.\n       "Further contributions to the theory of paired comparisons."\n       Biometrics, 11(1):43–62, 1955.\n       https://www.jstor.org/stable/3001479\n\n    .. [5] Claude Berge\n       "Théorie des graphes et ses applications."\n       Dunod, Paris, France, 1958.\n\n    .. [6] Phillip Bonacich.\n       "Technique for analyzing overlapping memberships."\n       Sociological Methodology, 4:176–185, 1972.\n       https://www.jstor.org/stable/270732\n\n    .. [7] Arnoldi iteration:: https://en.wikipedia.org/wiki/Arnoldi_iteration\n\n    '
    import numpy as np
    import scipy as sp
    if len(G) == 0:
        raise nx.NetworkXPointlessConcept('cannot compute centrality for the null graph')
    M = nx.to_scipy_sparse_array(G, nodelist=list(G), weight=weight, dtype=float)
    (_, eigenvector) = sp.sparse.linalg.eigs(M.T, k=1, which='LR', maxiter=max_iter, tol=tol)
    largest = eigenvector.flatten().real
    norm = np.sign(largest.sum()) * sp.linalg.norm(largest)
    return dict(zip(G, largest / norm))