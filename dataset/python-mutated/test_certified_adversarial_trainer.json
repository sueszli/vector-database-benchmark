[
    {
        "func_name": "fix_get_mnist_data",
        "original": "@pytest.fixture()\ndef fix_get_mnist_data():\n    \"\"\"\n    Get the first 100 samples of the mnist test set with channels first format\n\n    :return: First 100 sample/label pairs of the MNIST test dataset.\n    \"\"\"\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test.astype(np.float32), y_test)",
        "mutated": [
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test.astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test.astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test.astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test.astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_mnist_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Get the first 100 samples of the mnist test set with channels first format\\n\\n    :return: First 100 sample/label pairs of the MNIST test dataset.\\n    '\n    nb_test = 100\n    ((_, _), (x_test, y_test), _, _) = load_dataset('mnist')\n    x_test = np.squeeze(x_test)\n    x_test = np.expand_dims(x_test, axis=1)\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (x_test.astype(np.float32), y_test)"
        ]
    },
    {
        "func_name": "fix_get_cifar10_data",
        "original": "@pytest.fixture()\ndef fix_get_cifar10_data():\n    \"\"\"\n    Get the first 10 samples of the cifar10 test set\n\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\n    \"\"\"\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (np.moveaxis(x_test, [3], [1]).astype(np.float32), y_test)",
        "mutated": [
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n    '\\n    Get the first 10 samples of the cifar10 test set\\n\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (np.moveaxis(x_test, [3], [1]).astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Get the first 10 samples of the cifar10 test set\\n\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (np.moveaxis(x_test, [3], [1]).astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Get the first 10 samples of the cifar10 test set\\n\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (np.moveaxis(x_test, [3], [1]).astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Get the first 10 samples of the cifar10 test set\\n\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (np.moveaxis(x_test, [3], [1]).astype(np.float32), y_test)",
            "@pytest.fixture()\ndef fix_get_cifar10_data():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Get the first 10 samples of the cifar10 test set\\n\\n    :return: First 10 sample/label pairs of the cifar10 test dataset.\\n    '\n    nb_test = 10\n    ((_, _), (x_test, y_test), _, _) = load_dataset('cifar10')\n    y_test = np.argmax(y_test, axis=1)\n    (x_test, y_test) = (x_test[:nb_test], y_test[:nb_test])\n    return (np.moveaxis(x_test, [3], [1]).astype(np.float32), y_test)"
        ]
    },
    {
        "func_name": "test_mnist_certified_training",
        "original": "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_training(art_warning, fix_get_mnist_data):\n    \"\"\"\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound\n        1) Check regular loss\n        2) Train the model for 3 epochs using certified training.\n        3) Re-Check regular loss\n    \"\"\"\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=0.1)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.095\n        trainer.fit(fix_get_mnist_data[0], fix_get_mnist_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.092\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_training(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=0.1)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.095\n        trainer.fit(fix_get_mnist_data[0], fix_get_mnist_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_training(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=0.1)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.095\n        trainer.fit(fix_get_mnist_data[0], fix_get_mnist_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_training(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=0.1)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.095\n        trainer.fit(fix_get_mnist_data[0], fix_get_mnist_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_training(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=0.1)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.095\n        trainer.fit(fix_get_mnist_data[0], fix_get_mnist_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_training(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check the following properties for the first 100 samples of the MNIST test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=0.1)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.095\n        trainer.fit(fix_get_mnist_data[0], fix_get_mnist_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_mnist_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_mnist_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 3) == 0.092\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    },
    {
        "func_name": "test_mnist_certified_loss",
        "original": "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_loss(art_warning, fix_get_mnist_data):\n    \"\"\"\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\n    bound compared to PGD.\n    \"\"\"\n    bound = 0.05\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_mnist_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_mnist_data[0], fix_get_mnist_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 39.7759\n        samples_certified = 0\n        certified_loss = 0\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(784) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == -309.2724\n        assert samples_certified == 94\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_mnist_data[0], y=fix_get_mnist_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_mnist_data[1]) / len(fix_get_mnist_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_loss(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 0.05\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_mnist_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_mnist_data[0], fix_get_mnist_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 39.7759\n        samples_certified = 0\n        certified_loss = 0\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(784) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == -309.2724\n        assert samples_certified == 94\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_mnist_data[0], y=fix_get_mnist_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_mnist_data[1]) / len(fix_get_mnist_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_loss(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 0.05\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_mnist_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_mnist_data[0], fix_get_mnist_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 39.7759\n        samples_certified = 0\n        certified_loss = 0\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(784) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == -309.2724\n        assert samples_certified == 94\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_mnist_data[0], y=fix_get_mnist_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_mnist_data[1]) / len(fix_get_mnist_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_loss(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 0.05\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_mnist_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_mnist_data[0], fix_get_mnist_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 39.7759\n        samples_certified = 0\n        certified_loss = 0\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(784) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == -309.2724\n        assert samples_certified == 94\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_mnist_data[0], y=fix_get_mnist_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_mnist_data[1]) / len(fix_get_mnist_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_loss(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 0.05\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_mnist_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_mnist_data[0], fix_get_mnist_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 39.7759\n        samples_certified = 0\n        certified_loss = 0\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(784) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == -309.2724\n        assert samples_certified == 94\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_mnist_data[0], y=fix_get_mnist_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_mnist_data[1]) / len(fix_get_mnist_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_mnist_certified_loss(art_warning, fix_get_mnist_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 0.05\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_image_classifier_pt(from_logits=True, use_maxpool=False)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model.to(device), optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(1, 28, 28), nb_classes=10)\n    pgd_params = {'eps': 0.25, 'eps_step': 0.05, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_mnist_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_mnist_data[0], fix_get_mnist_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 39.7759\n        samples_certified = 0\n        certified_loss = 0\n        for (x, y) in zip(fix_get_mnist_data[0], fix_get_mnist_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(784) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(784) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == -309.2724\n        assert samples_certified == 94\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_mnist_data[0], y=fix_get_mnist_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_mnist_data[1]) / len(fix_get_mnist_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    },
    {
        "func_name": "test_cifar_certified_training",
        "original": "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_training(art_warning, fix_get_cifar10_data):\n    \"\"\"\n    Check the following properties for the first 10 samples of the CIFAR test set given an l_inft bound\n        1) Check regular loss\n        2) Train the model for 3 epochs using certified training.\n        3) Re-Check regular loss\n    \"\"\"\n    bound = 0.01\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0611\n        trainer.fit(fix_get_cifar10_data[0], fix_get_cifar10_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0092\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_training(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n    '\\n    Check the following properties for the first 10 samples of the CIFAR test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    bound = 0.01\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0611\n        trainer.fit(fix_get_cifar10_data[0], fix_get_cifar10_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_training(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check the following properties for the first 10 samples of the CIFAR test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    bound = 0.01\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0611\n        trainer.fit(fix_get_cifar10_data[0], fix_get_cifar10_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_training(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check the following properties for the first 10 samples of the CIFAR test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    bound = 0.01\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0611\n        trainer.fit(fix_get_cifar10_data[0], fix_get_cifar10_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_training(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check the following properties for the first 10 samples of the CIFAR test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    bound = 0.01\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0611\n        trainer.fit(fix_get_cifar10_data[0], fix_get_cifar10_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0092\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_training(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check the following properties for the first 10 samples of the CIFAR test set given an l_inft bound\\n        1) Check regular loss\\n        2) Train the model for 3 epochs using certified training.\\n        3) Re-Check regular loss\\n    '\n    bound = 0.01\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    try:\n        trainer._classifier.model.set_forward_mode('concrete')\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0611\n        trainer.fit(fix_get_cifar10_data[0], fix_get_cifar10_data[1], nb_epochs=3)\n        prediction = trainer._classifier.model.forward(fix_get_cifar10_data[0])\n        loss = trainer._classifier.concrete_loss(prediction, torch.tensor(fix_get_cifar10_data[1]).to(device))\n        assert round(float(loss.cpu().detach().numpy()), 4) == 1.0092\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    },
    {
        "func_name": "test_cifar_certified_loss",
        "original": "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_loss(art_warning, fix_get_cifar10_data):\n    \"\"\"\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\n    bound compared to PGD.\n    \"\"\"\n    bound = 2 / 255\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_cifar10_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        certified_loss = certified_loss.cpu().detach().numpy()\n        assert round(float(certified_loss), 4) == 16.5492\n        samples_certified = 0\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(3 * 32 * 32) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 1.6515\n        assert samples_certified == 6\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_cifar10_data[0], y=fix_get_cifar10_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_cifar10_data[1]) / len(fix_get_cifar10_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_loss(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 2 / 255\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_cifar10_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        certified_loss = certified_loss.cpu().detach().numpy()\n        assert round(float(certified_loss), 4) == 16.5492\n        samples_certified = 0\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(3 * 32 * 32) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 1.6515\n        assert samples_certified == 6\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_cifar10_data[0], y=fix_get_cifar10_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_cifar10_data[1]) / len(fix_get_cifar10_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_loss(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 2 / 255\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_cifar10_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        certified_loss = certified_loss.cpu().detach().numpy()\n        assert round(float(certified_loss), 4) == 16.5492\n        samples_certified = 0\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(3 * 32 * 32) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 1.6515\n        assert samples_certified == 6\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_cifar10_data[0], y=fix_get_cifar10_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_cifar10_data[1]) / len(fix_get_cifar10_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_loss(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 2 / 255\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_cifar10_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        certified_loss = certified_loss.cpu().detach().numpy()\n        assert round(float(certified_loss), 4) == 16.5492\n        samples_certified = 0\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(3 * 32 * 32) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 1.6515\n        assert samples_certified == 6\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_cifar10_data[0], y=fix_get_cifar10_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_cifar10_data[1]) / len(fix_get_cifar10_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_loss(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 2 / 255\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_cifar10_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        certified_loss = certified_loss.cpu().detach().numpy()\n        assert round(float(certified_loss), 4) == 16.5492\n        samples_certified = 0\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(3 * 32 * 32) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 1.6515\n        assert samples_certified == 6\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_cifar10_data[0], y=fix_get_cifar10_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_cifar10_data[1]) / len(fix_get_cifar10_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_framework('mxnet', 'non_dl_frameworks', 'tensorflow1', 'keras', 'kerastf', 'tensorflow2', 'tensorflow2v1', 'huggingface')\ndef test_cifar_certified_loss(art_warning, fix_get_cifar10_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check the certified losses with interval_loss_cce, max_logit_loss, and make sure that we give a lower\\n    bound compared to PGD.\\n    '\n    bound = 2 / 255\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    ptc = get_cifar10_image_classifier_pt(from_logits=True)\n    import torch.optim as optim\n    optimizer = optim.Adam(ptc.model.parameters(), lr=0.0001)\n    zonotope_model = PytorchDeepZ(model=ptc.model, optimizer=optimizer, clip_values=(0, 1), loss=torch.nn.CrossEntropyLoss(), input_shape=(3, 32, 32), nb_classes=10)\n    pgd_params = {'eps': 8 / 255, 'eps_step': 1 / 255, 'max_iter': 20, 'num_random_init': 0, 'batch_size': 64}\n    trainer = AdversarialTrainerCertifiedPytorch(zonotope_model, pgd_params=pgd_params, batch_size=10, bound=bound)\n    np.random.seed(123)\n    random.seed(123)\n    torch.manual_seed(123)\n    concrete_correct = 0\n    (samples_x, samples_eps) = trainer.predict_zonotopes(np.copy(fix_get_cifar10_data[0]), bound)\n    try:\n        certified_loss = 0\n        for (x, y) in zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1]):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=x, eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            certified_loss += trainer._classifier.interval_loss_cce(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n        certified_loss = certified_loss.cpu().detach().numpy()\n        assert round(float(certified_loss), 4) == 16.5492\n        samples_certified = 0\n        certified_loss = 0\n        for (i, (x, y)) in enumerate(zip(fix_get_cifar10_data[0], fix_get_cifar10_data[1])):\n            x = x.astype('float32')\n            pred_sample = np.copy(x)\n            pred_sample = np.expand_dims(pred_sample, axis=0)\n            zonotope_model.model.set_forward_mode('concrete')\n            prediction = trainer._classifier.model.forward(torch.from_numpy(pred_sample.astype('float32')).to(device))\n            if np.argmax(prediction.cpu().detach().numpy()) == y:\n                concrete_correct += 1\n            eps_bound = np.eye(3 * 32 * 32) * bound\n            zonotope_model.model.set_forward_mode('abstract')\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=eps_bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            (bias, eps_bound) = trainer._classifier.model.forward(eps=eps_bound, cent=data_sample_processed)\n            bias = torch.unsqueeze(bias, dim=0)\n            assert np.allclose(samples_x[i], bias.cpu().detach().numpy())\n            assert np.allclose(samples_eps[i], eps_bound.cpu().detach().numpy())\n            sample_loss = trainer._classifier.max_logit_loss(prediction=torch.cat((bias, eps_bound)), target=torch.from_numpy(np.expand_dims(y, axis=0)).to(device))\n            (data_sample_processed, eps_bound) = zonotope_model.pre_process(cent=np.copy(x), eps=np.eye(3 * 32 * 32) * bound)\n            data_sample_processed = np.expand_dims(data_sample_processed, axis=0)\n            is_certified = zonotope_model.certify(eps=eps_bound, cent=data_sample_processed, prediction=np.argmax(prediction.cpu().detach().numpy()))\n            if is_certified and int(np.argmax(prediction.cpu().detach().numpy())) == y:\n                assert sample_loss <= 0.0\n                samples_certified += 1\n            certified_loss += sample_loss\n        assert round(float(certified_loss.cpu().detach().numpy()), 4) == 1.6515\n        assert samples_certified == 6\n        zonotope_model.model.set_forward_mode('concrete')\n        attack = ProjectedGradientDescent(estimator=trainer._classifier, eps=bound, eps_step=bound / 20, max_iter=30, num_random_init=0)\n        i_batch = attack.generate(fix_get_cifar10_data[0], y=fix_get_cifar10_data[1])\n        preds = trainer._classifier.model.forward(i_batch)\n        preds = preds.cpu().detach().numpy()\n        acc = np.sum(np.argmax(preds, axis=1) == fix_get_cifar10_data[1]) / len(fix_get_cifar10_data[1])\n        assert acc * 100 >= samples_certified\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    }
]