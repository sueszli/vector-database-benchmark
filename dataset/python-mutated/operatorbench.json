[
    {
        "func_name": "compute_speedups",
        "original": "def compute_speedups(operator, models, example_inputs, repeats, accuracy_checking=False, device='cuda'):\n    expected = models[0](*example_inputs)\n    if accuracy_checking:\n        for model in models[1:]:\n            actual = model(*example_inputs)\n            try:\n                same(actual, expected, cos_similarity=True, equal_nan=True)\n            except AssertionError as e:\n                print(e)\n                print(f'Accuracy check failed: {operator}')\n                print((expected[0] - actual[0]).abs().max())\n    timings = np.zeros((repeats, len(models)), np.float64)\n    for rep in range(repeats):\n        for (m, model) in enumerate(models):\n            if device == 'cuda':\n                import triton\n                model(*example_inputs)\n                timings[rep, m] = triton.testing.do_bench(lambda : model(*example_inputs))\n            else:\n                from torch._inductor.utils import timed\n                timings[rep, m] = timed(model, example_inputs)\n    return np.median(timings, axis=0)",
        "mutated": [
            "def compute_speedups(operator, models, example_inputs, repeats, accuracy_checking=False, device='cuda'):\n    if False:\n        i = 10\n    expected = models[0](*example_inputs)\n    if accuracy_checking:\n        for model in models[1:]:\n            actual = model(*example_inputs)\n            try:\n                same(actual, expected, cos_similarity=True, equal_nan=True)\n            except AssertionError as e:\n                print(e)\n                print(f'Accuracy check failed: {operator}')\n                print((expected[0] - actual[0]).abs().max())\n    timings = np.zeros((repeats, len(models)), np.float64)\n    for rep in range(repeats):\n        for (m, model) in enumerate(models):\n            if device == 'cuda':\n                import triton\n                model(*example_inputs)\n                timings[rep, m] = triton.testing.do_bench(lambda : model(*example_inputs))\n            else:\n                from torch._inductor.utils import timed\n                timings[rep, m] = timed(model, example_inputs)\n    return np.median(timings, axis=0)",
            "def compute_speedups(operator, models, example_inputs, repeats, accuracy_checking=False, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    expected = models[0](*example_inputs)\n    if accuracy_checking:\n        for model in models[1:]:\n            actual = model(*example_inputs)\n            try:\n                same(actual, expected, cos_similarity=True, equal_nan=True)\n            except AssertionError as e:\n                print(e)\n                print(f'Accuracy check failed: {operator}')\n                print((expected[0] - actual[0]).abs().max())\n    timings = np.zeros((repeats, len(models)), np.float64)\n    for rep in range(repeats):\n        for (m, model) in enumerate(models):\n            if device == 'cuda':\n                import triton\n                model(*example_inputs)\n                timings[rep, m] = triton.testing.do_bench(lambda : model(*example_inputs))\n            else:\n                from torch._inductor.utils import timed\n                timings[rep, m] = timed(model, example_inputs)\n    return np.median(timings, axis=0)",
            "def compute_speedups(operator, models, example_inputs, repeats, accuracy_checking=False, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    expected = models[0](*example_inputs)\n    if accuracy_checking:\n        for model in models[1:]:\n            actual = model(*example_inputs)\n            try:\n                same(actual, expected, cos_similarity=True, equal_nan=True)\n            except AssertionError as e:\n                print(e)\n                print(f'Accuracy check failed: {operator}')\n                print((expected[0] - actual[0]).abs().max())\n    timings = np.zeros((repeats, len(models)), np.float64)\n    for rep in range(repeats):\n        for (m, model) in enumerate(models):\n            if device == 'cuda':\n                import triton\n                model(*example_inputs)\n                timings[rep, m] = triton.testing.do_bench(lambda : model(*example_inputs))\n            else:\n                from torch._inductor.utils import timed\n                timings[rep, m] = timed(model, example_inputs)\n    return np.median(timings, axis=0)",
            "def compute_speedups(operator, models, example_inputs, repeats, accuracy_checking=False, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    expected = models[0](*example_inputs)\n    if accuracy_checking:\n        for model in models[1:]:\n            actual = model(*example_inputs)\n            try:\n                same(actual, expected, cos_similarity=True, equal_nan=True)\n            except AssertionError as e:\n                print(e)\n                print(f'Accuracy check failed: {operator}')\n                print((expected[0] - actual[0]).abs().max())\n    timings = np.zeros((repeats, len(models)), np.float64)\n    for rep in range(repeats):\n        for (m, model) in enumerate(models):\n            if device == 'cuda':\n                import triton\n                model(*example_inputs)\n                timings[rep, m] = triton.testing.do_bench(lambda : model(*example_inputs))\n            else:\n                from torch._inductor.utils import timed\n                timings[rep, m] = timed(model, example_inputs)\n    return np.median(timings, axis=0)",
            "def compute_speedups(operator, models, example_inputs, repeats, accuracy_checking=False, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    expected = models[0](*example_inputs)\n    if accuracy_checking:\n        for model in models[1:]:\n            actual = model(*example_inputs)\n            try:\n                same(actual, expected, cos_similarity=True, equal_nan=True)\n            except AssertionError as e:\n                print(e)\n                print(f'Accuracy check failed: {operator}')\n                print((expected[0] - actual[0]).abs().max())\n    timings = np.zeros((repeats, len(models)), np.float64)\n    for rep in range(repeats):\n        for (m, model) in enumerate(models):\n            if device == 'cuda':\n                import triton\n                model(*example_inputs)\n                timings[rep, m] = triton.testing.do_bench(lambda : model(*example_inputs))\n            else:\n                from torch._inductor.utils import timed\n                timings[rep, m] = timed(model, example_inputs)\n    return np.median(timings, axis=0)"
        ]
    },
    {
        "func_name": "strip_overloads",
        "original": "def strip_overloads(gm):\n    \"\"\"\n    Modifies the target of graph nodes in :attr:`gm` to strip overloads.\n    Args:\n        gm(fx.GraphModule): The input Fx graph module to be modified\n    \"\"\"\n    for node in gm.graph.nodes:\n        if isinstance(node.target, torch._ops.OpOverload):\n            node.target = node.target.overloadpacket\n    gm.recompile()",
        "mutated": [
            "def strip_overloads(gm):\n    if False:\n        i = 10\n    '\\n    Modifies the target of graph nodes in :attr:`gm` to strip overloads.\\n    Args:\\n        gm(fx.GraphModule): The input Fx graph module to be modified\\n    '\n    for node in gm.graph.nodes:\n        if isinstance(node.target, torch._ops.OpOverload):\n            node.target = node.target.overloadpacket\n    gm.recompile()",
            "def strip_overloads(gm):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Modifies the target of graph nodes in :attr:`gm` to strip overloads.\\n    Args:\\n        gm(fx.GraphModule): The input Fx graph module to be modified\\n    '\n    for node in gm.graph.nodes:\n        if isinstance(node.target, torch._ops.OpOverload):\n            node.target = node.target.overloadpacket\n    gm.recompile()",
            "def strip_overloads(gm):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Modifies the target of graph nodes in :attr:`gm` to strip overloads.\\n    Args:\\n        gm(fx.GraphModule): The input Fx graph module to be modified\\n    '\n    for node in gm.graph.nodes:\n        if isinstance(node.target, torch._ops.OpOverload):\n            node.target = node.target.overloadpacket\n    gm.recompile()",
            "def strip_overloads(gm):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Modifies the target of graph nodes in :attr:`gm` to strip overloads.\\n    Args:\\n        gm(fx.GraphModule): The input Fx graph module to be modified\\n    '\n    for node in gm.graph.nodes:\n        if isinstance(node.target, torch._ops.OpOverload):\n            node.target = node.target.overloadpacket\n    gm.recompile()",
            "def strip_overloads(gm):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Modifies the target of graph nodes in :attr:`gm` to strip overloads.\\n    Args:\\n        gm(fx.GraphModule): The input Fx graph module to be modified\\n    '\n    for node in gm.graph.nodes:\n        if isinstance(node.target, torch._ops.OpOverload):\n            node.target = node.target.overloadpacket\n    gm.recompile()"
        ]
    },
    {
        "func_name": "convert_to_jit",
        "original": "def convert_to_jit(gm, gm_args):\n    strip_overloads(gm)\n    try:\n        return torch.jit.script(gm)\n    except Exception:\n        pass\n    return torch.jit.trace(gm, gm_args)",
        "mutated": [
            "def convert_to_jit(gm, gm_args):\n    if False:\n        i = 10\n    strip_overloads(gm)\n    try:\n        return torch.jit.script(gm)\n    except Exception:\n        pass\n    return torch.jit.trace(gm, gm_args)",
            "def convert_to_jit(gm, gm_args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    strip_overloads(gm)\n    try:\n        return torch.jit.script(gm)\n    except Exception:\n        pass\n    return torch.jit.trace(gm, gm_args)",
            "def convert_to_jit(gm, gm_args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    strip_overloads(gm)\n    try:\n        return torch.jit.script(gm)\n    except Exception:\n        pass\n    return torch.jit.trace(gm, gm_args)",
            "def convert_to_jit(gm, gm_args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    strip_overloads(gm)\n    try:\n        return torch.jit.script(gm)\n    except Exception:\n        pass\n    return torch.jit.trace(gm, gm_args)",
            "def convert_to_jit(gm, gm_args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    strip_overloads(gm)\n    try:\n        return torch.jit.script(gm)\n    except Exception:\n        pass\n    return torch.jit.trace(gm, gm_args)"
        ]
    },
    {
        "func_name": "to_channels_last",
        "original": "def to_channels_last(ten):\n    return ten if ten.ndim != 4 else ten.to(memory_format=torch.channels_last)",
        "mutated": [
            "def to_channels_last(ten):\n    if False:\n        i = 10\n    return ten if ten.ndim != 4 else ten.to(memory_format=torch.channels_last)",
            "def to_channels_last(ten):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return ten if ten.ndim != 4 else ten.to(memory_format=torch.channels_last)",
            "def to_channels_last(ten):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return ten if ten.ndim != 4 else ten.to(memory_format=torch.channels_last)",
            "def to_channels_last(ten):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return ten if ten.ndim != 4 else ten.to(memory_format=torch.channels_last)",
            "def to_channels_last(ten):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return ten if ten.ndim != 4 else ten.to(memory_format=torch.channels_last)"
        ]
    },
    {
        "func_name": "microbenchmark",
        "original": "def microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device):\n    (gm, gm_args) = gen_gm_and_inputs(operator, args, kwargs)\n    torch.jit._builtins._register_builtin(torch.ops.aten.convolution_backward.default, 'aten::convolution_backward')\n    if device == 'cuda':\n        cudagraphs_eager = cudagraphs_inner(gm, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled_fn = compile_fx(gm, gm_args)\n        cudagraphs_compiled = cudagraphs_inner(compiled_fn, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled = [cudagraphs_eager, cudagraphs_compiled]\n    else:\n        compiled_fn = compile_fx(gm, gm_args)\n        compiled = [gm, compiled_fn]\n    if measure_nvfuser:\n        g = convert_to_jit(gm, gm_args)\n        cudagraphs_jit = cudagraphs_inner(g, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled += [cudagraphs_jit]\n    if accuracy_checking:\n        repeats = 1\n    medians = compute_speedups(operator, compiled, gm_args, repeats, accuracy_checking, device)\n    return medians",
        "mutated": [
            "def microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device):\n    if False:\n        i = 10\n    (gm, gm_args) = gen_gm_and_inputs(operator, args, kwargs)\n    torch.jit._builtins._register_builtin(torch.ops.aten.convolution_backward.default, 'aten::convolution_backward')\n    if device == 'cuda':\n        cudagraphs_eager = cudagraphs_inner(gm, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled_fn = compile_fx(gm, gm_args)\n        cudagraphs_compiled = cudagraphs_inner(compiled_fn, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled = [cudagraphs_eager, cudagraphs_compiled]\n    else:\n        compiled_fn = compile_fx(gm, gm_args)\n        compiled = [gm, compiled_fn]\n    if measure_nvfuser:\n        g = convert_to_jit(gm, gm_args)\n        cudagraphs_jit = cudagraphs_inner(g, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled += [cudagraphs_jit]\n    if accuracy_checking:\n        repeats = 1\n    medians = compute_speedups(operator, compiled, gm_args, repeats, accuracy_checking, device)\n    return medians",
            "def microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (gm, gm_args) = gen_gm_and_inputs(operator, args, kwargs)\n    torch.jit._builtins._register_builtin(torch.ops.aten.convolution_backward.default, 'aten::convolution_backward')\n    if device == 'cuda':\n        cudagraphs_eager = cudagraphs_inner(gm, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled_fn = compile_fx(gm, gm_args)\n        cudagraphs_compiled = cudagraphs_inner(compiled_fn, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled = [cudagraphs_eager, cudagraphs_compiled]\n    else:\n        compiled_fn = compile_fx(gm, gm_args)\n        compiled = [gm, compiled_fn]\n    if measure_nvfuser:\n        g = convert_to_jit(gm, gm_args)\n        cudagraphs_jit = cudagraphs_inner(g, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled += [cudagraphs_jit]\n    if accuracy_checking:\n        repeats = 1\n    medians = compute_speedups(operator, compiled, gm_args, repeats, accuracy_checking, device)\n    return medians",
            "def microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (gm, gm_args) = gen_gm_and_inputs(operator, args, kwargs)\n    torch.jit._builtins._register_builtin(torch.ops.aten.convolution_backward.default, 'aten::convolution_backward')\n    if device == 'cuda':\n        cudagraphs_eager = cudagraphs_inner(gm, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled_fn = compile_fx(gm, gm_args)\n        cudagraphs_compiled = cudagraphs_inner(compiled_fn, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled = [cudagraphs_eager, cudagraphs_compiled]\n    else:\n        compiled_fn = compile_fx(gm, gm_args)\n        compiled = [gm, compiled_fn]\n    if measure_nvfuser:\n        g = convert_to_jit(gm, gm_args)\n        cudagraphs_jit = cudagraphs_inner(g, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled += [cudagraphs_jit]\n    if accuracy_checking:\n        repeats = 1\n    medians = compute_speedups(operator, compiled, gm_args, repeats, accuracy_checking, device)\n    return medians",
            "def microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (gm, gm_args) = gen_gm_and_inputs(operator, args, kwargs)\n    torch.jit._builtins._register_builtin(torch.ops.aten.convolution_backward.default, 'aten::convolution_backward')\n    if device == 'cuda':\n        cudagraphs_eager = cudagraphs_inner(gm, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled_fn = compile_fx(gm, gm_args)\n        cudagraphs_compiled = cudagraphs_inner(compiled_fn, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled = [cudagraphs_eager, cudagraphs_compiled]\n    else:\n        compiled_fn = compile_fx(gm, gm_args)\n        compiled = [gm, compiled_fn]\n    if measure_nvfuser:\n        g = convert_to_jit(gm, gm_args)\n        cudagraphs_jit = cudagraphs_inner(g, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled += [cudagraphs_jit]\n    if accuracy_checking:\n        repeats = 1\n    medians = compute_speedups(operator, compiled, gm_args, repeats, accuracy_checking, device)\n    return medians",
            "def microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (gm, gm_args) = gen_gm_and_inputs(operator, args, kwargs)\n    torch.jit._builtins._register_builtin(torch.ops.aten.convolution_backward.default, 'aten::convolution_backward')\n    if device == 'cuda':\n        cudagraphs_eager = cudagraphs_inner(gm, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled_fn = compile_fx(gm, gm_args)\n        cudagraphs_compiled = cudagraphs_inner(compiled_fn, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled = [cudagraphs_eager, cudagraphs_compiled]\n    else:\n        compiled_fn = compile_fx(gm, gm_args)\n        compiled = [gm, compiled_fn]\n    if measure_nvfuser:\n        g = convert_to_jit(gm, gm_args)\n        cudagraphs_jit = cudagraphs_inner(g, gm_args, copy_outputs=False, copy_inputs=False)\n        compiled += [cudagraphs_jit]\n    if accuracy_checking:\n        repeats = 1\n    medians = compute_speedups(operator, compiled, gm_args, repeats, accuracy_checking, device)\n    return medians"
        ]
    },
    {
        "func_name": "skip_operator",
        "original": "def skip_operator(operator):\n    nyi_strings = ('aten.gather.default', 'nll_loss', 'aten.index', 'aten.scatter_', 'masked_fill_.Scalar')\n    if any((nyi_string in str(operator) for nyi_string in nyi_strings)):\n        print(f'Skipping {operator}, input generator nyi')\n        return True\n    if operator == torch.ops.aten._unsafe_view.default:\n        print(f'Skipping {operator}, non compute operator')\n        return True\n    op_impls = [operator]\n    if isinstance(operator, torch._ops.OpOverload):\n        op_impls.append(operator.overloadpacket)\n    if all((op not in decompositions and op not in lowerings for op in op_impls)):\n        print(f'Skipping {operator}, no inductor impl')\n        return True\n    if 'convolution' in str(operator):\n        return True\n    return False",
        "mutated": [
            "def skip_operator(operator):\n    if False:\n        i = 10\n    nyi_strings = ('aten.gather.default', 'nll_loss', 'aten.index', 'aten.scatter_', 'masked_fill_.Scalar')\n    if any((nyi_string in str(operator) for nyi_string in nyi_strings)):\n        print(f'Skipping {operator}, input generator nyi')\n        return True\n    if operator == torch.ops.aten._unsafe_view.default:\n        print(f'Skipping {operator}, non compute operator')\n        return True\n    op_impls = [operator]\n    if isinstance(operator, torch._ops.OpOverload):\n        op_impls.append(operator.overloadpacket)\n    if all((op not in decompositions and op not in lowerings for op in op_impls)):\n        print(f'Skipping {operator}, no inductor impl')\n        return True\n    if 'convolution' in str(operator):\n        return True\n    return False",
            "def skip_operator(operator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    nyi_strings = ('aten.gather.default', 'nll_loss', 'aten.index', 'aten.scatter_', 'masked_fill_.Scalar')\n    if any((nyi_string in str(operator) for nyi_string in nyi_strings)):\n        print(f'Skipping {operator}, input generator nyi')\n        return True\n    if operator == torch.ops.aten._unsafe_view.default:\n        print(f'Skipping {operator}, non compute operator')\n        return True\n    op_impls = [operator]\n    if isinstance(operator, torch._ops.OpOverload):\n        op_impls.append(operator.overloadpacket)\n    if all((op not in decompositions and op not in lowerings for op in op_impls)):\n        print(f'Skipping {operator}, no inductor impl')\n        return True\n    if 'convolution' in str(operator):\n        return True\n    return False",
            "def skip_operator(operator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    nyi_strings = ('aten.gather.default', 'nll_loss', 'aten.index', 'aten.scatter_', 'masked_fill_.Scalar')\n    if any((nyi_string in str(operator) for nyi_string in nyi_strings)):\n        print(f'Skipping {operator}, input generator nyi')\n        return True\n    if operator == torch.ops.aten._unsafe_view.default:\n        print(f'Skipping {operator}, non compute operator')\n        return True\n    op_impls = [operator]\n    if isinstance(operator, torch._ops.OpOverload):\n        op_impls.append(operator.overloadpacket)\n    if all((op not in decompositions and op not in lowerings for op in op_impls)):\n        print(f'Skipping {operator}, no inductor impl')\n        return True\n    if 'convolution' in str(operator):\n        return True\n    return False",
            "def skip_operator(operator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    nyi_strings = ('aten.gather.default', 'nll_loss', 'aten.index', 'aten.scatter_', 'masked_fill_.Scalar')\n    if any((nyi_string in str(operator) for nyi_string in nyi_strings)):\n        print(f'Skipping {operator}, input generator nyi')\n        return True\n    if operator == torch.ops.aten._unsafe_view.default:\n        print(f'Skipping {operator}, non compute operator')\n        return True\n    op_impls = [operator]\n    if isinstance(operator, torch._ops.OpOverload):\n        op_impls.append(operator.overloadpacket)\n    if all((op not in decompositions and op not in lowerings for op in op_impls)):\n        print(f'Skipping {operator}, no inductor impl')\n        return True\n    if 'convolution' in str(operator):\n        return True\n    return False",
            "def skip_operator(operator):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    nyi_strings = ('aten.gather.default', 'nll_loss', 'aten.index', 'aten.scatter_', 'masked_fill_.Scalar')\n    if any((nyi_string in str(operator) for nyi_string in nyi_strings)):\n        print(f'Skipping {operator}, input generator nyi')\n        return True\n    if operator == torch.ops.aten._unsafe_view.default:\n        print(f'Skipping {operator}, non compute operator')\n        return True\n    op_impls = [operator]\n    if isinstance(operator, torch._ops.OpOverload):\n        op_impls.append(operator.overloadpacket)\n    if all((op not in decompositions and op not in lowerings for op in op_impls)):\n        print(f'Skipping {operator}, no inductor impl')\n        return True\n    if 'convolution' in str(operator):\n        return True\n    return False"
        ]
    },
    {
        "func_name": "benchmark",
        "original": "@click.command()\n@click.option('--suite', help='suite to load inps from: options: timm, huggingface, torchbench', default='torchbench')\n@click.option('--op', help='operator overload to benchmark')\n@click.option('--dtype', help='dtype to benchmark')\n@click.option('--max-samples', help='max samples per op', default=15)\n@click.option('--accuracy-checking', help='check accuracy', default=False)\n@click.option('--repeats', help='how many times to repeat for perf measurement', default=3)\n@click.option('--measure-nvfuser', help='default we only measure inductor', default=False)\n@click.option('--device', help='cpu or cuda', default='cuda')\n@click.option('--inp-file', help='use custom input file instead of suite', default=None)\n@click.option('--start-idx', help='specify start index of samples', default=0)\n@click.option('--channels-last', help='force inputs to channels last', is_flag=True, default=False)\ndef benchmark(suite, op, dtype, max_samples, accuracy_checking, repeats, measure_nvfuser, device, inp_file, start_idx, channels_last):\n    if inp_file is not None:\n        loader = OperatorInputsLoader(inp_file)\n    else:\n        assert suite in ('timm', 'huggingface', 'torchbench'), f'got {suite}'\n        if suite == 'timm':\n            loader = OperatorInputsLoader.get_timm_loader()\n        elif suite == 'huggingface':\n            loader = OperatorInputsLoader.get_huggingface_loader()\n        else:\n            loader = OperatorInputsLoader.get_torchbench_loader()\n    assert dtype in ('float16', 'float32'), f'got {dtype}'\n    if op == 'all':\n        filename = f\"timings_{suite}_{op.replace('.', '_')}{dtype}.txt\"\n        f = open(filename, 'a')\n    dtype = torch.float16 if dtype == 'float16' else torch.float32\n    if op == 'all':\n        ops = loader.get_all_ops()\n    else:\n        ops = [eval(op)]\n    max_samples = max_samples + start_idx\n    for operator in ops:\n        if skip_operator(operator):\n            continue\n        print(f'Running {operator}')\n        inp_gen = loader.get_inputs_for_operator(operator, dtype=dtype, device=device)\n        timings = []\n        for i in range(min(max_samples, 1000000)):\n            try:\n                inps = next(inp_gen)\n                if inps is None:\n                    break\n                if i < start_idx:\n                    continue\n                print(f'Iter {i}')\n                (args, kwargs) = inps\n                if channels_last:\n                    (args, kwargs) = tree_map_only(torch.Tensor, to_channels_last, (args, kwargs))\n            except StopIteration:\n                break\n            try:\n                timings.append(microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device))\n            except Exception as e:\n                print(f'error {operator}')\n                print(e)\n        if not timings:\n            continue\n        timings = torch.tensor(timings).T\n        q = torch.tensor([0.2, 0.5, 0.8], dtype=torch.float64)\n        output = f'{operator}:\\nInductor Speedups : {torch.quantile(timings[0] / timings[1], q).tolist()}\\n'\n        if measure_nvfuser:\n            output += f'NVFUSER Speedups :{torch.quantile(timings[0] / timings[2], q).tolist()}\\n'\n        if op == 'all':\n            f.write(output)\n        print(output)\n    if op == 'all':\n        f.close()",
        "mutated": [
            "@click.command()\n@click.option('--suite', help='suite to load inps from: options: timm, huggingface, torchbench', default='torchbench')\n@click.option('--op', help='operator overload to benchmark')\n@click.option('--dtype', help='dtype to benchmark')\n@click.option('--max-samples', help='max samples per op', default=15)\n@click.option('--accuracy-checking', help='check accuracy', default=False)\n@click.option('--repeats', help='how many times to repeat for perf measurement', default=3)\n@click.option('--measure-nvfuser', help='default we only measure inductor', default=False)\n@click.option('--device', help='cpu or cuda', default='cuda')\n@click.option('--inp-file', help='use custom input file instead of suite', default=None)\n@click.option('--start-idx', help='specify start index of samples', default=0)\n@click.option('--channels-last', help='force inputs to channels last', is_flag=True, default=False)\ndef benchmark(suite, op, dtype, max_samples, accuracy_checking, repeats, measure_nvfuser, device, inp_file, start_idx, channels_last):\n    if False:\n        i = 10\n    if inp_file is not None:\n        loader = OperatorInputsLoader(inp_file)\n    else:\n        assert suite in ('timm', 'huggingface', 'torchbench'), f'got {suite}'\n        if suite == 'timm':\n            loader = OperatorInputsLoader.get_timm_loader()\n        elif suite == 'huggingface':\n            loader = OperatorInputsLoader.get_huggingface_loader()\n        else:\n            loader = OperatorInputsLoader.get_torchbench_loader()\n    assert dtype in ('float16', 'float32'), f'got {dtype}'\n    if op == 'all':\n        filename = f\"timings_{suite}_{op.replace('.', '_')}{dtype}.txt\"\n        f = open(filename, 'a')\n    dtype = torch.float16 if dtype == 'float16' else torch.float32\n    if op == 'all':\n        ops = loader.get_all_ops()\n    else:\n        ops = [eval(op)]\n    max_samples = max_samples + start_idx\n    for operator in ops:\n        if skip_operator(operator):\n            continue\n        print(f'Running {operator}')\n        inp_gen = loader.get_inputs_for_operator(operator, dtype=dtype, device=device)\n        timings = []\n        for i in range(min(max_samples, 1000000)):\n            try:\n                inps = next(inp_gen)\n                if inps is None:\n                    break\n                if i < start_idx:\n                    continue\n                print(f'Iter {i}')\n                (args, kwargs) = inps\n                if channels_last:\n                    (args, kwargs) = tree_map_only(torch.Tensor, to_channels_last, (args, kwargs))\n            except StopIteration:\n                break\n            try:\n                timings.append(microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device))\n            except Exception as e:\n                print(f'error {operator}')\n                print(e)\n        if not timings:\n            continue\n        timings = torch.tensor(timings).T\n        q = torch.tensor([0.2, 0.5, 0.8], dtype=torch.float64)\n        output = f'{operator}:\\nInductor Speedups : {torch.quantile(timings[0] / timings[1], q).tolist()}\\n'\n        if measure_nvfuser:\n            output += f'NVFUSER Speedups :{torch.quantile(timings[0] / timings[2], q).tolist()}\\n'\n        if op == 'all':\n            f.write(output)\n        print(output)\n    if op == 'all':\n        f.close()",
            "@click.command()\n@click.option('--suite', help='suite to load inps from: options: timm, huggingface, torchbench', default='torchbench')\n@click.option('--op', help='operator overload to benchmark')\n@click.option('--dtype', help='dtype to benchmark')\n@click.option('--max-samples', help='max samples per op', default=15)\n@click.option('--accuracy-checking', help='check accuracy', default=False)\n@click.option('--repeats', help='how many times to repeat for perf measurement', default=3)\n@click.option('--measure-nvfuser', help='default we only measure inductor', default=False)\n@click.option('--device', help='cpu or cuda', default='cuda')\n@click.option('--inp-file', help='use custom input file instead of suite', default=None)\n@click.option('--start-idx', help='specify start index of samples', default=0)\n@click.option('--channels-last', help='force inputs to channels last', is_flag=True, default=False)\ndef benchmark(suite, op, dtype, max_samples, accuracy_checking, repeats, measure_nvfuser, device, inp_file, start_idx, channels_last):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if inp_file is not None:\n        loader = OperatorInputsLoader(inp_file)\n    else:\n        assert suite in ('timm', 'huggingface', 'torchbench'), f'got {suite}'\n        if suite == 'timm':\n            loader = OperatorInputsLoader.get_timm_loader()\n        elif suite == 'huggingface':\n            loader = OperatorInputsLoader.get_huggingface_loader()\n        else:\n            loader = OperatorInputsLoader.get_torchbench_loader()\n    assert dtype in ('float16', 'float32'), f'got {dtype}'\n    if op == 'all':\n        filename = f\"timings_{suite}_{op.replace('.', '_')}{dtype}.txt\"\n        f = open(filename, 'a')\n    dtype = torch.float16 if dtype == 'float16' else torch.float32\n    if op == 'all':\n        ops = loader.get_all_ops()\n    else:\n        ops = [eval(op)]\n    max_samples = max_samples + start_idx\n    for operator in ops:\n        if skip_operator(operator):\n            continue\n        print(f'Running {operator}')\n        inp_gen = loader.get_inputs_for_operator(operator, dtype=dtype, device=device)\n        timings = []\n        for i in range(min(max_samples, 1000000)):\n            try:\n                inps = next(inp_gen)\n                if inps is None:\n                    break\n                if i < start_idx:\n                    continue\n                print(f'Iter {i}')\n                (args, kwargs) = inps\n                if channels_last:\n                    (args, kwargs) = tree_map_only(torch.Tensor, to_channels_last, (args, kwargs))\n            except StopIteration:\n                break\n            try:\n                timings.append(microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device))\n            except Exception as e:\n                print(f'error {operator}')\n                print(e)\n        if not timings:\n            continue\n        timings = torch.tensor(timings).T\n        q = torch.tensor([0.2, 0.5, 0.8], dtype=torch.float64)\n        output = f'{operator}:\\nInductor Speedups : {torch.quantile(timings[0] / timings[1], q).tolist()}\\n'\n        if measure_nvfuser:\n            output += f'NVFUSER Speedups :{torch.quantile(timings[0] / timings[2], q).tolist()}\\n'\n        if op == 'all':\n            f.write(output)\n        print(output)\n    if op == 'all':\n        f.close()",
            "@click.command()\n@click.option('--suite', help='suite to load inps from: options: timm, huggingface, torchbench', default='torchbench')\n@click.option('--op', help='operator overload to benchmark')\n@click.option('--dtype', help='dtype to benchmark')\n@click.option('--max-samples', help='max samples per op', default=15)\n@click.option('--accuracy-checking', help='check accuracy', default=False)\n@click.option('--repeats', help='how many times to repeat for perf measurement', default=3)\n@click.option('--measure-nvfuser', help='default we only measure inductor', default=False)\n@click.option('--device', help='cpu or cuda', default='cuda')\n@click.option('--inp-file', help='use custom input file instead of suite', default=None)\n@click.option('--start-idx', help='specify start index of samples', default=0)\n@click.option('--channels-last', help='force inputs to channels last', is_flag=True, default=False)\ndef benchmark(suite, op, dtype, max_samples, accuracy_checking, repeats, measure_nvfuser, device, inp_file, start_idx, channels_last):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if inp_file is not None:\n        loader = OperatorInputsLoader(inp_file)\n    else:\n        assert suite in ('timm', 'huggingface', 'torchbench'), f'got {suite}'\n        if suite == 'timm':\n            loader = OperatorInputsLoader.get_timm_loader()\n        elif suite == 'huggingface':\n            loader = OperatorInputsLoader.get_huggingface_loader()\n        else:\n            loader = OperatorInputsLoader.get_torchbench_loader()\n    assert dtype in ('float16', 'float32'), f'got {dtype}'\n    if op == 'all':\n        filename = f\"timings_{suite}_{op.replace('.', '_')}{dtype}.txt\"\n        f = open(filename, 'a')\n    dtype = torch.float16 if dtype == 'float16' else torch.float32\n    if op == 'all':\n        ops = loader.get_all_ops()\n    else:\n        ops = [eval(op)]\n    max_samples = max_samples + start_idx\n    for operator in ops:\n        if skip_operator(operator):\n            continue\n        print(f'Running {operator}')\n        inp_gen = loader.get_inputs_for_operator(operator, dtype=dtype, device=device)\n        timings = []\n        for i in range(min(max_samples, 1000000)):\n            try:\n                inps = next(inp_gen)\n                if inps is None:\n                    break\n                if i < start_idx:\n                    continue\n                print(f'Iter {i}')\n                (args, kwargs) = inps\n                if channels_last:\n                    (args, kwargs) = tree_map_only(torch.Tensor, to_channels_last, (args, kwargs))\n            except StopIteration:\n                break\n            try:\n                timings.append(microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device))\n            except Exception as e:\n                print(f'error {operator}')\n                print(e)\n        if not timings:\n            continue\n        timings = torch.tensor(timings).T\n        q = torch.tensor([0.2, 0.5, 0.8], dtype=torch.float64)\n        output = f'{operator}:\\nInductor Speedups : {torch.quantile(timings[0] / timings[1], q).tolist()}\\n'\n        if measure_nvfuser:\n            output += f'NVFUSER Speedups :{torch.quantile(timings[0] / timings[2], q).tolist()}\\n'\n        if op == 'all':\n            f.write(output)\n        print(output)\n    if op == 'all':\n        f.close()",
            "@click.command()\n@click.option('--suite', help='suite to load inps from: options: timm, huggingface, torchbench', default='torchbench')\n@click.option('--op', help='operator overload to benchmark')\n@click.option('--dtype', help='dtype to benchmark')\n@click.option('--max-samples', help='max samples per op', default=15)\n@click.option('--accuracy-checking', help='check accuracy', default=False)\n@click.option('--repeats', help='how many times to repeat for perf measurement', default=3)\n@click.option('--measure-nvfuser', help='default we only measure inductor', default=False)\n@click.option('--device', help='cpu or cuda', default='cuda')\n@click.option('--inp-file', help='use custom input file instead of suite', default=None)\n@click.option('--start-idx', help='specify start index of samples', default=0)\n@click.option('--channels-last', help='force inputs to channels last', is_flag=True, default=False)\ndef benchmark(suite, op, dtype, max_samples, accuracy_checking, repeats, measure_nvfuser, device, inp_file, start_idx, channels_last):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if inp_file is not None:\n        loader = OperatorInputsLoader(inp_file)\n    else:\n        assert suite in ('timm', 'huggingface', 'torchbench'), f'got {suite}'\n        if suite == 'timm':\n            loader = OperatorInputsLoader.get_timm_loader()\n        elif suite == 'huggingface':\n            loader = OperatorInputsLoader.get_huggingface_loader()\n        else:\n            loader = OperatorInputsLoader.get_torchbench_loader()\n    assert dtype in ('float16', 'float32'), f'got {dtype}'\n    if op == 'all':\n        filename = f\"timings_{suite}_{op.replace('.', '_')}{dtype}.txt\"\n        f = open(filename, 'a')\n    dtype = torch.float16 if dtype == 'float16' else torch.float32\n    if op == 'all':\n        ops = loader.get_all_ops()\n    else:\n        ops = [eval(op)]\n    max_samples = max_samples + start_idx\n    for operator in ops:\n        if skip_operator(operator):\n            continue\n        print(f'Running {operator}')\n        inp_gen = loader.get_inputs_for_operator(operator, dtype=dtype, device=device)\n        timings = []\n        for i in range(min(max_samples, 1000000)):\n            try:\n                inps = next(inp_gen)\n                if inps is None:\n                    break\n                if i < start_idx:\n                    continue\n                print(f'Iter {i}')\n                (args, kwargs) = inps\n                if channels_last:\n                    (args, kwargs) = tree_map_only(torch.Tensor, to_channels_last, (args, kwargs))\n            except StopIteration:\n                break\n            try:\n                timings.append(microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device))\n            except Exception as e:\n                print(f'error {operator}')\n                print(e)\n        if not timings:\n            continue\n        timings = torch.tensor(timings).T\n        q = torch.tensor([0.2, 0.5, 0.8], dtype=torch.float64)\n        output = f'{operator}:\\nInductor Speedups : {torch.quantile(timings[0] / timings[1], q).tolist()}\\n'\n        if measure_nvfuser:\n            output += f'NVFUSER Speedups :{torch.quantile(timings[0] / timings[2], q).tolist()}\\n'\n        if op == 'all':\n            f.write(output)\n        print(output)\n    if op == 'all':\n        f.close()",
            "@click.command()\n@click.option('--suite', help='suite to load inps from: options: timm, huggingface, torchbench', default='torchbench')\n@click.option('--op', help='operator overload to benchmark')\n@click.option('--dtype', help='dtype to benchmark')\n@click.option('--max-samples', help='max samples per op', default=15)\n@click.option('--accuracy-checking', help='check accuracy', default=False)\n@click.option('--repeats', help='how many times to repeat for perf measurement', default=3)\n@click.option('--measure-nvfuser', help='default we only measure inductor', default=False)\n@click.option('--device', help='cpu or cuda', default='cuda')\n@click.option('--inp-file', help='use custom input file instead of suite', default=None)\n@click.option('--start-idx', help='specify start index of samples', default=0)\n@click.option('--channels-last', help='force inputs to channels last', is_flag=True, default=False)\ndef benchmark(suite, op, dtype, max_samples, accuracy_checking, repeats, measure_nvfuser, device, inp_file, start_idx, channels_last):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if inp_file is not None:\n        loader = OperatorInputsLoader(inp_file)\n    else:\n        assert suite in ('timm', 'huggingface', 'torchbench'), f'got {suite}'\n        if suite == 'timm':\n            loader = OperatorInputsLoader.get_timm_loader()\n        elif suite == 'huggingface':\n            loader = OperatorInputsLoader.get_huggingface_loader()\n        else:\n            loader = OperatorInputsLoader.get_torchbench_loader()\n    assert dtype in ('float16', 'float32'), f'got {dtype}'\n    if op == 'all':\n        filename = f\"timings_{suite}_{op.replace('.', '_')}{dtype}.txt\"\n        f = open(filename, 'a')\n    dtype = torch.float16 if dtype == 'float16' else torch.float32\n    if op == 'all':\n        ops = loader.get_all_ops()\n    else:\n        ops = [eval(op)]\n    max_samples = max_samples + start_idx\n    for operator in ops:\n        if skip_operator(operator):\n            continue\n        print(f'Running {operator}')\n        inp_gen = loader.get_inputs_for_operator(operator, dtype=dtype, device=device)\n        timings = []\n        for i in range(min(max_samples, 1000000)):\n            try:\n                inps = next(inp_gen)\n                if inps is None:\n                    break\n                if i < start_idx:\n                    continue\n                print(f'Iter {i}')\n                (args, kwargs) = inps\n                if channels_last:\n                    (args, kwargs) = tree_map_only(torch.Tensor, to_channels_last, (args, kwargs))\n            except StopIteration:\n                break\n            try:\n                timings.append(microbenchmark(operator, args, kwargs, dtype, accuracy_checking, repeats, measure_nvfuser, device))\n            except Exception as e:\n                print(f'error {operator}')\n                print(e)\n        if not timings:\n            continue\n        timings = torch.tensor(timings).T\n        q = torch.tensor([0.2, 0.5, 0.8], dtype=torch.float64)\n        output = f'{operator}:\\nInductor Speedups : {torch.quantile(timings[0] / timings[1], q).tolist()}\\n'\n        if measure_nvfuser:\n            output += f'NVFUSER Speedups :{torch.quantile(timings[0] / timings[2], q).tolist()}\\n'\n        if op == 'all':\n            f.write(output)\n        print(output)\n    if op == 'all':\n        f.close()"
        ]
    }
]