[
    {
        "func_name": "__init__",
        "original": "def __init__(self, beam_size, model, eos_token_id, go_token_id=seq2seq_util.GO_ID, post_eos_penalty=None):\n    self.beam_size = beam_size\n    self.model = model\n    self.step_model = Seq2SeqModelHelper(name='step_model', param_model=self.model)\n    self.go_token_id = go_token_id\n    self.eos_token_id = eos_token_id\n    self.post_eos_penalty = post_eos_penalty\n    (self.timestep, self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev) = self.step_model.net.AddExternalInputs('timestep', 'scores_t_prev', 'tokens_t_prev', 'hypo_t_prev', 'attention_t_prev')\n    tokens_t_prev_int32 = self.step_model.net.Cast(self.tokens_t_prev, 'tokens_t_prev_int32', to=core.DataType.INT32)\n    (self.tokens_t_prev_int32_flattened, _) = self.step_model.net.Reshape([tokens_t_prev_int32], [tokens_t_prev_int32, 'input_t_int32_old_shape'], shape=[1, -1])",
        "mutated": [
            "def __init__(self, beam_size, model, eos_token_id, go_token_id=seq2seq_util.GO_ID, post_eos_penalty=None):\n    if False:\n        i = 10\n    self.beam_size = beam_size\n    self.model = model\n    self.step_model = Seq2SeqModelHelper(name='step_model', param_model=self.model)\n    self.go_token_id = go_token_id\n    self.eos_token_id = eos_token_id\n    self.post_eos_penalty = post_eos_penalty\n    (self.timestep, self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev) = self.step_model.net.AddExternalInputs('timestep', 'scores_t_prev', 'tokens_t_prev', 'hypo_t_prev', 'attention_t_prev')\n    tokens_t_prev_int32 = self.step_model.net.Cast(self.tokens_t_prev, 'tokens_t_prev_int32', to=core.DataType.INT32)\n    (self.tokens_t_prev_int32_flattened, _) = self.step_model.net.Reshape([tokens_t_prev_int32], [tokens_t_prev_int32, 'input_t_int32_old_shape'], shape=[1, -1])",
            "def __init__(self, beam_size, model, eos_token_id, go_token_id=seq2seq_util.GO_ID, post_eos_penalty=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.beam_size = beam_size\n    self.model = model\n    self.step_model = Seq2SeqModelHelper(name='step_model', param_model=self.model)\n    self.go_token_id = go_token_id\n    self.eos_token_id = eos_token_id\n    self.post_eos_penalty = post_eos_penalty\n    (self.timestep, self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev) = self.step_model.net.AddExternalInputs('timestep', 'scores_t_prev', 'tokens_t_prev', 'hypo_t_prev', 'attention_t_prev')\n    tokens_t_prev_int32 = self.step_model.net.Cast(self.tokens_t_prev, 'tokens_t_prev_int32', to=core.DataType.INT32)\n    (self.tokens_t_prev_int32_flattened, _) = self.step_model.net.Reshape([tokens_t_prev_int32], [tokens_t_prev_int32, 'input_t_int32_old_shape'], shape=[1, -1])",
            "def __init__(self, beam_size, model, eos_token_id, go_token_id=seq2seq_util.GO_ID, post_eos_penalty=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.beam_size = beam_size\n    self.model = model\n    self.step_model = Seq2SeqModelHelper(name='step_model', param_model=self.model)\n    self.go_token_id = go_token_id\n    self.eos_token_id = eos_token_id\n    self.post_eos_penalty = post_eos_penalty\n    (self.timestep, self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev) = self.step_model.net.AddExternalInputs('timestep', 'scores_t_prev', 'tokens_t_prev', 'hypo_t_prev', 'attention_t_prev')\n    tokens_t_prev_int32 = self.step_model.net.Cast(self.tokens_t_prev, 'tokens_t_prev_int32', to=core.DataType.INT32)\n    (self.tokens_t_prev_int32_flattened, _) = self.step_model.net.Reshape([tokens_t_prev_int32], [tokens_t_prev_int32, 'input_t_int32_old_shape'], shape=[1, -1])",
            "def __init__(self, beam_size, model, eos_token_id, go_token_id=seq2seq_util.GO_ID, post_eos_penalty=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.beam_size = beam_size\n    self.model = model\n    self.step_model = Seq2SeqModelHelper(name='step_model', param_model=self.model)\n    self.go_token_id = go_token_id\n    self.eos_token_id = eos_token_id\n    self.post_eos_penalty = post_eos_penalty\n    (self.timestep, self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev) = self.step_model.net.AddExternalInputs('timestep', 'scores_t_prev', 'tokens_t_prev', 'hypo_t_prev', 'attention_t_prev')\n    tokens_t_prev_int32 = self.step_model.net.Cast(self.tokens_t_prev, 'tokens_t_prev_int32', to=core.DataType.INT32)\n    (self.tokens_t_prev_int32_flattened, _) = self.step_model.net.Reshape([tokens_t_prev_int32], [tokens_t_prev_int32, 'input_t_int32_old_shape'], shape=[1, -1])",
            "def __init__(self, beam_size, model, eos_token_id, go_token_id=seq2seq_util.GO_ID, post_eos_penalty=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.beam_size = beam_size\n    self.model = model\n    self.step_model = Seq2SeqModelHelper(name='step_model', param_model=self.model)\n    self.go_token_id = go_token_id\n    self.eos_token_id = eos_token_id\n    self.post_eos_penalty = post_eos_penalty\n    (self.timestep, self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev) = self.step_model.net.AddExternalInputs('timestep', 'scores_t_prev', 'tokens_t_prev', 'hypo_t_prev', 'attention_t_prev')\n    tokens_t_prev_int32 = self.step_model.net.Cast(self.tokens_t_prev, 'tokens_t_prev_int32', to=core.DataType.INT32)\n    (self.tokens_t_prev_int32_flattened, _) = self.step_model.net.Reshape([tokens_t_prev_int32], [tokens_t_prev_int32, 'input_t_int32_old_shape'], shape=[1, -1])"
        ]
    },
    {
        "func_name": "get_step_model",
        "original": "def get_step_model(self):\n    return self.step_model",
        "mutated": [
            "def get_step_model(self):\n    if False:\n        i = 10\n    return self.step_model",
            "def get_step_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.step_model",
            "def get_step_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.step_model",
            "def get_step_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.step_model",
            "def get_step_model(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.step_model"
        ]
    },
    {
        "func_name": "get_previous_tokens",
        "original": "def get_previous_tokens(self):\n    return self.tokens_t_prev_int32_flattened",
        "mutated": [
            "def get_previous_tokens(self):\n    if False:\n        i = 10\n    return self.tokens_t_prev_int32_flattened",
            "def get_previous_tokens(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.tokens_t_prev_int32_flattened",
            "def get_previous_tokens(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.tokens_t_prev_int32_flattened",
            "def get_previous_tokens(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.tokens_t_prev_int32_flattened",
            "def get_previous_tokens(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.tokens_t_prev_int32_flattened"
        ]
    },
    {
        "func_name": "get_timestep",
        "original": "def get_timestep(self):\n    return self.timestep",
        "mutated": [
            "def get_timestep(self):\n    if False:\n        i = 10\n    return self.timestep",
            "def get_timestep(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.timestep",
            "def get_timestep(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.timestep",
            "def get_timestep(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.timestep",
            "def get_timestep(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.timestep"
        ]
    },
    {
        "func_name": "choose_state_per_hypo",
        "original": "def choose_state_per_hypo(state_config):\n    (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n    state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n    return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))",
        "mutated": [
            "def choose_state_per_hypo(state_config):\n    if False:\n        i = 10\n    (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n    state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n    return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))",
            "def choose_state_per_hypo(state_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n    state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n    return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))",
            "def choose_state_per_hypo(state_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n    state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n    return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))",
            "def choose_state_per_hypo(state_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n    state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n    return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))",
            "def choose_state_per_hypo(state_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n    state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n    return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))"
        ]
    },
    {
        "func_name": "apply",
        "original": "def apply(self, inputs, length, log_probs, attentions, state_configs, data_dependencies, word_rewards=None, possible_translation_tokens=None, go_token_id=None):\n    ZERO = self.model.param_init_net.ConstantFill([], 'ZERO', shape=[1], value=0, dtype=core.DataType.INT32)\n    on_initial_step = self.step_model.net.EQ([ZERO, self.timestep], 'on_initial_step')\n    if self.post_eos_penalty is not None:\n        eos_token = self.model.param_init_net.ConstantFill([], 'eos_token', shape=[self.beam_size], value=self.eos_token_id, dtype=core.DataType.INT32)\n        finished_penalty = self.model.param_init_net.ConstantFill([], 'finished_penalty', shape=[1], value=float(self.post_eos_penalty), dtype=core.DataType.FLOAT)\n        ZERO_FLOAT = self.model.param_init_net.ConstantFill([], 'ZERO_FLOAT', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n        finished_penalty = self.step_model.net.Conditional([on_initial_step, ZERO_FLOAT, finished_penalty], 'possible_finished_penalty')\n        tokens_t_flat = self.step_model.net.FlattenToVec(self.tokens_t_prev, 'tokens_t_flat')\n        tokens_t_flat_int = self.step_model.net.Cast(tokens_t_flat, 'tokens_t_flat_int', to=core.DataType.INT32)\n        predecessor_is_eos = self.step_model.net.EQ([tokens_t_flat_int, eos_token], 'predecessor_is_eos')\n        predecessor_is_eos_float = self.step_model.net.Cast(predecessor_is_eos, 'predecessor_is_eos_float', to=core.DataType.FLOAT)\n        predecessor_is_eos_penalty = self.step_model.net.Mul([predecessor_is_eos_float, finished_penalty], 'predecessor_is_eos_penalty', broadcast=1)\n        log_probs = self.step_model.net.Add([log_probs, predecessor_is_eos_penalty], 'log_probs_penalized', broadcast=1, axis=0)\n    (best_scores_per_hypo, best_tokens_per_hypo) = self.step_model.net.TopK(log_probs, ['best_scores_per_hypo', 'best_tokens_per_hypo_indices'], k=self.beam_size)\n    if possible_translation_tokens:\n        best_tokens_per_hypo = self.step_model.net.Gather([possible_translation_tokens, best_tokens_per_hypo], ['best_tokens_per_hypo'])\n    (scores_t_prev_squeezed, _) = self.step_model.net.Reshape(self.scores_t_prev, ['scores_t_prev_squeezed', 'scores_t_prev_old_shape'], shape=[self.beam_size])\n    output_scores = self.step_model.net.Add([best_scores_per_hypo, scores_t_prev_squeezed], 'output_scores', broadcast=1, axis=0)\n    if word_rewards is not None:\n        word_rewards_for_best_tokens_per_hypo = self.step_model.net.Gather([word_rewards, best_tokens_per_hypo], 'word_rewards_for_best_tokens_per_hypo')\n        output_scores = self.step_model.net.Add([output_scores, word_rewards_for_best_tokens_per_hypo], 'output_scores')\n    (output_scores_flattened, _) = self.step_model.net.Reshape([output_scores], [output_scores, 'output_scores_old_shape'], shape=[-1])\n    MINUS_ONE_INT32 = self.model.param_init_net.ConstantFill([], 'MINUS_ONE_INT32', value=-1, shape=[1], dtype=core.DataType.INT32)\n    BEAM_SIZE = self.model.param_init_net.ConstantFill([], 'beam_size', shape=[1], value=self.beam_size, dtype=core.DataType.INT32)\n    slice_end = self.step_model.net.Conditional([on_initial_step, BEAM_SIZE, MINUS_ONE_INT32], ['slice_end'])\n    output_scores_flattened_slice = self.step_model.net.Slice([output_scores_flattened, ZERO, slice_end], 'output_scores_flattened_slice')\n    (output_scores_flattened_slice, _) = self.step_model.net.Reshape(output_scores_flattened_slice, [output_scores_flattened_slice, 'output_scores_flattened_slice_old_shape'], shape=[1, -1])\n    (scores_t, best_indices) = self.step_model.net.TopK(output_scores_flattened_slice, ['scores_t', 'best_indices'], k=self.beam_size)\n    BEAM_SIZE_64 = self.model.param_init_net.Cast(BEAM_SIZE, 'BEAM_SIZE_64', to=core.DataType.INT64)\n    hypo_t_int32 = self.step_model.net.Div([best_indices, BEAM_SIZE_64], 'hypo_t_int32', broadcast=1)\n    hypo_t = self.step_model.net.Cast(hypo_t_int32, 'hypo_t', to=core.DataType.FLOAT)\n    attention_t = self.step_model.net.Gather([attentions, hypo_t_int32], 'attention_t')\n    (attention_t, _) = self.step_model.net.Reshape(attention_t, [attention_t, 'attention_t_old_shape'], shape=[1, self.beam_size, -1])\n    (best_tokens_per_hypo_flatten, _) = self.step_model.net.Reshape(best_tokens_per_hypo, ['best_tokens_per_hypo_flatten', 'best_tokens_per_hypo_old_shape'], shape=[-1])\n    tokens_t_int32 = self.step_model.net.Gather([best_tokens_per_hypo_flatten, best_indices], 'tokens_t_int32')\n    tokens_t = self.step_model.net.Cast(tokens_t_int32, 'tokens_t', to=core.DataType.FLOAT)\n\n    def choose_state_per_hypo(state_config):\n        (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n        state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n        return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))\n    state_configs = [choose_state_per_hypo(c) for c in state_configs]\n    initial_scores = self.model.param_init_net.ConstantFill([], 'initial_scores', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    if go_token_id:\n        initial_tokens = self.model.net.Copy([go_token_id], 'initial_tokens')\n    else:\n        initial_tokens = self.model.param_init_net.ConstantFill([], 'initial_tokens', shape=[1], value=float(self.go_token_id), dtype=core.DataType.FLOAT)\n    initial_hypo = self.model.param_init_net.ConstantFill([], 'initial_hypo', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    (encoder_inputs_flattened, _) = self.model.net.Reshape(inputs, ['encoder_inputs_flattened', 'encoder_inputs_old_shape'], shape=[-1])\n    init_attention = self.model.net.ConstantFill(encoder_inputs_flattened, 'init_attention', value=0.0, dtype=core.DataType.FLOAT)\n    state_configs = state_configs + [self.StateConfig(initial_value=initial_scores, state_prev_link=self.LinkConfig(self.scores_t_prev, 0, 1), state_link=self.LinkConfig(scores_t, 1, 1)), self.StateConfig(initial_value=initial_tokens, state_prev_link=self.LinkConfig(self.tokens_t_prev, 0, 1), state_link=self.LinkConfig(tokens_t, 1, 1)), self.StateConfig(initial_value=initial_hypo, state_prev_link=self.LinkConfig(self.hypo_t_prev, 0, 1), state_link=self.LinkConfig(hypo_t, 1, 1)), self.StateConfig(initial_value=init_attention, state_prev_link=self.LinkConfig(self.attention_t_prev, 0, 1), state_link=self.LinkConfig(attention_t, 1, 1))]\n    fake_input = self.model.net.ConstantFill(length, 'beam_search_fake_input', input_as_shape=True, extra_shape=[self.beam_size, 1], value=0.0, dtype=core.DataType.FLOAT)\n    all_inputs = [fake_input] + self.step_model.params + [state_config.initial_value for state_config in state_configs] + data_dependencies\n    forward_links = []\n    recurrent_states = []\n    for state_config in state_configs:\n        state_name = str(state_config.state_prev_link.blob) + '_states'\n        recurrent_states.append(state_name)\n        forward_links.append((state_config.state_prev_link.blob, state_name, state_config.state_prev_link.offset, state_config.state_prev_link.window))\n        forward_links.append((state_config.state_link.blob, state_name, state_config.state_link.offset, state_config.state_link.window))\n    (link_internal, link_external, link_offset, link_window) = zip(*forward_links)\n    all_outputs = [str(s) + '_all' for s in [scores_t, tokens_t, hypo_t, attention_t]]\n    results = self.model.net.RecurrentNetwork(all_inputs, all_outputs + ['step_workspaces'], param=[all_inputs.index(p) for p in self.step_model.params], alias_src=[str(s) + '_states' for s in [self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev]], alias_dst=all_outputs, alias_offset=[0] * 4, recurrent_states=recurrent_states, initial_recurrent_state_ids=[all_inputs.index(state_config.initial_value) for state_config in state_configs], link_internal=[str(l) for l in link_internal], link_external=[str(l) for l in link_external], link_offset=link_offset, link_window=link_window, backward_link_internal=[], backward_link_external=[], backward_link_offset=[], step_net=self.step_model.net.Proto(), timestep=str(self.timestep), outputs_with_grads=[], enable_rnn_executor=1, rnn_executor_debug=0)\n    (score_t_all, tokens_t_all, hypo_t_all, attention_t_all) = results[:4]\n    output_token_beam_list = self.model.net.Cast(tokens_t_all, 'output_token_beam_list', to=core.DataType.INT32)\n    output_prev_index_beam_list = self.model.net.Cast(hypo_t_all, 'output_prev_index_beam_list', to=core.DataType.INT32)\n    output_score_beam_list = self.model.net.Alias(score_t_all, 'output_score_beam_list')\n    output_attention_weights_beam_list = self.model.net.Alias(attention_t_all, 'output_attention_weights_beam_list')\n    return (output_token_beam_list, output_prev_index_beam_list, output_score_beam_list, output_attention_weights_beam_list)",
        "mutated": [
            "def apply(self, inputs, length, log_probs, attentions, state_configs, data_dependencies, word_rewards=None, possible_translation_tokens=None, go_token_id=None):\n    if False:\n        i = 10\n    ZERO = self.model.param_init_net.ConstantFill([], 'ZERO', shape=[1], value=0, dtype=core.DataType.INT32)\n    on_initial_step = self.step_model.net.EQ([ZERO, self.timestep], 'on_initial_step')\n    if self.post_eos_penalty is not None:\n        eos_token = self.model.param_init_net.ConstantFill([], 'eos_token', shape=[self.beam_size], value=self.eos_token_id, dtype=core.DataType.INT32)\n        finished_penalty = self.model.param_init_net.ConstantFill([], 'finished_penalty', shape=[1], value=float(self.post_eos_penalty), dtype=core.DataType.FLOAT)\n        ZERO_FLOAT = self.model.param_init_net.ConstantFill([], 'ZERO_FLOAT', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n        finished_penalty = self.step_model.net.Conditional([on_initial_step, ZERO_FLOAT, finished_penalty], 'possible_finished_penalty')\n        tokens_t_flat = self.step_model.net.FlattenToVec(self.tokens_t_prev, 'tokens_t_flat')\n        tokens_t_flat_int = self.step_model.net.Cast(tokens_t_flat, 'tokens_t_flat_int', to=core.DataType.INT32)\n        predecessor_is_eos = self.step_model.net.EQ([tokens_t_flat_int, eos_token], 'predecessor_is_eos')\n        predecessor_is_eos_float = self.step_model.net.Cast(predecessor_is_eos, 'predecessor_is_eos_float', to=core.DataType.FLOAT)\n        predecessor_is_eos_penalty = self.step_model.net.Mul([predecessor_is_eos_float, finished_penalty], 'predecessor_is_eos_penalty', broadcast=1)\n        log_probs = self.step_model.net.Add([log_probs, predecessor_is_eos_penalty], 'log_probs_penalized', broadcast=1, axis=0)\n    (best_scores_per_hypo, best_tokens_per_hypo) = self.step_model.net.TopK(log_probs, ['best_scores_per_hypo', 'best_tokens_per_hypo_indices'], k=self.beam_size)\n    if possible_translation_tokens:\n        best_tokens_per_hypo = self.step_model.net.Gather([possible_translation_tokens, best_tokens_per_hypo], ['best_tokens_per_hypo'])\n    (scores_t_prev_squeezed, _) = self.step_model.net.Reshape(self.scores_t_prev, ['scores_t_prev_squeezed', 'scores_t_prev_old_shape'], shape=[self.beam_size])\n    output_scores = self.step_model.net.Add([best_scores_per_hypo, scores_t_prev_squeezed], 'output_scores', broadcast=1, axis=0)\n    if word_rewards is not None:\n        word_rewards_for_best_tokens_per_hypo = self.step_model.net.Gather([word_rewards, best_tokens_per_hypo], 'word_rewards_for_best_tokens_per_hypo')\n        output_scores = self.step_model.net.Add([output_scores, word_rewards_for_best_tokens_per_hypo], 'output_scores')\n    (output_scores_flattened, _) = self.step_model.net.Reshape([output_scores], [output_scores, 'output_scores_old_shape'], shape=[-1])\n    MINUS_ONE_INT32 = self.model.param_init_net.ConstantFill([], 'MINUS_ONE_INT32', value=-1, shape=[1], dtype=core.DataType.INT32)\n    BEAM_SIZE = self.model.param_init_net.ConstantFill([], 'beam_size', shape=[1], value=self.beam_size, dtype=core.DataType.INT32)\n    slice_end = self.step_model.net.Conditional([on_initial_step, BEAM_SIZE, MINUS_ONE_INT32], ['slice_end'])\n    output_scores_flattened_slice = self.step_model.net.Slice([output_scores_flattened, ZERO, slice_end], 'output_scores_flattened_slice')\n    (output_scores_flattened_slice, _) = self.step_model.net.Reshape(output_scores_flattened_slice, [output_scores_flattened_slice, 'output_scores_flattened_slice_old_shape'], shape=[1, -1])\n    (scores_t, best_indices) = self.step_model.net.TopK(output_scores_flattened_slice, ['scores_t', 'best_indices'], k=self.beam_size)\n    BEAM_SIZE_64 = self.model.param_init_net.Cast(BEAM_SIZE, 'BEAM_SIZE_64', to=core.DataType.INT64)\n    hypo_t_int32 = self.step_model.net.Div([best_indices, BEAM_SIZE_64], 'hypo_t_int32', broadcast=1)\n    hypo_t = self.step_model.net.Cast(hypo_t_int32, 'hypo_t', to=core.DataType.FLOAT)\n    attention_t = self.step_model.net.Gather([attentions, hypo_t_int32], 'attention_t')\n    (attention_t, _) = self.step_model.net.Reshape(attention_t, [attention_t, 'attention_t_old_shape'], shape=[1, self.beam_size, -1])\n    (best_tokens_per_hypo_flatten, _) = self.step_model.net.Reshape(best_tokens_per_hypo, ['best_tokens_per_hypo_flatten', 'best_tokens_per_hypo_old_shape'], shape=[-1])\n    tokens_t_int32 = self.step_model.net.Gather([best_tokens_per_hypo_flatten, best_indices], 'tokens_t_int32')\n    tokens_t = self.step_model.net.Cast(tokens_t_int32, 'tokens_t', to=core.DataType.FLOAT)\n\n    def choose_state_per_hypo(state_config):\n        (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n        state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n        return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))\n    state_configs = [choose_state_per_hypo(c) for c in state_configs]\n    initial_scores = self.model.param_init_net.ConstantFill([], 'initial_scores', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    if go_token_id:\n        initial_tokens = self.model.net.Copy([go_token_id], 'initial_tokens')\n    else:\n        initial_tokens = self.model.param_init_net.ConstantFill([], 'initial_tokens', shape=[1], value=float(self.go_token_id), dtype=core.DataType.FLOAT)\n    initial_hypo = self.model.param_init_net.ConstantFill([], 'initial_hypo', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    (encoder_inputs_flattened, _) = self.model.net.Reshape(inputs, ['encoder_inputs_flattened', 'encoder_inputs_old_shape'], shape=[-1])\n    init_attention = self.model.net.ConstantFill(encoder_inputs_flattened, 'init_attention', value=0.0, dtype=core.DataType.FLOAT)\n    state_configs = state_configs + [self.StateConfig(initial_value=initial_scores, state_prev_link=self.LinkConfig(self.scores_t_prev, 0, 1), state_link=self.LinkConfig(scores_t, 1, 1)), self.StateConfig(initial_value=initial_tokens, state_prev_link=self.LinkConfig(self.tokens_t_prev, 0, 1), state_link=self.LinkConfig(tokens_t, 1, 1)), self.StateConfig(initial_value=initial_hypo, state_prev_link=self.LinkConfig(self.hypo_t_prev, 0, 1), state_link=self.LinkConfig(hypo_t, 1, 1)), self.StateConfig(initial_value=init_attention, state_prev_link=self.LinkConfig(self.attention_t_prev, 0, 1), state_link=self.LinkConfig(attention_t, 1, 1))]\n    fake_input = self.model.net.ConstantFill(length, 'beam_search_fake_input', input_as_shape=True, extra_shape=[self.beam_size, 1], value=0.0, dtype=core.DataType.FLOAT)\n    all_inputs = [fake_input] + self.step_model.params + [state_config.initial_value for state_config in state_configs] + data_dependencies\n    forward_links = []\n    recurrent_states = []\n    for state_config in state_configs:\n        state_name = str(state_config.state_prev_link.blob) + '_states'\n        recurrent_states.append(state_name)\n        forward_links.append((state_config.state_prev_link.blob, state_name, state_config.state_prev_link.offset, state_config.state_prev_link.window))\n        forward_links.append((state_config.state_link.blob, state_name, state_config.state_link.offset, state_config.state_link.window))\n    (link_internal, link_external, link_offset, link_window) = zip(*forward_links)\n    all_outputs = [str(s) + '_all' for s in [scores_t, tokens_t, hypo_t, attention_t]]\n    results = self.model.net.RecurrentNetwork(all_inputs, all_outputs + ['step_workspaces'], param=[all_inputs.index(p) for p in self.step_model.params], alias_src=[str(s) + '_states' for s in [self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev]], alias_dst=all_outputs, alias_offset=[0] * 4, recurrent_states=recurrent_states, initial_recurrent_state_ids=[all_inputs.index(state_config.initial_value) for state_config in state_configs], link_internal=[str(l) for l in link_internal], link_external=[str(l) for l in link_external], link_offset=link_offset, link_window=link_window, backward_link_internal=[], backward_link_external=[], backward_link_offset=[], step_net=self.step_model.net.Proto(), timestep=str(self.timestep), outputs_with_grads=[], enable_rnn_executor=1, rnn_executor_debug=0)\n    (score_t_all, tokens_t_all, hypo_t_all, attention_t_all) = results[:4]\n    output_token_beam_list = self.model.net.Cast(tokens_t_all, 'output_token_beam_list', to=core.DataType.INT32)\n    output_prev_index_beam_list = self.model.net.Cast(hypo_t_all, 'output_prev_index_beam_list', to=core.DataType.INT32)\n    output_score_beam_list = self.model.net.Alias(score_t_all, 'output_score_beam_list')\n    output_attention_weights_beam_list = self.model.net.Alias(attention_t_all, 'output_attention_weights_beam_list')\n    return (output_token_beam_list, output_prev_index_beam_list, output_score_beam_list, output_attention_weights_beam_list)",
            "def apply(self, inputs, length, log_probs, attentions, state_configs, data_dependencies, word_rewards=None, possible_translation_tokens=None, go_token_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ZERO = self.model.param_init_net.ConstantFill([], 'ZERO', shape=[1], value=0, dtype=core.DataType.INT32)\n    on_initial_step = self.step_model.net.EQ([ZERO, self.timestep], 'on_initial_step')\n    if self.post_eos_penalty is not None:\n        eos_token = self.model.param_init_net.ConstantFill([], 'eos_token', shape=[self.beam_size], value=self.eos_token_id, dtype=core.DataType.INT32)\n        finished_penalty = self.model.param_init_net.ConstantFill([], 'finished_penalty', shape=[1], value=float(self.post_eos_penalty), dtype=core.DataType.FLOAT)\n        ZERO_FLOAT = self.model.param_init_net.ConstantFill([], 'ZERO_FLOAT', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n        finished_penalty = self.step_model.net.Conditional([on_initial_step, ZERO_FLOAT, finished_penalty], 'possible_finished_penalty')\n        tokens_t_flat = self.step_model.net.FlattenToVec(self.tokens_t_prev, 'tokens_t_flat')\n        tokens_t_flat_int = self.step_model.net.Cast(tokens_t_flat, 'tokens_t_flat_int', to=core.DataType.INT32)\n        predecessor_is_eos = self.step_model.net.EQ([tokens_t_flat_int, eos_token], 'predecessor_is_eos')\n        predecessor_is_eos_float = self.step_model.net.Cast(predecessor_is_eos, 'predecessor_is_eos_float', to=core.DataType.FLOAT)\n        predecessor_is_eos_penalty = self.step_model.net.Mul([predecessor_is_eos_float, finished_penalty], 'predecessor_is_eos_penalty', broadcast=1)\n        log_probs = self.step_model.net.Add([log_probs, predecessor_is_eos_penalty], 'log_probs_penalized', broadcast=1, axis=0)\n    (best_scores_per_hypo, best_tokens_per_hypo) = self.step_model.net.TopK(log_probs, ['best_scores_per_hypo', 'best_tokens_per_hypo_indices'], k=self.beam_size)\n    if possible_translation_tokens:\n        best_tokens_per_hypo = self.step_model.net.Gather([possible_translation_tokens, best_tokens_per_hypo], ['best_tokens_per_hypo'])\n    (scores_t_prev_squeezed, _) = self.step_model.net.Reshape(self.scores_t_prev, ['scores_t_prev_squeezed', 'scores_t_prev_old_shape'], shape=[self.beam_size])\n    output_scores = self.step_model.net.Add([best_scores_per_hypo, scores_t_prev_squeezed], 'output_scores', broadcast=1, axis=0)\n    if word_rewards is not None:\n        word_rewards_for_best_tokens_per_hypo = self.step_model.net.Gather([word_rewards, best_tokens_per_hypo], 'word_rewards_for_best_tokens_per_hypo')\n        output_scores = self.step_model.net.Add([output_scores, word_rewards_for_best_tokens_per_hypo], 'output_scores')\n    (output_scores_flattened, _) = self.step_model.net.Reshape([output_scores], [output_scores, 'output_scores_old_shape'], shape=[-1])\n    MINUS_ONE_INT32 = self.model.param_init_net.ConstantFill([], 'MINUS_ONE_INT32', value=-1, shape=[1], dtype=core.DataType.INT32)\n    BEAM_SIZE = self.model.param_init_net.ConstantFill([], 'beam_size', shape=[1], value=self.beam_size, dtype=core.DataType.INT32)\n    slice_end = self.step_model.net.Conditional([on_initial_step, BEAM_SIZE, MINUS_ONE_INT32], ['slice_end'])\n    output_scores_flattened_slice = self.step_model.net.Slice([output_scores_flattened, ZERO, slice_end], 'output_scores_flattened_slice')\n    (output_scores_flattened_slice, _) = self.step_model.net.Reshape(output_scores_flattened_slice, [output_scores_flattened_slice, 'output_scores_flattened_slice_old_shape'], shape=[1, -1])\n    (scores_t, best_indices) = self.step_model.net.TopK(output_scores_flattened_slice, ['scores_t', 'best_indices'], k=self.beam_size)\n    BEAM_SIZE_64 = self.model.param_init_net.Cast(BEAM_SIZE, 'BEAM_SIZE_64', to=core.DataType.INT64)\n    hypo_t_int32 = self.step_model.net.Div([best_indices, BEAM_SIZE_64], 'hypo_t_int32', broadcast=1)\n    hypo_t = self.step_model.net.Cast(hypo_t_int32, 'hypo_t', to=core.DataType.FLOAT)\n    attention_t = self.step_model.net.Gather([attentions, hypo_t_int32], 'attention_t')\n    (attention_t, _) = self.step_model.net.Reshape(attention_t, [attention_t, 'attention_t_old_shape'], shape=[1, self.beam_size, -1])\n    (best_tokens_per_hypo_flatten, _) = self.step_model.net.Reshape(best_tokens_per_hypo, ['best_tokens_per_hypo_flatten', 'best_tokens_per_hypo_old_shape'], shape=[-1])\n    tokens_t_int32 = self.step_model.net.Gather([best_tokens_per_hypo_flatten, best_indices], 'tokens_t_int32')\n    tokens_t = self.step_model.net.Cast(tokens_t_int32, 'tokens_t', to=core.DataType.FLOAT)\n\n    def choose_state_per_hypo(state_config):\n        (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n        state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n        return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))\n    state_configs = [choose_state_per_hypo(c) for c in state_configs]\n    initial_scores = self.model.param_init_net.ConstantFill([], 'initial_scores', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    if go_token_id:\n        initial_tokens = self.model.net.Copy([go_token_id], 'initial_tokens')\n    else:\n        initial_tokens = self.model.param_init_net.ConstantFill([], 'initial_tokens', shape=[1], value=float(self.go_token_id), dtype=core.DataType.FLOAT)\n    initial_hypo = self.model.param_init_net.ConstantFill([], 'initial_hypo', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    (encoder_inputs_flattened, _) = self.model.net.Reshape(inputs, ['encoder_inputs_flattened', 'encoder_inputs_old_shape'], shape=[-1])\n    init_attention = self.model.net.ConstantFill(encoder_inputs_flattened, 'init_attention', value=0.0, dtype=core.DataType.FLOAT)\n    state_configs = state_configs + [self.StateConfig(initial_value=initial_scores, state_prev_link=self.LinkConfig(self.scores_t_prev, 0, 1), state_link=self.LinkConfig(scores_t, 1, 1)), self.StateConfig(initial_value=initial_tokens, state_prev_link=self.LinkConfig(self.tokens_t_prev, 0, 1), state_link=self.LinkConfig(tokens_t, 1, 1)), self.StateConfig(initial_value=initial_hypo, state_prev_link=self.LinkConfig(self.hypo_t_prev, 0, 1), state_link=self.LinkConfig(hypo_t, 1, 1)), self.StateConfig(initial_value=init_attention, state_prev_link=self.LinkConfig(self.attention_t_prev, 0, 1), state_link=self.LinkConfig(attention_t, 1, 1))]\n    fake_input = self.model.net.ConstantFill(length, 'beam_search_fake_input', input_as_shape=True, extra_shape=[self.beam_size, 1], value=0.0, dtype=core.DataType.FLOAT)\n    all_inputs = [fake_input] + self.step_model.params + [state_config.initial_value for state_config in state_configs] + data_dependencies\n    forward_links = []\n    recurrent_states = []\n    for state_config in state_configs:\n        state_name = str(state_config.state_prev_link.blob) + '_states'\n        recurrent_states.append(state_name)\n        forward_links.append((state_config.state_prev_link.blob, state_name, state_config.state_prev_link.offset, state_config.state_prev_link.window))\n        forward_links.append((state_config.state_link.blob, state_name, state_config.state_link.offset, state_config.state_link.window))\n    (link_internal, link_external, link_offset, link_window) = zip(*forward_links)\n    all_outputs = [str(s) + '_all' for s in [scores_t, tokens_t, hypo_t, attention_t]]\n    results = self.model.net.RecurrentNetwork(all_inputs, all_outputs + ['step_workspaces'], param=[all_inputs.index(p) for p in self.step_model.params], alias_src=[str(s) + '_states' for s in [self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev]], alias_dst=all_outputs, alias_offset=[0] * 4, recurrent_states=recurrent_states, initial_recurrent_state_ids=[all_inputs.index(state_config.initial_value) for state_config in state_configs], link_internal=[str(l) for l in link_internal], link_external=[str(l) for l in link_external], link_offset=link_offset, link_window=link_window, backward_link_internal=[], backward_link_external=[], backward_link_offset=[], step_net=self.step_model.net.Proto(), timestep=str(self.timestep), outputs_with_grads=[], enable_rnn_executor=1, rnn_executor_debug=0)\n    (score_t_all, tokens_t_all, hypo_t_all, attention_t_all) = results[:4]\n    output_token_beam_list = self.model.net.Cast(tokens_t_all, 'output_token_beam_list', to=core.DataType.INT32)\n    output_prev_index_beam_list = self.model.net.Cast(hypo_t_all, 'output_prev_index_beam_list', to=core.DataType.INT32)\n    output_score_beam_list = self.model.net.Alias(score_t_all, 'output_score_beam_list')\n    output_attention_weights_beam_list = self.model.net.Alias(attention_t_all, 'output_attention_weights_beam_list')\n    return (output_token_beam_list, output_prev_index_beam_list, output_score_beam_list, output_attention_weights_beam_list)",
            "def apply(self, inputs, length, log_probs, attentions, state_configs, data_dependencies, word_rewards=None, possible_translation_tokens=None, go_token_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ZERO = self.model.param_init_net.ConstantFill([], 'ZERO', shape=[1], value=0, dtype=core.DataType.INT32)\n    on_initial_step = self.step_model.net.EQ([ZERO, self.timestep], 'on_initial_step')\n    if self.post_eos_penalty is not None:\n        eos_token = self.model.param_init_net.ConstantFill([], 'eos_token', shape=[self.beam_size], value=self.eos_token_id, dtype=core.DataType.INT32)\n        finished_penalty = self.model.param_init_net.ConstantFill([], 'finished_penalty', shape=[1], value=float(self.post_eos_penalty), dtype=core.DataType.FLOAT)\n        ZERO_FLOAT = self.model.param_init_net.ConstantFill([], 'ZERO_FLOAT', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n        finished_penalty = self.step_model.net.Conditional([on_initial_step, ZERO_FLOAT, finished_penalty], 'possible_finished_penalty')\n        tokens_t_flat = self.step_model.net.FlattenToVec(self.tokens_t_prev, 'tokens_t_flat')\n        tokens_t_flat_int = self.step_model.net.Cast(tokens_t_flat, 'tokens_t_flat_int', to=core.DataType.INT32)\n        predecessor_is_eos = self.step_model.net.EQ([tokens_t_flat_int, eos_token], 'predecessor_is_eos')\n        predecessor_is_eos_float = self.step_model.net.Cast(predecessor_is_eos, 'predecessor_is_eos_float', to=core.DataType.FLOAT)\n        predecessor_is_eos_penalty = self.step_model.net.Mul([predecessor_is_eos_float, finished_penalty], 'predecessor_is_eos_penalty', broadcast=1)\n        log_probs = self.step_model.net.Add([log_probs, predecessor_is_eos_penalty], 'log_probs_penalized', broadcast=1, axis=0)\n    (best_scores_per_hypo, best_tokens_per_hypo) = self.step_model.net.TopK(log_probs, ['best_scores_per_hypo', 'best_tokens_per_hypo_indices'], k=self.beam_size)\n    if possible_translation_tokens:\n        best_tokens_per_hypo = self.step_model.net.Gather([possible_translation_tokens, best_tokens_per_hypo], ['best_tokens_per_hypo'])\n    (scores_t_prev_squeezed, _) = self.step_model.net.Reshape(self.scores_t_prev, ['scores_t_prev_squeezed', 'scores_t_prev_old_shape'], shape=[self.beam_size])\n    output_scores = self.step_model.net.Add([best_scores_per_hypo, scores_t_prev_squeezed], 'output_scores', broadcast=1, axis=0)\n    if word_rewards is not None:\n        word_rewards_for_best_tokens_per_hypo = self.step_model.net.Gather([word_rewards, best_tokens_per_hypo], 'word_rewards_for_best_tokens_per_hypo')\n        output_scores = self.step_model.net.Add([output_scores, word_rewards_for_best_tokens_per_hypo], 'output_scores')\n    (output_scores_flattened, _) = self.step_model.net.Reshape([output_scores], [output_scores, 'output_scores_old_shape'], shape=[-1])\n    MINUS_ONE_INT32 = self.model.param_init_net.ConstantFill([], 'MINUS_ONE_INT32', value=-1, shape=[1], dtype=core.DataType.INT32)\n    BEAM_SIZE = self.model.param_init_net.ConstantFill([], 'beam_size', shape=[1], value=self.beam_size, dtype=core.DataType.INT32)\n    slice_end = self.step_model.net.Conditional([on_initial_step, BEAM_SIZE, MINUS_ONE_INT32], ['slice_end'])\n    output_scores_flattened_slice = self.step_model.net.Slice([output_scores_flattened, ZERO, slice_end], 'output_scores_flattened_slice')\n    (output_scores_flattened_slice, _) = self.step_model.net.Reshape(output_scores_flattened_slice, [output_scores_flattened_slice, 'output_scores_flattened_slice_old_shape'], shape=[1, -1])\n    (scores_t, best_indices) = self.step_model.net.TopK(output_scores_flattened_slice, ['scores_t', 'best_indices'], k=self.beam_size)\n    BEAM_SIZE_64 = self.model.param_init_net.Cast(BEAM_SIZE, 'BEAM_SIZE_64', to=core.DataType.INT64)\n    hypo_t_int32 = self.step_model.net.Div([best_indices, BEAM_SIZE_64], 'hypo_t_int32', broadcast=1)\n    hypo_t = self.step_model.net.Cast(hypo_t_int32, 'hypo_t', to=core.DataType.FLOAT)\n    attention_t = self.step_model.net.Gather([attentions, hypo_t_int32], 'attention_t')\n    (attention_t, _) = self.step_model.net.Reshape(attention_t, [attention_t, 'attention_t_old_shape'], shape=[1, self.beam_size, -1])\n    (best_tokens_per_hypo_flatten, _) = self.step_model.net.Reshape(best_tokens_per_hypo, ['best_tokens_per_hypo_flatten', 'best_tokens_per_hypo_old_shape'], shape=[-1])\n    tokens_t_int32 = self.step_model.net.Gather([best_tokens_per_hypo_flatten, best_indices], 'tokens_t_int32')\n    tokens_t = self.step_model.net.Cast(tokens_t_int32, 'tokens_t', to=core.DataType.FLOAT)\n\n    def choose_state_per_hypo(state_config):\n        (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n        state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n        return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))\n    state_configs = [choose_state_per_hypo(c) for c in state_configs]\n    initial_scores = self.model.param_init_net.ConstantFill([], 'initial_scores', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    if go_token_id:\n        initial_tokens = self.model.net.Copy([go_token_id], 'initial_tokens')\n    else:\n        initial_tokens = self.model.param_init_net.ConstantFill([], 'initial_tokens', shape=[1], value=float(self.go_token_id), dtype=core.DataType.FLOAT)\n    initial_hypo = self.model.param_init_net.ConstantFill([], 'initial_hypo', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    (encoder_inputs_flattened, _) = self.model.net.Reshape(inputs, ['encoder_inputs_flattened', 'encoder_inputs_old_shape'], shape=[-1])\n    init_attention = self.model.net.ConstantFill(encoder_inputs_flattened, 'init_attention', value=0.0, dtype=core.DataType.FLOAT)\n    state_configs = state_configs + [self.StateConfig(initial_value=initial_scores, state_prev_link=self.LinkConfig(self.scores_t_prev, 0, 1), state_link=self.LinkConfig(scores_t, 1, 1)), self.StateConfig(initial_value=initial_tokens, state_prev_link=self.LinkConfig(self.tokens_t_prev, 0, 1), state_link=self.LinkConfig(tokens_t, 1, 1)), self.StateConfig(initial_value=initial_hypo, state_prev_link=self.LinkConfig(self.hypo_t_prev, 0, 1), state_link=self.LinkConfig(hypo_t, 1, 1)), self.StateConfig(initial_value=init_attention, state_prev_link=self.LinkConfig(self.attention_t_prev, 0, 1), state_link=self.LinkConfig(attention_t, 1, 1))]\n    fake_input = self.model.net.ConstantFill(length, 'beam_search_fake_input', input_as_shape=True, extra_shape=[self.beam_size, 1], value=0.0, dtype=core.DataType.FLOAT)\n    all_inputs = [fake_input] + self.step_model.params + [state_config.initial_value for state_config in state_configs] + data_dependencies\n    forward_links = []\n    recurrent_states = []\n    for state_config in state_configs:\n        state_name = str(state_config.state_prev_link.blob) + '_states'\n        recurrent_states.append(state_name)\n        forward_links.append((state_config.state_prev_link.blob, state_name, state_config.state_prev_link.offset, state_config.state_prev_link.window))\n        forward_links.append((state_config.state_link.blob, state_name, state_config.state_link.offset, state_config.state_link.window))\n    (link_internal, link_external, link_offset, link_window) = zip(*forward_links)\n    all_outputs = [str(s) + '_all' for s in [scores_t, tokens_t, hypo_t, attention_t]]\n    results = self.model.net.RecurrentNetwork(all_inputs, all_outputs + ['step_workspaces'], param=[all_inputs.index(p) for p in self.step_model.params], alias_src=[str(s) + '_states' for s in [self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev]], alias_dst=all_outputs, alias_offset=[0] * 4, recurrent_states=recurrent_states, initial_recurrent_state_ids=[all_inputs.index(state_config.initial_value) for state_config in state_configs], link_internal=[str(l) for l in link_internal], link_external=[str(l) for l in link_external], link_offset=link_offset, link_window=link_window, backward_link_internal=[], backward_link_external=[], backward_link_offset=[], step_net=self.step_model.net.Proto(), timestep=str(self.timestep), outputs_with_grads=[], enable_rnn_executor=1, rnn_executor_debug=0)\n    (score_t_all, tokens_t_all, hypo_t_all, attention_t_all) = results[:4]\n    output_token_beam_list = self.model.net.Cast(tokens_t_all, 'output_token_beam_list', to=core.DataType.INT32)\n    output_prev_index_beam_list = self.model.net.Cast(hypo_t_all, 'output_prev_index_beam_list', to=core.DataType.INT32)\n    output_score_beam_list = self.model.net.Alias(score_t_all, 'output_score_beam_list')\n    output_attention_weights_beam_list = self.model.net.Alias(attention_t_all, 'output_attention_weights_beam_list')\n    return (output_token_beam_list, output_prev_index_beam_list, output_score_beam_list, output_attention_weights_beam_list)",
            "def apply(self, inputs, length, log_probs, attentions, state_configs, data_dependencies, word_rewards=None, possible_translation_tokens=None, go_token_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ZERO = self.model.param_init_net.ConstantFill([], 'ZERO', shape=[1], value=0, dtype=core.DataType.INT32)\n    on_initial_step = self.step_model.net.EQ([ZERO, self.timestep], 'on_initial_step')\n    if self.post_eos_penalty is not None:\n        eos_token = self.model.param_init_net.ConstantFill([], 'eos_token', shape=[self.beam_size], value=self.eos_token_id, dtype=core.DataType.INT32)\n        finished_penalty = self.model.param_init_net.ConstantFill([], 'finished_penalty', shape=[1], value=float(self.post_eos_penalty), dtype=core.DataType.FLOAT)\n        ZERO_FLOAT = self.model.param_init_net.ConstantFill([], 'ZERO_FLOAT', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n        finished_penalty = self.step_model.net.Conditional([on_initial_step, ZERO_FLOAT, finished_penalty], 'possible_finished_penalty')\n        tokens_t_flat = self.step_model.net.FlattenToVec(self.tokens_t_prev, 'tokens_t_flat')\n        tokens_t_flat_int = self.step_model.net.Cast(tokens_t_flat, 'tokens_t_flat_int', to=core.DataType.INT32)\n        predecessor_is_eos = self.step_model.net.EQ([tokens_t_flat_int, eos_token], 'predecessor_is_eos')\n        predecessor_is_eos_float = self.step_model.net.Cast(predecessor_is_eos, 'predecessor_is_eos_float', to=core.DataType.FLOAT)\n        predecessor_is_eos_penalty = self.step_model.net.Mul([predecessor_is_eos_float, finished_penalty], 'predecessor_is_eos_penalty', broadcast=1)\n        log_probs = self.step_model.net.Add([log_probs, predecessor_is_eos_penalty], 'log_probs_penalized', broadcast=1, axis=0)\n    (best_scores_per_hypo, best_tokens_per_hypo) = self.step_model.net.TopK(log_probs, ['best_scores_per_hypo', 'best_tokens_per_hypo_indices'], k=self.beam_size)\n    if possible_translation_tokens:\n        best_tokens_per_hypo = self.step_model.net.Gather([possible_translation_tokens, best_tokens_per_hypo], ['best_tokens_per_hypo'])\n    (scores_t_prev_squeezed, _) = self.step_model.net.Reshape(self.scores_t_prev, ['scores_t_prev_squeezed', 'scores_t_prev_old_shape'], shape=[self.beam_size])\n    output_scores = self.step_model.net.Add([best_scores_per_hypo, scores_t_prev_squeezed], 'output_scores', broadcast=1, axis=0)\n    if word_rewards is not None:\n        word_rewards_for_best_tokens_per_hypo = self.step_model.net.Gather([word_rewards, best_tokens_per_hypo], 'word_rewards_for_best_tokens_per_hypo')\n        output_scores = self.step_model.net.Add([output_scores, word_rewards_for_best_tokens_per_hypo], 'output_scores')\n    (output_scores_flattened, _) = self.step_model.net.Reshape([output_scores], [output_scores, 'output_scores_old_shape'], shape=[-1])\n    MINUS_ONE_INT32 = self.model.param_init_net.ConstantFill([], 'MINUS_ONE_INT32', value=-1, shape=[1], dtype=core.DataType.INT32)\n    BEAM_SIZE = self.model.param_init_net.ConstantFill([], 'beam_size', shape=[1], value=self.beam_size, dtype=core.DataType.INT32)\n    slice_end = self.step_model.net.Conditional([on_initial_step, BEAM_SIZE, MINUS_ONE_INT32], ['slice_end'])\n    output_scores_flattened_slice = self.step_model.net.Slice([output_scores_flattened, ZERO, slice_end], 'output_scores_flattened_slice')\n    (output_scores_flattened_slice, _) = self.step_model.net.Reshape(output_scores_flattened_slice, [output_scores_flattened_slice, 'output_scores_flattened_slice_old_shape'], shape=[1, -1])\n    (scores_t, best_indices) = self.step_model.net.TopK(output_scores_flattened_slice, ['scores_t', 'best_indices'], k=self.beam_size)\n    BEAM_SIZE_64 = self.model.param_init_net.Cast(BEAM_SIZE, 'BEAM_SIZE_64', to=core.DataType.INT64)\n    hypo_t_int32 = self.step_model.net.Div([best_indices, BEAM_SIZE_64], 'hypo_t_int32', broadcast=1)\n    hypo_t = self.step_model.net.Cast(hypo_t_int32, 'hypo_t', to=core.DataType.FLOAT)\n    attention_t = self.step_model.net.Gather([attentions, hypo_t_int32], 'attention_t')\n    (attention_t, _) = self.step_model.net.Reshape(attention_t, [attention_t, 'attention_t_old_shape'], shape=[1, self.beam_size, -1])\n    (best_tokens_per_hypo_flatten, _) = self.step_model.net.Reshape(best_tokens_per_hypo, ['best_tokens_per_hypo_flatten', 'best_tokens_per_hypo_old_shape'], shape=[-1])\n    tokens_t_int32 = self.step_model.net.Gather([best_tokens_per_hypo_flatten, best_indices], 'tokens_t_int32')\n    tokens_t = self.step_model.net.Cast(tokens_t_int32, 'tokens_t', to=core.DataType.FLOAT)\n\n    def choose_state_per_hypo(state_config):\n        (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n        state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n        return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))\n    state_configs = [choose_state_per_hypo(c) for c in state_configs]\n    initial_scores = self.model.param_init_net.ConstantFill([], 'initial_scores', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    if go_token_id:\n        initial_tokens = self.model.net.Copy([go_token_id], 'initial_tokens')\n    else:\n        initial_tokens = self.model.param_init_net.ConstantFill([], 'initial_tokens', shape=[1], value=float(self.go_token_id), dtype=core.DataType.FLOAT)\n    initial_hypo = self.model.param_init_net.ConstantFill([], 'initial_hypo', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    (encoder_inputs_flattened, _) = self.model.net.Reshape(inputs, ['encoder_inputs_flattened', 'encoder_inputs_old_shape'], shape=[-1])\n    init_attention = self.model.net.ConstantFill(encoder_inputs_flattened, 'init_attention', value=0.0, dtype=core.DataType.FLOAT)\n    state_configs = state_configs + [self.StateConfig(initial_value=initial_scores, state_prev_link=self.LinkConfig(self.scores_t_prev, 0, 1), state_link=self.LinkConfig(scores_t, 1, 1)), self.StateConfig(initial_value=initial_tokens, state_prev_link=self.LinkConfig(self.tokens_t_prev, 0, 1), state_link=self.LinkConfig(tokens_t, 1, 1)), self.StateConfig(initial_value=initial_hypo, state_prev_link=self.LinkConfig(self.hypo_t_prev, 0, 1), state_link=self.LinkConfig(hypo_t, 1, 1)), self.StateConfig(initial_value=init_attention, state_prev_link=self.LinkConfig(self.attention_t_prev, 0, 1), state_link=self.LinkConfig(attention_t, 1, 1))]\n    fake_input = self.model.net.ConstantFill(length, 'beam_search_fake_input', input_as_shape=True, extra_shape=[self.beam_size, 1], value=0.0, dtype=core.DataType.FLOAT)\n    all_inputs = [fake_input] + self.step_model.params + [state_config.initial_value for state_config in state_configs] + data_dependencies\n    forward_links = []\n    recurrent_states = []\n    for state_config in state_configs:\n        state_name = str(state_config.state_prev_link.blob) + '_states'\n        recurrent_states.append(state_name)\n        forward_links.append((state_config.state_prev_link.blob, state_name, state_config.state_prev_link.offset, state_config.state_prev_link.window))\n        forward_links.append((state_config.state_link.blob, state_name, state_config.state_link.offset, state_config.state_link.window))\n    (link_internal, link_external, link_offset, link_window) = zip(*forward_links)\n    all_outputs = [str(s) + '_all' for s in [scores_t, tokens_t, hypo_t, attention_t]]\n    results = self.model.net.RecurrentNetwork(all_inputs, all_outputs + ['step_workspaces'], param=[all_inputs.index(p) for p in self.step_model.params], alias_src=[str(s) + '_states' for s in [self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev]], alias_dst=all_outputs, alias_offset=[0] * 4, recurrent_states=recurrent_states, initial_recurrent_state_ids=[all_inputs.index(state_config.initial_value) for state_config in state_configs], link_internal=[str(l) for l in link_internal], link_external=[str(l) for l in link_external], link_offset=link_offset, link_window=link_window, backward_link_internal=[], backward_link_external=[], backward_link_offset=[], step_net=self.step_model.net.Proto(), timestep=str(self.timestep), outputs_with_grads=[], enable_rnn_executor=1, rnn_executor_debug=0)\n    (score_t_all, tokens_t_all, hypo_t_all, attention_t_all) = results[:4]\n    output_token_beam_list = self.model.net.Cast(tokens_t_all, 'output_token_beam_list', to=core.DataType.INT32)\n    output_prev_index_beam_list = self.model.net.Cast(hypo_t_all, 'output_prev_index_beam_list', to=core.DataType.INT32)\n    output_score_beam_list = self.model.net.Alias(score_t_all, 'output_score_beam_list')\n    output_attention_weights_beam_list = self.model.net.Alias(attention_t_all, 'output_attention_weights_beam_list')\n    return (output_token_beam_list, output_prev_index_beam_list, output_score_beam_list, output_attention_weights_beam_list)",
            "def apply(self, inputs, length, log_probs, attentions, state_configs, data_dependencies, word_rewards=None, possible_translation_tokens=None, go_token_id=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ZERO = self.model.param_init_net.ConstantFill([], 'ZERO', shape=[1], value=0, dtype=core.DataType.INT32)\n    on_initial_step = self.step_model.net.EQ([ZERO, self.timestep], 'on_initial_step')\n    if self.post_eos_penalty is not None:\n        eos_token = self.model.param_init_net.ConstantFill([], 'eos_token', shape=[self.beam_size], value=self.eos_token_id, dtype=core.DataType.INT32)\n        finished_penalty = self.model.param_init_net.ConstantFill([], 'finished_penalty', shape=[1], value=float(self.post_eos_penalty), dtype=core.DataType.FLOAT)\n        ZERO_FLOAT = self.model.param_init_net.ConstantFill([], 'ZERO_FLOAT', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n        finished_penalty = self.step_model.net.Conditional([on_initial_step, ZERO_FLOAT, finished_penalty], 'possible_finished_penalty')\n        tokens_t_flat = self.step_model.net.FlattenToVec(self.tokens_t_prev, 'tokens_t_flat')\n        tokens_t_flat_int = self.step_model.net.Cast(tokens_t_flat, 'tokens_t_flat_int', to=core.DataType.INT32)\n        predecessor_is_eos = self.step_model.net.EQ([tokens_t_flat_int, eos_token], 'predecessor_is_eos')\n        predecessor_is_eos_float = self.step_model.net.Cast(predecessor_is_eos, 'predecessor_is_eos_float', to=core.DataType.FLOAT)\n        predecessor_is_eos_penalty = self.step_model.net.Mul([predecessor_is_eos_float, finished_penalty], 'predecessor_is_eos_penalty', broadcast=1)\n        log_probs = self.step_model.net.Add([log_probs, predecessor_is_eos_penalty], 'log_probs_penalized', broadcast=1, axis=0)\n    (best_scores_per_hypo, best_tokens_per_hypo) = self.step_model.net.TopK(log_probs, ['best_scores_per_hypo', 'best_tokens_per_hypo_indices'], k=self.beam_size)\n    if possible_translation_tokens:\n        best_tokens_per_hypo = self.step_model.net.Gather([possible_translation_tokens, best_tokens_per_hypo], ['best_tokens_per_hypo'])\n    (scores_t_prev_squeezed, _) = self.step_model.net.Reshape(self.scores_t_prev, ['scores_t_prev_squeezed', 'scores_t_prev_old_shape'], shape=[self.beam_size])\n    output_scores = self.step_model.net.Add([best_scores_per_hypo, scores_t_prev_squeezed], 'output_scores', broadcast=1, axis=0)\n    if word_rewards is not None:\n        word_rewards_for_best_tokens_per_hypo = self.step_model.net.Gather([word_rewards, best_tokens_per_hypo], 'word_rewards_for_best_tokens_per_hypo')\n        output_scores = self.step_model.net.Add([output_scores, word_rewards_for_best_tokens_per_hypo], 'output_scores')\n    (output_scores_flattened, _) = self.step_model.net.Reshape([output_scores], [output_scores, 'output_scores_old_shape'], shape=[-1])\n    MINUS_ONE_INT32 = self.model.param_init_net.ConstantFill([], 'MINUS_ONE_INT32', value=-1, shape=[1], dtype=core.DataType.INT32)\n    BEAM_SIZE = self.model.param_init_net.ConstantFill([], 'beam_size', shape=[1], value=self.beam_size, dtype=core.DataType.INT32)\n    slice_end = self.step_model.net.Conditional([on_initial_step, BEAM_SIZE, MINUS_ONE_INT32], ['slice_end'])\n    output_scores_flattened_slice = self.step_model.net.Slice([output_scores_flattened, ZERO, slice_end], 'output_scores_flattened_slice')\n    (output_scores_flattened_slice, _) = self.step_model.net.Reshape(output_scores_flattened_slice, [output_scores_flattened_slice, 'output_scores_flattened_slice_old_shape'], shape=[1, -1])\n    (scores_t, best_indices) = self.step_model.net.TopK(output_scores_flattened_slice, ['scores_t', 'best_indices'], k=self.beam_size)\n    BEAM_SIZE_64 = self.model.param_init_net.Cast(BEAM_SIZE, 'BEAM_SIZE_64', to=core.DataType.INT64)\n    hypo_t_int32 = self.step_model.net.Div([best_indices, BEAM_SIZE_64], 'hypo_t_int32', broadcast=1)\n    hypo_t = self.step_model.net.Cast(hypo_t_int32, 'hypo_t', to=core.DataType.FLOAT)\n    attention_t = self.step_model.net.Gather([attentions, hypo_t_int32], 'attention_t')\n    (attention_t, _) = self.step_model.net.Reshape(attention_t, [attention_t, 'attention_t_old_shape'], shape=[1, self.beam_size, -1])\n    (best_tokens_per_hypo_flatten, _) = self.step_model.net.Reshape(best_tokens_per_hypo, ['best_tokens_per_hypo_flatten', 'best_tokens_per_hypo_old_shape'], shape=[-1])\n    tokens_t_int32 = self.step_model.net.Gather([best_tokens_per_hypo_flatten, best_indices], 'tokens_t_int32')\n    tokens_t = self.step_model.net.Cast(tokens_t_int32, 'tokens_t', to=core.DataType.FLOAT)\n\n    def choose_state_per_hypo(state_config):\n        (state_flattened, _) = self.step_model.net.Reshape(state_config.state_link.blob, [state_config.state_link.blob, state_config.state_link.blob + '_old_shape'], shape=[self.beam_size, -1])\n        state_chosen_per_hypo = self.step_model.net.Gather([state_flattened, hypo_t_int32], str(state_config.state_link.blob) + '_chosen_per_hypo')\n        return self.StateConfig(initial_value=state_config.initial_value, state_prev_link=state_config.state_prev_link, state_link=self.LinkConfig(blob=state_chosen_per_hypo, offset=state_config.state_link.offset, window=state_config.state_link.window))\n    state_configs = [choose_state_per_hypo(c) for c in state_configs]\n    initial_scores = self.model.param_init_net.ConstantFill([], 'initial_scores', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    if go_token_id:\n        initial_tokens = self.model.net.Copy([go_token_id], 'initial_tokens')\n    else:\n        initial_tokens = self.model.param_init_net.ConstantFill([], 'initial_tokens', shape=[1], value=float(self.go_token_id), dtype=core.DataType.FLOAT)\n    initial_hypo = self.model.param_init_net.ConstantFill([], 'initial_hypo', shape=[1], value=0.0, dtype=core.DataType.FLOAT)\n    (encoder_inputs_flattened, _) = self.model.net.Reshape(inputs, ['encoder_inputs_flattened', 'encoder_inputs_old_shape'], shape=[-1])\n    init_attention = self.model.net.ConstantFill(encoder_inputs_flattened, 'init_attention', value=0.0, dtype=core.DataType.FLOAT)\n    state_configs = state_configs + [self.StateConfig(initial_value=initial_scores, state_prev_link=self.LinkConfig(self.scores_t_prev, 0, 1), state_link=self.LinkConfig(scores_t, 1, 1)), self.StateConfig(initial_value=initial_tokens, state_prev_link=self.LinkConfig(self.tokens_t_prev, 0, 1), state_link=self.LinkConfig(tokens_t, 1, 1)), self.StateConfig(initial_value=initial_hypo, state_prev_link=self.LinkConfig(self.hypo_t_prev, 0, 1), state_link=self.LinkConfig(hypo_t, 1, 1)), self.StateConfig(initial_value=init_attention, state_prev_link=self.LinkConfig(self.attention_t_prev, 0, 1), state_link=self.LinkConfig(attention_t, 1, 1))]\n    fake_input = self.model.net.ConstantFill(length, 'beam_search_fake_input', input_as_shape=True, extra_shape=[self.beam_size, 1], value=0.0, dtype=core.DataType.FLOAT)\n    all_inputs = [fake_input] + self.step_model.params + [state_config.initial_value for state_config in state_configs] + data_dependencies\n    forward_links = []\n    recurrent_states = []\n    for state_config in state_configs:\n        state_name = str(state_config.state_prev_link.blob) + '_states'\n        recurrent_states.append(state_name)\n        forward_links.append((state_config.state_prev_link.blob, state_name, state_config.state_prev_link.offset, state_config.state_prev_link.window))\n        forward_links.append((state_config.state_link.blob, state_name, state_config.state_link.offset, state_config.state_link.window))\n    (link_internal, link_external, link_offset, link_window) = zip(*forward_links)\n    all_outputs = [str(s) + '_all' for s in [scores_t, tokens_t, hypo_t, attention_t]]\n    results = self.model.net.RecurrentNetwork(all_inputs, all_outputs + ['step_workspaces'], param=[all_inputs.index(p) for p in self.step_model.params], alias_src=[str(s) + '_states' for s in [self.scores_t_prev, self.tokens_t_prev, self.hypo_t_prev, self.attention_t_prev]], alias_dst=all_outputs, alias_offset=[0] * 4, recurrent_states=recurrent_states, initial_recurrent_state_ids=[all_inputs.index(state_config.initial_value) for state_config in state_configs], link_internal=[str(l) for l in link_internal], link_external=[str(l) for l in link_external], link_offset=link_offset, link_window=link_window, backward_link_internal=[], backward_link_external=[], backward_link_offset=[], step_net=self.step_model.net.Proto(), timestep=str(self.timestep), outputs_with_grads=[], enable_rnn_executor=1, rnn_executor_debug=0)\n    (score_t_all, tokens_t_all, hypo_t_all, attention_t_all) = results[:4]\n    output_token_beam_list = self.model.net.Cast(tokens_t_all, 'output_token_beam_list', to=core.DataType.INT32)\n    output_prev_index_beam_list = self.model.net.Cast(hypo_t_all, 'output_prev_index_beam_list', to=core.DataType.INT32)\n    output_score_beam_list = self.model.net.Alias(score_t_all, 'output_score_beam_list')\n    output_attention_weights_beam_list = self.model.net.Alias(attention_t_all, 'output_attention_weights_beam_list')\n    return (output_token_beam_list, output_prev_index_beam_list, output_score_beam_list, output_attention_weights_beam_list)"
        ]
    }
]