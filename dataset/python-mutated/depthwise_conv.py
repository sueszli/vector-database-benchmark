import jittor as jt
from jittor import init
from jittor import nn
from jittor import Function

class DepthwiseConv(Function):

    def __init__(self, stride=1, padding=0, dilation=1):
        if False:
            return 10
        self.stride = stride if isinstance(stride, tuple) else (stride, stride)
        self.padding = padding if isinstance(padding, tuple) else (padding, padding)
        self.dilation = dilation if isinstance(dilation, tuple) else (dilation, dilation)

    def execute(self, x, weight):
        if False:
            print('Hello World!')
        if not jt.flags.use_cuda or not jt.compiler.is_cuda:
            return nn.conv2d(x, weight, None, self.stride, self.padding, self.dilation, x.shape[1])
        self.save_vars = (x, weight)
        (N, C, H, W) = x.shape
        (o, i, Kh, Kw) = weight.shape
        assert o == C
        oh = (H + self.padding[0] * 2 - Kh * self.dilation[0] + self.dilation[0] - 1) // self.stride[0] + 1
        ow = (W + self.padding[1] * 2 - Kw * self.dilation[1] + self.dilation[1] - 1) // self.stride[1] + 1
        (filter_height, filter_width) = (Kh, Kw)
        self.Khw = (Kh, Kw)
        assert oh > 0 and ow > 0
        output = jt.code([N, C, oh, ow], x.dtype, [x, weight], cuda_header='\n        template <typename T, \n            int filter_height,\n            int filter_width, \n            int stride_height,\n            int stride_width>\n        __global__ void KernelDepthwiseConv(\n            const T *const input_data, const T *const filter_data, const int batch_size,\n            const int output_channels, const int output_height,\n            const int output_width, const int input_channels,  \n            const int input_height, const int input_width,     \n            const int padding_height, const int padding_width, \n            const int dilate_height, const int dilate_width, T *const output_data) {\n            const int kWeghtSize = filter_height * filter_width;\n            T r_weight[kWeghtSize];\n            const int batch = blockIdx.y;\n            const int c_out = blockIdx.x;\n            const T* weight = filter_data + c_out * filter_height * filter_width;\n            for (int i = 0; i < filter_height * filter_width; i++) r_weight[i] = weight[i];\n\n            for (int w_out = threadIdx.x; w_out < output_width; w_out += blockDim.x) {\n                for (int h_out = threadIdx.y; h_out < output_height; h_out += blockDim.y) {\n                    const int batch = blockIdx.y;\n                    const int c_out = blockIdx.x;\n\n                    const int c_in = c_out;\n                    T value = 0;\n                    const int h_in_start = -padding_height + h_out * stride_height;\n                    const int w_in_start = -padding_width + w_out * stride_width;\n                    const int h_in_end = h_in_start + filter_height * dilate_height;\n                    const int w_in_end = w_in_start + filter_width * dilate_width;\n\n                    const int in_offset =\n                        ((batch * input_channels + c_in) * input_height) * input_width;\n\n                    const int h_end = h_in_end < input_height ? h_in_end : input_height;\n                    const int w_end = w_in_end < input_width ? w_in_end : input_width;\n                    const int h_start = h_in_start > 0 ? h_in_start : 0;\n                    const int w_start = w_in_start > 0 ? w_in_start : 0;\n\n                    for (int h_in = h_in_start, h_f = 0; h_f < filter_height;\n                        h_in += dilate_height, h_f++) {\n                        for (int w_in = w_in_start, w_f = 0; w_f < filter_width;\n                            w_in += dilate_width, w_f++) {\n                            if (h_in >= 0 && h_in < input_height && w_in >= 0 &&\n                                w_in < input_width) {\n                                const int offset = in_offset + h_in * input_width + w_in;\n                                value += r_weight[h_f * filter_width + w_f] * input_data[offset];\n                            }\n                        }\n                    }\n                    int index =\n                        ((batch * gridDim.x + c_out) * output_height + h_out) * output_width +\n                        w_out;\n                    output_data[index] = value;\n                }\n            }\n        }\n        ', cuda_src=f'\n            @alias(input, in0)\n            @alias(filter, in1)\n            @alias(output, out)\n            \n            const int batch_size = input_shape0;\n            const int input_channels = input_shape1;\n            const int input_height = input_shape2;\n            const int input_width = input_shape3;\n            const int output_channels = output_shape1;\n            const int output_height = output_shape2;\n            const int output_width = output_shape3;\n            const int ksize_height = {Kh};\n            const int ksize_width = {Kw};\n            const int stride_height = {self.stride[0]};\n            const int stride_width = {self.stride[1]};\n            const int padding_height = {self.padding[0]};\n            const int padding_width = {self.padding[1]};\n            const int dilate_height = {self.dilation[0]};\n            const int dilate_width = {self.dilation[1]};\n\n            int thread = 512;\n            if (output_width > 1024 && output_width <= 2048)\n                thread = (output_width - 1) / 2 + 1;\n            else if (output_width > 512 && output_width <= 1024)\n                thread = output_width;\n            int blocks = std::min(std::max(thread / output_width, 1), output_height);\n            dim3 threads(std::min(output_width, thread), blocks, 1);\n            dim3 grid(output_channels, batch_size, 1);\n            KernelDepthwiseConv<\n                input_type, ksize_height, ksize_width, \n                stride_height, stride_width>\n            <<<grid, threads>>>( \n                input_p, filter_p, batch_size, output_channels, output_height,\n                output_width, input_channels, input_height, input_width,\n                padding_height, padding_width, dilate_height,\n                dilate_width, output_p);\n        ')
        return output

    def grad(self, grad):
        if False:
            for i in range(10):
                print('nop')
        (x, weight) = self.save_vars
        (Kh, Kw) = self.Khw
        return jt.code([x.shape, weight.shape], [x.dtype, weight.dtype], [x, weight, grad], cuda_header=f'#include <{jt.compile_extern.cub_home}cub/cub.cuh>' + '\n    template <typename T>\n    __device__ __inline__ void CudaAtomicAddWithWarp(T* sum, T value) {\n    typedef cub::WarpReduce<T> WarpReduce;\n    typename WarpReduce::TempStorage temp_storage;\n    value = WarpReduce(temp_storage).Sum(value);\n    if (cub::LaneId() == 0) \n        atomicAdd(sum, value);\n    }\n    \n    // CUDA kernel to compute the depthwise convolution backprop w.r.t input.\n    template <typename T, \n        int filter_height,\n        int filter_width, \n        int stride_height,\n        int stride_width>\n    __global__ void KernelDepthwiseConvInputGradCFilter(\n        const T *const input_data, const T *const output_grad_data,\n        const T *const filter_data, const int batch_size,   \n        const int output_channels, const int output_height, \n        const int output_width, const int input_channels,   \n        const int input_height, const int input_width,      \n        const int padding_height, const int padding_width,  \n        const int dilate_height, const int dilate_width,    \n        T *const input_grad_data) {\n        const int kWeghtSize = filter_height * filter_width + 1;\n        T r_weight[kWeghtSize];\n        const int batch = blockIdx.y;\n        const int c_in = blockIdx.x;\n\n        const T* weight = filter_data + c_in * filter_height * filter_width;\n        for (int i = 0; i < filter_height * filter_width; i++)\n            r_weight[i] =\n                weight[filter_height * filter_width - i - 1];\n\n        for (int w_in = threadIdx.x; w_in < input_width; w_in += blockDim.x) {\n            for (int h_in = threadIdx.y; h_in < input_height; h_in += blockDim.y) {\n                const int batch = blockIdx.y;\n                const int c_in = blockIdx.x;\n\n                int h_out_start = h_in - (filter_height - 1) * dilate_height + padding_height;\n\n                int w_out_start = w_in - (filter_width - 1) * dilate_width + padding_width;\n\n                T value = 0;\n                int index =\n                    ((batch * gridDim.x + c_in) * input_height + h_in) * input_width +\n                    w_in;\n\n                for (int h_out = h_out_start, h_f = 0; h_f < filter_height;\n                    h_out += dilate_height, h_f++) {\n                    for (int w_out = w_out_start, w_f = 0; w_f < filter_width;\n                        w_out += dilate_width, w_f++) {\n                        int s_h_out = h_out / stride_height;\n                        int s_w_out = w_out / stride_width;\n                        if (h_out % stride_height == 0 && w_out % stride_width == 0 &&\n                            s_h_out >= 0 && s_h_out < output_height && s_w_out >= 0 &&\n                            s_w_out < output_width) {\n                        const int output_grad_offset =\n                            ((batch * output_channels + c_in) * output_height +\n                            s_h_out) *\n                                output_width +\n                            s_w_out;\n                        value +=\n                            output_grad_data[output_grad_offset] *\n                            r_weight[h_f * filter_width + w_f];\n                        }\n                    }\n                }\n                input_grad_data[index] = value;\n            }\n        }\n    }\n\n    // Cuda kernel to compute the depthwise convolution backprop w.r.t. filter.\n    template <typename T>\n    __global__ void KernelDepthwiseConvFilterGrad(\n        const T* output_grad_data, const T* input_data, const int num,\n        const int output_channels, const int output_height, const int output_width,\n        const int input_channels, const int input_height, const int input_width,\n        const int filter_height,\n        const int filter_width, const int stride_height, const int stride_width,\n        const int padding_height, const int padding_width, const int dilate_height,\n        const int dilate_width, T* filter_grad_data) {\n        T s = 0;\n\n        int gbid = (((blockIdx.z * blockDim.z + threadIdx.z) * gridDim.y) + blockIdx.y) * gridDim.x + blockIdx.x;\n\n        for (int image_w = threadIdx.x; image_w < output_width;\n            image_w += blockDim.x) {\n            for (int bid = 0; bid < num; bid++) {\n            //for (int bid = threadIdx.z; bid < num; bid+=blockDim.z) {\n                for (int image_h = threadIdx.y; image_h < output_height;\n                    image_h += blockDim.y) {\n                    int kernel_id = blockIdx.z;\n                    int kernel_h = blockIdx.y * dilate_height - padding_height;\n                    int kernel_w = blockIdx.x * dilate_width - padding_width;\n\n                    int image_hk = image_h * stride_height + kernel_h;\n                    int image_wk = image_w * stride_width + kernel_w;\n                    if (image_hk < 0 || image_hk >= input_height) continue;\n                    if (image_wk < 0 || image_wk >= input_width) continue;\n                    #define gaid(N, C, H, W)                     ((((N)*gridDim.z + (C)) * output_height + (H)) * output_width + (W))\n                            int input_id = ((bid * gridDim.z +\n                                            kernel_id) *\n                                                input_height +\n                                            image_hk) *\n                                            input_width +\n                                        image_wk;\n                            s += output_grad_data[gaid(bid, kernel_id, image_h, image_w)] *\n                                input_data[input_id];\n\n                    #undef gaid\n                }\n            }\n        }\n        CudaAtomicAddWithWarp(&filter_grad_data[gbid], s);\n    }\n        ', cuda_src=f'\n    // source for backward to data\n        @alias(input, in0)\n        @alias(filter, in1)\n        @alias(output_grad, in2)\n        @alias(input_grad, out0)\n        @alias(filter_grad, out1)\n\n        const int batch_size = input_shape0;\n        const int input_channels = input_shape1;\n        const int input_height = input_shape2;\n        const int input_width = input_shape3;\n        const int output_channels = output_grad_shape1;\n        const int output_height = output_grad_shape2;\n        const int output_width = output_grad_shape3;\n        const int ksize_height = {Kh};\n        const int ksize_width = {Kw};\n        const int stride_height = {self.stride[0]};\n        const int stride_width = {self.stride[1]};\n        const int padding_height = {self.padding[0]};\n        const int padding_width = {self.padding[1]};\n        const int dilate_height = {self.dilation[0]};\n        const int dilate_width = {self.dilation[1]};\n\n        int thread = 512;\n        if (input_width > 1024 && input_width <= 2048)\n        thread = (input_width - 1) / 2 + 1;\n        else if (input_width > 512 && input_width <= 1024)\n        thread = input_width;\n        int blocks = std::min(std::max(thread / input_width, 1), input_height);\n        dim3 threads(std::min(input_width, thread), blocks, 1);\n        dim3 grid(input_channels, batch_size, 1);\n        KernelDepthwiseConvInputGradCFilter<\n            input_type, ksize_height, ksize_width\n            , stride_height, stride_width>\n            <<<grid, threads, 0>>>( \n            input_p, output_grad_p, filter_p, batch_size,          \n            output_channels, output_height, output_width, input_channels,   \n            input_height, input_width, padding_height,       \n            padding_width, dilate_height, dilate_width, input_grad_p);   \n\n    // source for backward to filter\n    \n        int block_size = 512;\n        if (output_width > 1024 && output_width <= 2048)\n        block_size = (output_width - 1) / 2 + 1;\n        else if (output_width > 512 && output_width <= 1024)\n        block_size = output_width;\n        int crop_output_height =\n            std::min(std::max(block_size / output_width, 1), output_height);\n\n        grid = dim3(ksize_width, ksize_height, output_channels);\n        threads = dim3(std::min(output_width, block_size), crop_output_height, 1);\n        cudaMemsetAsync(filter_grad_p, 0, filter_grad->size);\n\n        KernelDepthwiseConvFilterGrad<                                         \n            input_type><<<grid, threads, 0>>>(      \n            output_grad_p, input_p, batch_size, output_channels,           \n            output_height, output_width, input_channels, input_height,           \n            input_width, ksize_height, ksize_width,           \n            stride_height, stride_width, padding_height, padding_width,          \n            dilate_height, dilate_width, filter_grad_p);                      \n    ')