[
    {
        "func_name": "__init__",
        "original": "def __init__(self, num_classes, in_channels, train_cfg, test_cfg, feat_channels=256, use_direction_classifier=True, anchor_generator=dict(type='Anchor3DRangeGenerator', range=[0, -39.68, -1.78, 69.12, 39.68, -1.78], strides=[2], sizes=[[3.9, 1.6, 1.56]], rotations=[0, 1.57], custom_values=[], reshape_out=False), assigner_per_size=False, assign_per_class=False, diff_rad_by_sin=True, dir_offset=-np.pi / 2, dir_limit_offset=0, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_dir=dict(type='CrossEntropyLoss', loss_weight=0.2), init_cfg=None):\n    super().__init__(init_cfg=init_cfg)\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.feat_channels = feat_channels\n    self.diff_rad_by_sin = diff_rad_by_sin\n    self.use_direction_classifier = use_direction_classifier\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.assigner_per_size = assigner_per_size\n    self.assign_per_class = assign_per_class\n    self.dir_offset = dir_offset\n    self.dir_limit_offset = dir_limit_offset\n    import warnings\n    warnings.warn('dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future')\n    self.fp16_enabled = False\n    self.anchor_generator = build_prior_generator(anchor_generator)\n    self.num_anchors = self.anchor_generator.num_base_anchors\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.box_code_size = self.bbox_coder.code_size\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n    if not self.use_sigmoid_cls:\n        self.num_classes += 1\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_dir = build_loss(loss_dir)\n    self.fp16_enabled = False\n    self._init_layers()\n    self._init_assigner_sampler()\n    if init_cfg is None:\n        self.init_cfg = dict(type='Normal', layer='Conv2d', std=0.01, override=dict(type='Normal', name='conv_cls', std=0.01, bias_prob=0.01))",
        "mutated": [
            "def __init__(self, num_classes, in_channels, train_cfg, test_cfg, feat_channels=256, use_direction_classifier=True, anchor_generator=dict(type='Anchor3DRangeGenerator', range=[0, -39.68, -1.78, 69.12, 39.68, -1.78], strides=[2], sizes=[[3.9, 1.6, 1.56]], rotations=[0, 1.57], custom_values=[], reshape_out=False), assigner_per_size=False, assign_per_class=False, diff_rad_by_sin=True, dir_offset=-np.pi / 2, dir_limit_offset=0, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_dir=dict(type='CrossEntropyLoss', loss_weight=0.2), init_cfg=None):\n    if False:\n        i = 10\n    super().__init__(init_cfg=init_cfg)\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.feat_channels = feat_channels\n    self.diff_rad_by_sin = diff_rad_by_sin\n    self.use_direction_classifier = use_direction_classifier\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.assigner_per_size = assigner_per_size\n    self.assign_per_class = assign_per_class\n    self.dir_offset = dir_offset\n    self.dir_limit_offset = dir_limit_offset\n    import warnings\n    warnings.warn('dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future')\n    self.fp16_enabled = False\n    self.anchor_generator = build_prior_generator(anchor_generator)\n    self.num_anchors = self.anchor_generator.num_base_anchors\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.box_code_size = self.bbox_coder.code_size\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n    if not self.use_sigmoid_cls:\n        self.num_classes += 1\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_dir = build_loss(loss_dir)\n    self.fp16_enabled = False\n    self._init_layers()\n    self._init_assigner_sampler()\n    if init_cfg is None:\n        self.init_cfg = dict(type='Normal', layer='Conv2d', std=0.01, override=dict(type='Normal', name='conv_cls', std=0.01, bias_prob=0.01))",
            "def __init__(self, num_classes, in_channels, train_cfg, test_cfg, feat_channels=256, use_direction_classifier=True, anchor_generator=dict(type='Anchor3DRangeGenerator', range=[0, -39.68, -1.78, 69.12, 39.68, -1.78], strides=[2], sizes=[[3.9, 1.6, 1.56]], rotations=[0, 1.57], custom_values=[], reshape_out=False), assigner_per_size=False, assign_per_class=False, diff_rad_by_sin=True, dir_offset=-np.pi / 2, dir_limit_offset=0, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_dir=dict(type='CrossEntropyLoss', loss_weight=0.2), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__(init_cfg=init_cfg)\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.feat_channels = feat_channels\n    self.diff_rad_by_sin = diff_rad_by_sin\n    self.use_direction_classifier = use_direction_classifier\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.assigner_per_size = assigner_per_size\n    self.assign_per_class = assign_per_class\n    self.dir_offset = dir_offset\n    self.dir_limit_offset = dir_limit_offset\n    import warnings\n    warnings.warn('dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future')\n    self.fp16_enabled = False\n    self.anchor_generator = build_prior_generator(anchor_generator)\n    self.num_anchors = self.anchor_generator.num_base_anchors\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.box_code_size = self.bbox_coder.code_size\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n    if not self.use_sigmoid_cls:\n        self.num_classes += 1\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_dir = build_loss(loss_dir)\n    self.fp16_enabled = False\n    self._init_layers()\n    self._init_assigner_sampler()\n    if init_cfg is None:\n        self.init_cfg = dict(type='Normal', layer='Conv2d', std=0.01, override=dict(type='Normal', name='conv_cls', std=0.01, bias_prob=0.01))",
            "def __init__(self, num_classes, in_channels, train_cfg, test_cfg, feat_channels=256, use_direction_classifier=True, anchor_generator=dict(type='Anchor3DRangeGenerator', range=[0, -39.68, -1.78, 69.12, 39.68, -1.78], strides=[2], sizes=[[3.9, 1.6, 1.56]], rotations=[0, 1.57], custom_values=[], reshape_out=False), assigner_per_size=False, assign_per_class=False, diff_rad_by_sin=True, dir_offset=-np.pi / 2, dir_limit_offset=0, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_dir=dict(type='CrossEntropyLoss', loss_weight=0.2), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__(init_cfg=init_cfg)\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.feat_channels = feat_channels\n    self.diff_rad_by_sin = diff_rad_by_sin\n    self.use_direction_classifier = use_direction_classifier\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.assigner_per_size = assigner_per_size\n    self.assign_per_class = assign_per_class\n    self.dir_offset = dir_offset\n    self.dir_limit_offset = dir_limit_offset\n    import warnings\n    warnings.warn('dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future')\n    self.fp16_enabled = False\n    self.anchor_generator = build_prior_generator(anchor_generator)\n    self.num_anchors = self.anchor_generator.num_base_anchors\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.box_code_size = self.bbox_coder.code_size\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n    if not self.use_sigmoid_cls:\n        self.num_classes += 1\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_dir = build_loss(loss_dir)\n    self.fp16_enabled = False\n    self._init_layers()\n    self._init_assigner_sampler()\n    if init_cfg is None:\n        self.init_cfg = dict(type='Normal', layer='Conv2d', std=0.01, override=dict(type='Normal', name='conv_cls', std=0.01, bias_prob=0.01))",
            "def __init__(self, num_classes, in_channels, train_cfg, test_cfg, feat_channels=256, use_direction_classifier=True, anchor_generator=dict(type='Anchor3DRangeGenerator', range=[0, -39.68, -1.78, 69.12, 39.68, -1.78], strides=[2], sizes=[[3.9, 1.6, 1.56]], rotations=[0, 1.57], custom_values=[], reshape_out=False), assigner_per_size=False, assign_per_class=False, diff_rad_by_sin=True, dir_offset=-np.pi / 2, dir_limit_offset=0, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_dir=dict(type='CrossEntropyLoss', loss_weight=0.2), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__(init_cfg=init_cfg)\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.feat_channels = feat_channels\n    self.diff_rad_by_sin = diff_rad_by_sin\n    self.use_direction_classifier = use_direction_classifier\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.assigner_per_size = assigner_per_size\n    self.assign_per_class = assign_per_class\n    self.dir_offset = dir_offset\n    self.dir_limit_offset = dir_limit_offset\n    import warnings\n    warnings.warn('dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future')\n    self.fp16_enabled = False\n    self.anchor_generator = build_prior_generator(anchor_generator)\n    self.num_anchors = self.anchor_generator.num_base_anchors\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.box_code_size = self.bbox_coder.code_size\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n    if not self.use_sigmoid_cls:\n        self.num_classes += 1\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_dir = build_loss(loss_dir)\n    self.fp16_enabled = False\n    self._init_layers()\n    self._init_assigner_sampler()\n    if init_cfg is None:\n        self.init_cfg = dict(type='Normal', layer='Conv2d', std=0.01, override=dict(type='Normal', name='conv_cls', std=0.01, bias_prob=0.01))",
            "def __init__(self, num_classes, in_channels, train_cfg, test_cfg, feat_channels=256, use_direction_classifier=True, anchor_generator=dict(type='Anchor3DRangeGenerator', range=[0, -39.68, -1.78, 69.12, 39.68, -1.78], strides=[2], sizes=[[3.9, 1.6, 1.56]], rotations=[0, 1.57], custom_values=[], reshape_out=False), assigner_per_size=False, assign_per_class=False, diff_rad_by_sin=True, dir_offset=-np.pi / 2, dir_limit_offset=0, bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'), loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=2.0), loss_dir=dict(type='CrossEntropyLoss', loss_weight=0.2), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__(init_cfg=init_cfg)\n    self.in_channels = in_channels\n    self.num_classes = num_classes\n    self.feat_channels = feat_channels\n    self.diff_rad_by_sin = diff_rad_by_sin\n    self.use_direction_classifier = use_direction_classifier\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.assigner_per_size = assigner_per_size\n    self.assign_per_class = assign_per_class\n    self.dir_offset = dir_offset\n    self.dir_limit_offset = dir_limit_offset\n    import warnings\n    warnings.warn('dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future')\n    self.fp16_enabled = False\n    self.anchor_generator = build_prior_generator(anchor_generator)\n    self.num_anchors = self.anchor_generator.num_base_anchors\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.box_code_size = self.bbox_coder.code_size\n    self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n    self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n    if not self.use_sigmoid_cls:\n        self.num_classes += 1\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_bbox = build_loss(loss_bbox)\n    self.loss_dir = build_loss(loss_dir)\n    self.fp16_enabled = False\n    self._init_layers()\n    self._init_assigner_sampler()\n    if init_cfg is None:\n        self.init_cfg = dict(type='Normal', layer='Conv2d', std=0.01, override=dict(type='Normal', name='conv_cls', std=0.01, bias_prob=0.01))"
        ]
    },
    {
        "func_name": "_init_assigner_sampler",
        "original": "def _init_assigner_sampler(self):\n    \"\"\"Initialize the target assigner and sampler of the head.\"\"\"\n    if self.train_cfg is None:\n        return\n    if self.sampling:\n        self.bbox_sampler = build_sampler(self.train_cfg.sampler)\n    else:\n        self.bbox_sampler = PseudoSampler()\n    if isinstance(self.train_cfg.assigner, dict):\n        self.bbox_assigner = build_assigner(self.train_cfg.assigner)\n    elif isinstance(self.train_cfg.assigner, list):\n        self.bbox_assigner = [build_assigner(res) for res in self.train_cfg.assigner]",
        "mutated": [
            "def _init_assigner_sampler(self):\n    if False:\n        i = 10\n    'Initialize the target assigner and sampler of the head.'\n    if self.train_cfg is None:\n        return\n    if self.sampling:\n        self.bbox_sampler = build_sampler(self.train_cfg.sampler)\n    else:\n        self.bbox_sampler = PseudoSampler()\n    if isinstance(self.train_cfg.assigner, dict):\n        self.bbox_assigner = build_assigner(self.train_cfg.assigner)\n    elif isinstance(self.train_cfg.assigner, list):\n        self.bbox_assigner = [build_assigner(res) for res in self.train_cfg.assigner]",
            "def _init_assigner_sampler(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initialize the target assigner and sampler of the head.'\n    if self.train_cfg is None:\n        return\n    if self.sampling:\n        self.bbox_sampler = build_sampler(self.train_cfg.sampler)\n    else:\n        self.bbox_sampler = PseudoSampler()\n    if isinstance(self.train_cfg.assigner, dict):\n        self.bbox_assigner = build_assigner(self.train_cfg.assigner)\n    elif isinstance(self.train_cfg.assigner, list):\n        self.bbox_assigner = [build_assigner(res) for res in self.train_cfg.assigner]",
            "def _init_assigner_sampler(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initialize the target assigner and sampler of the head.'\n    if self.train_cfg is None:\n        return\n    if self.sampling:\n        self.bbox_sampler = build_sampler(self.train_cfg.sampler)\n    else:\n        self.bbox_sampler = PseudoSampler()\n    if isinstance(self.train_cfg.assigner, dict):\n        self.bbox_assigner = build_assigner(self.train_cfg.assigner)\n    elif isinstance(self.train_cfg.assigner, list):\n        self.bbox_assigner = [build_assigner(res) for res in self.train_cfg.assigner]",
            "def _init_assigner_sampler(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initialize the target assigner and sampler of the head.'\n    if self.train_cfg is None:\n        return\n    if self.sampling:\n        self.bbox_sampler = build_sampler(self.train_cfg.sampler)\n    else:\n        self.bbox_sampler = PseudoSampler()\n    if isinstance(self.train_cfg.assigner, dict):\n        self.bbox_assigner = build_assigner(self.train_cfg.assigner)\n    elif isinstance(self.train_cfg.assigner, list):\n        self.bbox_assigner = [build_assigner(res) for res in self.train_cfg.assigner]",
            "def _init_assigner_sampler(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initialize the target assigner and sampler of the head.'\n    if self.train_cfg is None:\n        return\n    if self.sampling:\n        self.bbox_sampler = build_sampler(self.train_cfg.sampler)\n    else:\n        self.bbox_sampler = PseudoSampler()\n    if isinstance(self.train_cfg.assigner, dict):\n        self.bbox_assigner = build_assigner(self.train_cfg.assigner)\n    elif isinstance(self.train_cfg.assigner, list):\n        self.bbox_assigner = [build_assigner(res) for res in self.train_cfg.assigner]"
        ]
    },
    {
        "func_name": "_init_layers",
        "original": "def _init_layers(self):\n    \"\"\"Initialize neural network layers of the head.\"\"\"\n    self.cls_out_channels = self.num_anchors * self.num_classes\n    self.conv_cls = nn.Conv2d(self.feat_channels, self.cls_out_channels, 1)\n    self.conv_reg = nn.Conv2d(self.feat_channels, self.num_anchors * self.box_code_size, 1)\n    if self.use_direction_classifier:\n        self.conv_dir_cls = nn.Conv2d(self.feat_channels, self.num_anchors * 2, 1)",
        "mutated": [
            "def _init_layers(self):\n    if False:\n        i = 10\n    'Initialize neural network layers of the head.'\n    self.cls_out_channels = self.num_anchors * self.num_classes\n    self.conv_cls = nn.Conv2d(self.feat_channels, self.cls_out_channels, 1)\n    self.conv_reg = nn.Conv2d(self.feat_channels, self.num_anchors * self.box_code_size, 1)\n    if self.use_direction_classifier:\n        self.conv_dir_cls = nn.Conv2d(self.feat_channels, self.num_anchors * 2, 1)",
            "def _init_layers(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initialize neural network layers of the head.'\n    self.cls_out_channels = self.num_anchors * self.num_classes\n    self.conv_cls = nn.Conv2d(self.feat_channels, self.cls_out_channels, 1)\n    self.conv_reg = nn.Conv2d(self.feat_channels, self.num_anchors * self.box_code_size, 1)\n    if self.use_direction_classifier:\n        self.conv_dir_cls = nn.Conv2d(self.feat_channels, self.num_anchors * 2, 1)",
            "def _init_layers(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initialize neural network layers of the head.'\n    self.cls_out_channels = self.num_anchors * self.num_classes\n    self.conv_cls = nn.Conv2d(self.feat_channels, self.cls_out_channels, 1)\n    self.conv_reg = nn.Conv2d(self.feat_channels, self.num_anchors * self.box_code_size, 1)\n    if self.use_direction_classifier:\n        self.conv_dir_cls = nn.Conv2d(self.feat_channels, self.num_anchors * 2, 1)",
            "def _init_layers(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initialize neural network layers of the head.'\n    self.cls_out_channels = self.num_anchors * self.num_classes\n    self.conv_cls = nn.Conv2d(self.feat_channels, self.cls_out_channels, 1)\n    self.conv_reg = nn.Conv2d(self.feat_channels, self.num_anchors * self.box_code_size, 1)\n    if self.use_direction_classifier:\n        self.conv_dir_cls = nn.Conv2d(self.feat_channels, self.num_anchors * 2, 1)",
            "def _init_layers(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initialize neural network layers of the head.'\n    self.cls_out_channels = self.num_anchors * self.num_classes\n    self.conv_cls = nn.Conv2d(self.feat_channels, self.cls_out_channels, 1)\n    self.conv_reg = nn.Conv2d(self.feat_channels, self.num_anchors * self.box_code_size, 1)\n    if self.use_direction_classifier:\n        self.conv_dir_cls = nn.Conv2d(self.feat_channels, self.num_anchors * 2, 1)"
        ]
    },
    {
        "func_name": "forward_single",
        "original": "def forward_single(self, x):\n    \"\"\"Forward function on a single-scale feature map.\n\n        Args:\n            x (torch.Tensor): Input features.\n\n        Returns:\n            tuple[torch.Tensor]: Contain score of each class, bbox\n                regression and direction classification predictions.\n        \"\"\"\n    cls_score = self.conv_cls(x)\n    bbox_pred = self.conv_reg(x)\n    dir_cls_preds = None\n    if self.use_direction_classifier:\n        dir_cls_preds = self.conv_dir_cls(x)\n    return (cls_score, bbox_pred, dir_cls_preds)",
        "mutated": [
            "def forward_single(self, x):\n    if False:\n        i = 10\n    'Forward function on a single-scale feature map.\\n\\n        Args:\\n            x (torch.Tensor): Input features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Contain score of each class, bbox\\n                regression and direction classification predictions.\\n        '\n    cls_score = self.conv_cls(x)\n    bbox_pred = self.conv_reg(x)\n    dir_cls_preds = None\n    if self.use_direction_classifier:\n        dir_cls_preds = self.conv_dir_cls(x)\n    return (cls_score, bbox_pred, dir_cls_preds)",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward function on a single-scale feature map.\\n\\n        Args:\\n            x (torch.Tensor): Input features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Contain score of each class, bbox\\n                regression and direction classification predictions.\\n        '\n    cls_score = self.conv_cls(x)\n    bbox_pred = self.conv_reg(x)\n    dir_cls_preds = None\n    if self.use_direction_classifier:\n        dir_cls_preds = self.conv_dir_cls(x)\n    return (cls_score, bbox_pred, dir_cls_preds)",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward function on a single-scale feature map.\\n\\n        Args:\\n            x (torch.Tensor): Input features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Contain score of each class, bbox\\n                regression and direction classification predictions.\\n        '\n    cls_score = self.conv_cls(x)\n    bbox_pred = self.conv_reg(x)\n    dir_cls_preds = None\n    if self.use_direction_classifier:\n        dir_cls_preds = self.conv_dir_cls(x)\n    return (cls_score, bbox_pred, dir_cls_preds)",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward function on a single-scale feature map.\\n\\n        Args:\\n            x (torch.Tensor): Input features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Contain score of each class, bbox\\n                regression and direction classification predictions.\\n        '\n    cls_score = self.conv_cls(x)\n    bbox_pred = self.conv_reg(x)\n    dir_cls_preds = None\n    if self.use_direction_classifier:\n        dir_cls_preds = self.conv_dir_cls(x)\n    return (cls_score, bbox_pred, dir_cls_preds)",
            "def forward_single(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward function on a single-scale feature map.\\n\\n        Args:\\n            x (torch.Tensor): Input features.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Contain score of each class, bbox\\n                regression and direction classification predictions.\\n        '\n    cls_score = self.conv_cls(x)\n    bbox_pred = self.conv_reg(x)\n    dir_cls_preds = None\n    if self.use_direction_classifier:\n        dir_cls_preds = self.conv_dir_cls(x)\n    return (cls_score, bbox_pred, dir_cls_preds)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, feats):\n    \"\"\"Forward pass.\n\n        Args:\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\n                features produced by FPN.\n\n        Returns:\n            tuple[list[torch.Tensor]]: Multi-level class score, bbox\n                and direction predictions.\n        \"\"\"\n    return multi_apply(self.forward_single, feats)",
        "mutated": [
            "def forward(self, feats):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Multi-level class score, bbox\\n                and direction predictions.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Multi-level class score, bbox\\n                and direction predictions.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Multi-level class score, bbox\\n                and direction predictions.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Multi-level class score, bbox\\n                and direction predictions.\\n        '\n    return multi_apply(self.forward_single, feats)",
            "def forward(self, feats):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            feats (list[torch.Tensor]): Multi-level features, e.g.,\\n                features produced by FPN.\\n\\n        Returns:\\n            tuple[list[torch.Tensor]]: Multi-level class score, bbox\\n                and direction predictions.\\n        '\n    return multi_apply(self.forward_single, feats)"
        ]
    },
    {
        "func_name": "get_anchors",
        "original": "def get_anchors(self, featmap_sizes, input_metas, device='cuda'):\n    \"\"\"Get anchors according to feature map sizes.\n\n        Args:\n            featmap_sizes (list[tuple]): Multi-level feature map sizes.\n            input_metas (list[dict]): contain pcd and img's meta info.\n            device (str): device of current module.\n\n        Returns:\n            list[list[torch.Tensor]]: Anchors of each image, valid flags\n                of each image.\n        \"\"\"\n    num_imgs = len(input_metas)\n    multi_level_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n    return anchor_list",
        "mutated": [
            "def get_anchors(self, featmap_sizes, input_metas, device='cuda'):\n    if False:\n        i = 10\n    \"Get anchors according to feature map sizes.\\n\\n        Args:\\n            featmap_sizes (list[tuple]): Multi-level feature map sizes.\\n            input_metas (list[dict]): contain pcd and img's meta info.\\n            device (str): device of current module.\\n\\n        Returns:\\n            list[list[torch.Tensor]]: Anchors of each image, valid flags\\n                of each image.\\n        \"\n    num_imgs = len(input_metas)\n    multi_level_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n    return anchor_list",
            "def get_anchors(self, featmap_sizes, input_metas, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Get anchors according to feature map sizes.\\n\\n        Args:\\n            featmap_sizes (list[tuple]): Multi-level feature map sizes.\\n            input_metas (list[dict]): contain pcd and img's meta info.\\n            device (str): device of current module.\\n\\n        Returns:\\n            list[list[torch.Tensor]]: Anchors of each image, valid flags\\n                of each image.\\n        \"\n    num_imgs = len(input_metas)\n    multi_level_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n    return anchor_list",
            "def get_anchors(self, featmap_sizes, input_metas, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Get anchors according to feature map sizes.\\n\\n        Args:\\n            featmap_sizes (list[tuple]): Multi-level feature map sizes.\\n            input_metas (list[dict]): contain pcd and img's meta info.\\n            device (str): device of current module.\\n\\n        Returns:\\n            list[list[torch.Tensor]]: Anchors of each image, valid flags\\n                of each image.\\n        \"\n    num_imgs = len(input_metas)\n    multi_level_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n    return anchor_list",
            "def get_anchors(self, featmap_sizes, input_metas, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Get anchors according to feature map sizes.\\n\\n        Args:\\n            featmap_sizes (list[tuple]): Multi-level feature map sizes.\\n            input_metas (list[dict]): contain pcd and img's meta info.\\n            device (str): device of current module.\\n\\n        Returns:\\n            list[list[torch.Tensor]]: Anchors of each image, valid flags\\n                of each image.\\n        \"\n    num_imgs = len(input_metas)\n    multi_level_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n    return anchor_list",
            "def get_anchors(self, featmap_sizes, input_metas, device='cuda'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Get anchors according to feature map sizes.\\n\\n        Args:\\n            featmap_sizes (list[tuple]): Multi-level feature map sizes.\\n            input_metas (list[dict]): contain pcd and img's meta info.\\n            device (str): device of current module.\\n\\n        Returns:\\n            list[list[torch.Tensor]]: Anchors of each image, valid flags\\n                of each image.\\n        \"\n    num_imgs = len(input_metas)\n    multi_level_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n    return anchor_list"
        ]
    },
    {
        "func_name": "loss_single",
        "original": "def loss_single(self, cls_score, bbox_pred, dir_cls_preds, labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, num_total_samples):\n    \"\"\"Calculate loss of Single-level results.\n\n        Args:\n            cls_score (torch.Tensor): Class score in single-level.\n            bbox_pred (torch.Tensor): Bbox prediction in single-level.\n            dir_cls_preds (torch.Tensor): Predictions of direction class\n                in single-level.\n            labels (torch.Tensor): Labels of class.\n            label_weights (torch.Tensor): Weights of class loss.\n            bbox_targets (torch.Tensor): Targets of bbox predictions.\n            bbox_weights (torch.Tensor): Weights of bbox loss.\n            dir_targets (torch.Tensor): Targets of direction predictions.\n            dir_weights (torch.Tensor): Weights of direction loss.\n            num_total_samples (int): The number of valid samples.\n\n        Returns:\n            tuple[torch.Tensor]: Losses of class, bbox\n                and direction, respectively.\n        \"\"\"\n    if num_total_samples is None:\n        num_total_samples = int(cls_score.shape[0])\n    labels = labels.reshape(-1)\n    label_weights = label_weights.reshape(-1)\n    cls_score = cls_score.permute(0, 2, 3, 1).reshape(-1, self.num_classes)\n    assert labels.max().item() <= self.num_classes\n    loss_cls = self.loss_cls(cls_score, labels, label_weights, avg_factor=num_total_samples)\n    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, self.box_code_size)\n    bbox_targets = bbox_targets.reshape(-1, self.box_code_size)\n    bbox_weights = bbox_weights.reshape(-1, self.box_code_size)\n    bg_class_ind = self.num_classes\n    pos_inds = ((labels >= 0) & (labels < bg_class_ind)).nonzero(as_tuple=False).reshape(-1)\n    num_pos = len(pos_inds)\n    pos_bbox_pred = bbox_pred[pos_inds]\n    pos_bbox_targets = bbox_targets[pos_inds]\n    pos_bbox_weights = bbox_weights[pos_inds]\n    if self.use_direction_classifier:\n        dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).reshape(-1, 2)\n        dir_targets = dir_targets.reshape(-1)\n        dir_weights = dir_weights.reshape(-1)\n        pos_dir_cls_preds = dir_cls_preds[pos_inds]\n        pos_dir_targets = dir_targets[pos_inds]\n        pos_dir_weights = dir_weights[pos_inds]\n    if num_pos > 0:\n        code_weight = self.train_cfg.get('code_weight', None)\n        if code_weight:\n            pos_bbox_weights = pos_bbox_weights * bbox_weights.new_tensor(code_weight)\n        if self.diff_rad_by_sin:\n            (pos_bbox_pred, pos_bbox_targets) = self.add_sin_difference(pos_bbox_pred, pos_bbox_targets)\n        loss_bbox = self.loss_bbox(pos_bbox_pred, pos_bbox_targets, pos_bbox_weights, avg_factor=num_total_samples)\n        loss_dir = None\n        if self.use_direction_classifier:\n            loss_dir = self.loss_dir(pos_dir_cls_preds, pos_dir_targets, pos_dir_weights, avg_factor=num_total_samples)\n    else:\n        loss_bbox = pos_bbox_pred.sum()\n        if self.use_direction_classifier:\n            loss_dir = pos_dir_cls_preds.sum()\n    return (loss_cls, loss_bbox, loss_dir)",
        "mutated": [
            "def loss_single(self, cls_score, bbox_pred, dir_cls_preds, labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, num_total_samples):\n    if False:\n        i = 10\n    'Calculate loss of Single-level results.\\n\\n        Args:\\n            cls_score (torch.Tensor): Class score in single-level.\\n            bbox_pred (torch.Tensor): Bbox prediction in single-level.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single-level.\\n            labels (torch.Tensor): Labels of class.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_targets (torch.Tensor): Targets of bbox predictions.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n            dir_targets (torch.Tensor): Targets of direction predictions.\\n            dir_weights (torch.Tensor): Weights of direction loss.\\n            num_total_samples (int): The number of valid samples.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Losses of class, bbox\\n                and direction, respectively.\\n        '\n    if num_total_samples is None:\n        num_total_samples = int(cls_score.shape[0])\n    labels = labels.reshape(-1)\n    label_weights = label_weights.reshape(-1)\n    cls_score = cls_score.permute(0, 2, 3, 1).reshape(-1, self.num_classes)\n    assert labels.max().item() <= self.num_classes\n    loss_cls = self.loss_cls(cls_score, labels, label_weights, avg_factor=num_total_samples)\n    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, self.box_code_size)\n    bbox_targets = bbox_targets.reshape(-1, self.box_code_size)\n    bbox_weights = bbox_weights.reshape(-1, self.box_code_size)\n    bg_class_ind = self.num_classes\n    pos_inds = ((labels >= 0) & (labels < bg_class_ind)).nonzero(as_tuple=False).reshape(-1)\n    num_pos = len(pos_inds)\n    pos_bbox_pred = bbox_pred[pos_inds]\n    pos_bbox_targets = bbox_targets[pos_inds]\n    pos_bbox_weights = bbox_weights[pos_inds]\n    if self.use_direction_classifier:\n        dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).reshape(-1, 2)\n        dir_targets = dir_targets.reshape(-1)\n        dir_weights = dir_weights.reshape(-1)\n        pos_dir_cls_preds = dir_cls_preds[pos_inds]\n        pos_dir_targets = dir_targets[pos_inds]\n        pos_dir_weights = dir_weights[pos_inds]\n    if num_pos > 0:\n        code_weight = self.train_cfg.get('code_weight', None)\n        if code_weight:\n            pos_bbox_weights = pos_bbox_weights * bbox_weights.new_tensor(code_weight)\n        if self.diff_rad_by_sin:\n            (pos_bbox_pred, pos_bbox_targets) = self.add_sin_difference(pos_bbox_pred, pos_bbox_targets)\n        loss_bbox = self.loss_bbox(pos_bbox_pred, pos_bbox_targets, pos_bbox_weights, avg_factor=num_total_samples)\n        loss_dir = None\n        if self.use_direction_classifier:\n            loss_dir = self.loss_dir(pos_dir_cls_preds, pos_dir_targets, pos_dir_weights, avg_factor=num_total_samples)\n    else:\n        loss_bbox = pos_bbox_pred.sum()\n        if self.use_direction_classifier:\n            loss_dir = pos_dir_cls_preds.sum()\n    return (loss_cls, loss_bbox, loss_dir)",
            "def loss_single(self, cls_score, bbox_pred, dir_cls_preds, labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, num_total_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Calculate loss of Single-level results.\\n\\n        Args:\\n            cls_score (torch.Tensor): Class score in single-level.\\n            bbox_pred (torch.Tensor): Bbox prediction in single-level.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single-level.\\n            labels (torch.Tensor): Labels of class.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_targets (torch.Tensor): Targets of bbox predictions.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n            dir_targets (torch.Tensor): Targets of direction predictions.\\n            dir_weights (torch.Tensor): Weights of direction loss.\\n            num_total_samples (int): The number of valid samples.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Losses of class, bbox\\n                and direction, respectively.\\n        '\n    if num_total_samples is None:\n        num_total_samples = int(cls_score.shape[0])\n    labels = labels.reshape(-1)\n    label_weights = label_weights.reshape(-1)\n    cls_score = cls_score.permute(0, 2, 3, 1).reshape(-1, self.num_classes)\n    assert labels.max().item() <= self.num_classes\n    loss_cls = self.loss_cls(cls_score, labels, label_weights, avg_factor=num_total_samples)\n    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, self.box_code_size)\n    bbox_targets = bbox_targets.reshape(-1, self.box_code_size)\n    bbox_weights = bbox_weights.reshape(-1, self.box_code_size)\n    bg_class_ind = self.num_classes\n    pos_inds = ((labels >= 0) & (labels < bg_class_ind)).nonzero(as_tuple=False).reshape(-1)\n    num_pos = len(pos_inds)\n    pos_bbox_pred = bbox_pred[pos_inds]\n    pos_bbox_targets = bbox_targets[pos_inds]\n    pos_bbox_weights = bbox_weights[pos_inds]\n    if self.use_direction_classifier:\n        dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).reshape(-1, 2)\n        dir_targets = dir_targets.reshape(-1)\n        dir_weights = dir_weights.reshape(-1)\n        pos_dir_cls_preds = dir_cls_preds[pos_inds]\n        pos_dir_targets = dir_targets[pos_inds]\n        pos_dir_weights = dir_weights[pos_inds]\n    if num_pos > 0:\n        code_weight = self.train_cfg.get('code_weight', None)\n        if code_weight:\n            pos_bbox_weights = pos_bbox_weights * bbox_weights.new_tensor(code_weight)\n        if self.diff_rad_by_sin:\n            (pos_bbox_pred, pos_bbox_targets) = self.add_sin_difference(pos_bbox_pred, pos_bbox_targets)\n        loss_bbox = self.loss_bbox(pos_bbox_pred, pos_bbox_targets, pos_bbox_weights, avg_factor=num_total_samples)\n        loss_dir = None\n        if self.use_direction_classifier:\n            loss_dir = self.loss_dir(pos_dir_cls_preds, pos_dir_targets, pos_dir_weights, avg_factor=num_total_samples)\n    else:\n        loss_bbox = pos_bbox_pred.sum()\n        if self.use_direction_classifier:\n            loss_dir = pos_dir_cls_preds.sum()\n    return (loss_cls, loss_bbox, loss_dir)",
            "def loss_single(self, cls_score, bbox_pred, dir_cls_preds, labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, num_total_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Calculate loss of Single-level results.\\n\\n        Args:\\n            cls_score (torch.Tensor): Class score in single-level.\\n            bbox_pred (torch.Tensor): Bbox prediction in single-level.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single-level.\\n            labels (torch.Tensor): Labels of class.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_targets (torch.Tensor): Targets of bbox predictions.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n            dir_targets (torch.Tensor): Targets of direction predictions.\\n            dir_weights (torch.Tensor): Weights of direction loss.\\n            num_total_samples (int): The number of valid samples.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Losses of class, bbox\\n                and direction, respectively.\\n        '\n    if num_total_samples is None:\n        num_total_samples = int(cls_score.shape[0])\n    labels = labels.reshape(-1)\n    label_weights = label_weights.reshape(-1)\n    cls_score = cls_score.permute(0, 2, 3, 1).reshape(-1, self.num_classes)\n    assert labels.max().item() <= self.num_classes\n    loss_cls = self.loss_cls(cls_score, labels, label_weights, avg_factor=num_total_samples)\n    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, self.box_code_size)\n    bbox_targets = bbox_targets.reshape(-1, self.box_code_size)\n    bbox_weights = bbox_weights.reshape(-1, self.box_code_size)\n    bg_class_ind = self.num_classes\n    pos_inds = ((labels >= 0) & (labels < bg_class_ind)).nonzero(as_tuple=False).reshape(-1)\n    num_pos = len(pos_inds)\n    pos_bbox_pred = bbox_pred[pos_inds]\n    pos_bbox_targets = bbox_targets[pos_inds]\n    pos_bbox_weights = bbox_weights[pos_inds]\n    if self.use_direction_classifier:\n        dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).reshape(-1, 2)\n        dir_targets = dir_targets.reshape(-1)\n        dir_weights = dir_weights.reshape(-1)\n        pos_dir_cls_preds = dir_cls_preds[pos_inds]\n        pos_dir_targets = dir_targets[pos_inds]\n        pos_dir_weights = dir_weights[pos_inds]\n    if num_pos > 0:\n        code_weight = self.train_cfg.get('code_weight', None)\n        if code_weight:\n            pos_bbox_weights = pos_bbox_weights * bbox_weights.new_tensor(code_weight)\n        if self.diff_rad_by_sin:\n            (pos_bbox_pred, pos_bbox_targets) = self.add_sin_difference(pos_bbox_pred, pos_bbox_targets)\n        loss_bbox = self.loss_bbox(pos_bbox_pred, pos_bbox_targets, pos_bbox_weights, avg_factor=num_total_samples)\n        loss_dir = None\n        if self.use_direction_classifier:\n            loss_dir = self.loss_dir(pos_dir_cls_preds, pos_dir_targets, pos_dir_weights, avg_factor=num_total_samples)\n    else:\n        loss_bbox = pos_bbox_pred.sum()\n        if self.use_direction_classifier:\n            loss_dir = pos_dir_cls_preds.sum()\n    return (loss_cls, loss_bbox, loss_dir)",
            "def loss_single(self, cls_score, bbox_pred, dir_cls_preds, labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, num_total_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Calculate loss of Single-level results.\\n\\n        Args:\\n            cls_score (torch.Tensor): Class score in single-level.\\n            bbox_pred (torch.Tensor): Bbox prediction in single-level.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single-level.\\n            labels (torch.Tensor): Labels of class.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_targets (torch.Tensor): Targets of bbox predictions.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n            dir_targets (torch.Tensor): Targets of direction predictions.\\n            dir_weights (torch.Tensor): Weights of direction loss.\\n            num_total_samples (int): The number of valid samples.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Losses of class, bbox\\n                and direction, respectively.\\n        '\n    if num_total_samples is None:\n        num_total_samples = int(cls_score.shape[0])\n    labels = labels.reshape(-1)\n    label_weights = label_weights.reshape(-1)\n    cls_score = cls_score.permute(0, 2, 3, 1).reshape(-1, self.num_classes)\n    assert labels.max().item() <= self.num_classes\n    loss_cls = self.loss_cls(cls_score, labels, label_weights, avg_factor=num_total_samples)\n    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, self.box_code_size)\n    bbox_targets = bbox_targets.reshape(-1, self.box_code_size)\n    bbox_weights = bbox_weights.reshape(-1, self.box_code_size)\n    bg_class_ind = self.num_classes\n    pos_inds = ((labels >= 0) & (labels < bg_class_ind)).nonzero(as_tuple=False).reshape(-1)\n    num_pos = len(pos_inds)\n    pos_bbox_pred = bbox_pred[pos_inds]\n    pos_bbox_targets = bbox_targets[pos_inds]\n    pos_bbox_weights = bbox_weights[pos_inds]\n    if self.use_direction_classifier:\n        dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).reshape(-1, 2)\n        dir_targets = dir_targets.reshape(-1)\n        dir_weights = dir_weights.reshape(-1)\n        pos_dir_cls_preds = dir_cls_preds[pos_inds]\n        pos_dir_targets = dir_targets[pos_inds]\n        pos_dir_weights = dir_weights[pos_inds]\n    if num_pos > 0:\n        code_weight = self.train_cfg.get('code_weight', None)\n        if code_weight:\n            pos_bbox_weights = pos_bbox_weights * bbox_weights.new_tensor(code_weight)\n        if self.diff_rad_by_sin:\n            (pos_bbox_pred, pos_bbox_targets) = self.add_sin_difference(pos_bbox_pred, pos_bbox_targets)\n        loss_bbox = self.loss_bbox(pos_bbox_pred, pos_bbox_targets, pos_bbox_weights, avg_factor=num_total_samples)\n        loss_dir = None\n        if self.use_direction_classifier:\n            loss_dir = self.loss_dir(pos_dir_cls_preds, pos_dir_targets, pos_dir_weights, avg_factor=num_total_samples)\n    else:\n        loss_bbox = pos_bbox_pred.sum()\n        if self.use_direction_classifier:\n            loss_dir = pos_dir_cls_preds.sum()\n    return (loss_cls, loss_bbox, loss_dir)",
            "def loss_single(self, cls_score, bbox_pred, dir_cls_preds, labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, num_total_samples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Calculate loss of Single-level results.\\n\\n        Args:\\n            cls_score (torch.Tensor): Class score in single-level.\\n            bbox_pred (torch.Tensor): Bbox prediction in single-level.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single-level.\\n            labels (torch.Tensor): Labels of class.\\n            label_weights (torch.Tensor): Weights of class loss.\\n            bbox_targets (torch.Tensor): Targets of bbox predictions.\\n            bbox_weights (torch.Tensor): Weights of bbox loss.\\n            dir_targets (torch.Tensor): Targets of direction predictions.\\n            dir_weights (torch.Tensor): Weights of direction loss.\\n            num_total_samples (int): The number of valid samples.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Losses of class, bbox\\n                and direction, respectively.\\n        '\n    if num_total_samples is None:\n        num_total_samples = int(cls_score.shape[0])\n    labels = labels.reshape(-1)\n    label_weights = label_weights.reshape(-1)\n    cls_score = cls_score.permute(0, 2, 3, 1).reshape(-1, self.num_classes)\n    assert labels.max().item() <= self.num_classes\n    loss_cls = self.loss_cls(cls_score, labels, label_weights, avg_factor=num_total_samples)\n    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(-1, self.box_code_size)\n    bbox_targets = bbox_targets.reshape(-1, self.box_code_size)\n    bbox_weights = bbox_weights.reshape(-1, self.box_code_size)\n    bg_class_ind = self.num_classes\n    pos_inds = ((labels >= 0) & (labels < bg_class_ind)).nonzero(as_tuple=False).reshape(-1)\n    num_pos = len(pos_inds)\n    pos_bbox_pred = bbox_pred[pos_inds]\n    pos_bbox_targets = bbox_targets[pos_inds]\n    pos_bbox_weights = bbox_weights[pos_inds]\n    if self.use_direction_classifier:\n        dir_cls_preds = dir_cls_preds.permute(0, 2, 3, 1).reshape(-1, 2)\n        dir_targets = dir_targets.reshape(-1)\n        dir_weights = dir_weights.reshape(-1)\n        pos_dir_cls_preds = dir_cls_preds[pos_inds]\n        pos_dir_targets = dir_targets[pos_inds]\n        pos_dir_weights = dir_weights[pos_inds]\n    if num_pos > 0:\n        code_weight = self.train_cfg.get('code_weight', None)\n        if code_weight:\n            pos_bbox_weights = pos_bbox_weights * bbox_weights.new_tensor(code_weight)\n        if self.diff_rad_by_sin:\n            (pos_bbox_pred, pos_bbox_targets) = self.add_sin_difference(pos_bbox_pred, pos_bbox_targets)\n        loss_bbox = self.loss_bbox(pos_bbox_pred, pos_bbox_targets, pos_bbox_weights, avg_factor=num_total_samples)\n        loss_dir = None\n        if self.use_direction_classifier:\n            loss_dir = self.loss_dir(pos_dir_cls_preds, pos_dir_targets, pos_dir_weights, avg_factor=num_total_samples)\n    else:\n        loss_bbox = pos_bbox_pred.sum()\n        if self.use_direction_classifier:\n            loss_dir = pos_dir_cls_preds.sum()\n    return (loss_cls, loss_bbox, loss_dir)"
        ]
    },
    {
        "func_name": "add_sin_difference",
        "original": "@staticmethod\ndef add_sin_difference(boxes1, boxes2):\n    \"\"\"Convert the rotation difference to difference in sine function.\n\n        Args:\n            boxes1 (torch.Tensor): Original Boxes in shape (NxC), where C>=7\n                and the 7th dimension is rotation dimension.\n            boxes2 (torch.Tensor): Target boxes in shape (NxC), where C>=7 and\n                the 7th dimension is rotation dimension.\n\n        Returns:\n            tuple[torch.Tensor]: ``boxes1`` and ``boxes2`` whose 7th\n                dimensions are changed.\n        \"\"\"\n    rad_pred_encoding = torch.sin(boxes1[..., 6:7]) * torch.cos(boxes2[..., 6:7])\n    rad_tg_encoding = torch.cos(boxes1[..., 6:7]) * torch.sin(boxes2[..., 6:7])\n    boxes1 = torch.cat([boxes1[..., :6], rad_pred_encoding, boxes1[..., 7:]], dim=-1)\n    boxes2 = torch.cat([boxes2[..., :6], rad_tg_encoding, boxes2[..., 7:]], dim=-1)\n    return (boxes1, boxes2)",
        "mutated": [
            "@staticmethod\ndef add_sin_difference(boxes1, boxes2):\n    if False:\n        i = 10\n    'Convert the rotation difference to difference in sine function.\\n\\n        Args:\\n            boxes1 (torch.Tensor): Original Boxes in shape (NxC), where C>=7\\n                and the 7th dimension is rotation dimension.\\n            boxes2 (torch.Tensor): Target boxes in shape (NxC), where C>=7 and\\n                the 7th dimension is rotation dimension.\\n\\n        Returns:\\n            tuple[torch.Tensor]: ``boxes1`` and ``boxes2`` whose 7th\\n                dimensions are changed.\\n        '\n    rad_pred_encoding = torch.sin(boxes1[..., 6:7]) * torch.cos(boxes2[..., 6:7])\n    rad_tg_encoding = torch.cos(boxes1[..., 6:7]) * torch.sin(boxes2[..., 6:7])\n    boxes1 = torch.cat([boxes1[..., :6], rad_pred_encoding, boxes1[..., 7:]], dim=-1)\n    boxes2 = torch.cat([boxes2[..., :6], rad_tg_encoding, boxes2[..., 7:]], dim=-1)\n    return (boxes1, boxes2)",
            "@staticmethod\ndef add_sin_difference(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Convert the rotation difference to difference in sine function.\\n\\n        Args:\\n            boxes1 (torch.Tensor): Original Boxes in shape (NxC), where C>=7\\n                and the 7th dimension is rotation dimension.\\n            boxes2 (torch.Tensor): Target boxes in shape (NxC), where C>=7 and\\n                the 7th dimension is rotation dimension.\\n\\n        Returns:\\n            tuple[torch.Tensor]: ``boxes1`` and ``boxes2`` whose 7th\\n                dimensions are changed.\\n        '\n    rad_pred_encoding = torch.sin(boxes1[..., 6:7]) * torch.cos(boxes2[..., 6:7])\n    rad_tg_encoding = torch.cos(boxes1[..., 6:7]) * torch.sin(boxes2[..., 6:7])\n    boxes1 = torch.cat([boxes1[..., :6], rad_pred_encoding, boxes1[..., 7:]], dim=-1)\n    boxes2 = torch.cat([boxes2[..., :6], rad_tg_encoding, boxes2[..., 7:]], dim=-1)\n    return (boxes1, boxes2)",
            "@staticmethod\ndef add_sin_difference(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Convert the rotation difference to difference in sine function.\\n\\n        Args:\\n            boxes1 (torch.Tensor): Original Boxes in shape (NxC), where C>=7\\n                and the 7th dimension is rotation dimension.\\n            boxes2 (torch.Tensor): Target boxes in shape (NxC), where C>=7 and\\n                the 7th dimension is rotation dimension.\\n\\n        Returns:\\n            tuple[torch.Tensor]: ``boxes1`` and ``boxes2`` whose 7th\\n                dimensions are changed.\\n        '\n    rad_pred_encoding = torch.sin(boxes1[..., 6:7]) * torch.cos(boxes2[..., 6:7])\n    rad_tg_encoding = torch.cos(boxes1[..., 6:7]) * torch.sin(boxes2[..., 6:7])\n    boxes1 = torch.cat([boxes1[..., :6], rad_pred_encoding, boxes1[..., 7:]], dim=-1)\n    boxes2 = torch.cat([boxes2[..., :6], rad_tg_encoding, boxes2[..., 7:]], dim=-1)\n    return (boxes1, boxes2)",
            "@staticmethod\ndef add_sin_difference(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Convert the rotation difference to difference in sine function.\\n\\n        Args:\\n            boxes1 (torch.Tensor): Original Boxes in shape (NxC), where C>=7\\n                and the 7th dimension is rotation dimension.\\n            boxes2 (torch.Tensor): Target boxes in shape (NxC), where C>=7 and\\n                the 7th dimension is rotation dimension.\\n\\n        Returns:\\n            tuple[torch.Tensor]: ``boxes1`` and ``boxes2`` whose 7th\\n                dimensions are changed.\\n        '\n    rad_pred_encoding = torch.sin(boxes1[..., 6:7]) * torch.cos(boxes2[..., 6:7])\n    rad_tg_encoding = torch.cos(boxes1[..., 6:7]) * torch.sin(boxes2[..., 6:7])\n    boxes1 = torch.cat([boxes1[..., :6], rad_pred_encoding, boxes1[..., 7:]], dim=-1)\n    boxes2 = torch.cat([boxes2[..., :6], rad_tg_encoding, boxes2[..., 7:]], dim=-1)\n    return (boxes1, boxes2)",
            "@staticmethod\ndef add_sin_difference(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Convert the rotation difference to difference in sine function.\\n\\n        Args:\\n            boxes1 (torch.Tensor): Original Boxes in shape (NxC), where C>=7\\n                and the 7th dimension is rotation dimension.\\n            boxes2 (torch.Tensor): Target boxes in shape (NxC), where C>=7 and\\n                the 7th dimension is rotation dimension.\\n\\n        Returns:\\n            tuple[torch.Tensor]: ``boxes1`` and ``boxes2`` whose 7th\\n                dimensions are changed.\\n        '\n    rad_pred_encoding = torch.sin(boxes1[..., 6:7]) * torch.cos(boxes2[..., 6:7])\n    rad_tg_encoding = torch.cos(boxes1[..., 6:7]) * torch.sin(boxes2[..., 6:7])\n    boxes1 = torch.cat([boxes1[..., :6], rad_pred_encoding, boxes1[..., 7:]], dim=-1)\n    boxes2 = torch.cat([boxes2[..., :6], rad_tg_encoding, boxes2[..., 7:]], dim=-1)\n    return (boxes1, boxes2)"
        ]
    },
    {
        "func_name": "loss",
        "original": "@force_fp32(apply_to=('cls_scores', 'bbox_preds', 'dir_cls_preds'))\ndef loss(self, cls_scores, bbox_preds, dir_cls_preds, gt_bboxes, gt_labels, input_metas, gt_bboxes_ignore=None):\n    \"\"\"Calculate losses.\n\n        Args:\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\n                class predictions.\n            gt_bboxes (list[:obj:`BaseInstance3DBoxes`]): Gt bboxes\n                of each sample.\n            gt_labels (list[torch.Tensor]): Gt labels of each sample.\n            input_metas (list[dict]): Contain pcd and img's meta info.\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\n                which bounding boxes to ignore.\n\n        Returns:\n            dict[str, list[torch.Tensor]]: Classification, bbox, and\n                direction losses of each level.\n\n                - loss_cls (list[torch.Tensor]): Classification losses.\n                - loss_bbox (list[torch.Tensor]): Box regression losses.\n                - loss_dir (list[torch.Tensor]): Direction classification\n                    losses.\n        \"\"\"\n    featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n    assert len(featmap_sizes) == self.anchor_generator.num_levels\n    device = cls_scores[0].device\n    anchor_list = self.get_anchors(featmap_sizes, input_metas, device=device)\n    label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n    cls_reg_targets = self.anchor_target_3d(anchor_list, gt_bboxes, input_metas, gt_bboxes_ignore_list=gt_bboxes_ignore, gt_labels_list=gt_labels, num_classes=self.num_classes, label_channels=label_channels, sampling=self.sampling)\n    if cls_reg_targets is None:\n        return None\n    (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg) = cls_reg_targets\n    num_total_samples = num_total_pos + num_total_neg if self.sampling else num_total_pos\n    (losses_cls, losses_bbox, losses_dir) = multi_apply(self.loss_single, cls_scores, bbox_preds, dir_cls_preds, labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_samples=num_total_samples)\n    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox, loss_dir=losses_dir)",
        "mutated": [
            "@force_fp32(apply_to=('cls_scores', 'bbox_preds', 'dir_cls_preds'))\ndef loss(self, cls_scores, bbox_preds, dir_cls_preds, gt_bboxes, gt_labels, input_metas, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n    \"Calculate losses.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            gt_bboxes (list[:obj:`BaseInstance3DBoxes`]): Gt bboxes\\n                of each sample.\\n            gt_labels (list[torch.Tensor]): Gt labels of each sample.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding boxes to ignore.\\n\\n        Returns:\\n            dict[str, list[torch.Tensor]]: Classification, bbox, and\\n                direction losses of each level.\\n\\n                - loss_cls (list[torch.Tensor]): Classification losses.\\n                - loss_bbox (list[torch.Tensor]): Box regression losses.\\n                - loss_dir (list[torch.Tensor]): Direction classification\\n                    losses.\\n        \"\n    featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n    assert len(featmap_sizes) == self.anchor_generator.num_levels\n    device = cls_scores[0].device\n    anchor_list = self.get_anchors(featmap_sizes, input_metas, device=device)\n    label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n    cls_reg_targets = self.anchor_target_3d(anchor_list, gt_bboxes, input_metas, gt_bboxes_ignore_list=gt_bboxes_ignore, gt_labels_list=gt_labels, num_classes=self.num_classes, label_channels=label_channels, sampling=self.sampling)\n    if cls_reg_targets is None:\n        return None\n    (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg) = cls_reg_targets\n    num_total_samples = num_total_pos + num_total_neg if self.sampling else num_total_pos\n    (losses_cls, losses_bbox, losses_dir) = multi_apply(self.loss_single, cls_scores, bbox_preds, dir_cls_preds, labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_samples=num_total_samples)\n    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox, loss_dir=losses_dir)",
            "@force_fp32(apply_to=('cls_scores', 'bbox_preds', 'dir_cls_preds'))\ndef loss(self, cls_scores, bbox_preds, dir_cls_preds, gt_bboxes, gt_labels, input_metas, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Calculate losses.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            gt_bboxes (list[:obj:`BaseInstance3DBoxes`]): Gt bboxes\\n                of each sample.\\n            gt_labels (list[torch.Tensor]): Gt labels of each sample.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding boxes to ignore.\\n\\n        Returns:\\n            dict[str, list[torch.Tensor]]: Classification, bbox, and\\n                direction losses of each level.\\n\\n                - loss_cls (list[torch.Tensor]): Classification losses.\\n                - loss_bbox (list[torch.Tensor]): Box regression losses.\\n                - loss_dir (list[torch.Tensor]): Direction classification\\n                    losses.\\n        \"\n    featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n    assert len(featmap_sizes) == self.anchor_generator.num_levels\n    device = cls_scores[0].device\n    anchor_list = self.get_anchors(featmap_sizes, input_metas, device=device)\n    label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n    cls_reg_targets = self.anchor_target_3d(anchor_list, gt_bboxes, input_metas, gt_bboxes_ignore_list=gt_bboxes_ignore, gt_labels_list=gt_labels, num_classes=self.num_classes, label_channels=label_channels, sampling=self.sampling)\n    if cls_reg_targets is None:\n        return None\n    (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg) = cls_reg_targets\n    num_total_samples = num_total_pos + num_total_neg if self.sampling else num_total_pos\n    (losses_cls, losses_bbox, losses_dir) = multi_apply(self.loss_single, cls_scores, bbox_preds, dir_cls_preds, labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_samples=num_total_samples)\n    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox, loss_dir=losses_dir)",
            "@force_fp32(apply_to=('cls_scores', 'bbox_preds', 'dir_cls_preds'))\ndef loss(self, cls_scores, bbox_preds, dir_cls_preds, gt_bboxes, gt_labels, input_metas, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Calculate losses.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            gt_bboxes (list[:obj:`BaseInstance3DBoxes`]): Gt bboxes\\n                of each sample.\\n            gt_labels (list[torch.Tensor]): Gt labels of each sample.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding boxes to ignore.\\n\\n        Returns:\\n            dict[str, list[torch.Tensor]]: Classification, bbox, and\\n                direction losses of each level.\\n\\n                - loss_cls (list[torch.Tensor]): Classification losses.\\n                - loss_bbox (list[torch.Tensor]): Box regression losses.\\n                - loss_dir (list[torch.Tensor]): Direction classification\\n                    losses.\\n        \"\n    featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n    assert len(featmap_sizes) == self.anchor_generator.num_levels\n    device = cls_scores[0].device\n    anchor_list = self.get_anchors(featmap_sizes, input_metas, device=device)\n    label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n    cls_reg_targets = self.anchor_target_3d(anchor_list, gt_bboxes, input_metas, gt_bboxes_ignore_list=gt_bboxes_ignore, gt_labels_list=gt_labels, num_classes=self.num_classes, label_channels=label_channels, sampling=self.sampling)\n    if cls_reg_targets is None:\n        return None\n    (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg) = cls_reg_targets\n    num_total_samples = num_total_pos + num_total_neg if self.sampling else num_total_pos\n    (losses_cls, losses_bbox, losses_dir) = multi_apply(self.loss_single, cls_scores, bbox_preds, dir_cls_preds, labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_samples=num_total_samples)\n    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox, loss_dir=losses_dir)",
            "@force_fp32(apply_to=('cls_scores', 'bbox_preds', 'dir_cls_preds'))\ndef loss(self, cls_scores, bbox_preds, dir_cls_preds, gt_bboxes, gt_labels, input_metas, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Calculate losses.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            gt_bboxes (list[:obj:`BaseInstance3DBoxes`]): Gt bboxes\\n                of each sample.\\n            gt_labels (list[torch.Tensor]): Gt labels of each sample.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding boxes to ignore.\\n\\n        Returns:\\n            dict[str, list[torch.Tensor]]: Classification, bbox, and\\n                direction losses of each level.\\n\\n                - loss_cls (list[torch.Tensor]): Classification losses.\\n                - loss_bbox (list[torch.Tensor]): Box regression losses.\\n                - loss_dir (list[torch.Tensor]): Direction classification\\n                    losses.\\n        \"\n    featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n    assert len(featmap_sizes) == self.anchor_generator.num_levels\n    device = cls_scores[0].device\n    anchor_list = self.get_anchors(featmap_sizes, input_metas, device=device)\n    label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n    cls_reg_targets = self.anchor_target_3d(anchor_list, gt_bboxes, input_metas, gt_bboxes_ignore_list=gt_bboxes_ignore, gt_labels_list=gt_labels, num_classes=self.num_classes, label_channels=label_channels, sampling=self.sampling)\n    if cls_reg_targets is None:\n        return None\n    (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg) = cls_reg_targets\n    num_total_samples = num_total_pos + num_total_neg if self.sampling else num_total_pos\n    (losses_cls, losses_bbox, losses_dir) = multi_apply(self.loss_single, cls_scores, bbox_preds, dir_cls_preds, labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_samples=num_total_samples)\n    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox, loss_dir=losses_dir)",
            "@force_fp32(apply_to=('cls_scores', 'bbox_preds', 'dir_cls_preds'))\ndef loss(self, cls_scores, bbox_preds, dir_cls_preds, gt_bboxes, gt_labels, input_metas, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Calculate losses.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            gt_bboxes (list[:obj:`BaseInstance3DBoxes`]): Gt bboxes\\n                of each sample.\\n            gt_labels (list[torch.Tensor]): Gt labels of each sample.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding boxes to ignore.\\n\\n        Returns:\\n            dict[str, list[torch.Tensor]]: Classification, bbox, and\\n                direction losses of each level.\\n\\n                - loss_cls (list[torch.Tensor]): Classification losses.\\n                - loss_bbox (list[torch.Tensor]): Box regression losses.\\n                - loss_dir (list[torch.Tensor]): Direction classification\\n                    losses.\\n        \"\n    featmap_sizes = [featmap.size()[-2:] for featmap in cls_scores]\n    assert len(featmap_sizes) == self.anchor_generator.num_levels\n    device = cls_scores[0].device\n    anchor_list = self.get_anchors(featmap_sizes, input_metas, device=device)\n    label_channels = self.cls_out_channels if self.use_sigmoid_cls else 1\n    cls_reg_targets = self.anchor_target_3d(anchor_list, gt_bboxes, input_metas, gt_bboxes_ignore_list=gt_bboxes_ignore, gt_labels_list=gt_labels, num_classes=self.num_classes, label_channels=label_channels, sampling=self.sampling)\n    if cls_reg_targets is None:\n        return None\n    (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg) = cls_reg_targets\n    num_total_samples = num_total_pos + num_total_neg if self.sampling else num_total_pos\n    (losses_cls, losses_bbox, losses_dir) = multi_apply(self.loss_single, cls_scores, bbox_preds, dir_cls_preds, labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_samples=num_total_samples)\n    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox, loss_dir=losses_dir)"
        ]
    },
    {
        "func_name": "get_bboxes",
        "original": "def get_bboxes(self, cls_scores, bbox_preds, dir_cls_preds, input_metas, cfg=None, rescale=False):\n    \"\"\"Get bboxes of anchor head.\n\n        Args:\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\n                class predictions.\n            input_metas (list[dict]): Contain pcd and img's meta info.\n            cfg (:obj:`ConfigDict`): Training or testing config.\n            rescale (list[torch.Tensor]): Whether th rescale bbox.\n\n        Returns:\n            list[tuple]: Prediction resultes of batches.\n        \"\"\"\n    assert len(cls_scores) == len(bbox_preds)\n    assert len(cls_scores) == len(dir_cls_preds)\n    num_levels = len(cls_scores)\n    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n    device = cls_scores[0].device\n    mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    mlvl_anchors = [anchor.reshape(-1, self.box_code_size) for anchor in mlvl_anchors]\n    result_list = []\n    for img_id in range(len(input_metas)):\n        cls_score_list = [cls_scores[i][img_id].detach() for i in range(num_levels)]\n        bbox_pred_list = [bbox_preds[i][img_id].detach() for i in range(num_levels)]\n        dir_cls_pred_list = [dir_cls_preds[i][img_id].detach() for i in range(num_levels)]\n        input_meta = input_metas[img_id]\n        proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, dir_cls_pred_list, mlvl_anchors, input_meta, cfg, rescale)\n        result_list.append(proposals)\n    return result_list",
        "mutated": [
            "def get_bboxes(self, cls_scores, bbox_preds, dir_cls_preds, input_metas, cfg=None, rescale=False):\n    if False:\n        i = 10\n    \"Get bboxes of anchor head.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): Whether th rescale bbox.\\n\\n        Returns:\\n            list[tuple]: Prediction resultes of batches.\\n        \"\n    assert len(cls_scores) == len(bbox_preds)\n    assert len(cls_scores) == len(dir_cls_preds)\n    num_levels = len(cls_scores)\n    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n    device = cls_scores[0].device\n    mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    mlvl_anchors = [anchor.reshape(-1, self.box_code_size) for anchor in mlvl_anchors]\n    result_list = []\n    for img_id in range(len(input_metas)):\n        cls_score_list = [cls_scores[i][img_id].detach() for i in range(num_levels)]\n        bbox_pred_list = [bbox_preds[i][img_id].detach() for i in range(num_levels)]\n        dir_cls_pred_list = [dir_cls_preds[i][img_id].detach() for i in range(num_levels)]\n        input_meta = input_metas[img_id]\n        proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, dir_cls_pred_list, mlvl_anchors, input_meta, cfg, rescale)\n        result_list.append(proposals)\n    return result_list",
            "def get_bboxes(self, cls_scores, bbox_preds, dir_cls_preds, input_metas, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Get bboxes of anchor head.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): Whether th rescale bbox.\\n\\n        Returns:\\n            list[tuple]: Prediction resultes of batches.\\n        \"\n    assert len(cls_scores) == len(bbox_preds)\n    assert len(cls_scores) == len(dir_cls_preds)\n    num_levels = len(cls_scores)\n    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n    device = cls_scores[0].device\n    mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    mlvl_anchors = [anchor.reshape(-1, self.box_code_size) for anchor in mlvl_anchors]\n    result_list = []\n    for img_id in range(len(input_metas)):\n        cls_score_list = [cls_scores[i][img_id].detach() for i in range(num_levels)]\n        bbox_pred_list = [bbox_preds[i][img_id].detach() for i in range(num_levels)]\n        dir_cls_pred_list = [dir_cls_preds[i][img_id].detach() for i in range(num_levels)]\n        input_meta = input_metas[img_id]\n        proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, dir_cls_pred_list, mlvl_anchors, input_meta, cfg, rescale)\n        result_list.append(proposals)\n    return result_list",
            "def get_bboxes(self, cls_scores, bbox_preds, dir_cls_preds, input_metas, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Get bboxes of anchor head.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): Whether th rescale bbox.\\n\\n        Returns:\\n            list[tuple]: Prediction resultes of batches.\\n        \"\n    assert len(cls_scores) == len(bbox_preds)\n    assert len(cls_scores) == len(dir_cls_preds)\n    num_levels = len(cls_scores)\n    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n    device = cls_scores[0].device\n    mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    mlvl_anchors = [anchor.reshape(-1, self.box_code_size) for anchor in mlvl_anchors]\n    result_list = []\n    for img_id in range(len(input_metas)):\n        cls_score_list = [cls_scores[i][img_id].detach() for i in range(num_levels)]\n        bbox_pred_list = [bbox_preds[i][img_id].detach() for i in range(num_levels)]\n        dir_cls_pred_list = [dir_cls_preds[i][img_id].detach() for i in range(num_levels)]\n        input_meta = input_metas[img_id]\n        proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, dir_cls_pred_list, mlvl_anchors, input_meta, cfg, rescale)\n        result_list.append(proposals)\n    return result_list",
            "def get_bboxes(self, cls_scores, bbox_preds, dir_cls_preds, input_metas, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Get bboxes of anchor head.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): Whether th rescale bbox.\\n\\n        Returns:\\n            list[tuple]: Prediction resultes of batches.\\n        \"\n    assert len(cls_scores) == len(bbox_preds)\n    assert len(cls_scores) == len(dir_cls_preds)\n    num_levels = len(cls_scores)\n    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n    device = cls_scores[0].device\n    mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    mlvl_anchors = [anchor.reshape(-1, self.box_code_size) for anchor in mlvl_anchors]\n    result_list = []\n    for img_id in range(len(input_metas)):\n        cls_score_list = [cls_scores[i][img_id].detach() for i in range(num_levels)]\n        bbox_pred_list = [bbox_preds[i][img_id].detach() for i in range(num_levels)]\n        dir_cls_pred_list = [dir_cls_preds[i][img_id].detach() for i in range(num_levels)]\n        input_meta = input_metas[img_id]\n        proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, dir_cls_pred_list, mlvl_anchors, input_meta, cfg, rescale)\n        result_list.append(proposals)\n    return result_list",
            "def get_bboxes(self, cls_scores, bbox_preds, dir_cls_preds, input_metas, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Get bboxes of anchor head.\\n\\n        Args:\\n            cls_scores (list[torch.Tensor]): Multi-level class scores.\\n            bbox_preds (list[torch.Tensor]): Multi-level bbox predictions.\\n            dir_cls_preds (list[torch.Tensor]): Multi-level direction\\n                class predictions.\\n            input_metas (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): Whether th rescale bbox.\\n\\n        Returns:\\n            list[tuple]: Prediction resultes of batches.\\n        \"\n    assert len(cls_scores) == len(bbox_preds)\n    assert len(cls_scores) == len(dir_cls_preds)\n    num_levels = len(cls_scores)\n    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n    device = cls_scores[0].device\n    mlvl_anchors = self.anchor_generator.grid_anchors(featmap_sizes, device=device)\n    mlvl_anchors = [anchor.reshape(-1, self.box_code_size) for anchor in mlvl_anchors]\n    result_list = []\n    for img_id in range(len(input_metas)):\n        cls_score_list = [cls_scores[i][img_id].detach() for i in range(num_levels)]\n        bbox_pred_list = [bbox_preds[i][img_id].detach() for i in range(num_levels)]\n        dir_cls_pred_list = [dir_cls_preds[i][img_id].detach() for i in range(num_levels)]\n        input_meta = input_metas[img_id]\n        proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, dir_cls_pred_list, mlvl_anchors, input_meta, cfg, rescale)\n        result_list.append(proposals)\n    return result_list"
        ]
    },
    {
        "func_name": "get_bboxes_single",
        "original": "def get_bboxes_single(self, cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors, input_meta, cfg=None, rescale=False):\n    \"\"\"Get bboxes of single branch.\n\n        Args:\n            cls_scores (torch.Tensor): Class score in single batch.\n            bbox_preds (torch.Tensor): Bbox prediction in single batch.\n            dir_cls_preds (torch.Tensor): Predictions of direction class\n                in single batch.\n            mlvl_anchors (List[torch.Tensor]): Multi-level anchors\n                in single batch.\n            input_meta (list[dict]): Contain pcd and img's meta info.\n            cfg (:obj:`ConfigDict`): Training or testing config.\n            rescale (list[torch.Tensor]): whether th rescale bbox.\n\n        Returns:\n            tuple: Contain predictions of single batch.\n\n                - bboxes (:obj:`BaseInstance3DBoxes`): Predicted 3d bboxes.\n                - scores (torch.Tensor): Class score of each bbox.\n                - labels (torch.Tensor): Label of each bbox.\n        \"\"\"\n    cfg = self.test_cfg if cfg is None else cfg\n    assert len(cls_scores) == len(bbox_preds) == len(mlvl_anchors)\n    mlvl_bboxes = []\n    mlvl_scores = []\n    mlvl_dir_scores = []\n    for (cls_score, bbox_pred, dir_cls_pred, anchors) in zip(cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors):\n        assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n        assert cls_score.size()[-2:] == dir_cls_pred.size()[-2:]\n        dir_cls_pred = dir_cls_pred.permute(1, 2, 0).reshape(-1, 2)\n        dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n        cls_score = cls_score.permute(1, 2, 0).reshape(-1, self.num_classes)\n        if self.use_sigmoid_cls:\n            scores = cls_score.sigmoid()\n        else:\n            scores = cls_score.softmax(-1)\n        bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, self.box_code_size)\n        nms_pre = cfg.get('nms_pre', -1)\n        if nms_pre > 0 and scores.shape[0] > nms_pre:\n            if self.use_sigmoid_cls:\n                (max_scores, _) = scores.max(dim=1)\n            else:\n                (max_scores, _) = scores[:, :-1].max(dim=1)\n            (_, topk_inds) = max_scores.topk(nms_pre)\n            anchors = anchors[topk_inds, :]\n            bbox_pred = bbox_pred[topk_inds, :]\n            scores = scores[topk_inds, :]\n            dir_cls_score = dir_cls_score[topk_inds]\n        bboxes = self.bbox_coder.decode(anchors, bbox_pred)\n        mlvl_bboxes.append(bboxes)\n        mlvl_scores.append(scores)\n        mlvl_dir_scores.append(dir_cls_score)\n    mlvl_bboxes = torch.cat(mlvl_bboxes)\n    mlvl_bboxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](mlvl_bboxes, box_dim=self.box_code_size).bev)\n    mlvl_scores = torch.cat(mlvl_scores)\n    mlvl_dir_scores = torch.cat(mlvl_dir_scores)\n    if self.use_sigmoid_cls:\n        padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n        mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n    score_thr = cfg.get('score_thr', 0)\n    results = box3d_multiclass_nms(mlvl_bboxes, mlvl_bboxes_for_nms, mlvl_scores, score_thr, cfg.max_num, cfg, mlvl_dir_scores)\n    (bboxes, scores, labels, dir_scores) = results\n    if bboxes.shape[0] > 0:\n        dir_rot = limit_period(bboxes[..., 6] - self.dir_offset, self.dir_limit_offset, np.pi)\n        bboxes[..., 6] = dir_rot + self.dir_offset + np.pi * dir_scores.to(bboxes.dtype)\n    bboxes = input_meta['box_type_3d'](bboxes, box_dim=self.box_code_size)\n    return (bboxes, scores, labels)",
        "mutated": [
            "def get_bboxes_single(self, cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors, input_meta, cfg=None, rescale=False):\n    if False:\n        i = 10\n    \"Get bboxes of single branch.\\n\\n        Args:\\n            cls_scores (torch.Tensor): Class score in single batch.\\n            bbox_preds (torch.Tensor): Bbox prediction in single batch.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single batch.\\n            mlvl_anchors (List[torch.Tensor]): Multi-level anchors\\n                in single batch.\\n            input_meta (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): whether th rescale bbox.\\n\\n        Returns:\\n            tuple: Contain predictions of single batch.\\n\\n                - bboxes (:obj:`BaseInstance3DBoxes`): Predicted 3d bboxes.\\n                - scores (torch.Tensor): Class score of each bbox.\\n                - labels (torch.Tensor): Label of each bbox.\\n        \"\n    cfg = self.test_cfg if cfg is None else cfg\n    assert len(cls_scores) == len(bbox_preds) == len(mlvl_anchors)\n    mlvl_bboxes = []\n    mlvl_scores = []\n    mlvl_dir_scores = []\n    for (cls_score, bbox_pred, dir_cls_pred, anchors) in zip(cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors):\n        assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n        assert cls_score.size()[-2:] == dir_cls_pred.size()[-2:]\n        dir_cls_pred = dir_cls_pred.permute(1, 2, 0).reshape(-1, 2)\n        dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n        cls_score = cls_score.permute(1, 2, 0).reshape(-1, self.num_classes)\n        if self.use_sigmoid_cls:\n            scores = cls_score.sigmoid()\n        else:\n            scores = cls_score.softmax(-1)\n        bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, self.box_code_size)\n        nms_pre = cfg.get('nms_pre', -1)\n        if nms_pre > 0 and scores.shape[0] > nms_pre:\n            if self.use_sigmoid_cls:\n                (max_scores, _) = scores.max(dim=1)\n            else:\n                (max_scores, _) = scores[:, :-1].max(dim=1)\n            (_, topk_inds) = max_scores.topk(nms_pre)\n            anchors = anchors[topk_inds, :]\n            bbox_pred = bbox_pred[topk_inds, :]\n            scores = scores[topk_inds, :]\n            dir_cls_score = dir_cls_score[topk_inds]\n        bboxes = self.bbox_coder.decode(anchors, bbox_pred)\n        mlvl_bboxes.append(bboxes)\n        mlvl_scores.append(scores)\n        mlvl_dir_scores.append(dir_cls_score)\n    mlvl_bboxes = torch.cat(mlvl_bboxes)\n    mlvl_bboxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](mlvl_bboxes, box_dim=self.box_code_size).bev)\n    mlvl_scores = torch.cat(mlvl_scores)\n    mlvl_dir_scores = torch.cat(mlvl_dir_scores)\n    if self.use_sigmoid_cls:\n        padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n        mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n    score_thr = cfg.get('score_thr', 0)\n    results = box3d_multiclass_nms(mlvl_bboxes, mlvl_bboxes_for_nms, mlvl_scores, score_thr, cfg.max_num, cfg, mlvl_dir_scores)\n    (bboxes, scores, labels, dir_scores) = results\n    if bboxes.shape[0] > 0:\n        dir_rot = limit_period(bboxes[..., 6] - self.dir_offset, self.dir_limit_offset, np.pi)\n        bboxes[..., 6] = dir_rot + self.dir_offset + np.pi * dir_scores.to(bboxes.dtype)\n    bboxes = input_meta['box_type_3d'](bboxes, box_dim=self.box_code_size)\n    return (bboxes, scores, labels)",
            "def get_bboxes_single(self, cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors, input_meta, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Get bboxes of single branch.\\n\\n        Args:\\n            cls_scores (torch.Tensor): Class score in single batch.\\n            bbox_preds (torch.Tensor): Bbox prediction in single batch.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single batch.\\n            mlvl_anchors (List[torch.Tensor]): Multi-level anchors\\n                in single batch.\\n            input_meta (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): whether th rescale bbox.\\n\\n        Returns:\\n            tuple: Contain predictions of single batch.\\n\\n                - bboxes (:obj:`BaseInstance3DBoxes`): Predicted 3d bboxes.\\n                - scores (torch.Tensor): Class score of each bbox.\\n                - labels (torch.Tensor): Label of each bbox.\\n        \"\n    cfg = self.test_cfg if cfg is None else cfg\n    assert len(cls_scores) == len(bbox_preds) == len(mlvl_anchors)\n    mlvl_bboxes = []\n    mlvl_scores = []\n    mlvl_dir_scores = []\n    for (cls_score, bbox_pred, dir_cls_pred, anchors) in zip(cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors):\n        assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n        assert cls_score.size()[-2:] == dir_cls_pred.size()[-2:]\n        dir_cls_pred = dir_cls_pred.permute(1, 2, 0).reshape(-1, 2)\n        dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n        cls_score = cls_score.permute(1, 2, 0).reshape(-1, self.num_classes)\n        if self.use_sigmoid_cls:\n            scores = cls_score.sigmoid()\n        else:\n            scores = cls_score.softmax(-1)\n        bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, self.box_code_size)\n        nms_pre = cfg.get('nms_pre', -1)\n        if nms_pre > 0 and scores.shape[0] > nms_pre:\n            if self.use_sigmoid_cls:\n                (max_scores, _) = scores.max(dim=1)\n            else:\n                (max_scores, _) = scores[:, :-1].max(dim=1)\n            (_, topk_inds) = max_scores.topk(nms_pre)\n            anchors = anchors[topk_inds, :]\n            bbox_pred = bbox_pred[topk_inds, :]\n            scores = scores[topk_inds, :]\n            dir_cls_score = dir_cls_score[topk_inds]\n        bboxes = self.bbox_coder.decode(anchors, bbox_pred)\n        mlvl_bboxes.append(bboxes)\n        mlvl_scores.append(scores)\n        mlvl_dir_scores.append(dir_cls_score)\n    mlvl_bboxes = torch.cat(mlvl_bboxes)\n    mlvl_bboxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](mlvl_bboxes, box_dim=self.box_code_size).bev)\n    mlvl_scores = torch.cat(mlvl_scores)\n    mlvl_dir_scores = torch.cat(mlvl_dir_scores)\n    if self.use_sigmoid_cls:\n        padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n        mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n    score_thr = cfg.get('score_thr', 0)\n    results = box3d_multiclass_nms(mlvl_bboxes, mlvl_bboxes_for_nms, mlvl_scores, score_thr, cfg.max_num, cfg, mlvl_dir_scores)\n    (bboxes, scores, labels, dir_scores) = results\n    if bboxes.shape[0] > 0:\n        dir_rot = limit_period(bboxes[..., 6] - self.dir_offset, self.dir_limit_offset, np.pi)\n        bboxes[..., 6] = dir_rot + self.dir_offset + np.pi * dir_scores.to(bboxes.dtype)\n    bboxes = input_meta['box_type_3d'](bboxes, box_dim=self.box_code_size)\n    return (bboxes, scores, labels)",
            "def get_bboxes_single(self, cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors, input_meta, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Get bboxes of single branch.\\n\\n        Args:\\n            cls_scores (torch.Tensor): Class score in single batch.\\n            bbox_preds (torch.Tensor): Bbox prediction in single batch.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single batch.\\n            mlvl_anchors (List[torch.Tensor]): Multi-level anchors\\n                in single batch.\\n            input_meta (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): whether th rescale bbox.\\n\\n        Returns:\\n            tuple: Contain predictions of single batch.\\n\\n                - bboxes (:obj:`BaseInstance3DBoxes`): Predicted 3d bboxes.\\n                - scores (torch.Tensor): Class score of each bbox.\\n                - labels (torch.Tensor): Label of each bbox.\\n        \"\n    cfg = self.test_cfg if cfg is None else cfg\n    assert len(cls_scores) == len(bbox_preds) == len(mlvl_anchors)\n    mlvl_bboxes = []\n    mlvl_scores = []\n    mlvl_dir_scores = []\n    for (cls_score, bbox_pred, dir_cls_pred, anchors) in zip(cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors):\n        assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n        assert cls_score.size()[-2:] == dir_cls_pred.size()[-2:]\n        dir_cls_pred = dir_cls_pred.permute(1, 2, 0).reshape(-1, 2)\n        dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n        cls_score = cls_score.permute(1, 2, 0).reshape(-1, self.num_classes)\n        if self.use_sigmoid_cls:\n            scores = cls_score.sigmoid()\n        else:\n            scores = cls_score.softmax(-1)\n        bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, self.box_code_size)\n        nms_pre = cfg.get('nms_pre', -1)\n        if nms_pre > 0 and scores.shape[0] > nms_pre:\n            if self.use_sigmoid_cls:\n                (max_scores, _) = scores.max(dim=1)\n            else:\n                (max_scores, _) = scores[:, :-1].max(dim=1)\n            (_, topk_inds) = max_scores.topk(nms_pre)\n            anchors = anchors[topk_inds, :]\n            bbox_pred = bbox_pred[topk_inds, :]\n            scores = scores[topk_inds, :]\n            dir_cls_score = dir_cls_score[topk_inds]\n        bboxes = self.bbox_coder.decode(anchors, bbox_pred)\n        mlvl_bboxes.append(bboxes)\n        mlvl_scores.append(scores)\n        mlvl_dir_scores.append(dir_cls_score)\n    mlvl_bboxes = torch.cat(mlvl_bboxes)\n    mlvl_bboxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](mlvl_bboxes, box_dim=self.box_code_size).bev)\n    mlvl_scores = torch.cat(mlvl_scores)\n    mlvl_dir_scores = torch.cat(mlvl_dir_scores)\n    if self.use_sigmoid_cls:\n        padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n        mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n    score_thr = cfg.get('score_thr', 0)\n    results = box3d_multiclass_nms(mlvl_bboxes, mlvl_bboxes_for_nms, mlvl_scores, score_thr, cfg.max_num, cfg, mlvl_dir_scores)\n    (bboxes, scores, labels, dir_scores) = results\n    if bboxes.shape[0] > 0:\n        dir_rot = limit_period(bboxes[..., 6] - self.dir_offset, self.dir_limit_offset, np.pi)\n        bboxes[..., 6] = dir_rot + self.dir_offset + np.pi * dir_scores.to(bboxes.dtype)\n    bboxes = input_meta['box_type_3d'](bboxes, box_dim=self.box_code_size)\n    return (bboxes, scores, labels)",
            "def get_bboxes_single(self, cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors, input_meta, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Get bboxes of single branch.\\n\\n        Args:\\n            cls_scores (torch.Tensor): Class score in single batch.\\n            bbox_preds (torch.Tensor): Bbox prediction in single batch.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single batch.\\n            mlvl_anchors (List[torch.Tensor]): Multi-level anchors\\n                in single batch.\\n            input_meta (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): whether th rescale bbox.\\n\\n        Returns:\\n            tuple: Contain predictions of single batch.\\n\\n                - bboxes (:obj:`BaseInstance3DBoxes`): Predicted 3d bboxes.\\n                - scores (torch.Tensor): Class score of each bbox.\\n                - labels (torch.Tensor): Label of each bbox.\\n        \"\n    cfg = self.test_cfg if cfg is None else cfg\n    assert len(cls_scores) == len(bbox_preds) == len(mlvl_anchors)\n    mlvl_bboxes = []\n    mlvl_scores = []\n    mlvl_dir_scores = []\n    for (cls_score, bbox_pred, dir_cls_pred, anchors) in zip(cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors):\n        assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n        assert cls_score.size()[-2:] == dir_cls_pred.size()[-2:]\n        dir_cls_pred = dir_cls_pred.permute(1, 2, 0).reshape(-1, 2)\n        dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n        cls_score = cls_score.permute(1, 2, 0).reshape(-1, self.num_classes)\n        if self.use_sigmoid_cls:\n            scores = cls_score.sigmoid()\n        else:\n            scores = cls_score.softmax(-1)\n        bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, self.box_code_size)\n        nms_pre = cfg.get('nms_pre', -1)\n        if nms_pre > 0 and scores.shape[0] > nms_pre:\n            if self.use_sigmoid_cls:\n                (max_scores, _) = scores.max(dim=1)\n            else:\n                (max_scores, _) = scores[:, :-1].max(dim=1)\n            (_, topk_inds) = max_scores.topk(nms_pre)\n            anchors = anchors[topk_inds, :]\n            bbox_pred = bbox_pred[topk_inds, :]\n            scores = scores[topk_inds, :]\n            dir_cls_score = dir_cls_score[topk_inds]\n        bboxes = self.bbox_coder.decode(anchors, bbox_pred)\n        mlvl_bboxes.append(bboxes)\n        mlvl_scores.append(scores)\n        mlvl_dir_scores.append(dir_cls_score)\n    mlvl_bboxes = torch.cat(mlvl_bboxes)\n    mlvl_bboxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](mlvl_bboxes, box_dim=self.box_code_size).bev)\n    mlvl_scores = torch.cat(mlvl_scores)\n    mlvl_dir_scores = torch.cat(mlvl_dir_scores)\n    if self.use_sigmoid_cls:\n        padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n        mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n    score_thr = cfg.get('score_thr', 0)\n    results = box3d_multiclass_nms(mlvl_bboxes, mlvl_bboxes_for_nms, mlvl_scores, score_thr, cfg.max_num, cfg, mlvl_dir_scores)\n    (bboxes, scores, labels, dir_scores) = results\n    if bboxes.shape[0] > 0:\n        dir_rot = limit_period(bboxes[..., 6] - self.dir_offset, self.dir_limit_offset, np.pi)\n        bboxes[..., 6] = dir_rot + self.dir_offset + np.pi * dir_scores.to(bboxes.dtype)\n    bboxes = input_meta['box_type_3d'](bboxes, box_dim=self.box_code_size)\n    return (bboxes, scores, labels)",
            "def get_bboxes_single(self, cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors, input_meta, cfg=None, rescale=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Get bboxes of single branch.\\n\\n        Args:\\n            cls_scores (torch.Tensor): Class score in single batch.\\n            bbox_preds (torch.Tensor): Bbox prediction in single batch.\\n            dir_cls_preds (torch.Tensor): Predictions of direction class\\n                in single batch.\\n            mlvl_anchors (List[torch.Tensor]): Multi-level anchors\\n                in single batch.\\n            input_meta (list[dict]): Contain pcd and img's meta info.\\n            cfg (:obj:`ConfigDict`): Training or testing config.\\n            rescale (list[torch.Tensor]): whether th rescale bbox.\\n\\n        Returns:\\n            tuple: Contain predictions of single batch.\\n\\n                - bboxes (:obj:`BaseInstance3DBoxes`): Predicted 3d bboxes.\\n                - scores (torch.Tensor): Class score of each bbox.\\n                - labels (torch.Tensor): Label of each bbox.\\n        \"\n    cfg = self.test_cfg if cfg is None else cfg\n    assert len(cls_scores) == len(bbox_preds) == len(mlvl_anchors)\n    mlvl_bboxes = []\n    mlvl_scores = []\n    mlvl_dir_scores = []\n    for (cls_score, bbox_pred, dir_cls_pred, anchors) in zip(cls_scores, bbox_preds, dir_cls_preds, mlvl_anchors):\n        assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n        assert cls_score.size()[-2:] == dir_cls_pred.size()[-2:]\n        dir_cls_pred = dir_cls_pred.permute(1, 2, 0).reshape(-1, 2)\n        dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n        cls_score = cls_score.permute(1, 2, 0).reshape(-1, self.num_classes)\n        if self.use_sigmoid_cls:\n            scores = cls_score.sigmoid()\n        else:\n            scores = cls_score.softmax(-1)\n        bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, self.box_code_size)\n        nms_pre = cfg.get('nms_pre', -1)\n        if nms_pre > 0 and scores.shape[0] > nms_pre:\n            if self.use_sigmoid_cls:\n                (max_scores, _) = scores.max(dim=1)\n            else:\n                (max_scores, _) = scores[:, :-1].max(dim=1)\n            (_, topk_inds) = max_scores.topk(nms_pre)\n            anchors = anchors[topk_inds, :]\n            bbox_pred = bbox_pred[topk_inds, :]\n            scores = scores[topk_inds, :]\n            dir_cls_score = dir_cls_score[topk_inds]\n        bboxes = self.bbox_coder.decode(anchors, bbox_pred)\n        mlvl_bboxes.append(bboxes)\n        mlvl_scores.append(scores)\n        mlvl_dir_scores.append(dir_cls_score)\n    mlvl_bboxes = torch.cat(mlvl_bboxes)\n    mlvl_bboxes_for_nms = xywhr2xyxyr(input_meta['box_type_3d'](mlvl_bboxes, box_dim=self.box_code_size).bev)\n    mlvl_scores = torch.cat(mlvl_scores)\n    mlvl_dir_scores = torch.cat(mlvl_dir_scores)\n    if self.use_sigmoid_cls:\n        padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n        mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n    score_thr = cfg.get('score_thr', 0)\n    results = box3d_multiclass_nms(mlvl_bboxes, mlvl_bboxes_for_nms, mlvl_scores, score_thr, cfg.max_num, cfg, mlvl_dir_scores)\n    (bboxes, scores, labels, dir_scores) = results\n    if bboxes.shape[0] > 0:\n        dir_rot = limit_period(bboxes[..., 6] - self.dir_offset, self.dir_limit_offset, np.pi)\n        bboxes[..., 6] = dir_rot + self.dir_offset + np.pi * dir_scores.to(bboxes.dtype)\n    bboxes = input_meta['box_type_3d'](bboxes, box_dim=self.box_code_size)\n    return (bboxes, scores, labels)"
        ]
    }
]