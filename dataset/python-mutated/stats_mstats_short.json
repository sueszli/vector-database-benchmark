[
    {
        "func_name": "quantiles",
        "original": "def quantiles(a, prob=list([0.25, 0.5, 0.75]), alphap=0.4, betap=0.4, axis=None, limit=(), masknan=False):\n    \"\"\"\n    Computes empirical quantiles for a data array.\n\n    Samples quantile are defined by :math:`Q(p) = (1-g).x[i] +g.x[i+1]`,\n    where :math:`x[j]` is the *j*th order statistic, and\n    `i = (floor(n*p+m))`, `m=alpha+p*(1-alpha-beta)` and `g = n*p + m - i`.\n\n    Typical values of (alpha,beta) are:\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\n        - (.5,.5)  : *p(k) = (k+1/2.)/n* : piecewise linear\n          function (R, type 5)\n        - (0,0)    : *p(k) = k/(n+1)* : (R type 6)\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\n          That's R default (R type 7)\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\n          The resulting quantile estimates are approximately median-unbiased\n          regardless of the distribution of x. (R type 8)\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*. Blom.\n          The resulting quantile estimates are approximately unbiased\n          if x is normally distributed (R type 9)\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\n        - (.35,.35): APL, used with PWM ?? JP\n        - (0.35, 0.65): PWM   ?? JP  p(k) = (k-0.35)/n\n\n    Parameters\n    ----------\n    a : array_like\n        Input data, as a sequence or array of dimension at most 2.\n    prob : array_like, optional\n        List of quantiles to compute.\n    alpha : float, optional\n        Plotting positions parameter, default is 0.4.\n    beta : float, optional\n        Plotting positions parameter, default is 0.4.\n    axis : int, optional\n        Axis along which to perform the trimming.\n        If None (default), the input array is first flattened.\n    limit : tuple\n        Tuple of (lower, upper) values.\n        Values of `a` outside this closed interval are ignored.\n\n    Returns\n    -------\n    quants : MaskedArray\n        An array containing the calculated quantiles.\n\n    Examples\n    --------\n    >>> from scipy.stats.mstats import mquantiles\n    >>> a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])\n    >>> mquantiles(a)\n    array([ 19.2,  40. ,  42.8])\n\n    Using a 2D array, specifying axis and limit.\n\n    >>> data = np.array([[   6.,    7.,    1.],\n                         [  47.,   15.,    2.],\n                         [  49.,   36.,    3.],\n                         [  15.,   39.,    4.],\n                         [  42.,   40., -999.],\n                         [  41.,   41., -999.],\n                         [   7., -999., -999.],\n                         [  39., -999., -999.],\n                         [  43., -999., -999.],\n                         [  40., -999., -999.],\n                         [  36., -999., -999.]])\n    >>> mquantiles(data, axis=0, limit=(0, 50))\n    array([[ 19.2 ,  14.6 ,   1.45],\n           [ 40.  ,  37.5 ,   2.5 ],\n           [ 42.8 ,  40.05,   3.55]])\n\n    >>> data[:, 2] = -999.\n    >>> mquantiles(data, axis=0, limit=(0, 50))\n    masked_array(data =\n     [[19.2 14.6 --]\n     [40.0 37.5 --]\n     [42.8 40.05 --]],\n                 mask =\n     [[False False  True]\n      [False False  True]\n      [False False  True]],\n           fill_value = 1e+20)\n    \"\"\"\n    if isinstance(a, np.ma.MaskedArray):\n        return stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n    if limit:\n        marr = stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n        return ma.filled(marr, fill_value=np.nan)\n    if masknan:\n        nanmask = np.isnan(a)\n        if nanmask.any():\n            marr = ma.array(a, mask=nanmask)\n            marr = stats.mstats.mquantiles(marr, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(a)\n    p = np.array(prob, copy=False, ndmin=1)\n    m = alphap + p * (1.0 - alphap - betap)\n    isrolled = False\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    else:\n        axis = np.arange(data.ndim)[axis]\n        data = np.rollaxis(data, axis)\n        isrolled = True\n    x = np.sort(data, axis=0)\n    n = x.shape[0]\n    returnshape = list(data.shape)\n    returnshape[axis] = p\n    if n == 0:\n        return np.empty(len(p), dtype=float)\n    elif n == 1:\n        return np.resize(x, p.shape)\n    aleph = n * p + m\n    k = np.floor(aleph.clip(1, n - 1)).astype(int)\n    ind = [None] * x.ndim\n    ind[0] = slice(None)\n    gamma = (aleph - k).clip(0, 1)[ind]\n    q = (1.0 - gamma) * x[k - 1] + gamma * x[k]\n    if isrolled:\n        return np.rollaxis(q, 0, axis + 1)\n    else:\n        return q",
        "mutated": [
            "def quantiles(a, prob=list([0.25, 0.5, 0.75]), alphap=0.4, betap=0.4, axis=None, limit=(), masknan=False):\n    if False:\n        i = 10\n    \"\\n    Computes empirical quantiles for a data array.\\n\\n    Samples quantile are defined by :math:`Q(p) = (1-g).x[i] +g.x[i+1]`,\\n    where :math:`x[j]` is the *j*th order statistic, and\\n    `i = (floor(n*p+m))`, `m=alpha+p*(1-alpha-beta)` and `g = n*p + m - i`.\\n\\n    Typical values of (alpha,beta) are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k+1/2.)/n* : piecewise linear\\n          function (R, type 5)\\n        - (0,0)    : *p(k) = k/(n+1)* : (R type 6)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That's R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*. Blom.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM ?? JP\\n        - (0.35, 0.65): PWM   ?? JP  p(k) = (k-0.35)/n\\n\\n    Parameters\\n    ----------\\n    a : array_like\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : array_like, optional\\n        List of quantiles to compute.\\n    alpha : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    beta : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    axis : int, optional\\n        Axis along which to perform the trimming.\\n        If None (default), the input array is first flattened.\\n    limit : tuple\\n        Tuple of (lower, upper) values.\\n        Values of `a` outside this closed interval are ignored.\\n\\n    Returns\\n    -------\\n    quants : MaskedArray\\n        An array containing the calculated quantiles.\\n\\n    Examples\\n    --------\\n    >>> from scipy.stats.mstats import mquantiles\\n    >>> a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])\\n    >>> mquantiles(a)\\n    array([ 19.2,  40. ,  42.8])\\n\\n    Using a 2D array, specifying axis and limit.\\n\\n    >>> data = np.array([[   6.,    7.,    1.],\\n                         [  47.,   15.,    2.],\\n                         [  49.,   36.,    3.],\\n                         [  15.,   39.,    4.],\\n                         [  42.,   40., -999.],\\n                         [  41.,   41., -999.],\\n                         [   7., -999., -999.],\\n                         [  39., -999., -999.],\\n                         [  43., -999., -999.],\\n                         [  40., -999., -999.],\\n                         [  36., -999., -999.]])\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    array([[ 19.2 ,  14.6 ,   1.45],\\n           [ 40.  ,  37.5 ,   2.5 ],\\n           [ 42.8 ,  40.05,   3.55]])\\n\\n    >>> data[:, 2] = -999.\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    masked_array(data =\\n     [[19.2 14.6 --]\\n     [40.0 37.5 --]\\n     [42.8 40.05 --]],\\n                 mask =\\n     [[False False  True]\\n      [False False  True]\\n      [False False  True]],\\n           fill_value = 1e+20)\\n    \"\n    if isinstance(a, np.ma.MaskedArray):\n        return stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n    if limit:\n        marr = stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n        return ma.filled(marr, fill_value=np.nan)\n    if masknan:\n        nanmask = np.isnan(a)\n        if nanmask.any():\n            marr = ma.array(a, mask=nanmask)\n            marr = stats.mstats.mquantiles(marr, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(a)\n    p = np.array(prob, copy=False, ndmin=1)\n    m = alphap + p * (1.0 - alphap - betap)\n    isrolled = False\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    else:\n        axis = np.arange(data.ndim)[axis]\n        data = np.rollaxis(data, axis)\n        isrolled = True\n    x = np.sort(data, axis=0)\n    n = x.shape[0]\n    returnshape = list(data.shape)\n    returnshape[axis] = p\n    if n == 0:\n        return np.empty(len(p), dtype=float)\n    elif n == 1:\n        return np.resize(x, p.shape)\n    aleph = n * p + m\n    k = np.floor(aleph.clip(1, n - 1)).astype(int)\n    ind = [None] * x.ndim\n    ind[0] = slice(None)\n    gamma = (aleph - k).clip(0, 1)[ind]\n    q = (1.0 - gamma) * x[k - 1] + gamma * x[k]\n    if isrolled:\n        return np.rollaxis(q, 0, axis + 1)\n    else:\n        return q",
            "def quantiles(a, prob=list([0.25, 0.5, 0.75]), alphap=0.4, betap=0.4, axis=None, limit=(), masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Computes empirical quantiles for a data array.\\n\\n    Samples quantile are defined by :math:`Q(p) = (1-g).x[i] +g.x[i+1]`,\\n    where :math:`x[j]` is the *j*th order statistic, and\\n    `i = (floor(n*p+m))`, `m=alpha+p*(1-alpha-beta)` and `g = n*p + m - i`.\\n\\n    Typical values of (alpha,beta) are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k+1/2.)/n* : piecewise linear\\n          function (R, type 5)\\n        - (0,0)    : *p(k) = k/(n+1)* : (R type 6)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That's R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*. Blom.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM ?? JP\\n        - (0.35, 0.65): PWM   ?? JP  p(k) = (k-0.35)/n\\n\\n    Parameters\\n    ----------\\n    a : array_like\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : array_like, optional\\n        List of quantiles to compute.\\n    alpha : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    beta : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    axis : int, optional\\n        Axis along which to perform the trimming.\\n        If None (default), the input array is first flattened.\\n    limit : tuple\\n        Tuple of (lower, upper) values.\\n        Values of `a` outside this closed interval are ignored.\\n\\n    Returns\\n    -------\\n    quants : MaskedArray\\n        An array containing the calculated quantiles.\\n\\n    Examples\\n    --------\\n    >>> from scipy.stats.mstats import mquantiles\\n    >>> a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])\\n    >>> mquantiles(a)\\n    array([ 19.2,  40. ,  42.8])\\n\\n    Using a 2D array, specifying axis and limit.\\n\\n    >>> data = np.array([[   6.,    7.,    1.],\\n                         [  47.,   15.,    2.],\\n                         [  49.,   36.,    3.],\\n                         [  15.,   39.,    4.],\\n                         [  42.,   40., -999.],\\n                         [  41.,   41., -999.],\\n                         [   7., -999., -999.],\\n                         [  39., -999., -999.],\\n                         [  43., -999., -999.],\\n                         [  40., -999., -999.],\\n                         [  36., -999., -999.]])\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    array([[ 19.2 ,  14.6 ,   1.45],\\n           [ 40.  ,  37.5 ,   2.5 ],\\n           [ 42.8 ,  40.05,   3.55]])\\n\\n    >>> data[:, 2] = -999.\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    masked_array(data =\\n     [[19.2 14.6 --]\\n     [40.0 37.5 --]\\n     [42.8 40.05 --]],\\n                 mask =\\n     [[False False  True]\\n      [False False  True]\\n      [False False  True]],\\n           fill_value = 1e+20)\\n    \"\n    if isinstance(a, np.ma.MaskedArray):\n        return stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n    if limit:\n        marr = stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n        return ma.filled(marr, fill_value=np.nan)\n    if masknan:\n        nanmask = np.isnan(a)\n        if nanmask.any():\n            marr = ma.array(a, mask=nanmask)\n            marr = stats.mstats.mquantiles(marr, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(a)\n    p = np.array(prob, copy=False, ndmin=1)\n    m = alphap + p * (1.0 - alphap - betap)\n    isrolled = False\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    else:\n        axis = np.arange(data.ndim)[axis]\n        data = np.rollaxis(data, axis)\n        isrolled = True\n    x = np.sort(data, axis=0)\n    n = x.shape[0]\n    returnshape = list(data.shape)\n    returnshape[axis] = p\n    if n == 0:\n        return np.empty(len(p), dtype=float)\n    elif n == 1:\n        return np.resize(x, p.shape)\n    aleph = n * p + m\n    k = np.floor(aleph.clip(1, n - 1)).astype(int)\n    ind = [None] * x.ndim\n    ind[0] = slice(None)\n    gamma = (aleph - k).clip(0, 1)[ind]\n    q = (1.0 - gamma) * x[k - 1] + gamma * x[k]\n    if isrolled:\n        return np.rollaxis(q, 0, axis + 1)\n    else:\n        return q",
            "def quantiles(a, prob=list([0.25, 0.5, 0.75]), alphap=0.4, betap=0.4, axis=None, limit=(), masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Computes empirical quantiles for a data array.\\n\\n    Samples quantile are defined by :math:`Q(p) = (1-g).x[i] +g.x[i+1]`,\\n    where :math:`x[j]` is the *j*th order statistic, and\\n    `i = (floor(n*p+m))`, `m=alpha+p*(1-alpha-beta)` and `g = n*p + m - i`.\\n\\n    Typical values of (alpha,beta) are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k+1/2.)/n* : piecewise linear\\n          function (R, type 5)\\n        - (0,0)    : *p(k) = k/(n+1)* : (R type 6)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That's R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*. Blom.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM ?? JP\\n        - (0.35, 0.65): PWM   ?? JP  p(k) = (k-0.35)/n\\n\\n    Parameters\\n    ----------\\n    a : array_like\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : array_like, optional\\n        List of quantiles to compute.\\n    alpha : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    beta : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    axis : int, optional\\n        Axis along which to perform the trimming.\\n        If None (default), the input array is first flattened.\\n    limit : tuple\\n        Tuple of (lower, upper) values.\\n        Values of `a` outside this closed interval are ignored.\\n\\n    Returns\\n    -------\\n    quants : MaskedArray\\n        An array containing the calculated quantiles.\\n\\n    Examples\\n    --------\\n    >>> from scipy.stats.mstats import mquantiles\\n    >>> a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])\\n    >>> mquantiles(a)\\n    array([ 19.2,  40. ,  42.8])\\n\\n    Using a 2D array, specifying axis and limit.\\n\\n    >>> data = np.array([[   6.,    7.,    1.],\\n                         [  47.,   15.,    2.],\\n                         [  49.,   36.,    3.],\\n                         [  15.,   39.,    4.],\\n                         [  42.,   40., -999.],\\n                         [  41.,   41., -999.],\\n                         [   7., -999., -999.],\\n                         [  39., -999., -999.],\\n                         [  43., -999., -999.],\\n                         [  40., -999., -999.],\\n                         [  36., -999., -999.]])\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    array([[ 19.2 ,  14.6 ,   1.45],\\n           [ 40.  ,  37.5 ,   2.5 ],\\n           [ 42.8 ,  40.05,   3.55]])\\n\\n    >>> data[:, 2] = -999.\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    masked_array(data =\\n     [[19.2 14.6 --]\\n     [40.0 37.5 --]\\n     [42.8 40.05 --]],\\n                 mask =\\n     [[False False  True]\\n      [False False  True]\\n      [False False  True]],\\n           fill_value = 1e+20)\\n    \"\n    if isinstance(a, np.ma.MaskedArray):\n        return stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n    if limit:\n        marr = stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n        return ma.filled(marr, fill_value=np.nan)\n    if masknan:\n        nanmask = np.isnan(a)\n        if nanmask.any():\n            marr = ma.array(a, mask=nanmask)\n            marr = stats.mstats.mquantiles(marr, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(a)\n    p = np.array(prob, copy=False, ndmin=1)\n    m = alphap + p * (1.0 - alphap - betap)\n    isrolled = False\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    else:\n        axis = np.arange(data.ndim)[axis]\n        data = np.rollaxis(data, axis)\n        isrolled = True\n    x = np.sort(data, axis=0)\n    n = x.shape[0]\n    returnshape = list(data.shape)\n    returnshape[axis] = p\n    if n == 0:\n        return np.empty(len(p), dtype=float)\n    elif n == 1:\n        return np.resize(x, p.shape)\n    aleph = n * p + m\n    k = np.floor(aleph.clip(1, n - 1)).astype(int)\n    ind = [None] * x.ndim\n    ind[0] = slice(None)\n    gamma = (aleph - k).clip(0, 1)[ind]\n    q = (1.0 - gamma) * x[k - 1] + gamma * x[k]\n    if isrolled:\n        return np.rollaxis(q, 0, axis + 1)\n    else:\n        return q",
            "def quantiles(a, prob=list([0.25, 0.5, 0.75]), alphap=0.4, betap=0.4, axis=None, limit=(), masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Computes empirical quantiles for a data array.\\n\\n    Samples quantile are defined by :math:`Q(p) = (1-g).x[i] +g.x[i+1]`,\\n    where :math:`x[j]` is the *j*th order statistic, and\\n    `i = (floor(n*p+m))`, `m=alpha+p*(1-alpha-beta)` and `g = n*p + m - i`.\\n\\n    Typical values of (alpha,beta) are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k+1/2.)/n* : piecewise linear\\n          function (R, type 5)\\n        - (0,0)    : *p(k) = k/(n+1)* : (R type 6)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That's R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*. Blom.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM ?? JP\\n        - (0.35, 0.65): PWM   ?? JP  p(k) = (k-0.35)/n\\n\\n    Parameters\\n    ----------\\n    a : array_like\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : array_like, optional\\n        List of quantiles to compute.\\n    alpha : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    beta : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    axis : int, optional\\n        Axis along which to perform the trimming.\\n        If None (default), the input array is first flattened.\\n    limit : tuple\\n        Tuple of (lower, upper) values.\\n        Values of `a` outside this closed interval are ignored.\\n\\n    Returns\\n    -------\\n    quants : MaskedArray\\n        An array containing the calculated quantiles.\\n\\n    Examples\\n    --------\\n    >>> from scipy.stats.mstats import mquantiles\\n    >>> a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])\\n    >>> mquantiles(a)\\n    array([ 19.2,  40. ,  42.8])\\n\\n    Using a 2D array, specifying axis and limit.\\n\\n    >>> data = np.array([[   6.,    7.,    1.],\\n                         [  47.,   15.,    2.],\\n                         [  49.,   36.,    3.],\\n                         [  15.,   39.,    4.],\\n                         [  42.,   40., -999.],\\n                         [  41.,   41., -999.],\\n                         [   7., -999., -999.],\\n                         [  39., -999., -999.],\\n                         [  43., -999., -999.],\\n                         [  40., -999., -999.],\\n                         [  36., -999., -999.]])\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    array([[ 19.2 ,  14.6 ,   1.45],\\n           [ 40.  ,  37.5 ,   2.5 ],\\n           [ 42.8 ,  40.05,   3.55]])\\n\\n    >>> data[:, 2] = -999.\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    masked_array(data =\\n     [[19.2 14.6 --]\\n     [40.0 37.5 --]\\n     [42.8 40.05 --]],\\n                 mask =\\n     [[False False  True]\\n      [False False  True]\\n      [False False  True]],\\n           fill_value = 1e+20)\\n    \"\n    if isinstance(a, np.ma.MaskedArray):\n        return stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n    if limit:\n        marr = stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n        return ma.filled(marr, fill_value=np.nan)\n    if masknan:\n        nanmask = np.isnan(a)\n        if nanmask.any():\n            marr = ma.array(a, mask=nanmask)\n            marr = stats.mstats.mquantiles(marr, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(a)\n    p = np.array(prob, copy=False, ndmin=1)\n    m = alphap + p * (1.0 - alphap - betap)\n    isrolled = False\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    else:\n        axis = np.arange(data.ndim)[axis]\n        data = np.rollaxis(data, axis)\n        isrolled = True\n    x = np.sort(data, axis=0)\n    n = x.shape[0]\n    returnshape = list(data.shape)\n    returnshape[axis] = p\n    if n == 0:\n        return np.empty(len(p), dtype=float)\n    elif n == 1:\n        return np.resize(x, p.shape)\n    aleph = n * p + m\n    k = np.floor(aleph.clip(1, n - 1)).astype(int)\n    ind = [None] * x.ndim\n    ind[0] = slice(None)\n    gamma = (aleph - k).clip(0, 1)[ind]\n    q = (1.0 - gamma) * x[k - 1] + gamma * x[k]\n    if isrolled:\n        return np.rollaxis(q, 0, axis + 1)\n    else:\n        return q",
            "def quantiles(a, prob=list([0.25, 0.5, 0.75]), alphap=0.4, betap=0.4, axis=None, limit=(), masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Computes empirical quantiles for a data array.\\n\\n    Samples quantile are defined by :math:`Q(p) = (1-g).x[i] +g.x[i+1]`,\\n    where :math:`x[j]` is the *j*th order statistic, and\\n    `i = (floor(n*p+m))`, `m=alpha+p*(1-alpha-beta)` and `g = n*p + m - i`.\\n\\n    Typical values of (alpha,beta) are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k+1/2.)/n* : piecewise linear\\n          function (R, type 5)\\n        - (0,0)    : *p(k) = k/(n+1)* : (R type 6)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That's R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*. Blom.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM ?? JP\\n        - (0.35, 0.65): PWM   ?? JP  p(k) = (k-0.35)/n\\n\\n    Parameters\\n    ----------\\n    a : array_like\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : array_like, optional\\n        List of quantiles to compute.\\n    alpha : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    beta : float, optional\\n        Plotting positions parameter, default is 0.4.\\n    axis : int, optional\\n        Axis along which to perform the trimming.\\n        If None (default), the input array is first flattened.\\n    limit : tuple\\n        Tuple of (lower, upper) values.\\n        Values of `a` outside this closed interval are ignored.\\n\\n    Returns\\n    -------\\n    quants : MaskedArray\\n        An array containing the calculated quantiles.\\n\\n    Examples\\n    --------\\n    >>> from scipy.stats.mstats import mquantiles\\n    >>> a = np.array([6., 47., 49., 15., 42., 41., 7., 39., 43., 40., 36.])\\n    >>> mquantiles(a)\\n    array([ 19.2,  40. ,  42.8])\\n\\n    Using a 2D array, specifying axis and limit.\\n\\n    >>> data = np.array([[   6.,    7.,    1.],\\n                         [  47.,   15.,    2.],\\n                         [  49.,   36.,    3.],\\n                         [  15.,   39.,    4.],\\n                         [  42.,   40., -999.],\\n                         [  41.,   41., -999.],\\n                         [   7., -999., -999.],\\n                         [  39., -999., -999.],\\n                         [  43., -999., -999.],\\n                         [  40., -999., -999.],\\n                         [  36., -999., -999.]])\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    array([[ 19.2 ,  14.6 ,   1.45],\\n           [ 40.  ,  37.5 ,   2.5 ],\\n           [ 42.8 ,  40.05,   3.55]])\\n\\n    >>> data[:, 2] = -999.\\n    >>> mquantiles(data, axis=0, limit=(0, 50))\\n    masked_array(data =\\n     [[19.2 14.6 --]\\n     [40.0 37.5 --]\\n     [42.8 40.05 --]],\\n                 mask =\\n     [[False False  True]\\n      [False False  True]\\n      [False False  True]],\\n           fill_value = 1e+20)\\n    \"\n    if isinstance(a, np.ma.MaskedArray):\n        return stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n    if limit:\n        marr = stats.mstats.mquantiles(a, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n        return ma.filled(marr, fill_value=np.nan)\n    if masknan:\n        nanmask = np.isnan(a)\n        if nanmask.any():\n            marr = ma.array(a, mask=nanmask)\n            marr = stats.mstats.mquantiles(marr, prob=prob, alphap=alphap, betap=alphap, axis=axis, limit=limit)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(a)\n    p = np.array(prob, copy=False, ndmin=1)\n    m = alphap + p * (1.0 - alphap - betap)\n    isrolled = False\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    else:\n        axis = np.arange(data.ndim)[axis]\n        data = np.rollaxis(data, axis)\n        isrolled = True\n    x = np.sort(data, axis=0)\n    n = x.shape[0]\n    returnshape = list(data.shape)\n    returnshape[axis] = p\n    if n == 0:\n        return np.empty(len(p), dtype=float)\n    elif n == 1:\n        return np.resize(x, p.shape)\n    aleph = n * p + m\n    k = np.floor(aleph.clip(1, n - 1)).astype(int)\n    ind = [None] * x.ndim\n    ind[0] = slice(None)\n    gamma = (aleph - k).clip(0, 1)[ind]\n    q = (1.0 - gamma) * x[k - 1] + gamma * x[k]\n    if isrolled:\n        return np.rollaxis(q, 0, axis + 1)\n    else:\n        return q"
        ]
    },
    {
        "func_name": "scoreatpercentile",
        "original": "def scoreatpercentile(data, per, limit=(), alphap=0.4, betap=0.4, axis=0, masknan=None):\n    \"\"\"Calculate the score at the given 'per' percentile of the\n    sequence a.  For example, the score at per=50 is the median.\n\n    This function is a shortcut to mquantile\n    \"\"\"\n    per = np.asarray(per, float)\n    if (per < 0).any() or (per > 100.0).any():\n        raise ValueError('The percentile should be between 0. and 100. ! (got %s)' % per)\n    return quantiles(data, prob=[per / 100.0], alphap=alphap, betap=betap, limit=limit, axis=axis, masknan=masknan).squeeze()",
        "mutated": [
            "def scoreatpercentile(data, per, limit=(), alphap=0.4, betap=0.4, axis=0, masknan=None):\n    if False:\n        i = 10\n    \"Calculate the score at the given 'per' percentile of the\\n    sequence a.  For example, the score at per=50 is the median.\\n\\n    This function is a shortcut to mquantile\\n    \"\n    per = np.asarray(per, float)\n    if (per < 0).any() or (per > 100.0).any():\n        raise ValueError('The percentile should be between 0. and 100. ! (got %s)' % per)\n    return quantiles(data, prob=[per / 100.0], alphap=alphap, betap=betap, limit=limit, axis=axis, masknan=masknan).squeeze()",
            "def scoreatpercentile(data, per, limit=(), alphap=0.4, betap=0.4, axis=0, masknan=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Calculate the score at the given 'per' percentile of the\\n    sequence a.  For example, the score at per=50 is the median.\\n\\n    This function is a shortcut to mquantile\\n    \"\n    per = np.asarray(per, float)\n    if (per < 0).any() or (per > 100.0).any():\n        raise ValueError('The percentile should be between 0. and 100. ! (got %s)' % per)\n    return quantiles(data, prob=[per / 100.0], alphap=alphap, betap=betap, limit=limit, axis=axis, masknan=masknan).squeeze()",
            "def scoreatpercentile(data, per, limit=(), alphap=0.4, betap=0.4, axis=0, masknan=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Calculate the score at the given 'per' percentile of the\\n    sequence a.  For example, the score at per=50 is the median.\\n\\n    This function is a shortcut to mquantile\\n    \"\n    per = np.asarray(per, float)\n    if (per < 0).any() or (per > 100.0).any():\n        raise ValueError('The percentile should be between 0. and 100. ! (got %s)' % per)\n    return quantiles(data, prob=[per / 100.0], alphap=alphap, betap=betap, limit=limit, axis=axis, masknan=masknan).squeeze()",
            "def scoreatpercentile(data, per, limit=(), alphap=0.4, betap=0.4, axis=0, masknan=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Calculate the score at the given 'per' percentile of the\\n    sequence a.  For example, the score at per=50 is the median.\\n\\n    This function is a shortcut to mquantile\\n    \"\n    per = np.asarray(per, float)\n    if (per < 0).any() or (per > 100.0).any():\n        raise ValueError('The percentile should be between 0. and 100. ! (got %s)' % per)\n    return quantiles(data, prob=[per / 100.0], alphap=alphap, betap=betap, limit=limit, axis=axis, masknan=masknan).squeeze()",
            "def scoreatpercentile(data, per, limit=(), alphap=0.4, betap=0.4, axis=0, masknan=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Calculate the score at the given 'per' percentile of the\\n    sequence a.  For example, the score at per=50 is the median.\\n\\n    This function is a shortcut to mquantile\\n    \"\n    per = np.asarray(per, float)\n    if (per < 0).any() or (per > 100.0).any():\n        raise ValueError('The percentile should be between 0. and 100. ! (got %s)' % per)\n    return quantiles(data, prob=[per / 100.0], alphap=alphap, betap=betap, limit=limit, axis=axis, masknan=masknan).squeeze()"
        ]
    },
    {
        "func_name": "plotting_positions",
        "original": "def plotting_positions(data, alpha=0.4, beta=0.4, axis=0, masknan=False):\n    \"\"\"Returns the plotting positions (or empirical percentile points) for the\n    data.\n    Plotting positions are defined as (i-alpha)/(n+1-alpha-beta), where:\n        - i is the rank order statistics (starting at 1)\n        - n is the number of unmasked values along the given axis\n        - alpha and beta are two parameters.\n\n    Typical values for alpha and beta are:\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\n        - (.5,.5)  : *p(k) = (k-1/2.)/n* : piecewise linear function (R, type 5)\n          (Bliss 1967: \"Rankit\")\n        - (0,0)    : *p(k) = k/(n+1)* : Weibull (R type 6), (Van der Waerden 1952)\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\n          That's R default (R type 7)\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\n          The resulting quantile estimates are approximately median-unbiased\n          regardless of the distribution of x. (R type 8), (Tukey 1962)\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*.\n          The resulting quantile estimates are approximately unbiased\n          if x is normally distributed (R type 9) (Blom 1958)\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\n        - (.35,.35): APL, used with PWM\n\n    Parameters\n    ----------\n    x : sequence\n        Input data, as a sequence or array of dimension at most 2.\n    prob : sequence\n        List of quantiles to compute.\n    alpha : {0.4, float} optional\n        Plotting positions parameter.\n    beta : {0.4, float} optional\n        Plotting positions parameter.\n\n    Notes\n    -----\n    I think the adjustments assume that there are no ties in order to be a reasonable\n    approximation to a continuous density function. TODO: check this\n\n    References\n    ----------\n    unknown,\n    dates to original papers from Beasley, Erickson, Allison 2009 Behav Genet\n    \"\"\"\n    if isinstance(data, np.ma.MaskedArray):\n        if axis is None or data.ndim == 1:\n            return stats.mstats.plotting_positions(data, alpha=alpha, beta=beta)\n        else:\n            return ma.apply_along_axis(stats.mstats.plotting_positions, axis, data, alpha=alpha, beta=beta)\n    if masknan:\n        nanmask = np.isnan(data)\n        if nanmask.any():\n            marr = ma.array(data, mask=nanmask)\n            if axis is None or data.ndim == 1:\n                marr = stats.mstats.plotting_positions(marr, alpha=alpha, beta=beta)\n            else:\n                marr = ma.apply_along_axis(stats.mstats.plotting_positions, axis, marr, alpha=alpha, beta=beta)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(data)\n    if data.size == 1:\n        data = np.atleast_1d(data)\n        axis = 0\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    n = data.shape[axis]\n    if data.ndim == 1:\n        plpos = np.empty(data.shape, dtype=float)\n        plpos[data.argsort()] = (np.arange(1, n + 1) - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        plpos = (data.argsort(axis).argsort(axis) + 1.0 - alpha) / (n + 1.0 - alpha - beta)\n    return plpos",
        "mutated": [
            "def plotting_positions(data, alpha=0.4, beta=0.4, axis=0, masknan=False):\n    if False:\n        i = 10\n    'Returns the plotting positions (or empirical percentile points) for the\\n    data.\\n    Plotting positions are defined as (i-alpha)/(n+1-alpha-beta), where:\\n        - i is the rank order statistics (starting at 1)\\n        - n is the number of unmasked values along the given axis\\n        - alpha and beta are two parameters.\\n\\n    Typical values for alpha and beta are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k-1/2.)/n* : piecewise linear function (R, type 5)\\n          (Bliss 1967: \"Rankit\")\\n        - (0,0)    : *p(k) = k/(n+1)* : Weibull (R type 6), (Van der Waerden 1952)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That\\'s R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8), (Tukey 1962)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9) (Blom 1958)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM\\n\\n    Parameters\\n    ----------\\n    x : sequence\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : sequence\\n        List of quantiles to compute.\\n    alpha : {0.4, float} optional\\n        Plotting positions parameter.\\n    beta : {0.4, float} optional\\n        Plotting positions parameter.\\n\\n    Notes\\n    -----\\n    I think the adjustments assume that there are no ties in order to be a reasonable\\n    approximation to a continuous density function. TODO: check this\\n\\n    References\\n    ----------\\n    unknown,\\n    dates to original papers from Beasley, Erickson, Allison 2009 Behav Genet\\n    '\n    if isinstance(data, np.ma.MaskedArray):\n        if axis is None or data.ndim == 1:\n            return stats.mstats.plotting_positions(data, alpha=alpha, beta=beta)\n        else:\n            return ma.apply_along_axis(stats.mstats.plotting_positions, axis, data, alpha=alpha, beta=beta)\n    if masknan:\n        nanmask = np.isnan(data)\n        if nanmask.any():\n            marr = ma.array(data, mask=nanmask)\n            if axis is None or data.ndim == 1:\n                marr = stats.mstats.plotting_positions(marr, alpha=alpha, beta=beta)\n            else:\n                marr = ma.apply_along_axis(stats.mstats.plotting_positions, axis, marr, alpha=alpha, beta=beta)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(data)\n    if data.size == 1:\n        data = np.atleast_1d(data)\n        axis = 0\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    n = data.shape[axis]\n    if data.ndim == 1:\n        plpos = np.empty(data.shape, dtype=float)\n        plpos[data.argsort()] = (np.arange(1, n + 1) - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        plpos = (data.argsort(axis).argsort(axis) + 1.0 - alpha) / (n + 1.0 - alpha - beta)\n    return plpos",
            "def plotting_positions(data, alpha=0.4, beta=0.4, axis=0, masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns the plotting positions (or empirical percentile points) for the\\n    data.\\n    Plotting positions are defined as (i-alpha)/(n+1-alpha-beta), where:\\n        - i is the rank order statistics (starting at 1)\\n        - n is the number of unmasked values along the given axis\\n        - alpha and beta are two parameters.\\n\\n    Typical values for alpha and beta are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k-1/2.)/n* : piecewise linear function (R, type 5)\\n          (Bliss 1967: \"Rankit\")\\n        - (0,0)    : *p(k) = k/(n+1)* : Weibull (R type 6), (Van der Waerden 1952)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That\\'s R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8), (Tukey 1962)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9) (Blom 1958)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM\\n\\n    Parameters\\n    ----------\\n    x : sequence\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : sequence\\n        List of quantiles to compute.\\n    alpha : {0.4, float} optional\\n        Plotting positions parameter.\\n    beta : {0.4, float} optional\\n        Plotting positions parameter.\\n\\n    Notes\\n    -----\\n    I think the adjustments assume that there are no ties in order to be a reasonable\\n    approximation to a continuous density function. TODO: check this\\n\\n    References\\n    ----------\\n    unknown,\\n    dates to original papers from Beasley, Erickson, Allison 2009 Behav Genet\\n    '\n    if isinstance(data, np.ma.MaskedArray):\n        if axis is None or data.ndim == 1:\n            return stats.mstats.plotting_positions(data, alpha=alpha, beta=beta)\n        else:\n            return ma.apply_along_axis(stats.mstats.plotting_positions, axis, data, alpha=alpha, beta=beta)\n    if masknan:\n        nanmask = np.isnan(data)\n        if nanmask.any():\n            marr = ma.array(data, mask=nanmask)\n            if axis is None or data.ndim == 1:\n                marr = stats.mstats.plotting_positions(marr, alpha=alpha, beta=beta)\n            else:\n                marr = ma.apply_along_axis(stats.mstats.plotting_positions, axis, marr, alpha=alpha, beta=beta)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(data)\n    if data.size == 1:\n        data = np.atleast_1d(data)\n        axis = 0\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    n = data.shape[axis]\n    if data.ndim == 1:\n        plpos = np.empty(data.shape, dtype=float)\n        plpos[data.argsort()] = (np.arange(1, n + 1) - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        plpos = (data.argsort(axis).argsort(axis) + 1.0 - alpha) / (n + 1.0 - alpha - beta)\n    return plpos",
            "def plotting_positions(data, alpha=0.4, beta=0.4, axis=0, masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns the plotting positions (or empirical percentile points) for the\\n    data.\\n    Plotting positions are defined as (i-alpha)/(n+1-alpha-beta), where:\\n        - i is the rank order statistics (starting at 1)\\n        - n is the number of unmasked values along the given axis\\n        - alpha and beta are two parameters.\\n\\n    Typical values for alpha and beta are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k-1/2.)/n* : piecewise linear function (R, type 5)\\n          (Bliss 1967: \"Rankit\")\\n        - (0,0)    : *p(k) = k/(n+1)* : Weibull (R type 6), (Van der Waerden 1952)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That\\'s R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8), (Tukey 1962)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9) (Blom 1958)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM\\n\\n    Parameters\\n    ----------\\n    x : sequence\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : sequence\\n        List of quantiles to compute.\\n    alpha : {0.4, float} optional\\n        Plotting positions parameter.\\n    beta : {0.4, float} optional\\n        Plotting positions parameter.\\n\\n    Notes\\n    -----\\n    I think the adjustments assume that there are no ties in order to be a reasonable\\n    approximation to a continuous density function. TODO: check this\\n\\n    References\\n    ----------\\n    unknown,\\n    dates to original papers from Beasley, Erickson, Allison 2009 Behav Genet\\n    '\n    if isinstance(data, np.ma.MaskedArray):\n        if axis is None or data.ndim == 1:\n            return stats.mstats.plotting_positions(data, alpha=alpha, beta=beta)\n        else:\n            return ma.apply_along_axis(stats.mstats.plotting_positions, axis, data, alpha=alpha, beta=beta)\n    if masknan:\n        nanmask = np.isnan(data)\n        if nanmask.any():\n            marr = ma.array(data, mask=nanmask)\n            if axis is None or data.ndim == 1:\n                marr = stats.mstats.plotting_positions(marr, alpha=alpha, beta=beta)\n            else:\n                marr = ma.apply_along_axis(stats.mstats.plotting_positions, axis, marr, alpha=alpha, beta=beta)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(data)\n    if data.size == 1:\n        data = np.atleast_1d(data)\n        axis = 0\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    n = data.shape[axis]\n    if data.ndim == 1:\n        plpos = np.empty(data.shape, dtype=float)\n        plpos[data.argsort()] = (np.arange(1, n + 1) - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        plpos = (data.argsort(axis).argsort(axis) + 1.0 - alpha) / (n + 1.0 - alpha - beta)\n    return plpos",
            "def plotting_positions(data, alpha=0.4, beta=0.4, axis=0, masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns the plotting positions (or empirical percentile points) for the\\n    data.\\n    Plotting positions are defined as (i-alpha)/(n+1-alpha-beta), where:\\n        - i is the rank order statistics (starting at 1)\\n        - n is the number of unmasked values along the given axis\\n        - alpha and beta are two parameters.\\n\\n    Typical values for alpha and beta are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k-1/2.)/n* : piecewise linear function (R, type 5)\\n          (Bliss 1967: \"Rankit\")\\n        - (0,0)    : *p(k) = k/(n+1)* : Weibull (R type 6), (Van der Waerden 1952)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That\\'s R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8), (Tukey 1962)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9) (Blom 1958)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM\\n\\n    Parameters\\n    ----------\\n    x : sequence\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : sequence\\n        List of quantiles to compute.\\n    alpha : {0.4, float} optional\\n        Plotting positions parameter.\\n    beta : {0.4, float} optional\\n        Plotting positions parameter.\\n\\n    Notes\\n    -----\\n    I think the adjustments assume that there are no ties in order to be a reasonable\\n    approximation to a continuous density function. TODO: check this\\n\\n    References\\n    ----------\\n    unknown,\\n    dates to original papers from Beasley, Erickson, Allison 2009 Behav Genet\\n    '\n    if isinstance(data, np.ma.MaskedArray):\n        if axis is None or data.ndim == 1:\n            return stats.mstats.plotting_positions(data, alpha=alpha, beta=beta)\n        else:\n            return ma.apply_along_axis(stats.mstats.plotting_positions, axis, data, alpha=alpha, beta=beta)\n    if masknan:\n        nanmask = np.isnan(data)\n        if nanmask.any():\n            marr = ma.array(data, mask=nanmask)\n            if axis is None or data.ndim == 1:\n                marr = stats.mstats.plotting_positions(marr, alpha=alpha, beta=beta)\n            else:\n                marr = ma.apply_along_axis(stats.mstats.plotting_positions, axis, marr, alpha=alpha, beta=beta)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(data)\n    if data.size == 1:\n        data = np.atleast_1d(data)\n        axis = 0\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    n = data.shape[axis]\n    if data.ndim == 1:\n        plpos = np.empty(data.shape, dtype=float)\n        plpos[data.argsort()] = (np.arange(1, n + 1) - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        plpos = (data.argsort(axis).argsort(axis) + 1.0 - alpha) / (n + 1.0 - alpha - beta)\n    return plpos",
            "def plotting_positions(data, alpha=0.4, beta=0.4, axis=0, masknan=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns the plotting positions (or empirical percentile points) for the\\n    data.\\n    Plotting positions are defined as (i-alpha)/(n+1-alpha-beta), where:\\n        - i is the rank order statistics (starting at 1)\\n        - n is the number of unmasked values along the given axis\\n        - alpha and beta are two parameters.\\n\\n    Typical values for alpha and beta are:\\n        - (0,1)    : *p(k) = k/n* : linear interpolation of cdf (R, type 4)\\n        - (.5,.5)  : *p(k) = (k-1/2.)/n* : piecewise linear function (R, type 5)\\n          (Bliss 1967: \"Rankit\")\\n        - (0,0)    : *p(k) = k/(n+1)* : Weibull (R type 6), (Van der Waerden 1952)\\n        - (1,1)    : *p(k) = (k-1)/(n-1)*. In this case, p(k) = mode[F(x[k])].\\n          That\\'s R default (R type 7)\\n        - (1/3,1/3): *p(k) = (k-1/3)/(n+1/3)*. Then p(k) ~ median[F(x[k])].\\n          The resulting quantile estimates are approximately median-unbiased\\n          regardless of the distribution of x. (R type 8), (Tukey 1962)\\n        - (3/8,3/8): *p(k) = (k-3/8)/(n+1/4)*.\\n          The resulting quantile estimates are approximately unbiased\\n          if x is normally distributed (R type 9) (Blom 1958)\\n        - (.4,.4)  : approximately quantile unbiased (Cunnane)\\n        - (.35,.35): APL, used with PWM\\n\\n    Parameters\\n    ----------\\n    x : sequence\\n        Input data, as a sequence or array of dimension at most 2.\\n    prob : sequence\\n        List of quantiles to compute.\\n    alpha : {0.4, float} optional\\n        Plotting positions parameter.\\n    beta : {0.4, float} optional\\n        Plotting positions parameter.\\n\\n    Notes\\n    -----\\n    I think the adjustments assume that there are no ties in order to be a reasonable\\n    approximation to a continuous density function. TODO: check this\\n\\n    References\\n    ----------\\n    unknown,\\n    dates to original papers from Beasley, Erickson, Allison 2009 Behav Genet\\n    '\n    if isinstance(data, np.ma.MaskedArray):\n        if axis is None or data.ndim == 1:\n            return stats.mstats.plotting_positions(data, alpha=alpha, beta=beta)\n        else:\n            return ma.apply_along_axis(stats.mstats.plotting_positions, axis, data, alpha=alpha, beta=beta)\n    if masknan:\n        nanmask = np.isnan(data)\n        if nanmask.any():\n            marr = ma.array(data, mask=nanmask)\n            if axis is None or data.ndim == 1:\n                marr = stats.mstats.plotting_positions(marr, alpha=alpha, beta=beta)\n            else:\n                marr = ma.apply_along_axis(stats.mstats.plotting_positions, axis, marr, alpha=alpha, beta=beta)\n            return ma.filled(marr, fill_value=np.nan)\n    data = np.asarray(data)\n    if data.size == 1:\n        data = np.atleast_1d(data)\n        axis = 0\n    if axis is None:\n        data = data.ravel()\n        axis = 0\n    n = data.shape[axis]\n    if data.ndim == 1:\n        plpos = np.empty(data.shape, dtype=float)\n        plpos[data.argsort()] = (np.arange(1, n + 1) - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        plpos = (data.argsort(axis).argsort(axis) + 1.0 - alpha) / (n + 1.0 - alpha - beta)\n    return plpos"
        ]
    },
    {
        "func_name": "plotting_positions_w1d",
        "original": "def plotting_positions_w1d(data, weights=None, alpha=0.4, beta=0.4, method='notnormed'):\n    \"\"\"Weighted plotting positions (or empirical percentile points) for the data.\n\n    observations are weighted and the plotting positions are defined as\n    (ws-alpha)/(n-alpha-beta), where:\n        - ws is the weighted rank order statistics or cumulative weighted sum,\n          normalized to n if method is \"normed\"\n        - n is the number of values along the given axis if method is \"normed\"\n          and total weight otherwise\n        - alpha and beta are two parameters.\n\n    wtd.quantile in R package Hmisc seems to use the \"notnormed\" version.\n    notnormed coincides with unweighted segment in example, drop \"normed\" version ?\n\n\n    See Also\n    --------\n    plotting_positions : unweighted version that works also with more than one\n        dimension and has other options\n    \"\"\"\n    x = np.atleast_1d(data)\n    if x.ndim > 1:\n        raise ValueError('currently implemented only for 1d')\n    if weights is None:\n        weights = np.ones(x.shape)\n    else:\n        weights = np.array(weights, float, copy=False, ndmin=1)\n        if weights.shape != x.shape:\n            raise ValueError('if weights is given, it needs to be the sameshape as data')\n    n = len(x)\n    xargsort = x.argsort()\n    ws = weights[xargsort].cumsum()\n    res = np.empty(x.shape)\n    if method == 'normed':\n        res[xargsort] = (1.0 * ws / ws[-1] * n - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        res[xargsort] = (1.0 * ws - alpha) / (ws[-1] + 1.0 - alpha - beta)\n    return res",
        "mutated": [
            "def plotting_positions_w1d(data, weights=None, alpha=0.4, beta=0.4, method='notnormed'):\n    if False:\n        i = 10\n    'Weighted plotting positions (or empirical percentile points) for the data.\\n\\n    observations are weighted and the plotting positions are defined as\\n    (ws-alpha)/(n-alpha-beta), where:\\n        - ws is the weighted rank order statistics or cumulative weighted sum,\\n          normalized to n if method is \"normed\"\\n        - n is the number of values along the given axis if method is \"normed\"\\n          and total weight otherwise\\n        - alpha and beta are two parameters.\\n\\n    wtd.quantile in R package Hmisc seems to use the \"notnormed\" version.\\n    notnormed coincides with unweighted segment in example, drop \"normed\" version ?\\n\\n\\n    See Also\\n    --------\\n    plotting_positions : unweighted version that works also with more than one\\n        dimension and has other options\\n    '\n    x = np.atleast_1d(data)\n    if x.ndim > 1:\n        raise ValueError('currently implemented only for 1d')\n    if weights is None:\n        weights = np.ones(x.shape)\n    else:\n        weights = np.array(weights, float, copy=False, ndmin=1)\n        if weights.shape != x.shape:\n            raise ValueError('if weights is given, it needs to be the sameshape as data')\n    n = len(x)\n    xargsort = x.argsort()\n    ws = weights[xargsort].cumsum()\n    res = np.empty(x.shape)\n    if method == 'normed':\n        res[xargsort] = (1.0 * ws / ws[-1] * n - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        res[xargsort] = (1.0 * ws - alpha) / (ws[-1] + 1.0 - alpha - beta)\n    return res",
            "def plotting_positions_w1d(data, weights=None, alpha=0.4, beta=0.4, method='notnormed'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Weighted plotting positions (or empirical percentile points) for the data.\\n\\n    observations are weighted and the plotting positions are defined as\\n    (ws-alpha)/(n-alpha-beta), where:\\n        - ws is the weighted rank order statistics or cumulative weighted sum,\\n          normalized to n if method is \"normed\"\\n        - n is the number of values along the given axis if method is \"normed\"\\n          and total weight otherwise\\n        - alpha and beta are two parameters.\\n\\n    wtd.quantile in R package Hmisc seems to use the \"notnormed\" version.\\n    notnormed coincides with unweighted segment in example, drop \"normed\" version ?\\n\\n\\n    See Also\\n    --------\\n    plotting_positions : unweighted version that works also with more than one\\n        dimension and has other options\\n    '\n    x = np.atleast_1d(data)\n    if x.ndim > 1:\n        raise ValueError('currently implemented only for 1d')\n    if weights is None:\n        weights = np.ones(x.shape)\n    else:\n        weights = np.array(weights, float, copy=False, ndmin=1)\n        if weights.shape != x.shape:\n            raise ValueError('if weights is given, it needs to be the sameshape as data')\n    n = len(x)\n    xargsort = x.argsort()\n    ws = weights[xargsort].cumsum()\n    res = np.empty(x.shape)\n    if method == 'normed':\n        res[xargsort] = (1.0 * ws / ws[-1] * n - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        res[xargsort] = (1.0 * ws - alpha) / (ws[-1] + 1.0 - alpha - beta)\n    return res",
            "def plotting_positions_w1d(data, weights=None, alpha=0.4, beta=0.4, method='notnormed'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Weighted plotting positions (or empirical percentile points) for the data.\\n\\n    observations are weighted and the plotting positions are defined as\\n    (ws-alpha)/(n-alpha-beta), where:\\n        - ws is the weighted rank order statistics or cumulative weighted sum,\\n          normalized to n if method is \"normed\"\\n        - n is the number of values along the given axis if method is \"normed\"\\n          and total weight otherwise\\n        - alpha and beta are two parameters.\\n\\n    wtd.quantile in R package Hmisc seems to use the \"notnormed\" version.\\n    notnormed coincides with unweighted segment in example, drop \"normed\" version ?\\n\\n\\n    See Also\\n    --------\\n    plotting_positions : unweighted version that works also with more than one\\n        dimension and has other options\\n    '\n    x = np.atleast_1d(data)\n    if x.ndim > 1:\n        raise ValueError('currently implemented only for 1d')\n    if weights is None:\n        weights = np.ones(x.shape)\n    else:\n        weights = np.array(weights, float, copy=False, ndmin=1)\n        if weights.shape != x.shape:\n            raise ValueError('if weights is given, it needs to be the sameshape as data')\n    n = len(x)\n    xargsort = x.argsort()\n    ws = weights[xargsort].cumsum()\n    res = np.empty(x.shape)\n    if method == 'normed':\n        res[xargsort] = (1.0 * ws / ws[-1] * n - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        res[xargsort] = (1.0 * ws - alpha) / (ws[-1] + 1.0 - alpha - beta)\n    return res",
            "def plotting_positions_w1d(data, weights=None, alpha=0.4, beta=0.4, method='notnormed'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Weighted plotting positions (or empirical percentile points) for the data.\\n\\n    observations are weighted and the plotting positions are defined as\\n    (ws-alpha)/(n-alpha-beta), where:\\n        - ws is the weighted rank order statistics or cumulative weighted sum,\\n          normalized to n if method is \"normed\"\\n        - n is the number of values along the given axis if method is \"normed\"\\n          and total weight otherwise\\n        - alpha and beta are two parameters.\\n\\n    wtd.quantile in R package Hmisc seems to use the \"notnormed\" version.\\n    notnormed coincides with unweighted segment in example, drop \"normed\" version ?\\n\\n\\n    See Also\\n    --------\\n    plotting_positions : unweighted version that works also with more than one\\n        dimension and has other options\\n    '\n    x = np.atleast_1d(data)\n    if x.ndim > 1:\n        raise ValueError('currently implemented only for 1d')\n    if weights is None:\n        weights = np.ones(x.shape)\n    else:\n        weights = np.array(weights, float, copy=False, ndmin=1)\n        if weights.shape != x.shape:\n            raise ValueError('if weights is given, it needs to be the sameshape as data')\n    n = len(x)\n    xargsort = x.argsort()\n    ws = weights[xargsort].cumsum()\n    res = np.empty(x.shape)\n    if method == 'normed':\n        res[xargsort] = (1.0 * ws / ws[-1] * n - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        res[xargsort] = (1.0 * ws - alpha) / (ws[-1] + 1.0 - alpha - beta)\n    return res",
            "def plotting_positions_w1d(data, weights=None, alpha=0.4, beta=0.4, method='notnormed'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Weighted plotting positions (or empirical percentile points) for the data.\\n\\n    observations are weighted and the plotting positions are defined as\\n    (ws-alpha)/(n-alpha-beta), where:\\n        - ws is the weighted rank order statistics or cumulative weighted sum,\\n          normalized to n if method is \"normed\"\\n        - n is the number of values along the given axis if method is \"normed\"\\n          and total weight otherwise\\n        - alpha and beta are two parameters.\\n\\n    wtd.quantile in R package Hmisc seems to use the \"notnormed\" version.\\n    notnormed coincides with unweighted segment in example, drop \"normed\" version ?\\n\\n\\n    See Also\\n    --------\\n    plotting_positions : unweighted version that works also with more than one\\n        dimension and has other options\\n    '\n    x = np.atleast_1d(data)\n    if x.ndim > 1:\n        raise ValueError('currently implemented only for 1d')\n    if weights is None:\n        weights = np.ones(x.shape)\n    else:\n        weights = np.array(weights, float, copy=False, ndmin=1)\n        if weights.shape != x.shape:\n            raise ValueError('if weights is given, it needs to be the sameshape as data')\n    n = len(x)\n    xargsort = x.argsort()\n    ws = weights[xargsort].cumsum()\n    res = np.empty(x.shape)\n    if method == 'normed':\n        res[xargsort] = (1.0 * ws / ws[-1] * n - alpha) / (n + 1.0 - alpha - beta)\n    else:\n        res[xargsort] = (1.0 * ws - alpha) / (ws[-1] + 1.0 - alpha - beta)\n    return res"
        ]
    },
    {
        "func_name": "edf_normal_inverse_transformed",
        "original": "def edf_normal_inverse_transformed(x, alpha=3.0 / 8, beta=3.0 / 8, axis=0):\n    \"\"\"rank based normal inverse transformed cdf\n    \"\"\"\n    from scipy import stats\n    ranks = plotting_positions(x, alpha=alpha, beta=alpha, axis=0, masknan=False)\n    ranks_transf = stats.norm.ppf(ranks)\n    return ranks_transf",
        "mutated": [
            "def edf_normal_inverse_transformed(x, alpha=3.0 / 8, beta=3.0 / 8, axis=0):\n    if False:\n        i = 10\n    'rank based normal inverse transformed cdf\\n    '\n    from scipy import stats\n    ranks = plotting_positions(x, alpha=alpha, beta=alpha, axis=0, masknan=False)\n    ranks_transf = stats.norm.ppf(ranks)\n    return ranks_transf",
            "def edf_normal_inverse_transformed(x, alpha=3.0 / 8, beta=3.0 / 8, axis=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'rank based normal inverse transformed cdf\\n    '\n    from scipy import stats\n    ranks = plotting_positions(x, alpha=alpha, beta=alpha, axis=0, masknan=False)\n    ranks_transf = stats.norm.ppf(ranks)\n    return ranks_transf",
            "def edf_normal_inverse_transformed(x, alpha=3.0 / 8, beta=3.0 / 8, axis=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'rank based normal inverse transformed cdf\\n    '\n    from scipy import stats\n    ranks = plotting_positions(x, alpha=alpha, beta=alpha, axis=0, masknan=False)\n    ranks_transf = stats.norm.ppf(ranks)\n    return ranks_transf",
            "def edf_normal_inverse_transformed(x, alpha=3.0 / 8, beta=3.0 / 8, axis=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'rank based normal inverse transformed cdf\\n    '\n    from scipy import stats\n    ranks = plotting_positions(x, alpha=alpha, beta=alpha, axis=0, masknan=False)\n    ranks_transf = stats.norm.ppf(ranks)\n    return ranks_transf",
            "def edf_normal_inverse_transformed(x, alpha=3.0 / 8, beta=3.0 / 8, axis=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'rank based normal inverse transformed cdf\\n    '\n    from scipy import stats\n    ranks = plotting_positions(x, alpha=alpha, beta=alpha, axis=0, masknan=False)\n    ranks_transf = stats.norm.ppf(ranks)\n    return ranks_transf"
        ]
    }
]