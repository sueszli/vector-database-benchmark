[
    {
        "func_name": "inference",
        "original": "def inference(x, is_training, num_steps, reuse=None):\n    \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n    print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n    init = tf.random_uniform_initializer(-init_scale, init_scale)\n    with tf.variable_scope('model', reuse=reuse):\n        net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n        lstm1 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n        lstm2 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n        net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n    return (net, lstm1, lstm2)",
        "mutated": [
            "def inference(x, is_training, num_steps, reuse=None):\n    if False:\n        i = 10\n    'If reuse is True, the inferences use the existing parameters,\\n        then different inferences share the same parameters.\\n\\n        Note :\\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\\n        '\n    print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n    init = tf.random_uniform_initializer(-init_scale, init_scale)\n    with tf.variable_scope('model', reuse=reuse):\n        net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n        lstm1 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n        lstm2 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n        net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n    return (net, lstm1, lstm2)",
            "def inference(x, is_training, num_steps, reuse=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'If reuse is True, the inferences use the existing parameters,\\n        then different inferences share the same parameters.\\n\\n        Note :\\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\\n        '\n    print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n    init = tf.random_uniform_initializer(-init_scale, init_scale)\n    with tf.variable_scope('model', reuse=reuse):\n        net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n        lstm1 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n        lstm2 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n        net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n    return (net, lstm1, lstm2)",
            "def inference(x, is_training, num_steps, reuse=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'If reuse is True, the inferences use the existing parameters,\\n        then different inferences share the same parameters.\\n\\n        Note :\\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\\n        '\n    print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n    init = tf.random_uniform_initializer(-init_scale, init_scale)\n    with tf.variable_scope('model', reuse=reuse):\n        net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n        lstm1 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n        lstm2 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n        net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n    return (net, lstm1, lstm2)",
            "def inference(x, is_training, num_steps, reuse=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'If reuse is True, the inferences use the existing parameters,\\n        then different inferences share the same parameters.\\n\\n        Note :\\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\\n        '\n    print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n    init = tf.random_uniform_initializer(-init_scale, init_scale)\n    with tf.variable_scope('model', reuse=reuse):\n        net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n        lstm1 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n        lstm2 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n        net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n    return (net, lstm1, lstm2)",
            "def inference(x, is_training, num_steps, reuse=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'If reuse is True, the inferences use the existing parameters,\\n        then different inferences share the same parameters.\\n\\n        Note :\\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\\n        '\n    print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n    init = tf.random_uniform_initializer(-init_scale, init_scale)\n    with tf.variable_scope('model', reuse=reuse):\n        net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n        lstm1 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n        net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n        lstm2 = net\n        net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n        net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n    return (net, lstm1, lstm2)"
        ]
    },
    {
        "func_name": "loss_fn",
        "original": "def loss_fn(outputs, targets, batch_size):\n    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n    cost = tf.reduce_sum(loss) / batch_size\n    return cost",
        "mutated": [
            "def loss_fn(outputs, targets, batch_size):\n    if False:\n        i = 10\n    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n    cost = tf.reduce_sum(loss) / batch_size\n    return cost",
            "def loss_fn(outputs, targets, batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n    cost = tf.reduce_sum(loss) / batch_size\n    return cost",
            "def loss_fn(outputs, targets, batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n    cost = tf.reduce_sum(loss) / batch_size\n    return cost",
            "def loss_fn(outputs, targets, batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n    cost = tf.reduce_sum(loss) / batch_size\n    return cost",
            "def loss_fn(outputs, targets, batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n    cost = tf.reduce_sum(loss) / batch_size\n    return cost"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(_):\n    \"\"\"\n    The core of the model consists of an LSTM cell that processes one word at\n    a time and computes probabilities of the possible continuations of the\n    sentence. The memory state of the network is initialized with a vector\n    of zeros and gets updated after reading each word. Also, for computational\n    reasons, we will process data in mini-batches of size batch_size.\n    \"\"\"\n    if FLAGS.model == 'small':\n        init_scale = 0.1\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 20\n        hidden_size = 200\n        max_epoch = 4\n        max_max_epoch = 13\n        keep_prob = 1.0\n        lr_decay = 0.5\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'medium':\n        init_scale = 0.05\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 35\n        hidden_size = 650\n        max_epoch = 6\n        max_max_epoch = 39\n        keep_prob = 0.5\n        lr_decay = 0.8\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'large':\n        init_scale = 0.04\n        learning_rate = 1.0\n        max_grad_norm = 10\n        num_steps = 35\n        hidden_size = 1500\n        max_epoch = 14\n        max_max_epoch = 55\n        keep_prob = 0.35\n        lr_decay = 1 / 1.15\n        batch_size = 20\n        vocab_size = 10000\n    else:\n        raise ValueError('Invalid model: %s', FLAGS.model)\n    (train_data, valid_data, test_data, vocab_size) = tl.files.load_ptb_dataset()\n    print('len(train_data) {}'.format(len(train_data)))\n    print('len(valid_data) {}'.format(len(valid_data)))\n    print('len(test_data)  {}'.format(len(test_data)))\n    print('vocab_size      {}'.format(vocab_size))\n    sess = tf.InteractiveSession()\n    input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n    targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n    input_data_test = tf.placeholder(tf.int32, [1, 1])\n    targets_test = tf.placeholder(tf.int32, [1, 1])\n\n    def inference(x, is_training, num_steps, reuse=None):\n        \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n        print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n        init = tf.random_uniform_initializer(-init_scale, init_scale)\n        with tf.variable_scope('model', reuse=reuse):\n            net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n            lstm1 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n            lstm2 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n        return (net, lstm1, lstm2)\n    (net, lstm1, lstm2) = inference(input_data, is_training=True, num_steps=num_steps, reuse=None)\n    (net_val, lstm1_val, lstm2_val) = inference(input_data, is_training=False, num_steps=num_steps, reuse=True)\n    (net_test, lstm1_test, lstm2_test) = inference(input_data_test, is_training=False, num_steps=1, reuse=True)\n    sess.run(tf.global_variables_initializer())\n\n    def loss_fn(outputs, targets, batch_size):\n        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n        cost = tf.reduce_sum(loss) / batch_size\n        return cost\n    cost = loss_fn(net.outputs, targets, batch_size)\n    cost_val = loss_fn(net_val.outputs, targets, batch_size)\n    cost_test = loss_fn(net_test.outputs, targets_test, 1)\n    with tf.variable_scope('learning_rate'):\n        lr = tf.Variable(0.0, trainable=False)\n    tvars = tf.trainable_variables()\n    (grads, _) = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    train_op = optimizer.apply_gradients(zip(grads, tvars))\n    sess.run(tf.global_variables_initializer())\n    net.print_params()\n    net.print_layers()\n    tl.layers.print_all_variables()\n    print('nStart learning a language model by using PTB dataset')\n    for i in range(max_max_epoch):\n        new_lr_decay = lr_decay ** max(i - max_epoch, 0.0)\n        sess.run(tf.assign(lr, learning_rate * new_lr_decay))\n        print('Epoch: %d/%d Learning rate: %.3f' % (i + 1, max_max_epoch, sess.run(lr)))\n        epoch_size = (len(train_data) // batch_size - 1) // num_steps\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(train_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1.initial_state.c: state1[0], lstm1.initial_state.h: state1[1], lstm2.initial_state.c: state2[0], lstm2.initial_state.h: state2[1]}\n            feed_dict.update(net.all_drop)\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost, lstm1.final_state.c, lstm1.final_state.h, lstm2.final_state.c, lstm2.final_state.h, train_op], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n            if step % (epoch_size // 10) == 10:\n                print('%.3f perplexity: %.3f speed: %.0f wps' % (step * 1.0 / epoch_size, np.exp(costs / iters), iters * batch_size / (time.time() - start_time)))\n        train_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Train Perplexity: %.3f' % (i + 1, max_max_epoch, train_perplexity))\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1_val.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2_val.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(valid_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1_val.initial_state.c: state1[0], lstm1_val.initial_state.h: state1[1], lstm2_val.initial_state.c: state2[0], lstm2_val.initial_state.h: state2[1]}\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost_val, lstm1_val.final_state.c, lstm1_val.final_state.h, lstm2_val.final_state.c, lstm2_val.final_state.h, tf.no_op()], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n        valid_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Valid Perplexity: %.3f' % (i + 1, max_max_epoch, valid_perplexity))\n    print('Evaluation')\n    start_time = time.time()\n    costs = 0.0\n    iters = 0\n    state1 = tl.layers.initialize_rnn_state(lstm1_test.initial_state)\n    state2 = tl.layers.initialize_rnn_state(lstm2_test.initial_state)\n    for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(test_data, batch_size=1, num_steps=1)):\n        feed_dict = {input_data_test: x, targets_test: y, lstm1_test.initial_state.c: state1[0], lstm1_test.initial_state.h: state1[1], lstm2_test.initial_state.c: state2[0], lstm2_test.initial_state.h: state2[1]}\n        (_cost, state1_c, state1_h, state2_c, state2_h) = sess.run([cost_test, lstm1_test.final_state.c, lstm1_test.final_state.h, lstm2_test.final_state.c, lstm2_test.final_state.h], feed_dict=feed_dict)\n        state1 = (state1_c, state1_h)\n        state2 = (state2_c, state2_h)\n        costs += _cost\n        iters += 1\n    test_perplexity = np.exp(costs / iters)\n    print('Test Perplexity: %.3f took %.2fs' % (test_perplexity, time.time() - start_time))\n    print(\"More example: Text generation using Trump's speech data: https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_generate_text.py  -- def main_lstm_generate_text():\")",
        "mutated": [
            "def main(_):\n    if False:\n        i = 10\n    '\\n    The core of the model consists of an LSTM cell that processes one word at\\n    a time and computes probabilities of the possible continuations of the\\n    sentence. The memory state of the network is initialized with a vector\\n    of zeros and gets updated after reading each word. Also, for computational\\n    reasons, we will process data in mini-batches of size batch_size.\\n    '\n    if FLAGS.model == 'small':\n        init_scale = 0.1\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 20\n        hidden_size = 200\n        max_epoch = 4\n        max_max_epoch = 13\n        keep_prob = 1.0\n        lr_decay = 0.5\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'medium':\n        init_scale = 0.05\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 35\n        hidden_size = 650\n        max_epoch = 6\n        max_max_epoch = 39\n        keep_prob = 0.5\n        lr_decay = 0.8\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'large':\n        init_scale = 0.04\n        learning_rate = 1.0\n        max_grad_norm = 10\n        num_steps = 35\n        hidden_size = 1500\n        max_epoch = 14\n        max_max_epoch = 55\n        keep_prob = 0.35\n        lr_decay = 1 / 1.15\n        batch_size = 20\n        vocab_size = 10000\n    else:\n        raise ValueError('Invalid model: %s', FLAGS.model)\n    (train_data, valid_data, test_data, vocab_size) = tl.files.load_ptb_dataset()\n    print('len(train_data) {}'.format(len(train_data)))\n    print('len(valid_data) {}'.format(len(valid_data)))\n    print('len(test_data)  {}'.format(len(test_data)))\n    print('vocab_size      {}'.format(vocab_size))\n    sess = tf.InteractiveSession()\n    input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n    targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n    input_data_test = tf.placeholder(tf.int32, [1, 1])\n    targets_test = tf.placeholder(tf.int32, [1, 1])\n\n    def inference(x, is_training, num_steps, reuse=None):\n        \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n        print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n        init = tf.random_uniform_initializer(-init_scale, init_scale)\n        with tf.variable_scope('model', reuse=reuse):\n            net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n            lstm1 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n            lstm2 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n        return (net, lstm1, lstm2)\n    (net, lstm1, lstm2) = inference(input_data, is_training=True, num_steps=num_steps, reuse=None)\n    (net_val, lstm1_val, lstm2_val) = inference(input_data, is_training=False, num_steps=num_steps, reuse=True)\n    (net_test, lstm1_test, lstm2_test) = inference(input_data_test, is_training=False, num_steps=1, reuse=True)\n    sess.run(tf.global_variables_initializer())\n\n    def loss_fn(outputs, targets, batch_size):\n        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n        cost = tf.reduce_sum(loss) / batch_size\n        return cost\n    cost = loss_fn(net.outputs, targets, batch_size)\n    cost_val = loss_fn(net_val.outputs, targets, batch_size)\n    cost_test = loss_fn(net_test.outputs, targets_test, 1)\n    with tf.variable_scope('learning_rate'):\n        lr = tf.Variable(0.0, trainable=False)\n    tvars = tf.trainable_variables()\n    (grads, _) = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    train_op = optimizer.apply_gradients(zip(grads, tvars))\n    sess.run(tf.global_variables_initializer())\n    net.print_params()\n    net.print_layers()\n    tl.layers.print_all_variables()\n    print('nStart learning a language model by using PTB dataset')\n    for i in range(max_max_epoch):\n        new_lr_decay = lr_decay ** max(i - max_epoch, 0.0)\n        sess.run(tf.assign(lr, learning_rate * new_lr_decay))\n        print('Epoch: %d/%d Learning rate: %.3f' % (i + 1, max_max_epoch, sess.run(lr)))\n        epoch_size = (len(train_data) // batch_size - 1) // num_steps\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(train_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1.initial_state.c: state1[0], lstm1.initial_state.h: state1[1], lstm2.initial_state.c: state2[0], lstm2.initial_state.h: state2[1]}\n            feed_dict.update(net.all_drop)\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost, lstm1.final_state.c, lstm1.final_state.h, lstm2.final_state.c, lstm2.final_state.h, train_op], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n            if step % (epoch_size // 10) == 10:\n                print('%.3f perplexity: %.3f speed: %.0f wps' % (step * 1.0 / epoch_size, np.exp(costs / iters), iters * batch_size / (time.time() - start_time)))\n        train_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Train Perplexity: %.3f' % (i + 1, max_max_epoch, train_perplexity))\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1_val.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2_val.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(valid_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1_val.initial_state.c: state1[0], lstm1_val.initial_state.h: state1[1], lstm2_val.initial_state.c: state2[0], lstm2_val.initial_state.h: state2[1]}\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost_val, lstm1_val.final_state.c, lstm1_val.final_state.h, lstm2_val.final_state.c, lstm2_val.final_state.h, tf.no_op()], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n        valid_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Valid Perplexity: %.3f' % (i + 1, max_max_epoch, valid_perplexity))\n    print('Evaluation')\n    start_time = time.time()\n    costs = 0.0\n    iters = 0\n    state1 = tl.layers.initialize_rnn_state(lstm1_test.initial_state)\n    state2 = tl.layers.initialize_rnn_state(lstm2_test.initial_state)\n    for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(test_data, batch_size=1, num_steps=1)):\n        feed_dict = {input_data_test: x, targets_test: y, lstm1_test.initial_state.c: state1[0], lstm1_test.initial_state.h: state1[1], lstm2_test.initial_state.c: state2[0], lstm2_test.initial_state.h: state2[1]}\n        (_cost, state1_c, state1_h, state2_c, state2_h) = sess.run([cost_test, lstm1_test.final_state.c, lstm1_test.final_state.h, lstm2_test.final_state.c, lstm2_test.final_state.h], feed_dict=feed_dict)\n        state1 = (state1_c, state1_h)\n        state2 = (state2_c, state2_h)\n        costs += _cost\n        iters += 1\n    test_perplexity = np.exp(costs / iters)\n    print('Test Perplexity: %.3f took %.2fs' % (test_perplexity, time.time() - start_time))\n    print(\"More example: Text generation using Trump's speech data: https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_generate_text.py  -- def main_lstm_generate_text():\")",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    The core of the model consists of an LSTM cell that processes one word at\\n    a time and computes probabilities of the possible continuations of the\\n    sentence. The memory state of the network is initialized with a vector\\n    of zeros and gets updated after reading each word. Also, for computational\\n    reasons, we will process data in mini-batches of size batch_size.\\n    '\n    if FLAGS.model == 'small':\n        init_scale = 0.1\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 20\n        hidden_size = 200\n        max_epoch = 4\n        max_max_epoch = 13\n        keep_prob = 1.0\n        lr_decay = 0.5\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'medium':\n        init_scale = 0.05\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 35\n        hidden_size = 650\n        max_epoch = 6\n        max_max_epoch = 39\n        keep_prob = 0.5\n        lr_decay = 0.8\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'large':\n        init_scale = 0.04\n        learning_rate = 1.0\n        max_grad_norm = 10\n        num_steps = 35\n        hidden_size = 1500\n        max_epoch = 14\n        max_max_epoch = 55\n        keep_prob = 0.35\n        lr_decay = 1 / 1.15\n        batch_size = 20\n        vocab_size = 10000\n    else:\n        raise ValueError('Invalid model: %s', FLAGS.model)\n    (train_data, valid_data, test_data, vocab_size) = tl.files.load_ptb_dataset()\n    print('len(train_data) {}'.format(len(train_data)))\n    print('len(valid_data) {}'.format(len(valid_data)))\n    print('len(test_data)  {}'.format(len(test_data)))\n    print('vocab_size      {}'.format(vocab_size))\n    sess = tf.InteractiveSession()\n    input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n    targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n    input_data_test = tf.placeholder(tf.int32, [1, 1])\n    targets_test = tf.placeholder(tf.int32, [1, 1])\n\n    def inference(x, is_training, num_steps, reuse=None):\n        \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n        print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n        init = tf.random_uniform_initializer(-init_scale, init_scale)\n        with tf.variable_scope('model', reuse=reuse):\n            net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n            lstm1 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n            lstm2 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n        return (net, lstm1, lstm2)\n    (net, lstm1, lstm2) = inference(input_data, is_training=True, num_steps=num_steps, reuse=None)\n    (net_val, lstm1_val, lstm2_val) = inference(input_data, is_training=False, num_steps=num_steps, reuse=True)\n    (net_test, lstm1_test, lstm2_test) = inference(input_data_test, is_training=False, num_steps=1, reuse=True)\n    sess.run(tf.global_variables_initializer())\n\n    def loss_fn(outputs, targets, batch_size):\n        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n        cost = tf.reduce_sum(loss) / batch_size\n        return cost\n    cost = loss_fn(net.outputs, targets, batch_size)\n    cost_val = loss_fn(net_val.outputs, targets, batch_size)\n    cost_test = loss_fn(net_test.outputs, targets_test, 1)\n    with tf.variable_scope('learning_rate'):\n        lr = tf.Variable(0.0, trainable=False)\n    tvars = tf.trainable_variables()\n    (grads, _) = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    train_op = optimizer.apply_gradients(zip(grads, tvars))\n    sess.run(tf.global_variables_initializer())\n    net.print_params()\n    net.print_layers()\n    tl.layers.print_all_variables()\n    print('nStart learning a language model by using PTB dataset')\n    for i in range(max_max_epoch):\n        new_lr_decay = lr_decay ** max(i - max_epoch, 0.0)\n        sess.run(tf.assign(lr, learning_rate * new_lr_decay))\n        print('Epoch: %d/%d Learning rate: %.3f' % (i + 1, max_max_epoch, sess.run(lr)))\n        epoch_size = (len(train_data) // batch_size - 1) // num_steps\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(train_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1.initial_state.c: state1[0], lstm1.initial_state.h: state1[1], lstm2.initial_state.c: state2[0], lstm2.initial_state.h: state2[1]}\n            feed_dict.update(net.all_drop)\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost, lstm1.final_state.c, lstm1.final_state.h, lstm2.final_state.c, lstm2.final_state.h, train_op], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n            if step % (epoch_size // 10) == 10:\n                print('%.3f perplexity: %.3f speed: %.0f wps' % (step * 1.0 / epoch_size, np.exp(costs / iters), iters * batch_size / (time.time() - start_time)))\n        train_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Train Perplexity: %.3f' % (i + 1, max_max_epoch, train_perplexity))\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1_val.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2_val.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(valid_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1_val.initial_state.c: state1[0], lstm1_val.initial_state.h: state1[1], lstm2_val.initial_state.c: state2[0], lstm2_val.initial_state.h: state2[1]}\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost_val, lstm1_val.final_state.c, lstm1_val.final_state.h, lstm2_val.final_state.c, lstm2_val.final_state.h, tf.no_op()], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n        valid_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Valid Perplexity: %.3f' % (i + 1, max_max_epoch, valid_perplexity))\n    print('Evaluation')\n    start_time = time.time()\n    costs = 0.0\n    iters = 0\n    state1 = tl.layers.initialize_rnn_state(lstm1_test.initial_state)\n    state2 = tl.layers.initialize_rnn_state(lstm2_test.initial_state)\n    for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(test_data, batch_size=1, num_steps=1)):\n        feed_dict = {input_data_test: x, targets_test: y, lstm1_test.initial_state.c: state1[0], lstm1_test.initial_state.h: state1[1], lstm2_test.initial_state.c: state2[0], lstm2_test.initial_state.h: state2[1]}\n        (_cost, state1_c, state1_h, state2_c, state2_h) = sess.run([cost_test, lstm1_test.final_state.c, lstm1_test.final_state.h, lstm2_test.final_state.c, lstm2_test.final_state.h], feed_dict=feed_dict)\n        state1 = (state1_c, state1_h)\n        state2 = (state2_c, state2_h)\n        costs += _cost\n        iters += 1\n    test_perplexity = np.exp(costs / iters)\n    print('Test Perplexity: %.3f took %.2fs' % (test_perplexity, time.time() - start_time))\n    print(\"More example: Text generation using Trump's speech data: https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_generate_text.py  -- def main_lstm_generate_text():\")",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    The core of the model consists of an LSTM cell that processes one word at\\n    a time and computes probabilities of the possible continuations of the\\n    sentence. The memory state of the network is initialized with a vector\\n    of zeros and gets updated after reading each word. Also, for computational\\n    reasons, we will process data in mini-batches of size batch_size.\\n    '\n    if FLAGS.model == 'small':\n        init_scale = 0.1\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 20\n        hidden_size = 200\n        max_epoch = 4\n        max_max_epoch = 13\n        keep_prob = 1.0\n        lr_decay = 0.5\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'medium':\n        init_scale = 0.05\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 35\n        hidden_size = 650\n        max_epoch = 6\n        max_max_epoch = 39\n        keep_prob = 0.5\n        lr_decay = 0.8\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'large':\n        init_scale = 0.04\n        learning_rate = 1.0\n        max_grad_norm = 10\n        num_steps = 35\n        hidden_size = 1500\n        max_epoch = 14\n        max_max_epoch = 55\n        keep_prob = 0.35\n        lr_decay = 1 / 1.15\n        batch_size = 20\n        vocab_size = 10000\n    else:\n        raise ValueError('Invalid model: %s', FLAGS.model)\n    (train_data, valid_data, test_data, vocab_size) = tl.files.load_ptb_dataset()\n    print('len(train_data) {}'.format(len(train_data)))\n    print('len(valid_data) {}'.format(len(valid_data)))\n    print('len(test_data)  {}'.format(len(test_data)))\n    print('vocab_size      {}'.format(vocab_size))\n    sess = tf.InteractiveSession()\n    input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n    targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n    input_data_test = tf.placeholder(tf.int32, [1, 1])\n    targets_test = tf.placeholder(tf.int32, [1, 1])\n\n    def inference(x, is_training, num_steps, reuse=None):\n        \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n        print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n        init = tf.random_uniform_initializer(-init_scale, init_scale)\n        with tf.variable_scope('model', reuse=reuse):\n            net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n            lstm1 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n            lstm2 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n        return (net, lstm1, lstm2)\n    (net, lstm1, lstm2) = inference(input_data, is_training=True, num_steps=num_steps, reuse=None)\n    (net_val, lstm1_val, lstm2_val) = inference(input_data, is_training=False, num_steps=num_steps, reuse=True)\n    (net_test, lstm1_test, lstm2_test) = inference(input_data_test, is_training=False, num_steps=1, reuse=True)\n    sess.run(tf.global_variables_initializer())\n\n    def loss_fn(outputs, targets, batch_size):\n        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n        cost = tf.reduce_sum(loss) / batch_size\n        return cost\n    cost = loss_fn(net.outputs, targets, batch_size)\n    cost_val = loss_fn(net_val.outputs, targets, batch_size)\n    cost_test = loss_fn(net_test.outputs, targets_test, 1)\n    with tf.variable_scope('learning_rate'):\n        lr = tf.Variable(0.0, trainable=False)\n    tvars = tf.trainable_variables()\n    (grads, _) = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    train_op = optimizer.apply_gradients(zip(grads, tvars))\n    sess.run(tf.global_variables_initializer())\n    net.print_params()\n    net.print_layers()\n    tl.layers.print_all_variables()\n    print('nStart learning a language model by using PTB dataset')\n    for i in range(max_max_epoch):\n        new_lr_decay = lr_decay ** max(i - max_epoch, 0.0)\n        sess.run(tf.assign(lr, learning_rate * new_lr_decay))\n        print('Epoch: %d/%d Learning rate: %.3f' % (i + 1, max_max_epoch, sess.run(lr)))\n        epoch_size = (len(train_data) // batch_size - 1) // num_steps\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(train_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1.initial_state.c: state1[0], lstm1.initial_state.h: state1[1], lstm2.initial_state.c: state2[0], lstm2.initial_state.h: state2[1]}\n            feed_dict.update(net.all_drop)\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost, lstm1.final_state.c, lstm1.final_state.h, lstm2.final_state.c, lstm2.final_state.h, train_op], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n            if step % (epoch_size // 10) == 10:\n                print('%.3f perplexity: %.3f speed: %.0f wps' % (step * 1.0 / epoch_size, np.exp(costs / iters), iters * batch_size / (time.time() - start_time)))\n        train_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Train Perplexity: %.3f' % (i + 1, max_max_epoch, train_perplexity))\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1_val.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2_val.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(valid_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1_val.initial_state.c: state1[0], lstm1_val.initial_state.h: state1[1], lstm2_val.initial_state.c: state2[0], lstm2_val.initial_state.h: state2[1]}\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost_val, lstm1_val.final_state.c, lstm1_val.final_state.h, lstm2_val.final_state.c, lstm2_val.final_state.h, tf.no_op()], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n        valid_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Valid Perplexity: %.3f' % (i + 1, max_max_epoch, valid_perplexity))\n    print('Evaluation')\n    start_time = time.time()\n    costs = 0.0\n    iters = 0\n    state1 = tl.layers.initialize_rnn_state(lstm1_test.initial_state)\n    state2 = tl.layers.initialize_rnn_state(lstm2_test.initial_state)\n    for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(test_data, batch_size=1, num_steps=1)):\n        feed_dict = {input_data_test: x, targets_test: y, lstm1_test.initial_state.c: state1[0], lstm1_test.initial_state.h: state1[1], lstm2_test.initial_state.c: state2[0], lstm2_test.initial_state.h: state2[1]}\n        (_cost, state1_c, state1_h, state2_c, state2_h) = sess.run([cost_test, lstm1_test.final_state.c, lstm1_test.final_state.h, lstm2_test.final_state.c, lstm2_test.final_state.h], feed_dict=feed_dict)\n        state1 = (state1_c, state1_h)\n        state2 = (state2_c, state2_h)\n        costs += _cost\n        iters += 1\n    test_perplexity = np.exp(costs / iters)\n    print('Test Perplexity: %.3f took %.2fs' % (test_perplexity, time.time() - start_time))\n    print(\"More example: Text generation using Trump's speech data: https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_generate_text.py  -- def main_lstm_generate_text():\")",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    The core of the model consists of an LSTM cell that processes one word at\\n    a time and computes probabilities of the possible continuations of the\\n    sentence. The memory state of the network is initialized with a vector\\n    of zeros and gets updated after reading each word. Also, for computational\\n    reasons, we will process data in mini-batches of size batch_size.\\n    '\n    if FLAGS.model == 'small':\n        init_scale = 0.1\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 20\n        hidden_size = 200\n        max_epoch = 4\n        max_max_epoch = 13\n        keep_prob = 1.0\n        lr_decay = 0.5\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'medium':\n        init_scale = 0.05\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 35\n        hidden_size = 650\n        max_epoch = 6\n        max_max_epoch = 39\n        keep_prob = 0.5\n        lr_decay = 0.8\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'large':\n        init_scale = 0.04\n        learning_rate = 1.0\n        max_grad_norm = 10\n        num_steps = 35\n        hidden_size = 1500\n        max_epoch = 14\n        max_max_epoch = 55\n        keep_prob = 0.35\n        lr_decay = 1 / 1.15\n        batch_size = 20\n        vocab_size = 10000\n    else:\n        raise ValueError('Invalid model: %s', FLAGS.model)\n    (train_data, valid_data, test_data, vocab_size) = tl.files.load_ptb_dataset()\n    print('len(train_data) {}'.format(len(train_data)))\n    print('len(valid_data) {}'.format(len(valid_data)))\n    print('len(test_data)  {}'.format(len(test_data)))\n    print('vocab_size      {}'.format(vocab_size))\n    sess = tf.InteractiveSession()\n    input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n    targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n    input_data_test = tf.placeholder(tf.int32, [1, 1])\n    targets_test = tf.placeholder(tf.int32, [1, 1])\n\n    def inference(x, is_training, num_steps, reuse=None):\n        \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n        print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n        init = tf.random_uniform_initializer(-init_scale, init_scale)\n        with tf.variable_scope('model', reuse=reuse):\n            net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n            lstm1 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n            lstm2 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n        return (net, lstm1, lstm2)\n    (net, lstm1, lstm2) = inference(input_data, is_training=True, num_steps=num_steps, reuse=None)\n    (net_val, lstm1_val, lstm2_val) = inference(input_data, is_training=False, num_steps=num_steps, reuse=True)\n    (net_test, lstm1_test, lstm2_test) = inference(input_data_test, is_training=False, num_steps=1, reuse=True)\n    sess.run(tf.global_variables_initializer())\n\n    def loss_fn(outputs, targets, batch_size):\n        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n        cost = tf.reduce_sum(loss) / batch_size\n        return cost\n    cost = loss_fn(net.outputs, targets, batch_size)\n    cost_val = loss_fn(net_val.outputs, targets, batch_size)\n    cost_test = loss_fn(net_test.outputs, targets_test, 1)\n    with tf.variable_scope('learning_rate'):\n        lr = tf.Variable(0.0, trainable=False)\n    tvars = tf.trainable_variables()\n    (grads, _) = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    train_op = optimizer.apply_gradients(zip(grads, tvars))\n    sess.run(tf.global_variables_initializer())\n    net.print_params()\n    net.print_layers()\n    tl.layers.print_all_variables()\n    print('nStart learning a language model by using PTB dataset')\n    for i in range(max_max_epoch):\n        new_lr_decay = lr_decay ** max(i - max_epoch, 0.0)\n        sess.run(tf.assign(lr, learning_rate * new_lr_decay))\n        print('Epoch: %d/%d Learning rate: %.3f' % (i + 1, max_max_epoch, sess.run(lr)))\n        epoch_size = (len(train_data) // batch_size - 1) // num_steps\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(train_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1.initial_state.c: state1[0], lstm1.initial_state.h: state1[1], lstm2.initial_state.c: state2[0], lstm2.initial_state.h: state2[1]}\n            feed_dict.update(net.all_drop)\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost, lstm1.final_state.c, lstm1.final_state.h, lstm2.final_state.c, lstm2.final_state.h, train_op], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n            if step % (epoch_size // 10) == 10:\n                print('%.3f perplexity: %.3f speed: %.0f wps' % (step * 1.0 / epoch_size, np.exp(costs / iters), iters * batch_size / (time.time() - start_time)))\n        train_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Train Perplexity: %.3f' % (i + 1, max_max_epoch, train_perplexity))\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1_val.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2_val.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(valid_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1_val.initial_state.c: state1[0], lstm1_val.initial_state.h: state1[1], lstm2_val.initial_state.c: state2[0], lstm2_val.initial_state.h: state2[1]}\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost_val, lstm1_val.final_state.c, lstm1_val.final_state.h, lstm2_val.final_state.c, lstm2_val.final_state.h, tf.no_op()], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n        valid_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Valid Perplexity: %.3f' % (i + 1, max_max_epoch, valid_perplexity))\n    print('Evaluation')\n    start_time = time.time()\n    costs = 0.0\n    iters = 0\n    state1 = tl.layers.initialize_rnn_state(lstm1_test.initial_state)\n    state2 = tl.layers.initialize_rnn_state(lstm2_test.initial_state)\n    for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(test_data, batch_size=1, num_steps=1)):\n        feed_dict = {input_data_test: x, targets_test: y, lstm1_test.initial_state.c: state1[0], lstm1_test.initial_state.h: state1[1], lstm2_test.initial_state.c: state2[0], lstm2_test.initial_state.h: state2[1]}\n        (_cost, state1_c, state1_h, state2_c, state2_h) = sess.run([cost_test, lstm1_test.final_state.c, lstm1_test.final_state.h, lstm2_test.final_state.c, lstm2_test.final_state.h], feed_dict=feed_dict)\n        state1 = (state1_c, state1_h)\n        state2 = (state2_c, state2_h)\n        costs += _cost\n        iters += 1\n    test_perplexity = np.exp(costs / iters)\n    print('Test Perplexity: %.3f took %.2fs' % (test_perplexity, time.time() - start_time))\n    print(\"More example: Text generation using Trump's speech data: https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_generate_text.py  -- def main_lstm_generate_text():\")",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    The core of the model consists of an LSTM cell that processes one word at\\n    a time and computes probabilities of the possible continuations of the\\n    sentence. The memory state of the network is initialized with a vector\\n    of zeros and gets updated after reading each word. Also, for computational\\n    reasons, we will process data in mini-batches of size batch_size.\\n    '\n    if FLAGS.model == 'small':\n        init_scale = 0.1\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 20\n        hidden_size = 200\n        max_epoch = 4\n        max_max_epoch = 13\n        keep_prob = 1.0\n        lr_decay = 0.5\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'medium':\n        init_scale = 0.05\n        learning_rate = 1.0\n        max_grad_norm = 5\n        num_steps = 35\n        hidden_size = 650\n        max_epoch = 6\n        max_max_epoch = 39\n        keep_prob = 0.5\n        lr_decay = 0.8\n        batch_size = 20\n        vocab_size = 10000\n    elif FLAGS.model == 'large':\n        init_scale = 0.04\n        learning_rate = 1.0\n        max_grad_norm = 10\n        num_steps = 35\n        hidden_size = 1500\n        max_epoch = 14\n        max_max_epoch = 55\n        keep_prob = 0.35\n        lr_decay = 1 / 1.15\n        batch_size = 20\n        vocab_size = 10000\n    else:\n        raise ValueError('Invalid model: %s', FLAGS.model)\n    (train_data, valid_data, test_data, vocab_size) = tl.files.load_ptb_dataset()\n    print('len(train_data) {}'.format(len(train_data)))\n    print('len(valid_data) {}'.format(len(valid_data)))\n    print('len(test_data)  {}'.format(len(test_data)))\n    print('vocab_size      {}'.format(vocab_size))\n    sess = tf.InteractiveSession()\n    input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n    targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n    input_data_test = tf.placeholder(tf.int32, [1, 1])\n    targets_test = tf.placeholder(tf.int32, [1, 1])\n\n    def inference(x, is_training, num_steps, reuse=None):\n        \"\"\"If reuse is True, the inferences use the existing parameters,\n        then different inferences share the same parameters.\n\n        Note :\n        - For DynamicRNNLayer, you can set dropout and the number of RNN layer internally.\n        \"\"\"\n        print('\\nnum_steps : %d, is_training : %s, reuse : %s' % (num_steps, is_training, reuse))\n        init = tf.random_uniform_initializer(-init_scale, init_scale)\n        with tf.variable_scope('model', reuse=reuse):\n            net = tl.layers.EmbeddingInputlayer(x, vocab_size, hidden_size, init, name='embedding')\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop1')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, name='basic_lstm1')\n            lstm1 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop2')\n            net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, cell_init_args={'forget_bias': 0.0, 'state_is_tuple': True}, n_hidden=hidden_size, initializer=init, n_steps=num_steps, return_last=False, return_seq_2d=True, name='basic_lstm2')\n            lstm2 = net\n            net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\n        return (net, lstm1, lstm2)\n    (net, lstm1, lstm2) = inference(input_data, is_training=True, num_steps=num_steps, reuse=None)\n    (net_val, lstm1_val, lstm2_val) = inference(input_data, is_training=False, num_steps=num_steps, reuse=True)\n    (net_test, lstm1_test, lstm2_test) = inference(input_data_test, is_training=False, num_steps=1, reuse=True)\n    sess.run(tf.global_variables_initializer())\n\n    def loss_fn(outputs, targets, batch_size):\n        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n        cost = tf.reduce_sum(loss) / batch_size\n        return cost\n    cost = loss_fn(net.outputs, targets, batch_size)\n    cost_val = loss_fn(net_val.outputs, targets, batch_size)\n    cost_test = loss_fn(net_test.outputs, targets_test, 1)\n    with tf.variable_scope('learning_rate'):\n        lr = tf.Variable(0.0, trainable=False)\n    tvars = tf.trainable_variables()\n    (grads, _) = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    train_op = optimizer.apply_gradients(zip(grads, tvars))\n    sess.run(tf.global_variables_initializer())\n    net.print_params()\n    net.print_layers()\n    tl.layers.print_all_variables()\n    print('nStart learning a language model by using PTB dataset')\n    for i in range(max_max_epoch):\n        new_lr_decay = lr_decay ** max(i - max_epoch, 0.0)\n        sess.run(tf.assign(lr, learning_rate * new_lr_decay))\n        print('Epoch: %d/%d Learning rate: %.3f' % (i + 1, max_max_epoch, sess.run(lr)))\n        epoch_size = (len(train_data) // batch_size - 1) // num_steps\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(train_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1.initial_state.c: state1[0], lstm1.initial_state.h: state1[1], lstm2.initial_state.c: state2[0], lstm2.initial_state.h: state2[1]}\n            feed_dict.update(net.all_drop)\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost, lstm1.final_state.c, lstm1.final_state.h, lstm2.final_state.c, lstm2.final_state.h, train_op], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n            if step % (epoch_size // 10) == 10:\n                print('%.3f perplexity: %.3f speed: %.0f wps' % (step * 1.0 / epoch_size, np.exp(costs / iters), iters * batch_size / (time.time() - start_time)))\n        train_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Train Perplexity: %.3f' % (i + 1, max_max_epoch, train_perplexity))\n        start_time = time.time()\n        costs = 0.0\n        iters = 0\n        state1 = tl.layers.initialize_rnn_state(lstm1_val.initial_state)\n        state2 = tl.layers.initialize_rnn_state(lstm2_val.initial_state)\n        for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(valid_data, batch_size, num_steps)):\n            feed_dict = {input_data: x, targets: y, lstm1_val.initial_state.c: state1[0], lstm1_val.initial_state.h: state1[1], lstm2_val.initial_state.c: state2[0], lstm2_val.initial_state.h: state2[1]}\n            (_cost, state1_c, state1_h, state2_c, state2_h, _) = sess.run([cost_val, lstm1_val.final_state.c, lstm1_val.final_state.h, lstm2_val.final_state.c, lstm2_val.final_state.h, tf.no_op()], feed_dict=feed_dict)\n            state1 = (state1_c, state1_h)\n            state2 = (state2_c, state2_h)\n            costs += _cost\n            iters += num_steps\n        valid_perplexity = np.exp(costs / iters)\n        print('Epoch: %d/%d Valid Perplexity: %.3f' % (i + 1, max_max_epoch, valid_perplexity))\n    print('Evaluation')\n    start_time = time.time()\n    costs = 0.0\n    iters = 0\n    state1 = tl.layers.initialize_rnn_state(lstm1_test.initial_state)\n    state2 = tl.layers.initialize_rnn_state(lstm2_test.initial_state)\n    for (step, (x, y)) in enumerate(tl.iterate.ptb_iterator(test_data, batch_size=1, num_steps=1)):\n        feed_dict = {input_data_test: x, targets_test: y, lstm1_test.initial_state.c: state1[0], lstm1_test.initial_state.h: state1[1], lstm2_test.initial_state.c: state2[0], lstm2_test.initial_state.h: state2[1]}\n        (_cost, state1_c, state1_h, state2_c, state2_h) = sess.run([cost_test, lstm1_test.final_state.c, lstm1_test.final_state.h, lstm2_test.final_state.c, lstm2_test.final_state.h], feed_dict=feed_dict)\n        state1 = (state1_c, state1_h)\n        state2 = (state2_c, state2_h)\n        costs += _cost\n        iters += 1\n    test_perplexity = np.exp(costs / iters)\n    print('Test Perplexity: %.3f took %.2fs' % (test_perplexity, time.time() - start_time))\n    print(\"More example: Text generation using Trump's speech data: https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_generate_text.py  -- def main_lstm_generate_text():\")"
        ]
    }
]