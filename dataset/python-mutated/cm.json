[
    {
        "func_name": "_inputs",
        "original": "def _inputs(problem):\n    with tf.name_scope('inputs'):\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        if problem.input_type == 'vision':\n            inputs.append(('imgs', tf.float32, (problem.batch_size, None, len(problem.aux_delta_thetas) + 1, problem.img_height, problem.img_width, problem.img_channels)))\n        elif problem.input_type == 'analytical_counts':\n            for i in range(len(problem.map_crop_sizes)):\n                inputs.append(('analytical_counts_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        if problem.outputs.readout_maps:\n            for i in range(len(problem.readout_maps_crop_sizes)):\n                inputs.append(('readout_maps_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.readout_maps_crop_sizes[i], problem.readout_maps_crop_sizes[i], problem.readout_maps_channels)))\n        for i in range(len(problem.map_crop_sizes)):\n            inputs.append(('ego_goal_imgs_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.goal_channels)))\n            for s in ['sum_num', 'sum_denom', 'max_denom']:\n                inputs.append(('running_' + s + '_{:d}'.format(i), tf.float32, (problem.batch_size, 1, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
        "mutated": [
            "def _inputs(problem):\n    if False:\n        i = 10\n    with tf.name_scope('inputs'):\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        if problem.input_type == 'vision':\n            inputs.append(('imgs', tf.float32, (problem.batch_size, None, len(problem.aux_delta_thetas) + 1, problem.img_height, problem.img_width, problem.img_channels)))\n        elif problem.input_type == 'analytical_counts':\n            for i in range(len(problem.map_crop_sizes)):\n                inputs.append(('analytical_counts_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        if problem.outputs.readout_maps:\n            for i in range(len(problem.readout_maps_crop_sizes)):\n                inputs.append(('readout_maps_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.readout_maps_crop_sizes[i], problem.readout_maps_crop_sizes[i], problem.readout_maps_channels)))\n        for i in range(len(problem.map_crop_sizes)):\n            inputs.append(('ego_goal_imgs_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.goal_channels)))\n            for s in ['sum_num', 'sum_denom', 'max_denom']:\n                inputs.append(('running_' + s + '_{:d}'.format(i), tf.float32, (problem.batch_size, 1, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.name_scope('inputs'):\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        if problem.input_type == 'vision':\n            inputs.append(('imgs', tf.float32, (problem.batch_size, None, len(problem.aux_delta_thetas) + 1, problem.img_height, problem.img_width, problem.img_channels)))\n        elif problem.input_type == 'analytical_counts':\n            for i in range(len(problem.map_crop_sizes)):\n                inputs.append(('analytical_counts_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        if problem.outputs.readout_maps:\n            for i in range(len(problem.readout_maps_crop_sizes)):\n                inputs.append(('readout_maps_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.readout_maps_crop_sizes[i], problem.readout_maps_crop_sizes[i], problem.readout_maps_channels)))\n        for i in range(len(problem.map_crop_sizes)):\n            inputs.append(('ego_goal_imgs_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.goal_channels)))\n            for s in ['sum_num', 'sum_denom', 'max_denom']:\n                inputs.append(('running_' + s + '_{:d}'.format(i), tf.float32, (problem.batch_size, 1, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.name_scope('inputs'):\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        if problem.input_type == 'vision':\n            inputs.append(('imgs', tf.float32, (problem.batch_size, None, len(problem.aux_delta_thetas) + 1, problem.img_height, problem.img_width, problem.img_channels)))\n        elif problem.input_type == 'analytical_counts':\n            for i in range(len(problem.map_crop_sizes)):\n                inputs.append(('analytical_counts_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        if problem.outputs.readout_maps:\n            for i in range(len(problem.readout_maps_crop_sizes)):\n                inputs.append(('readout_maps_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.readout_maps_crop_sizes[i], problem.readout_maps_crop_sizes[i], problem.readout_maps_channels)))\n        for i in range(len(problem.map_crop_sizes)):\n            inputs.append(('ego_goal_imgs_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.goal_channels)))\n            for s in ['sum_num', 'sum_denom', 'max_denom']:\n                inputs.append(('running_' + s + '_{:d}'.format(i), tf.float32, (problem.batch_size, 1, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.name_scope('inputs'):\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        if problem.input_type == 'vision':\n            inputs.append(('imgs', tf.float32, (problem.batch_size, None, len(problem.aux_delta_thetas) + 1, problem.img_height, problem.img_width, problem.img_channels)))\n        elif problem.input_type == 'analytical_counts':\n            for i in range(len(problem.map_crop_sizes)):\n                inputs.append(('analytical_counts_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        if problem.outputs.readout_maps:\n            for i in range(len(problem.readout_maps_crop_sizes)):\n                inputs.append(('readout_maps_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.readout_maps_crop_sizes[i], problem.readout_maps_crop_sizes[i], problem.readout_maps_channels)))\n        for i in range(len(problem.map_crop_sizes)):\n            inputs.append(('ego_goal_imgs_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.goal_channels)))\n            for s in ['sum_num', 'sum_denom', 'max_denom']:\n                inputs.append(('running_' + s + '_{:d}'.format(i), tf.float32, (problem.batch_size, 1, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)",
            "def _inputs(problem):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.name_scope('inputs'):\n        inputs = []\n        inputs.append(('orig_maps', tf.float32, (problem.batch_size, 1, None, None, 1)))\n        inputs.append(('goal_loc', tf.float32, (problem.batch_size, problem.num_goals, 2)))\n        (common_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        if problem.input_type == 'vision':\n            inputs.append(('imgs', tf.float32, (problem.batch_size, None, len(problem.aux_delta_thetas) + 1, problem.img_height, problem.img_width, problem.img_channels)))\n        elif problem.input_type == 'analytical_counts':\n            for i in range(len(problem.map_crop_sizes)):\n                inputs.append(('analytical_counts_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        if problem.outputs.readout_maps:\n            for i in range(len(problem.readout_maps_crop_sizes)):\n                inputs.append(('readout_maps_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.readout_maps_crop_sizes[i], problem.readout_maps_crop_sizes[i], problem.readout_maps_channels)))\n        for i in range(len(problem.map_crop_sizes)):\n            inputs.append(('ego_goal_imgs_{:d}'.format(i), tf.float32, (problem.batch_size, None, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.goal_channels)))\n            for s in ['sum_num', 'sum_denom', 'max_denom']:\n                inputs.append(('running_' + s + '_{:d}'.format(i), tf.float32, (problem.batch_size, 1, problem.map_crop_sizes[i], problem.map_crop_sizes[i], problem.map_channels)))\n        inputs.append(('incremental_locs', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('incremental_thetas', tf.float32, (problem.batch_size, None, 1)))\n        inputs.append(('step_number', tf.int32, (1, None, 1)))\n        inputs.append(('node_ids', tf.int32, (problem.batch_size, None, problem.node_ids_dim)))\n        inputs.append(('perturbs', tf.float32, (problem.batch_size, None, problem.perturbs_dim)))\n        inputs.append(('loc_on_map', tf.float32, (problem.batch_size, None, 2)))\n        inputs.append(('gt_dist_to_goal', tf.float32, (problem.batch_size, None, 1)))\n        (step_input_data, _) = tf_utils.setup_inputs(inputs)\n        inputs = []\n        inputs.append(('action', tf.int32, (problem.batch_size, None, problem.num_actions)))\n        (train_data, _) = tf_utils.setup_inputs(inputs)\n        train_data.update(step_input_data)\n        train_data.update(common_input_data)\n    return (common_input_data, step_input_data, train_data)"
        ]
    },
    {
        "func_name": "readout_general",
        "original": "def readout_general(multi_scale_belief, num_neurons, strides, layers_per_block, kernel_size, batch_norm_is_training_op, wt_decay):\n    multi_scale_belief = tf.stop_gradient(multi_scale_belief)\n    with tf.variable_scope('readout_maps_deconv'):\n        (x, outs) = deconv(multi_scale_belief, batch_norm_is_training_op, wt_decay=wt_decay, neurons=num_neurons, strides=strides, layers_per_block=layers_per_block, kernel_size=kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='readout_maps_deconv')\n        probs = tf.sigmoid(x)\n    return (x, probs)",
        "mutated": [
            "def readout_general(multi_scale_belief, num_neurons, strides, layers_per_block, kernel_size, batch_norm_is_training_op, wt_decay):\n    if False:\n        i = 10\n    multi_scale_belief = tf.stop_gradient(multi_scale_belief)\n    with tf.variable_scope('readout_maps_deconv'):\n        (x, outs) = deconv(multi_scale_belief, batch_norm_is_training_op, wt_decay=wt_decay, neurons=num_neurons, strides=strides, layers_per_block=layers_per_block, kernel_size=kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='readout_maps_deconv')\n        probs = tf.sigmoid(x)\n    return (x, probs)",
            "def readout_general(multi_scale_belief, num_neurons, strides, layers_per_block, kernel_size, batch_norm_is_training_op, wt_decay):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    multi_scale_belief = tf.stop_gradient(multi_scale_belief)\n    with tf.variable_scope('readout_maps_deconv'):\n        (x, outs) = deconv(multi_scale_belief, batch_norm_is_training_op, wt_decay=wt_decay, neurons=num_neurons, strides=strides, layers_per_block=layers_per_block, kernel_size=kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='readout_maps_deconv')\n        probs = tf.sigmoid(x)\n    return (x, probs)",
            "def readout_general(multi_scale_belief, num_neurons, strides, layers_per_block, kernel_size, batch_norm_is_training_op, wt_decay):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    multi_scale_belief = tf.stop_gradient(multi_scale_belief)\n    with tf.variable_scope('readout_maps_deconv'):\n        (x, outs) = deconv(multi_scale_belief, batch_norm_is_training_op, wt_decay=wt_decay, neurons=num_neurons, strides=strides, layers_per_block=layers_per_block, kernel_size=kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='readout_maps_deconv')\n        probs = tf.sigmoid(x)\n    return (x, probs)",
            "def readout_general(multi_scale_belief, num_neurons, strides, layers_per_block, kernel_size, batch_norm_is_training_op, wt_decay):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    multi_scale_belief = tf.stop_gradient(multi_scale_belief)\n    with tf.variable_scope('readout_maps_deconv'):\n        (x, outs) = deconv(multi_scale_belief, batch_norm_is_training_op, wt_decay=wt_decay, neurons=num_neurons, strides=strides, layers_per_block=layers_per_block, kernel_size=kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='readout_maps_deconv')\n        probs = tf.sigmoid(x)\n    return (x, probs)",
            "def readout_general(multi_scale_belief, num_neurons, strides, layers_per_block, kernel_size, batch_norm_is_training_op, wt_decay):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    multi_scale_belief = tf.stop_gradient(multi_scale_belief)\n    with tf.variable_scope('readout_maps_deconv'):\n        (x, outs) = deconv(multi_scale_belief, batch_norm_is_training_op, wt_decay=wt_decay, neurons=num_neurons, strides=strides, layers_per_block=layers_per_block, kernel_size=kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='readout_maps_deconv')\n        probs = tf.sigmoid(x)\n    return (x, probs)"
        ]
    },
    {
        "func_name": "running_combine",
        "original": "def running_combine(fss_logits, confs_probs, incremental_locs, incremental_thetas, previous_sum_num, previous_sum_denom, previous_max_denom, map_size, num_steps):\n    with tf.name_scope('combine_{:d}'.format(num_steps)):\n        running_sum_nums_ = []\n        running_sum_denoms_ = []\n        running_max_denoms_ = []\n        fss_logits_ = tf.unstack(fss_logits, axis=1, num=num_steps)\n        confs_probs_ = tf.unstack(confs_probs, axis=1, num=num_steps)\n        incremental_locs_ = tf.unstack(incremental_locs, axis=1, num=num_steps)\n        incremental_thetas_ = tf.unstack(incremental_thetas, axis=1, num=num_steps)\n        running_sum_num = tf.unstack(previous_sum_num, axis=1, num=1)[0]\n        running_sum_denom = tf.unstack(previous_sum_denom, axis=1, num=1)[0]\n        running_max_denom = tf.unstack(previous_max_denom, axis=1, num=1)[0]\n        for i in range(num_steps):\n            (running_sum_num, running_sum_denom, running_max_denom) = rotate_preds(incremental_locs_[i], incremental_thetas_[i], map_size, [running_sum_num, running_sum_denom, running_max_denom], output_valid_mask=False)[0]\n            running_sum_num = running_sum_num + fss_logits_[i] * confs_probs_[i]\n            running_sum_denom = running_sum_denom + confs_probs_[i]\n            running_max_denom = tf.maximum(running_max_denom, confs_probs_[i])\n            running_sum_nums_.append(running_sum_num)\n            running_sum_denoms_.append(running_sum_denom)\n            running_max_denoms_.append(running_max_denom)\n        running_sum_nums = tf.stack(running_sum_nums_, axis=1)\n        running_sum_denoms = tf.stack(running_sum_denoms_, axis=1)\n        running_max_denoms = tf.stack(running_max_denoms_, axis=1)\n        return (running_sum_nums, running_sum_denoms, running_max_denoms)",
        "mutated": [
            "def running_combine(fss_logits, confs_probs, incremental_locs, incremental_thetas, previous_sum_num, previous_sum_denom, previous_max_denom, map_size, num_steps):\n    if False:\n        i = 10\n    with tf.name_scope('combine_{:d}'.format(num_steps)):\n        running_sum_nums_ = []\n        running_sum_denoms_ = []\n        running_max_denoms_ = []\n        fss_logits_ = tf.unstack(fss_logits, axis=1, num=num_steps)\n        confs_probs_ = tf.unstack(confs_probs, axis=1, num=num_steps)\n        incremental_locs_ = tf.unstack(incremental_locs, axis=1, num=num_steps)\n        incremental_thetas_ = tf.unstack(incremental_thetas, axis=1, num=num_steps)\n        running_sum_num = tf.unstack(previous_sum_num, axis=1, num=1)[0]\n        running_sum_denom = tf.unstack(previous_sum_denom, axis=1, num=1)[0]\n        running_max_denom = tf.unstack(previous_max_denom, axis=1, num=1)[0]\n        for i in range(num_steps):\n            (running_sum_num, running_sum_denom, running_max_denom) = rotate_preds(incremental_locs_[i], incremental_thetas_[i], map_size, [running_sum_num, running_sum_denom, running_max_denom], output_valid_mask=False)[0]\n            running_sum_num = running_sum_num + fss_logits_[i] * confs_probs_[i]\n            running_sum_denom = running_sum_denom + confs_probs_[i]\n            running_max_denom = tf.maximum(running_max_denom, confs_probs_[i])\n            running_sum_nums_.append(running_sum_num)\n            running_sum_denoms_.append(running_sum_denom)\n            running_max_denoms_.append(running_max_denom)\n        running_sum_nums = tf.stack(running_sum_nums_, axis=1)\n        running_sum_denoms = tf.stack(running_sum_denoms_, axis=1)\n        running_max_denoms = tf.stack(running_max_denoms_, axis=1)\n        return (running_sum_nums, running_sum_denoms, running_max_denoms)",
            "def running_combine(fss_logits, confs_probs, incremental_locs, incremental_thetas, previous_sum_num, previous_sum_denom, previous_max_denom, map_size, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with tf.name_scope('combine_{:d}'.format(num_steps)):\n        running_sum_nums_ = []\n        running_sum_denoms_ = []\n        running_max_denoms_ = []\n        fss_logits_ = tf.unstack(fss_logits, axis=1, num=num_steps)\n        confs_probs_ = tf.unstack(confs_probs, axis=1, num=num_steps)\n        incremental_locs_ = tf.unstack(incremental_locs, axis=1, num=num_steps)\n        incremental_thetas_ = tf.unstack(incremental_thetas, axis=1, num=num_steps)\n        running_sum_num = tf.unstack(previous_sum_num, axis=1, num=1)[0]\n        running_sum_denom = tf.unstack(previous_sum_denom, axis=1, num=1)[0]\n        running_max_denom = tf.unstack(previous_max_denom, axis=1, num=1)[0]\n        for i in range(num_steps):\n            (running_sum_num, running_sum_denom, running_max_denom) = rotate_preds(incremental_locs_[i], incremental_thetas_[i], map_size, [running_sum_num, running_sum_denom, running_max_denom], output_valid_mask=False)[0]\n            running_sum_num = running_sum_num + fss_logits_[i] * confs_probs_[i]\n            running_sum_denom = running_sum_denom + confs_probs_[i]\n            running_max_denom = tf.maximum(running_max_denom, confs_probs_[i])\n            running_sum_nums_.append(running_sum_num)\n            running_sum_denoms_.append(running_sum_denom)\n            running_max_denoms_.append(running_max_denom)\n        running_sum_nums = tf.stack(running_sum_nums_, axis=1)\n        running_sum_denoms = tf.stack(running_sum_denoms_, axis=1)\n        running_max_denoms = tf.stack(running_max_denoms_, axis=1)\n        return (running_sum_nums, running_sum_denoms, running_max_denoms)",
            "def running_combine(fss_logits, confs_probs, incremental_locs, incremental_thetas, previous_sum_num, previous_sum_denom, previous_max_denom, map_size, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with tf.name_scope('combine_{:d}'.format(num_steps)):\n        running_sum_nums_ = []\n        running_sum_denoms_ = []\n        running_max_denoms_ = []\n        fss_logits_ = tf.unstack(fss_logits, axis=1, num=num_steps)\n        confs_probs_ = tf.unstack(confs_probs, axis=1, num=num_steps)\n        incremental_locs_ = tf.unstack(incremental_locs, axis=1, num=num_steps)\n        incremental_thetas_ = tf.unstack(incremental_thetas, axis=1, num=num_steps)\n        running_sum_num = tf.unstack(previous_sum_num, axis=1, num=1)[0]\n        running_sum_denom = tf.unstack(previous_sum_denom, axis=1, num=1)[0]\n        running_max_denom = tf.unstack(previous_max_denom, axis=1, num=1)[0]\n        for i in range(num_steps):\n            (running_sum_num, running_sum_denom, running_max_denom) = rotate_preds(incremental_locs_[i], incremental_thetas_[i], map_size, [running_sum_num, running_sum_denom, running_max_denom], output_valid_mask=False)[0]\n            running_sum_num = running_sum_num + fss_logits_[i] * confs_probs_[i]\n            running_sum_denom = running_sum_denom + confs_probs_[i]\n            running_max_denom = tf.maximum(running_max_denom, confs_probs_[i])\n            running_sum_nums_.append(running_sum_num)\n            running_sum_denoms_.append(running_sum_denom)\n            running_max_denoms_.append(running_max_denom)\n        running_sum_nums = tf.stack(running_sum_nums_, axis=1)\n        running_sum_denoms = tf.stack(running_sum_denoms_, axis=1)\n        running_max_denoms = tf.stack(running_max_denoms_, axis=1)\n        return (running_sum_nums, running_sum_denoms, running_max_denoms)",
            "def running_combine(fss_logits, confs_probs, incremental_locs, incremental_thetas, previous_sum_num, previous_sum_denom, previous_max_denom, map_size, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with tf.name_scope('combine_{:d}'.format(num_steps)):\n        running_sum_nums_ = []\n        running_sum_denoms_ = []\n        running_max_denoms_ = []\n        fss_logits_ = tf.unstack(fss_logits, axis=1, num=num_steps)\n        confs_probs_ = tf.unstack(confs_probs, axis=1, num=num_steps)\n        incremental_locs_ = tf.unstack(incremental_locs, axis=1, num=num_steps)\n        incremental_thetas_ = tf.unstack(incremental_thetas, axis=1, num=num_steps)\n        running_sum_num = tf.unstack(previous_sum_num, axis=1, num=1)[0]\n        running_sum_denom = tf.unstack(previous_sum_denom, axis=1, num=1)[0]\n        running_max_denom = tf.unstack(previous_max_denom, axis=1, num=1)[0]\n        for i in range(num_steps):\n            (running_sum_num, running_sum_denom, running_max_denom) = rotate_preds(incremental_locs_[i], incremental_thetas_[i], map_size, [running_sum_num, running_sum_denom, running_max_denom], output_valid_mask=False)[0]\n            running_sum_num = running_sum_num + fss_logits_[i] * confs_probs_[i]\n            running_sum_denom = running_sum_denom + confs_probs_[i]\n            running_max_denom = tf.maximum(running_max_denom, confs_probs_[i])\n            running_sum_nums_.append(running_sum_num)\n            running_sum_denoms_.append(running_sum_denom)\n            running_max_denoms_.append(running_max_denom)\n        running_sum_nums = tf.stack(running_sum_nums_, axis=1)\n        running_sum_denoms = tf.stack(running_sum_denoms_, axis=1)\n        running_max_denoms = tf.stack(running_max_denoms_, axis=1)\n        return (running_sum_nums, running_sum_denoms, running_max_denoms)",
            "def running_combine(fss_logits, confs_probs, incremental_locs, incremental_thetas, previous_sum_num, previous_sum_denom, previous_max_denom, map_size, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with tf.name_scope('combine_{:d}'.format(num_steps)):\n        running_sum_nums_ = []\n        running_sum_denoms_ = []\n        running_max_denoms_ = []\n        fss_logits_ = tf.unstack(fss_logits, axis=1, num=num_steps)\n        confs_probs_ = tf.unstack(confs_probs, axis=1, num=num_steps)\n        incremental_locs_ = tf.unstack(incremental_locs, axis=1, num=num_steps)\n        incremental_thetas_ = tf.unstack(incremental_thetas, axis=1, num=num_steps)\n        running_sum_num = tf.unstack(previous_sum_num, axis=1, num=1)[0]\n        running_sum_denom = tf.unstack(previous_sum_denom, axis=1, num=1)[0]\n        running_max_denom = tf.unstack(previous_max_denom, axis=1, num=1)[0]\n        for i in range(num_steps):\n            (running_sum_num, running_sum_denom, running_max_denom) = rotate_preds(incremental_locs_[i], incremental_thetas_[i], map_size, [running_sum_num, running_sum_denom, running_max_denom], output_valid_mask=False)[0]\n            running_sum_num = running_sum_num + fss_logits_[i] * confs_probs_[i]\n            running_sum_denom = running_sum_denom + confs_probs_[i]\n            running_max_denom = tf.maximum(running_max_denom, confs_probs_[i])\n            running_sum_nums_.append(running_sum_num)\n            running_sum_denoms_.append(running_sum_denom)\n            running_max_denoms_.append(running_max_denom)\n        running_sum_nums = tf.stack(running_sum_nums_, axis=1)\n        running_sum_denoms = tf.stack(running_sum_denoms_, axis=1)\n        running_max_denoms = tf.stack(running_max_denoms_, axis=1)\n        return (running_sum_nums, running_sum_denoms, running_max_denoms)"
        ]
    },
    {
        "func_name": "get_map_from_images",
        "original": "def get_map_from_images(imgs, mapper_arch, task_params, freeze_conv, wt_decay, is_training, batch_norm_is_training_op, num_maps, split_maps=True):\n    n_views = len(task_params.aux_delta_thetas) + 1\n    out = utils.Foo()\n    images_reshaped = tf.reshape(imgs, shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    (x, out.vars_to_restore) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, mapper_arch.encoder, freeze_conv, wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    out.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(out.encoder_output, shape=[-1] + sh_before[1:])\n    if mapper_arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = mapper_arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = mapper_arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        out.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(out.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        out.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    with tf.variable_scope('fc'):\n        fc_batch_norm_param = {'center': True, 'scale': True, 'activation_fn': tf.nn.relu, 'is_training': batch_norm_is_training_op}\n        f = out.reshape_conv_feat\n        out_neurons = mapper_arch.fc_out_size ** 2 * mapper_arch.fc_out_neurons\n        neurons = mapper_arch.fc_neurons + [out_neurons]\n        (f, _) = tf_utils.fc_network(f, neurons=neurons, wt_decay=wt_decay, name='fc', offset=0, batch_norm_param=fc_batch_norm_param, is_training=is_training, dropout_ratio=mapper_arch.fc_dropout)\n        f = tf.reshape(f, shape=[-1, mapper_arch.fc_out_size, mapper_arch.fc_out_size, mapper_arch.fc_out_neurons], name='re_fc')\n    with tf.variable_scope('deconv'):\n        (x, outs) = deconv(f, batch_norm_is_training_op, wt_decay=wt_decay, neurons=mapper_arch.deconv_neurons, strides=mapper_arch.deconv_strides, layers_per_block=mapper_arch.deconv_layers_per_block, kernel_size=mapper_arch.deconv_kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='deconv')\n    sh = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[task_params.batch_size, -1] + sh[1:])\n    out.deconv_output = x\n    if split_maps:\n        with tf.name_scope('split'):\n            out_all = tf.split(value=x, axis=4, num_or_size_splits=2 * num_maps)\n            out.fss_logits = out_all[:num_maps]\n            out.confs_logits = out_all[num_maps:]\n        with tf.name_scope('sigmoid'):\n            out.confs_probs = [tf.nn.sigmoid(x) for x in out.confs_logits]\n    return out",
        "mutated": [
            "def get_map_from_images(imgs, mapper_arch, task_params, freeze_conv, wt_decay, is_training, batch_norm_is_training_op, num_maps, split_maps=True):\n    if False:\n        i = 10\n    n_views = len(task_params.aux_delta_thetas) + 1\n    out = utils.Foo()\n    images_reshaped = tf.reshape(imgs, shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    (x, out.vars_to_restore) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, mapper_arch.encoder, freeze_conv, wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    out.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(out.encoder_output, shape=[-1] + sh_before[1:])\n    if mapper_arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = mapper_arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = mapper_arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        out.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(out.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        out.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    with tf.variable_scope('fc'):\n        fc_batch_norm_param = {'center': True, 'scale': True, 'activation_fn': tf.nn.relu, 'is_training': batch_norm_is_training_op}\n        f = out.reshape_conv_feat\n        out_neurons = mapper_arch.fc_out_size ** 2 * mapper_arch.fc_out_neurons\n        neurons = mapper_arch.fc_neurons + [out_neurons]\n        (f, _) = tf_utils.fc_network(f, neurons=neurons, wt_decay=wt_decay, name='fc', offset=0, batch_norm_param=fc_batch_norm_param, is_training=is_training, dropout_ratio=mapper_arch.fc_dropout)\n        f = tf.reshape(f, shape=[-1, mapper_arch.fc_out_size, mapper_arch.fc_out_size, mapper_arch.fc_out_neurons], name='re_fc')\n    with tf.variable_scope('deconv'):\n        (x, outs) = deconv(f, batch_norm_is_training_op, wt_decay=wt_decay, neurons=mapper_arch.deconv_neurons, strides=mapper_arch.deconv_strides, layers_per_block=mapper_arch.deconv_layers_per_block, kernel_size=mapper_arch.deconv_kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='deconv')\n    sh = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[task_params.batch_size, -1] + sh[1:])\n    out.deconv_output = x\n    if split_maps:\n        with tf.name_scope('split'):\n            out_all = tf.split(value=x, axis=4, num_or_size_splits=2 * num_maps)\n            out.fss_logits = out_all[:num_maps]\n            out.confs_logits = out_all[num_maps:]\n        with tf.name_scope('sigmoid'):\n            out.confs_probs = [tf.nn.sigmoid(x) for x in out.confs_logits]\n    return out",
            "def get_map_from_images(imgs, mapper_arch, task_params, freeze_conv, wt_decay, is_training, batch_norm_is_training_op, num_maps, split_maps=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    n_views = len(task_params.aux_delta_thetas) + 1\n    out = utils.Foo()\n    images_reshaped = tf.reshape(imgs, shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    (x, out.vars_to_restore) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, mapper_arch.encoder, freeze_conv, wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    out.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(out.encoder_output, shape=[-1] + sh_before[1:])\n    if mapper_arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = mapper_arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = mapper_arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        out.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(out.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        out.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    with tf.variable_scope('fc'):\n        fc_batch_norm_param = {'center': True, 'scale': True, 'activation_fn': tf.nn.relu, 'is_training': batch_norm_is_training_op}\n        f = out.reshape_conv_feat\n        out_neurons = mapper_arch.fc_out_size ** 2 * mapper_arch.fc_out_neurons\n        neurons = mapper_arch.fc_neurons + [out_neurons]\n        (f, _) = tf_utils.fc_network(f, neurons=neurons, wt_decay=wt_decay, name='fc', offset=0, batch_norm_param=fc_batch_norm_param, is_training=is_training, dropout_ratio=mapper_arch.fc_dropout)\n        f = tf.reshape(f, shape=[-1, mapper_arch.fc_out_size, mapper_arch.fc_out_size, mapper_arch.fc_out_neurons], name='re_fc')\n    with tf.variable_scope('deconv'):\n        (x, outs) = deconv(f, batch_norm_is_training_op, wt_decay=wt_decay, neurons=mapper_arch.deconv_neurons, strides=mapper_arch.deconv_strides, layers_per_block=mapper_arch.deconv_layers_per_block, kernel_size=mapper_arch.deconv_kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='deconv')\n    sh = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[task_params.batch_size, -1] + sh[1:])\n    out.deconv_output = x\n    if split_maps:\n        with tf.name_scope('split'):\n            out_all = tf.split(value=x, axis=4, num_or_size_splits=2 * num_maps)\n            out.fss_logits = out_all[:num_maps]\n            out.confs_logits = out_all[num_maps:]\n        with tf.name_scope('sigmoid'):\n            out.confs_probs = [tf.nn.sigmoid(x) for x in out.confs_logits]\n    return out",
            "def get_map_from_images(imgs, mapper_arch, task_params, freeze_conv, wt_decay, is_training, batch_norm_is_training_op, num_maps, split_maps=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    n_views = len(task_params.aux_delta_thetas) + 1\n    out = utils.Foo()\n    images_reshaped = tf.reshape(imgs, shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    (x, out.vars_to_restore) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, mapper_arch.encoder, freeze_conv, wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    out.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(out.encoder_output, shape=[-1] + sh_before[1:])\n    if mapper_arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = mapper_arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = mapper_arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        out.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(out.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        out.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    with tf.variable_scope('fc'):\n        fc_batch_norm_param = {'center': True, 'scale': True, 'activation_fn': tf.nn.relu, 'is_training': batch_norm_is_training_op}\n        f = out.reshape_conv_feat\n        out_neurons = mapper_arch.fc_out_size ** 2 * mapper_arch.fc_out_neurons\n        neurons = mapper_arch.fc_neurons + [out_neurons]\n        (f, _) = tf_utils.fc_network(f, neurons=neurons, wt_decay=wt_decay, name='fc', offset=0, batch_norm_param=fc_batch_norm_param, is_training=is_training, dropout_ratio=mapper_arch.fc_dropout)\n        f = tf.reshape(f, shape=[-1, mapper_arch.fc_out_size, mapper_arch.fc_out_size, mapper_arch.fc_out_neurons], name='re_fc')\n    with tf.variable_scope('deconv'):\n        (x, outs) = deconv(f, batch_norm_is_training_op, wt_decay=wt_decay, neurons=mapper_arch.deconv_neurons, strides=mapper_arch.deconv_strides, layers_per_block=mapper_arch.deconv_layers_per_block, kernel_size=mapper_arch.deconv_kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='deconv')\n    sh = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[task_params.batch_size, -1] + sh[1:])\n    out.deconv_output = x\n    if split_maps:\n        with tf.name_scope('split'):\n            out_all = tf.split(value=x, axis=4, num_or_size_splits=2 * num_maps)\n            out.fss_logits = out_all[:num_maps]\n            out.confs_logits = out_all[num_maps:]\n        with tf.name_scope('sigmoid'):\n            out.confs_probs = [tf.nn.sigmoid(x) for x in out.confs_logits]\n    return out",
            "def get_map_from_images(imgs, mapper_arch, task_params, freeze_conv, wt_decay, is_training, batch_norm_is_training_op, num_maps, split_maps=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    n_views = len(task_params.aux_delta_thetas) + 1\n    out = utils.Foo()\n    images_reshaped = tf.reshape(imgs, shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    (x, out.vars_to_restore) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, mapper_arch.encoder, freeze_conv, wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    out.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(out.encoder_output, shape=[-1] + sh_before[1:])\n    if mapper_arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = mapper_arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = mapper_arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        out.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(out.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        out.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    with tf.variable_scope('fc'):\n        fc_batch_norm_param = {'center': True, 'scale': True, 'activation_fn': tf.nn.relu, 'is_training': batch_norm_is_training_op}\n        f = out.reshape_conv_feat\n        out_neurons = mapper_arch.fc_out_size ** 2 * mapper_arch.fc_out_neurons\n        neurons = mapper_arch.fc_neurons + [out_neurons]\n        (f, _) = tf_utils.fc_network(f, neurons=neurons, wt_decay=wt_decay, name='fc', offset=0, batch_norm_param=fc_batch_norm_param, is_training=is_training, dropout_ratio=mapper_arch.fc_dropout)\n        f = tf.reshape(f, shape=[-1, mapper_arch.fc_out_size, mapper_arch.fc_out_size, mapper_arch.fc_out_neurons], name='re_fc')\n    with tf.variable_scope('deconv'):\n        (x, outs) = deconv(f, batch_norm_is_training_op, wt_decay=wt_decay, neurons=mapper_arch.deconv_neurons, strides=mapper_arch.deconv_strides, layers_per_block=mapper_arch.deconv_layers_per_block, kernel_size=mapper_arch.deconv_kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='deconv')\n    sh = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[task_params.batch_size, -1] + sh[1:])\n    out.deconv_output = x\n    if split_maps:\n        with tf.name_scope('split'):\n            out_all = tf.split(value=x, axis=4, num_or_size_splits=2 * num_maps)\n            out.fss_logits = out_all[:num_maps]\n            out.confs_logits = out_all[num_maps:]\n        with tf.name_scope('sigmoid'):\n            out.confs_probs = [tf.nn.sigmoid(x) for x in out.confs_logits]\n    return out",
            "def get_map_from_images(imgs, mapper_arch, task_params, freeze_conv, wt_decay, is_training, batch_norm_is_training_op, num_maps, split_maps=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    n_views = len(task_params.aux_delta_thetas) + 1\n    out = utils.Foo()\n    images_reshaped = tf.reshape(imgs, shape=[-1, task_params.img_height, task_params.img_width, task_params.img_channels], name='re_image')\n    (x, out.vars_to_restore) = get_repr_from_image(images_reshaped, task_params.modalities, task_params.data_augment, mapper_arch.encoder, freeze_conv, wt_decay, is_training)\n    sh_before = x.get_shape().as_list()\n    out.encoder_output = tf.reshape(x, shape=[task_params.batch_size, -1, n_views] + sh_before[1:])\n    x = tf.reshape(out.encoder_output, shape=[-1] + sh_before[1:])\n    if mapper_arch.dim_reduce_neurons > 0:\n        ks = 1\n        neurons = mapper_arch.dim_reduce_neurons\n        init_var = np.sqrt(2.0 / ks ** 2 / neurons)\n        batch_norm_param = mapper_arch.batch_norm_param\n        batch_norm_param['is_training'] = batch_norm_is_training_op\n        out.conv_feat = slim.conv2d(x, neurons, kernel_size=ks, stride=1, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_param, padding='SAME', scope='dim_reduce', weights_regularizer=slim.l2_regularizer(wt_decay), weights_initializer=tf.random_normal_initializer(stddev=init_var))\n        reshape_conv_feat = slim.flatten(out.conv_feat)\n        sh = reshape_conv_feat.get_shape().as_list()\n        out.reshape_conv_feat = tf.reshape(reshape_conv_feat, shape=[-1, sh[1] * n_views])\n    with tf.variable_scope('fc'):\n        fc_batch_norm_param = {'center': True, 'scale': True, 'activation_fn': tf.nn.relu, 'is_training': batch_norm_is_training_op}\n        f = out.reshape_conv_feat\n        out_neurons = mapper_arch.fc_out_size ** 2 * mapper_arch.fc_out_neurons\n        neurons = mapper_arch.fc_neurons + [out_neurons]\n        (f, _) = tf_utils.fc_network(f, neurons=neurons, wt_decay=wt_decay, name='fc', offset=0, batch_norm_param=fc_batch_norm_param, is_training=is_training, dropout_ratio=mapper_arch.fc_dropout)\n        f = tf.reshape(f, shape=[-1, mapper_arch.fc_out_size, mapper_arch.fc_out_size, mapper_arch.fc_out_neurons], name='re_fc')\n    with tf.variable_scope('deconv'):\n        (x, outs) = deconv(f, batch_norm_is_training_op, wt_decay=wt_decay, neurons=mapper_arch.deconv_neurons, strides=mapper_arch.deconv_strides, layers_per_block=mapper_arch.deconv_layers_per_block, kernel_size=mapper_arch.deconv_kernel_size, conv_fn=slim.conv2d_transpose, offset=0, name='deconv')\n    sh = x.get_shape().as_list()\n    x = tf.reshape(x, shape=[task_params.batch_size, -1] + sh[1:])\n    out.deconv_output = x\n    if split_maps:\n        with tf.name_scope('split'):\n            out_all = tf.split(value=x, axis=4, num_or_size_splits=2 * num_maps)\n            out.fss_logits = out_all[:num_maps]\n            out.confs_logits = out_all[num_maps:]\n        with tf.name_scope('sigmoid'):\n            out.confs_probs = [tf.nn.sigmoid(x) for x in out.confs_logits]\n    return out"
        ]
    },
    {
        "func_name": "setup_to_run",
        "original": "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    assert args.arch.multi_scale, 'removed support for old single scale code.'\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    m.train_ops = {}\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params)\n    m.init_fn = None\n    if task_params.input_type == 'vision':\n        m.vision_ops = get_map_from_images(m.input_tensors['step']['imgs'], args.mapper_arch, task_params, args.solver.freeze_conv, args.solver.wt_decay, is_training, batch_norm_is_training_op, num_maps=len(task_params.map_crop_sizes))\n        if args.solver.pretrained_path is not None:\n            m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, m.vision_ops.vars_to_restore)\n        if args.solver.freeze_conv:\n            m.train_ops['step_data_cache'] = [m.vision_ops.encoder_output]\n        else:\n            m.train_ops['step_data_cache'] = []\n        m.ego_map_ops = m.vision_ops.fss_logits\n        m.coverage_ops = m.vision_ops.confs_probs\n        for i in range(len(m.ego_map_ops)):\n            if args.mapper_arch.pad_map_with_zeros_each[i] > 0:\n                paddings = np.zeros((5, 2), dtype=np.int32)\n                paddings[2:4, :] = args.mapper_arch.pad_map_with_zeros_each[i]\n                paddings_op = tf.constant(paddings, dtype=tf.int32)\n                m.ego_map_ops[i] = tf.pad(m.ego_map_ops[i], paddings=paddings_op)\n                m.coverage_ops[i] = tf.pad(m.coverage_ops[i], paddings=paddings_op)\n    elif task_params.input_type == 'analytical_counts':\n        m.ego_map_ops = []\n        m.coverage_ops = []\n        for i in range(len(task_params.map_crop_sizes)):\n            ego_map_op = m.input_tensors['step']['analytical_counts_{:d}'.format(i)]\n            coverage_op = tf.cast(tf.greater_equal(tf.reduce_max(ego_map_op, reduction_indices=[4], keep_dims=True), 1), tf.float32)\n            coverage_op = tf.ones_like(ego_map_op) * coverage_op\n            m.ego_map_ops.append(ego_map_op)\n            m.coverage_ops.append(coverage_op)\n            m.train_ops['step_data_cache'] = []\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    map_crop_size_ops = []\n    for map_crop_size in task_params.map_crop_sizes:\n        map_crop_size_ops.append(tf.constant(map_crop_size, dtype=tf.int32, shape=(2,)))\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.ego_map_ops[0]), num=5)[1], 1)\n    fr_ops = []\n    value_ops = []\n    fr_intermediate_ops = []\n    value_intermediate_ops = []\n    crop_value_ops = []\n    resize_crop_value_ops = []\n    confs = []\n    occupancys = []\n    previous_value_op = None\n    updated_state = []\n    state_names = []\n    for i in range(len(task_params.map_crop_sizes)):\n        map_crop_size = task_params.map_crop_sizes[i]\n        with tf.variable_scope('scale_{:d}'.format(i)):\n            fn = lambda ns: running_combine(m.ego_map_ops[i], m.coverage_ops[i], m.input_tensors['step']['incremental_locs'] * task_params.map_scales[i], m.input_tensors['step']['incremental_thetas'], m.input_tensors['step']['running_sum_num_{:d}'.format(i)], m.input_tensors['step']['running_sum_denom_{:d}'.format(i)], m.input_tensors['step']['running_max_denom_{:d}'.format(i)], map_crop_size, ns)\n            (running_sum_num, running_sum_denom, running_max_denom) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps * num_goals))\n            updated_state += [running_sum_num, running_sum_denom, running_max_denom]\n            state_names += ['running_sum_num_{:d}'.format(i), 'running_sum_denom_{:d}'.format(i), 'running_max_denom_{:d}'.format(i)]\n            occupancy = running_sum_num / tf.maximum(running_sum_denom, 0.001)\n            conf = running_max_denom\n            with tf.name_scope('concat'):\n                sh = [-1, map_crop_size, map_crop_size, task_params.map_channels]\n                occupancy = tf.reshape(occupancy, shape=sh)\n                conf = tf.reshape(conf, shape=sh)\n                sh = [-1, map_crop_size, map_crop_size, task_params.goal_channels]\n                goal = tf.reshape(m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)], shape=sh)\n                to_concat = [occupancy, conf, goal]\n                if previous_value_op is not None:\n                    to_concat.append(previous_value_op)\n                x = tf.concat(to_concat, 3)\n            (fr_op, fr_intermediate_op) = fr_v2(x, output_neurons=args.arch.fr_neurons, inside_neurons=args.arch.fr_inside_neurons, is_training=batch_norm_is_training_op, name='fr', wt_decay=args.solver.wt_decay, stride=args.arch.fr_stride)\n            if args.arch.vin_num_iters > 0:\n                (value_op, value_intermediate_op) = value_iteration_network(fr_op, num_iters=args.arch.vin_num_iters, val_neurons=args.arch.vin_val_neurons, action_neurons=args.arch.vin_action_neurons, kernel_size=args.arch.vin_ks, share_wts=args.arch.vin_share_wts, name='vin', wt_decay=args.solver.wt_decay)\n            else:\n                value_op = fr_op\n                value_intermediate_op = []\n            remove = args.arch.crop_remove_each\n            if remove > 0:\n                crop_value_op = value_op[:, remove:-remove, remove:-remove, :]\n            else:\n                crop_value_op = value_op\n            crop_value_op = tf.reshape(crop_value_op, shape=[-1, args.arch.value_crop_size, args.arch.value_crop_size, args.arch.vin_val_neurons])\n            if i < len(task_params.map_crop_sizes) - 1:\n                previous_value_op = tf.image.resize_bilinear(crop_value_op, map_crop_size_ops[i + 1], align_corners=True)\n                resize_crop_value_ops.append(previous_value_op)\n            occupancys.append(occupancy)\n            confs.append(conf)\n            value_ops.append(value_op)\n            crop_value_ops.append(crop_value_op)\n            fr_ops.append(fr_op)\n            fr_intermediate_ops.append(fr_intermediate_op)\n    m.value_ops = value_ops\n    m.value_intermediate_ops = value_intermediate_ops\n    m.fr_ops = fr_ops\n    m.fr_intermediate_ops = fr_intermediate_ops\n    m.final_value_op = crop_value_op\n    m.crop_value_ops = crop_value_ops\n    m.resize_crop_value_ops = resize_crop_value_ops\n    m.confs = confs\n    m.occupancys = occupancys\n    sh = [-1, args.arch.vin_val_neurons * args.arch.value_crop_size ** 2]\n    m.value_features_op = tf.reshape(m.final_value_op, sh, name='reshape_value_op')\n    with tf.variable_scope('action_pred'):\n        batch_norm_param = args.arch.pred_batch_norm_param\n        if batch_norm_param is not None:\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.action_logits_op, _) = tf_utils.fc_network(m.value_features_op, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=task_params.num_actions, batch_norm_param=batch_norm_param)\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    init_state = tf.constant(0.0, dtype=tf.float32, shape=[task_params.batch_size, 1, map_crop_size, map_crop_size, task_params.map_channels])\n    m.train_ops['state_names'] = state_names\n    m.train_ops['updated_state'] = updated_state\n    m.train_ops['init_state'] = [init_state for _ in updated_state]\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc']]\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.loss_ops = []\n    m.loss_ops_names = []\n    if args.arch.readout_maps:\n        with tf.name_scope('readout_maps'):\n            all_occupancys = tf.concat(m.occupancys + m.confs, 3)\n            (readout_maps, probs) = readout_general(all_occupancys, num_neurons=args.arch.rom_arch.num_neurons, strides=args.arch.rom_arch.strides, layers_per_block=args.arch.rom_arch.layers_per_block, kernel_size=args.arch.rom_arch.kernel_size, batch_norm_is_training_op=batch_norm_is_training_op, wt_decay=args.solver.wt_decay)\n            gt_ego_maps = [m.input_tensors['step']['readout_maps_{:d}'.format(i)] for i in range(len(task_params.readout_maps_crop_sizes))]\n            m.readout_maps_gt = tf.concat(gt_ego_maps, 4)\n            gt_shape = tf.shape(m.readout_maps_gt)\n            m.readout_maps_logits = tf.reshape(readout_maps, gt_shape)\n            m.readout_maps_probs = tf.reshape(probs, gt_shape)\n            m.readout_maps_loss_op = tf.losses.sigmoid_cross_entropy(tf.reshape(m.readout_maps_gt, [-1, len(task_params.readout_maps_crop_sizes)]), tf.reshape(readout_maps, [-1, len(task_params.readout_maps_crop_sizes)]), scope='loss')\n            m.readout_maps_loss_op = 10.0 * m.readout_maps_loss_op\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=task_params.num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.arch.readout_maps:\n        m.total_loss_op = m.total_loss_op + m.readout_maps_loss_op\n        m.loss_ops += [m.readout_maps_loss_op]\n        m.loss_ops_names += ['readout_maps_loss']\n    m.loss_ops += [m.reg_loss_op, m.data_loss_op, m.total_loss_op]\n    m.loss_ops_names += ['reg_loss', 'data_loss', 'total_loss']\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(m.vision_ops.vars_to_restore))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    m.summary_ops = {summary_mode: _add_summaries(m, args, summary_mode, args.summary.arop_full_summary_iters)}\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
        "mutated": [
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n    assert args.arch.multi_scale, 'removed support for old single scale code.'\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    m.train_ops = {}\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params)\n    m.init_fn = None\n    if task_params.input_type == 'vision':\n        m.vision_ops = get_map_from_images(m.input_tensors['step']['imgs'], args.mapper_arch, task_params, args.solver.freeze_conv, args.solver.wt_decay, is_training, batch_norm_is_training_op, num_maps=len(task_params.map_crop_sizes))\n        if args.solver.pretrained_path is not None:\n            m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, m.vision_ops.vars_to_restore)\n        if args.solver.freeze_conv:\n            m.train_ops['step_data_cache'] = [m.vision_ops.encoder_output]\n        else:\n            m.train_ops['step_data_cache'] = []\n        m.ego_map_ops = m.vision_ops.fss_logits\n        m.coverage_ops = m.vision_ops.confs_probs\n        for i in range(len(m.ego_map_ops)):\n            if args.mapper_arch.pad_map_with_zeros_each[i] > 0:\n                paddings = np.zeros((5, 2), dtype=np.int32)\n                paddings[2:4, :] = args.mapper_arch.pad_map_with_zeros_each[i]\n                paddings_op = tf.constant(paddings, dtype=tf.int32)\n                m.ego_map_ops[i] = tf.pad(m.ego_map_ops[i], paddings=paddings_op)\n                m.coverage_ops[i] = tf.pad(m.coverage_ops[i], paddings=paddings_op)\n    elif task_params.input_type == 'analytical_counts':\n        m.ego_map_ops = []\n        m.coverage_ops = []\n        for i in range(len(task_params.map_crop_sizes)):\n            ego_map_op = m.input_tensors['step']['analytical_counts_{:d}'.format(i)]\n            coverage_op = tf.cast(tf.greater_equal(tf.reduce_max(ego_map_op, reduction_indices=[4], keep_dims=True), 1), tf.float32)\n            coverage_op = tf.ones_like(ego_map_op) * coverage_op\n            m.ego_map_ops.append(ego_map_op)\n            m.coverage_ops.append(coverage_op)\n            m.train_ops['step_data_cache'] = []\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    map_crop_size_ops = []\n    for map_crop_size in task_params.map_crop_sizes:\n        map_crop_size_ops.append(tf.constant(map_crop_size, dtype=tf.int32, shape=(2,)))\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.ego_map_ops[0]), num=5)[1], 1)\n    fr_ops = []\n    value_ops = []\n    fr_intermediate_ops = []\n    value_intermediate_ops = []\n    crop_value_ops = []\n    resize_crop_value_ops = []\n    confs = []\n    occupancys = []\n    previous_value_op = None\n    updated_state = []\n    state_names = []\n    for i in range(len(task_params.map_crop_sizes)):\n        map_crop_size = task_params.map_crop_sizes[i]\n        with tf.variable_scope('scale_{:d}'.format(i)):\n            fn = lambda ns: running_combine(m.ego_map_ops[i], m.coverage_ops[i], m.input_tensors['step']['incremental_locs'] * task_params.map_scales[i], m.input_tensors['step']['incremental_thetas'], m.input_tensors['step']['running_sum_num_{:d}'.format(i)], m.input_tensors['step']['running_sum_denom_{:d}'.format(i)], m.input_tensors['step']['running_max_denom_{:d}'.format(i)], map_crop_size, ns)\n            (running_sum_num, running_sum_denom, running_max_denom) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps * num_goals))\n            updated_state += [running_sum_num, running_sum_denom, running_max_denom]\n            state_names += ['running_sum_num_{:d}'.format(i), 'running_sum_denom_{:d}'.format(i), 'running_max_denom_{:d}'.format(i)]\n            occupancy = running_sum_num / tf.maximum(running_sum_denom, 0.001)\n            conf = running_max_denom\n            with tf.name_scope('concat'):\n                sh = [-1, map_crop_size, map_crop_size, task_params.map_channels]\n                occupancy = tf.reshape(occupancy, shape=sh)\n                conf = tf.reshape(conf, shape=sh)\n                sh = [-1, map_crop_size, map_crop_size, task_params.goal_channels]\n                goal = tf.reshape(m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)], shape=sh)\n                to_concat = [occupancy, conf, goal]\n                if previous_value_op is not None:\n                    to_concat.append(previous_value_op)\n                x = tf.concat(to_concat, 3)\n            (fr_op, fr_intermediate_op) = fr_v2(x, output_neurons=args.arch.fr_neurons, inside_neurons=args.arch.fr_inside_neurons, is_training=batch_norm_is_training_op, name='fr', wt_decay=args.solver.wt_decay, stride=args.arch.fr_stride)\n            if args.arch.vin_num_iters > 0:\n                (value_op, value_intermediate_op) = value_iteration_network(fr_op, num_iters=args.arch.vin_num_iters, val_neurons=args.arch.vin_val_neurons, action_neurons=args.arch.vin_action_neurons, kernel_size=args.arch.vin_ks, share_wts=args.arch.vin_share_wts, name='vin', wt_decay=args.solver.wt_decay)\n            else:\n                value_op = fr_op\n                value_intermediate_op = []\n            remove = args.arch.crop_remove_each\n            if remove > 0:\n                crop_value_op = value_op[:, remove:-remove, remove:-remove, :]\n            else:\n                crop_value_op = value_op\n            crop_value_op = tf.reshape(crop_value_op, shape=[-1, args.arch.value_crop_size, args.arch.value_crop_size, args.arch.vin_val_neurons])\n            if i < len(task_params.map_crop_sizes) - 1:\n                previous_value_op = tf.image.resize_bilinear(crop_value_op, map_crop_size_ops[i + 1], align_corners=True)\n                resize_crop_value_ops.append(previous_value_op)\n            occupancys.append(occupancy)\n            confs.append(conf)\n            value_ops.append(value_op)\n            crop_value_ops.append(crop_value_op)\n            fr_ops.append(fr_op)\n            fr_intermediate_ops.append(fr_intermediate_op)\n    m.value_ops = value_ops\n    m.value_intermediate_ops = value_intermediate_ops\n    m.fr_ops = fr_ops\n    m.fr_intermediate_ops = fr_intermediate_ops\n    m.final_value_op = crop_value_op\n    m.crop_value_ops = crop_value_ops\n    m.resize_crop_value_ops = resize_crop_value_ops\n    m.confs = confs\n    m.occupancys = occupancys\n    sh = [-1, args.arch.vin_val_neurons * args.arch.value_crop_size ** 2]\n    m.value_features_op = tf.reshape(m.final_value_op, sh, name='reshape_value_op')\n    with tf.variable_scope('action_pred'):\n        batch_norm_param = args.arch.pred_batch_norm_param\n        if batch_norm_param is not None:\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.action_logits_op, _) = tf_utils.fc_network(m.value_features_op, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=task_params.num_actions, batch_norm_param=batch_norm_param)\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    init_state = tf.constant(0.0, dtype=tf.float32, shape=[task_params.batch_size, 1, map_crop_size, map_crop_size, task_params.map_channels])\n    m.train_ops['state_names'] = state_names\n    m.train_ops['updated_state'] = updated_state\n    m.train_ops['init_state'] = [init_state for _ in updated_state]\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc']]\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.loss_ops = []\n    m.loss_ops_names = []\n    if args.arch.readout_maps:\n        with tf.name_scope('readout_maps'):\n            all_occupancys = tf.concat(m.occupancys + m.confs, 3)\n            (readout_maps, probs) = readout_general(all_occupancys, num_neurons=args.arch.rom_arch.num_neurons, strides=args.arch.rom_arch.strides, layers_per_block=args.arch.rom_arch.layers_per_block, kernel_size=args.arch.rom_arch.kernel_size, batch_norm_is_training_op=batch_norm_is_training_op, wt_decay=args.solver.wt_decay)\n            gt_ego_maps = [m.input_tensors['step']['readout_maps_{:d}'.format(i)] for i in range(len(task_params.readout_maps_crop_sizes))]\n            m.readout_maps_gt = tf.concat(gt_ego_maps, 4)\n            gt_shape = tf.shape(m.readout_maps_gt)\n            m.readout_maps_logits = tf.reshape(readout_maps, gt_shape)\n            m.readout_maps_probs = tf.reshape(probs, gt_shape)\n            m.readout_maps_loss_op = tf.losses.sigmoid_cross_entropy(tf.reshape(m.readout_maps_gt, [-1, len(task_params.readout_maps_crop_sizes)]), tf.reshape(readout_maps, [-1, len(task_params.readout_maps_crop_sizes)]), scope='loss')\n            m.readout_maps_loss_op = 10.0 * m.readout_maps_loss_op\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=task_params.num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.arch.readout_maps:\n        m.total_loss_op = m.total_loss_op + m.readout_maps_loss_op\n        m.loss_ops += [m.readout_maps_loss_op]\n        m.loss_ops_names += ['readout_maps_loss']\n    m.loss_ops += [m.reg_loss_op, m.data_loss_op, m.total_loss_op]\n    m.loss_ops_names += ['reg_loss', 'data_loss', 'total_loss']\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(m.vision_ops.vars_to_restore))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    m.summary_ops = {summary_mode: _add_summaries(m, args, summary_mode, args.summary.arop_full_summary_iters)}\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert args.arch.multi_scale, 'removed support for old single scale code.'\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    m.train_ops = {}\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params)\n    m.init_fn = None\n    if task_params.input_type == 'vision':\n        m.vision_ops = get_map_from_images(m.input_tensors['step']['imgs'], args.mapper_arch, task_params, args.solver.freeze_conv, args.solver.wt_decay, is_training, batch_norm_is_training_op, num_maps=len(task_params.map_crop_sizes))\n        if args.solver.pretrained_path is not None:\n            m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, m.vision_ops.vars_to_restore)\n        if args.solver.freeze_conv:\n            m.train_ops['step_data_cache'] = [m.vision_ops.encoder_output]\n        else:\n            m.train_ops['step_data_cache'] = []\n        m.ego_map_ops = m.vision_ops.fss_logits\n        m.coverage_ops = m.vision_ops.confs_probs\n        for i in range(len(m.ego_map_ops)):\n            if args.mapper_arch.pad_map_with_zeros_each[i] > 0:\n                paddings = np.zeros((5, 2), dtype=np.int32)\n                paddings[2:4, :] = args.mapper_arch.pad_map_with_zeros_each[i]\n                paddings_op = tf.constant(paddings, dtype=tf.int32)\n                m.ego_map_ops[i] = tf.pad(m.ego_map_ops[i], paddings=paddings_op)\n                m.coverage_ops[i] = tf.pad(m.coverage_ops[i], paddings=paddings_op)\n    elif task_params.input_type == 'analytical_counts':\n        m.ego_map_ops = []\n        m.coverage_ops = []\n        for i in range(len(task_params.map_crop_sizes)):\n            ego_map_op = m.input_tensors['step']['analytical_counts_{:d}'.format(i)]\n            coverage_op = tf.cast(tf.greater_equal(tf.reduce_max(ego_map_op, reduction_indices=[4], keep_dims=True), 1), tf.float32)\n            coverage_op = tf.ones_like(ego_map_op) * coverage_op\n            m.ego_map_ops.append(ego_map_op)\n            m.coverage_ops.append(coverage_op)\n            m.train_ops['step_data_cache'] = []\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    map_crop_size_ops = []\n    for map_crop_size in task_params.map_crop_sizes:\n        map_crop_size_ops.append(tf.constant(map_crop_size, dtype=tf.int32, shape=(2,)))\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.ego_map_ops[0]), num=5)[1], 1)\n    fr_ops = []\n    value_ops = []\n    fr_intermediate_ops = []\n    value_intermediate_ops = []\n    crop_value_ops = []\n    resize_crop_value_ops = []\n    confs = []\n    occupancys = []\n    previous_value_op = None\n    updated_state = []\n    state_names = []\n    for i in range(len(task_params.map_crop_sizes)):\n        map_crop_size = task_params.map_crop_sizes[i]\n        with tf.variable_scope('scale_{:d}'.format(i)):\n            fn = lambda ns: running_combine(m.ego_map_ops[i], m.coverage_ops[i], m.input_tensors['step']['incremental_locs'] * task_params.map_scales[i], m.input_tensors['step']['incremental_thetas'], m.input_tensors['step']['running_sum_num_{:d}'.format(i)], m.input_tensors['step']['running_sum_denom_{:d}'.format(i)], m.input_tensors['step']['running_max_denom_{:d}'.format(i)], map_crop_size, ns)\n            (running_sum_num, running_sum_denom, running_max_denom) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps * num_goals))\n            updated_state += [running_sum_num, running_sum_denom, running_max_denom]\n            state_names += ['running_sum_num_{:d}'.format(i), 'running_sum_denom_{:d}'.format(i), 'running_max_denom_{:d}'.format(i)]\n            occupancy = running_sum_num / tf.maximum(running_sum_denom, 0.001)\n            conf = running_max_denom\n            with tf.name_scope('concat'):\n                sh = [-1, map_crop_size, map_crop_size, task_params.map_channels]\n                occupancy = tf.reshape(occupancy, shape=sh)\n                conf = tf.reshape(conf, shape=sh)\n                sh = [-1, map_crop_size, map_crop_size, task_params.goal_channels]\n                goal = tf.reshape(m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)], shape=sh)\n                to_concat = [occupancy, conf, goal]\n                if previous_value_op is not None:\n                    to_concat.append(previous_value_op)\n                x = tf.concat(to_concat, 3)\n            (fr_op, fr_intermediate_op) = fr_v2(x, output_neurons=args.arch.fr_neurons, inside_neurons=args.arch.fr_inside_neurons, is_training=batch_norm_is_training_op, name='fr', wt_decay=args.solver.wt_decay, stride=args.arch.fr_stride)\n            if args.arch.vin_num_iters > 0:\n                (value_op, value_intermediate_op) = value_iteration_network(fr_op, num_iters=args.arch.vin_num_iters, val_neurons=args.arch.vin_val_neurons, action_neurons=args.arch.vin_action_neurons, kernel_size=args.arch.vin_ks, share_wts=args.arch.vin_share_wts, name='vin', wt_decay=args.solver.wt_decay)\n            else:\n                value_op = fr_op\n                value_intermediate_op = []\n            remove = args.arch.crop_remove_each\n            if remove > 0:\n                crop_value_op = value_op[:, remove:-remove, remove:-remove, :]\n            else:\n                crop_value_op = value_op\n            crop_value_op = tf.reshape(crop_value_op, shape=[-1, args.arch.value_crop_size, args.arch.value_crop_size, args.arch.vin_val_neurons])\n            if i < len(task_params.map_crop_sizes) - 1:\n                previous_value_op = tf.image.resize_bilinear(crop_value_op, map_crop_size_ops[i + 1], align_corners=True)\n                resize_crop_value_ops.append(previous_value_op)\n            occupancys.append(occupancy)\n            confs.append(conf)\n            value_ops.append(value_op)\n            crop_value_ops.append(crop_value_op)\n            fr_ops.append(fr_op)\n            fr_intermediate_ops.append(fr_intermediate_op)\n    m.value_ops = value_ops\n    m.value_intermediate_ops = value_intermediate_ops\n    m.fr_ops = fr_ops\n    m.fr_intermediate_ops = fr_intermediate_ops\n    m.final_value_op = crop_value_op\n    m.crop_value_ops = crop_value_ops\n    m.resize_crop_value_ops = resize_crop_value_ops\n    m.confs = confs\n    m.occupancys = occupancys\n    sh = [-1, args.arch.vin_val_neurons * args.arch.value_crop_size ** 2]\n    m.value_features_op = tf.reshape(m.final_value_op, sh, name='reshape_value_op')\n    with tf.variable_scope('action_pred'):\n        batch_norm_param = args.arch.pred_batch_norm_param\n        if batch_norm_param is not None:\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.action_logits_op, _) = tf_utils.fc_network(m.value_features_op, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=task_params.num_actions, batch_norm_param=batch_norm_param)\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    init_state = tf.constant(0.0, dtype=tf.float32, shape=[task_params.batch_size, 1, map_crop_size, map_crop_size, task_params.map_channels])\n    m.train_ops['state_names'] = state_names\n    m.train_ops['updated_state'] = updated_state\n    m.train_ops['init_state'] = [init_state for _ in updated_state]\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc']]\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.loss_ops = []\n    m.loss_ops_names = []\n    if args.arch.readout_maps:\n        with tf.name_scope('readout_maps'):\n            all_occupancys = tf.concat(m.occupancys + m.confs, 3)\n            (readout_maps, probs) = readout_general(all_occupancys, num_neurons=args.arch.rom_arch.num_neurons, strides=args.arch.rom_arch.strides, layers_per_block=args.arch.rom_arch.layers_per_block, kernel_size=args.arch.rom_arch.kernel_size, batch_norm_is_training_op=batch_norm_is_training_op, wt_decay=args.solver.wt_decay)\n            gt_ego_maps = [m.input_tensors['step']['readout_maps_{:d}'.format(i)] for i in range(len(task_params.readout_maps_crop_sizes))]\n            m.readout_maps_gt = tf.concat(gt_ego_maps, 4)\n            gt_shape = tf.shape(m.readout_maps_gt)\n            m.readout_maps_logits = tf.reshape(readout_maps, gt_shape)\n            m.readout_maps_probs = tf.reshape(probs, gt_shape)\n            m.readout_maps_loss_op = tf.losses.sigmoid_cross_entropy(tf.reshape(m.readout_maps_gt, [-1, len(task_params.readout_maps_crop_sizes)]), tf.reshape(readout_maps, [-1, len(task_params.readout_maps_crop_sizes)]), scope='loss')\n            m.readout_maps_loss_op = 10.0 * m.readout_maps_loss_op\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=task_params.num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.arch.readout_maps:\n        m.total_loss_op = m.total_loss_op + m.readout_maps_loss_op\n        m.loss_ops += [m.readout_maps_loss_op]\n        m.loss_ops_names += ['readout_maps_loss']\n    m.loss_ops += [m.reg_loss_op, m.data_loss_op, m.total_loss_op]\n    m.loss_ops_names += ['reg_loss', 'data_loss', 'total_loss']\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(m.vision_ops.vars_to_restore))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    m.summary_ops = {summary_mode: _add_summaries(m, args, summary_mode, args.summary.arop_full_summary_iters)}\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert args.arch.multi_scale, 'removed support for old single scale code.'\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    m.train_ops = {}\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params)\n    m.init_fn = None\n    if task_params.input_type == 'vision':\n        m.vision_ops = get_map_from_images(m.input_tensors['step']['imgs'], args.mapper_arch, task_params, args.solver.freeze_conv, args.solver.wt_decay, is_training, batch_norm_is_training_op, num_maps=len(task_params.map_crop_sizes))\n        if args.solver.pretrained_path is not None:\n            m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, m.vision_ops.vars_to_restore)\n        if args.solver.freeze_conv:\n            m.train_ops['step_data_cache'] = [m.vision_ops.encoder_output]\n        else:\n            m.train_ops['step_data_cache'] = []\n        m.ego_map_ops = m.vision_ops.fss_logits\n        m.coverage_ops = m.vision_ops.confs_probs\n        for i in range(len(m.ego_map_ops)):\n            if args.mapper_arch.pad_map_with_zeros_each[i] > 0:\n                paddings = np.zeros((5, 2), dtype=np.int32)\n                paddings[2:4, :] = args.mapper_arch.pad_map_with_zeros_each[i]\n                paddings_op = tf.constant(paddings, dtype=tf.int32)\n                m.ego_map_ops[i] = tf.pad(m.ego_map_ops[i], paddings=paddings_op)\n                m.coverage_ops[i] = tf.pad(m.coverage_ops[i], paddings=paddings_op)\n    elif task_params.input_type == 'analytical_counts':\n        m.ego_map_ops = []\n        m.coverage_ops = []\n        for i in range(len(task_params.map_crop_sizes)):\n            ego_map_op = m.input_tensors['step']['analytical_counts_{:d}'.format(i)]\n            coverage_op = tf.cast(tf.greater_equal(tf.reduce_max(ego_map_op, reduction_indices=[4], keep_dims=True), 1), tf.float32)\n            coverage_op = tf.ones_like(ego_map_op) * coverage_op\n            m.ego_map_ops.append(ego_map_op)\n            m.coverage_ops.append(coverage_op)\n            m.train_ops['step_data_cache'] = []\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    map_crop_size_ops = []\n    for map_crop_size in task_params.map_crop_sizes:\n        map_crop_size_ops.append(tf.constant(map_crop_size, dtype=tf.int32, shape=(2,)))\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.ego_map_ops[0]), num=5)[1], 1)\n    fr_ops = []\n    value_ops = []\n    fr_intermediate_ops = []\n    value_intermediate_ops = []\n    crop_value_ops = []\n    resize_crop_value_ops = []\n    confs = []\n    occupancys = []\n    previous_value_op = None\n    updated_state = []\n    state_names = []\n    for i in range(len(task_params.map_crop_sizes)):\n        map_crop_size = task_params.map_crop_sizes[i]\n        with tf.variable_scope('scale_{:d}'.format(i)):\n            fn = lambda ns: running_combine(m.ego_map_ops[i], m.coverage_ops[i], m.input_tensors['step']['incremental_locs'] * task_params.map_scales[i], m.input_tensors['step']['incremental_thetas'], m.input_tensors['step']['running_sum_num_{:d}'.format(i)], m.input_tensors['step']['running_sum_denom_{:d}'.format(i)], m.input_tensors['step']['running_max_denom_{:d}'.format(i)], map_crop_size, ns)\n            (running_sum_num, running_sum_denom, running_max_denom) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps * num_goals))\n            updated_state += [running_sum_num, running_sum_denom, running_max_denom]\n            state_names += ['running_sum_num_{:d}'.format(i), 'running_sum_denom_{:d}'.format(i), 'running_max_denom_{:d}'.format(i)]\n            occupancy = running_sum_num / tf.maximum(running_sum_denom, 0.001)\n            conf = running_max_denom\n            with tf.name_scope('concat'):\n                sh = [-1, map_crop_size, map_crop_size, task_params.map_channels]\n                occupancy = tf.reshape(occupancy, shape=sh)\n                conf = tf.reshape(conf, shape=sh)\n                sh = [-1, map_crop_size, map_crop_size, task_params.goal_channels]\n                goal = tf.reshape(m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)], shape=sh)\n                to_concat = [occupancy, conf, goal]\n                if previous_value_op is not None:\n                    to_concat.append(previous_value_op)\n                x = tf.concat(to_concat, 3)\n            (fr_op, fr_intermediate_op) = fr_v2(x, output_neurons=args.arch.fr_neurons, inside_neurons=args.arch.fr_inside_neurons, is_training=batch_norm_is_training_op, name='fr', wt_decay=args.solver.wt_decay, stride=args.arch.fr_stride)\n            if args.arch.vin_num_iters > 0:\n                (value_op, value_intermediate_op) = value_iteration_network(fr_op, num_iters=args.arch.vin_num_iters, val_neurons=args.arch.vin_val_neurons, action_neurons=args.arch.vin_action_neurons, kernel_size=args.arch.vin_ks, share_wts=args.arch.vin_share_wts, name='vin', wt_decay=args.solver.wt_decay)\n            else:\n                value_op = fr_op\n                value_intermediate_op = []\n            remove = args.arch.crop_remove_each\n            if remove > 0:\n                crop_value_op = value_op[:, remove:-remove, remove:-remove, :]\n            else:\n                crop_value_op = value_op\n            crop_value_op = tf.reshape(crop_value_op, shape=[-1, args.arch.value_crop_size, args.arch.value_crop_size, args.arch.vin_val_neurons])\n            if i < len(task_params.map_crop_sizes) - 1:\n                previous_value_op = tf.image.resize_bilinear(crop_value_op, map_crop_size_ops[i + 1], align_corners=True)\n                resize_crop_value_ops.append(previous_value_op)\n            occupancys.append(occupancy)\n            confs.append(conf)\n            value_ops.append(value_op)\n            crop_value_ops.append(crop_value_op)\n            fr_ops.append(fr_op)\n            fr_intermediate_ops.append(fr_intermediate_op)\n    m.value_ops = value_ops\n    m.value_intermediate_ops = value_intermediate_ops\n    m.fr_ops = fr_ops\n    m.fr_intermediate_ops = fr_intermediate_ops\n    m.final_value_op = crop_value_op\n    m.crop_value_ops = crop_value_ops\n    m.resize_crop_value_ops = resize_crop_value_ops\n    m.confs = confs\n    m.occupancys = occupancys\n    sh = [-1, args.arch.vin_val_neurons * args.arch.value_crop_size ** 2]\n    m.value_features_op = tf.reshape(m.final_value_op, sh, name='reshape_value_op')\n    with tf.variable_scope('action_pred'):\n        batch_norm_param = args.arch.pred_batch_norm_param\n        if batch_norm_param is not None:\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.action_logits_op, _) = tf_utils.fc_network(m.value_features_op, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=task_params.num_actions, batch_norm_param=batch_norm_param)\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    init_state = tf.constant(0.0, dtype=tf.float32, shape=[task_params.batch_size, 1, map_crop_size, map_crop_size, task_params.map_channels])\n    m.train_ops['state_names'] = state_names\n    m.train_ops['updated_state'] = updated_state\n    m.train_ops['init_state'] = [init_state for _ in updated_state]\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc']]\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.loss_ops = []\n    m.loss_ops_names = []\n    if args.arch.readout_maps:\n        with tf.name_scope('readout_maps'):\n            all_occupancys = tf.concat(m.occupancys + m.confs, 3)\n            (readout_maps, probs) = readout_general(all_occupancys, num_neurons=args.arch.rom_arch.num_neurons, strides=args.arch.rom_arch.strides, layers_per_block=args.arch.rom_arch.layers_per_block, kernel_size=args.arch.rom_arch.kernel_size, batch_norm_is_training_op=batch_norm_is_training_op, wt_decay=args.solver.wt_decay)\n            gt_ego_maps = [m.input_tensors['step']['readout_maps_{:d}'.format(i)] for i in range(len(task_params.readout_maps_crop_sizes))]\n            m.readout_maps_gt = tf.concat(gt_ego_maps, 4)\n            gt_shape = tf.shape(m.readout_maps_gt)\n            m.readout_maps_logits = tf.reshape(readout_maps, gt_shape)\n            m.readout_maps_probs = tf.reshape(probs, gt_shape)\n            m.readout_maps_loss_op = tf.losses.sigmoid_cross_entropy(tf.reshape(m.readout_maps_gt, [-1, len(task_params.readout_maps_crop_sizes)]), tf.reshape(readout_maps, [-1, len(task_params.readout_maps_crop_sizes)]), scope='loss')\n            m.readout_maps_loss_op = 10.0 * m.readout_maps_loss_op\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=task_params.num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.arch.readout_maps:\n        m.total_loss_op = m.total_loss_op + m.readout_maps_loss_op\n        m.loss_ops += [m.readout_maps_loss_op]\n        m.loss_ops_names += ['readout_maps_loss']\n    m.loss_ops += [m.reg_loss_op, m.data_loss_op, m.total_loss_op]\n    m.loss_ops_names += ['reg_loss', 'data_loss', 'total_loss']\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(m.vision_ops.vars_to_restore))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    m.summary_ops = {summary_mode: _add_summaries(m, args, summary_mode, args.summary.arop_full_summary_iters)}\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert args.arch.multi_scale, 'removed support for old single scale code.'\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    m.train_ops = {}\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params)\n    m.init_fn = None\n    if task_params.input_type == 'vision':\n        m.vision_ops = get_map_from_images(m.input_tensors['step']['imgs'], args.mapper_arch, task_params, args.solver.freeze_conv, args.solver.wt_decay, is_training, batch_norm_is_training_op, num_maps=len(task_params.map_crop_sizes))\n        if args.solver.pretrained_path is not None:\n            m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, m.vision_ops.vars_to_restore)\n        if args.solver.freeze_conv:\n            m.train_ops['step_data_cache'] = [m.vision_ops.encoder_output]\n        else:\n            m.train_ops['step_data_cache'] = []\n        m.ego_map_ops = m.vision_ops.fss_logits\n        m.coverage_ops = m.vision_ops.confs_probs\n        for i in range(len(m.ego_map_ops)):\n            if args.mapper_arch.pad_map_with_zeros_each[i] > 0:\n                paddings = np.zeros((5, 2), dtype=np.int32)\n                paddings[2:4, :] = args.mapper_arch.pad_map_with_zeros_each[i]\n                paddings_op = tf.constant(paddings, dtype=tf.int32)\n                m.ego_map_ops[i] = tf.pad(m.ego_map_ops[i], paddings=paddings_op)\n                m.coverage_ops[i] = tf.pad(m.coverage_ops[i], paddings=paddings_op)\n    elif task_params.input_type == 'analytical_counts':\n        m.ego_map_ops = []\n        m.coverage_ops = []\n        for i in range(len(task_params.map_crop_sizes)):\n            ego_map_op = m.input_tensors['step']['analytical_counts_{:d}'.format(i)]\n            coverage_op = tf.cast(tf.greater_equal(tf.reduce_max(ego_map_op, reduction_indices=[4], keep_dims=True), 1), tf.float32)\n            coverage_op = tf.ones_like(ego_map_op) * coverage_op\n            m.ego_map_ops.append(ego_map_op)\n            m.coverage_ops.append(coverage_op)\n            m.train_ops['step_data_cache'] = []\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    map_crop_size_ops = []\n    for map_crop_size in task_params.map_crop_sizes:\n        map_crop_size_ops.append(tf.constant(map_crop_size, dtype=tf.int32, shape=(2,)))\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.ego_map_ops[0]), num=5)[1], 1)\n    fr_ops = []\n    value_ops = []\n    fr_intermediate_ops = []\n    value_intermediate_ops = []\n    crop_value_ops = []\n    resize_crop_value_ops = []\n    confs = []\n    occupancys = []\n    previous_value_op = None\n    updated_state = []\n    state_names = []\n    for i in range(len(task_params.map_crop_sizes)):\n        map_crop_size = task_params.map_crop_sizes[i]\n        with tf.variable_scope('scale_{:d}'.format(i)):\n            fn = lambda ns: running_combine(m.ego_map_ops[i], m.coverage_ops[i], m.input_tensors['step']['incremental_locs'] * task_params.map_scales[i], m.input_tensors['step']['incremental_thetas'], m.input_tensors['step']['running_sum_num_{:d}'.format(i)], m.input_tensors['step']['running_sum_denom_{:d}'.format(i)], m.input_tensors['step']['running_max_denom_{:d}'.format(i)], map_crop_size, ns)\n            (running_sum_num, running_sum_denom, running_max_denom) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps * num_goals))\n            updated_state += [running_sum_num, running_sum_denom, running_max_denom]\n            state_names += ['running_sum_num_{:d}'.format(i), 'running_sum_denom_{:d}'.format(i), 'running_max_denom_{:d}'.format(i)]\n            occupancy = running_sum_num / tf.maximum(running_sum_denom, 0.001)\n            conf = running_max_denom\n            with tf.name_scope('concat'):\n                sh = [-1, map_crop_size, map_crop_size, task_params.map_channels]\n                occupancy = tf.reshape(occupancy, shape=sh)\n                conf = tf.reshape(conf, shape=sh)\n                sh = [-1, map_crop_size, map_crop_size, task_params.goal_channels]\n                goal = tf.reshape(m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)], shape=sh)\n                to_concat = [occupancy, conf, goal]\n                if previous_value_op is not None:\n                    to_concat.append(previous_value_op)\n                x = tf.concat(to_concat, 3)\n            (fr_op, fr_intermediate_op) = fr_v2(x, output_neurons=args.arch.fr_neurons, inside_neurons=args.arch.fr_inside_neurons, is_training=batch_norm_is_training_op, name='fr', wt_decay=args.solver.wt_decay, stride=args.arch.fr_stride)\n            if args.arch.vin_num_iters > 0:\n                (value_op, value_intermediate_op) = value_iteration_network(fr_op, num_iters=args.arch.vin_num_iters, val_neurons=args.arch.vin_val_neurons, action_neurons=args.arch.vin_action_neurons, kernel_size=args.arch.vin_ks, share_wts=args.arch.vin_share_wts, name='vin', wt_decay=args.solver.wt_decay)\n            else:\n                value_op = fr_op\n                value_intermediate_op = []\n            remove = args.arch.crop_remove_each\n            if remove > 0:\n                crop_value_op = value_op[:, remove:-remove, remove:-remove, :]\n            else:\n                crop_value_op = value_op\n            crop_value_op = tf.reshape(crop_value_op, shape=[-1, args.arch.value_crop_size, args.arch.value_crop_size, args.arch.vin_val_neurons])\n            if i < len(task_params.map_crop_sizes) - 1:\n                previous_value_op = tf.image.resize_bilinear(crop_value_op, map_crop_size_ops[i + 1], align_corners=True)\n                resize_crop_value_ops.append(previous_value_op)\n            occupancys.append(occupancy)\n            confs.append(conf)\n            value_ops.append(value_op)\n            crop_value_ops.append(crop_value_op)\n            fr_ops.append(fr_op)\n            fr_intermediate_ops.append(fr_intermediate_op)\n    m.value_ops = value_ops\n    m.value_intermediate_ops = value_intermediate_ops\n    m.fr_ops = fr_ops\n    m.fr_intermediate_ops = fr_intermediate_ops\n    m.final_value_op = crop_value_op\n    m.crop_value_ops = crop_value_ops\n    m.resize_crop_value_ops = resize_crop_value_ops\n    m.confs = confs\n    m.occupancys = occupancys\n    sh = [-1, args.arch.vin_val_neurons * args.arch.value_crop_size ** 2]\n    m.value_features_op = tf.reshape(m.final_value_op, sh, name='reshape_value_op')\n    with tf.variable_scope('action_pred'):\n        batch_norm_param = args.arch.pred_batch_norm_param\n        if batch_norm_param is not None:\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.action_logits_op, _) = tf_utils.fc_network(m.value_features_op, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=task_params.num_actions, batch_norm_param=batch_norm_param)\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    init_state = tf.constant(0.0, dtype=tf.float32, shape=[task_params.batch_size, 1, map_crop_size, map_crop_size, task_params.map_channels])\n    m.train_ops['state_names'] = state_names\n    m.train_ops['updated_state'] = updated_state\n    m.train_ops['init_state'] = [init_state for _ in updated_state]\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc']]\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.loss_ops = []\n    m.loss_ops_names = []\n    if args.arch.readout_maps:\n        with tf.name_scope('readout_maps'):\n            all_occupancys = tf.concat(m.occupancys + m.confs, 3)\n            (readout_maps, probs) = readout_general(all_occupancys, num_neurons=args.arch.rom_arch.num_neurons, strides=args.arch.rom_arch.strides, layers_per_block=args.arch.rom_arch.layers_per_block, kernel_size=args.arch.rom_arch.kernel_size, batch_norm_is_training_op=batch_norm_is_training_op, wt_decay=args.solver.wt_decay)\n            gt_ego_maps = [m.input_tensors['step']['readout_maps_{:d}'.format(i)] for i in range(len(task_params.readout_maps_crop_sizes))]\n            m.readout_maps_gt = tf.concat(gt_ego_maps, 4)\n            gt_shape = tf.shape(m.readout_maps_gt)\n            m.readout_maps_logits = tf.reshape(readout_maps, gt_shape)\n            m.readout_maps_probs = tf.reshape(probs, gt_shape)\n            m.readout_maps_loss_op = tf.losses.sigmoid_cross_entropy(tf.reshape(m.readout_maps_gt, [-1, len(task_params.readout_maps_crop_sizes)]), tf.reshape(readout_maps, [-1, len(task_params.readout_maps_crop_sizes)]), scope='loss')\n            m.readout_maps_loss_op = 10.0 * m.readout_maps_loss_op\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=task_params.num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.arch.readout_maps:\n        m.total_loss_op = m.total_loss_op + m.readout_maps_loss_op\n        m.loss_ops += [m.readout_maps_loss_op]\n        m.loss_ops_names += ['readout_maps_loss']\n    m.loss_ops += [m.reg_loss_op, m.data_loss_op, m.total_loss_op]\n    m.loss_ops_names += ['reg_loss', 'data_loss', 'total_loss']\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(m.vision_ops.vars_to_restore))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    m.summary_ops = {summary_mode: _add_summaries(m, args, summary_mode, args.summary.arop_full_summary_iters)}\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m",
            "def setup_to_run(m, args, is_training, batch_norm_is_training, summary_mode):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert args.arch.multi_scale, 'removed support for old single scale code.'\n    tf.set_random_seed(args.solver.seed)\n    task_params = args.navtask.task_params\n    batch_norm_is_training_op = tf.placeholder_with_default(batch_norm_is_training, shape=[], name='batch_norm_is_training_op')\n    m.input_tensors = {}\n    m.train_ops = {}\n    (m.input_tensors['common'], m.input_tensors['step'], m.input_tensors['train']) = _inputs(task_params)\n    m.init_fn = None\n    if task_params.input_type == 'vision':\n        m.vision_ops = get_map_from_images(m.input_tensors['step']['imgs'], args.mapper_arch, task_params, args.solver.freeze_conv, args.solver.wt_decay, is_training, batch_norm_is_training_op, num_maps=len(task_params.map_crop_sizes))\n        if args.solver.pretrained_path is not None:\n            m.init_fn = slim.assign_from_checkpoint_fn(args.solver.pretrained_path, m.vision_ops.vars_to_restore)\n        if args.solver.freeze_conv:\n            m.train_ops['step_data_cache'] = [m.vision_ops.encoder_output]\n        else:\n            m.train_ops['step_data_cache'] = []\n        m.ego_map_ops = m.vision_ops.fss_logits\n        m.coverage_ops = m.vision_ops.confs_probs\n        for i in range(len(m.ego_map_ops)):\n            if args.mapper_arch.pad_map_with_zeros_each[i] > 0:\n                paddings = np.zeros((5, 2), dtype=np.int32)\n                paddings[2:4, :] = args.mapper_arch.pad_map_with_zeros_each[i]\n                paddings_op = tf.constant(paddings, dtype=tf.int32)\n                m.ego_map_ops[i] = tf.pad(m.ego_map_ops[i], paddings=paddings_op)\n                m.coverage_ops[i] = tf.pad(m.coverage_ops[i], paddings=paddings_op)\n    elif task_params.input_type == 'analytical_counts':\n        m.ego_map_ops = []\n        m.coverage_ops = []\n        for i in range(len(task_params.map_crop_sizes)):\n            ego_map_op = m.input_tensors['step']['analytical_counts_{:d}'.format(i)]\n            coverage_op = tf.cast(tf.greater_equal(tf.reduce_max(ego_map_op, reduction_indices=[4], keep_dims=True), 1), tf.float32)\n            coverage_op = tf.ones_like(ego_map_op) * coverage_op\n            m.ego_map_ops.append(ego_map_op)\n            m.coverage_ops.append(coverage_op)\n            m.train_ops['step_data_cache'] = []\n    num_steps = task_params.num_steps\n    num_goals = task_params.num_goals\n    map_crop_size_ops = []\n    for map_crop_size in task_params.map_crop_sizes:\n        map_crop_size_ops.append(tf.constant(map_crop_size, dtype=tf.int32, shape=(2,)))\n    with tf.name_scope('check_size'):\n        is_single_step = tf.equal(tf.unstack(tf.shape(m.ego_map_ops[0]), num=5)[1], 1)\n    fr_ops = []\n    value_ops = []\n    fr_intermediate_ops = []\n    value_intermediate_ops = []\n    crop_value_ops = []\n    resize_crop_value_ops = []\n    confs = []\n    occupancys = []\n    previous_value_op = None\n    updated_state = []\n    state_names = []\n    for i in range(len(task_params.map_crop_sizes)):\n        map_crop_size = task_params.map_crop_sizes[i]\n        with tf.variable_scope('scale_{:d}'.format(i)):\n            fn = lambda ns: running_combine(m.ego_map_ops[i], m.coverage_ops[i], m.input_tensors['step']['incremental_locs'] * task_params.map_scales[i], m.input_tensors['step']['incremental_thetas'], m.input_tensors['step']['running_sum_num_{:d}'.format(i)], m.input_tensors['step']['running_sum_denom_{:d}'.format(i)], m.input_tensors['step']['running_max_denom_{:d}'.format(i)], map_crop_size, ns)\n            (running_sum_num, running_sum_denom, running_max_denom) = tf.cond(is_single_step, lambda : fn(1), lambda : fn(num_steps * num_goals))\n            updated_state += [running_sum_num, running_sum_denom, running_max_denom]\n            state_names += ['running_sum_num_{:d}'.format(i), 'running_sum_denom_{:d}'.format(i), 'running_max_denom_{:d}'.format(i)]\n            occupancy = running_sum_num / tf.maximum(running_sum_denom, 0.001)\n            conf = running_max_denom\n            with tf.name_scope('concat'):\n                sh = [-1, map_crop_size, map_crop_size, task_params.map_channels]\n                occupancy = tf.reshape(occupancy, shape=sh)\n                conf = tf.reshape(conf, shape=sh)\n                sh = [-1, map_crop_size, map_crop_size, task_params.goal_channels]\n                goal = tf.reshape(m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)], shape=sh)\n                to_concat = [occupancy, conf, goal]\n                if previous_value_op is not None:\n                    to_concat.append(previous_value_op)\n                x = tf.concat(to_concat, 3)\n            (fr_op, fr_intermediate_op) = fr_v2(x, output_neurons=args.arch.fr_neurons, inside_neurons=args.arch.fr_inside_neurons, is_training=batch_norm_is_training_op, name='fr', wt_decay=args.solver.wt_decay, stride=args.arch.fr_stride)\n            if args.arch.vin_num_iters > 0:\n                (value_op, value_intermediate_op) = value_iteration_network(fr_op, num_iters=args.arch.vin_num_iters, val_neurons=args.arch.vin_val_neurons, action_neurons=args.arch.vin_action_neurons, kernel_size=args.arch.vin_ks, share_wts=args.arch.vin_share_wts, name='vin', wt_decay=args.solver.wt_decay)\n            else:\n                value_op = fr_op\n                value_intermediate_op = []\n            remove = args.arch.crop_remove_each\n            if remove > 0:\n                crop_value_op = value_op[:, remove:-remove, remove:-remove, :]\n            else:\n                crop_value_op = value_op\n            crop_value_op = tf.reshape(crop_value_op, shape=[-1, args.arch.value_crop_size, args.arch.value_crop_size, args.arch.vin_val_neurons])\n            if i < len(task_params.map_crop_sizes) - 1:\n                previous_value_op = tf.image.resize_bilinear(crop_value_op, map_crop_size_ops[i + 1], align_corners=True)\n                resize_crop_value_ops.append(previous_value_op)\n            occupancys.append(occupancy)\n            confs.append(conf)\n            value_ops.append(value_op)\n            crop_value_ops.append(crop_value_op)\n            fr_ops.append(fr_op)\n            fr_intermediate_ops.append(fr_intermediate_op)\n    m.value_ops = value_ops\n    m.value_intermediate_ops = value_intermediate_ops\n    m.fr_ops = fr_ops\n    m.fr_intermediate_ops = fr_intermediate_ops\n    m.final_value_op = crop_value_op\n    m.crop_value_ops = crop_value_ops\n    m.resize_crop_value_ops = resize_crop_value_ops\n    m.confs = confs\n    m.occupancys = occupancys\n    sh = [-1, args.arch.vin_val_neurons * args.arch.value_crop_size ** 2]\n    m.value_features_op = tf.reshape(m.final_value_op, sh, name='reshape_value_op')\n    with tf.variable_scope('action_pred'):\n        batch_norm_param = args.arch.pred_batch_norm_param\n        if batch_norm_param is not None:\n            batch_norm_param['is_training'] = batch_norm_is_training_op\n        (m.action_logits_op, _) = tf_utils.fc_network(m.value_features_op, neurons=args.arch.pred_neurons, wt_decay=args.solver.wt_decay, name='pred', offset=0, num_pred=task_params.num_actions, batch_norm_param=batch_norm_param)\n        m.action_prob_op = tf.nn.softmax(m.action_logits_op)\n    init_state = tf.constant(0.0, dtype=tf.float32, shape=[task_params.batch_size, 1, map_crop_size, map_crop_size, task_params.map_channels])\n    m.train_ops['state_names'] = state_names\n    m.train_ops['updated_state'] = updated_state\n    m.train_ops['init_state'] = [init_state for _ in updated_state]\n    m.train_ops['step'] = m.action_prob_op\n    m.train_ops['common'] = [m.input_tensors['common']['orig_maps'], m.input_tensors['common']['goal_loc']]\n    m.train_ops['batch_norm_is_training_op'] = batch_norm_is_training_op\n    m.loss_ops = []\n    m.loss_ops_names = []\n    if args.arch.readout_maps:\n        with tf.name_scope('readout_maps'):\n            all_occupancys = tf.concat(m.occupancys + m.confs, 3)\n            (readout_maps, probs) = readout_general(all_occupancys, num_neurons=args.arch.rom_arch.num_neurons, strides=args.arch.rom_arch.strides, layers_per_block=args.arch.rom_arch.layers_per_block, kernel_size=args.arch.rom_arch.kernel_size, batch_norm_is_training_op=batch_norm_is_training_op, wt_decay=args.solver.wt_decay)\n            gt_ego_maps = [m.input_tensors['step']['readout_maps_{:d}'.format(i)] for i in range(len(task_params.readout_maps_crop_sizes))]\n            m.readout_maps_gt = tf.concat(gt_ego_maps, 4)\n            gt_shape = tf.shape(m.readout_maps_gt)\n            m.readout_maps_logits = tf.reshape(readout_maps, gt_shape)\n            m.readout_maps_probs = tf.reshape(probs, gt_shape)\n            m.readout_maps_loss_op = tf.losses.sigmoid_cross_entropy(tf.reshape(m.readout_maps_gt, [-1, len(task_params.readout_maps_crop_sizes)]), tf.reshape(readout_maps, [-1, len(task_params.readout_maps_crop_sizes)]), scope='loss')\n            m.readout_maps_loss_op = 10.0 * m.readout_maps_loss_op\n    ewma_decay = 0.99 if is_training else 0.0\n    weight = tf.ones_like(m.input_tensors['train']['action'], dtype=tf.float32, name='weight')\n    (m.reg_loss_op, m.data_loss_op, m.total_loss_op, m.acc_ops) = compute_losses_multi_or(m.action_logits_op, m.input_tensors['train']['action'], weights=weight, num_actions=task_params.num_actions, data_loss_wt=args.solver.data_loss_wt, reg_loss_wt=args.solver.reg_loss_wt, ewma_decay=ewma_decay)\n    if args.arch.readout_maps:\n        m.total_loss_op = m.total_loss_op + m.readout_maps_loss_op\n        m.loss_ops += [m.readout_maps_loss_op]\n        m.loss_ops_names += ['readout_maps_loss']\n    m.loss_ops += [m.reg_loss_op, m.data_loss_op, m.total_loss_op]\n    m.loss_ops_names += ['reg_loss', 'data_loss', 'total_loss']\n    if args.solver.freeze_conv:\n        vars_to_optimize = list(set(tf.trainable_variables()) - set(m.vision_ops.vars_to_restore))\n    else:\n        vars_to_optimize = None\n    (m.lr_op, m.global_step_op, m.train_op, m.should_stop_op, m.optimizer, m.sync_optimizer) = tf_utils.setup_training(m.total_loss_op, args.solver.initial_learning_rate, args.solver.steps_per_decay, args.solver.learning_rate_decay, args.solver.momentum, args.solver.max_steps, args.solver.sync, args.solver.adjust_lr_sync, args.solver.num_workers, args.solver.task, vars_to_optimize=vars_to_optimize, clip_gradient_norm=args.solver.clip_gradient_norm, typ=args.solver.typ, momentum2=args.solver.momentum2, adam_eps=args.solver.adam_eps)\n    if args.arch.sample_gt_prob_type == 'inverse_sigmoid_decay':\n        m.sample_gt_prob_op = tf_utils.inverse_sigmoid_decay(args.arch.isd_k, m.global_step_op)\n    elif args.arch.sample_gt_prob_type == 'zero':\n        m.sample_gt_prob_op = tf.constant(-1.0, dtype=tf.float32)\n    elif args.arch.sample_gt_prob_type.split('_')[0] == 'step':\n        step = int(args.arch.sample_gt_prob_type.split('_')[1])\n        m.sample_gt_prob_op = tf_utils.step_gt_prob(step, m.input_tensors['step']['step_number'][0, 0, 0])\n    m.sample_action_type = args.arch.action_sample_type\n    m.sample_action_combine_type = args.arch.action_sample_combine_type\n    m.summary_ops = {summary_mode: _add_summaries(m, args, summary_mode, args.summary.arop_full_summary_iters)}\n    m.init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n    m.saver_op = tf.train.Saver(keep_checkpoint_every_n_hours=4, write_version=tf.train.SaverDef.V2)\n    return m"
        ]
    }
]