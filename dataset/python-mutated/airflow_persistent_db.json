[
    {
        "func_name": "__init__",
        "original": "def __init__(self, dagster_run: DagsterRun, uri: str, dag_run_config: Optional[dict]=None):\n    self.uri = uri\n    super().__init__(dagster_run=dagster_run, dag_run_config=dag_run_config)",
        "mutated": [
            "def __init__(self, dagster_run: DagsterRun, uri: str, dag_run_config: Optional[dict]=None):\n    if False:\n        i = 10\n    self.uri = uri\n    super().__init__(dagster_run=dagster_run, dag_run_config=dag_run_config)",
            "def __init__(self, dagster_run: DagsterRun, uri: str, dag_run_config: Optional[dict]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.uri = uri\n    super().__init__(dagster_run=dagster_run, dag_run_config=dag_run_config)",
            "def __init__(self, dagster_run: DagsterRun, uri: str, dag_run_config: Optional[dict]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.uri = uri\n    super().__init__(dagster_run=dagster_run, dag_run_config=dag_run_config)",
            "def __init__(self, dagster_run: DagsterRun, uri: str, dag_run_config: Optional[dict]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.uri = uri\n    super().__init__(dagster_run=dagster_run, dag_run_config=dag_run_config)",
            "def __init__(self, dagster_run: DagsterRun, uri: str, dag_run_config: Optional[dict]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.uri = uri\n    super().__init__(dagster_run=dagster_run, dag_run_config=dag_run_config)"
        ]
    },
    {
        "func_name": "_initialize_database",
        "original": "@staticmethod\ndef _initialize_database(uri: str, connections: List[Connection]=[]):\n    if is_airflow_2_loaded_in_environment('2.3.0'):\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow.configuration)\n        importlib.reload(airflow.settings)\n        importlib.reload(airflow)\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow)\n    create_airflow_connections(connections)",
        "mutated": [
            "@staticmethod\ndef _initialize_database(uri: str, connections: List[Connection]=[]):\n    if False:\n        i = 10\n    if is_airflow_2_loaded_in_environment('2.3.0'):\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow.configuration)\n        importlib.reload(airflow.settings)\n        importlib.reload(airflow)\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow)\n    create_airflow_connections(connections)",
            "@staticmethod\ndef _initialize_database(uri: str, connections: List[Connection]=[]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if is_airflow_2_loaded_in_environment('2.3.0'):\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow.configuration)\n        importlib.reload(airflow.settings)\n        importlib.reload(airflow)\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow)\n    create_airflow_connections(connections)",
            "@staticmethod\ndef _initialize_database(uri: str, connections: List[Connection]=[]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if is_airflow_2_loaded_in_environment('2.3.0'):\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow.configuration)\n        importlib.reload(airflow.settings)\n        importlib.reload(airflow)\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow)\n    create_airflow_connections(connections)",
            "@staticmethod\ndef _initialize_database(uri: str, connections: List[Connection]=[]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if is_airflow_2_loaded_in_environment('2.3.0'):\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow.configuration)\n        importlib.reload(airflow.settings)\n        importlib.reload(airflow)\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow)\n    create_airflow_connections(connections)",
            "@staticmethod\ndef _initialize_database(uri: str, connections: List[Connection]=[]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if is_airflow_2_loaded_in_environment('2.3.0'):\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow.configuration)\n        importlib.reload(airflow.settings)\n        importlib.reload(airflow)\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n        importlib.reload(airflow)\n    create_airflow_connections(connections)"
        ]
    },
    {
        "func_name": "from_resource_context",
        "original": "@staticmethod\ndef from_resource_context(context: InitResourceContext) -> 'AirflowPersistentDatabase':\n    uri = context.resource_config['uri']\n    AirflowPersistentDatabase._initialize_database(uri=uri, connections=[Connection(**c) for c in context.resource_config['connections']])\n    return AirflowPersistentDatabase(dagster_run=check.not_none(context.dagster_run, 'Context must have run'), uri=uri, dag_run_config=context.resource_config['dag_run_config'])",
        "mutated": [
            "@staticmethod\ndef from_resource_context(context: InitResourceContext) -> 'AirflowPersistentDatabase':\n    if False:\n        i = 10\n    uri = context.resource_config['uri']\n    AirflowPersistentDatabase._initialize_database(uri=uri, connections=[Connection(**c) for c in context.resource_config['connections']])\n    return AirflowPersistentDatabase(dagster_run=check.not_none(context.dagster_run, 'Context must have run'), uri=uri, dag_run_config=context.resource_config['dag_run_config'])",
            "@staticmethod\ndef from_resource_context(context: InitResourceContext) -> 'AirflowPersistentDatabase':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    uri = context.resource_config['uri']\n    AirflowPersistentDatabase._initialize_database(uri=uri, connections=[Connection(**c) for c in context.resource_config['connections']])\n    return AirflowPersistentDatabase(dagster_run=check.not_none(context.dagster_run, 'Context must have run'), uri=uri, dag_run_config=context.resource_config['dag_run_config'])",
            "@staticmethod\ndef from_resource_context(context: InitResourceContext) -> 'AirflowPersistentDatabase':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    uri = context.resource_config['uri']\n    AirflowPersistentDatabase._initialize_database(uri=uri, connections=[Connection(**c) for c in context.resource_config['connections']])\n    return AirflowPersistentDatabase(dagster_run=check.not_none(context.dagster_run, 'Context must have run'), uri=uri, dag_run_config=context.resource_config['dag_run_config'])",
            "@staticmethod\ndef from_resource_context(context: InitResourceContext) -> 'AirflowPersistentDatabase':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    uri = context.resource_config['uri']\n    AirflowPersistentDatabase._initialize_database(uri=uri, connections=[Connection(**c) for c in context.resource_config['connections']])\n    return AirflowPersistentDatabase(dagster_run=check.not_none(context.dagster_run, 'Context must have run'), uri=uri, dag_run_config=context.resource_config['dag_run_config'])",
            "@staticmethod\ndef from_resource_context(context: InitResourceContext) -> 'AirflowPersistentDatabase':\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    uri = context.resource_config['uri']\n    AirflowPersistentDatabase._initialize_database(uri=uri, connections=[Connection(**c) for c in context.resource_config['connections']])\n    return AirflowPersistentDatabase(dagster_run=check.not_none(context.dagster_run, 'Context must have run'), uri=uri, dag_run_config=context.resource_config['dag_run_config'])"
        ]
    },
    {
        "func_name": "make_persistent_airflow_db_resource",
        "original": "def make_persistent_airflow_db_resource(uri: str='', connections: List[Connection]=[], dag_run_config: Optional[dict]={}) -> ResourceDefinition:\n    \"\"\"Creates a Dagster resource that provides an persistent Airflow database.\n\n\n    Usage:\n        .. code-block:: python\n\n            from dagster_airflow import (\n                make_dagster_definitions_from_airflow_dags_path,\n                make_persistent_airflow_db_resource,\n            )\n            postgres_airflow_db = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\"\n            airflow_db = make_persistent_airflow_db_resource(uri=postgres_airflow_db)\n            definitions = make_dagster_definitions_from_airflow_example_dags(\n                '/path/to/dags/',\n                resource_defs={\"airflow_db\": airflow_db}\n            )\n\n\n    Args:\n        uri: SQLAlchemy URI of the Airflow DB to be used\n        connections (List[Connection]): List of Airflow Connections to be created in the Airflow DB\n        dag_run_config (Optional[dict]): dag_run configuration to be used when creating a DagRun\n\n    Returns:\n        ResourceDefinition: The persistent Airflow DB resource\n\n    \"\"\"\n    if is_airflow_2_loaded_in_environment():\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n    serialized_connections = serialize_connections(connections)\n    airflow_db_resource_def = ResourceDefinition(resource_fn=AirflowPersistentDatabase.from_resource_context, config_schema={'uri': Field(StringSource, default_value=uri, is_required=False), 'connections': Field(Array(inner_type=dict), default_value=serialized_connections, is_required=False), 'dag_run_config': Field(dict, default_value=dag_run_config, is_required=False)}, description='Persistent Airflow DB to be used by dagster-airflow ')\n    return airflow_db_resource_def",
        "mutated": [
            "def make_persistent_airflow_db_resource(uri: str='', connections: List[Connection]=[], dag_run_config: Optional[dict]={}) -> ResourceDefinition:\n    if False:\n        i = 10\n    'Creates a Dagster resource that provides an persistent Airflow database.\\n\\n\\n    Usage:\\n        .. code-block:: python\\n\\n            from dagster_airflow import (\\n                make_dagster_definitions_from_airflow_dags_path,\\n                make_persistent_airflow_db_resource,\\n            )\\n            postgres_airflow_db = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\"\\n            airflow_db = make_persistent_airflow_db_resource(uri=postgres_airflow_db)\\n            definitions = make_dagster_definitions_from_airflow_example_dags(\\n                \\'/path/to/dags/\\',\\n                resource_defs={\"airflow_db\": airflow_db}\\n            )\\n\\n\\n    Args:\\n        uri: SQLAlchemy URI of the Airflow DB to be used\\n        connections (List[Connection]): List of Airflow Connections to be created in the Airflow DB\\n        dag_run_config (Optional[dict]): dag_run configuration to be used when creating a DagRun\\n\\n    Returns:\\n        ResourceDefinition: The persistent Airflow DB resource\\n\\n    '\n    if is_airflow_2_loaded_in_environment():\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n    serialized_connections = serialize_connections(connections)\n    airflow_db_resource_def = ResourceDefinition(resource_fn=AirflowPersistentDatabase.from_resource_context, config_schema={'uri': Field(StringSource, default_value=uri, is_required=False), 'connections': Field(Array(inner_type=dict), default_value=serialized_connections, is_required=False), 'dag_run_config': Field(dict, default_value=dag_run_config, is_required=False)}, description='Persistent Airflow DB to be used by dagster-airflow ')\n    return airflow_db_resource_def",
            "def make_persistent_airflow_db_resource(uri: str='', connections: List[Connection]=[], dag_run_config: Optional[dict]={}) -> ResourceDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Creates a Dagster resource that provides an persistent Airflow database.\\n\\n\\n    Usage:\\n        .. code-block:: python\\n\\n            from dagster_airflow import (\\n                make_dagster_definitions_from_airflow_dags_path,\\n                make_persistent_airflow_db_resource,\\n            )\\n            postgres_airflow_db = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\"\\n            airflow_db = make_persistent_airflow_db_resource(uri=postgres_airflow_db)\\n            definitions = make_dagster_definitions_from_airflow_example_dags(\\n                \\'/path/to/dags/\\',\\n                resource_defs={\"airflow_db\": airflow_db}\\n            )\\n\\n\\n    Args:\\n        uri: SQLAlchemy URI of the Airflow DB to be used\\n        connections (List[Connection]): List of Airflow Connections to be created in the Airflow DB\\n        dag_run_config (Optional[dict]): dag_run configuration to be used when creating a DagRun\\n\\n    Returns:\\n        ResourceDefinition: The persistent Airflow DB resource\\n\\n    '\n    if is_airflow_2_loaded_in_environment():\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n    serialized_connections = serialize_connections(connections)\n    airflow_db_resource_def = ResourceDefinition(resource_fn=AirflowPersistentDatabase.from_resource_context, config_schema={'uri': Field(StringSource, default_value=uri, is_required=False), 'connections': Field(Array(inner_type=dict), default_value=serialized_connections, is_required=False), 'dag_run_config': Field(dict, default_value=dag_run_config, is_required=False)}, description='Persistent Airflow DB to be used by dagster-airflow ')\n    return airflow_db_resource_def",
            "def make_persistent_airflow_db_resource(uri: str='', connections: List[Connection]=[], dag_run_config: Optional[dict]={}) -> ResourceDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Creates a Dagster resource that provides an persistent Airflow database.\\n\\n\\n    Usage:\\n        .. code-block:: python\\n\\n            from dagster_airflow import (\\n                make_dagster_definitions_from_airflow_dags_path,\\n                make_persistent_airflow_db_resource,\\n            )\\n            postgres_airflow_db = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\"\\n            airflow_db = make_persistent_airflow_db_resource(uri=postgres_airflow_db)\\n            definitions = make_dagster_definitions_from_airflow_example_dags(\\n                \\'/path/to/dags/\\',\\n                resource_defs={\"airflow_db\": airflow_db}\\n            )\\n\\n\\n    Args:\\n        uri: SQLAlchemy URI of the Airflow DB to be used\\n        connections (List[Connection]): List of Airflow Connections to be created in the Airflow DB\\n        dag_run_config (Optional[dict]): dag_run configuration to be used when creating a DagRun\\n\\n    Returns:\\n        ResourceDefinition: The persistent Airflow DB resource\\n\\n    '\n    if is_airflow_2_loaded_in_environment():\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n    serialized_connections = serialize_connections(connections)\n    airflow_db_resource_def = ResourceDefinition(resource_fn=AirflowPersistentDatabase.from_resource_context, config_schema={'uri': Field(StringSource, default_value=uri, is_required=False), 'connections': Field(Array(inner_type=dict), default_value=serialized_connections, is_required=False), 'dag_run_config': Field(dict, default_value=dag_run_config, is_required=False)}, description='Persistent Airflow DB to be used by dagster-airflow ')\n    return airflow_db_resource_def",
            "def make_persistent_airflow_db_resource(uri: str='', connections: List[Connection]=[], dag_run_config: Optional[dict]={}) -> ResourceDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Creates a Dagster resource that provides an persistent Airflow database.\\n\\n\\n    Usage:\\n        .. code-block:: python\\n\\n            from dagster_airflow import (\\n                make_dagster_definitions_from_airflow_dags_path,\\n                make_persistent_airflow_db_resource,\\n            )\\n            postgres_airflow_db = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\"\\n            airflow_db = make_persistent_airflow_db_resource(uri=postgres_airflow_db)\\n            definitions = make_dagster_definitions_from_airflow_example_dags(\\n                \\'/path/to/dags/\\',\\n                resource_defs={\"airflow_db\": airflow_db}\\n            )\\n\\n\\n    Args:\\n        uri: SQLAlchemy URI of the Airflow DB to be used\\n        connections (List[Connection]): List of Airflow Connections to be created in the Airflow DB\\n        dag_run_config (Optional[dict]): dag_run configuration to be used when creating a DagRun\\n\\n    Returns:\\n        ResourceDefinition: The persistent Airflow DB resource\\n\\n    '\n    if is_airflow_2_loaded_in_environment():\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n    serialized_connections = serialize_connections(connections)\n    airflow_db_resource_def = ResourceDefinition(resource_fn=AirflowPersistentDatabase.from_resource_context, config_schema={'uri': Field(StringSource, default_value=uri, is_required=False), 'connections': Field(Array(inner_type=dict), default_value=serialized_connections, is_required=False), 'dag_run_config': Field(dict, default_value=dag_run_config, is_required=False)}, description='Persistent Airflow DB to be used by dagster-airflow ')\n    return airflow_db_resource_def",
            "def make_persistent_airflow_db_resource(uri: str='', connections: List[Connection]=[], dag_run_config: Optional[dict]={}) -> ResourceDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Creates a Dagster resource that provides an persistent Airflow database.\\n\\n\\n    Usage:\\n        .. code-block:: python\\n\\n            from dagster_airflow import (\\n                make_dagster_definitions_from_airflow_dags_path,\\n                make_persistent_airflow_db_resource,\\n            )\\n            postgres_airflow_db = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\"\\n            airflow_db = make_persistent_airflow_db_resource(uri=postgres_airflow_db)\\n            definitions = make_dagster_definitions_from_airflow_example_dags(\\n                \\'/path/to/dags/\\',\\n                resource_defs={\"airflow_db\": airflow_db}\\n            )\\n\\n\\n    Args:\\n        uri: SQLAlchemy URI of the Airflow DB to be used\\n        connections (List[Connection]): List of Airflow Connections to be created in the Airflow DB\\n        dag_run_config (Optional[dict]): dag_run configuration to be used when creating a DagRun\\n\\n    Returns:\\n        ResourceDefinition: The persistent Airflow DB resource\\n\\n    '\n    if is_airflow_2_loaded_in_environment():\n        os.environ['AIRFLOW__DATABASE__SQL_ALCHEMY_CONN'] = uri\n    else:\n        os.environ['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = uri\n    serialized_connections = serialize_connections(connections)\n    airflow_db_resource_def = ResourceDefinition(resource_fn=AirflowPersistentDatabase.from_resource_context, config_schema={'uri': Field(StringSource, default_value=uri, is_required=False), 'connections': Field(Array(inner_type=dict), default_value=serialized_connections, is_required=False), 'dag_run_config': Field(dict, default_value=dag_run_config, is_required=False)}, description='Persistent Airflow DB to be used by dagster-airflow ')\n    return airflow_db_resource_def"
        ]
    }
]