[
    {
        "func_name": "_t_fn",
        "original": "def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n    check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n    with tempfile.TemporaryDirectory() as output_notebook_dir:\n        executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n        with open(executed_notebook_path, 'rb') as fd:\n            yield Output(fd.read())\n        import scrapbook\n        output_nb = scrapbook.read_notebook(executed_notebook_path)\n        for (key, value) in output_nb.scraps.items():\n            if key.startswith('event-'):\n                with open(value.data, 'rb') as fd:\n                    event = pickle.loads(fd.read())\n                    if isinstance(event, (Failure, RetryRequested)):\n                        raise event\n                    else:\n                        yield event",
        "mutated": [
            "def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n    if False:\n        i = 10\n    check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n    with tempfile.TemporaryDirectory() as output_notebook_dir:\n        executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n        with open(executed_notebook_path, 'rb') as fd:\n            yield Output(fd.read())\n        import scrapbook\n        output_nb = scrapbook.read_notebook(executed_notebook_path)\n        for (key, value) in output_nb.scraps.items():\n            if key.startswith('event-'):\n                with open(value.data, 'rb') as fd:\n                    event = pickle.loads(fd.read())\n                    if isinstance(event, (Failure, RetryRequested)):\n                        raise event\n                    else:\n                        yield event",
            "def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n    with tempfile.TemporaryDirectory() as output_notebook_dir:\n        executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n        with open(executed_notebook_path, 'rb') as fd:\n            yield Output(fd.read())\n        import scrapbook\n        output_nb = scrapbook.read_notebook(executed_notebook_path)\n        for (key, value) in output_nb.scraps.items():\n            if key.startswith('event-'):\n                with open(value.data, 'rb') as fd:\n                    event = pickle.loads(fd.read())\n                    if isinstance(event, (Failure, RetryRequested)):\n                        raise event\n                    else:\n                        yield event",
            "def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n    with tempfile.TemporaryDirectory() as output_notebook_dir:\n        executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n        with open(executed_notebook_path, 'rb') as fd:\n            yield Output(fd.read())\n        import scrapbook\n        output_nb = scrapbook.read_notebook(executed_notebook_path)\n        for (key, value) in output_nb.scraps.items():\n            if key.startswith('event-'):\n                with open(value.data, 'rb') as fd:\n                    event = pickle.loads(fd.read())\n                    if isinstance(event, (Failure, RetryRequested)):\n                        raise event\n                    else:\n                        yield event",
            "def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n    with tempfile.TemporaryDirectory() as output_notebook_dir:\n        executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n        with open(executed_notebook_path, 'rb') as fd:\n            yield Output(fd.read())\n        import scrapbook\n        output_nb = scrapbook.read_notebook(executed_notebook_path)\n        for (key, value) in output_nb.scraps.items():\n            if key.startswith('event-'):\n                with open(value.data, 'rb') as fd:\n                    event = pickle.loads(fd.read())\n                    if isinstance(event, (Failure, RetryRequested)):\n                        raise event\n                    else:\n                        yield event",
            "def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n    with tempfile.TemporaryDirectory() as output_notebook_dir:\n        executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n        with open(executed_notebook_path, 'rb') as fd:\n            yield Output(fd.read())\n        import scrapbook\n        output_nb = scrapbook.read_notebook(executed_notebook_path)\n        for (key, value) in output_nb.scraps.items():\n            if key.startswith('event-'):\n                with open(value.data, 'rb') as fd:\n                    event = pickle.loads(fd.read())\n                    if isinstance(event, (Failure, RetryRequested)):\n                        raise event\n                    else:\n                        yield event"
        ]
    },
    {
        "func_name": "_make_dagstermill_asset_compute_fn",
        "original": "def _make_dagstermill_asset_compute_fn(name: str, notebook_path: str, save_notebook_on_failure: bool) -> Callable:\n\n    def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n        check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n        with tempfile.TemporaryDirectory() as output_notebook_dir:\n            executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n            with open(executed_notebook_path, 'rb') as fd:\n                yield Output(fd.read())\n            import scrapbook\n            output_nb = scrapbook.read_notebook(executed_notebook_path)\n            for (key, value) in output_nb.scraps.items():\n                if key.startswith('event-'):\n                    with open(value.data, 'rb') as fd:\n                        event = pickle.loads(fd.read())\n                        if isinstance(event, (Failure, RetryRequested)):\n                            raise event\n                        else:\n                            yield event\n    return _t_fn",
        "mutated": [
            "def _make_dagstermill_asset_compute_fn(name: str, notebook_path: str, save_notebook_on_failure: bool) -> Callable:\n    if False:\n        i = 10\n\n    def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n        check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n        with tempfile.TemporaryDirectory() as output_notebook_dir:\n            executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n            with open(executed_notebook_path, 'rb') as fd:\n                yield Output(fd.read())\n            import scrapbook\n            output_nb = scrapbook.read_notebook(executed_notebook_path)\n            for (key, value) in output_nb.scraps.items():\n                if key.startswith('event-'):\n                    with open(value.data, 'rb') as fd:\n                        event = pickle.loads(fd.read())\n                        if isinstance(event, (Failure, RetryRequested)):\n                            raise event\n                        else:\n                            yield event\n    return _t_fn",
            "def _make_dagstermill_asset_compute_fn(name: str, notebook_path: str, save_notebook_on_failure: bool) -> Callable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n        check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n        with tempfile.TemporaryDirectory() as output_notebook_dir:\n            executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n            with open(executed_notebook_path, 'rb') as fd:\n                yield Output(fd.read())\n            import scrapbook\n            output_nb = scrapbook.read_notebook(executed_notebook_path)\n            for (key, value) in output_nb.scraps.items():\n                if key.startswith('event-'):\n                    with open(value.data, 'rb') as fd:\n                        event = pickle.loads(fd.read())\n                        if isinstance(event, (Failure, RetryRequested)):\n                            raise event\n                        else:\n                            yield event\n    return _t_fn",
            "def _make_dagstermill_asset_compute_fn(name: str, notebook_path: str, save_notebook_on_failure: bool) -> Callable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n        check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n        with tempfile.TemporaryDirectory() as output_notebook_dir:\n            executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n            with open(executed_notebook_path, 'rb') as fd:\n                yield Output(fd.read())\n            import scrapbook\n            output_nb = scrapbook.read_notebook(executed_notebook_path)\n            for (key, value) in output_nb.scraps.items():\n                if key.startswith('event-'):\n                    with open(value.data, 'rb') as fd:\n                        event = pickle.loads(fd.read())\n                        if isinstance(event, (Failure, RetryRequested)):\n                            raise event\n                        else:\n                            yield event\n    return _t_fn",
            "def _make_dagstermill_asset_compute_fn(name: str, notebook_path: str, save_notebook_on_failure: bool) -> Callable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n        check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n        with tempfile.TemporaryDirectory() as output_notebook_dir:\n            executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n            with open(executed_notebook_path, 'rb') as fd:\n                yield Output(fd.read())\n            import scrapbook\n            output_nb = scrapbook.read_notebook(executed_notebook_path)\n            for (key, value) in output_nb.scraps.items():\n                if key.startswith('event-'):\n                    with open(value.data, 'rb') as fd:\n                        event = pickle.loads(fd.read())\n                        if isinstance(event, (Failure, RetryRequested)):\n                            raise event\n                        else:\n                            yield event\n    return _t_fn",
            "def _make_dagstermill_asset_compute_fn(name: str, notebook_path: str, save_notebook_on_failure: bool) -> Callable:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def _t_fn(context: OpExecutionContext, **inputs) -> Iterable:\n        check.param_invariant(isinstance(context.run_config, dict), 'context', 'StepExecutionContext must have valid run_config')\n        with tempfile.TemporaryDirectory() as output_notebook_dir:\n            executed_notebook_path = execute_notebook(context.get_step_execution_context(), name=name, inputs=inputs, save_notebook_on_failure=save_notebook_on_failure, notebook_path=notebook_path, output_notebook_dir=output_notebook_dir)\n            with open(executed_notebook_path, 'rb') as fd:\n                yield Output(fd.read())\n            import scrapbook\n            output_nb = scrapbook.read_notebook(executed_notebook_path)\n            for (key, value) in output_nb.scraps.items():\n                if key.startswith('event-'):\n                    with open(value.data, 'rb') as fd:\n                        event = pickle.loads(fd.read())\n                        if isinstance(event, (Failure, RetryRequested)):\n                            raise event\n                        else:\n                            yield event\n    return _t_fn"
        ]
    },
    {
        "func_name": "define_dagstermill_asset",
        "original": "def define_dagstermill_asset(name: str, notebook_path: str, key_prefix: Optional[CoercibleToAssetKeyPrefix]=None, ins: Optional[Mapping[str, AssetIn]]=None, deps: Optional[Iterable[Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset]]]=None, metadata: Optional[Mapping[str, Any]]=None, config_schema: Optional[Union[Any, Mapping[str, Any]]]=None, required_resource_keys: Optional[Set[str]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]=None, description: Optional[str]=None, partitions_def: Optional[PartitionsDefinition]=None, op_tags: Optional[Mapping[str, Any]]=None, group_name: Optional[str]=None, io_manager_key: Optional[str]=None, retry_policy: Optional[RetryPolicy]=None, save_notebook_on_failure: bool=False, non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]]=None) -> AssetsDefinition:\n    \"\"\"Creates a Dagster asset for a Jupyter notebook.\n\n    Arguments:\n        name (str): The name for the asset\n        notebook_path (str): Path to the backing notebook\n        key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset's key is the\n            concatenation of the key_prefix and the asset's name, which defaults to the name of\n            the decorated function. Each item in key_prefix must be a valid name in dagster (ie only\n            contains letters, numbers, and _) and may not contain python reserved keywords.\n        ins (Optional[Mapping[str, AssetIn]]): A dictionary that maps input names to information\n            about the input.\n        deps (Optional[Sequence[Union[AssetsDefinition, SourceAsset, AssetKey, str]]]): The assets\n            that are upstream dependencies, but do not pass an input value to the notebook.\n        config_schema (Optional[ConfigSchema): The configuration schema for the asset's underlying\n            op. If set, Dagster will check that config provided for the op matches this schema and fail\n            if it does not. If not set, Dagster will accept any config provided for the op.\n        metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.\n        required_resource_keys (Optional[Set[str]]): Set of resource handles required by the notebook.\n        description (Optional[str]): Description of the asset to display in the Dagster UI.\n        partitions_def (Optional[PartitionsDefinition]): Defines the set of partition keys that\n            compose the asset.\n        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.\n            Frameworks may expect and require certain metadata to be attached to a op. Values that\n            are not strings will be json encoded and must meet the criteria that\n            `json.loads(json.dumps(value)) == value`.\n        group_name (Optional[str]): A string name used to organize multiple assets into groups. If not provided,\n            the name \"default\" is used.\n        resource_defs (Optional[Mapping[str, ResourceDefinition]]):\n            (Experimental) A mapping of resource keys to resource definitions. These resources\n            will be initialized during execution, and can be accessed from the\n            context within the notebook.\n        io_manager_key (Optional[str]): A string key for the IO manager used to store the output notebook.\n            If not provided, the default key output_notebook_io_manager will be used.\n        retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.\n        save_notebook_on_failure (bool): If True and the notebook fails during execution, the failed notebook will be\n            written to the Dagster storage directory. The location of the file will be printed in the Dagster logs.\n            Defaults to False.\n        non_argument_deps (Optional[Union[Set[AssetKey], Set[str]]]): Deprecated, use deps instead. Set of asset keys that are\n            upstream dependencies, but do not pass an input to the asset.\n\n    Examples:\n        .. code-block:: python\n\n            from dagstermill import define_dagstermill_asset\n            from dagster import asset, AssetIn, AssetKey\n            from sklearn import datasets\n            import pandas as pd\n            import numpy as np\n\n            @asset\n            def iris_dataset():\n                sk_iris = datasets.load_iris()\n                return pd.DataFrame(\n                    data=np.c_[sk_iris[\"data\"], sk_iris[\"target\"]],\n                    columns=sk_iris[\"feature_names\"] + [\"target\"],\n                )\n\n            iris_kmeans_notebook = define_dagstermill_asset(\n                name=\"iris_kmeans_notebook\",\n                notebook_path=\"/path/to/iris_kmeans.ipynb\",\n                ins={\n                    \"iris\": AssetIn(key=AssetKey(\"iris_dataset\"))\n                }\n            )\n    \"\"\"\n    check.str_param(name, 'name')\n    check.str_param(notebook_path, 'notebook_path')\n    check.bool_param(save_notebook_on_failure, 'save_notebook_on_failure')\n    required_resource_keys = set(check.opt_set_param(required_resource_keys, 'required_resource_keys', of_type=str))\n    ins = check.opt_mapping_param(ins, 'ins', key_type=str, value_type=AssetIn)\n    if isinstance(key_prefix, str):\n        key_prefix = [key_prefix]\n    key_prefix = check.opt_list_param(key_prefix, 'key_prefix', of_type=str)\n    default_description = f'This asset is backed by the notebook at {notebook_path}'\n    description = check.opt_str_param(description, 'description', default=default_description)\n    io_mgr_key = check.opt_str_param(io_manager_key, 'io_manager_key', default='output_notebook_io_manager')\n    user_tags = validate_tags(op_tags)\n    if op_tags is not None:\n        check.invariant('notebook_path' not in op_tags, 'user-defined op tags contains the `notebook_path` key, but the `notebook_path` key is reserved for use by Dagster')\n        check.invariant('kind' not in op_tags, 'user-defined op tags contains the `kind` key, but the `kind` key is reserved for use by Dagster')\n    default_tags = {'notebook_path': _clean_path_for_windows(notebook_path), 'kind': 'ipynb'}\n    if safe_is_subclass(config_schema, Config):\n        config_schema = infer_schema_from_config_class(cast(Type[Config], config_schema))\n    return asset(name=name, key_prefix=key_prefix, ins=ins, deps=deps, metadata=metadata, description=description, config_schema=config_schema, required_resource_keys=required_resource_keys, resource_defs=resource_defs, partitions_def=partitions_def, op_tags={**user_tags, **default_tags}, group_name=group_name, output_required=False, io_manager_key=io_mgr_key, retry_policy=retry_policy, non_argument_deps=non_argument_deps)(_make_dagstermill_asset_compute_fn(name=name, notebook_path=notebook_path, save_notebook_on_failure=save_notebook_on_failure))",
        "mutated": [
            "def define_dagstermill_asset(name: str, notebook_path: str, key_prefix: Optional[CoercibleToAssetKeyPrefix]=None, ins: Optional[Mapping[str, AssetIn]]=None, deps: Optional[Iterable[Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset]]]=None, metadata: Optional[Mapping[str, Any]]=None, config_schema: Optional[Union[Any, Mapping[str, Any]]]=None, required_resource_keys: Optional[Set[str]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]=None, description: Optional[str]=None, partitions_def: Optional[PartitionsDefinition]=None, op_tags: Optional[Mapping[str, Any]]=None, group_name: Optional[str]=None, io_manager_key: Optional[str]=None, retry_policy: Optional[RetryPolicy]=None, save_notebook_on_failure: bool=False, non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]]=None) -> AssetsDefinition:\n    if False:\n        i = 10\n    'Creates a Dagster asset for a Jupyter notebook.\\n\\n    Arguments:\\n        name (str): The name for the asset\\n        notebook_path (str): Path to the backing notebook\\n        key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset\\'s key is the\\n            concatenation of the key_prefix and the asset\\'s name, which defaults to the name of\\n            the decorated function. Each item in key_prefix must be a valid name in dagster (ie only\\n            contains letters, numbers, and _) and may not contain python reserved keywords.\\n        ins (Optional[Mapping[str, AssetIn]]): A dictionary that maps input names to information\\n            about the input.\\n        deps (Optional[Sequence[Union[AssetsDefinition, SourceAsset, AssetKey, str]]]): The assets\\n            that are upstream dependencies, but do not pass an input value to the notebook.\\n        config_schema (Optional[ConfigSchema): The configuration schema for the asset\\'s underlying\\n            op. If set, Dagster will check that config provided for the op matches this schema and fail\\n            if it does not. If not set, Dagster will accept any config provided for the op.\\n        metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.\\n        required_resource_keys (Optional[Set[str]]): Set of resource handles required by the notebook.\\n        description (Optional[str]): Description of the asset to display in the Dagster UI.\\n        partitions_def (Optional[PartitionsDefinition]): Defines the set of partition keys that\\n            compose the asset.\\n        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.\\n            Frameworks may expect and require certain metadata to be attached to a op. Values that\\n            are not strings will be json encoded and must meet the criteria that\\n            `json.loads(json.dumps(value)) == value`.\\n        group_name (Optional[str]): A string name used to organize multiple assets into groups. If not provided,\\n            the name \"default\" is used.\\n        resource_defs (Optional[Mapping[str, ResourceDefinition]]):\\n            (Experimental) A mapping of resource keys to resource definitions. These resources\\n            will be initialized during execution, and can be accessed from the\\n            context within the notebook.\\n        io_manager_key (Optional[str]): A string key for the IO manager used to store the output notebook.\\n            If not provided, the default key output_notebook_io_manager will be used.\\n        retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.\\n        save_notebook_on_failure (bool): If True and the notebook fails during execution, the failed notebook will be\\n            written to the Dagster storage directory. The location of the file will be printed in the Dagster logs.\\n            Defaults to False.\\n        non_argument_deps (Optional[Union[Set[AssetKey], Set[str]]]): Deprecated, use deps instead. Set of asset keys that are\\n            upstream dependencies, but do not pass an input to the asset.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            from dagstermill import define_dagstermill_asset\\n            from dagster import asset, AssetIn, AssetKey\\n            from sklearn import datasets\\n            import pandas as pd\\n            import numpy as np\\n\\n            @asset\\n            def iris_dataset():\\n                sk_iris = datasets.load_iris()\\n                return pd.DataFrame(\\n                    data=np.c_[sk_iris[\"data\"], sk_iris[\"target\"]],\\n                    columns=sk_iris[\"feature_names\"] + [\"target\"],\\n                )\\n\\n            iris_kmeans_notebook = define_dagstermill_asset(\\n                name=\"iris_kmeans_notebook\",\\n                notebook_path=\"/path/to/iris_kmeans.ipynb\",\\n                ins={\\n                    \"iris\": AssetIn(key=AssetKey(\"iris_dataset\"))\\n                }\\n            )\\n    '\n    check.str_param(name, 'name')\n    check.str_param(notebook_path, 'notebook_path')\n    check.bool_param(save_notebook_on_failure, 'save_notebook_on_failure')\n    required_resource_keys = set(check.opt_set_param(required_resource_keys, 'required_resource_keys', of_type=str))\n    ins = check.opt_mapping_param(ins, 'ins', key_type=str, value_type=AssetIn)\n    if isinstance(key_prefix, str):\n        key_prefix = [key_prefix]\n    key_prefix = check.opt_list_param(key_prefix, 'key_prefix', of_type=str)\n    default_description = f'This asset is backed by the notebook at {notebook_path}'\n    description = check.opt_str_param(description, 'description', default=default_description)\n    io_mgr_key = check.opt_str_param(io_manager_key, 'io_manager_key', default='output_notebook_io_manager')\n    user_tags = validate_tags(op_tags)\n    if op_tags is not None:\n        check.invariant('notebook_path' not in op_tags, 'user-defined op tags contains the `notebook_path` key, but the `notebook_path` key is reserved for use by Dagster')\n        check.invariant('kind' not in op_tags, 'user-defined op tags contains the `kind` key, but the `kind` key is reserved for use by Dagster')\n    default_tags = {'notebook_path': _clean_path_for_windows(notebook_path), 'kind': 'ipynb'}\n    if safe_is_subclass(config_schema, Config):\n        config_schema = infer_schema_from_config_class(cast(Type[Config], config_schema))\n    return asset(name=name, key_prefix=key_prefix, ins=ins, deps=deps, metadata=metadata, description=description, config_schema=config_schema, required_resource_keys=required_resource_keys, resource_defs=resource_defs, partitions_def=partitions_def, op_tags={**user_tags, **default_tags}, group_name=group_name, output_required=False, io_manager_key=io_mgr_key, retry_policy=retry_policy, non_argument_deps=non_argument_deps)(_make_dagstermill_asset_compute_fn(name=name, notebook_path=notebook_path, save_notebook_on_failure=save_notebook_on_failure))",
            "def define_dagstermill_asset(name: str, notebook_path: str, key_prefix: Optional[CoercibleToAssetKeyPrefix]=None, ins: Optional[Mapping[str, AssetIn]]=None, deps: Optional[Iterable[Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset]]]=None, metadata: Optional[Mapping[str, Any]]=None, config_schema: Optional[Union[Any, Mapping[str, Any]]]=None, required_resource_keys: Optional[Set[str]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]=None, description: Optional[str]=None, partitions_def: Optional[PartitionsDefinition]=None, op_tags: Optional[Mapping[str, Any]]=None, group_name: Optional[str]=None, io_manager_key: Optional[str]=None, retry_policy: Optional[RetryPolicy]=None, save_notebook_on_failure: bool=False, non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]]=None) -> AssetsDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Creates a Dagster asset for a Jupyter notebook.\\n\\n    Arguments:\\n        name (str): The name for the asset\\n        notebook_path (str): Path to the backing notebook\\n        key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset\\'s key is the\\n            concatenation of the key_prefix and the asset\\'s name, which defaults to the name of\\n            the decorated function. Each item in key_prefix must be a valid name in dagster (ie only\\n            contains letters, numbers, and _) and may not contain python reserved keywords.\\n        ins (Optional[Mapping[str, AssetIn]]): A dictionary that maps input names to information\\n            about the input.\\n        deps (Optional[Sequence[Union[AssetsDefinition, SourceAsset, AssetKey, str]]]): The assets\\n            that are upstream dependencies, but do not pass an input value to the notebook.\\n        config_schema (Optional[ConfigSchema): The configuration schema for the asset\\'s underlying\\n            op. If set, Dagster will check that config provided for the op matches this schema and fail\\n            if it does not. If not set, Dagster will accept any config provided for the op.\\n        metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.\\n        required_resource_keys (Optional[Set[str]]): Set of resource handles required by the notebook.\\n        description (Optional[str]): Description of the asset to display in the Dagster UI.\\n        partitions_def (Optional[PartitionsDefinition]): Defines the set of partition keys that\\n            compose the asset.\\n        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.\\n            Frameworks may expect and require certain metadata to be attached to a op. Values that\\n            are not strings will be json encoded and must meet the criteria that\\n            `json.loads(json.dumps(value)) == value`.\\n        group_name (Optional[str]): A string name used to organize multiple assets into groups. If not provided,\\n            the name \"default\" is used.\\n        resource_defs (Optional[Mapping[str, ResourceDefinition]]):\\n            (Experimental) A mapping of resource keys to resource definitions. These resources\\n            will be initialized during execution, and can be accessed from the\\n            context within the notebook.\\n        io_manager_key (Optional[str]): A string key for the IO manager used to store the output notebook.\\n            If not provided, the default key output_notebook_io_manager will be used.\\n        retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.\\n        save_notebook_on_failure (bool): If True and the notebook fails during execution, the failed notebook will be\\n            written to the Dagster storage directory. The location of the file will be printed in the Dagster logs.\\n            Defaults to False.\\n        non_argument_deps (Optional[Union[Set[AssetKey], Set[str]]]): Deprecated, use deps instead. Set of asset keys that are\\n            upstream dependencies, but do not pass an input to the asset.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            from dagstermill import define_dagstermill_asset\\n            from dagster import asset, AssetIn, AssetKey\\n            from sklearn import datasets\\n            import pandas as pd\\n            import numpy as np\\n\\n            @asset\\n            def iris_dataset():\\n                sk_iris = datasets.load_iris()\\n                return pd.DataFrame(\\n                    data=np.c_[sk_iris[\"data\"], sk_iris[\"target\"]],\\n                    columns=sk_iris[\"feature_names\"] + [\"target\"],\\n                )\\n\\n            iris_kmeans_notebook = define_dagstermill_asset(\\n                name=\"iris_kmeans_notebook\",\\n                notebook_path=\"/path/to/iris_kmeans.ipynb\",\\n                ins={\\n                    \"iris\": AssetIn(key=AssetKey(\"iris_dataset\"))\\n                }\\n            )\\n    '\n    check.str_param(name, 'name')\n    check.str_param(notebook_path, 'notebook_path')\n    check.bool_param(save_notebook_on_failure, 'save_notebook_on_failure')\n    required_resource_keys = set(check.opt_set_param(required_resource_keys, 'required_resource_keys', of_type=str))\n    ins = check.opt_mapping_param(ins, 'ins', key_type=str, value_type=AssetIn)\n    if isinstance(key_prefix, str):\n        key_prefix = [key_prefix]\n    key_prefix = check.opt_list_param(key_prefix, 'key_prefix', of_type=str)\n    default_description = f'This asset is backed by the notebook at {notebook_path}'\n    description = check.opt_str_param(description, 'description', default=default_description)\n    io_mgr_key = check.opt_str_param(io_manager_key, 'io_manager_key', default='output_notebook_io_manager')\n    user_tags = validate_tags(op_tags)\n    if op_tags is not None:\n        check.invariant('notebook_path' not in op_tags, 'user-defined op tags contains the `notebook_path` key, but the `notebook_path` key is reserved for use by Dagster')\n        check.invariant('kind' not in op_tags, 'user-defined op tags contains the `kind` key, but the `kind` key is reserved for use by Dagster')\n    default_tags = {'notebook_path': _clean_path_for_windows(notebook_path), 'kind': 'ipynb'}\n    if safe_is_subclass(config_schema, Config):\n        config_schema = infer_schema_from_config_class(cast(Type[Config], config_schema))\n    return asset(name=name, key_prefix=key_prefix, ins=ins, deps=deps, metadata=metadata, description=description, config_schema=config_schema, required_resource_keys=required_resource_keys, resource_defs=resource_defs, partitions_def=partitions_def, op_tags={**user_tags, **default_tags}, group_name=group_name, output_required=False, io_manager_key=io_mgr_key, retry_policy=retry_policy, non_argument_deps=non_argument_deps)(_make_dagstermill_asset_compute_fn(name=name, notebook_path=notebook_path, save_notebook_on_failure=save_notebook_on_failure))",
            "def define_dagstermill_asset(name: str, notebook_path: str, key_prefix: Optional[CoercibleToAssetKeyPrefix]=None, ins: Optional[Mapping[str, AssetIn]]=None, deps: Optional[Iterable[Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset]]]=None, metadata: Optional[Mapping[str, Any]]=None, config_schema: Optional[Union[Any, Mapping[str, Any]]]=None, required_resource_keys: Optional[Set[str]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]=None, description: Optional[str]=None, partitions_def: Optional[PartitionsDefinition]=None, op_tags: Optional[Mapping[str, Any]]=None, group_name: Optional[str]=None, io_manager_key: Optional[str]=None, retry_policy: Optional[RetryPolicy]=None, save_notebook_on_failure: bool=False, non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]]=None) -> AssetsDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Creates a Dagster asset for a Jupyter notebook.\\n\\n    Arguments:\\n        name (str): The name for the asset\\n        notebook_path (str): Path to the backing notebook\\n        key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset\\'s key is the\\n            concatenation of the key_prefix and the asset\\'s name, which defaults to the name of\\n            the decorated function. Each item in key_prefix must be a valid name in dagster (ie only\\n            contains letters, numbers, and _) and may not contain python reserved keywords.\\n        ins (Optional[Mapping[str, AssetIn]]): A dictionary that maps input names to information\\n            about the input.\\n        deps (Optional[Sequence[Union[AssetsDefinition, SourceAsset, AssetKey, str]]]): The assets\\n            that are upstream dependencies, but do not pass an input value to the notebook.\\n        config_schema (Optional[ConfigSchema): The configuration schema for the asset\\'s underlying\\n            op. If set, Dagster will check that config provided for the op matches this schema and fail\\n            if it does not. If not set, Dagster will accept any config provided for the op.\\n        metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.\\n        required_resource_keys (Optional[Set[str]]): Set of resource handles required by the notebook.\\n        description (Optional[str]): Description of the asset to display in the Dagster UI.\\n        partitions_def (Optional[PartitionsDefinition]): Defines the set of partition keys that\\n            compose the asset.\\n        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.\\n            Frameworks may expect and require certain metadata to be attached to a op. Values that\\n            are not strings will be json encoded and must meet the criteria that\\n            `json.loads(json.dumps(value)) == value`.\\n        group_name (Optional[str]): A string name used to organize multiple assets into groups. If not provided,\\n            the name \"default\" is used.\\n        resource_defs (Optional[Mapping[str, ResourceDefinition]]):\\n            (Experimental) A mapping of resource keys to resource definitions. These resources\\n            will be initialized during execution, and can be accessed from the\\n            context within the notebook.\\n        io_manager_key (Optional[str]): A string key for the IO manager used to store the output notebook.\\n            If not provided, the default key output_notebook_io_manager will be used.\\n        retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.\\n        save_notebook_on_failure (bool): If True and the notebook fails during execution, the failed notebook will be\\n            written to the Dagster storage directory. The location of the file will be printed in the Dagster logs.\\n            Defaults to False.\\n        non_argument_deps (Optional[Union[Set[AssetKey], Set[str]]]): Deprecated, use deps instead. Set of asset keys that are\\n            upstream dependencies, but do not pass an input to the asset.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            from dagstermill import define_dagstermill_asset\\n            from dagster import asset, AssetIn, AssetKey\\n            from sklearn import datasets\\n            import pandas as pd\\n            import numpy as np\\n\\n            @asset\\n            def iris_dataset():\\n                sk_iris = datasets.load_iris()\\n                return pd.DataFrame(\\n                    data=np.c_[sk_iris[\"data\"], sk_iris[\"target\"]],\\n                    columns=sk_iris[\"feature_names\"] + [\"target\"],\\n                )\\n\\n            iris_kmeans_notebook = define_dagstermill_asset(\\n                name=\"iris_kmeans_notebook\",\\n                notebook_path=\"/path/to/iris_kmeans.ipynb\",\\n                ins={\\n                    \"iris\": AssetIn(key=AssetKey(\"iris_dataset\"))\\n                }\\n            )\\n    '\n    check.str_param(name, 'name')\n    check.str_param(notebook_path, 'notebook_path')\n    check.bool_param(save_notebook_on_failure, 'save_notebook_on_failure')\n    required_resource_keys = set(check.opt_set_param(required_resource_keys, 'required_resource_keys', of_type=str))\n    ins = check.opt_mapping_param(ins, 'ins', key_type=str, value_type=AssetIn)\n    if isinstance(key_prefix, str):\n        key_prefix = [key_prefix]\n    key_prefix = check.opt_list_param(key_prefix, 'key_prefix', of_type=str)\n    default_description = f'This asset is backed by the notebook at {notebook_path}'\n    description = check.opt_str_param(description, 'description', default=default_description)\n    io_mgr_key = check.opt_str_param(io_manager_key, 'io_manager_key', default='output_notebook_io_manager')\n    user_tags = validate_tags(op_tags)\n    if op_tags is not None:\n        check.invariant('notebook_path' not in op_tags, 'user-defined op tags contains the `notebook_path` key, but the `notebook_path` key is reserved for use by Dagster')\n        check.invariant('kind' not in op_tags, 'user-defined op tags contains the `kind` key, but the `kind` key is reserved for use by Dagster')\n    default_tags = {'notebook_path': _clean_path_for_windows(notebook_path), 'kind': 'ipynb'}\n    if safe_is_subclass(config_schema, Config):\n        config_schema = infer_schema_from_config_class(cast(Type[Config], config_schema))\n    return asset(name=name, key_prefix=key_prefix, ins=ins, deps=deps, metadata=metadata, description=description, config_schema=config_schema, required_resource_keys=required_resource_keys, resource_defs=resource_defs, partitions_def=partitions_def, op_tags={**user_tags, **default_tags}, group_name=group_name, output_required=False, io_manager_key=io_mgr_key, retry_policy=retry_policy, non_argument_deps=non_argument_deps)(_make_dagstermill_asset_compute_fn(name=name, notebook_path=notebook_path, save_notebook_on_failure=save_notebook_on_failure))",
            "def define_dagstermill_asset(name: str, notebook_path: str, key_prefix: Optional[CoercibleToAssetKeyPrefix]=None, ins: Optional[Mapping[str, AssetIn]]=None, deps: Optional[Iterable[Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset]]]=None, metadata: Optional[Mapping[str, Any]]=None, config_schema: Optional[Union[Any, Mapping[str, Any]]]=None, required_resource_keys: Optional[Set[str]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]=None, description: Optional[str]=None, partitions_def: Optional[PartitionsDefinition]=None, op_tags: Optional[Mapping[str, Any]]=None, group_name: Optional[str]=None, io_manager_key: Optional[str]=None, retry_policy: Optional[RetryPolicy]=None, save_notebook_on_failure: bool=False, non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]]=None) -> AssetsDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Creates a Dagster asset for a Jupyter notebook.\\n\\n    Arguments:\\n        name (str): The name for the asset\\n        notebook_path (str): Path to the backing notebook\\n        key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset\\'s key is the\\n            concatenation of the key_prefix and the asset\\'s name, which defaults to the name of\\n            the decorated function. Each item in key_prefix must be a valid name in dagster (ie only\\n            contains letters, numbers, and _) and may not contain python reserved keywords.\\n        ins (Optional[Mapping[str, AssetIn]]): A dictionary that maps input names to information\\n            about the input.\\n        deps (Optional[Sequence[Union[AssetsDefinition, SourceAsset, AssetKey, str]]]): The assets\\n            that are upstream dependencies, but do not pass an input value to the notebook.\\n        config_schema (Optional[ConfigSchema): The configuration schema for the asset\\'s underlying\\n            op. If set, Dagster will check that config provided for the op matches this schema and fail\\n            if it does not. If not set, Dagster will accept any config provided for the op.\\n        metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.\\n        required_resource_keys (Optional[Set[str]]): Set of resource handles required by the notebook.\\n        description (Optional[str]): Description of the asset to display in the Dagster UI.\\n        partitions_def (Optional[PartitionsDefinition]): Defines the set of partition keys that\\n            compose the asset.\\n        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.\\n            Frameworks may expect and require certain metadata to be attached to a op. Values that\\n            are not strings will be json encoded and must meet the criteria that\\n            `json.loads(json.dumps(value)) == value`.\\n        group_name (Optional[str]): A string name used to organize multiple assets into groups. If not provided,\\n            the name \"default\" is used.\\n        resource_defs (Optional[Mapping[str, ResourceDefinition]]):\\n            (Experimental) A mapping of resource keys to resource definitions. These resources\\n            will be initialized during execution, and can be accessed from the\\n            context within the notebook.\\n        io_manager_key (Optional[str]): A string key for the IO manager used to store the output notebook.\\n            If not provided, the default key output_notebook_io_manager will be used.\\n        retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.\\n        save_notebook_on_failure (bool): If True and the notebook fails during execution, the failed notebook will be\\n            written to the Dagster storage directory. The location of the file will be printed in the Dagster logs.\\n            Defaults to False.\\n        non_argument_deps (Optional[Union[Set[AssetKey], Set[str]]]): Deprecated, use deps instead. Set of asset keys that are\\n            upstream dependencies, but do not pass an input to the asset.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            from dagstermill import define_dagstermill_asset\\n            from dagster import asset, AssetIn, AssetKey\\n            from sklearn import datasets\\n            import pandas as pd\\n            import numpy as np\\n\\n            @asset\\n            def iris_dataset():\\n                sk_iris = datasets.load_iris()\\n                return pd.DataFrame(\\n                    data=np.c_[sk_iris[\"data\"], sk_iris[\"target\"]],\\n                    columns=sk_iris[\"feature_names\"] + [\"target\"],\\n                )\\n\\n            iris_kmeans_notebook = define_dagstermill_asset(\\n                name=\"iris_kmeans_notebook\",\\n                notebook_path=\"/path/to/iris_kmeans.ipynb\",\\n                ins={\\n                    \"iris\": AssetIn(key=AssetKey(\"iris_dataset\"))\\n                }\\n            )\\n    '\n    check.str_param(name, 'name')\n    check.str_param(notebook_path, 'notebook_path')\n    check.bool_param(save_notebook_on_failure, 'save_notebook_on_failure')\n    required_resource_keys = set(check.opt_set_param(required_resource_keys, 'required_resource_keys', of_type=str))\n    ins = check.opt_mapping_param(ins, 'ins', key_type=str, value_type=AssetIn)\n    if isinstance(key_prefix, str):\n        key_prefix = [key_prefix]\n    key_prefix = check.opt_list_param(key_prefix, 'key_prefix', of_type=str)\n    default_description = f'This asset is backed by the notebook at {notebook_path}'\n    description = check.opt_str_param(description, 'description', default=default_description)\n    io_mgr_key = check.opt_str_param(io_manager_key, 'io_manager_key', default='output_notebook_io_manager')\n    user_tags = validate_tags(op_tags)\n    if op_tags is not None:\n        check.invariant('notebook_path' not in op_tags, 'user-defined op tags contains the `notebook_path` key, but the `notebook_path` key is reserved for use by Dagster')\n        check.invariant('kind' not in op_tags, 'user-defined op tags contains the `kind` key, but the `kind` key is reserved for use by Dagster')\n    default_tags = {'notebook_path': _clean_path_for_windows(notebook_path), 'kind': 'ipynb'}\n    if safe_is_subclass(config_schema, Config):\n        config_schema = infer_schema_from_config_class(cast(Type[Config], config_schema))\n    return asset(name=name, key_prefix=key_prefix, ins=ins, deps=deps, metadata=metadata, description=description, config_schema=config_schema, required_resource_keys=required_resource_keys, resource_defs=resource_defs, partitions_def=partitions_def, op_tags={**user_tags, **default_tags}, group_name=group_name, output_required=False, io_manager_key=io_mgr_key, retry_policy=retry_policy, non_argument_deps=non_argument_deps)(_make_dagstermill_asset_compute_fn(name=name, notebook_path=notebook_path, save_notebook_on_failure=save_notebook_on_failure))",
            "def define_dagstermill_asset(name: str, notebook_path: str, key_prefix: Optional[CoercibleToAssetKeyPrefix]=None, ins: Optional[Mapping[str, AssetIn]]=None, deps: Optional[Iterable[Union[CoercibleToAssetKey, AssetsDefinition, SourceAsset]]]=None, metadata: Optional[Mapping[str, Any]]=None, config_schema: Optional[Union[Any, Mapping[str, Any]]]=None, required_resource_keys: Optional[Set[str]]=None, resource_defs: Optional[Mapping[str, ResourceDefinition]]=None, description: Optional[str]=None, partitions_def: Optional[PartitionsDefinition]=None, op_tags: Optional[Mapping[str, Any]]=None, group_name: Optional[str]=None, io_manager_key: Optional[str]=None, retry_policy: Optional[RetryPolicy]=None, save_notebook_on_failure: bool=False, non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]]=None) -> AssetsDefinition:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Creates a Dagster asset for a Jupyter notebook.\\n\\n    Arguments:\\n        name (str): The name for the asset\\n        notebook_path (str): Path to the backing notebook\\n        key_prefix (Optional[Union[str, Sequence[str]]]): If provided, the asset\\'s key is the\\n            concatenation of the key_prefix and the asset\\'s name, which defaults to the name of\\n            the decorated function. Each item in key_prefix must be a valid name in dagster (ie only\\n            contains letters, numbers, and _) and may not contain python reserved keywords.\\n        ins (Optional[Mapping[str, AssetIn]]): A dictionary that maps input names to information\\n            about the input.\\n        deps (Optional[Sequence[Union[AssetsDefinition, SourceAsset, AssetKey, str]]]): The assets\\n            that are upstream dependencies, but do not pass an input value to the notebook.\\n        config_schema (Optional[ConfigSchema): The configuration schema for the asset\\'s underlying\\n            op. If set, Dagster will check that config provided for the op matches this schema and fail\\n            if it does not. If not set, Dagster will accept any config provided for the op.\\n        metadata (Optional[Dict[str, Any]]): A dict of metadata entries for the asset.\\n        required_resource_keys (Optional[Set[str]]): Set of resource handles required by the notebook.\\n        description (Optional[str]): Description of the asset to display in the Dagster UI.\\n        partitions_def (Optional[PartitionsDefinition]): Defines the set of partition keys that\\n            compose the asset.\\n        op_tags (Optional[Dict[str, Any]]): A dictionary of tags for the op that computes the asset.\\n            Frameworks may expect and require certain metadata to be attached to a op. Values that\\n            are not strings will be json encoded and must meet the criteria that\\n            `json.loads(json.dumps(value)) == value`.\\n        group_name (Optional[str]): A string name used to organize multiple assets into groups. If not provided,\\n            the name \"default\" is used.\\n        resource_defs (Optional[Mapping[str, ResourceDefinition]]):\\n            (Experimental) A mapping of resource keys to resource definitions. These resources\\n            will be initialized during execution, and can be accessed from the\\n            context within the notebook.\\n        io_manager_key (Optional[str]): A string key for the IO manager used to store the output notebook.\\n            If not provided, the default key output_notebook_io_manager will be used.\\n        retry_policy (Optional[RetryPolicy]): The retry policy for the op that computes the asset.\\n        save_notebook_on_failure (bool): If True and the notebook fails during execution, the failed notebook will be\\n            written to the Dagster storage directory. The location of the file will be printed in the Dagster logs.\\n            Defaults to False.\\n        non_argument_deps (Optional[Union[Set[AssetKey], Set[str]]]): Deprecated, use deps instead. Set of asset keys that are\\n            upstream dependencies, but do not pass an input to the asset.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            from dagstermill import define_dagstermill_asset\\n            from dagster import asset, AssetIn, AssetKey\\n            from sklearn import datasets\\n            import pandas as pd\\n            import numpy as np\\n\\n            @asset\\n            def iris_dataset():\\n                sk_iris = datasets.load_iris()\\n                return pd.DataFrame(\\n                    data=np.c_[sk_iris[\"data\"], sk_iris[\"target\"]],\\n                    columns=sk_iris[\"feature_names\"] + [\"target\"],\\n                )\\n\\n            iris_kmeans_notebook = define_dagstermill_asset(\\n                name=\"iris_kmeans_notebook\",\\n                notebook_path=\"/path/to/iris_kmeans.ipynb\",\\n                ins={\\n                    \"iris\": AssetIn(key=AssetKey(\"iris_dataset\"))\\n                }\\n            )\\n    '\n    check.str_param(name, 'name')\n    check.str_param(notebook_path, 'notebook_path')\n    check.bool_param(save_notebook_on_failure, 'save_notebook_on_failure')\n    required_resource_keys = set(check.opt_set_param(required_resource_keys, 'required_resource_keys', of_type=str))\n    ins = check.opt_mapping_param(ins, 'ins', key_type=str, value_type=AssetIn)\n    if isinstance(key_prefix, str):\n        key_prefix = [key_prefix]\n    key_prefix = check.opt_list_param(key_prefix, 'key_prefix', of_type=str)\n    default_description = f'This asset is backed by the notebook at {notebook_path}'\n    description = check.opt_str_param(description, 'description', default=default_description)\n    io_mgr_key = check.opt_str_param(io_manager_key, 'io_manager_key', default='output_notebook_io_manager')\n    user_tags = validate_tags(op_tags)\n    if op_tags is not None:\n        check.invariant('notebook_path' not in op_tags, 'user-defined op tags contains the `notebook_path` key, but the `notebook_path` key is reserved for use by Dagster')\n        check.invariant('kind' not in op_tags, 'user-defined op tags contains the `kind` key, but the `kind` key is reserved for use by Dagster')\n    default_tags = {'notebook_path': _clean_path_for_windows(notebook_path), 'kind': 'ipynb'}\n    if safe_is_subclass(config_schema, Config):\n        config_schema = infer_schema_from_config_class(cast(Type[Config], config_schema))\n    return asset(name=name, key_prefix=key_prefix, ins=ins, deps=deps, metadata=metadata, description=description, config_schema=config_schema, required_resource_keys=required_resource_keys, resource_defs=resource_defs, partitions_def=partitions_def, op_tags={**user_tags, **default_tags}, group_name=group_name, output_required=False, io_manager_key=io_mgr_key, retry_policy=retry_policy, non_argument_deps=non_argument_deps)(_make_dagstermill_asset_compute_fn(name=name, notebook_path=notebook_path, save_notebook_on_failure=save_notebook_on_failure))"
        ]
    }
]