[
    {
        "func_name": "main",
        "original": "def main(_):\n    \"\"\"Runs fine-tuning and inference.\n\n  There are three categories of images.\n  1) Images where we have previous and next frame, and that are not filtered\n     out by the heuristic. For them, we will use the fine-tuned predictions.\n  2) Images where we have previous and next frame, but that were filtered out\n     by our heuristic. For them, we will use the ordinary prediction instead.\n  3) Images where we have at least one missing adjacent frame. For them, we will\n     use the ordinary prediction as indicated by triplet_list_file_remains (if\n     provided). They will also not be part of the generated inference list in\n     the first place.\n\n  Raises:\n     ValueError: Invalid parameters have been passed.\n  \"\"\"\n    if FLAGS.handle_motion and FLAGS.joint_encoder:\n        raise ValueError('Using a joint encoder is currently not supported when modeling object motion.')\n    if FLAGS.handle_motion and FLAGS.seq_length != 3:\n        raise ValueError('The current motion model implementation only supports using a sequence length of three.')\n    if FLAGS.handle_motion and (not FLAGS.compute_minimum_loss):\n        raise ValueError('Computing the minimum photometric loss is required when enabling object motion handling.')\n    if FLAGS.size_constraint_weight > 0 and (not FLAGS.handle_motion):\n        raise ValueError('To enforce object size constraints, enable motion handling.')\n    if FLAGS.icp_weight > 0.0:\n        raise ValueError('ICP is currently not supported.')\n    if FLAGS.compute_minimum_loss and FLAGS.seq_length % 2 != 1:\n        raise ValueError('Compute minimum loss requires using an odd number of images in a sequence.')\n    if FLAGS.compute_minimum_loss and FLAGS.exhaustive_mode:\n        raise ValueError('Exhaustive mode has no effect when compute_minimum_loss is enabled.')\n    if FLAGS.img_width % 2 ** 5 != 0 or FLAGS.img_height % 2 ** 5 != 0:\n        logging.warn('Image size is not divisible by 2^5. For the architecture employed, this could cause artefacts caused by resizing in lower dimensions.')\n    if FLAGS.output_dir.endswith('/'):\n        FLAGS.output_dir = FLAGS.output_dir[:-1]\n    unique_file_name = str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '_')\n    unique_file = os.path.join(FLAGS.data_dir, unique_file_name + '.txt')\n    with gfile.FastGFile(FLAGS.triplet_list_file, 'r') as f:\n        files_to_process = f.readlines()\n        files_to_process = [line.rstrip() for line in files_to_process]\n        files_to_process = [line for line in files_to_process if len(line)]\n    logging.info('Creating unique file list %s with %s entries.', unique_file, len(files_to_process))\n    with gfile.FastGFile(unique_file, 'w') as f_out:\n        fetches_network = FLAGS.num_steps * FLAGS.batch_size\n        fetches_saves = FLAGS.batch_size * int(np.floor(FLAGS.num_steps / SAVE_EVERY))\n        repetitions = fetches_network + 3 * fetches_saves\n        for i in range(len(files_to_process)):\n            for _ in range(repetitions):\n                f_out.write(files_to_process[i] + '\\n')\n    remaining = []\n    if gfile.Exists(FLAGS.triplet_list_file_remains):\n        with gfile.FastGFile(FLAGS.triplet_list_file_remains, 'r') as f:\n            remaining = f.readlines()\n            remaining = [line.rstrip() for line in remaining]\n            remaining = [line for line in remaining if len(line)]\n    logging.info('Running fine-tuning on %s files, %s files are remaining.', len(files_to_process), len(remaining))\n    tf.set_random_seed(FIXED_SEED)\n    np.random.seed(FIXED_SEED)\n    random.seed(FIXED_SEED)\n    flipping_mode = reader.FLIP_ALWAYS if FLAGS.flip else reader.FLIP_NONE\n    train_model = model.Model(data_dir=FLAGS.data_dir, file_extension=FLAGS.file_extension, is_training=True, learning_rate=FLAGS.learning_rate, beta1=FLAGS.beta1, reconstr_weight=FLAGS.reconstr_weight, smooth_weight=FLAGS.smooth_weight, ssim_weight=FLAGS.ssim_weight, icp_weight=FLAGS.icp_weight, batch_size=FLAGS.batch_size, img_height=FLAGS.img_height, img_width=FLAGS.img_width, seq_length=FLAGS.seq_length, architecture=FLAGS.architecture, imagenet_norm=FLAGS.imagenet_norm, weight_reg=FLAGS.weight_reg, exhaustive_mode=FLAGS.exhaustive_mode, random_scale_crop=FLAGS.random_scale_crop, flipping_mode=flipping_mode, random_color=False, depth_upsampling=FLAGS.depth_upsampling, depth_normalization=FLAGS.depth_normalization, compute_minimum_loss=FLAGS.compute_minimum_loss, use_skip=FLAGS.use_skip, joint_encoder=FLAGS.joint_encoder, build_sum=False, shuffle=False, input_file=unique_file_name, handle_motion=FLAGS.handle_motion, size_constraint_weight=FLAGS.size_constraint_weight, train_global_scale_var=False)\n    failed_heuristic_ids = finetune_inference(train_model, FLAGS.model_ckpt, FLAGS.output_dir + '_ft')\n    logging.info('Fine-tuning completed, %s files were filtered out by heuristic.', len(failed_heuristic_ids))\n    for failed_id in failed_heuristic_ids:\n        failed_entry = files_to_process[failed_id]\n        remaining.append(failed_entry)\n    logging.info('In total, %s images were fine-tuned, while %s were not.', len(files_to_process) - len(failed_heuristic_ids), len(remaining))\n    for i in range(len(files_to_process)):\n        if files_to_process[i] not in remaining:\n            elements = files_to_process[i].split(' ')\n            source_file = os.path.join(FLAGS.output_dir + '_ft', FLAGS.ft_name + 'id_' + str(i), str(FLAGS.num_steps).zfill(10) + ('_flip' if FLAGS.flip else ''))\n            if len(elements) == 2:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n                target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n            else:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n                target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n            if not gfile.Exists(target_dir):\n                gfile.MakeDirs(target_dir)\n            logging.info('Copy refined result %s to %s.', source_file, target_file)\n            gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n            gfile.Copy(source_file + '.txt', target_file + '.txt', overwrite=True)\n            gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    for j in range(len(remaining)):\n        elements = remaining[j].split(' ')\n        if len(elements) == 2:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n            target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n        else:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n            target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n        if not gfile.Exists(target_dir):\n            gfile.MakeDirs(target_dir)\n        source_file = target_file.replace('_ft', '')\n        logging.info('Copy unrefined result %s to %s.', source_file, target_file)\n        gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n        gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    logging.info('Done, predictions saved in %s.', FLAGS.output_dir + '_ft')",
        "mutated": [
            "def main(_):\n    if False:\n        i = 10\n    'Runs fine-tuning and inference.\\n\\n  There are three categories of images.\\n  1) Images where we have previous and next frame, and that are not filtered\\n     out by the heuristic. For them, we will use the fine-tuned predictions.\\n  2) Images where we have previous and next frame, but that were filtered out\\n     by our heuristic. For them, we will use the ordinary prediction instead.\\n  3) Images where we have at least one missing adjacent frame. For them, we will\\n     use the ordinary prediction as indicated by triplet_list_file_remains (if\\n     provided). They will also not be part of the generated inference list in\\n     the first place.\\n\\n  Raises:\\n     ValueError: Invalid parameters have been passed.\\n  '\n    if FLAGS.handle_motion and FLAGS.joint_encoder:\n        raise ValueError('Using a joint encoder is currently not supported when modeling object motion.')\n    if FLAGS.handle_motion and FLAGS.seq_length != 3:\n        raise ValueError('The current motion model implementation only supports using a sequence length of three.')\n    if FLAGS.handle_motion and (not FLAGS.compute_minimum_loss):\n        raise ValueError('Computing the minimum photometric loss is required when enabling object motion handling.')\n    if FLAGS.size_constraint_weight > 0 and (not FLAGS.handle_motion):\n        raise ValueError('To enforce object size constraints, enable motion handling.')\n    if FLAGS.icp_weight > 0.0:\n        raise ValueError('ICP is currently not supported.')\n    if FLAGS.compute_minimum_loss and FLAGS.seq_length % 2 != 1:\n        raise ValueError('Compute minimum loss requires using an odd number of images in a sequence.')\n    if FLAGS.compute_minimum_loss and FLAGS.exhaustive_mode:\n        raise ValueError('Exhaustive mode has no effect when compute_minimum_loss is enabled.')\n    if FLAGS.img_width % 2 ** 5 != 0 or FLAGS.img_height % 2 ** 5 != 0:\n        logging.warn('Image size is not divisible by 2^5. For the architecture employed, this could cause artefacts caused by resizing in lower dimensions.')\n    if FLAGS.output_dir.endswith('/'):\n        FLAGS.output_dir = FLAGS.output_dir[:-1]\n    unique_file_name = str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '_')\n    unique_file = os.path.join(FLAGS.data_dir, unique_file_name + '.txt')\n    with gfile.FastGFile(FLAGS.triplet_list_file, 'r') as f:\n        files_to_process = f.readlines()\n        files_to_process = [line.rstrip() for line in files_to_process]\n        files_to_process = [line for line in files_to_process if len(line)]\n    logging.info('Creating unique file list %s with %s entries.', unique_file, len(files_to_process))\n    with gfile.FastGFile(unique_file, 'w') as f_out:\n        fetches_network = FLAGS.num_steps * FLAGS.batch_size\n        fetches_saves = FLAGS.batch_size * int(np.floor(FLAGS.num_steps / SAVE_EVERY))\n        repetitions = fetches_network + 3 * fetches_saves\n        for i in range(len(files_to_process)):\n            for _ in range(repetitions):\n                f_out.write(files_to_process[i] + '\\n')\n    remaining = []\n    if gfile.Exists(FLAGS.triplet_list_file_remains):\n        with gfile.FastGFile(FLAGS.triplet_list_file_remains, 'r') as f:\n            remaining = f.readlines()\n            remaining = [line.rstrip() for line in remaining]\n            remaining = [line for line in remaining if len(line)]\n    logging.info('Running fine-tuning on %s files, %s files are remaining.', len(files_to_process), len(remaining))\n    tf.set_random_seed(FIXED_SEED)\n    np.random.seed(FIXED_SEED)\n    random.seed(FIXED_SEED)\n    flipping_mode = reader.FLIP_ALWAYS if FLAGS.flip else reader.FLIP_NONE\n    train_model = model.Model(data_dir=FLAGS.data_dir, file_extension=FLAGS.file_extension, is_training=True, learning_rate=FLAGS.learning_rate, beta1=FLAGS.beta1, reconstr_weight=FLAGS.reconstr_weight, smooth_weight=FLAGS.smooth_weight, ssim_weight=FLAGS.ssim_weight, icp_weight=FLAGS.icp_weight, batch_size=FLAGS.batch_size, img_height=FLAGS.img_height, img_width=FLAGS.img_width, seq_length=FLAGS.seq_length, architecture=FLAGS.architecture, imagenet_norm=FLAGS.imagenet_norm, weight_reg=FLAGS.weight_reg, exhaustive_mode=FLAGS.exhaustive_mode, random_scale_crop=FLAGS.random_scale_crop, flipping_mode=flipping_mode, random_color=False, depth_upsampling=FLAGS.depth_upsampling, depth_normalization=FLAGS.depth_normalization, compute_minimum_loss=FLAGS.compute_minimum_loss, use_skip=FLAGS.use_skip, joint_encoder=FLAGS.joint_encoder, build_sum=False, shuffle=False, input_file=unique_file_name, handle_motion=FLAGS.handle_motion, size_constraint_weight=FLAGS.size_constraint_weight, train_global_scale_var=False)\n    failed_heuristic_ids = finetune_inference(train_model, FLAGS.model_ckpt, FLAGS.output_dir + '_ft')\n    logging.info('Fine-tuning completed, %s files were filtered out by heuristic.', len(failed_heuristic_ids))\n    for failed_id in failed_heuristic_ids:\n        failed_entry = files_to_process[failed_id]\n        remaining.append(failed_entry)\n    logging.info('In total, %s images were fine-tuned, while %s were not.', len(files_to_process) - len(failed_heuristic_ids), len(remaining))\n    for i in range(len(files_to_process)):\n        if files_to_process[i] not in remaining:\n            elements = files_to_process[i].split(' ')\n            source_file = os.path.join(FLAGS.output_dir + '_ft', FLAGS.ft_name + 'id_' + str(i), str(FLAGS.num_steps).zfill(10) + ('_flip' if FLAGS.flip else ''))\n            if len(elements) == 2:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n                target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n            else:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n                target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n            if not gfile.Exists(target_dir):\n                gfile.MakeDirs(target_dir)\n            logging.info('Copy refined result %s to %s.', source_file, target_file)\n            gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n            gfile.Copy(source_file + '.txt', target_file + '.txt', overwrite=True)\n            gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    for j in range(len(remaining)):\n        elements = remaining[j].split(' ')\n        if len(elements) == 2:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n            target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n        else:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n            target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n        if not gfile.Exists(target_dir):\n            gfile.MakeDirs(target_dir)\n        source_file = target_file.replace('_ft', '')\n        logging.info('Copy unrefined result %s to %s.', source_file, target_file)\n        gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n        gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    logging.info('Done, predictions saved in %s.', FLAGS.output_dir + '_ft')",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Runs fine-tuning and inference.\\n\\n  There are three categories of images.\\n  1) Images where we have previous and next frame, and that are not filtered\\n     out by the heuristic. For them, we will use the fine-tuned predictions.\\n  2) Images where we have previous and next frame, but that were filtered out\\n     by our heuristic. For them, we will use the ordinary prediction instead.\\n  3) Images where we have at least one missing adjacent frame. For them, we will\\n     use the ordinary prediction as indicated by triplet_list_file_remains (if\\n     provided). They will also not be part of the generated inference list in\\n     the first place.\\n\\n  Raises:\\n     ValueError: Invalid parameters have been passed.\\n  '\n    if FLAGS.handle_motion and FLAGS.joint_encoder:\n        raise ValueError('Using a joint encoder is currently not supported when modeling object motion.')\n    if FLAGS.handle_motion and FLAGS.seq_length != 3:\n        raise ValueError('The current motion model implementation only supports using a sequence length of three.')\n    if FLAGS.handle_motion and (not FLAGS.compute_minimum_loss):\n        raise ValueError('Computing the minimum photometric loss is required when enabling object motion handling.')\n    if FLAGS.size_constraint_weight > 0 and (not FLAGS.handle_motion):\n        raise ValueError('To enforce object size constraints, enable motion handling.')\n    if FLAGS.icp_weight > 0.0:\n        raise ValueError('ICP is currently not supported.')\n    if FLAGS.compute_minimum_loss and FLAGS.seq_length % 2 != 1:\n        raise ValueError('Compute minimum loss requires using an odd number of images in a sequence.')\n    if FLAGS.compute_minimum_loss and FLAGS.exhaustive_mode:\n        raise ValueError('Exhaustive mode has no effect when compute_minimum_loss is enabled.')\n    if FLAGS.img_width % 2 ** 5 != 0 or FLAGS.img_height % 2 ** 5 != 0:\n        logging.warn('Image size is not divisible by 2^5. For the architecture employed, this could cause artefacts caused by resizing in lower dimensions.')\n    if FLAGS.output_dir.endswith('/'):\n        FLAGS.output_dir = FLAGS.output_dir[:-1]\n    unique_file_name = str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '_')\n    unique_file = os.path.join(FLAGS.data_dir, unique_file_name + '.txt')\n    with gfile.FastGFile(FLAGS.triplet_list_file, 'r') as f:\n        files_to_process = f.readlines()\n        files_to_process = [line.rstrip() for line in files_to_process]\n        files_to_process = [line for line in files_to_process if len(line)]\n    logging.info('Creating unique file list %s with %s entries.', unique_file, len(files_to_process))\n    with gfile.FastGFile(unique_file, 'w') as f_out:\n        fetches_network = FLAGS.num_steps * FLAGS.batch_size\n        fetches_saves = FLAGS.batch_size * int(np.floor(FLAGS.num_steps / SAVE_EVERY))\n        repetitions = fetches_network + 3 * fetches_saves\n        for i in range(len(files_to_process)):\n            for _ in range(repetitions):\n                f_out.write(files_to_process[i] + '\\n')\n    remaining = []\n    if gfile.Exists(FLAGS.triplet_list_file_remains):\n        with gfile.FastGFile(FLAGS.triplet_list_file_remains, 'r') as f:\n            remaining = f.readlines()\n            remaining = [line.rstrip() for line in remaining]\n            remaining = [line for line in remaining if len(line)]\n    logging.info('Running fine-tuning on %s files, %s files are remaining.', len(files_to_process), len(remaining))\n    tf.set_random_seed(FIXED_SEED)\n    np.random.seed(FIXED_SEED)\n    random.seed(FIXED_SEED)\n    flipping_mode = reader.FLIP_ALWAYS if FLAGS.flip else reader.FLIP_NONE\n    train_model = model.Model(data_dir=FLAGS.data_dir, file_extension=FLAGS.file_extension, is_training=True, learning_rate=FLAGS.learning_rate, beta1=FLAGS.beta1, reconstr_weight=FLAGS.reconstr_weight, smooth_weight=FLAGS.smooth_weight, ssim_weight=FLAGS.ssim_weight, icp_weight=FLAGS.icp_weight, batch_size=FLAGS.batch_size, img_height=FLAGS.img_height, img_width=FLAGS.img_width, seq_length=FLAGS.seq_length, architecture=FLAGS.architecture, imagenet_norm=FLAGS.imagenet_norm, weight_reg=FLAGS.weight_reg, exhaustive_mode=FLAGS.exhaustive_mode, random_scale_crop=FLAGS.random_scale_crop, flipping_mode=flipping_mode, random_color=False, depth_upsampling=FLAGS.depth_upsampling, depth_normalization=FLAGS.depth_normalization, compute_minimum_loss=FLAGS.compute_minimum_loss, use_skip=FLAGS.use_skip, joint_encoder=FLAGS.joint_encoder, build_sum=False, shuffle=False, input_file=unique_file_name, handle_motion=FLAGS.handle_motion, size_constraint_weight=FLAGS.size_constraint_weight, train_global_scale_var=False)\n    failed_heuristic_ids = finetune_inference(train_model, FLAGS.model_ckpt, FLAGS.output_dir + '_ft')\n    logging.info('Fine-tuning completed, %s files were filtered out by heuristic.', len(failed_heuristic_ids))\n    for failed_id in failed_heuristic_ids:\n        failed_entry = files_to_process[failed_id]\n        remaining.append(failed_entry)\n    logging.info('In total, %s images were fine-tuned, while %s were not.', len(files_to_process) - len(failed_heuristic_ids), len(remaining))\n    for i in range(len(files_to_process)):\n        if files_to_process[i] not in remaining:\n            elements = files_to_process[i].split(' ')\n            source_file = os.path.join(FLAGS.output_dir + '_ft', FLAGS.ft_name + 'id_' + str(i), str(FLAGS.num_steps).zfill(10) + ('_flip' if FLAGS.flip else ''))\n            if len(elements) == 2:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n                target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n            else:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n                target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n            if not gfile.Exists(target_dir):\n                gfile.MakeDirs(target_dir)\n            logging.info('Copy refined result %s to %s.', source_file, target_file)\n            gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n            gfile.Copy(source_file + '.txt', target_file + '.txt', overwrite=True)\n            gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    for j in range(len(remaining)):\n        elements = remaining[j].split(' ')\n        if len(elements) == 2:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n            target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n        else:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n            target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n        if not gfile.Exists(target_dir):\n            gfile.MakeDirs(target_dir)\n        source_file = target_file.replace('_ft', '')\n        logging.info('Copy unrefined result %s to %s.', source_file, target_file)\n        gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n        gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    logging.info('Done, predictions saved in %s.', FLAGS.output_dir + '_ft')",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Runs fine-tuning and inference.\\n\\n  There are three categories of images.\\n  1) Images where we have previous and next frame, and that are not filtered\\n     out by the heuristic. For them, we will use the fine-tuned predictions.\\n  2) Images where we have previous and next frame, but that were filtered out\\n     by our heuristic. For them, we will use the ordinary prediction instead.\\n  3) Images where we have at least one missing adjacent frame. For them, we will\\n     use the ordinary prediction as indicated by triplet_list_file_remains (if\\n     provided). They will also not be part of the generated inference list in\\n     the first place.\\n\\n  Raises:\\n     ValueError: Invalid parameters have been passed.\\n  '\n    if FLAGS.handle_motion and FLAGS.joint_encoder:\n        raise ValueError('Using a joint encoder is currently not supported when modeling object motion.')\n    if FLAGS.handle_motion and FLAGS.seq_length != 3:\n        raise ValueError('The current motion model implementation only supports using a sequence length of three.')\n    if FLAGS.handle_motion and (not FLAGS.compute_minimum_loss):\n        raise ValueError('Computing the minimum photometric loss is required when enabling object motion handling.')\n    if FLAGS.size_constraint_weight > 0 and (not FLAGS.handle_motion):\n        raise ValueError('To enforce object size constraints, enable motion handling.')\n    if FLAGS.icp_weight > 0.0:\n        raise ValueError('ICP is currently not supported.')\n    if FLAGS.compute_minimum_loss and FLAGS.seq_length % 2 != 1:\n        raise ValueError('Compute minimum loss requires using an odd number of images in a sequence.')\n    if FLAGS.compute_minimum_loss and FLAGS.exhaustive_mode:\n        raise ValueError('Exhaustive mode has no effect when compute_minimum_loss is enabled.')\n    if FLAGS.img_width % 2 ** 5 != 0 or FLAGS.img_height % 2 ** 5 != 0:\n        logging.warn('Image size is not divisible by 2^5. For the architecture employed, this could cause artefacts caused by resizing in lower dimensions.')\n    if FLAGS.output_dir.endswith('/'):\n        FLAGS.output_dir = FLAGS.output_dir[:-1]\n    unique_file_name = str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '_')\n    unique_file = os.path.join(FLAGS.data_dir, unique_file_name + '.txt')\n    with gfile.FastGFile(FLAGS.triplet_list_file, 'r') as f:\n        files_to_process = f.readlines()\n        files_to_process = [line.rstrip() for line in files_to_process]\n        files_to_process = [line for line in files_to_process if len(line)]\n    logging.info('Creating unique file list %s with %s entries.', unique_file, len(files_to_process))\n    with gfile.FastGFile(unique_file, 'w') as f_out:\n        fetches_network = FLAGS.num_steps * FLAGS.batch_size\n        fetches_saves = FLAGS.batch_size * int(np.floor(FLAGS.num_steps / SAVE_EVERY))\n        repetitions = fetches_network + 3 * fetches_saves\n        for i in range(len(files_to_process)):\n            for _ in range(repetitions):\n                f_out.write(files_to_process[i] + '\\n')\n    remaining = []\n    if gfile.Exists(FLAGS.triplet_list_file_remains):\n        with gfile.FastGFile(FLAGS.triplet_list_file_remains, 'r') as f:\n            remaining = f.readlines()\n            remaining = [line.rstrip() for line in remaining]\n            remaining = [line for line in remaining if len(line)]\n    logging.info('Running fine-tuning on %s files, %s files are remaining.', len(files_to_process), len(remaining))\n    tf.set_random_seed(FIXED_SEED)\n    np.random.seed(FIXED_SEED)\n    random.seed(FIXED_SEED)\n    flipping_mode = reader.FLIP_ALWAYS if FLAGS.flip else reader.FLIP_NONE\n    train_model = model.Model(data_dir=FLAGS.data_dir, file_extension=FLAGS.file_extension, is_training=True, learning_rate=FLAGS.learning_rate, beta1=FLAGS.beta1, reconstr_weight=FLAGS.reconstr_weight, smooth_weight=FLAGS.smooth_weight, ssim_weight=FLAGS.ssim_weight, icp_weight=FLAGS.icp_weight, batch_size=FLAGS.batch_size, img_height=FLAGS.img_height, img_width=FLAGS.img_width, seq_length=FLAGS.seq_length, architecture=FLAGS.architecture, imagenet_norm=FLAGS.imagenet_norm, weight_reg=FLAGS.weight_reg, exhaustive_mode=FLAGS.exhaustive_mode, random_scale_crop=FLAGS.random_scale_crop, flipping_mode=flipping_mode, random_color=False, depth_upsampling=FLAGS.depth_upsampling, depth_normalization=FLAGS.depth_normalization, compute_minimum_loss=FLAGS.compute_minimum_loss, use_skip=FLAGS.use_skip, joint_encoder=FLAGS.joint_encoder, build_sum=False, shuffle=False, input_file=unique_file_name, handle_motion=FLAGS.handle_motion, size_constraint_weight=FLAGS.size_constraint_weight, train_global_scale_var=False)\n    failed_heuristic_ids = finetune_inference(train_model, FLAGS.model_ckpt, FLAGS.output_dir + '_ft')\n    logging.info('Fine-tuning completed, %s files were filtered out by heuristic.', len(failed_heuristic_ids))\n    for failed_id in failed_heuristic_ids:\n        failed_entry = files_to_process[failed_id]\n        remaining.append(failed_entry)\n    logging.info('In total, %s images were fine-tuned, while %s were not.', len(files_to_process) - len(failed_heuristic_ids), len(remaining))\n    for i in range(len(files_to_process)):\n        if files_to_process[i] not in remaining:\n            elements = files_to_process[i].split(' ')\n            source_file = os.path.join(FLAGS.output_dir + '_ft', FLAGS.ft_name + 'id_' + str(i), str(FLAGS.num_steps).zfill(10) + ('_flip' if FLAGS.flip else ''))\n            if len(elements) == 2:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n                target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n            else:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n                target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n            if not gfile.Exists(target_dir):\n                gfile.MakeDirs(target_dir)\n            logging.info('Copy refined result %s to %s.', source_file, target_file)\n            gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n            gfile.Copy(source_file + '.txt', target_file + '.txt', overwrite=True)\n            gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    for j in range(len(remaining)):\n        elements = remaining[j].split(' ')\n        if len(elements) == 2:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n            target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n        else:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n            target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n        if not gfile.Exists(target_dir):\n            gfile.MakeDirs(target_dir)\n        source_file = target_file.replace('_ft', '')\n        logging.info('Copy unrefined result %s to %s.', source_file, target_file)\n        gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n        gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    logging.info('Done, predictions saved in %s.', FLAGS.output_dir + '_ft')",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Runs fine-tuning and inference.\\n\\n  There are three categories of images.\\n  1) Images where we have previous and next frame, and that are not filtered\\n     out by the heuristic. For them, we will use the fine-tuned predictions.\\n  2) Images where we have previous and next frame, but that were filtered out\\n     by our heuristic. For them, we will use the ordinary prediction instead.\\n  3) Images where we have at least one missing adjacent frame. For them, we will\\n     use the ordinary prediction as indicated by triplet_list_file_remains (if\\n     provided). They will also not be part of the generated inference list in\\n     the first place.\\n\\n  Raises:\\n     ValueError: Invalid parameters have been passed.\\n  '\n    if FLAGS.handle_motion and FLAGS.joint_encoder:\n        raise ValueError('Using a joint encoder is currently not supported when modeling object motion.')\n    if FLAGS.handle_motion and FLAGS.seq_length != 3:\n        raise ValueError('The current motion model implementation only supports using a sequence length of three.')\n    if FLAGS.handle_motion and (not FLAGS.compute_minimum_loss):\n        raise ValueError('Computing the minimum photometric loss is required when enabling object motion handling.')\n    if FLAGS.size_constraint_weight > 0 and (not FLAGS.handle_motion):\n        raise ValueError('To enforce object size constraints, enable motion handling.')\n    if FLAGS.icp_weight > 0.0:\n        raise ValueError('ICP is currently not supported.')\n    if FLAGS.compute_minimum_loss and FLAGS.seq_length % 2 != 1:\n        raise ValueError('Compute minimum loss requires using an odd number of images in a sequence.')\n    if FLAGS.compute_minimum_loss and FLAGS.exhaustive_mode:\n        raise ValueError('Exhaustive mode has no effect when compute_minimum_loss is enabled.')\n    if FLAGS.img_width % 2 ** 5 != 0 or FLAGS.img_height % 2 ** 5 != 0:\n        logging.warn('Image size is not divisible by 2^5. For the architecture employed, this could cause artefacts caused by resizing in lower dimensions.')\n    if FLAGS.output_dir.endswith('/'):\n        FLAGS.output_dir = FLAGS.output_dir[:-1]\n    unique_file_name = str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '_')\n    unique_file = os.path.join(FLAGS.data_dir, unique_file_name + '.txt')\n    with gfile.FastGFile(FLAGS.triplet_list_file, 'r') as f:\n        files_to_process = f.readlines()\n        files_to_process = [line.rstrip() for line in files_to_process]\n        files_to_process = [line for line in files_to_process if len(line)]\n    logging.info('Creating unique file list %s with %s entries.', unique_file, len(files_to_process))\n    with gfile.FastGFile(unique_file, 'w') as f_out:\n        fetches_network = FLAGS.num_steps * FLAGS.batch_size\n        fetches_saves = FLAGS.batch_size * int(np.floor(FLAGS.num_steps / SAVE_EVERY))\n        repetitions = fetches_network + 3 * fetches_saves\n        for i in range(len(files_to_process)):\n            for _ in range(repetitions):\n                f_out.write(files_to_process[i] + '\\n')\n    remaining = []\n    if gfile.Exists(FLAGS.triplet_list_file_remains):\n        with gfile.FastGFile(FLAGS.triplet_list_file_remains, 'r') as f:\n            remaining = f.readlines()\n            remaining = [line.rstrip() for line in remaining]\n            remaining = [line for line in remaining if len(line)]\n    logging.info('Running fine-tuning on %s files, %s files are remaining.', len(files_to_process), len(remaining))\n    tf.set_random_seed(FIXED_SEED)\n    np.random.seed(FIXED_SEED)\n    random.seed(FIXED_SEED)\n    flipping_mode = reader.FLIP_ALWAYS if FLAGS.flip else reader.FLIP_NONE\n    train_model = model.Model(data_dir=FLAGS.data_dir, file_extension=FLAGS.file_extension, is_training=True, learning_rate=FLAGS.learning_rate, beta1=FLAGS.beta1, reconstr_weight=FLAGS.reconstr_weight, smooth_weight=FLAGS.smooth_weight, ssim_weight=FLAGS.ssim_weight, icp_weight=FLAGS.icp_weight, batch_size=FLAGS.batch_size, img_height=FLAGS.img_height, img_width=FLAGS.img_width, seq_length=FLAGS.seq_length, architecture=FLAGS.architecture, imagenet_norm=FLAGS.imagenet_norm, weight_reg=FLAGS.weight_reg, exhaustive_mode=FLAGS.exhaustive_mode, random_scale_crop=FLAGS.random_scale_crop, flipping_mode=flipping_mode, random_color=False, depth_upsampling=FLAGS.depth_upsampling, depth_normalization=FLAGS.depth_normalization, compute_minimum_loss=FLAGS.compute_minimum_loss, use_skip=FLAGS.use_skip, joint_encoder=FLAGS.joint_encoder, build_sum=False, shuffle=False, input_file=unique_file_name, handle_motion=FLAGS.handle_motion, size_constraint_weight=FLAGS.size_constraint_weight, train_global_scale_var=False)\n    failed_heuristic_ids = finetune_inference(train_model, FLAGS.model_ckpt, FLAGS.output_dir + '_ft')\n    logging.info('Fine-tuning completed, %s files were filtered out by heuristic.', len(failed_heuristic_ids))\n    for failed_id in failed_heuristic_ids:\n        failed_entry = files_to_process[failed_id]\n        remaining.append(failed_entry)\n    logging.info('In total, %s images were fine-tuned, while %s were not.', len(files_to_process) - len(failed_heuristic_ids), len(remaining))\n    for i in range(len(files_to_process)):\n        if files_to_process[i] not in remaining:\n            elements = files_to_process[i].split(' ')\n            source_file = os.path.join(FLAGS.output_dir + '_ft', FLAGS.ft_name + 'id_' + str(i), str(FLAGS.num_steps).zfill(10) + ('_flip' if FLAGS.flip else ''))\n            if len(elements) == 2:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n                target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n            else:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n                target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n            if not gfile.Exists(target_dir):\n                gfile.MakeDirs(target_dir)\n            logging.info('Copy refined result %s to %s.', source_file, target_file)\n            gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n            gfile.Copy(source_file + '.txt', target_file + '.txt', overwrite=True)\n            gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    for j in range(len(remaining)):\n        elements = remaining[j].split(' ')\n        if len(elements) == 2:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n            target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n        else:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n            target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n        if not gfile.Exists(target_dir):\n            gfile.MakeDirs(target_dir)\n        source_file = target_file.replace('_ft', '')\n        logging.info('Copy unrefined result %s to %s.', source_file, target_file)\n        gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n        gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    logging.info('Done, predictions saved in %s.', FLAGS.output_dir + '_ft')",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Runs fine-tuning and inference.\\n\\n  There are three categories of images.\\n  1) Images where we have previous and next frame, and that are not filtered\\n     out by the heuristic. For them, we will use the fine-tuned predictions.\\n  2) Images where we have previous and next frame, but that were filtered out\\n     by our heuristic. For them, we will use the ordinary prediction instead.\\n  3) Images where we have at least one missing adjacent frame. For them, we will\\n     use the ordinary prediction as indicated by triplet_list_file_remains (if\\n     provided). They will also not be part of the generated inference list in\\n     the first place.\\n\\n  Raises:\\n     ValueError: Invalid parameters have been passed.\\n  '\n    if FLAGS.handle_motion and FLAGS.joint_encoder:\n        raise ValueError('Using a joint encoder is currently not supported when modeling object motion.')\n    if FLAGS.handle_motion and FLAGS.seq_length != 3:\n        raise ValueError('The current motion model implementation only supports using a sequence length of three.')\n    if FLAGS.handle_motion and (not FLAGS.compute_minimum_loss):\n        raise ValueError('Computing the minimum photometric loss is required when enabling object motion handling.')\n    if FLAGS.size_constraint_weight > 0 and (not FLAGS.handle_motion):\n        raise ValueError('To enforce object size constraints, enable motion handling.')\n    if FLAGS.icp_weight > 0.0:\n        raise ValueError('ICP is currently not supported.')\n    if FLAGS.compute_minimum_loss and FLAGS.seq_length % 2 != 1:\n        raise ValueError('Compute minimum loss requires using an odd number of images in a sequence.')\n    if FLAGS.compute_minimum_loss and FLAGS.exhaustive_mode:\n        raise ValueError('Exhaustive mode has no effect when compute_minimum_loss is enabled.')\n    if FLAGS.img_width % 2 ** 5 != 0 or FLAGS.img_height % 2 ** 5 != 0:\n        logging.warn('Image size is not divisible by 2^5. For the architecture employed, this could cause artefacts caused by resizing in lower dimensions.')\n    if FLAGS.output_dir.endswith('/'):\n        FLAGS.output_dir = FLAGS.output_dir[:-1]\n    unique_file_name = str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '_')\n    unique_file = os.path.join(FLAGS.data_dir, unique_file_name + '.txt')\n    with gfile.FastGFile(FLAGS.triplet_list_file, 'r') as f:\n        files_to_process = f.readlines()\n        files_to_process = [line.rstrip() for line in files_to_process]\n        files_to_process = [line for line in files_to_process if len(line)]\n    logging.info('Creating unique file list %s with %s entries.', unique_file, len(files_to_process))\n    with gfile.FastGFile(unique_file, 'w') as f_out:\n        fetches_network = FLAGS.num_steps * FLAGS.batch_size\n        fetches_saves = FLAGS.batch_size * int(np.floor(FLAGS.num_steps / SAVE_EVERY))\n        repetitions = fetches_network + 3 * fetches_saves\n        for i in range(len(files_to_process)):\n            for _ in range(repetitions):\n                f_out.write(files_to_process[i] + '\\n')\n    remaining = []\n    if gfile.Exists(FLAGS.triplet_list_file_remains):\n        with gfile.FastGFile(FLAGS.triplet_list_file_remains, 'r') as f:\n            remaining = f.readlines()\n            remaining = [line.rstrip() for line in remaining]\n            remaining = [line for line in remaining if len(line)]\n    logging.info('Running fine-tuning on %s files, %s files are remaining.', len(files_to_process), len(remaining))\n    tf.set_random_seed(FIXED_SEED)\n    np.random.seed(FIXED_SEED)\n    random.seed(FIXED_SEED)\n    flipping_mode = reader.FLIP_ALWAYS if FLAGS.flip else reader.FLIP_NONE\n    train_model = model.Model(data_dir=FLAGS.data_dir, file_extension=FLAGS.file_extension, is_training=True, learning_rate=FLAGS.learning_rate, beta1=FLAGS.beta1, reconstr_weight=FLAGS.reconstr_weight, smooth_weight=FLAGS.smooth_weight, ssim_weight=FLAGS.ssim_weight, icp_weight=FLAGS.icp_weight, batch_size=FLAGS.batch_size, img_height=FLAGS.img_height, img_width=FLAGS.img_width, seq_length=FLAGS.seq_length, architecture=FLAGS.architecture, imagenet_norm=FLAGS.imagenet_norm, weight_reg=FLAGS.weight_reg, exhaustive_mode=FLAGS.exhaustive_mode, random_scale_crop=FLAGS.random_scale_crop, flipping_mode=flipping_mode, random_color=False, depth_upsampling=FLAGS.depth_upsampling, depth_normalization=FLAGS.depth_normalization, compute_minimum_loss=FLAGS.compute_minimum_loss, use_skip=FLAGS.use_skip, joint_encoder=FLAGS.joint_encoder, build_sum=False, shuffle=False, input_file=unique_file_name, handle_motion=FLAGS.handle_motion, size_constraint_weight=FLAGS.size_constraint_weight, train_global_scale_var=False)\n    failed_heuristic_ids = finetune_inference(train_model, FLAGS.model_ckpt, FLAGS.output_dir + '_ft')\n    logging.info('Fine-tuning completed, %s files were filtered out by heuristic.', len(failed_heuristic_ids))\n    for failed_id in failed_heuristic_ids:\n        failed_entry = files_to_process[failed_id]\n        remaining.append(failed_entry)\n    logging.info('In total, %s images were fine-tuned, while %s were not.', len(files_to_process) - len(failed_heuristic_ids), len(remaining))\n    for i in range(len(files_to_process)):\n        if files_to_process[i] not in remaining:\n            elements = files_to_process[i].split(' ')\n            source_file = os.path.join(FLAGS.output_dir + '_ft', FLAGS.ft_name + 'id_' + str(i), str(FLAGS.num_steps).zfill(10) + ('_flip' if FLAGS.flip else ''))\n            if len(elements) == 2:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n                target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n            else:\n                target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n                target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n            if not gfile.Exists(target_dir):\n                gfile.MakeDirs(target_dir)\n            logging.info('Copy refined result %s to %s.', source_file, target_file)\n            gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n            gfile.Copy(source_file + '.txt', target_file + '.txt', overwrite=True)\n            gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    for j in range(len(remaining)):\n        elements = remaining[j].split(' ')\n        if len(elements) == 2:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', elements[0])\n            target_file = os.path.join(target_dir, elements[1] + ('_flip' if FLAGS.flip else ''))\n        else:\n            target_dir = os.path.join(FLAGS.output_dir + '_ft', os.path.dirname(elements[2]))\n            target_file = os.path.join(target_dir, os.path.basename(elements[2]) + ('_flip' if FLAGS.flip else ''))\n        if not gfile.Exists(target_dir):\n            gfile.MakeDirs(target_dir)\n        source_file = target_file.replace('_ft', '')\n        logging.info('Copy unrefined result %s to %s.', source_file, target_file)\n        gfile.Copy(source_file + '.npy', target_file + '.npy', overwrite=True)\n        gfile.Copy(source_file + '.%s' % FLAGS.file_extension, target_file + '.%s' % FLAGS.file_extension, overwrite=True)\n    logging.info('Done, predictions saved in %s.', FLAGS.output_dir + '_ft')"
        ]
    },
    {
        "func_name": "finetune_inference",
        "original": "def finetune_inference(train_model, model_ckpt, output_dir):\n    \"\"\"Train model.\"\"\"\n    vars_to_restore = None\n    if model_ckpt is not None:\n        vars_to_restore = util.get_vars_to_save_and_restore(model_ckpt)\n        ckpt_path = model_ckpt\n    pretrain_restorer = tf.train.Saver(vars_to_restore)\n    sv = tf.train.Supervisor(logdir=None, save_summaries_secs=0, saver=None, summary_op=None)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    img_nr = 0\n    failed_heuristic = []\n    with sv.managed_session(config=config) as sess:\n        while True:\n            if model_ckpt is not None:\n                logging.info('Restored weights from %s', ckpt_path)\n                pretrain_restorer.restore(sess, ckpt_path)\n            logging.info('Running fine-tuning, image %s...', img_nr)\n            img_pred_folder = os.path.join(output_dir, FLAGS.ft_name + 'id_' + str(img_nr))\n            if not gfile.Exists(img_pred_folder):\n                gfile.MakeDirs(img_pred_folder)\n            step = 1\n            while step <= FLAGS.num_steps:\n                logging.info('Running step %s of %s.', step, FLAGS.num_steps)\n                fetches = {'train': train_model.train_op, 'global_step': train_model.global_step, 'incr_global_step': train_model.incr_global_step}\n                _ = sess.run(fetches)\n                if step % SAVE_EVERY == 0:\n                    pred = train_model.depth[1][0].eval(session=sess)\n                    if FLAGS.flip:\n                        pred = np.flip(pred, axis=2)\n                    input_img = train_model.image_stack.eval(session=sess)\n                    input_img_prev = input_img[0, :, :, 0:3]\n                    input_img_center = input_img[0, :, :, 3:6]\n                    input_img_next = input_img[0, :, :, 6:]\n                    img_pred_file = os.path.join(img_pred_folder, str(step).zfill(10) + ('_flip' if FLAGS.flip else '') + '.npy')\n                    motion = np.squeeze(train_model.egomotion.eval(session=sess))\n                    motion = np.mean(motion, axis=0)\n                    if SAVE_PREVIEWS or step == FLAGS.num_steps:\n                        color_map = util.normalize_depth_for_display(np.squeeze(pred[0, :, :]))\n                        visualization = np.concatenate((input_img_prev, input_img_center, input_img_next, color_map))\n                        motion_s = [str(m) for m in motion]\n                        s_rep = ','.join(motion_s)\n                        with gfile.Open(img_pred_file.replace('.npy', '.txt'), 'w') as f:\n                            f.write(s_rep)\n                        util.save_image(img_pred_file.replace('.npy', '.%s' % FLAGS.file_extension), visualization, FLAGS.file_extension)\n                    with gfile.Open(img_pred_file, 'wb') as f:\n                        np.save(f, pred)\n                ego_magnitude = np.linalg.norm(motion[:3], ord=2)\n                heuristic = ego_magnitude >= FLAGS.egomotion_threshold\n                if not heuristic and step == FLAGS.num_steps:\n                    failed_heuristic.append(img_nr)\n                step += 1\n            img_nr += 1\n    return failed_heuristic",
        "mutated": [
            "def finetune_inference(train_model, model_ckpt, output_dir):\n    if False:\n        i = 10\n    'Train model.'\n    vars_to_restore = None\n    if model_ckpt is not None:\n        vars_to_restore = util.get_vars_to_save_and_restore(model_ckpt)\n        ckpt_path = model_ckpt\n    pretrain_restorer = tf.train.Saver(vars_to_restore)\n    sv = tf.train.Supervisor(logdir=None, save_summaries_secs=0, saver=None, summary_op=None)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    img_nr = 0\n    failed_heuristic = []\n    with sv.managed_session(config=config) as sess:\n        while True:\n            if model_ckpt is not None:\n                logging.info('Restored weights from %s', ckpt_path)\n                pretrain_restorer.restore(sess, ckpt_path)\n            logging.info('Running fine-tuning, image %s...', img_nr)\n            img_pred_folder = os.path.join(output_dir, FLAGS.ft_name + 'id_' + str(img_nr))\n            if not gfile.Exists(img_pred_folder):\n                gfile.MakeDirs(img_pred_folder)\n            step = 1\n            while step <= FLAGS.num_steps:\n                logging.info('Running step %s of %s.', step, FLAGS.num_steps)\n                fetches = {'train': train_model.train_op, 'global_step': train_model.global_step, 'incr_global_step': train_model.incr_global_step}\n                _ = sess.run(fetches)\n                if step % SAVE_EVERY == 0:\n                    pred = train_model.depth[1][0].eval(session=sess)\n                    if FLAGS.flip:\n                        pred = np.flip(pred, axis=2)\n                    input_img = train_model.image_stack.eval(session=sess)\n                    input_img_prev = input_img[0, :, :, 0:3]\n                    input_img_center = input_img[0, :, :, 3:6]\n                    input_img_next = input_img[0, :, :, 6:]\n                    img_pred_file = os.path.join(img_pred_folder, str(step).zfill(10) + ('_flip' if FLAGS.flip else '') + '.npy')\n                    motion = np.squeeze(train_model.egomotion.eval(session=sess))\n                    motion = np.mean(motion, axis=0)\n                    if SAVE_PREVIEWS or step == FLAGS.num_steps:\n                        color_map = util.normalize_depth_for_display(np.squeeze(pred[0, :, :]))\n                        visualization = np.concatenate((input_img_prev, input_img_center, input_img_next, color_map))\n                        motion_s = [str(m) for m in motion]\n                        s_rep = ','.join(motion_s)\n                        with gfile.Open(img_pred_file.replace('.npy', '.txt'), 'w') as f:\n                            f.write(s_rep)\n                        util.save_image(img_pred_file.replace('.npy', '.%s' % FLAGS.file_extension), visualization, FLAGS.file_extension)\n                    with gfile.Open(img_pred_file, 'wb') as f:\n                        np.save(f, pred)\n                ego_magnitude = np.linalg.norm(motion[:3], ord=2)\n                heuristic = ego_magnitude >= FLAGS.egomotion_threshold\n                if not heuristic and step == FLAGS.num_steps:\n                    failed_heuristic.append(img_nr)\n                step += 1\n            img_nr += 1\n    return failed_heuristic",
            "def finetune_inference(train_model, model_ckpt, output_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Train model.'\n    vars_to_restore = None\n    if model_ckpt is not None:\n        vars_to_restore = util.get_vars_to_save_and_restore(model_ckpt)\n        ckpt_path = model_ckpt\n    pretrain_restorer = tf.train.Saver(vars_to_restore)\n    sv = tf.train.Supervisor(logdir=None, save_summaries_secs=0, saver=None, summary_op=None)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    img_nr = 0\n    failed_heuristic = []\n    with sv.managed_session(config=config) as sess:\n        while True:\n            if model_ckpt is not None:\n                logging.info('Restored weights from %s', ckpt_path)\n                pretrain_restorer.restore(sess, ckpt_path)\n            logging.info('Running fine-tuning, image %s...', img_nr)\n            img_pred_folder = os.path.join(output_dir, FLAGS.ft_name + 'id_' + str(img_nr))\n            if not gfile.Exists(img_pred_folder):\n                gfile.MakeDirs(img_pred_folder)\n            step = 1\n            while step <= FLAGS.num_steps:\n                logging.info('Running step %s of %s.', step, FLAGS.num_steps)\n                fetches = {'train': train_model.train_op, 'global_step': train_model.global_step, 'incr_global_step': train_model.incr_global_step}\n                _ = sess.run(fetches)\n                if step % SAVE_EVERY == 0:\n                    pred = train_model.depth[1][0].eval(session=sess)\n                    if FLAGS.flip:\n                        pred = np.flip(pred, axis=2)\n                    input_img = train_model.image_stack.eval(session=sess)\n                    input_img_prev = input_img[0, :, :, 0:3]\n                    input_img_center = input_img[0, :, :, 3:6]\n                    input_img_next = input_img[0, :, :, 6:]\n                    img_pred_file = os.path.join(img_pred_folder, str(step).zfill(10) + ('_flip' if FLAGS.flip else '') + '.npy')\n                    motion = np.squeeze(train_model.egomotion.eval(session=sess))\n                    motion = np.mean(motion, axis=0)\n                    if SAVE_PREVIEWS or step == FLAGS.num_steps:\n                        color_map = util.normalize_depth_for_display(np.squeeze(pred[0, :, :]))\n                        visualization = np.concatenate((input_img_prev, input_img_center, input_img_next, color_map))\n                        motion_s = [str(m) for m in motion]\n                        s_rep = ','.join(motion_s)\n                        with gfile.Open(img_pred_file.replace('.npy', '.txt'), 'w') as f:\n                            f.write(s_rep)\n                        util.save_image(img_pred_file.replace('.npy', '.%s' % FLAGS.file_extension), visualization, FLAGS.file_extension)\n                    with gfile.Open(img_pred_file, 'wb') as f:\n                        np.save(f, pred)\n                ego_magnitude = np.linalg.norm(motion[:3], ord=2)\n                heuristic = ego_magnitude >= FLAGS.egomotion_threshold\n                if not heuristic and step == FLAGS.num_steps:\n                    failed_heuristic.append(img_nr)\n                step += 1\n            img_nr += 1\n    return failed_heuristic",
            "def finetune_inference(train_model, model_ckpt, output_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Train model.'\n    vars_to_restore = None\n    if model_ckpt is not None:\n        vars_to_restore = util.get_vars_to_save_and_restore(model_ckpt)\n        ckpt_path = model_ckpt\n    pretrain_restorer = tf.train.Saver(vars_to_restore)\n    sv = tf.train.Supervisor(logdir=None, save_summaries_secs=0, saver=None, summary_op=None)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    img_nr = 0\n    failed_heuristic = []\n    with sv.managed_session(config=config) as sess:\n        while True:\n            if model_ckpt is not None:\n                logging.info('Restored weights from %s', ckpt_path)\n                pretrain_restorer.restore(sess, ckpt_path)\n            logging.info('Running fine-tuning, image %s...', img_nr)\n            img_pred_folder = os.path.join(output_dir, FLAGS.ft_name + 'id_' + str(img_nr))\n            if not gfile.Exists(img_pred_folder):\n                gfile.MakeDirs(img_pred_folder)\n            step = 1\n            while step <= FLAGS.num_steps:\n                logging.info('Running step %s of %s.', step, FLAGS.num_steps)\n                fetches = {'train': train_model.train_op, 'global_step': train_model.global_step, 'incr_global_step': train_model.incr_global_step}\n                _ = sess.run(fetches)\n                if step % SAVE_EVERY == 0:\n                    pred = train_model.depth[1][0].eval(session=sess)\n                    if FLAGS.flip:\n                        pred = np.flip(pred, axis=2)\n                    input_img = train_model.image_stack.eval(session=sess)\n                    input_img_prev = input_img[0, :, :, 0:3]\n                    input_img_center = input_img[0, :, :, 3:6]\n                    input_img_next = input_img[0, :, :, 6:]\n                    img_pred_file = os.path.join(img_pred_folder, str(step).zfill(10) + ('_flip' if FLAGS.flip else '') + '.npy')\n                    motion = np.squeeze(train_model.egomotion.eval(session=sess))\n                    motion = np.mean(motion, axis=0)\n                    if SAVE_PREVIEWS or step == FLAGS.num_steps:\n                        color_map = util.normalize_depth_for_display(np.squeeze(pred[0, :, :]))\n                        visualization = np.concatenate((input_img_prev, input_img_center, input_img_next, color_map))\n                        motion_s = [str(m) for m in motion]\n                        s_rep = ','.join(motion_s)\n                        with gfile.Open(img_pred_file.replace('.npy', '.txt'), 'w') as f:\n                            f.write(s_rep)\n                        util.save_image(img_pred_file.replace('.npy', '.%s' % FLAGS.file_extension), visualization, FLAGS.file_extension)\n                    with gfile.Open(img_pred_file, 'wb') as f:\n                        np.save(f, pred)\n                ego_magnitude = np.linalg.norm(motion[:3], ord=2)\n                heuristic = ego_magnitude >= FLAGS.egomotion_threshold\n                if not heuristic and step == FLAGS.num_steps:\n                    failed_heuristic.append(img_nr)\n                step += 1\n            img_nr += 1\n    return failed_heuristic",
            "def finetune_inference(train_model, model_ckpt, output_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Train model.'\n    vars_to_restore = None\n    if model_ckpt is not None:\n        vars_to_restore = util.get_vars_to_save_and_restore(model_ckpt)\n        ckpt_path = model_ckpt\n    pretrain_restorer = tf.train.Saver(vars_to_restore)\n    sv = tf.train.Supervisor(logdir=None, save_summaries_secs=0, saver=None, summary_op=None)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    img_nr = 0\n    failed_heuristic = []\n    with sv.managed_session(config=config) as sess:\n        while True:\n            if model_ckpt is not None:\n                logging.info('Restored weights from %s', ckpt_path)\n                pretrain_restorer.restore(sess, ckpt_path)\n            logging.info('Running fine-tuning, image %s...', img_nr)\n            img_pred_folder = os.path.join(output_dir, FLAGS.ft_name + 'id_' + str(img_nr))\n            if not gfile.Exists(img_pred_folder):\n                gfile.MakeDirs(img_pred_folder)\n            step = 1\n            while step <= FLAGS.num_steps:\n                logging.info('Running step %s of %s.', step, FLAGS.num_steps)\n                fetches = {'train': train_model.train_op, 'global_step': train_model.global_step, 'incr_global_step': train_model.incr_global_step}\n                _ = sess.run(fetches)\n                if step % SAVE_EVERY == 0:\n                    pred = train_model.depth[1][0].eval(session=sess)\n                    if FLAGS.flip:\n                        pred = np.flip(pred, axis=2)\n                    input_img = train_model.image_stack.eval(session=sess)\n                    input_img_prev = input_img[0, :, :, 0:3]\n                    input_img_center = input_img[0, :, :, 3:6]\n                    input_img_next = input_img[0, :, :, 6:]\n                    img_pred_file = os.path.join(img_pred_folder, str(step).zfill(10) + ('_flip' if FLAGS.flip else '') + '.npy')\n                    motion = np.squeeze(train_model.egomotion.eval(session=sess))\n                    motion = np.mean(motion, axis=0)\n                    if SAVE_PREVIEWS or step == FLAGS.num_steps:\n                        color_map = util.normalize_depth_for_display(np.squeeze(pred[0, :, :]))\n                        visualization = np.concatenate((input_img_prev, input_img_center, input_img_next, color_map))\n                        motion_s = [str(m) for m in motion]\n                        s_rep = ','.join(motion_s)\n                        with gfile.Open(img_pred_file.replace('.npy', '.txt'), 'w') as f:\n                            f.write(s_rep)\n                        util.save_image(img_pred_file.replace('.npy', '.%s' % FLAGS.file_extension), visualization, FLAGS.file_extension)\n                    with gfile.Open(img_pred_file, 'wb') as f:\n                        np.save(f, pred)\n                ego_magnitude = np.linalg.norm(motion[:3], ord=2)\n                heuristic = ego_magnitude >= FLAGS.egomotion_threshold\n                if not heuristic and step == FLAGS.num_steps:\n                    failed_heuristic.append(img_nr)\n                step += 1\n            img_nr += 1\n    return failed_heuristic",
            "def finetune_inference(train_model, model_ckpt, output_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Train model.'\n    vars_to_restore = None\n    if model_ckpt is not None:\n        vars_to_restore = util.get_vars_to_save_and_restore(model_ckpt)\n        ckpt_path = model_ckpt\n    pretrain_restorer = tf.train.Saver(vars_to_restore)\n    sv = tf.train.Supervisor(logdir=None, save_summaries_secs=0, saver=None, summary_op=None)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    img_nr = 0\n    failed_heuristic = []\n    with sv.managed_session(config=config) as sess:\n        while True:\n            if model_ckpt is not None:\n                logging.info('Restored weights from %s', ckpt_path)\n                pretrain_restorer.restore(sess, ckpt_path)\n            logging.info('Running fine-tuning, image %s...', img_nr)\n            img_pred_folder = os.path.join(output_dir, FLAGS.ft_name + 'id_' + str(img_nr))\n            if not gfile.Exists(img_pred_folder):\n                gfile.MakeDirs(img_pred_folder)\n            step = 1\n            while step <= FLAGS.num_steps:\n                logging.info('Running step %s of %s.', step, FLAGS.num_steps)\n                fetches = {'train': train_model.train_op, 'global_step': train_model.global_step, 'incr_global_step': train_model.incr_global_step}\n                _ = sess.run(fetches)\n                if step % SAVE_EVERY == 0:\n                    pred = train_model.depth[1][0].eval(session=sess)\n                    if FLAGS.flip:\n                        pred = np.flip(pred, axis=2)\n                    input_img = train_model.image_stack.eval(session=sess)\n                    input_img_prev = input_img[0, :, :, 0:3]\n                    input_img_center = input_img[0, :, :, 3:6]\n                    input_img_next = input_img[0, :, :, 6:]\n                    img_pred_file = os.path.join(img_pred_folder, str(step).zfill(10) + ('_flip' if FLAGS.flip else '') + '.npy')\n                    motion = np.squeeze(train_model.egomotion.eval(session=sess))\n                    motion = np.mean(motion, axis=0)\n                    if SAVE_PREVIEWS or step == FLAGS.num_steps:\n                        color_map = util.normalize_depth_for_display(np.squeeze(pred[0, :, :]))\n                        visualization = np.concatenate((input_img_prev, input_img_center, input_img_next, color_map))\n                        motion_s = [str(m) for m in motion]\n                        s_rep = ','.join(motion_s)\n                        with gfile.Open(img_pred_file.replace('.npy', '.txt'), 'w') as f:\n                            f.write(s_rep)\n                        util.save_image(img_pred_file.replace('.npy', '.%s' % FLAGS.file_extension), visualization, FLAGS.file_extension)\n                    with gfile.Open(img_pred_file, 'wb') as f:\n                        np.save(f, pred)\n                ego_magnitude = np.linalg.norm(motion[:3], ord=2)\n                heuristic = ego_magnitude >= FLAGS.egomotion_threshold\n                if not heuristic and step == FLAGS.num_steps:\n                    failed_heuristic.append(img_nr)\n                step += 1\n            img_nr += 1\n    return failed_heuristic"
        ]
    }
]