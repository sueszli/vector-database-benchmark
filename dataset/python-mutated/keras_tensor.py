"""Keras Input Tensor used to track functional API Topology."""
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import sparse_tensor
from tensorflow.python.framework import tensor as tensor_lib
from tensorflow.python.framework import tensor_shape
from tensorflow.python.framework import type_spec as type_spec_module
from tensorflow.python.keras.utils import object_identity
from tensorflow.python.ops import array_ops
from tensorflow.python.ops.ragged import ragged_operators
from tensorflow.python.ops.ragged import ragged_tensor
from tensorflow.python.util import nest
_MAX_TENSOR_RANK = 254

class KerasTensor(object):
    """A representation of a Keras in/output during Functional API construction.

  `KerasTensor`s are tensor-like objects that represent the symbolic inputs
  and outputs of Keras layers during Functional model construction. They are
  comprised of the `tf.TypeSpec` of the (Composite)Tensor that will be
  consumed/produced in the corresponding location of the Functional model.

  KerasTensors are intended as a private API, so users should never need to
  directly instantiate `KerasTensor`s.

  **Building Functional Models with KerasTensors**
  `tf.keras.Input` produces `KerasTensor`s that represent the symbolic inputs
  to your model.

  Passing a `KerasTensor` to a `tf.keras.Layer` `__call__` lets the layer know
  that you are building a Functional model. The layer __call__ will
  infer the output signature and return `KerasTensor`s with `tf.TypeSpec`s
  corresponding to the symbolic outputs of that layer call. These output
  `KerasTensor`s will have all of the internal KerasHistory metadata attached
  to them that Keras needs to construct a Functional Model.

  Currently, layers infer the output signature by:
    * creating a scratch `FuncGraph`
    * making placeholders in the scratch graph that match the input typespecs
    * Calling `layer.call` on these placeholders
    * extracting the signatures of the outputs before clearing the scratch graph

  (Note: names assigned to KerasTensors by this process are not guaranteed to
  be unique, and are subject to implementation details).

  `tf.nest` methods are used to insure all of the inputs/output data
  structures get maintained, with elements swapped between KerasTensors and
  placeholders.

  In rare cases (such as when directly manipulating shapes using Keras layers),
  the layer may be able to partially infer the value of the output in addition
  to just inferring the signature.
  When this happens, the returned KerasTensor will also contain the inferred
  value information. Follow-on layers can use this information.
  during their own output signature inference.
  E.g. if one layer produces a symbolic `KerasTensor` that the next layer uses
  as the shape of its outputs, partially knowing the value helps infer the
  output shape.

  **Automatically converting TF APIs to layers**:
  If you passing a `KerasTensor` to a TF API that supports dispatching,
  Keras will automatically turn that API call into a lambda
  layer in the Functional model, and return KerasTensors representing the
  symbolic outputs.

  Most TF APIs that take only tensors as input and produce output tensors
  will support dispatching.

  Calling a `tf.function` does not support dispatching, so you cannot pass
  `KerasTensor`s as inputs to a `tf.function`.

  Higher-order APIs that take methods which produce tensors (e.g. `tf.while`,
  `tf.map_fn`, `tf.cond`) also do not currently support dispatching. So, you
  cannot directly pass KerasTensors as inputs to these APIs either. If you
  want to use these APIs inside of a Functional model, you must put them inside
  of a custom layer.

  Args:
    type_spec: The `tf.TypeSpec` for the symbolic input created by
      `tf.keras.Input`, or symbolically inferred for the output
      during a symbolic layer `__call__`.
    inferred_value: (Optional) a non-symbolic static value, possibly partially
      specified, that could be symbolically inferred for the outputs during
      a symbolic layer `__call__`. This will generally only happen when
      grabbing and manipulating `tf.int32` shapes directly as tensors.
      Statically inferring values in this way and storing them in the
      KerasTensor allows follow-on layers to infer output signatures
      more effectively. (e.g. when using a symbolic shape tensor to later
      construct a tensor with that shape).
    name: (optional) string name for this KerasTensor. Names automatically
      generated by symbolic layer `__call__`s are not guaranteed to be unique,
      and are subject to implementation details.
  """

    def __init__(self, type_spec, inferred_value=None, name=None):
        if False:
            i = 10
            return i + 15
        'Constructs a KerasTensor.'
        if not isinstance(type_spec, type_spec_module.TypeSpec):
            raise ValueError('KerasTensors must be constructed with a `tf.TypeSpec`.')
        self._type_spec = type_spec
        self._inferred_value = inferred_value
        self._name = name

    @property
    def type_spec(self):
        if False:
            while True:
                i = 10
        'Returns the `tf.TypeSpec` symbolically inferred for this Keras output.'
        return self._type_spec

    @property
    def shape(self):
        if False:
            i = 10
            return i + 15
        'Returns the `TensorShape` symbolically inferred for this Keras output.'
        return self._type_spec._shape

    @classmethod
    def from_tensor(cls, tensor):
        if False:
            i = 10
            return i + 15
        'Convert a traced (composite)tensor to a representative KerasTensor.'
        if isinstance(tensor, tensor_lib.Tensor):
            name = getattr(tensor, 'name', None)
            type_spec = type_spec_module.type_spec_from_value(tensor)
            inferred_value = None
            if type_spec.dtype == dtypes.int32 and type_spec.shape.rank is not None and (type_spec.shape.rank < 2):
                inferred_value = array_ops.ones(shape=tensor).shape
                if inferred_value.dims:
                    inferred_value = inferred_value.as_list()
                    if len(inferred_value) > _MAX_TENSOR_RANK:
                        inferred_value = None
                else:
                    inferred_value = None
            return KerasTensor(type_spec, inferred_value=inferred_value, name=name)
        else:
            name = getattr(tensor, 'name', None)
            type_spec = type_spec_module.type_spec_from_value(tensor)
            return cls(type_spec, name=name)

    @classmethod
    def from_type_spec(cls, type_spec, name=None):
        if False:
            return 10
        return cls(type_spec=type_spec, name=name)

    def _to_placeholder(self):
        if False:
            return 10
        'Convert this KerasTensor to a placeholder in a graph.'
        if self._inferred_value is not None:
            inferred_value = array_ops.shape(array_ops.placeholder(shape=self._inferred_value, dtype=dtypes.int32))
            if self.type_spec.shape.rank == 0:
                inferred_value = inferred_value[0]
            return inferred_value

        def component_to_placeholder(component):
            if False:
                i = 10
                return i + 15
            return array_ops.placeholder(component.dtype, component.shape)
        return nest.map_structure(component_to_placeholder, self.type_spec, expand_composites=True)

    def get_shape(self) -> tensor_shape.TensorShape:
        if False:
            print('Hello World!')
        return self.shape

    def __len__(self):
        if False:
            while True:
                i = 10
        raise TypeError('Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.')

    @property
    def op(self):
        if False:
            for i in range(10):
                print('nop')
        raise TypeError('Keras symbolic inputs/outputs do not implement `op`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.')

    def __hash__(self):
        if False:
            for i in range(10):
                print('nop')
        raise TypeError('Tensors are unhashable. (%s)Instead, use tensor.ref() as the key.' % self)
    __array_priority__ = 100

    def __array__(self):
        if False:
            print('Hello World!')
        raise TypeError("Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.")

    @property
    def is_tensor_like(self):
        if False:
            for i in range(10):
                print('nop')
        return True

    def set_shape(self, shape):
        if False:
            i = 10
            return i + 15
        'Updates the shape of this KerasTensor. Mimics `tf.Tensor.set_shape()`.'
        if not isinstance(shape, tensor_shape.TensorShape):
            shape = tensor_shape.TensorShape(shape)
        if shape.dims is not None:
            dim_list = [dim.value for dim in shape.dims]
            for dim in range(len(dim_list)):
                if dim_list[dim] is None and self.shape.dims is not None:
                    dim_list[dim] = self.shape.dims[dim]
            shape = tensor_shape.TensorShape(dim_list)
        if not self.shape.is_compatible_with(shape):
            raise ValueError("Keras symbolic input/output's shape %s is notcompatible with supplied shape %s" % (self.shape, shape))
        else:
            self._type_spec._shape = shape

    def __str__(self):
        if False:
            i = 10
            return i + 15
        symbolic_description = ''
        inferred_value_string = ''
        name_string = ''
        if hasattr(self, '_keras_history'):
            layer = self._keras_history.layer
            symbolic_description = ', description="created by layer \'%s\'"' % (layer.name,)
        if self._inferred_value is not None:
            inferred_value_string = ', inferred_value=%s' % self._inferred_value
        if self.name is not None:
            name_string = ", name='%s'" % self._name
        return 'KerasTensor(type_spec=%s%s%s%s)' % (self.type_spec, inferred_value_string, name_string, symbolic_description)

    def __repr__(self):
        if False:
            for i in range(10):
                print('nop')
        symbolic_description = ''
        inferred_value_string = ''
        if isinstance(self.type_spec, tensor_lib.TensorSpec):
            type_spec_string = 'shape=%s dtype=%s' % (self.shape, self.dtype.name)
        else:
            type_spec_string = 'type_spec=%s' % self.type_spec
        if hasattr(self, '_keras_history'):
            layer = self._keras_history.layer
            symbolic_description = " (created by layer '%s')" % (layer.name,)
        if self._inferred_value is not None:
            inferred_value_string = ' inferred_value=%s' % self._inferred_value
        return '<KerasTensor: %s%s%s>' % (type_spec_string, inferred_value_string, symbolic_description)

    @property
    def dtype(self):
        if False:
            i = 10
            return i + 15
        'Returns the `dtype` symbolically inferred for this Keras output.'
        return self._type_spec._dtype

    def ref(self):
        if False:
            print('Hello World!')
        "Returns a hashable reference object to this KerasTensor.\n\n    The primary use case for this API is to put KerasTensors in a\n    set/dictionary. We can't put tensors in a set/dictionary as\n    `tensor.__hash__()` is not available and tensor equality (`==`) is supposed\n    to produce a tensor representing if the two inputs are equal.\n\n    See the documentation of `tf.Tensor.ref()` for more info.\n    "
        return object_identity.Reference(self)

    def __iter__(self):
        if False:
            i = 10
            return i + 15
        shape = None
        if self.shape.ndims is not None:
            shape = [dim.value for dim in self.shape.dims]
        if shape is None:
            raise TypeError('Cannot iterate over a Tensor with unknown shape.')
        if not shape:
            raise TypeError('Cannot iterate over a scalar.')
        if shape[0] is None:
            raise TypeError('Cannot iterate over a Tensor with unknown first dimension.')
        return _KerasTensorIterator(self, shape[0])

    @property
    def name(self):
        if False:
            while True:
                i = 10
        'Returns the (non-unique, optional) name of this symbolic Keras value.'
        return self._name

    @classmethod
    def _overload_all_operators(cls, tensor_class):
        if False:
            i = 10
            return i + 15
        'Register overloads for all operators.'
        for operator in tensor_lib.Tensor.OVERLOADABLE_OPERATORS:
            cls._overload_operator(tensor_class, operator)
        if hasattr(tensor_class, 'experimental_ref'):
            cls._overload_operator(tensor_class, 'experimental_ref')

    @classmethod
    def _overload_operator(cls, tensor_class, operator):
        if False:
            while True:
                i = 10
        'Overload an operator with the same implementation as a base Tensor class.\n\n    We pull the operator out of the class dynamically to avoid ordering issues.\n\n    Args:\n      tensor_class: The (Composite)Tensor to get the method from.\n      operator: string. The operator name.\n    '
        tensor_oper = getattr(tensor_class, operator)
        tensor_oper = getattr(tensor_oper, '__func__', tensor_oper)
        setattr(cls, operator, tensor_oper)
KerasTensor._overload_all_operators(tensor_lib.Tensor)

class SparseKerasTensor(KerasTensor):
    """A specialized KerasTensor representation for `tf.sparse.SparseTensor`s.

  Specifically, it specializes the conversion to a placeholder in order
  to maintain dense shape information.
  """

    def _to_placeholder(self):
        if False:
            for i in range(10):
                print('nop')
        spec = self.type_spec
        return array_ops.sparse_placeholder(dtype=spec.dtype, shape=spec.shape)

class RaggedKerasTensor(KerasTensor):
    """A specialized KerasTensor representation for `tf.RaggedTensor`s.

  Specifically, it:

  1. Specializes the conversion to a placeholder in order
  to maintain shape information for non-ragged dimensions.
  2. Overloads the KerasTensor's operators with the RaggedTensor versions
  when they don't match the `tf.Tensor` versions
  3. Exposes some of the instance method/attribute that are unique to
  the RaggedTensor API (such as ragged_rank).
  """

    def _to_placeholder(self):
        if False:
            return 10
        ragged_spec = self.type_spec
        if ragged_spec.ragged_rank == 0 or ragged_spec.shape.rank is None:
            return super(RaggedKerasTensor, self)._to_placeholder()
        flat_shape = ragged_spec.shape[ragged_spec.ragged_rank:]
        result = array_ops.placeholder(ragged_spec.dtype, flat_shape)
        known_num_splits = []
        prod = 1
        for axis_size in ragged_spec.shape:
            if prod is not None:
                if axis_size is None or getattr(axis_size, 'value', True) is None:
                    prod = None
                else:
                    prod = prod * axis_size
            known_num_splits.append(prod)
        for axis in range(ragged_spec.ragged_rank, 0, -1):
            axis_size = ragged_spec.shape[axis]
            if axis_size is None or getattr(axis_size, 'value', True) is None:
                num_splits = known_num_splits[axis - 1]
                if num_splits is not None:
                    num_splits = num_splits + 1
                splits = array_ops.placeholder(ragged_spec.row_splits_dtype, [num_splits])
                result = ragged_tensor.RaggedTensor.from_row_splits(result, splits, validate=False)
            else:
                rowlen = constant_op.constant(axis_size, ragged_spec.row_splits_dtype)
                result = ragged_tensor.RaggedTensor.from_uniform_row_length(result, rowlen, validate=False)
        return result

    @property
    def ragged_rank(self):
        if False:
            for i in range(10):
                print('nop')
        return self.type_spec.ragged_rank
RaggedKerasTensor._overload_operator(ragged_tensor.RaggedTensor, '__getitem__')
RaggedKerasTensor._overload_operator(ragged_tensor.RaggedTensor, '__add__')
RaggedKerasTensor._overload_operator(ragged_tensor.RaggedTensor, '__radd__')
RaggedKerasTensor._overload_operator(ragged_tensor.RaggedTensor, '__mul__')
RaggedKerasTensor._overload_operator(ragged_tensor.RaggedTensor, '__rmul__')

class UserRegisteredSpec(type_spec_module.TypeSpec):
    """TypeSpec to represent user-registered symbolic objects."""

    def __init__(self, shape, dtype):
        if False:
            return 10
        self.shape = shape
        self._dtype = dtype
        self.dtype = dtype

    def _component_specs(self):
        if False:
            return 10
        raise NotImplementedError

    def _from_components(self, components):
        if False:
            while True:
                i = 10
        raise NotImplementedError

    def _serialize(self):
        if False:
            return 10
        raise NotImplementedError

    def _to_components(self, value):
        if False:
            return 10
        raise NotImplementedError

    def value_type(self):
        if False:
            for i in range(10):
                print('nop')
        raise NotImplementedError

class UserRegisteredTypeKerasTensor(KerasTensor):
    """KerasTensor that represents legacy register_symbolic_tensor_type."""

    def __init__(self, user_registered_symbolic_object):
        if False:
            while True:
                i = 10
        x = user_registered_symbolic_object
        self._user_registered_symbolic_object = x
        type_spec = UserRegisteredSpec(x.shape, x.dtype)
        name = getattr(x, 'name', None)
        super(UserRegisteredTypeKerasTensor, self).__init__(type_spec, name)

    @classmethod
    def from_tensor(cls, tensor):
        if False:
            i = 10
            return i + 15
        return cls(tensor)

    @classmethod
    def from_type_spec(cls, type_spec, name=None):
        if False:
            for i in range(10):
                print('nop')
        raise NotImplementedError('You cannot instantiate a KerasTensor directly from TypeSpec: %s' % type_spec)

    def _to_placeholder(self):
        if False:
            i = 10
            return i + 15
        return self._user_registered_symbolic_object

class _KerasTensorIterator(object):
    """Iterates over the leading dim of a KerasTensor. Performs 0 error checks."""

    def __init__(self, tensor, dim0):
        if False:
            while True:
                i = 10
        self._tensor = tensor
        self._index = 0
        self._limit = dim0

    def __iter__(self):
        if False:
            return 10
        return self

    def __next__(self):
        if False:
            return 10
        if self._index == self._limit:
            raise StopIteration
        result = self._tensor[self._index]
        self._index += 1
        return result
keras_tensor_classes = [(tensor_lib.Tensor, KerasTensor), (sparse_tensor.SparseTensor, SparseKerasTensor), (ragged_tensor.RaggedTensor, RaggedKerasTensor), (object, KerasTensor)]

def register_keras_tensor_specialization(cls, keras_tensor_subclass):
    if False:
        while True:
            i = 10
    'Register a specialized KerasTensor subclass for a Tensor type.'
    keras_tensor_classes.insert(-1, (cls, keras_tensor_subclass))

def keras_tensor_to_placeholder(x):
    if False:
        while True:
            i = 10
    'Construct a graph placeholder to represent a KerasTensor when tracing.'
    if isinstance(x, KerasTensor):
        return x._to_placeholder()
    else:
        return x

def keras_tensor_from_tensor(tensor):
    if False:
        print('Hello World!')
    'Convert a traced (composite)tensor to a representative KerasTensor.'
    keras_tensor_cls = None
    for (tensor_type, cls) in keras_tensor_classes:
        if isinstance(tensor, tensor_type):
            keras_tensor_cls = cls
            break
    out = keras_tensor_cls.from_tensor(tensor)
    if hasattr(tensor, '_keras_mask'):
        out._keras_mask = keras_tensor_from_tensor(tensor._keras_mask)
    return out

def keras_tensor_from_type_spec(type_spec, name=None):
    if False:
        while True:
            i = 10
    'Convert a TypeSpec to a representative KerasTensor.'
    keras_tensor_cls = None
    value_type = type_spec.value_type
    for (tensor_type, cls) in keras_tensor_classes:
        if issubclass(value_type, tensor_type):
            keras_tensor_cls = cls
            break
    return keras_tensor_cls.from_type_spec(type_spec, name=name)