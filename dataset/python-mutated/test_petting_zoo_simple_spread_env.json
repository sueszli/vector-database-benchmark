[
    {
        "func_name": "test_agent_obs_only",
        "original": "def test_agent_obs_only(self):\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    assert obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, np.ndarray), timestep.obs\n        assert timestep.obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n        assert timestep.reward.dtype == np.float32\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
        "mutated": [
            "def test_agent_obs_only(self):\n    if False:\n        i = 10\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    assert obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, np.ndarray), timestep.obs\n        assert timestep.obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n        assert timestep.reward.dtype == np.float32\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_obs_only(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    assert obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, np.ndarray), timestep.obs\n        assert timestep.obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n        assert timestep.reward.dtype == np.float32\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_obs_only(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    assert obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, np.ndarray), timestep.obs\n        assert timestep.obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n        assert timestep.reward.dtype == np.float32\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_obs_only(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    assert obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, np.ndarray), timestep.obs\n        assert timestep.obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n        assert timestep.reward.dtype == np.float32\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_obs_only(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    assert obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, np.ndarray), timestep.obs\n        assert timestep.obs.shape == (n_agent, 2 + 2 + (n_agent - 1) * 2 + n_agent * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n        assert timestep.reward.dtype == np.float32\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()"
        ]
    },
    {
        "func_name": "test_dict_obs",
        "original": "def test_dict_obs(self):\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2,)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['action_mask'].dtype == np.float32\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
        "mutated": [
            "def test_dict_obs(self):\n    if False:\n        i = 10\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2,)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['action_mask'].dtype == np.float32\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_dict_obs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2,)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['action_mask'].dtype == np.float32\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_dict_obs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2,)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['action_mask'].dtype == np.float32\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_dict_obs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2,)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['action_mask'].dtype == np.float32\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_dict_obs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2,)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['action_mask'].dtype == np.float32\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()"
        ]
    },
    {
        "func_name": "test_agent_specific_global_state",
        "original": "def test_agent_specific_global_state(self):\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, agent_specific_global_state=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2 + n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
        "mutated": [
            "def test_agent_specific_global_state(self):\n    if False:\n        i = 10\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, agent_specific_global_state=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2 + n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_specific_global_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, agent_specific_global_state=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2 + n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_specific_global_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, agent_specific_global_state=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2 + n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_specific_global_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, agent_specific_global_state=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2 + n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()",
            "def test_agent_specific_global_state(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    n_agent = 5\n    n_landmark = n_agent\n    env = PettingZooEnv(EasyDict(dict(env_family='mpe', env_id='simple_spread_v2', n_agent=n_agent, n_landmark=n_landmark, max_step=100, agent_obs_only=False, agent_specific_global_state=True, continuous_actions=True)))\n    env.seed(123)\n    assert env._seed == 123\n    obs = env.reset()\n    for (k, v) in obs.items():\n        print(k, v.shape)\n    for i in range(10):\n        random_action = env.random_action()\n        random_action = np.array([random_action[agent] for agent in random_action])\n        timestep = env.step(random_action)\n        print(timestep)\n        assert isinstance(timestep.obs, dict), timestep.obs\n        assert isinstance(timestep.obs['agent_state'], np.ndarray), timestep.obs\n        assert timestep.obs['agent_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['global_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2 + n_agent * (2 + 2) + n_landmark * 2 + n_agent * (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2)\n        assert timestep.obs['agent_alone_padding_state'].shape == (n_agent, 2 + 2 + n_landmark * 2 + (n_agent - 1) * 2 + (n_agent - 1) * 2)\n        assert isinstance(timestep.done, bool), timestep.done\n        assert isinstance(timestep.reward, np.ndarray), timestep.reward\n    print(env.observation_space, env.action_space, env.reward_space)\n    env.close()"
        ]
    }
]