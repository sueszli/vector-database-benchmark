[
    {
        "func_name": "__init__",
        "original": "def __init__(self, proj_grad=True, euclidean=False, lrs=(0.1,), rnd_init=False, seed=None, **kwargs):\n    \"\"\"Ctor.\"\"\"\n    del kwargs\n    super().__init__(proj_grad, euclidean, rnd_init, seed)\n    self.lrs = lrs",
        "mutated": [
            "def __init__(self, proj_grad=True, euclidean=False, lrs=(0.1,), rnd_init=False, seed=None, **kwargs):\n    if False:\n        i = 10\n    'Ctor.'\n    del kwargs\n    super().__init__(proj_grad, euclidean, rnd_init, seed)\n    self.lrs = lrs",
            "def __init__(self, proj_grad=True, euclidean=False, lrs=(0.1,), rnd_init=False, seed=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Ctor.'\n    del kwargs\n    super().__init__(proj_grad, euclidean, rnd_init, seed)\n    self.lrs = lrs",
            "def __init__(self, proj_grad=True, euclidean=False, lrs=(0.1,), rnd_init=False, seed=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Ctor.'\n    del kwargs\n    super().__init__(proj_grad, euclidean, rnd_init, seed)\n    self.lrs = lrs",
            "def __init__(self, proj_grad=True, euclidean=False, lrs=(0.1,), rnd_init=False, seed=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Ctor.'\n    del kwargs\n    super().__init__(proj_grad, euclidean, rnd_init, seed)\n    self.lrs = lrs",
            "def __init__(self, proj_grad=True, euclidean=False, lrs=(0.1,), rnd_init=False, seed=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Ctor.'\n    del kwargs\n    super().__init__(proj_grad, euclidean, rnd_init, seed)\n    self.lrs = lrs"
        ]
    },
    {
        "func_name": "compute_gradients",
        "original": "def compute_gradients(self, params, payoff_matrices):\n    \"\"\"Compute and return exploitability.\n\n    Args:\n      params: tuple of params (dist,), see ped.gradients\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\n        are sorted and arrays should be indexed in the same order\n    Returns:\n      float, exploitability of current dist\n      unregularized exploitability (stochastic estimate)\n      unregularized exploitability (stochastic estimate) *duplicate\n    \"\"\"\n    return gradients(*params, payoff_matrices, self.num_players, self.proj_grad)",
        "mutated": [
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n    'Compute and return exploitability.\\n\\n    Args:\\n      params: tuple of params (dist,), see ped.gradients\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      float, exploitability of current dist\\n      unregularized exploitability (stochastic estimate)\\n      unregularized exploitability (stochastic estimate) *duplicate\\n    '\n    return gradients(*params, payoff_matrices, self.num_players, self.proj_grad)",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute and return exploitability.\\n\\n    Args:\\n      params: tuple of params (dist,), see ped.gradients\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      float, exploitability of current dist\\n      unregularized exploitability (stochastic estimate)\\n      unregularized exploitability (stochastic estimate) *duplicate\\n    '\n    return gradients(*params, payoff_matrices, self.num_players, self.proj_grad)",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute and return exploitability.\\n\\n    Args:\\n      params: tuple of params (dist,), see ped.gradients\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      float, exploitability of current dist\\n      unregularized exploitability (stochastic estimate)\\n      unregularized exploitability (stochastic estimate) *duplicate\\n    '\n    return gradients(*params, payoff_matrices, self.num_players, self.proj_grad)",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute and return exploitability.\\n\\n    Args:\\n      params: tuple of params (dist,), see ped.gradients\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      float, exploitability of current dist\\n      unregularized exploitability (stochastic estimate)\\n      unregularized exploitability (stochastic estimate) *duplicate\\n    '\n    return gradients(*params, payoff_matrices, self.num_players, self.proj_grad)",
            "def compute_gradients(self, params, payoff_matrices):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute and return exploitability.\\n\\n    Args:\\n      params: tuple of params (dist,), see ped.gradients\\n      payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    Returns:\\n      float, exploitability of current dist\\n      unregularized exploitability (stochastic estimate)\\n      unregularized exploitability (stochastic estimate) *duplicate\\n    '\n    return gradients(*params, payoff_matrices, self.num_players, self.proj_grad)"
        ]
    },
    {
        "func_name": "gradients",
        "original": "def gradients(dist, payoff_matrices, num_players, proj_grad=True):\n    \"\"\"Computes exploitablity gradient.\n\n  Args:\n    dist: list of 1-d np.arrays, current estimate of nash distribution\n    payoff_matrices: dictionary with keys as tuples of agents (i, j) and\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\n        are sorted and arrays should be indexed in the same order\n    num_players: int, number of players, in case payoff_matrices is abbreviated\n    proj_grad: bool, if True, projects dist gradient onto simplex\n  Returns:\n    gradient of exploitability w.r.t. (dist) as tuple\n    unregularized exploitability (stochastic estimate)\n    unregularized exploitability (stochastic estimate) *duplicate\n  \"\"\"\n    nabla = []\n    br = []\n    unreg_exp = []\n    for i in range(num_players):\n        nabla_i = np.zeros_like(dist[i])\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_i_ij = payoff_matrices[i, j][0]\n            else:\n                hess_i_ij = payoff_matrices[j, i][1].T\n            nabla_ij = hess_i_ij.dot(dist[j])\n            nabla_i += nabla_ij / float(num_players - 1)\n        nabla.append(nabla_i)\n        power = np.inf\n        s_i = np.linalg.norm(nabla_i, ord=power)\n        br_i = np.zeros_like(nabla_i)\n        maxima_i = nabla_i == s_i\n        br_i[maxima_i] = 1.0 / maxima_i.sum()\n        br.append(br_i)\n        unreg_exp.append(np.max(nabla_i) - nabla_i.dot(dist[i]))\n    grad_dist = []\n    for i in range(num_players):\n        grad_dist_i = -nabla[i]\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_j_ij = payoff_matrices[i, j][1]\n            else:\n                hess_j_ij = payoff_matrices[j, i][0].T\n            grad_dist_i += hess_j_ij.dot(br[j] - dist[j])\n        if proj_grad:\n            grad_dist_i = simplex.project_grad(grad_dist_i)\n        grad_dist.append(grad_dist_i)\n    return ((grad_dist,), np.mean(unreg_exp), np.mean(unreg_exp))",
        "mutated": [
            "def gradients(dist, payoff_matrices, num_players, proj_grad=True):\n    if False:\n        i = 10\n    'Computes exploitablity gradient.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    num_players: int, number of players, in case payoff_matrices is abbreviated\\n    proj_grad: bool, if True, projects dist gradient onto simplex\\n  Returns:\\n    gradient of exploitability w.r.t. (dist) as tuple\\n    unregularized exploitability (stochastic estimate)\\n    unregularized exploitability (stochastic estimate) *duplicate\\n  '\n    nabla = []\n    br = []\n    unreg_exp = []\n    for i in range(num_players):\n        nabla_i = np.zeros_like(dist[i])\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_i_ij = payoff_matrices[i, j][0]\n            else:\n                hess_i_ij = payoff_matrices[j, i][1].T\n            nabla_ij = hess_i_ij.dot(dist[j])\n            nabla_i += nabla_ij / float(num_players - 1)\n        nabla.append(nabla_i)\n        power = np.inf\n        s_i = np.linalg.norm(nabla_i, ord=power)\n        br_i = np.zeros_like(nabla_i)\n        maxima_i = nabla_i == s_i\n        br_i[maxima_i] = 1.0 / maxima_i.sum()\n        br.append(br_i)\n        unreg_exp.append(np.max(nabla_i) - nabla_i.dot(dist[i]))\n    grad_dist = []\n    for i in range(num_players):\n        grad_dist_i = -nabla[i]\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_j_ij = payoff_matrices[i, j][1]\n            else:\n                hess_j_ij = payoff_matrices[j, i][0].T\n            grad_dist_i += hess_j_ij.dot(br[j] - dist[j])\n        if proj_grad:\n            grad_dist_i = simplex.project_grad(grad_dist_i)\n        grad_dist.append(grad_dist_i)\n    return ((grad_dist,), np.mean(unreg_exp), np.mean(unreg_exp))",
            "def gradients(dist, payoff_matrices, num_players, proj_grad=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Computes exploitablity gradient.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    num_players: int, number of players, in case payoff_matrices is abbreviated\\n    proj_grad: bool, if True, projects dist gradient onto simplex\\n  Returns:\\n    gradient of exploitability w.r.t. (dist) as tuple\\n    unregularized exploitability (stochastic estimate)\\n    unregularized exploitability (stochastic estimate) *duplicate\\n  '\n    nabla = []\n    br = []\n    unreg_exp = []\n    for i in range(num_players):\n        nabla_i = np.zeros_like(dist[i])\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_i_ij = payoff_matrices[i, j][0]\n            else:\n                hess_i_ij = payoff_matrices[j, i][1].T\n            nabla_ij = hess_i_ij.dot(dist[j])\n            nabla_i += nabla_ij / float(num_players - 1)\n        nabla.append(nabla_i)\n        power = np.inf\n        s_i = np.linalg.norm(nabla_i, ord=power)\n        br_i = np.zeros_like(nabla_i)\n        maxima_i = nabla_i == s_i\n        br_i[maxima_i] = 1.0 / maxima_i.sum()\n        br.append(br_i)\n        unreg_exp.append(np.max(nabla_i) - nabla_i.dot(dist[i]))\n    grad_dist = []\n    for i in range(num_players):\n        grad_dist_i = -nabla[i]\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_j_ij = payoff_matrices[i, j][1]\n            else:\n                hess_j_ij = payoff_matrices[j, i][0].T\n            grad_dist_i += hess_j_ij.dot(br[j] - dist[j])\n        if proj_grad:\n            grad_dist_i = simplex.project_grad(grad_dist_i)\n        grad_dist.append(grad_dist_i)\n    return ((grad_dist,), np.mean(unreg_exp), np.mean(unreg_exp))",
            "def gradients(dist, payoff_matrices, num_players, proj_grad=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Computes exploitablity gradient.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    num_players: int, number of players, in case payoff_matrices is abbreviated\\n    proj_grad: bool, if True, projects dist gradient onto simplex\\n  Returns:\\n    gradient of exploitability w.r.t. (dist) as tuple\\n    unregularized exploitability (stochastic estimate)\\n    unregularized exploitability (stochastic estimate) *duplicate\\n  '\n    nabla = []\n    br = []\n    unreg_exp = []\n    for i in range(num_players):\n        nabla_i = np.zeros_like(dist[i])\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_i_ij = payoff_matrices[i, j][0]\n            else:\n                hess_i_ij = payoff_matrices[j, i][1].T\n            nabla_ij = hess_i_ij.dot(dist[j])\n            nabla_i += nabla_ij / float(num_players - 1)\n        nabla.append(nabla_i)\n        power = np.inf\n        s_i = np.linalg.norm(nabla_i, ord=power)\n        br_i = np.zeros_like(nabla_i)\n        maxima_i = nabla_i == s_i\n        br_i[maxima_i] = 1.0 / maxima_i.sum()\n        br.append(br_i)\n        unreg_exp.append(np.max(nabla_i) - nabla_i.dot(dist[i]))\n    grad_dist = []\n    for i in range(num_players):\n        grad_dist_i = -nabla[i]\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_j_ij = payoff_matrices[i, j][1]\n            else:\n                hess_j_ij = payoff_matrices[j, i][0].T\n            grad_dist_i += hess_j_ij.dot(br[j] - dist[j])\n        if proj_grad:\n            grad_dist_i = simplex.project_grad(grad_dist_i)\n        grad_dist.append(grad_dist_i)\n    return ((grad_dist,), np.mean(unreg_exp), np.mean(unreg_exp))",
            "def gradients(dist, payoff_matrices, num_players, proj_grad=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Computes exploitablity gradient.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    num_players: int, number of players, in case payoff_matrices is abbreviated\\n    proj_grad: bool, if True, projects dist gradient onto simplex\\n  Returns:\\n    gradient of exploitability w.r.t. (dist) as tuple\\n    unregularized exploitability (stochastic estimate)\\n    unregularized exploitability (stochastic estimate) *duplicate\\n  '\n    nabla = []\n    br = []\n    unreg_exp = []\n    for i in range(num_players):\n        nabla_i = np.zeros_like(dist[i])\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_i_ij = payoff_matrices[i, j][0]\n            else:\n                hess_i_ij = payoff_matrices[j, i][1].T\n            nabla_ij = hess_i_ij.dot(dist[j])\n            nabla_i += nabla_ij / float(num_players - 1)\n        nabla.append(nabla_i)\n        power = np.inf\n        s_i = np.linalg.norm(nabla_i, ord=power)\n        br_i = np.zeros_like(nabla_i)\n        maxima_i = nabla_i == s_i\n        br_i[maxima_i] = 1.0 / maxima_i.sum()\n        br.append(br_i)\n        unreg_exp.append(np.max(nabla_i) - nabla_i.dot(dist[i]))\n    grad_dist = []\n    for i in range(num_players):\n        grad_dist_i = -nabla[i]\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_j_ij = payoff_matrices[i, j][1]\n            else:\n                hess_j_ij = payoff_matrices[j, i][0].T\n            grad_dist_i += hess_j_ij.dot(br[j] - dist[j])\n        if proj_grad:\n            grad_dist_i = simplex.project_grad(grad_dist_i)\n        grad_dist.append(grad_dist_i)\n    return ((grad_dist,), np.mean(unreg_exp), np.mean(unreg_exp))",
            "def gradients(dist, payoff_matrices, num_players, proj_grad=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Computes exploitablity gradient.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_matrices: dictionary with keys as tuples of agents (i, j) and\\n        values of (2 x A x A) np.arrays, payoffs for each joint action. keys\\n        are sorted and arrays should be indexed in the same order\\n    num_players: int, number of players, in case payoff_matrices is abbreviated\\n    proj_grad: bool, if True, projects dist gradient onto simplex\\n  Returns:\\n    gradient of exploitability w.r.t. (dist) as tuple\\n    unregularized exploitability (stochastic estimate)\\n    unregularized exploitability (stochastic estimate) *duplicate\\n  '\n    nabla = []\n    br = []\n    unreg_exp = []\n    for i in range(num_players):\n        nabla_i = np.zeros_like(dist[i])\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_i_ij = payoff_matrices[i, j][0]\n            else:\n                hess_i_ij = payoff_matrices[j, i][1].T\n            nabla_ij = hess_i_ij.dot(dist[j])\n            nabla_i += nabla_ij / float(num_players - 1)\n        nabla.append(nabla_i)\n        power = np.inf\n        s_i = np.linalg.norm(nabla_i, ord=power)\n        br_i = np.zeros_like(nabla_i)\n        maxima_i = nabla_i == s_i\n        br_i[maxima_i] = 1.0 / maxima_i.sum()\n        br.append(br_i)\n        unreg_exp.append(np.max(nabla_i) - nabla_i.dot(dist[i]))\n    grad_dist = []\n    for i in range(num_players):\n        grad_dist_i = -nabla[i]\n        for j in range(num_players):\n            if j == i:\n                continue\n            if i < j:\n                hess_j_ij = payoff_matrices[i, j][1]\n            else:\n                hess_j_ij = payoff_matrices[j, i][0].T\n            grad_dist_i += hess_j_ij.dot(br[j] - dist[j])\n        if proj_grad:\n            grad_dist_i = simplex.project_grad(grad_dist_i)\n        grad_dist.append(grad_dist_i)\n    return ((grad_dist,), np.mean(unreg_exp), np.mean(unreg_exp))"
        ]
    }
]